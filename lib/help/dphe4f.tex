49900.      (VERSION 2023.09)   total number of lines in file (including this line)
 4.                          number of     sections below
  100.    L                  first line number of L section
20300.    M                  first line number of M section
39200.    N                  first line number of N section
45400.    O                  first line number of O section
 
----------------------------------------------------------
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
-------------------------  *L*  ZZZZZ--------------------
 
-----LABEL-------------------------------------------------------
 
LABEL
 
Name:
    ...LABEL
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the horizontal and vertical axis labels to appear on
    subsequent plots.
 
Description:
    The labels are the text which appear below the bottom horizontal
    frame line and outside of the vertical frame lines.  They
    typically define the variables/axes which are being plotted.  The
    labels are automatically centered and so no positioning is needed.
    The labels appear on all subsequent plots until blanked out (via
    the ...LABEL command with no arguments) or until overridden with
    new labels.  The analyst can define 5 plot labels:
       1) 3 below the bottom horizontal frame;
       2) 1 to the left of the left vertical frame;
       3) 1 to the right of the right vertical frame line.
    The label is specified by the prefix in the command.
 
Syntax:
    <prefix>LABEL   <text>
    where <text> specifies the text for the axis label (all characters
             after LABEL);
    and   <prefix> is one of the following:
             X1        refers to the first horizontal label
             X2        refers to the second horizontal label
             X3        refers to the third  horizontal label
             X         refers to the first horizontal label
             Y1        refers to the left vertical label
             Y2        refers to the right vertical label
             Y         refers to the left and right vertical labels
             no prefix refers to all 5 axis labels.
 
Examples:
    Y1LABEL TEMPERATURE
    X1LABEL TIME (IN SECONDS)
    X2LABEL SOLID = LAB 1   DOTTED = LAB 2
    X3LABEL DATA SOURCE = DATA.ASTM
 
Note:
    A ...LABEL command with no arguments blanks out the label.  Thus
    X1LABEL with no arguments blanks out the first horizontal axis
    label.  A ...LABEL command with no prefix refers to all 5 labels.
    Thus LABEL XXX assigns the text XXX to all 5 labels.  LABEL with
    no prefix and no arguments blanks out all 5 labels.  This is at
    times convenient if the analyst is finished with the analysis of
    one data set and wishes to start off with "clean" labels prior to
    the analysis of a completely different data set.
 
Default:
    All labels are blank.
 
Synonyms:
    None
 
Related Commands:
    PLOT                = Generates a data or function plot.
    LABEL AUTOMATIC     = Sets automatically generated labels.
    LABEL CASE          = Sets the case (upper/lower) for labels.
    LABEL COLOR         = Sets the color for plot labels.
    LABEL DISPLACEMENT  = Sets the distance from the frame to the
                          labels.
    LABEL FONT          = Sets the plot label fonts.
    LABEL SIZE          = Sets the size (height) for plot labels.
    LABEL THICKNESS     = Sets the line thickness for plot labels.
    TEXT                = Writes a text string.
    TITLE               = Sets the plot title.
    LEGEND              = Sets the plot legends.
    LEGEND COORDINATES  = Sets the locations for plot legends.
    BOX COORDINATES     = Sets the locations for plot boxes.
    ARROW COORDINATES   = Sets the locations for plot arrows.
    SEGMENT COORDINATES = Sets the locations for plot segments.
    FRAME               = Sets the on/off switch for plot frame.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE LABEL COMMAND
    X1LABEL LEAD
    X2LABEL POLLUTION SOURCE ANALYSIS: LLOYD CURRIE
    Y1LABEL POTASSIUM
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    PLOT POT VS LEAD
 
-----LABEL AUTOMATIC--------------------------------------------------
 
LABEL AUTOMATIC
 
Name:
    ...LABEL AUTOMATIC
 
Type:
    Plot Control Command
 
Purpose:
    Generates automatic labels for either the first horizontal axis or
    the left vertical axis.
 
Description:
    The vertical axis contains the second argument of the PLOT command
    while the horizontal axis contains the third argument of the PLOT
    command.  That is, PLOT TEMP TIME uses TEMP as the left vertical
    axis label and TIME for the first horizontal axis label.
    Specifying AUTOMATIC for the right vertical axis or the second and
    third horizontal axis results in the word AUTOMATIC being printed
    for the label.
 
Syntax 1: (for first horizontal axis)
    XLABEL AUTOMATIC
    X1LABEL AUTOMATIC
 
Syntax 2: (for the left vertical axis)
    Y1LABEL AUTOMATIC
 
Examples:
    Y1LABEL AUTOMATIC
    X1LABEL AUTOMATIC
    XLABEL AUTOMATIC
 
Default:
    All labels are blank.
 
Synonyms:
    None
 
Related Commands:
    TITLE AUTOMATIC     = Sets an automatic title.
    PLOT                = Generates a data or function plot.
    LABEL               = Specifies the labels for the plot axes.
    LABEL CASE          = Sets the case (upper/lower) for labels.
    LABEL COLOR         = Sets the color for plot labels.
    LABEL DISPLACEMENT  = Sets the distance from the frame to the
                          labels.
    LABEL FONT          = Sets the plot label fonts.
    LABEL SIZE          = Sets the size (height) for plot labels.
    LABEL THICKNESS     = Sets the line thickness for plot labels.
    TEXT                = Writes a text string.
    TITLE               = Sets the plot title.
    LEGEND              = Sets the plot legends.
    LEGEND COORDINATES  = Sets the locations for plot legends.
    BOX COORDINATES     = Sets the locations for plot boxes.
    ARROW COORDINATES   = Sets the locations for plot arrows.
    SEGMENT COORDINATES = Sets the locations for plot segments.
    FRAME               = Sets the on/off switch for plot frame.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE AUTOMATIC LABELS
    X1LABEL AUTOMATIC
    Y1LABEL AUTOMATIC
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    PLOT POT LEAD
 
-----LABEL CASE-------------------------------------------------------
 
LABEL CASE
 
Name:
    ...LABEL CASE
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the case of the labels (i.e., upper or lower) to appear
    on subsequent plots.
 
Description:
    The labels are the text which appear below the bottom horizontal
    frame line and outside of the vertical frame lines.  They
    typically define the variables/axes which are being plotted.  The
    label cases hold for all subsequent plots until defaulted (via the
    ...LABEL CASE command with no arguments) or until overridden with
    new label cases.  The analyst can define cases for all 5 plot
    labels:
       1) 3 below the bottom horizontal frame;
       2) 1 to the left of the left vertical frame;
       3) 1 to the right of the right vertical frame line.
    The label is specified by the prefix in the command.
 
Syntax:
    <prefix>LABEL CASE   <case>
    where <case> is either LOWER or UPPER;
    and   <prefix> is one of the following:
             X1        refers to the first horizontal label
             X2        refers to the second horizontal label
             X3        refers to the third  horizontal label
             X         refers to the first horizontal label
             Y1        refers to the left vertical label
             Y2        refers to the right vertical label
             Y         refers to the left and right vertical labels
             no prefix refers to all 5 axis labels.
 
    The specification of each individual label with a different case is
    rare.  The most common form (by far) for this command is the last
    one (with no prefix) which defines the case uniformly for all 5
    labels.
 
Examples:
    Y1LABEL CASE LOWER
    YLABEL CASE UPPER
    LABEL CASE UPPER
    LABEL CASE LOWER
 
Note:
    A ...LABEL CASE command with no arguments reverts the case to
    default.  Thus X1LABEL CASE with no arguments reverts the first
    horizontal axis label to default.  A ...LABEL CASE command with no
    prefix refers to all 5 labels.  Thus LABEL CASE LOWER assigns the
    case LOWER to all 5 labels.  LABEL CASE with no prefix and no
    arguments reverts all 5 labels to default.
 
Default:
    All label cases are upper case.
 
Synonyms:
    None
 
Related Commands:
    PLOT                = Generates a data or function plot.
    LABEL               = Specifies the labels for the plot axes.
    LABEL AUTOMATIC     = Sets automatically generated labels.
    LABEL COLOR         = Sets the color for plot labels.
    LABEL DISPLACEMENT  = Sets the distance from the frame to the
                          labels.
    LABEL FONT          = Sets the plot label fonts.
    LABEL SIZE          = Sets the size (height) for plot labels.
    LABEL THICKNESS     = Sets the line thickness for plot labels.
    TEXT                = Writes a text string.
    TITLE               = Sets the plot title.
    LEGEND              = Sets the plot legends.
    LEGEND COORDINATES  = Sets the locations for plot legends.
    BOX COORDINATES     = Sets the locations for plot boxes.
    ARROW COORDINATES   = Sets the locations for plot arrows.
    SEGMENT COORDINATES = Sets the locations for plot segments.
    FRAME               = Sets the on/off switch for plot frame.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE LABEL COMMAND
    X1LABEL LEAD
    Y1LABEL POTASSIUM
    LABEL CASE LOWER
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    PLOT POT VS LEAD
 
-----LABEL COLOR-------------------------------------------------------
 
LABEL COLOR
 
Name:
    ...LABEL COLOR
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the color of the labels to appear on subsequent plots.
 
Description:
    The labels are the text which appear below the bottom horizontal
    frame line and outside of the vertical frame lines.  They
    typically define the variables/axes which are being plotted.  The
    label colors hold for all subsequent plots until defaulted (via the
    ...LABEL COLOR command with no arguments) or until overridden with
    new label colors.  The analyst can define colors for all 5 plot
    labels:

       1) 3 below the bottom horizontal frame;
       2) 1 to the left of the left vertical frame;
       3) 1 to the right of the right vertical frame line.

    The label is specified by the prefix in the command.
 
    Dataplot provides two methods for specifying colors.

        1. Colors can be defined by name (or by the corresponding index).
           Dataplot adopted it's named colors from the X11 project.
           Currently, 162 named colors and 100 levels of grayscale are
           supported.  Grayscale can be specified with either G0, G1, ...,
           G100 (or -1, -2, ..., -100).  Many older devices support only a
           limited number of colors.  For these devices, unsupported colors
           will be mapped to one of the available colors.  To specify a
           named color, see Syntax 1.

        2. Most modern graphics devices support full RGB (RedBlueGreen)
           color.  You can alternatively specify RGB colors by entering
           three integer values to represent the Red, Green and Blue
           components, respectively.  These values should be in the range
           0 to 255.

    When setting the label RGB color, Dataplot first checks if the device
    supports RGB colors. If not, the named color will be used.  If the
    device does support RGB color, Dataplot will check if an RGB color
    has been specified.  If yes, then that RGB color is used.  If not,
    the named color will be used.

    To see the list of supported named colors (with the associated index
    number), see

    https://www.itl.nist.gov/div898/software/dataplot/refman1/ch11/homepage.htm

Syntax 1:
    <prefix>LABEL COLOR   <color>
    where <color> specifies the desired color;
    and   <prefix> is one of the following:
             X1        refers to the first horizontal label
             X2        refers to the second horizontal label
             X3        refers to the third  horizontal label
             X         refers to the first horizontal label
             Y1        refers to the left vertical label
             Y2        refers to the right vertical label
             Y         refers to the left and right vertical labels
             no prefix refers to all 5 axis labels.
 
    The specification of each individual label with a different color
    is rare.  The most common form (by far) for this command is the last
    one (with no prefix) which defines the color uniformly for all 5
    labels.
 
Syntax 2:
    <prefix>LABEL RGB COLOR  <red>  <green>  <blue>
    where <red> is a number or parameter that specifies the red
                component;
          <green> is a number or parameter that specifies the green
                component;
          <blue> is a number or parameter that specifies the blue
                component;
    and   <prefix> is one of the following:
             X1        refers to the first horizontal label
             X2        refers to the second horizontal label
             X3        refers to the third  horizontal label
             X         refers to the first horizontal label
             Y1        refers to the left vertical label
             Y2        refers to the right vertical label
             Y         refers to the left and right vertical labels
             no prefix refers to all 5 axis labels.
 
    The specification of each individual label with a different color
    is rare.  The most common form (by far) for this command is the last
    one (with no prefix) which defines the color uniformly for all 5
    labels.
 
    To turn off the RGB color, set the values to -1 (any negative value
    will work).  Values greater than 255 will be set to 255.

Examples:
    Y1LABEL COLOR BLUE
    YLABEL COLOR BLUE
    LABEL COLOR YELLOW
    LABEL COLOR WHITE
    LABEL RGB COLOR 238 238 75
 
Default:
    All label colors are black.
 
Synonyms:
    None
 
Note:
    A ...LABEL COLOR command with no arguments reverts the color to
    default.  Thus X1LABEL COLOR with no arguments reverts the first
    horizontal axis label to default.  A ...LABEL COLOR command with no
    prefix refers to all 5 labels.  Thus LABEL COLOR BLUE assigns the
    color BLUE to all 5 labels.  LABEL COLOR with no prefix and no
    arguments reverts all 5 labels to default.
 
Related Commands:
    PLOT                = Generates a data or function plot.
    LABEL               = Specifies the labels for the plot axes.
    LABEL AUTOMATIC     = Sets automatically generated labels.
    LABEL CASE          = Sets the case (upper/lower) for labels.
    LABEL DISPLACEMENT  = Sets the distance from the frame to the
                          labels.
    LABEL FONT          = Sets the plot label fonts.
    LABEL SIZE          = Sets the size (height) for plot labels.
    LABEL THICKNESS     = Sets the line thickness for plot labels.
    TEXT                = Writes a text string.
    TITLE               = Sets the plot title.
    LEGEND              = Sets the plot legends.
    FRAME               = Sets the on/off switch for the plot frame.
    TITLE COLOR         = Sets the color for the plot title.
    LEGEND COLOR        = Sets the color for plot legends.
    BOX COLOR           = Sets the color for plot boxes.
    ARROW COLOR         = Sets the color for plot arrows.
    SEGMENT COLOR       = Sets the color for plot segments.
    FRAME COLOR         = Sets the color for plot frame.
    GRID COLOR          = Sets the color for plot grids.
    TIC COLOR           = Sets the color for plot tics.
    TIC LABEL COLOR     = Sets the color for plot tic labels.
    MARGIN COLOR        = Sets the color for the plot margin.
    BACKGROUND COLOR    = Sets the color for the plot background.
    COLOR               = Sets the color of TEXT characters.
    CHARACTERS COLORS   = Sets the colors for plot characters.
    LINE COLORS         = Sets the colors for plot lines.
    SPIKE COLORS        = Sets the colors for plot spikes.
    BAR FILL COLORS     = Sets the colors for plot bar fills.
    BAR PATTERN COLORS  = Sets the colors for plot bar patterns.
    BAR BORDER COLORS   = Sets the colors for plot bar borders.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
    2020/10: Added support for RGB color
 
Program 1:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE LABEL COLOR
    X1LABEL LEAD
    Y1LABEL POTASSIUM
    X1LABEL COLOR RED
    Y1LABEL COLOR BLUE
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    PLOT POT VS LEAD
 
Program 2:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE LABEL RGB COLOR
    X1LABEL LEAD
    Y1LABEL POTASSIUM
    X1LABEL COLOR RED
    Y1LABEL COLOR BLUE
    X1LABEL RGB COLOR 220 109 88
    Y1LABEL RGB COLOR 175 238 238
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    PLOT POT VS LEAD
 
-----LABEL COORDINATES-----------------------------------------------
 
LABEL COORDINATES
 
Name:
    ...LABEL COORDINATES
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the positioning of labels to appear on subsequent plots.
 
Description:
    By default, the x coordinate of x axis labels is the mid-point of
    the frame coordinates.  For example, the default frame coordinates
    are (15,20) and (85,90) which results in a default x coordinate
    of (15+85)/2 = 50.  The y coordinate is determined by the LABEL
    DISPLACEMENT command.  This is specified in screen units from the
    frame line.  The default values for the X1LABEL, X2LABEL, and
    X3LABEL are 8, 11, 14, respectively.  This means the default y
    coordinates are 20 - 8 = 12, 20 - 11 = 9, and 20 -14 = 6,
    respectively.

    By default, the y coordinate of y axis labels is the mid-point of
    the frame coordinates.  The default y coordinate is (20+90)/2 = 55.
    The x coordinate is determined by the LABEL DISPLACEMENT command.
    This is specified in screen units from the frame line.  The default
    values for the Y1LABEL and Y2LABEL are 8 and 8, respectively.  This
    means the default x coordinates are 15 - 8 = 7 and 85 + 8 = 93,
    respectively.

    The axis labels are by default center justified to these coordinates.

    On occasion, you may want to have more control over the positioning
    of axis labels.  This can be accomplished with the LABEL COORDINATES
    and LABEL JUSTIFICATION commands.  The most common usages would be to
    left justify one of the horizontal labels from the left frame (or near
    the left frame) or to right justify one of the horizontal labels from
    the right frame (or near the right frame).

    The LABEL COORDINATES are given in 0 to 100 screen units (there is
    currently no provision for specifying the LABEL COORDINATES in data
    units).  If LABEL COORDINATES are outside this range they are
    ignored.  If LABEL COORDINATES are within this range, they will be
    used and any settings for LABEL DISPLACEMENT and LABEL OFFSET will be
    ignored.  The LABEL JUSTIFICATION settings will be relative to these
    coordinates.

    The LABEL DISPLACEMENT and LABEL OFFSET commands give an alternative
    way for positioning the axis labels.

    The label coordinates hold for all subsequent plots until defaulted
    (via the ...LABEL COORDINATE command with no arguments) or until
    overridden with new label coordinates.  The analyst can define
    coordinates for all five plot labels:

       1) 3 below the bottom horizontal frame;
       2) 1 to the left of the left vertical frame;
       3) 1 to the right of the right vertical frame line.

    The label is specified by the prefix in the command.
 
Syntax:
    <prefix>LABEL COORDINATES  <xcoor>  <ycoor>
    where <xcoor> is a number or parameter that specifies the desired
             x coordinate in units of 0 to 100;
          <ycoor> is a number or parameter that specifies the desired
             y coordinate in units of 0 to 100;
    and   <prefix> is one of the following:
             X1        refers to the first horizontal label
             X2        refers to the second horizontal label
             X3        refers to the third  horizontal label
             X         refers to the first horizontal label
             Y1        refers to the left vertical label
             Y2        refers to the right vertical label
             Y         refers to the left and right vertical labels
             no prefix refers to all 5 axis labels.

    If you only want to specify the x coordinate, you can omit the
    <ycoor> argument.  If you only want to specify the y coordinate, then
    enter a value for <xcoor> that is outside the 0 to 100 interval
    (e.g., use -1).

Examples:
    X1LABEL COORDINATES 15 14
    X1LABEL COORDINATES XCOOR YCOOR
    X1LABEL COORDINATES 15
    X1LABEL COORDINATES -1  6
    Y1LABEL COORDINATES 2 55

Note:
    A ...LABEL COORDINATES command with no arguments will use the
    default positioning.  Thus X1LABEL COORDINATES with no arguments
    reverts the first horizontal axis label to default.  A
    ...LABEL COORDINATES command with no prefix refers to all 5 labels.
    Thus LABEL COORDINATES restores the default positioning for all
    5 labels.

Default:
    Label positions are based on the FRAME CORNER COORDINATES and the
    LABEL DISPLACEMENT settings
 
Synonyms:
    None
 
Related Commands:
    PLOT                = Generates a data or function plot.
    LABEL               = Specifies the labels for the plot axes.
    LABEL AUTOMATIC     = Sets automatically generated labels.
    LABEL CASE          = Sets the case (upper/lower) for labels.
    LABEL COLOR         = Sets the color for plot labels.
    LABEL DISPLACEMENT  = Sets the distance from the frame to the
                          labels.
    LABEL FONT          = Sets the plot label fonts.
    LABEL SIZE          = Sets the character size for plot labels.
    LABEL THICKNESS     = Sets the line thickness for plot labels.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    2018/10
 
Program:
    label case asis
    .
    x1label coordinates 20 13
    x2label coordinates 50 10
    x3label coordinates 80  7
    y1label coordinates  2 55
    y2label coordinates 90 55
    .
    x1label just lebo
    x2label just cebo
    x3label just ribo
    .
    x1label Label 1
    x2label Label 2
    x3label Label 3
    y1label Left Y Axis
    y2label Right Y Axis
    .
    plot x**2 for x = 1 1 9

-----LABEL DISPLACEMENT-----------------------------------------------
 
LABEL DISPLACEMENT
 
Name:
    ...LABEL DISPLACEMENT
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the displacement (i.e., the distance from the frame to
    the label in DATAPLOT 0.0 to 100.0 coordinate units) of the labels
    to appear on subsequent plots.
 
Description:
    The labels are the text which appear below the bottom horizontal
    frame line and outside of the vertical frame lines.  They
    typically define the variables/axes which are being plotted.  The
    label displacements hold for all subsequent plots until defaulted
    (via the ...LABEL DISPLACEMENT command with no arguments) or until
    overridden with new label displacements.  The analyst can define
    displacements for all 5 plot labels:
       1) 3 below the bottom horizontal frame;
       2) 1 to the left of the left vertical frame;
       3) 1 to the right of the right vertical frame line.
    The label is specified by the prefix in the command.
 
Syntax:
    <prefix>LABEL DISPLACEMENT   <value>
    where <value> is a number or parameter that specifies the
             displacement;
    and   <prefix> is one of the following:
             X1        refers to the first horizontal label
             X2        refers to the second horizontal label
             X3        refers to the third  horizontal label
             X         refers to the first horizontal label
             Y1        refers to the left vertical label
             Y2        refers to the right vertical label
             Y         refers to the left and right vertical labels
             no prefix refers to all 5 axis labels.
 
Examples:
    Y1LABEL DISPLACEMENT 5.0
    YLABEL DISPLACEMENT 10
    X1LABEL DISPLACEMENT 5
    X3LABEL DISPLACEMENT 13
 
Note:
    A ...LABEL DISPLACEMENT command with no arguments reverts the
    displacement to default.  Thus X1LABEL DISPLACEMENT  with no
    arguments reverts the first horizontal axis label to default.  A
    ...LABEL DISPLACEMENT command with no prefix refers to all 5 labels.
    Thus LABEL DISPLACEMENT 8 assigns the displacement 8 to all 5
    labels.  LABEL DISPLACEMENT with no prefix and no arguments reverts
    all 5 labels to default.
 
Default:
    The default displacements are:
       X1LABEL  =  8.0
       X2LABEL  = 11.0
       X3LABEL  = 14.0
       Y1LABEL  = 8.0
       Y2LABEL  = 8.0
 
Synonyms:
    None
 
Applications:
    XX
 
Implementation Date:
    XX
 
Related Commands:
    TITLE DISPLACEMENT  = Sets the distance from the frame to the
                          title.
    PLOT                = Generates a data or function plot.
    LABEL               = Specifies the labels for the plot axes.
    LABEL AUTOMATIC     = Sets automatically generated labels.
    LABEL CASE          = Sets the case (upper/lower) for labels.
    LABEL COLOR         = Sets the color for plot labels.
    LABEL FONT          = Sets the plot label fonts.
    LABEL SIZE          = Sets the size (height) for plot labels.
    LABEL THICKNESS     = Sets the line thickness for plot labels.
    TEXT                = Writes a text string.
    TITLE               = Sets the plot title.
    LEGEND              = Sets the plot legends.
    LEGEND COORDINATES  = Sets the locations for plot legends.
    BOX COORDINATES     = Sets the locations for plot boxes.
    ARROW COORDINATES   = Sets the locations for plot arrows.
    SEGMENT COORDINATES = Sets the locations for plot segments.
    FRAME               = Sets the on/off switch for plot frame.
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE LABEL DISPLACEMENT
    X1LABEL LEAD
    X2LABEL POLLUTION SOURCE ANALYSIS: LLOYD CURRIE
    X2LABEL SIZE 1.5
    Y1LABEL POTASSIUM
    X1LABEL DISPLACEMENT 6.0
    X2LABEL DISPLACEMENT 9.0
    YLABEL DISPLACEMENT 6.0
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    PLOT POT VS LEAD
 
-----LABEL FILL-------------------------------------------------------
 
LABEL FILL
 
Name:
    ...LABEL FILL
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the fill of the labels to appear on subsequent plots.
 
Description:
    The labels are the text which appear below the bottom horizontal
    frame line and outside of the vertical frame lines.  They
    typically define the variables/axes which are being plotted.
 
    Labels can contain the special symbols available to the TEXT
    command and the special plotting symbols used by the CHARACTER
    command (these are identified with a trailing () symbol).  See the
    the documentation for CHARACTER TYPES for a list of these symbols.
    Entering one of these special strings in the LABEL command causes
    the symbol to be plotted in the label.  The following special
    symbols will also be solid filled if the label fill is on:
 
       CIRC(), SQUA(), TRIA(), REVT(), PYRA(), DIAM()
 
    for a circle, square, triangle, reverse triangle, pyramid, and
    diamond respectively.
 
    The label fills hold for all subsequent plots until defaulted (via
    the ...LABEL FILL command with no arguments) or until overridden
    with new label fills.  The analyst can define fills for all 5 plot
    labels:
       1) 3 below the bottom horizontal frame;
       2) 1 to the left of the left vertical frame;
       3) 1 to the right of the right vertical frame line.
 
Syntax:
    <prefix>LABEL FILL   <SOLID/OFF>
    where
            no prefix refers to all 5 axis labels.
            the prefix X  refers to the first horizontal label;
            the prefix Y  refers to the left and right vertical labels;
            the prefix X1 refers to the first horizontal label;
            the prefix X2 refers to the second horizontal label;
            the prefix X3 refers to the third horizontal side;
            the prefix Y1 refers to the left vertical label;
            the prefix Y2 refers to the right vertical label;
    and   SOLID specifies that the special symbols are solid filled
            while OFF specifies that they are not.
 
Examples:
    LABEL FILL SOLID
    XLABEL FILL SOLID
    LABEL FILL OFF
 
Note:
    A software font must be in effect for the special symbols to be
    drawn (and therefore for the label fill to be in effect).
 
Note:
    A ...LABEL FILL command with no arguments reverts the fill to
    default.  Thus X1LABEL FILL with no arguments reverts the first
    horizontal axis label to default.  A ...LABEL FILL command with no
    prefix refers to all 5 labels.  Thus LABEL FILL SOLID turns on the
    fill for all 5 labels.  LABEL FILL with no prefix and no arguments
    reverts all 5 labels to default.
 
Default:
    All label fills are off.
 
Synonyms:
    None
 
Related Commands:
    PLOT                = Generates a data or function plot.
    LABEL               = Specifies the labels for the plot axes.
    LABEL AUTOMATIC     = Sets automatically generated labels.
    LABEL CASE          = Sets the case (upper/lower) for labels.
    LABEL COLOR         = Sets the color for plot labels.
    LABEL DISPLACEMENT  = Sets the distance from the frame to the
                          labels.
    LABEL FONT          = Sets the font for plot labels.
    LABEL SIZE          = Sets the size (height) for plot labels.
    LABEL THICKNESS     = Sets the line thickness for plot labels.
    FILL                = Sets the fill for text characters.
    TITLE FILL          = Sets the fill for the plot title.
    LEGEND FILL         = Sets the fill for plot legends.
 
Applications:
    XX
 
Implementation Date:
    89/2
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER CIRCLE SQUARE
    CHARACTER FILL ON ALL
    LINE BLANK ALL
    X1LABEL CIRC() - POTASSIUM
    X2LABEL SQUA() - LEAD
    LABEL FONT DUPLEX
    LABEL FILL SOLID
    .
    TITLE DEMONSTRATE LABEL FILL COMMAND
    LET X = SEQUENCE 1 1 17
    PLOT POT X AND
    PLOT LEAD X
 
-----LABEL FONT-------------------------------------------------------
 
LABEL FONT
 
Name:
    ...LABEL FONT
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the font of the labels to appear on subsequent plots.
 
Description:
    The labels are the text which appear below the bottom horizontal
    frame line and outside of the vertical frame lines.  They
    typically define the variables/axes which are being plotted.  The
    label fonts hold for all subsequent plots until defaulted (via the
    ...LABEL FONT command with no arguments) or until overridden with
    new label fonts.  The analyst can define fonts for all 5 plot
    labels:
       1) 3 below the bottom horizontal frame;
       2) 1 to the left of the left vertical frame;
       3) 1 to the right of the right vertical frame line.
 
Syntax:
    <prefix>LABEL FONT   <font>
    where <font> specifies the desired font (TEKTRONIX, SIMPLEX,
             DUPLEX, TRIPLEX, COMPLEX, ITALIC, COMPLEX SCRIPT,
             TRIPLEX ITALIC, COMPLEX SCRIPT, SIMPLEX SCRIPT);
    and   <prefix> is one of the following:
             X1        refers to the first horizontal label
             X2        refers to the second horizontal label
             X3        refers to the third  horizontal label
             X         refers to the first horizontal label
             Y1        refers to the left vertical label
             Y2        refers to the right vertical label
             Y         refers to the left and right vertical labels
             no prefix refers to all 5 axis labels.
 
Examples:
    Y1LABEL FONT SIMPLEX
    YLABEL FONT DUPLEX
    LABEL FONT TRIPLEX
    LABEL FONT COMPLEX
 
Note:
    A ...LABEL FONT command with no arguments reverts the font to
    default.  Thus X1LABEL FONT with no arguments reverts the first
    horizontal axis label to default.  A ...LABEL FONT command with no
    prefix refers to all 5 labels.  Thus LABEL FONT SIMPLEX assigns the
    font SIMPLEX to all 5 labels.  LABEL FONT with no prefix and no
    arguments reverts all 5 labels to default.
 
Note:
    The FONT command sets the default font.  The LABEL FONT command is
    used to override the default font for the labels only.
 
Default:
    All label fonts are TEKTRONIX (i.e., hardware characters).
 
Synonyms:
    None
 
Related Commands:
    PLOT                = Generates a data or function plot.
    LABEL               = Specifies the labels for the plot axes.
    LABEL AUTOMATIC     = Sets automatically generated labels.
    LABEL CASE          = Sets the case (upper/lower) for labels.
    LABEL COLOR         = Sets the color for plot labels.
    LABEL DISPLACEMENT  = Sets the distance from the frame to the
                          labels.
    LABEL SIZE          = Sets the size (height) for plot labels.
    LABEL THICKNESS     = Sets the line thickness for plot labels.
    TEXT                = Writes a text string.
    TITLE               = Sets the plot title.
    LEGEND              = Sets the plot legends.
    LEGEND COORDINATES  = Sets the locations for plot legends.
    BOX COORDINATES     = Sets the locations for plot boxes.
    ARROW COORDINATES   = Sets the locations for plot arrows.
    SEGMENT COORDINATES = Sets the locations for plot segments.
    FRAME               = Sets the on/off switch for plot frame.
 
Applications:
    XX
 
Implementation Date:
    89/2
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE LABEL FONT
    X1LABEL LEAD
    Y1LABEL POTASSIUM
    XLABEL FONT SIMPLEX
    YLABEL FONT COMPLEX
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    PLOT POT VS LEAD
 
-----LABEL JUSTIFICATION-------------------------------------------
 
LABEL JUSTIFICATION
 
Name:
    ...LABEL JUSTIFICATION
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the justification of the labels to appear on subsequent
    plots.
 
Description:
    The labels are the text which appear below the bottom horizontal
    frame line and outside of the vertical frame lines.  They
    typically define the variables/axes which are being plotted.

    For most applications, the default justifications are desired
    (i.e., labels are centered about the appropriate axis).
    However, there are a few cases where an alternate
    justification is desirable.  The most common case is for the
    multiplot commands SCATTER PLOT MATRIX, FACTOR PLOT, and
    CONDITION PLOT.

    The label justification hold for all subsequent plots until
    defaulted (via the ...LABEL JUSTIFICIATION command with no
    arguments) or until overridden with new label offsets.  The
    analyst can define offsets for all 5 plot labels:
       1) 3 below the bottom horizontal frame;
       2) 1 to the left of the left vertical frame;
       3) 1 to the right of the right vertical frame line.
    The label is specified by the prefix in the command.
 
Syntax:
    <prefix>LABEL JUSTIFICATION   <value>
    where <value> is a string that specifies the
             justification;
    and   <prefix> is one of the following:
             X1        refers to the first horizontal label
             X2        refers to the second horizontal label
             X3        refers to the third  horizontal label
             X         refers to the first horizontal label
             Y1        refers to the left vertical label
             Y2        refers to the right vertical label
             Y         refers to the left and right vertical labels
             no prefix refers to all 5 axis labels.
 
    The following justifications are allowed:
      LEFT   = left horizontally, bottom vertically
      CENTER = center horizontally, bottom vertically
      RIGHT  = right horizontally, bottom vertically
      LECE   = left horizontally, center vertically
      CECE   = center horizontally, center vertically
      RICE   = right horizontally, center vertically
      LETO   = left horizontally, top vertically
      CETO   = center horizontally, top vertically
      RITO   = right horizontally, top vertically
 
Examples:
    X1LABEL JUSTIFICATION LEFT
    X2LABEL JUSTIFICATION RIGHT
 
Note:
    A ...LABEL JUSTIFICATION command with no arguments reverts the
    justification to default.  Thus X1LABEL JUSTIFICATION  with no
    arguments reverts the first horizontal axis label to default.  A
    ...LABEL JUSTIFICATION command with no prefix refers to all 5
    labels.  Thus LABEL JUSTIFICATION CENTER assigns the justification
    left to all 5 labels.  LABEL JUSTIFICATION with no prefix and no
    arguments reverts all 5 labels to default.
 
Default:
    The default justifications are all CECE.
 
Synonyms:
    LJUS and LEBO for LEFT.
    CJUS and CEBO for CENTER.
    RJUS and RIBO for RIGHT.
 
Related Commands:
    LABEL               = Specifies the labels for the plot axes.
    LABEL AUTOMATIC     = Sets automatically generated labels.
    LABEL CASE          = Sets the case (upper/lower) for labels.
    LABEL COLOR         = Sets the color for plot labels.
    LABEL DISPLACEMENT  = Sets the distance from the frame to the
    LABEL FONT          = Sets the plot label fonts.
    LABEL SIZE          = Sets the size (height) for plot labels.
    LABEL THICKNESS     = Sets the line thickness for plot labels.
 
Applications:
    Control labels for multiplot commands (SCATTER PLOT MATRIX,
    FACTOR PLOT, CONDITION PLOT).
 
Implementation Date:
    2000/1
 
Program:
    SKIP 25
    READ IRIS.DAT Y1 TO Y4 TAG
    MULTIIPLOT CORNER COORDINATES 10 10 90 90
    MULTIPLOT SCALE FACTOR 3
    SET MATRIX PLOT TYPE BIHISTOGRAM
    X1LABEL JUSTIFICATION LEFT
    X2LABEL JUSTIFICATION LEFT
    X1LABEL OFFSET -30
    X2LABEL OFFSET -30
    MATRIX PLOT Y1 Y2 Y3 Y4
 
-----LABEL OFFSET-----------------------------------------------
 
LABEL OFFSET
 
Name:
    ...LABEL OFFSET
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the offset of the labels to appear on subsequent
    plots.
 
Description:
    The labels are the text which appear below the bottom horizontal
    frame line and outside of the vertical frame lines.  They
    typically define the variables/axes which are being plotted.

    For the horizontal labels, the displacement (LABEL DISPLACEMENT)
    is the vertical distance from the frame to the label and the
    offset is the horizontal displacement.  For the vertical labels,
    the displacement (LABEL DISPLACEMENT) is the horizontal distance
    from the frame to the label and the offset is the vertical
    displacement of the label.

    The label offsets hold for all subsequent plots until defaulted
    (via the ...LABEL OFFSET command with no arguments) or until
    overridden with new label offsets.  The analyst can define
    offsets for all 5 plot labels:
       1) 3 below the bottom horizontal frame;
       2) 1 to the left of the left vertical frame;
       3) 1 to the right of the right vertical frame line.
    The label is specified by the prefix in the command.
 
Syntax:
    <prefix>LABEL OFFSET   <value>
    where <value> is a number or parameter that specifies the
             offset;
    and   <prefix> is one of the following:
             X1        refers to the first horizontal label
             X2        refers to the second horizontal label
             X3        refers to the third  horizontal label
             X         refers to the first horizontal label
             Y1        refers to the left vertical label
             Y2        refers to the right vertical label
             Y         refers to the left and right vertical labels
             no prefix refers to all 5 axis labels.
 
Examples:
    Y1LABEL OFFSET 5.0
    YLABEL OFFSET 10
    X1LABEL OFFSET 5
    X3LABEL OFFSET 13
 
Note:
    A ...LABEL OFFSET command with no arguments reverts the
    offset to default.  Thus X1LABEL OFFSET  with no
    arguments reverts the first horizontal axis label to default.  A
    ...LABEL OFFSET command with no prefix refers to all 5 labels.
    Thus LABEL OFFSET 8 assigns the offset 8 to all 5
    labels.  LABEL OFFSET with no prefix and no arguments reverts
    all 5 labels to default.
 
Note:
    This command recieves infrequent usage.  The most common
    application is with the multiplot commands SCATTER PLOT MATRIX,
    FACTOR PLOT, and CONDITION PLOT.

Default:
    The default offsets are all zero.
 
Synonyms:
    None
 
Related Commands:
    LABEL               = Specifies the labels for the plot axes.
    LABEL AUTOMATIC     = Sets automatically generated labels.
    LABEL CASE          = Sets the case (upper/lower) for labels.
    LABEL COLOR         = Sets the color for plot labels.
    LABEL DISPLACEMENT  = Sets the distance from the frame to the
    LABEL FONT          = Sets the plot label fonts.
    LABEL SIZE          = Sets the size (height) for plot labels.
    LABEL THICKNESS     = Sets the line thickness for plot labels.
 
Applications:
    Control labels for multiplot commands (SCATTER PLOT MATRIX,
    FACTOR PLOT, CONDITION PLOT).
 
Implementation Date:
    2000/1
 
Program:
    SKIP 25
    READ IRIS.DAT Y1 TO Y4 TAG
    MULTIIPLOT CORNER COORDINATES 10 10 90 90
    MULTIPLOT SCALE FACTOR 3
    SET MATRIX PLOT TYPE BIHISTOGRAM
    X1LABEL JUSTIFICATION LEFT
    X2LABEL JUSTIFICATION LEFT
    X1LABEL OFFSET -30
    X2LABEL OFFSET -30
    MATRIX PLOT Y1 Y2 Y3 Y4
 
-----LABEL SIZE-------------------------------------------------------
 
LABEL SIZE
 
Name:
    ...LABEL SIZE
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the size (height) of characters in labels to appear on
    subsequent plots.
 
Description:
    The labels are the text which appear below the bottom horizontal
    frame line and outside of the vertical frame lines.  They
    typically define the variables/axes which are being plotted.  The
    size is the height of the character (not counting vertical spacing).
    The height of the character is from the visible bottom of the
    character to the visible top of the character.  The vertical spacing
    between characters is not counted.  The height is in decimal units
    of 0 to 100.  A height of 0 would be negligibly small while a height
    of 100 would be full screen vertical distance.  The width of the
    character is automatically set to one half the character height.
    The label sizes hold for all subsequent plots until defaulted (via
    the ...LABEL SIZE command with no arguments) or until overridden
    with new label sizes.  The analyst can define sizes for all 5 plot
    labels:
       1) 3 below the bottom horizontal frame;
       2) 1 to the left of the left vertical frame;
       3) 1 to the right of the right vertical frame line.
    The label is specified by the prefix in the command.
 
Syntax:
    <prefix>LABEL SIZE   <size>
    where <size> is a number or parameter that specifies the desired
             character size (height) in units of 0 to 100;
    and   <prefix> is one of the following:
             X1        refers to the first horizontal label
             X2        refers to the second horizontal label
             X3        refers to the third  horizontal label
             X         refers to the first horizontal label
             Y1        refers to the left vertical label
             Y2        refers to the right vertical label
             Y         refers to the left and right vertical labels
             no prefix refers to all 5 axis labels.
 
    The specification of each individual label with a different size is
    rare.  The most common form (by far) for this command is the last
    one (with no prefix) which defines the size uniformly for all 5
    labels.
 
Examples:
    Y1LABEL SIZE 3
    X1LABEL SIZE 5
    LABLE SIZE 2
    LABEL SIZE 1.5
    LABEL SIZE A
 
Note:
    A ...LABEL SIZE command with no arguments reverts the size to
    default.  Thus X1LABEL SIZE with no arguments reverts the first
    horizontal axis label to default.  A ...LABEL SIZE command with no
    prefix refers to all 5 labels.  Thus LABEL SIZE 2 assigns the size
    2 to all 5 labels.  LABEL SIZE with no prefix and no arguments
    reverts all 5 labels to default.
 
Default:
    All label sizes are 2.0.
 
Synonyms:
    None
 
Related Commands:
    PLOT                = Generates a data or function plot.
    LABEL               = Specifies the labels for the plot axes.
    LABEL AUTOMATIC     = Sets automatically generated labels.
    LABEL CASE          = Sets the case (upper/lower) for labels.
    LABEL COLOR         = Sets the color for plot labels.
    LABEL DISPLACEMENT  = Sets the distance from the frame to the
                          labels.
    LABEL FONT          = Sets the plot label fonts.
    LABEL THICKNESS     = Sets the line thickness for plot labels.
    TEXT                = Writes a text string.
    TITLE               = Sets the plot title.
    LEGEND              = Sets the plot legends.
    LEGEND COORDINATES  = Sets the locations for plot legends.
    BOX COORDINATES     = Sets the locations for plot boxes.
    ARROW COORDINATES   = Sets the locations for plot arrows.
    SEGMENT COORDINATES = Sets the locations for plot segments.
    FRAME               = Sets the on/off switch for plot frame.
    TITLE SIZE          = Sets the size for the plot title.
    LEGEND SIZE         = Sets the size for plot legends.
    TIC SIZE            = Sets the size of plot tics.
    TIC LABEL SIZE      = Sets the size for plot tic labels.
    CHARACTER SIZES     = Sets the sizes for plot characters.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE LABEL SIZE
    X1LABEL LEAD
    Y1LABEL POTASSIUM
    XLABEL SIZE 4.0
    YLABEL SIZE 1.0
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    PLOT POT VS LEAD
 
-----LABEL THICKNESS--------------------------------------------------
 
LABEL THICKNESS
 
Name:
    ...LABEL THICKNESS
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the thickness of the labels to appear on subsequent plots.
 
Description:
    The labels are the text which appear below the bottom horizontal
    frame line and outside of the vertical frame lines.  They
    typically define the variables/axes which are being plotted.  The
    label thicknesses hold for all subsequent plots until defaulted
    (via the ...LABEL THICKNESS command with no arguments) or until
    overridden with new label thicknesses.  The analyst can define
    thicknesses for all 5 plot labels:
       1) 3 below the bottom horizontal frame;
       2) 1 to the left of the left vertical frame;
       3) 1 to the right of the right vertical frame line.
    The label is specified by the prefix in the command.
 
Syntax:
    <prefix>LABEL THICKNESS   <thickness>
    where <thickness> is a positive decimal number or parameter in the
             range 0 to 100 (values between 0.05 and 0.3 are most
             common) that specifies the thickness;
    and   <prefix> is one of the following:
             X1        refers to the first horizontal label
             X2        refers to the second horizontal label
             X3        refers to the third  horizontal label
             X         refers to the first horizontal label
             Y1        refers to the left vertical label
             Y2        refers to the right vertical label
             Y         refers to the left and right vertical labels
             no prefix refers to all 5 axis labels.
 
    The specification of each individual label with a different
    thickness is rare.  The most common form (by far) for this command
    is the last one (with no prefix) which defines the thickness
    uniformly for all 5 labels.
 
Examples:
    Y1LABEL THICKNESS 0.2
    YLABEL THICKNESS 0.1
    LABEL THICKNESS 0.3
    LABEL THICKNESS 0.2
 
Note:
    A ...LABEL THICKNESS command with no arguments reverts the
    thickness to default.  Thus X1LABEL THICKNESS with no arguments
    reverts the first horizontal axis label to default.  A ...LABEL
    THICKNESS command with no prefix refers to all 5 labels.  Thus LABEL
    THICKNESS 0.2 assigns the thickness 0.2.  to all 5 labels.  LABEL
    THICKNESS with no prefix and no arguments reverts all 5 labels to
    default.
 
Note:
    The THICKNESS command sets the default thickness.  The LABEL
    THICKNESS command is used to override the default thickness for the
    labels only.
 
Note:
    This command only applies if the labels are drawn with a software
    font (e.g., SIMPLEX).
 
Default:
    All label thicknesses are 0.1.
 
Synonyms:
    None
 
Related Commands:
    PLOT                = Generates a data or function plot.
    LABEL               = Specifies the labels for the plot axes.
    LABEL AUTOMATIC     = Sets automatically generated labels.
    LABEL CASE          = Sets the case (upper/lower) for labels.
    LABEL COLOR         = Sets the color for plot labels.
    LABEL DISPLACEMENT  = Sets the distance from the frame to the
                          labels.
    LABEL FONT          = Sets the plot label fonts.
    LABEL SIZE          = Sets the size (height) for plot labels.
    TEXT                = Writes a text string.
    TITLE               = Sets the plot title.
    LEGEND              = Sets the plot legends.
    LEGEND COORDINATES  = Sets the locations for plot legends.
    BOX COORDINATES     = Sets the locations for plot boxes.
    ARROW COORDINATES   = Sets the locations for plot arrows.
    SEGMENT COORDINATES = Sets the locations for plot segments.
    FRAME               = Sets the on/off switch for plot frame.
 
Applications:
    XX
 
Implementation Date:
    89/2
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE LABEL THICKNESS
    X1LABEL LEAD
    Y1LABEL POTASSIUM
    LABEL FONT SIMPLEX
    YLABEL THICKNESS 0.1
    XLABEL THICKNESS 0.25
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    PLOT POT VS LEAD
 
-----LAG PLOT-------------------------------------------------------
 
LAG PLOT
 
Name:
    LAG ... PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a lag plot.
 
Description:
    A lag plot is a graphical data analysis technique which has 2 uses:
       1) (for single time series)--to determine if autocorrelation
          structure exists within the time series;
       2) (for 2 time series)--to determine if cross-correlation
          structure exists between the time series.
    In time series analysis, a lag is a fixed time displacement.  For
    example, y(2) and y(7) would be said to have a lag of 5 (= 7-2).
    For a lag plot, the lag is fixed at some value specified by the
    analyst.  The default value is a lag of 1.
 
    For a lag plot on a single time series, the lag plot consists of:
       1) vertical axis   = x(i)
       2) horizontal axis = x(i+lag)
    For a lag plot for 2 time series, the lag plot consists of:
       1) vertical axis   = y(i)
       2) horizontal axis = x(i+lag)
    Ideally (for a white noise time series and for 2 uncorrelated time
    series), the lag plot should have the appearance of a random
    shotgun pattern.  Any kind of a structured pattern in a lag plot
    indicates an underlying auto/cross-correlation model, the nature of
    which may be inferred from the type of lag plot structure.
 
Syntax 1: (for a singe time series)
    LAG   <n>   PLOT   <x>  <SUBSET/EXCEPT/FOR qualification>
    where <n> is an integer number or parameter between 1 and n-1 (n is
              the number of observations) that specifies the lag;
          <x> is the variable of raw data values which is being
              analyzed for autocorrelation structure;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2: (for two time series)
    LAG   <n>   PLOT   <x>  <SUBSET/EXCEPT/FOR qualification>
    where <n> is an integer number or parameter between 1 and n-1 (n is
              the number of observations) that specifies the lag;
          <x> is the first variable of raw data values which is being
              analyzed for cross-correlation structure;
          <y> is the second variable of raw data values which is being
              analyzed for cross-correlation structure;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LAG 1 PLOT X
    LAG 3 PLOT X
    LAG PLOT X
    LAG 1 PLOT Y X
    LAG 12 PLOT Y X
    LAG -12 PLOT Y X
    LAG PLOT Y X
 
Default:
    If <n> is omitted, the default lag is 1.
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS          = Sets the types for plot characters.
    LINES               = Sets the types for plot lines.
    PLOT                = Generates a data or function plot.
    4-PLOT              = Generates a 4-plot for univariate analysis.
    CORRELATION PLOT    = Generates an auto or cross-correlation plot.
    SPECTRUM            = Generates a spectral plot.
    COMPLEX DEMOD PLOT  = Generates a complex demodulation plot.
    SUMMARY             = Generates a table of summary statistics.
    LET                 = Computes various statistics (and many other
                          capabilities).
    FIT                 = Carries out a least squares fit.
 
Applications:
    Time Series Analysis, Regression
 
Implementation Date:
    XX
 
Program 1:
    .  THIS SAMPLE PROGRAM READS THE FILE LEW.DAT IN THE DATAPLOT
    .  REFERENCE DIRECTORY.  SINCE IT CONTAINS 200 DATA POINTS, THEY
    .  ARE NOT REPRODUCED HERE.  THE DATA IS BEAM DELECTION DATA.
    LEGEND 1 AUTOCORRELATION ANALYSIS
    LEGEND 2 LAG PLOT
    Y1LABEL X(LC()i)
    .
    SKIP 25
    READ LEW.DAT Y
    .
    CHAR X
    LINES
    YMAX 500
    XMAX 500
    MULTIPLOT 2 2
    MULTIPLOT CORNMER COORDINATES 0 0 100 100
    LOOP FOR K = 1 1 4
      X1LABEL X(LC()I+^K)
      LAG ^K PLOT Y
    END OF LOOP
    END OF MULTIPLOT
 
Program 2:
    .  THIS SAMPLE PROGRAM READS THE FILE HAYES1.DAT IN THE DATAPLOT
    .  REFERENCE DIRECTORY.  SINCE IT CONTAINS ABOUT 100 DATA POINTS,
    .  IS NOT REPRODUCED HERE.  THIS IS FIRE RESEARCH SMOKE OBSCURATION
    .  DATA.
    .
    SKIP 25
    READ HAYES1.DAT JUNK Y1 Y2
    .
    LEGEND 1 CROSS-CORRELATION ANALYSIS
    LEGEND 2 LAG PLOT
    Y1LABEL X(LC()i)
    TIC OFFSET 0.2 0.2
    .
    CHAR X
    LINES
    YLIMITS 0 3
    XLIMITS 0 3
    MULTIPLOT 2 2
    MULTIPLOT CORNMER COORDINATES 0 0 100 100
    LOOP FOR K = 1 1 4
      X1LABEL Y(LC()I+^K)
      LAG ^K PLOT Y1 Y2
    END OF LOOP
    END OF MULTIPLOT
 
-----LAGUERRE (LET)--------------------------------
 
LAGUERRE
 
Name:
    LAGUERRE (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Laguerre, normalized Laguerre, or the generalized
    Laguerre polynomial of order N.
 
Description:
    From Abramowitz and Stegum (see Reference below), a system of
    nth degree polynomials f(x,n) is called orthogonal on the
    interval a<=x<=b with respect to a weight function w(x) if it
    satisfies the equation:
        INTEGRAL[w(x)*f(x,n)*f(x,m)]dx = 0   m<>n, (m,n = 0, 1, 2, ...

    Laguerre polynomials use the weight function EXP(-x) and are
    orthogonal for non-negative x.  Laguerre polynomials can also be
    defined by the following equation:
                 n
        Ln(x) = SUM[(-1)**M*(n)x**m/m!
                m=0         (m)

    Normalized Laguerre polynomials scale the Laguerre polynomials
    as follows:
        NLn(x) = n!*Ln(x)

    Generalized Laguerre polynomials use the weight function 
        x**alpha*EXP(-x)
    and are orthogonal for non-negative x.  The value of alpha > -1.

    DATAPLOT calculates the Laguerre polynomials using the following
    recurrence relation:
        L(x,n) = (((2*N+1)-x)*L(x,n-1)-n*L(x,n-2))/(n+1)
    and the normalized Laguerre polynomials with the following
    recurrence relation:
        NL(x,n) = (1+2*N-x)*L(x,n-1)-n**2*L(x,n-2)
    and the generalized Laguerre polynomials with the following
    recurrence relation:
        L(x,a,n) = (((2*N+a+1)-x)*L(x,a,n-1)-(n+a)*L(x,a,n-2))/(n+1)
    where the first few terms for the recuurence were obtained from
    the Handbook of Mathematical Functions (see the REFERENCE below).
 
Syntax 1:
    LET <y> = LAGUERRE(<x>,<n>)     <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, parameter, or variable;
          <n> is a non-negative integer number, parameter, or variable
              that specifies the order of the Laguerre polynomial;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Laguerre polynomial value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes Laguerre polynomials.

Syntax 2:
    LET <y> = NRMLAG(<x>,<n>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, parameter, or variable;
          <n> is a non-negative integer number, parameter, or variable
              that specifies the order of the Laguerre polynomial;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Laguerre polynomial value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes normalized Laguerre polynomials.

Syntax 3:
    LET <y> = LAGUERRL(<x>,<n>,<a>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, parameter, or variable;
          <n> is a non-negative integer number, parameter, or variable
              that specifies the order of the Laguerre polynomial;
          <a> is a number, parameter, or variable that specifies the
              shape parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Laguerre polynomial value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes generalized Laguerre polynomials.

Examples:
    LET A = LAGUERRE(0.5,4,2.5)
    LET X2 = LAGUERRE(X1,10,0.5)
    LET X2 = LAGUERRE(X1,N,A)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHEBT    = Compute the Chebychev polynomial first kind, order N.
    CHEBU    = Compute the Chebychev polynomial second kind, order N.
    HERMITE  = Compute the Hermite polynomial of order N.
    JACOBIPE = Compute the Jacobi polynomial of order N.
    ULTRASPH = Compute the ultrasperical polynomial of order N.
    LEGENDRE = Compute the Legendre polynomial of order N.
 
Reference:
    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 22).

Applications:
    Mathematics
 
Implementation Date:
    95/7
 
Program:
    TITLE CASE ASIS; LABEL CASE ASIS
    LINE SOLID DASH DOT DASH2
    X1LABEL X
    .
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE LAGUERRE POLYNOMIALS (ORDER 2 THRU 5)
    Y1LABEL Ln(X)
    PLOT LAGUERRE(X,2) FOR X = 0 .01 5 AND
    PLOT LAGUERRE(X,3) FOR X = 0 .01 5 AND
    PLOT LAGUERRE(X,4) FOR X = 0 .01 5 AND
    PLOT LAGUERRE(X,5) FOR X = 0 .01 5
    .
    TITLE Normalized Laguerre Polynomials (order 2 thru 5)
    Y1LABEL NLn(X)
    PLOT NRMLAG(X,2) FOR X = 0 .01 5 AND
    PLOT NRMLAG(X,3) FOR X = 0 .01 5 AND
    PLOT NRMLAG(X,4) FOR X = 0 .01 5 AND
    PLOT NRMLAG(X,5) FOR X = 0 .01 5
    .
    TITLE Generalized Laguerre Polynomials (order 2 thru 5)
    LET A = 3
    Y1LABEL Ln(X,^a)
    X2LABEL A = ^A
    PLOT LAGUERRL(X,2,A) FOR X = 0 .01 5 AND
    PLOT LAGUERRL(X,3,A) FOR X = 0 .01 5 AND
    PLOT LAGUERRL(X,4,A) FOR X = 0 .01 5 AND
    PLOT LAGUERRL(X,5,A) FOR X = 0 .01 5
    .
    LET A = 0.5
    Y1LABEL Ln(X,^a)
    X2LABEL A = ^A
    PLOT LAGUERRL(X,2,A) FOR X = 0 .01 5 AND
    PLOT LAGUERRL(X,3,A) FOR X = 0 .01 5 AND
    PLOT LAGUERRL(X,4,A) FOR X = 0 .01 5 AND
    PLOT LAGUERRL(X,5,A) FOR X = 0 .01 5
    END OF MULTIPLOT
 
-----LAHEY-------------------------------------------------------
 
LAHEY
 
Name:
    LAHEY
 
Type:
    Output Device Command
 
Purpose:
    Direct graphical output to a the screen when using the version of
    DATAPLOT on the IBM-PC built using the LAHEY compiler.
 
Description:
    There are currently 3 ways to generate graphics on the screen
    for the IBM-PC version of DATAPLOT.

      1) Use the TEKTRONIX 4014 driver in conjunction with the
         PLOTDEV utility.  This was the recommended method for the
         OTG based version.  The major problem with this approach is
         that it requires a special entry in the CONFIG.SYS file
         that may require rebooting your PC for some users to run
         DATAPLOT.  It also does not support color.

      2) Use the front-end menu system with the native mode VGA
         driver.  This is the recommended approach if you prefer to
         use the front-end menu system.  However, the VGA driver
         only works if you run the front-end.  Also, the LAHEY
         version does not yet work with the Front-end.

      3) Users with the LAHEY based version can use the LAHEY device
         driver discussed here.  It has the advantage that no
         special AUTOEXEC.BAT and CONFIG.SYS files are required (and
         therefore no rebooting the machine to run DATAPLOT as the
         OTG based version required).  This driver does have a few
         limitations that are discussed below.

    The LAHEY device driver uses a graphical library supplied with
    the LAHEY compiler.  This driver is only applicable if you are
    running DATAPLOT on an IBM-PC machine and the LAHEY compiler
    was used to build your version of DATAPLOT.

    This driver is an interim solution.  We are currently investigating
    our alternatives for running DATAPLOT in the various windows
    enviornments (Windows 3.1, Windows 95, Windows NT) on the PC.
    The LAHEY compiler is an intermediate step that avoids the
    nusiance of rebooting that the OTG compiler required.

Syntax
    DEVICE 1 LAHEY
 
    This form directs the LAHEY output to the terminal screen.  It
    is not currently possible to direct the LAHEY output to a file.
 
Examples:
    DEVICE 1 LAHEY
 
Note:
    The LAHEY driver has a few limitations (and also some advantages).

       1) This device driver supports color.  Enter the command
          SHOW COLORS VGA for a list of available colors.  Also,
          output sent to a black and white Postscript printer is
          NOT affected by the choice of colors for the screen.  This
          means you can chose foregrand and background colors that
          work well on the screen without harming your Postscript
          output.

       2) The most serious limitation of the LAHEY driver is that it
          does a terrible job with hardware characters.  Specifically,
          positioning is limited to character boxes (typically 
          30x80) so that hardware characters will not be accurately
          placed.  Also, hardware characters are drawn with a black
          background regardless of the color of the character.  This
          looks funny if do not use a black background for the plot.

          Using software characters avoids this problem (e.g.,
          FONT DUPLEX). However, it is common to want the hardware
          characters for your Postscript output since this provides
          typeset quality characters.

          To avoid this problem with the hardware characters on the
          screen, but to preserve hardware characters for the printed
          output, we added the following command:

             DEVICE <1/2/3> FONT <font>

          We recommend that when using the LAHEY driver that you
          enter the command DEVICE 1 FONT SIMPLEX (or whatever
          software font you prefer) after the DEVICE 1 LAHEY command.

       3) The LAHEY driver does not support dashed lines.  This
          is not actually too serious a problem in practice.  The
          dashed lines will show up on the printer output.  You
          can use color to distinguish lines on the screen.  For
          example,

              LINE SOLID DASH DOT
              LINE COLOR RED BLUE GREEN

          will give acceptable results on both the Postscript
          output and the screen (dashed lines for the printer, 
          unique colors on the screen).

       4) The LAHEY driver does not support the CROSS-HAIR command.

       5) The LAHEY driver uses the same screen for alphanumeric
          output and graphics output.  The plot on the screen will
          start to scroll off when the alphanumeric output gets
          to the bottom of the screen.  This is typically only a
          problem when adding diagrammatic graphics to a plot.  Once
          the plot starts scrolling off, the position of diagrammatic
          graphics will not be correct.  The printer output will
          still be correct.  Entering the command FEEDBACK OFF
          can minimize the amount of scrolling.

Default:
    None
 
Synonyms:
    None

DEVICE NOTES
    1) HARDWARE TEXT - the use of the command DEVICE 1 FONT SIMPLEX
       recommended to avoid terrible performance of hardware characters
       with the LAHEY driver.
    2) COLOR - Use the SHOW COLORS VGA command to see what colors are
       supported.
    3) HARDWARE FILL - Solid fills generated in hardware.
    4) DASH PATTERNS - Dash patterns not supported.
    5) LINE WIDTH - Thick lines are generated in software as multiple
       lines.
    6) GRAPHICS INPUT - The CROSS-HAIR command is not supported for
       this device.
 
Related Commands:
    HPGL                  = Direct graphical output to an HPGL device.
    TEKTRONIX             = Direct graphical output to a Tektronix
                            device.
    X11                   = Direct graphical output to an X11 device.
    DEVICE                = Specify certain actions for the graphics
                            output.
    REGIS                 = Direct graphical output to a Regis device.
    HP 2622               = Direct graphical output to an HP terminal.
    CALCOMP               = Direct graphical output to a Calcomp
                            device.
 
Applications:
    Screen Graphics
 
Implementation Date:
    96/7
 
Program:
    DEVICE 1 LAHEY
    DEVICE 1 FONT SIMPLEX
    PLOT X**2 FOR X = 1 1 9
 
-----LAMBDA (LET)--------------------------------
 
LAMBDA
 
Name:
    LAMBDA (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the lambda function.
 
Description:
    The lambda function is defined as:

        f(x,v) = 2**V*GAMMA(v+1)*[J(x,v)/x**v)  (v <> -1, -2, ...)

    where v is the order of the lambda function, GAMMA is the
    gamma function, and J(x,v) is the Bessel function of the
    first kind.  Dataplot supports a maximum order of 500.

    Dataplot computes this function using the LAMV and LAMN
    routines from "Computation of Special Functions" (see the
    Reference section below).
 
Syntax:
    LET <y> = LAMBDA(<x>,<v>)    <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, variable or parameter;
          <v> is a number, parameter, or variable (less than 500);
          <y> is a variable or a parameter (depending on what <x> 
               and <v> are) where the computed lambda function
               values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LAMBDA(2.3,1)
    LET A = LAMBDA(X,A1)
    LET X2 = LAMBDA(X1,4) FOR X1 = 0.1 0.1 3.0
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    GAMMA      = Compute the gamma function.
    BESSJN     = Compute the Bessel function of the first kind.
    LAMBDAP    = Compute the derivative of the lambda function.
 
Reference:
    "Computation of Special Functions", Shanjie Zhang and Jianming
    Jin, John Wiley and Sons, 1996, pp. 182-184.
 
Applications:
    Special Functions
 
Implementation Date:
    1997/12
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    TITLE ORDER 0
    PLOT LAMBDA(X,0) FOR X = 0 0.01 10
    TITLE ORDER 1
    PLOT LAMBDA(X,1) FOR X = 0 0.01 10
    TITLE ORDER 2
    PLOT LAMBDA(X,2) FOR X = 0 0.01 10
    TITLE ORDER 3
    PLOT LAMBDA(X,3) FOR X = 0 0.01 10
    END OF MULTIPLOT
    MOVE 50 97
    CENTER JUSTIFICATION
    TEXT LAMBDA FUNCTIONS
 
-----LAMBDAP (LET)--------------------------------
 
LAMBDAP
 
Name:
    LAMBDAP (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the derivative of the lambda function.
 
Description:
    The lambda function is defined as:

        f(x,v) = 2**V*GAMMA(v+1)*[J(x,v)/x**v)  (v <> -1, -2, ...)

    where v is the order of the lambda function, GAMMA is the
    gamma function, and J(x,v) is the Bessel function of the
    first kind.  Dataplot supports a maximum order of 500.

    The derivative of the lambda function can be defined in
    terms of the lambda function:

        f'(x,v) = (2*v/x)[f(x,v-1) - f(x,v)]

    where f(x,v) is the lambda function.

    Dataplot computes this function using the LAMV and LAMN
    routines from "Computation of Special Functions" (see the
    Reference section below).
 
Syntax:
    LET <y> = LAMBDAP(<x>,<v>)    <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, variable or parameter;
          <v> is a number, parameter, or variable (less than 500);
          <y> is a variable or a parameter (depending on what <x> 
               and <v> are) where the computed lambda function
               derivative values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LAMBDAP(2.3,1)
    LET A = LAMBDAP(X,A1)
    LET X2 = LAMBDAP(X1,4) FOR X1 = 0.1 0.1 3.0
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LAMBDA     = Compute the lambda function.
    GAMMA      = Compute the gamma function.
    BESSJN     = Compute the Bessel function of the first kind.
 
Reference:
    "Computation of Special Functions", Shanjie Zhang and Jianming
    Jin, John Wiley and Sons, 1996, pp. 182-184.
 
Applications:
    Special Functions
 
Implementation Date:
    1997/12
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    TITLE ORDER 0
    PLOT LAMBDAP(X,0) FOR X = 0 0.01 10
    TITLE ORDER 1
    PLOT LAMBDAP(X,1) FOR X = 0 0.01 10
    TITLE ORDER 2
    PLOT LAMBDAP(X,2) FOR X = 0 0.01 10
    TITLE ORDER 3
    PLOT LAMBDAP(X,3) FOR X = 0 0.01 10
    END OF MULTIPLOT
    MOVE 50 97
    CENTER JUSTIFICATION
    TEXT DERIVATIVE OF LAMBDA FUNCTIONS
 
-----LAMCDF (LET)--------------------------------
 
LAMCDF
 
Name:
    LAMCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Tukey-Lambda cumulative distribution function with
    shape parameter lambda.
 
Description:
    The Tukey-Lambda distribution does not have a simple, general,
    closed form formula for either the probability density function or
    the cumulative distribution function.  Some special cases are:
       1) lambda = -1    - approximately Cauchy;
       2) lambda = 0     - exactly logistic;
       3) lambda = 0.14  - approximately normal;
       4) lambda = 0.5   - U shaped;
       5) lambda = 1.0   - exactly uniform.
    The input value is limited to the range =/-(1/lambda).
 
Syntax:
    LET <y2> = LAMCDF(<y1>,<lambda>) <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable, a number, or a parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed Tukey-Lambda cdf value is saved;
          <lambda> is a number or parameter that specifies the shape
               parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LAMCDF(3,1)
    LET X2 = LAMCDF(X1,LAMBDA)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LAMPDF = Compute the Tukey-Lambda probability density function.
    LAMPDF = Compute the Tukey-Lambda probability density function.
    NORPDF = Compute the standard normal probability density function.
    NORCDF = Compute the standard normal cumulative distribution
             function.
    NORPPF = Compute the standard normal percent point function.
    LOGCDF = Compute the logistic cumulative distribution function.
    LOGPDF = Compute the logistic probability density function.
    LOGPPF = Compute the logistic percent point function.
    UNICDF = Compute the uniform cumulative distribution function.
    UNIPDF = Compute the uniform probability density function.
    UNIPPF = Compute the uniform percent point function.
 
Reference:
    "Low Moments for Small Samples: A Comparative Study of Order
    Statistics", Annals of Mathematical Statistics, 18, 1947 (pp.
    413-426).
 
Applications:
    XX
 
Implementation Date:
    94/4
 
Program:
    MAJOR YTIC NUMBER 6; MINOR YTIC NUMBER 1
    YLIMITS 0 1; YTIC DECIMAL 1
    MULTIPLOT 2 3; MULTIPLOT CORNER COORDINATES 0 0 100 100
    LET JUNK = -1
    TITLE AUTOMATIC
    X1LABEL EXACTLY UNIFORM DISTRIBUTION; XLIMITS -1 1
    XTIC OFFSET 0.1 0.1
    PLOT LAMCDF(X,1) FOR X = -1 0.01 1.0
    X1LABEL U SHAPED; XLIMITS -2 2; XTIC OFFSET 0.2 0.2
    PLOT LAMCDF(X,0.5) FOR X = -1.99 0.01 1.99
    X1LABEL APPROXIMATELY NORMAL; XLIMITS -3 3; XTIC OFFSET 0.2 0.2
    PLOT LAMCDF(X,0.14) FOR X = -3 .01 3
    X1LABEL EXACTLY LOGISTIC; XLIMITS -5 5; XTIC OFFSET 0.2 0.2
    PLOT LAMCDF(X,0) FOR X = -5.5 0.01 5.5
    X1LABEL APPROXIMATELY CAUCHY; XLIMITS -4 4; XTIC OFFSET 0.2 0.2
    PLOT LAMCDF(X,JUNK) FOR X = -4 0.01 4
    X1LABEL ; XLIMITS -0.2 0.2; XTIC OFFSET 0.1 0.1
    PLOT LAMCDF(X,5) FOR X = -0.2 0.001 0.2
    END OF MULTIPLOT
 
-----LAMPDF (LET)--------------------------------
 
LAMPDF
 
Name:
    LAMPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Tukey-Lambda probability density function with shape
     parameter lambda.
 
Description:
    The Tukey-Lambda distribution does not have a simple, general,
    closed form formula for the probability density function.  Some
    special cases are:
       1) lambda = -1    - approximately Cauchy;
       2) lambda = 0     - exactly logistic;
       3) lambda = 0.14  - approximately normal;
       4) lambda = 0.5   - U shaped;
       5) lambda = 1.0   - exactly uniform.
    The input value is limited to the range =/-(1/lambda).
 
Syntax:
    LET <y2> = LAMPDF(<y1>,<lambda>) <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable, a number, or a parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed Tukey-Lambda pdf value is saved;
          <lambda> is a number or parameter that specifies the shape
               parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LAMPDF(3,1)
    LET X2 = LAMPDF(X1,LAMBDA)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LAMCDF = Compute the Tukey-Lambda cumulative distribution function.
    LAMPPF = Compute the Tukey-Lambda percent point function.
    LAMSF  = Compute the Tukey-Lambda sparsity function.
    NORPDF = Compute the standard normal probability density function.
    NORCDF = Compute the standard normal cumulative distribution
             function.
    NORPPF = Compute the standard normal percent point function.
    LOGCDF = Compute the logistic cumulative distribution function.
    LOGPDF = Compute the logistic probability density function.
    LOGPPF = Compute the logistic percent point function.
    UNICDF = Compute the uniform cumulative distribution function.
    UNIPDF = Compute the uniform probability density function.
    UNIPPF = Compute the uniform percent point function.
 
Reference:
    "Low Moments for Small Samples: A Comparative Study of Order
    Statistics", Annals of Mathematical Statistics, 18, 1947 (pp.
    413-426).
 
Applications:
    XX
 
Implementation Date:
    94/4
 
Program:
    MULTIPLOT 2 3; MULTIPLOT CORNER COORDINATES 0 0 100 100
    LET JUNK = -1
    TITLE AUTOMATIC
    X1LABEL EXACTLY UNIFORM DISTRIBUTION
    XLIMITS -1 1; XTIC OFFSET 0.1 0.1
    PLOT LAMPDF(X,1) FOR X = -1 0.01 1.0
    X1LABEL U SHAPED
    XLIMITS -2 2; XTIC OFFSET 0.2 0.2
    PLOT LAMPDF(X,0.5) FOR X = -1.99 0.01 1.99
    X1LABEL APPROXIMATELY NORMAL
    XLIMITS -3 3; XTIC OFFSET 0.2 0.2
    PLOT LAMPDF(X,0.14) FOR X = -3 .01 3
    X1LABEL EXACTLY LOGISTIC
    XLIMITS -5 5; XTIC OFFSET 0.2 0.2
    PLOT LAMPDF(X,0) FOR X = -5.5 0.01 5.5
    X1LABEL APPROXIMATELY CAUCHY
    XLIMITS -4 4; XTIC OFFSET 0.2 0.2
    PLOT LAMPDF(X,JUNK) FOR X = -4 0.01 4
    X1LABEL
    XLIMITS -0.2 0.2; XTIC OFFSET 0.1 0.1
    PLOT LAMPDF(X,5) FOR X = -0.2 0.01 0.2
    END OF MULTIPLOT
 
-----LAMPPF (LET)--------------------------------
 
LAMPPF
 
Name:
    LAMPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Tukey-Lambda percent point function.
 
Description:
    The Tukey-Lambda distribution does not have a simple, general,
    closed formula for the probability density function or the
    cumulative distribution function.
 
    The percent point function is the inverse of the cumulative
    distribution function.  The cumulative distribution sums the
    probability from 0 to the given x value (i.e., the integral of the
    above function).  The percent point function takes a cumulative
    probability value and computes the corresponding x value.  The
    formula for the percent point function is:
        G(p) = (p**lambda - (1-p)**lambda)/lambda
 
    The input value is a real number between 0 and 1 (since it
    corresponds to a probability).
 
Syntax:
    LET <y2> = LAMPPF(<y1>,lambda)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable, a number, or a parameter in the range 0
               to 1;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed Tukey-Lambda ppf value is stored;
          <lambda> is a number or parameter that specifies the shape
               parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LAMPPF(0.9)
    LET X2 = LAMPPF(X1)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LAMCDF = Compute the Tukey-Lambda cumulative distribution function.
    LAMPDF = Compute the Tukey-Lambda probability density function.
    LAMSF  = Compute the Tukey-Lambda sparsity function.
    NORPDF = Compute the standard normal probability density function.
    NORCDF = Compute the standard normal cumulative distribution
             function.
    NORPPF = Compute the standard normal percent point function.
    LOGCDF = Compute the logistic cumulative distribution function.
    LOGPDF = Compute the logistic probability density function.
    LOGPPF = Compute the logistic percent point function.
    UNICDF = Compute the uniform cumulative distribution function.
    UNIPDF = Compute the uniform probability density function.
    UNIPPF = Compute the uniform percent point function.
 
Reference:
    "Low Moments for Small Samples: A Comparative Study of Order
    Statistics", Annals of Mathematical Statistics, 18, 1947 (pp.
    413-426).
 
Applications:
    XX
 
Implementation Date:
    94/4
 
Program:
    XLIMITS 0 1; XTIC OFFSET 0.1 0.1
    MAJOR XTIC NUMBER 6; MINOR XTIC NUMBER 1
    MULTIPLOT 2 3; MULTIPLOT CORNER COORDINATES 0 0 100 100
    LET JUNK = -1
    TITLE AUTOMATIC; TITLE SIZE 3
    X1LABEL EXACTLY UNIFORM DISTRIBUTION
    PLOT LAMPPF(X,1) FOR X = 0.01 .01 0.99
    X1LABEL U SHAPED
    PLOT LAMPPF(X,0.5) FOR X = 0.01 0.01 0.99
    X1LABEL APPROXIMATELY NORMAL
    PLOT LAMPPF(X,0.14) FOR X = 0.01 0.01 0.99
    X1LABEL EXACTLY LOGISTIC
    PLOT LAMPPF(X,0) FOR X = 0.01 0.01 0.99
    X1LABEL APPROXIMATELY CAUCHY
    PLOT LAMPPF(X,JUNK) FOR X = 0.01 0.01 0.99
    X1LABEL
    PLOT LAMPPF(X,5) FOR X = 0.01 0.01 0.99
    END OF MULTIPLOT
 
-----LAMSF (LET)--------------------------------
 
LAMSF
 
Name:
    LAMSF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Tukey-Lambda sparsity function.
 
Description:
    The Tukey-Lambda distribution does not have a simple, general,
    closed formula for the probability density function or the
    cumulative distribution function.
 
    The sparsity function is the derivative of the percent point
    function, which is the inverse of the cumulative distribution
    function.  The cumulative distribution sums the probability from 0
    to the given x value (i.e., the integral of the above function).
    The percent point function takes a cumulative probability value
    and computes the corresponding x value.  The formula for the
    sparsity function is:
        sf(p) = p**(lambda-1) + (1-p)**(lambda-1)
 
    The input value is a real number between 0 and 1 (since it
    corresponds to a probability).
 
Syntax:
    LET <y2> = LAMSF(<y1>,lambda)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable, a number, or a parameter in the range 0
               to 1;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed Tukey-Lambda sf value is stored;
          <lambda> is a number or parameter that specifies the shape
               parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LAMSF(0.9)
    LET X2 = LAMSF(X1)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LAMCDF = Compute the Tukey-Lambda cumulative distribution function.
    LAMPDF = Compute the Tukey-Lambda probability density function.
    LAMPPF = Compute the Tukey-Lambda percent point function.
    NORPDF = Compute the standard normal probability density function.
    NORCDF = Compute the standard normal cumulative distribution
             function.
    NORPPF = Compute the standard normal percent point function.
    LOGCDF = Compute the logistic cumulative distribution function.
    LOGPDF = Compute the logistic probability density function.
    LOGPPF = Compute the logistic percent point function.
    UNICDF = Compute the uniform cumulative distribution function.
    UNIPDF = Compute the uniform probability density function.
    UNIPPF = Compute the uniform percent point function.
 
Reference:
    "Low Moments for Small Samples: A Comparative Study of Order
    Statistics", Annals of Mathematical Statistics, 18, 1947 (pp.
    413-426).
 
Applications:
    XX
 
Implementation Date:
    94/4
 
Program:
    XLIMITS 0 1; XTIC OFFSET 0.1 0.1
    MAJOR XTIC NUMBER 6; MINOR XTIC NUMBER 1
    MULTIPLOT 2 3; MULTIPLOT CORNER COORDINATES 0 0 100 100
    LET JUNK = -1
    TITLE AUTOMATIC; TITLE SIZE 3
    X1LABEL EXACTLY UNIFORM DISTRIBUTION
    PLOT LAMPPF(X,1) FOR X = 0.01 .01 0.99
    X1LABEL U SHAPED
    PLOT LAMPPF(X,0.5) FOR X = 0.01 0.01 0.99
    X1LABEL APPROXIMATELY NORMAL
    PLOT LAMPPF(X,0.14) FOR X = 0.01 0.01 0.99
    X1LABEL EXACTLY LOGISTIC
    PLOT LAMPPF(X,0) FOR X = 0.01 0.01 0.99
    X1LABEL APPROXIMATELY CAUCHY
    PLOT LAMPPF(X,JUNK) FOR X = 0.01 0.01 0.99
    X1LABEL
    PLOT LAMPPF(X,5) FOR X = 0.01 0.01 0.99
    END OF MULTIPLOT
 
-----LANCDF (LET)--------------------------------
 
LANCDF
 
Name:
    LANCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard Landau cumulative distribution function.
 
Description:
    The standard Landau distribution is the integral from minus
    infinity to x of the Landau probability density function:

       f(x) = (1/(2*PI*i)*INTEGRAL[e-i*infinity to e+i*infinity]
              [EXP(x*s s*LN(s))ds]

    The most common use of the Landau distribution is in
    the field of experimental physics.
 
Syntax:
    LET <y> = LANCDF(<x>)      <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Landau cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LANCDF(3)
    LET X2 = LANCDF(X1)
 
Note:
    Dataplot computes the LANCDF routine using the DISLAN routine
    of Kolbig and Schorr (see Reference below) in the CERNLIB
    library.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LANCDF           = Compute the Landau Probability density
                       function.
    LANPPF           = Compute the Landau percent point function.
    LANXM1           = Compute the Landau first moment function.
    LANXM2           = Compute the Landau second moment function.
    LANDIF           = Compute the derivative of the Landau probability
                       density function.
    RANDOM NUMBERS   = Generate random numbers from 60+ univariate
                       distributions.
    PROBABILITY PLOT = Generate a probability plot.
 
Reference:
    "A Program Package for the Landau Distribution", K. S. Kolbig
    and Schorr, Computer Physics Communications, 31 (1984),
    pp. 97-111.
 
Applications:
    Experimental Physics
 
Implementation Date:
    2003/5
 
Program:
    TITLE LANDAU PDF
    PLOT LANCDF(X)  FOR X = -5  0.1  200
-----LANDIF (LET)--------------------------------
 
LANDIF
 
Name:
    LANDIF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the derivative of the probability density function for
    the standard Landau distribution.
 
Description:
    The standard Landau distribution has the following
    probability density function:

       f(x) = (1/(2*PI*i)*INTEGRAL[e-i*infinity to e+i*infinity]
              [EXP(x*s s*LN(s))ds]

    This function computes the derivative of that function.

    The most common use of the Landau distribution is in
    the field of experimental physics.
 
Syntax:
    LET <y> = LANDIF(<x>)      <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed derivative of the Landau pdf value
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LANDIF(3)
    LET X2 = LANDIF(X1)
 
Note:
    Dataplot computes the LANDIF routine using the DIFLAN routine
    of Kolbig and Schorr (see Reference below) in the CERNLIB
    library.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LANCDF           = Compute the Landau cumulative distribution
                       function.
    LANPDF           = Compute the Landau probability density
                       function.
    LANPPF           = Compute the Landau percent point function.
    LANXM1           = Compute the Landau first moment function.
    LANXM2           = Compute the Landau second moment function.
    RANDOM NUMBERS   = Generate random numbers from 60+ univariate
                       distributions.
    PROBABILITY PLOT = Generate a probability plot.
 
Reference:
    "A Program Package for the Landau Distribution", K. S. Kolbig
    and Schorr, Computer Physics Communications, 31 (1984),
    pp. 97-111.
 
Applications:
    Experimental Physics
 
Implementation Date:
    2003/5
 
Program:
    TITLE LANDAU PDF
    PLOT LANDIF(X)  FOR X = -5  0.1  200
-----LANPDF (LET)--------------------------------
 
LANPDF
 
Name:
    LANPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard Landau probability density function.
 
Description:
    The standard Landau distribution has the following
    probability density function:

       f(x) = (1/(2*PI*i)*INTEGRAL[e-i*infinity to e+i*infinity]
              [EXP(x*s s*LN(s))ds]

    The most common use of the Landau distribution is in
    the field of experimental physics.
 
Syntax:
    LET <y> = LANPDF(<x>)      <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Landau pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LANPDF(3)
    LET X2 = LANPDF(X1)
 
Note:
    Dataplot computes the LANPDF routine using the DENLAN routine
    of Kolbig and Schorr (see Reference below) in the CERNLIB
    library.
 
Note:
    The following commands are also supported for the Landau distribution:

       LET Y = LANDAU RANDOM NUMBERS FOR I = 1 1 N
       LANDAU PROBABILITY PLOT Y
       LANDAU KOLMOGOROV SMIRNOV GOODNESS OF FIT
       LANDAU CHI-SQUARE GOODNESS OF FIT

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LANCDF           = Compute the Landau cumulative distribution
                       function.
    LANPPF           = Compute the Landau percent point function.
    LANXM1           = Compute the Landau first moment function.
    LANXM2           = Compute the Landau second moment function.
    LANDIF           = Compute the derivative of the Landau probability
                       density function.
    RANDOM NUMBERS   = Generate random numbers from 60+ univariate
                       distributions.
    PROBABILITY PLOT = Generate a probability plot.
 
Reference:
    "A Program Package for the Landau Distribution", K. S. Kolbig
    and Schorr, Computer Physics Communications, 31 (1984),
    pp. 97-111.
 
Applications:
    Experimental Physics
 
Implementation Date:
    2003/5
 
Program:
    TITLE LANDAU PDF
    PLOT LANPDF(X)  FOR X = -5  0.1  200

-----LANPPF (LET)--------------------------------
 
LANPPF
 
Name:
    LANPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard Landau percent point function.
 
Description:
    The standard Landau distribution has the following
    probability density function:

       f(x) = (1/(2*PI*i)*INTEGRAL[e-i*infinity to e+i*infinity]
              [EXP(x*s s*LN(s))ds]

    The cumulative distribution function is the cumulative
    integral from minus infinity to x of this function and
    the percent point function is the inverse of the cumulative
    distribution function.

    The most common use of the Landau distribution is in
    the field of experimental physics.
 
Syntax:
    LET <y> = LANPPF(<p>)      <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, a number, or a parameter in the interval
              0 to 1;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Landau ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LANPPF(0.9)
    LET X2 = LANPPF(P1)
 
Note:
    Dataplot computes the LANPPF routine using the RANLAN routine
    of Kolbig and Schorr (see Reference below) in the CERNLIB
    library.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LANCDF           = Compute the Landau cumulative distribution
                       function.
    LANPDF           = Compute the Landau probability density
                       function.
    LANXM1           = Compute the Landau first moment function.
    LANXM2           = Compute the Landau second moment function.
    LANDIF           = Compute the derivative of the Landau probability
                       density function.
    RANDOM NUMBERS   = Generate random numbers from 60+ univariate
                       distributions.
    PROBABILITY PLOT = Generate a probability plot.
 
Reference:
    "A Program Package for the Landau Distribution", K. S. Kolbig
    and Schorr, Computer Physics Communications, 31 (1984),
    pp. 97-111.
 
Applications:
    Experimental Physics
 
Implementation Date:
    2003/5
 
Program:
    TITLE LANDAU PPF
    PLOT LANPPF(P)  FOR P = 0.01  0.01 0.99

-----LANXM1 (LET)--------------------------------
 
LANXM1
 
Name:
    LANXM1 (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the first moment of the standard Landau distribution.
 
Description:
    The standard Landau distribution has the following
    first moment function:

       F(1)(x) = (1/F(X))*INTEGRAL[-infinity to x][x*f(x)dx]

    where F(x) and f(x) are the cumulative distribution function
    and the probability density function of the Landau distribution,
    respectively.

    The most common use of the Landau distribution is in
    the field of experimental physics.
 
Syntax:
    LET <y> = LANXM1(<x>)      <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Landau first moment value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LANXM1(3)
    LET X2 = LANXM1(X1)
 
Note:
    Dataplot computes the LANXM1 routine using the DENXM1 routine
    of Kolbig and Schorr (see Reference below) in the CERNLIB
    library.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LANCDF           = Compute the Landau cumulative distribution
                       function.
    LANPDF           = Compute the Landau probability density
                       function.
    LANPPF           = Compute the Landau percent point function.
    LANXM2           = Compute the Landau second moment function.
    LANDIF           = Compute the derivative of the Landau probability
                       density function.
    RANDOM NUMBERS   = Generate random numbers from 60+ univariate
                       distributions.
    PROBABILITY PLOT = Generate a probability plot.
 
Reference:
    "A Program Package for the Landau Distribution", K. S. Kolbig
    and Schorr, Computer Physics Communications, 31 (1984),
    pp. 97-111.
 
Applications:
    Experimental Physics
 
Implementation Date:
    2003/5
 
Program:
    TITLE LANDAU PDF
    PLOT LANXM1(X)  FOR X = -5  0.1  200

-----LANXM2 (LET)--------------------------------
 
LANXM2
 
Name:
    LANXM2 (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the second moment of the standard Landau distribution.
 
Description:
    The standard Landau distribution has the following
    second moment function:

       F(2)(x) = (1/F(X))*INTEGRAL[-infinity to x][x**2*f(x)dx]

    where F(x) and f(x) are the cumulative distribution function
    and the probability density function of the Landau distribution,
    respectively.

    The most common use of the Landau distribution is in
    the field of experimental physics.
 
Syntax:
    LET <y> = LANXM2(<x>)      <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Landau second moment value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LANXM2(3)
    LET X2 = LANXM2(X1)
 
Note:
    Dataplot computes the LANXM2 routine using the DENXM2 routine
    of Kolbig and Schorr (see Reference below) in the CERNLIB
    library.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LANCDF           = Compute the Landau cumulative distribution
                       function.
    LANPDF           = Compute the Landau probability density
                       function.
    LANPPF           = Compute the Landau percent point function.
    LANXM1           = Compute the Landau first moment function.
    LANDIF           = Compute the derivative of the Landau probability
                       density function.
    RANDOM NUMBERS   = Generate random numbers from 60+ univariate
                       distributions.
    PROBABILITY PLOT = Generate a probability plot.
 
Reference:
    "A Program Package for the Landau Distribution", K. S. Kolbig
    and Schorr, Computer Physics Communications, 31 (1984),
    pp. 97-111.
 
Applications:
    Experimental Physics
 
Implementation Date:
    2003/5
 
Program:
    TITLE LANDAU PDF
    PLOT LANXM2(X)  FOR X = -5  0.1  200

-----LARGEST (LET)-------------------------------------
 
LARGEST
 
Name:
    LARGEST (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Extract the largest elements of a variable.

Description:
    This is a generalization of the MAXIMUM command.  However, instead of
    returning the single largest value, it returns the user specified
    number of largest values.

    The values will be returned in sorted order.  If the requested number
    of largest values is less than 1, then an error will be returned.  If
    the requested number of largest values is greater than the number of
    observations in the response variable, then the full response variable
    will be returned in sorted order.

Syntax:
    LET <y> = LARGEST <x>  <nval>     <SUBSET/EXCEPT/FOR>
    where <x> is a response variable;
          <nval> is a number or parameter that specifies how
              many values to extract;
          <y> is a variable that contains the largest values.
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET NVAL = 3
    LET Y = LARGEST X NVAL
 
    LET Y = LARGEST X 3
    LET Y = LARGEST X 5
    LET Y = LARGEST X 5  FOR I = 1 1 500

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SMALLEST           = Return the smalles values in a variable.
    MAXIMUM            = Return the maximum value of a variable.
    MINIMUM            = Return the minimum value of a variable.
 
Applications:
    Data Transformation
 
Implementation Date:
    2018/10
 
Program:
    let y = normal random numbers for i = 1 1 100
    let nval = 5
    let yout = largest y nval
    set write decimals 3
    print yout

-----LATEX---------------------------------------------------------
 
LATEX
 
Name:
    LATEX
 
Type:
    Output Device Command
 
Purpose:
    Create Latex format graphics files.
 
Description:
    Tex is a powerful typesetting program originally developed
    by Donald Knuth.  LaTex was developed by Leslie Lamport and
    is a program written on top of Tex.  LaTex provides access
    to the power of Tex, but with a simpler command language.
   
    The motivation for developing a LaTex graphics driver in
    Dataplot is to help in producing publication quality
    graphics with Dataplot.  Additional comments on utilizing
    the typesetting capabilities of LaTex from within Dataplot are
    given below.

    The basic process in using LaTex is:

       1) Create an ASCII text file with a ".tex" file extension
          that contains the desired text along with the LaTex
          formatting commands.

       2) Run the "latex" command on this file to create a
          device indpendent file (called a DVI file).

       3) Run a driver program to generate the DVI file for
          a specific device.  For example, on Unix platforms
          the command "dvips" is typically run to generate a
          Postscript from the DVI file.

          Note that LaTex provides a "special" mechanism to
          take advantage of features specific to a given output
          device.  It is up to the DVI driver program to implement
          these "special" options.  

    Although Tex and Latex were written primarily for typesetting
    text, there are several ways that Latex provides for
    graphics:

       1) LaTex supports a "picture" environment that provides
          some capabilites for graphics in the LaTex language.

          This environment has some serious limitations (e.g.,
          no direct color support, lines can only be drawn at
          a fairly limited number of slopes).

          In order to overcome these limitations, a number of
          "add-on" packages have been written to enhance the
          picture environment.  These packages may implement
          some of their capabilites in LaTex (which will be
          available on all supported devices) and others using
          "special" features of a DVI driver (these may not be
          available on some devices).

          The Dataplot LaTex graphics driver uses the LaTex
          picture environment along with the following packages:

              1) epic
              2) eepic
              3) graphics

          If your local LaTex installation does not already
          have these add-on packages available, then you need
          to download and install them (they are freely
          downloadable).

       2) The "epsfig" package can be used to import Postscript
          graphics.  Dataplot Postscript graphics can be
          incorporated into LaTex documents in this way.  In
          particular, the SET POSTSCRIPT CONVERT and CAPTURE LATEX
          commands can be used to automate this in Dataplot
          (enter HELP CAPTURE LATEX for details).

    Dataplot supports LaTex output in three ways:

       1) You can generate a "standalone" LaTex file.  You
          can run the latex command on this file to generate
          the desired graph.

       2) You can generate a file without the LaTex preamble
          and postamble commands.  This is useful if you want
          to import the graphics into an already existing
          LaTex file.

       3) You can use the CAPTURE LATEX option to create a
          LaTex file that has both the alphanumeric output
          and the graphics generated by Dataplot in a single
          file.

    Features of the LaTex driver are discussed in the Notes section
    below.

Syntax 1:
    DEVICE 2 LATEX STANDALONE
 
    This syntax is used to generate a standalone LaTex file.
 
Syntax 2:
    DEVICE 2 LATEX
 
    This syntax is used to generate a LaTex file that can be
    imported into another LaTex file (i.e., you cannot run the
    latex command directly on this file).
 
Syntax 3:
    DEVICE 1 LATEX
 
    This syntax is used in conjunction with the CAPTURE LATEX
    command to incorporate Dataplot alphanumeric and graphics
    output in a single LaTex file.  The Program 2 example below
    gives an example of this.
 
Examples:
    DEVICE 2 LATEX STANDALONE
    DEVICE 2 LATEX
 
Note:
    One of the primary reasons for using the latex graphics
    driver is to obtain publication quality text on your
    graphs. 

    In particular, this applies to special characters such
    as subscritps, superscripts, Greek characters, and
    special mathematical symbols.  If your text does not
    utilize these, you can obtain publication quality
    text by simply using the Postscript driver.

    There are two ways to utilize these special symbols.
    
        1) Dataplot provides a mechanism for software fonts
           to generate special symbols.  A list of supported
           symbols can be found at

              http://www.itl.nist.gov/div898/software/dataplot/
              refman1/ch13/homepage.pdf

           For example, alph() will generate a Greek alpha.

           The latex driver will convert these Dataplot
           codings for special symbols to the corresponding
           LaTex codings.

           A few notes on this:

           a) For Greek characters, use LC() and UC() to
              specify lower case and upper case, respectively
              (the default is upper case).

           b) A few symbols are currently not translated:

                DEL()   - VECTOR PRODUCT
                VARI()  - VARIES
                THFO()  - THEREFORE
                LELB()  - LEFT ELBOW
                RELB()  - RIGHT ELBOW
                HBAR()  - HORIZONTAL BAR
                LHNA()  - LONG HORIZONTAL BAR
 
        2) Alternatively, you can put the appropriate LaTex
           code in the text yourself.  For example, to put
           an alpha squared in a title, enter the following:

              REPLACEMENT CHARACTER @
              TITLE $\alpha^{2}$

           The "$" symbol is used to specify LaTex math mode
           (you need to be in math mode for LaTex to properly
           interpert the special symbols).  By default, Dataplot
           uses the "^" to denote replacement of parameters
           and strings in Dataplot commands.  If your LaTex
           codings use superscripts, then you need to modify
           the Dataplot replacement character before any
           commands that use "^" to specify superscripting
           to LaTex. 

           The primary advantage of this method is that it
           gives you full access to the LaTex special symbol
           library.  This library is extensive and contains
           many characters not currently supported in
           Dataplot.  In addition, you can do things such
           as generating bold or italic text.

           The primary disadvantage is that Dataplot does no
           error checking of the text you enter.  It is simply
           passed to the LaTex file as entered.  If you have
           non-matching braces or dollar signs, your LaTex file
           may not compile when you run the latex command.
           
Note:
    In standalone mode, Dataplot will generate an appropriate
    preamble at the beginning of the LaTex file and a
    postamble at the end of the LaTex file.

    If you want to provide your own preamble or postamble,
    you can enter the following command:

        SET LATEX HEADER FILE  <file>
        SET LATEX FOOTER FILE  <file>

    The header file should contain the following two lines:

        \usepackage{epic,eepic}
        \usepackage{graphics,color}

Note:
    The generated LaTex file is an ASCII file.  If you have
    some proficiency in LaTex, you can modify the LaTex output
    using a text editor.  For example, you may want to have
    LaTex load a different font (Dataplot uses the default LaTex
    font).  If you entered a LaTex text coding incorrectly, you
    can fix it in the generated LaTex file without rerunning the
    Dataplot code that created the LaTex file.

Note:
    By default, the LaTex graphic file is generated without
    color. In order to activate color, enter the following
    command before the DEVICE <1/2> LATEX command:

       SET LATEX COLOR ON

Note:
    Thick lines can be generated either by LaTex or by
    Dataplot.  LaTex supports 3 distinct line thickneses.

    To have LaTex generate thick lines, enter

        SET LATEX LINE THICKNESS HARDWARE

    To have Dataplot generate thick lines, enter

        SET LATEX LINE THICKNESS SOFTWARE

Note:
    Dataplot currently creates the LaTex graphics at 300
    dots per inch.  It assumes a page size with a width
    of 6.5 inches and a height of 9 inches.

    Currently, Dataplot does not support different dots
    per inch.

    If you specify ORIENTATION LANDSCAPE or ORIENTATION
    LANDSCAPE WORDPERFECT, the graph will be generated
    with a width of 6.25 inches and a height of 4.8 inches
    (i.e., a landscape orientation on a portrait page).
    If you specify ORIENTATION PORTRAIT, the graph will
    be generated with a width of 6.26 inches and a height
    of 9 inches.  If you specify ORIENTATION SQUARE, the
    graph will be generated with a width of 6 inches and
    a height of 6 inches.  Dataplot does not currently
    support a true landscape mode (i.e., a rotated picture
    with a width of 9 inches and a height of 6.25 inches).

    You can also specify your own dimensions.  For example,
    to generate a 5 inch by 5 inch plot, enter the
    commands

       LET AWIDTH = 5.0*300
       DEVICE 2 LATEX STANDALONE
       DEVICE 2 PICTURE POINTS AWIDTH AWIDTH
 
    If you use the default landscape mode, you may want
    to specify larger character sizes.  Dataplot text sizes
    are specified as a percentage of the height and generating
    a landscape mode plot may result in the default character
    sizes being smaller than desired.  You may want to
    include the following size commands:

        HEIGHT 3
        LEGEND SIZE 3
        TITLE SIZE 3
        LABEL SIZE 3
        TIC MARK LABEL SIZE 3
        CHARACTER SIZE 3 ALL

    The default character size for the above commands is 2.
 
    Note that Dataplot cannot specify a specific point size
    for text to LaTex.  Instead, there are 10 commands
    (e.g., \normalsize, \footnotesize, \tiny, \large).  The
    actual size LaTex generates depends on the font and the
    default point size for the LaTex file.  Dataplot maps the
    requested character size to one of the 10 LaTex size
    commands based on a default point size of 12 and the
    default LaTex font.  Our testing shows that this
    results in 5 distinct point sizes generated by LaTex.

    If you use a different font, Dataplot's best guess as
    to the size LaTex will generate may not be accurate. 
    Since Dataplot uses LaTex to justify text, this should
    typically not be a problem.  One case where it might
    be an issue is in the placement of tick mark labels.
    You can use the TIC MARK LABEL DISPLACEMENT comamnd to
    adjust their positioning if needed.

Note:
    Typically, you want LaTex files to have a ".tex" file
    extension.  You can do something like the following
    to modify the default plot file name:

        SET IPL1NA  plot1.tex
        DEVICE 2 LATEX STANDALONE

Note:
    The CAPTURE LATEX command will generate the output from
    Dataplot analysis commands in LaTex format.  This feature
    is partially implemented.  For commands that have not
    been implemented, the Dataplot output will be enclosed
    in the "verbatim" environment.  Enter HELP CAPTURE LATEX
    for a list of commands that will generate Latex specific
    output and for details on the use of this command.

    You can combine this with the DEVICE 1 LATEX command
    to generate a LaTex file with both the analysis output
    and the graphics output in the same file.  A typical
    sequence of commands would be

       FEEDBACK OFF
       CAPTURE LATEX  sample.tex
       DEVICE 1 LATEX
          ...  analysis and graphics commands  ...
       DEVICE 1 CLOSE
       END OF CAPTURE

    Note that the order of the commands matters here.
    Specifically, the CAPTURE LATEX command should be
    entered before the DEVICE 1 LATEX command and the
    DEVICE 1 CLOSE command should be entered before the
    END OF CAPTURE command.  If this sequence is not followed,
    some of the needed LaTex commands may not be written to
    the LaTex file.
     
Note:
    Even if you would like to import a presentation quality
    graph into Word, WordPerfect, or some other Windows-based
    word proceser, the LaTex driver can still be useful.

    The steps involved are:

      1) Use the DEVICE 2 LATEX STANDALONE to generate a LaTex
         file.

      2) Use the latex and dvips commands to create a Postscript
         file of the graph.

      3) Import this Postscript graph into the Windows version
         of Ghostview (which you should have typically installed
         when installing the Windows version of Dataplot).  Use
         the Convert menu under the File menu to convert the
         graph into a format that can be imported by Word (or
         whatever word processer you are using).  The JPEG
         format should be supported in most cases.  The Convert
         menu will allow you to preserve the 300 dot per inch
         resolution.

      4) Import the resulting JPEG format graph into Word in
         the standard way.

    This does require that LaTex (and the epic and eepic
    packages) be installed on your local platform.

Default:
    None
 
Synonyms:
    None

Related Commands:
    CAPTURE LATEX    = Direct alphanumeric output to a file in
                       LaTex format.
    POSTSCRIPT       = Create graphical output in Postscript format.
    SVG              = Create graphical output in SVG
                       (Scalable Vector Graphics) format.
    DEVICE           = Specify certain actions for the graphics
                       output.
 
References:
    "LaTEX: A Document Preparation System", Second Edition, Leslie Lamport,
    Addison-Wesley, 1994.

    "The LATEX Companion", Second Edition, Frank Mittelbach and
    Michel Goosens with Johannes Braams, David Carlisle, and
    Chris Rowley, Addison-Wesley, 2004.

    "Guide to LATEX", Fourth Edition, Helmut Kopka and Patrick Daly,
    Addison-Wesley, 2003.

Applications:
    Publication Quality Graphics
 
Implementation Date:
    2006/2: Original Implementation
 
Program 1:
    .  Demonstrate following features of Latex driver:
    .
    .  1) Color
    .  2) Text using Latex encodings
    .  3) Text using Dataplot encodings
    .  4) Thick lines
    .
    set ipl1na plot1.tex
    set latex color on
    device 2 latex standalone
    .
    skip 25
    read berger1.dat y x
    .
    quadratic fit y x
    .
    title case asis
    label case asis
    legend case asis
    title size 3
    legend size 3
    label size 3
    tic mark label size 3
    title offset 2
    replacement character !
    .  Use Latex encodings for title
    title Y = $\alpha_{0} + \alpha_{1}x + \alpha_{2}x^{2}$
    replacement character ^
    y1label Measured In-Field Defect Size
    x1label Measured In-Lab Defect Size
    .  Use Dataplot encodings for legends
    legend 1 lc()alph()sub()0unsb() = ^a0
    legend 2 lc()alph()sub()1unsb() = ^a1
    legend 3 lc()alph()sub()2unsb() = ^a2
    tic offset units screen
    tic offset 3 3
    .
    title size 3
    tic mark label size 3
    label size 3
    .
    char x blank
    character color red all
    line blank solid
    line color blue all
    line thickness 0.2
    .
    plot y pred vs x
    .
    device 2 close
    system latex plot1.tex
    system dvips plot1
    .

Program 2:
    .  Example of creating Dataplot output in a single
    .  Latex file (i.e., both graphics and alphanumeric output
    .
    .  Step 1: Read Data
    .
    skip 25
    read stutz86.dat y1 to y5 x
    .
    .  Step 2: Generate the Consensus Means Output
    .
    feedback off
    capture latex  consensus.tex
    tabulate mean y1 x
    tabulate sd y1 x
    consensus mean y1 x
    .
    .  Step 3: Generate Some Complementary Graphics
    .
    device 1 latex
    .
    multiplot corner coordinates 2 2 98 98
    multiplot 2 2
    multiplot scale factor 2
    .
    title offset 2
    title size 3
    label size 3
    tic mark label size 3
    title automatic
    tic offset units screen
    tic offset 3 3
    line blank solid
    char x blank
    .
    mean plot y1 x
    sd plot y1 x
    .
    character box plot
    lines box plot
    fences on
    box plot y1 x
    .
    end of multiplot
    .
    device 1 close
    end of capture
    .
    system latex consensus.tex
    system dvips consensus.dvi > consensus.ps
    .

-----LATTICE-------------------------------------------------------
 
LATTICE
 
Name:
    LATTICE
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Draws a lattice (i.e., a rectangular grid).
 
Description:
    The 3 pairs of coordinates define the (x,y) values for the lower
    corner of the grid, the x and y increments for drawing grid lines,
    and the opposing corner of the lattice respectively.
 
Syntax:
    LATTICE  <x1>   <y1>   <x2>   <y2>  <x3> <y3>
    where <x1> is a number or parameter in the range 0 to 100 that
               specifies the x coordinate of the lower corner of the
               grid;
          <y1> is a number or parameter in the range 0 to 100 that
               specifies the y coordinate of the lower corner of the
               grid;
          <x2> is a number or parameter in the range 0 to 100 that
               specifies the x increment for the grid;
          <y2> is a number or parameter in the range 0 to 100 that
               specifies the y increment for the grid;
          <x3> is a number or parameter in the range 0 to 100 that
               specifies the x coordinate of the upper corner of the
               grid;
    and   <y3> is a number or parameter in the range 0 to 100 that
               specifies the y coordinate of the upper corner of the
               grid.
 
Examples:
    LATTICE 10 10 5 5 90 90
    LATTICE 90 90 5 5 10 10
    LATTICE 30 40 5 8 75 93
 
Note:
    The line style (i.e., SOLID, DASH), line color, and line thickness
    are controlled by the first entry of the LINE, LINE COLOR, and LINE
    THICKNESS commands respectively.
 
Note:
    The keywords DATA and RELATIVE were added to the TRIANGLE
    command 7/1997.  These keywords are independent and can
    be used separately or together.  For example, 
    TRIANGLE DATA, TRIANGLE RELATIVE, or TRIANGLE DATA RELATIVE.
    The word DATA should come before the word RELATIVE if both
    appear.

    DATA means that the coordinates are specified in terms of
    the data units of the most recent plot rather than Dataplot
    0 to 100 screen units.

    RELATIVE means that the coordinates of the first point
    are drawn in absolute coordinates an all subsequent points
    in the figure are relative to that first point.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MOVE             = Moves to a point.
    POINT            = Draws a point.
    ARROW            = Draws an arrow.
    TRIANGLE         = Draws a triangle.
    BOX              = Draws a box.
    HEXAGON          = Draws a hexagon.
    CIRCLE           = Draws a circle.
    SEMI-CIRCLE      = Draws a semi-circle.
    ARC              = Draws an arc.
    ELLIPSE          = Draws an ellipse.
    OVAL             = Draws an oval.
    DIAMOND          = Draws a diamond.
    LINES            = Sets the line type for figures and plot lines.
    LINE THICKNESSES = Sets the line thickness for figures and plot
                       lines.
    LINE COLOR       = Sets the line colors for figures and plot lines.
    CROSS-HAIR       = Activates and reads the cross-hair.
    TEXT             = Writes a text string.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    LINE DASH
    LINE COLOR G50
    LINE THICKNESS 0.4
    LATTICE 10 10 10 5 90 90
    JUSTIFICATION CENTER
    MOVE 50 95
    TEXT LATTICE 10 10 5 90 90
 
-----LBECDF (LET)--------------------------------
 
LBECDF
 
Name:
    LBECDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the log beta cumulative distribution function
    with shape parameters alpha, beta, c, and d.
 
Description:
    The log beta cumulative distribution function can be computed
    using the beta cumulative distribution function as follows:

        LBECDF(x;alpha,beta,c,d) = BETCDF(z;alpha,beta)
                                   0 < c <= x <= d
                                   alpha, beta > 0

    with alpha and beta denoting the shape parameters, c and d
    denoting the lower and upper limits of the log beta
    distribution, BETCDF denoting the beta cumulative distribution
    function, and where

         z = (LOG(x) - LOG(c)/(LOG(d) - LOG(c))

    The log beta distribution can be generalized with location
    and scale parameters in the usual way.

Syntax:
    LET <y> = LBECDF(<y>,<alpha>,<beta>,<c>,<d>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <alpha> is a number, parameter, or variable that specifies
               the first shape parameter;
          <beta> is a number, parameter, or variable that specifies
               the second shape parameter;
          <c> is a number, parameter, or variable that specifies
               the third shape parameter;
          <d> is a number, parameter, or variable that specifies
               the fourth shape parameter;
          <loc> is a number, parameter, or variable that specifies
               the optional location parameter;
          <scale> is a number, parameter, or variable that specifies
               the optional scale parameter;
          <y> is a variable or a parameter (depending on what <x>
               is) where the computed log beta cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The location and scale parameters are optional (the default
    values are zero and one, respectively).

Examples:
    LET A = LBECDF(2,6,6,1,3)
    LET Y = LBECDF(X,ALPHA,BETA,C,D)
    PLOT LBECDF(X,6,6,1,3) FOR X = 1.01  0.01 2.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LBEPDF    = Compute the log beta probability density function.
    LBEPPF    = Compute the log beta percent point function.
    BETPDF    = Compute the beta probability density function.
    BNOPDF    = Compute the beta normal probability density function.
    LGNPDF    = Compute the lognormal probability density function.
 
Reference:
    Nadarajah and Gupta (2004).  "Applications of the Beta
    Distribution" in "Handbook of the Beta Distribution", Edited
    by Gupta and Nadarajah, Marcel-Dekker, pp. 100-102.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2006/8
 
Program:
    title displacement 2
    y1label displacement 17
    x1label displacement 12
    case asis
    title case asis
    label case asis
    y1label Probability
    x1label X
    .
    let c = 1
    let d = 3
    .
    multiplot corner coordinates 0 0 100 95
    multiplot scale factor 2
    multiplot 2 2
    .
    title Alpha = 3, Beta = 3
    plot lbecdf(x,3,3,c,d) for x = 1.01  0.01  2.99
    .
    title Alpha = 5, Beta = 2
    plot lbecdf(x,5,2,c,d) for x = 1.01  0.01  2.99
    .
    title Alpha = 2, Beta = 5
    plot lbecdf(x,2,5,c,d) for x = 1.01  0.01  2.99
    .
    title Alpha = 5, Beta = 1
    plot lbecdf(x,5,1,c,d) for x = 1.01  0.01  2.99
    .
    end of multiplot
    .
    justification center
    move 50 97
    text Log Beta Cumulative Distribution Functions

-----LBEPDF (LET)--------------------------------
 
LBEPDF
 
Name:
    LBEPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the log beta probability density function with
    shape parameters alpha, beta, c, and d.
 
Description:
    The log beta distribution has the following probability
    density function:

        LBEPDF(x;alpha,beta,c,d) = BETPDF(z;alpha,beta)
                                   0 < c <= x <= d
                                   alpha, beta > 0

    with alpha and beta denoting the shape parameters of the
    underlying beta distribution, c and d denoting the lower
    and upper limits of the log beta distribution, BETPDF
    denoting the beta probability density function, and where

         z = (LOG(x) - LOG(c)/(LOG(d) - LOG(c))

    The log beta distribution has been proposed as an
    alternative to the log normal distribution.  It has the
    advantage of being able to model both left and right skewness
    (the lognormal can only model right skewness).  It may
    also be more appropriate when the data has an upper bound.

    The log beta distribution can be generalized with location
    and scale parameters in the usual way.

Syntax:
    LET <y> = LBEPDF(<y>,<alpha>,<beta>,<c>,<d>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <alpha> is a number, parameter, or variable that specifies
               the first shape parameter;
          <beta> is a number, parameter, or variable that specifies
               the second shape parameter;
          <c> is a number, parameter, or variable that specifies
               the third shape parameter;
          <d> is a number, parameter, or variable that specifies
               the fourth shape parameter;
          <loc> is a number, parameter, or variable that specifies
               the optional location parameter;
          <scale> is a number, parameter, or variable that specifies
               the optional scale parameter;
          <y> is a variable or a parameter (depending on what <x>
               is) where the computed log beta pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The location and scale parameters are optional (the default
    values are zero and one, respectively).

Examples:
    LET A = LBEPDF(2,6,6,1,3)
    LET Y = LBEPDF(X,ALPHA,BETA,C,D)
    PLOT LBEPDF(X,6,6,1,3) FOR X = 1.01  0.01 2.99
 
Note:
    Log beta random numbers, probability plots, and goodness
    of fit tests can be generated with the commands:

       LET ALPHA = <value>
       LET BETA = <value>
       LET C = <value>
       LET D = <value>
       LET Y = LOG BETA RANDOM NUMBERS FOR I = 1 1 N
       LOG BETA PROBABILITY PLOT Y
       LOG BETA PROBABILITY PLOT Y2 X2
       LOG BETA PROBABILITY PLOT Y3 XLOW XHIGH
       LOG BETA KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       LOG BETA CHI-SQUARE GOODNESS OF FIT Y2 X2
       LOG BETA CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    The following commands can be used to estimate the alpha
    and beta shape parameters (the lower and upper limit
    parameters c and d are assumed known) for the log beta
    distribution:

       LET C = <value>
       LET D = <value>
       LET ALPHA1 = <value>
       LET ALPHA2 = <value>
       LET BETA1 = <value>
       LET BETA2 = <value>
       LOG BETA PPCC PLOT Y
       LOG BETA PPCC PLOT Y2 X2
       LOG BETA PPCC PLOT Y3 XLOW XHIGH
       LOG BETA KS PLOT Y
       LOG BETA KS PLOT Y2 X2
       LOG BETA KS PLOT Y3 XLOW XHIGH

    The default values for ALPHA1 and ALPHA2 are 0.5 and 10.
    The default values for BETA1 and BETA2 are 0.5 and 10.

    Note that the log beta percent point function is expensive
    to compute.  For larger data samples, this can make the
    above fit commands slow.  We can do the following to
    improve the speed of these commands.

       1) Instead of generating the ppcc plot or ks plot on
          the original data, we can generate them on
          selected percentiles of the data.  For example,
          if we have 1,000 points, we can choose to generate
          the plots on 100 evenly spaced percentiles with
          the command

             SET PPCC PLOT DATA POINTS 100

       2) For the ks plot, we can speed up the computations
          considerably by specifying the location and
          scale parameters with the commands

             LET KSLOC = 0
             LET KSSCALE = 1

          Since this distribution includes the lower and upper
          limits, location and scale parameters are typically
          not used. 

          The ppcc plot is invariant to location and scale,
          so there is no speedup obtained by omitting the
          location and scale parameters.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LBECDF                            = Compute the log beta
                                        cumulative distribution
                                        function.
    LBEPPF                            = Compute the log beta percent
                                        point function.
    BETPDF                            = Compute the beta probability
                                        density function.
    BNOPDF                            = Compute the beta normal
                                        probability density function.
    LGNPDF                            = Compute the lognormal
                                        probability density function.
    PROBABILITY PLOT                  = Generate a probability plot.
    PPCC PLOT                         = Generate a ppcc plot.
    KS PLOT                           = Generate a Kolmogorov-Smirnov
                                        (or chi-square for binned
                                        data) plot.
    KOLM SMIRNOV GOODNESS OF FIT      = Perform a Kolmogorov-Smirnov
                                        goodness of fit test.
 
Reference:
    Nadarajah and Gupta (2004).  "Applications of the Beta
    Distribution" in "Handbook of the Beta Distribution", Edited
    by Gupta and Nadarajah, Marcel-Dekker, pp. 100-102.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2006/8
 
Program 1:
    title displacement 2
    y1label displacement 17
    x1label displacement 12
    case asis
    title case asis
    label case asis
    y1label Probability Density
    x1label X
    .
    let c = 1
    let d = 3
    .
    multiplot corner coordinates 0 0 100 95
    multiplot scale factor 2
    multiplot 2 2
    .
    title Alpha = 3, Beta = 3
    plot lbepdf(x,3,3,c,d) for x = 1.01  0.01  2.99
    .
    title Alpha = 5, Beta = 2
    plot lbepdf(x,5,2,c,d) for x = 1.01  0.01  2.99
    .
    title Alpha = 2, Beta = 5
    plot lbepdf(x,2,5,c,d) for x = 1.01  0.01  2.99
    .
    title Alpha = 5, Beta = 1
    plot lbepdf(x,5,1,c,d) for x = 1.01  0.01  2.99
    .
    end of multiplot
    .
    justification center
    move 50 97
    text Log Beta Probability Density Functions

Program 2:
    let alpha = 0.7
    let beta = 2.1
    let c = 1
    let d = 10
    let y = log beta rand numb for i = 1 1 500
    let y2 x2 = binned y
    let amin = minimum y
    let amax = maximum y
    .
    title displacement 2
    case asis
    title case asis
    label case asis
    .
    title Histogram with Overlaid PDF
    y1label Relative Frequency
    x1label X
    relative histogram y2 x2
    limits freeze
    pre-erase off
    line color blue
    plot lbepdf(x,alpha,beta,c,d) for x = amin  0.1  amax
    limits
    pre-erase on
    line color black
    .
    title Log Beta Probability Plot
    y1label Theoretical
    x1label Data
    char x
    line bl
    log beta probability plot y
    justification center
    move 50 6
    text PPCC = ^ppcc
    line solid
    char blank
    .
    multiplot corner coordinates 0 0 100 100
    multiplot scale factor 2
    y1label displacement 17
    x1label displacement 12
    multiplot 2 2
    .
    let alpha1 = 0.5
    let alpha2 = 5
    let beta1 = 0.5
    let beta2 = 5
    set ppcc plot data points 100
    .
    title PPCC Plot
    y1label Correlation Coefficient
    x1label Beta (Curves Represent Values of Alpha)
    log beta ppcc plot y
    let alpha = shape1
    let beta  = shape2
    set ppcc plot axis order reverse
    log beta ppcc plot y
    set ppcc plot axis order default
    title Probability Plot
    y1label Theoretical
    x1label Data
    log beta probability plot y
    log beta kolmogorov smirnov goodness of fit y
    title
    label
    plot
    justification left
    move 25 90
    text Alpha   = ^alpha
    move 25 85
    text Beta    = ^beta
    move 25 80
    text PPCC    = ^ppcc
    move 25 75
    text Min KS  = ^statval
    end of multiplot
    .
    multiplot 2 2
    let ksloc = 0
    let ksscale = 1
    title Chi-Square Plot
    y1label Minimum Chi-Square
    x1label Beta (Curves Represent Values of Alpha)
    log beta ks plot y2 x2
    let alpha = shape1
    let beta  = shape2
    set ppcc plot axis order reverse
    log beta ks plot y2 x2
    set ppcc plot axis order default
    title Probability Plot
    y1label Theoretical
    x1label Data
    log beta probability plot y2 x2
    log beta chi-square goodness of fit y2 x2
    title
    label
    plot
    justification left
    move 25 90
    text Alpha   = ^alpha
    move 25 85
    text Beta    = ^beta
    move 25 80
    text PPCC    = ^ppcc
    move 25 75
    text Min KS  = ^statval
    end of multiplot
 
-----LBEPPF (LET)--------------------------------
 
LBEPPF
 
Name:
    LBEPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the log beta percent point function with shape
    parameters alpha, beta, c, and d.
 
Description:
    The log beta percent point function can be computed using
    the beta percent point function as follows:

        LBEPPF(x;alpha,beta,c,d) = EXP(LOG(c)+ (LOG(d) - LOG(c))*
                                   BETPPF(p;alpha,beta))
                                   0 < p < 1;
                                   alpha, beta > 0

    with alpha and beta denoting the shape parameters, c and d
    denoting the lower and upper limits of the log beta
    distribution, and BETPPF denoting the beta percent point
    function.

    The log beta distribution can be generalized with location
    and scale parameters in the usual way.

Syntax:
    LET <y> = LBEPPF(<y>,<alpha>,<beta>,<c>,<d>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <alpha> is a number, parameter, or variable that specifies
               the first shape parameter;
          <beta> is a number, parameter, or variable that specifies
               the second shape parameter;
          <c> is a number, parameter, or variable that specifies
               the third shape parameter;
          <d> is a number, parameter, or variable that specifies
               the fourth shape parameter;
          <loc> is a number, parameter, or variable that specifies
               the optional location parameter;
          <scale> is a number, parameter, or variable that specifies
               the optional scale parameter;
          <y> is a variable or a parameter (depending on what <x>
               is) where the computed log beta cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The location and scale parameters are optional (the default
    values are zero and one, respectively).

Examples:
    LET A = LBEPPF(0.95,6,6,1,3)
    LET Y = LBEPPF(P,ALPHA,BETA,C,D)
    PLOT LBEPPF(P,6,6,1,3) FOR P = 0.01  0.01 0.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LBECDF    = Compute the log beta cumulative distribution
                function.
    LBEPDF    = Compute the log beta probability density function.
    BETPDF    = Compute the beta probability density function.
    BNOPDF    = Compute the beta normal probability density
                function.
    LGNPDF    = Compute the lognormal probability density function.
 
Reference:
    Nadarajah and Gupta (2004).  "Applications of the Beta
    Distribution" in "Handbook of the Beta Distribution", Edited
    by Gupta and Nadarajah, Marcel-Dekker, pp. 100-102.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2006/8
 
Program:
    title displacement 2
    y1label displacement 17
    x1label displacement 12
    case asis
    title case asis
    label case asis
    x1label Probability
    y1label X
    .
    let c = 1
    let d = 3
    .
    multiplot corner coordinates 0 0 100 95
    multiplot scale factor 2
    multiplot 2 2
    .
    title Alpha = 3, Beta = 3
    plot lbeppf(p,3,3,c,d) for p = 0.01  0.01  0.99
    .
    title Alpha = 5, Beta = 2
    plot lbeppf(p,5,2,c,d) for p = 0.01  0.01  0.99
    .
    title Alpha = 2, Beta = 5
    plot lbeppf(p,2,5,c,d) for p = 0.01  0.01  0.99
    .
    title Alpha = 5, Beta = 1
    plot lbeppf(p,5,1,c,d) for p = 0.01  0.01  0.99
    .
    end of multiplot
    .
    justification center
    move 50 97
    text Log Beta Percent Point Functions

-----LCTCDF (LET)--------------------------------
 
LCTCDF
 
Name:
    LCTCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the leads in coin tossing cumulative distribution
    function.
 
Description:
    The leads in coin tossing distribution has the following
    probability mass function:

       p(x;N) = (2*X)!(2*N-2*X)!*2**(-2*N)/(X!*X!*(N-X)!*(N-X)!)
                X = 0, 1, ..., N
 
   The cumulative distribution function is computed by summing
   the probability mass function.

Syntax:
    LET <y> = LCTCDF(<x>,<n>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter containing
              values between 0 and <n>;
          <n> is a number or parameter that defines the upper limit
              of the leads in coin tossing distribution;
          <y> is a variable or a parameter (depending on what <x>
              is) where the computed cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LCTCDF(3,20)
    LET Y = LCTCDF(X,100)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LCTCDF = Compute the leads in coin tossing cumulative
             distribution function.
    LCTPPF = Compute the leads in coin tossing percent point
             function.
    DISPDF = Compute the discrete uniform probability mass
             function.
    MATPDF = Compute the matching probability mass function.
    LOSPDF = Compute the lost games probability mass function.
    ARSPDF = Compute the arcsine probability density function.
    BETPDF = Compute the beta probability density function.
    UNIPDF = Compute the uniform probability mass function.
 
Reference:
    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 274-275.

    Feller (1957), "Introduction to Probability Theory",
    Third Edition, John Wiley and Sons, pp. 78-84.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    TITLE CASE ASIS
    TITLE Leads in Coin Tossing Cumulative Distribution ...
          Function CR() (N = 50)
    LABEL CASE ASIS
    Y1LABEL Probability
    X1LABEL X
    LINE BLANK
    SPIKE ON
    TIC OFFSET UNITS SCREEN
    TIC OFFSET 3 3
    PLOT LCTCDF(X,50) FOR X = 0 1 50
 
-----LCTPDF (LET)--------------------------------
 
LCTPDF
 
Name:
    LCTPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the leads in coin tossing probability mass function.
 
Description:
    The leads in coin tossing distribution has the following
    probability mass function:

       p(x;N) = (2*X)!(2*N-2*X)!*2**(-2*N)/(X!*X!*(N-X)!*(N-X)!)
                X = 0, 1, ..., N

    Given 2*n coin tosses, let 2*k denote the last coin toss for
    which the cumulative number of heads and tails were equal
    (0 <= k <= n).  The leads in coin tossing distribution is
    the distribution of k.  We use 2*n and 2*k since a tie can
    only occur on an even number toss.

    Feller (see References below) points out that the
    common belief that in a long coin-tossing game that each
    player will be on the winning side approximately half the
    time with frequent lead changes is in fact erroneous.
    Frequent lead changes implies that k should be close to n.
    However, for this distribution the probability that x = k
    is equal to the probability that x = n - k.  The implication
    of this is that with probability 1/2 no equalization will
    occur in the second half of the game regardless of the length
    of the game.

    The mean and variance of the leads in coin tossing
    distribution are:

       mean = n/2
       variance = n*(n+2)/12

    The leads in coin tossing distribution is also known as the
    discrete arcsine distribution.

Syntax:
    LET <y> = LCTPDF(<x>,<n>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter containing
              values between 0 and <n>;
          <n> is a number or parameter that defines the upper limit
              of the leads in coin tossing distribution;
          <y> is a variable or a parameter (depending on what <x>
              is) where the computed pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LCTPDF(3,20)
    LET Y = LCTPDF(X,100)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Note:
    For a number of commands utilizing the leads in coin
    tossing distribution, it is convenient to bin the data.
    There are two basic ways of binning the data.

      1) For some commands (histograms, maximum likelihood
         estimation), bins with equal size widths are
         required.  This can be accomplished with the
         following commands:

            LET AMIN = MINIMUM Y
            LET AMAX = MAXIMUM Y
            LET AMIN2 = AMIN - 0.5
            LET AMAX2 = AMAX + 0.5
            CLASS MINIMUM AMIN2
            CLASS MAXIMUM AMAX2
            CLASS WIDTH 1
            LET Y2 X2 = BINNED

      2) For some commands, unequal width bins may be
         helpful.  In particular, for the chi-square goodness
         of fit, it is typically recommended that the minimum
         class frequency be at least 5.  In this case, it may
         be helpful to combine small frequencies in the tails.
         Unequal class width bins can be created with the
         commands

            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = INTEGER FREQUENCY TABLE Y

         If you already have equal width bins data, you can
         use the commands
         
            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = COMBINE FREQUENCY TABLE Y2 X2

         The MINSIZE parameter defines the minimum class
         frequency.  The default value is 5.

Note:
    You can generate leads in coin tossing random numbers, 
    probability plots, and chi-square goodness of fit tests
    with the following commands:

       LET NSIZE = VALUE
       LET N = <value>
       LET Y = LEADS IN COIN TOSSING RANDOM NUMBERS FOR I = 1 1 N

       LEADS IN COIN TOSSING PROBABILITY PLOT Y
       LEADS IN COIN TOSSING PROBABILITY PLOT Y2 X2
       LEADS IN COIN TOSSING PROBABILITY PLOT Y3 XLOW XHIGH

       LEADS IN COIN TOSSING CHI-SQUARE GOODNESS OF FIT Y
       LEADS IN COIN TOSSING CHI-SQUARE GOODNESS OF FIT Y2 X2
       LEADS IN COIN TOSSING CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    Dataplot does not provide any explicit parameter estimation
    methods.  For this distribution, we simply subtract the
    minimum value (so the data starts at zero) and then use
    the maximum value as the estimate of N.  We can then apply
    goodness of fit tests (i.e., the probability plot or the
    chi-square goodness of fit) to see if the leads in coin tossing
    is an appropriate distribution.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LCTCDF = Compute the leads in coin tossing cumulative
             distribution function.
    LCTPPF = Compute the leads in coin tossing percent point
             function.
    DISPDF = Compute the discrete uniform probability mass
             function.
    MATPDF = Compute the matching probability mass function.
    LOSPDF = Compute the lost games probability mass function.
    ARSPDF = Compute the arcsine probability density function.
    BETPDF = Compute the beta probability density function.
    UNIPDF = Compute the uniform probability mass function.
 
Reference:
    Feller (1957), "Introduction to Probability Theory",
    Third Edition, John Wiley and Sons, pp. 78-84.

    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 274-275.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    TITLE CASE ASIS
    TITLE Leads in Coin Tossing Probability Mass Function CR() ...
          (N = 50)
    LABEL CASE ASIS
    Y1LABEL Probability Mass
    X1LABEL X
    LINE BLANK
    SPIKE ON
    TIC OFFSET UNITS SCREEN
    TIC OFFSET 3 3
    PLOT LCTPDF(X,50) FOR X = 0 1 50
 
-----LCTPPF (LET)--------------------------------
 
LCTPPF
 
Name:
    LCTPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the leads in coin tossing percent point function.
 
Description:
    The leads in coin tossing distribution has the following
    probability mass function:

       p(x;N) = (2*X)!(2*N-2*X)!*2**(-2*N)/(X!*X!*(N-X)!*(N-X)!)
                X = 0, 1, ..., N
 
    The cumulative distribution function is computed by summing
    the probability mass function.  The percent point function
    is the inverse of the cumulative distribution function and
    is obtained by computing the cumulative distribution function
    until the specified probability is reached.

Syntax:
    LET <y> = LCTPPF(<p>,<n>)  <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, a number, or a parameter in the
              interval (0,1);
          <n> is a number or parameter that defines the upper limit
              of the leads in coin tossing distribution;
          <y> is a variable or a parameter (depending on what <p>
              is) where the computed ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LCTPPF(0.95,20)
    LET Y = LCTPPF(P,100)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LCTCDF = Compute the leads in coin tossing cumulative
             distribution function.
    LCTPDF = Compute the leads in coin tossing probability mass
             function.
    DISPDF = Compute the discrete uniform probability mass
             function.
    MATPDF = Compute the matching probability mass function.
    LOSPDF = Compute the lost games probability mass function.
    ARSPDF = Compute the arcsine probability density function.
    BETPDF = Compute the beta probability density function.
    UNIPDF = Compute the uniform probability mass function.
 
Reference:
    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 274-275.

    Feller (1957), "Introduction to Probability Theory",
    Third Edition, John Wiley and Sons, pp. 78-84.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    TITLE CASE ASIS
    TITLE Leads in Coin Tossing Percent Point Function CR() ...
          (N = 50)
    LABEL CASE ASIS
    X1LABEL Probability
    Y1LABEL X
    TIC OFFSET UNITS SCREEN
    TIC OFFSET 3 3
    PLOT LCTPPF(P,50) FOR P = 0  0.01  1
 
-----LDECDF (LET)--------------------------------
 
LDECDF
 
Name:
    LDECDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard form of the log double exponential (also
    known as the log Laplace distribution) cumulative distribution
    function.
 
Description:
    The standard form of the log double exponential distribution has
    the following cumulative distribution function:
       F(x) = (1/2)*x**alpha            0 < x < 1
            = 1 - (1/2)*x**(-alpha)     x >= 1
    The input value can be any real number.
 
Syntax:
    LET <y> = LDECDF(<x>,<alpha>)   <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed log double exponential cdf value
              is saved;
          <alpha> is a variable, a number, or a parameter that
              specifies the shape parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LDECDF(3,2)
    LET A = LDECDF(A1,1.5)
    LET X2 = LDECDF(X1,0.5)
 
Note:
    The general form of the log double exponential distribution is:
       F(x) = (1/2)*((x-u)/beta)**alpha           mu < x < mu + beta
            = 1 - (1/2)*((x-u)/beta)**(-alpha)    x >= mu + beta
    The parameter u is a location parameter and the parameter beta is a
    scale parameter that must be greater than 0.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LDEPDF = Compute the double exponential probability density
             function.
    LDEPPF = Compute the double exponential percent point
             function.
    DEXPDF = Compute the double exponential cumulative distribution
             function.
    EXPPDF = Compute the exponential cumulative distribution function.
    WEIPDF = Compute the Weibull cumulative distribution function.
    EV1PDF = Compute the extreme value type I cumulative distribution
             function.
    CHSPDF = Compute the chi-square cumulative distribution function.
 
Reference:
    "Continuous Univariate Distributions: Volume 2", 2nd Ed.,
    Johnson, Kotz, and Balakrishnan, John Wiley, 1994, page 192.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2001/10
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    TITLE AUTOMATIC
    PLOT LDECDF(X,0.5)  FOR X = 0.01 0.01 5
    PLOT LDECDF(X,1)  FOR X = 0.01 0.01 5
    PLOT LDECDF(X,2)  FOR X = 0.01 0.01 5
    PLOT LDECDF(X,5)  FOR X = 0.01 0.01 5
    END OF MULTIPLOT
 
-----LDEPDF (LET)--------------------------------
 
LDEPDF
 
Name:
    LDEPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard form of the log double exponential (also
    known as the log Laplace distribution) probability density
    function.
 
Description:
    The standard form of the log double exponential distribution has
    the following probability density function:
       f(x) = (alpha/2)*x**(alpha-1)             0 < x < 1
            = (alpha/2)*x**(-alpha-1)            x >= 1
    The input value can be any real number.
 
Syntax:
    LET <y> = LDEPDF(<x>,<alpha>)   <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed log double exponential pdf value
              is saved;
          <alpha> is a variable, a number, or a parameter that
              specifies the shape parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LDEPDF(3,2)
    LET A = LDEPDF(A1,1.5)
    LET X2 = LDEPDF(X1,0.5)
 
Note:
    The general form of the log double exponential distribution is:
       f(x) = (alpha/(2*beta))*((x-u)/beta)**(alpha-1)   mu < x < mu + beta
            = (alpha/(2*beta))*((x-u)/beta)**(-alpha-1)  x >= mu + beta
    The parameter u is a location parameter and the parameter beta is a
    scale parameter that must be greater than 0.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LDECDF = Compute the double exponential cumulative distribution
             function.
    LDEPPF = Compute the double exponential percent point
             function.
    DEXPDF = Compute the double exponential probability density
             function.
    EXPPDF = Compute the exponential probability density function.
    WEIPDF = Compute the Weibull probability density function.
    EV1PDF = Compute the extreme value type I probability density
             function.
    CHSPDF = Compute the chi-square probability density function.
 
Reference:
    "Continuous Univariate Distributions: Volume 2", 2nd Ed.,
    Johnson, Kotz, and Balakrishnan, John Wiley, 1994, page 192.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2001/10
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    TITLE AUTOMATIC
    PLOT LDEPDF(X,0.5)  FOR X = 0.01 0.01 5
    PLOT LDEPDF(X,1)  FOR X = 0.01 0.01 5
    PLOT LDEPDF(X,2)  FOR X = 0.01 0.01 5
    PLOT LDEPDF(X,5)  FOR X = 0.01 0.01 5
    END OF MULTIPLOT
 
-----LDEPPF (LET)--------------------------------
 
LDEPPF
 
Name:
    LDEPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard form of the log double exponential (also
    known as the log Laplace distribution) percent point
    function.
 
Description:
    The standard form of the log double exponential distribution has
    the following percent point function:
       G(p) = (2*p)**(1/alpha)          0 <= p < LDECDF(1,alpha)
              (2*(1-p))**(-1/alpha)     LDECDF(1,alpha) <= p < 1
 
Syntax:
    LET <y> = LDEPPF(<p>,<alpha>)   <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, a number, or a parameter;
          <y> is a variable or a parameter (depending on what <p> is)
              where the computed log double exponential ppf value
              is saved;
          <alpha> is a variable, a number, or a parameter that
              specifies the shape parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LDEPPF(0.9,2)
    LET X2 = LDEPPF(P1,0.5)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LDECDF = Compute the double exponential cumulative distribution
             function.
    LDEPDF = Compute the double exponential probability density
             function.
    DEXPDF = Compute the double exponential cumulative distribution
             function.
    EXPPDF = Compute the exponential cumulative distribution function.
    WEIPDF = Compute the Weibull cumulative distribution function.
    EV1PDF = Compute the extreme value type I cumulative distribution
             function.
    CHSPDF = Compute the chi-square cumulative distribution function.
 
Reference:
    "Continuous Univariate Distributions: Volume 2", 2nd Ed.,
    Johnson, Kotz, and Balakrishnan, John Wiley, 1994, page 192.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2001/10
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    TITLE AUTOMATIC
    PLOT LDEPPF(P,0.5)  FOR P = 0.01 0.01 0.99
    PLOT LDEPPF(P,1)  FOR P = 0.01 0.01 0.99
    PLOT LDEPPF(P,2)  FOR P = 0.01 0.01 0.99
    PLOT LDEPPF(P,5)  FOR P = 0.01 0.01 0.99
    END OF MULTIPLOT
 
-----LE (LET)--------------------------------
 
LE
 
Name:
    LE (LET)
 
Type:
    Library Function
 
Purpose:
    Return a 1 if the first number is less than or equal to the second
    and return a 0 otherwise.

Description:
    SUBSET clauses do not support syntax like the following:

         LET Y = Y1  SUBSET Y1 > Y2
         LET Y = Y1  SUBSET Y1 >= Y2
         LET Y = Y1  SUBSET Y1 < Y2
         LET Y = Y1  SUBSET Y1 <= Y2
         LET Y = Y1  SUBSET Y1 = Y2
         LET Y = Y1  SUBSET Y1 <> Y2

    where Y1 and Y2 are both variables.

    This command is most typically used to create a tag variable
    that can be used on subsequent SUBSET clauses.  For example,
    suppose that Y1 and Y2 are two previously created variables and
    we want to sum the values of Y1 that are less than or equal to
    the corresponding rows of Y2.

        LET TAG = LE(Y1,Y2)
        LET Y1SUM = SUM Y1 SUBSET TAG = 1
 
Syntax:
    LET <tag> = LE(<y1>,<y2>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter;
          <tag> is a variable or a parameter (depending on what <y1> and
               <y2> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET TAG = LE(Y1,Y2)
    LET A = LE(3,2)

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LT       = Return 1 where the first number is less than the second
               number and 0 otherwise.
    GT       = Return 1 where the first number is greater than the second
               number and 0 otherwise.
    GE       = Return 1 where the first number is greater than or
               equal to the second number and zero otherwise.
    EQ       = Return 1 where the first number is equal to the second
               number and zero otherwise.
    NE       = Return 1 where the first number is not equal to the second
               number and zero otherwise.
 
Applications:
    Data Management
 
Implementation Date:
    2021/06
 
Program:
    SKIP 25
    READ NATR332.DAT Y1 Y2
    LET TAG = LE(Y1,Y2)
    LET NLE = SUM TAG SUBSET TAG = 1
    LET N = SIZE Y1
    LET NGT = N - NLE
    PRINT "Number of rows where Y1 <= Y2:   ^NLE"
    PRINT "Number of rows where Y1 >  Y2:   ^NGT"
 
-----LEGEND-------------------------------------------------------
 
LEGEND
 
Name:
    LEGEND ...
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the legends to appear on subsequent plots.
 
Description:
    The legends are the text which the analyst can position anywhere
    (via the LEGEND ... COORDINATES command) on a plot.  The legends
    appear on all subsequent plots until blanked out (via a LEGEND
    command with no arguments) or until overridden with new legends.
    100 such legends can be specified.
 
Syntax:
    LEGEND   <id>   <text>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
    and   <text> is the desired legend (all characters from the legend
              identifier to the end of the line).
 
Examples:
    LEGEND 1 SOLID  = LABORATORY 4
    LEGEND 2 DOTTED = LABORATORY 5
    LEGEND 1
    LEGEND
 
Note:
    A LEGEND ... command with no text blanks out the legend.  Thus
    LEGEND 1 with no text blanks out legend 1.  A LEGEND ... command
    with no <id> and no text (that is, LEGEND alone) blanks out all 100
    legends.  This is at times convenient if the analyst is finished
    with the analysis of one data set and wishes to start off with
    "clean" legends prior to the analysis of a completely different
    data set.
 
Note:
    The maximum number of characters for a single legend is 130.  The
    maximum number of characters for all legends is 1,000.
 
Default:
    All legends are blank.
 
Synonyms:
    None
 
Related Commands:
    PLOT                 = Generates a data or function plot.
    LEGEND ANGLE         = Sets the plot legend angles.
    LEGEND CASE          = Sets the plot legend cases.
    LEGEND COLOR         = Sets the plot legend colors.
    LEGEND COORDINATES   = Sets the plot legend locations.
    LEGEND DIRECTION     = Sets the plot legend directions.
    LEGEND FONT          = Sets the plot legend fonts.
    LEGEND HW            = Sets the plot legend heights and widths.
    LEGEND JUSTIFICATION = Sets the plot legend justifications.
    LEGEND SIZES         = Sets the plot legend sizes.
    LEGEND THICKNESS     = Sets the plot legend line thicknesses.
    TEXT                 = Writes a text string.
    TITLE                = Sets the plot title.
    LABEL                = Sets the plot labels.
    BOX COORDINATES      = Sets the locations for plot boxes.
    ARROW COORDINATES    = Sets the locations for plot arrows.
    SEGMENT COORDINATES  = Sets the locations for plot segments.
    FRAME                = Sets the on/off switch for plot frame.
    CHARACTERS           = Sets the types for plot characters.
    LINES                = Sets the types for plot lines.
    SPIKES               = Sets the on/off switches for plot spikes.
    BARS                 = Sets the on/off switches for plot bars.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER X1 X2 Y1 Y2
    LINE BLANK ALL
    LEGEND 1 X - POTASSIUM
    LEGEND 2 Y - LEAD
    .
    TITLE DEMONSTRATE LEGEND COMMAND
    LET X = SEQUENCE 1 1 17
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
 
-----LEGEND ANGLE-----------------------------------------------------
 
LEGEND ANGLE
 
Name:
    LEGEND ... ANGLE
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the angle of the legends to appear on subsequent plots.
 
Description:
    The legends are the text which the analyst can position anywhere
    (via the LEGEND ... COORDINATES command) on a plot.  The legends
    appear on all subsequent plots until blanked out (via a LEGEND
    command with no arguments) or until overridden with new legends.
    100 such legends can be specified.
 
    The legend angles hold for all subsequent plots until defaulted
    (via the LEGEND ... ANGLE command with no arguments) or until
    overridden with new legend angles.
 
Syntax:
    LEGEND   <id>   ANGLE   <angle>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
    and   <angle> is a decimal number or parameter that specifies the
              desired legend angle.
 
Examples:
    LEGEND 1 ANGLE 90.
    LEGEND 2 ANGLE 45.
    LEGEND 1 ANGLE
    LEGEND ANGLE
 
Note:
    A LEGEND ... ANGLE command with no angle reverts the angle to
    default.  Thus LEGEND 1 ANGLE with no angle reverts the angle of
    legend 1 to default.  A LEGEND ... ANGLE command with no <id> refers
    to all 100 labels.  Thus LEGEND ANGLE 90. assigns the angle 90. to
    all 100 labels.  LABEL ANGLE with no <id> and no angle reverts all
    100 labels to the default angle.
 
Note:
    This command only applies if the legend is drawn with a software
    font (e.g., SIMPLEX).  The LEGEND DIRECTION command can be used to
    set either horizontal or vertical text strings when the legend is
    drawn with hardware characters.
 
Default:
    All legend angles are 0. (i.e., horizontal).
 
Synonyms:
    None
 
Related Commands:
    PLOT                 = Generates a data or function plot.
    LEGEND               = Specify the legends for subsequent plots.
    LEGEND CASE          = Sets the plot legend cases.
    LEGEND COLOR         = Sets the plot legend colors.
    LEGEND COORDINATES   = Sets the plot legend locations.
    LEGEND DIRECTION     = Sets the plot legend directions.
    LEGEND FONT          = Sets the plot legend fonts.
    LEGEND HW            = Sets the plot legend heights and widths.
    LEGEND JUSTIFICATION = Sets the plot legend justifications.
    LEGEND SIZES         = Sets the plot legend sizes.
    LEGEND THICKNESS     = Sets the plot legend line thicknesses.
 
Applications:
    XX
 
Implementation Date:
    89/2
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER X1 X2 Y1 Y2
    LINE BLANK ALL
    ANGLE UNITS DEGREES
    LEGEND FONT DUPLEX
    LEGEND 1 Y - LEAD
    LEGEND 2 X - POTASSIUM
    LEGEND 1 ANGLE 45
    LEGEND 2 ANGLE -45
    .
    TITLE DEMONSTRATE LEGEND ANGLE COMMAND
    LET X = SEQUENCE 1 1 17
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
 
-----LEGEND CASE-------------------------------------------------------
 
LEGEND CASE
 
Name:
    LEGEND ... CASE
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the case of the legends (i.e., upper or lower) to appear
    on subsequent plots.
 
Description:
    The legends are the text which the analyst can position anywhere
    (via the LEGEND ... COORDINATES command) on a plot.  The legends
    appear on all subsequent plots until blanked out (via a LEGEND
    command with no arguments) or until overridden with new legends.
    100 such legends can be specified.
 
    The legend cases hold for all subsequent plots until defaulted (via
    the LEGEND ... CASE command with no arguments) or until overridden
    with new legend cases.
 
Syntax:
    LEGEND   <id>   CASE   <case>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
    and   <case> is either UPPER (for upper case) or LOWER (for lower
              case).
 
Examples:
    LEGEND 1 CASE UPPER
    LEGEND 2 CASE LOWER
    LEGEND 1 CASE
    LEGEND CASE
 
Note:
    A LEGEND ... CASE command with no case reverts the case to default.
    Thus LEGEND 1 CASE with no case reverts the case of legend 1 to
    default.  A LEGEND ... CASE command with no <id> refers to all 100
    legends.  Thus LEGEND CASE LOWER assigns the case LOWER to all 100
    legends.  LABEL CASE with no <id> and no case reverts all 100
    legends to the default case.
 
Default:
    All legend cases are upper.
 
Synonyms:
    None
 
Related Commands:
    PLOT                 = Generates a data or function plot.
    LEGEND               = Specify the legends for subsequent plots.
    LEGEND ANGLE         = Sets the plot legend angles.
    LEGEND COLOR         = Sets the plot legend colors.
    LEGEND COORDINATES   = Sets the plot legend locations.
    LEGEND DIRECTION     = Sets the plot legend directions.
    LEGEND FONT          = Sets the plot legend fonts.
    LEGEND HW            = Sets the plot legend heights and widths.
    LEGEND JUSTIFICATION = Sets the plot legend justifications.
    LEGEND SIZES         = Sets the plot legend sizes.
    LEGEND THICKNESS     = Sets the plot legend line thicknesses.
 
Applications:
    XX
 
Implementation Date:
    89/2
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER X1 X2 Y1 Y2
    LINE BLANK ALL
    LEGEND 1 X - POTASSIUM
    LEGEND 2 Y - LEAD
    LEGEND 1 CASE UPPER
    LEGEND 2 CASE LOWER
    .
    TITLE DEMONSTRATE LEGEND CASE COMMAND
    LET X = SEQUENCE 1 1 17
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
 
-----LEGEND COLOR-----------------------------------------------------
 
LEGEND COLOR
 
Name:
    LEGEND ... COLOR
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the color of the legends to appear on subsequent plots.
 
Description:
    The legends are the text which the analyst can position anywhere
    (via the LEGEND ... COORDINATES command) on a plot.  The legends
    appear on all subsequent plots until blanked out (via a LEGEND
    command with no arguments) or until overridden with new legends.
    100 such legends can be specified.
 
    The legend colors hold for all subsequent plots until defaulted
    (via the LEGEND ... COLOR command with no arguments) or until
    overridden with new legend colors.
 
    Dataplot provides two methods for specifying colors.

        1. Colors can be defined by name (or by the corresponding index).
           Dataplot adopted it's named colors from the X11 project.
           Currently, 162 named colors and 100 levels of grayscale are
           supported.  Grayscale can be specified with either G0, G1, ...,
           G100 (or -1, -2, ..., -100).  Many older devices support only a
           limited number of colors.  For these devices, unsupported colors
           will be mapped to one of the available colors.  To specify a
           named color, see Syntax 1.

        2. Most modern graphics devices support full RGB (RedBlueGreen)
           color.  You can alternatively specify RGB colors by entering
           three integer values to represent the Red, Green and Blue
           components, respectively.  These values should be in the range
           0 to 255.

    When setting the legend RGB color, Dataplot first checks if the device
    supports RGB colors. If not, the named color will be used.  If the
    device does support RGB color, Dataplot will check if an RGB color
    has been specified.  If yes, then that RGB color is used.  If not,
    the named color will be used.

    To see the list of supported named colors (with the associated index
    number), see

    https://www.itl.nist.gov/div898/software/dataplot/refman1/ch11/homepage.htm

Syntax 1:
    LEGEND  <id>  COLOR  <color>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
    and   <color> is the desired legend color.
 
Syntax 2:
    LEGEND  <id>  RGB COLORS <red> <green> <blue>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
          <red> is a number or parameter that specifies the red
              component;
          <green> is a number or parameter that specifies the green
              component;
          <blue> is a number or parameter that specifies the blue
              component.

    To turn off the RGB color, set the values to -1 (any negative value
    will work).  Values greater than 255 will be set to 255.
 
Examples:
    LEGEND 1 COLOR YELLOW
    LEGEND 2 COLOR BLACK
    LEGEND 1 COLOR
    LEGEND COLOR
    LEGEND 1 RGB COLOR 220 109 88
    LEGEND 2 RGB COLOR 175 238 238
 
Note:
    A LEGEND ... COLOR command with no color reverts the color to
    default.  Thus LEGEND 1 COLOR with no color reverts the color of
    legend 1 to default.  A LEGEND ... COLOR command with no <id> refers
    to all 100 legends.  Thus LEGEND COLOR BLUE assigns the color BLUE
    to all 100 legends.  LABEL COLOR with no <id> and no color reverts
    all 100 legends to the default color.
 
Default:
    All legend colors are black.
 
Synonyms:
    None
 
Related Commands:
    PLOT                 = Generates a data or function plot.
    LEGEND               = Specify the legends for subsequent plots.
    LEGEND ANGLE         = Sets the plot legend angles.
    LEGEND CASE          = Sets the plot legend cases.
    LEGEND COORDINATES   = Sets the plot legend locations.
    LEGEND DIRECTION     = Sets the plot legend directions.
    LEGEND FONT          = Sets the plot legend fonts.
    LEGEND HW            = Sets the plot legend heights and widths.
    LEGEND JUSTIFICATION = Sets the plot legend justifications.
    LEGEND SIZES         = Sets the plot legend sizes.
    LEGEND THICKNESS     = Sets the plot legend line thicknesses.
    TITLE COLOR          = Sets the color for the plot title.
    LABEL COLOR          = Sets the color for plot labels.
    BOX COLOR            = Sets the color for plot boxes.
    ARROW COLOR          = Sets the color for plot arrows.
    SEGMENT COLOR        = Sets the color for plot segments.
    FRAME COLOR          = Sets the color for plot frame.
    GRID COLOR           = Sets the color for plot grids.
    TIC COLOR            = Sets the color for plot tics.
    TIC LABEL COLOR      = Sets the color for plot tic labels.
    MARGIN COLOR         = Sets the color for plot margin.
    BACKGROUND COLOR     = Sets the color for plot background.
    CHARACTERS COLORS    = Sets the colors for plot characters.
    LINE COLORS          = Sets the colors for plot lines.
    SPIKE COLORS         = Sets the colors for plot spikes.
    BAR FILL COLORS      = Sets the colors for plot bar fills.
    BAR PATTERN COLORS   = Sets the colors for plot bar patterns.
    BAR BORDER COLORS    = Sets the colors for plot bar borders.
    COLOR                = Sets the color of TEXT characters.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
    2020/10: Support for RGB colors
 
Program 1:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER X1 X2 Y1 Y2
    CHARACTER COLOR RED RED BLUE BLUE
    LINE BLANK ALL
    LEGEND 1 X - POTASSIUM
    LEGEND 2 Y - LEAD
    LEGEND 1 COLOR RED
    LEGEND 2 COLOR BLUE
    .
    TITLE DEMONSTRATE LEGEND COLOR COMMAND
    LET X = SEQUENCE 1 1 17
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
 
Program 2:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER X1 X2 Y1 Y2
    CHARACTER COLOR RED RED BLUE BLUE
    LINE BLANK ALL
    LEGEND 1 X - POTASSIUM
    LEGEND 2 Y - LEAD
    LEGEND 1 COLOR RED
    LEGEND 2 COLOR BLUE
    LEGEND 1 RGB COLOR 220 109 88
    LEGEND 2 RGB COLOR 175 238 238
    .
    TITLE DEMONSTRATE LEGEND RGB COLOR COMMAND
    LET X = SEQUENCE 1 1 17
    PLOT POT X ID2 AND
    PLOT LEAD X ID2

-----LEGEND COORDINATES-----------------------------------------------
 
LEGEND COORDINATES
 
Name:
    LEGEND ... COORDINATES
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the coordinates of legends to appear on subsequent plots.
 
Description:
    The legends are the text which the analyst can position anywhere
    (via the LEGEND ... COORDINATES command) on a plot.  The legends
    appear on all subsequent plots until blanked out (via a LEGEND
    command with no arguments) or until overridden with new legends.
    100 such legends can be specified.
 
    The (x,y) coordinate is that of the bottom left point of the first
    character of the legend text string.  The coordinates range from 0
    to 100, where (0,0) is the lower left corner of the screen and
    (100,100) is the upper right corner of the screen.  The legend
    coordinates hold for all subsequent plots until overridden with new
    legend coordinates.
 
Syntax:
    LEGEND   <id>   COORDINATES   <x>   <y>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
          <x> is a decimal number or parameter in the decimal range 0 to
              100 that specifies the horizontal coordinate;
    and   <y> is a decimal number or parameter in the decimal range 0 to
              100 that specifies the vertical coordinate.
 
Examples:
    LEGEND 3 COORDINATES 25 80
    LEGEND 4 COORDINATES 25 76
    LEGEND 5 COORDINATES 25 72
    LEGEND 6 COORDINATES 75 80
    LEGEND 1 COORDINATES 40 80
    LEGEND 15 COORDINATES 95 95
 
Note:
    A LEGEND ... COORDINATES command with no arguments reverts the
    coordinates to default.  Thus LEGEND 1 COORDINATES with no arguments
    reverts the coordinates of legend 1 to (20,84).  A LEGEND ...
    COORDINATES command with no <id> refers to all 100 legends.  Thus
    LEGEND COORDINATES 30 50 assigns the coordinates (30,50) to all 100
    legends (but this has no practical use).  LEGEND COORDINATES with no
    <id> and no arguments reverts all 100 legends to their default
    coordinates.
 
Default:
    For legend 1--x = 20, y = 84.
    For legend 2--x = 20, y = 80.
    For legend 3--x = 20, y = 76.
    For legend 4--x = 20, y = 72.
    etc.
 
Synonyms:
    None
 
Related Commands:
    PLOT                 = Generates a data or function plot.
    LEGEND               = Specify the legends for subsequent plots.
    LEGEND ANGLE         = Sets the plot legend angles.
    LEGEND CASE          = Sets the plot legend cases.
    LEGEND COLOR         = Sets the plot legend colors.
    LEGEND COORDINATES   = Sets the plot legend locations.
    LEGEND DIRECTION     = Sets the plot legend directions.
    LEGEND FONT          = Sets the plot legend fonts.
    LEGEND HW            = Sets the plot legend heights and widths.
    LEGEND JUSTIFICATION = Sets the plot legend justifications.
    LEGEND SIZES         = Sets the plot legend sizes.
    LEGEND THICKNESS     = Sets the plot legend line thicknesses.
    BOX COORDINATES      = Sets location of plot boxes.
    ARROW COORDINATES    = Sets location of plot arrows.
    SEGMENT COORDINATES  = Sets location of plot line seg.
    FRAME COORDINATES    = Sets location of plot frame.
    WINDOW COORDINATES   = Sets location of plot window.
    CURSOR COORDINATES   = Sets location of post-plot cursor.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER X1 X2 Y1 Y2
    LINE BLANK ALL
    LEGEND 1 X - POTASSIUM
    LEGEND 2 Y - LEAD
    LEGEND 1 COORDINATES 70 85
    LEGEND 2 COORDINATES 70 80
    .
    TITLE DEMONSTRATE LEGEND COORDINATES
    LET X = SEQUENCE 1 1 17
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
 
-----LEGEND DIRECTION-------------------------------------------------
 
LEGEND DIRECTION
 
Name:
    LEGEND ... DIRECTION
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the direction of the legends to appear on subsequent
    plots (i.e., horizontal or vertical).
 
Description:
    The legends are the text which the analyst can position anywhere
    (via the LEGEND ... COORDINATES command) on a plot.  The legends
    appear on all subsequent plots until blanked out (via a LEGEND
    command with no arguments) or until overridden with new legends.
    100 such legends can be specified.
 
    The legend directions hold for all subsequent plots until
    defaulted (via the LEGEND ...  DIRECTION command with no arguments)
    or until overridden with new legend directions.
 
Syntax:
    LEGEND   <id>   DIRECTION   <direction>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
    and   <direction> is either HORIZONTAL (for horizontal legends) or
              VERTICAL (for vertical legends).
 
Examples:
    LEGEND 1 DIRECTION VERTICAL
    LEGEND 2 DIRECTION HORIZONTAL
    LEGEND 1 DIRECTION
    LEGEND DIRECTION
 
Note:
    A LEGEND ... DIRECTION command with no direction reverts the
    direction to default. Thus LEGEND 1 DIRECTION with no direction
    reverts the direction of legend 1 to default.  A LEGEND ...
    DIRECTION command with no <id> refers to all 100 legends.  Thus
    LEGEND DIRECTION VERTICAL assigns the direction VERTICAL to all 100
    legends.  LABEL DIRECTION with no <id> and no direction reverts all
    100 legends to the default direction.
 
Note:
    This command only applies if the legend is drawn with hardware
    characters.  The LEGEND ANGLE command can be used to set an
    arbitrary direction for text strings when the legend is drawn with
    a software font (e.g., SIMPLEX).
 
Default:
    All legend directions are horizontal.
 
Synonyms:
    None
 
Related Commands:
    PLOT                 = Generates a data or function plot.
    LEGEND               = Specify the legends for subsequent plots.
    LEGEND ANGLE         = Sets the plot legend angles.
    LEGEND CASE          = Sets the plot legend cases.
    LEGEND COLOR         = Sets the plot legend colors.
    LEGEND COORDINATES   = Sets the plot legend locations.
    LEGEND FONT          = Sets the plot legend fonts.
    LEGEND HW            = Sets the plot legend heights and widths.
    LEGEND JUSTIFICATION = Sets the plot legend justifications.
    LEGEND SIZES         = Sets the plot legend sizes.
    LEGEND THICKNESS     = Sets the plot legend line thicknesses.
 
Applications:
    XX
 
Implementation Date:
    89/2
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER X1 X2 Y1 Y2
    LINE BLANK ALL
    LEGEND 1 X - POTASSIUM
    LEGEND 2 Y - LEAD
    LEGEND 1 DIRECTION HORIZONTAL
    LEGEND 2 DIRECTION VERTICAL
    LEGEND 2 JUSTIFICATION CETO
    .
    TITLE DEMONSTRATE LEGEND DIRECTION COMMAND
    LET X = SEQUENCE 1 1 17
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
 
-----LEGEND FILL-------------------------------------------------------
 
LEGEND FILL
 
Name:
    LEGEND ... FILL
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the fill of the legends to appear on subsequent plots.
 
Description:
    The legends are the text which the analyst can position anywhere
    (via the LEGEND ... COORDINATES command) on a plot.  The legends
    appear on all subsequent plots until blanked out (via a LEGEND
    command with no arguments) or until overridden with new legends.
    100 such legends can be specified.
 
    Legends can contain the Greek characters, mathematics symbols,
    and other special symbols available to the TEXT command (these
    are identified by a trailing () symbol).  Specifically, it can
    contain the special plotting symbols available to the CHARACTER
    command (enter HELP CHARACTER TYPES for a list of these symbols).
    The following special plot symbols can also be filled with a
    solid pattern:
        CIRC()
        SQUA()
        TRIA()
        REVT()
        PYRA()
        DIAM()
    Entering one of the following strings in the text for the LEGEND
    command will cause the symbol to plotted in the legend.  The LEGEND
    FILL command can be used to specify that this symbol should be
    solid filled as well.  This capability is typically used to
    identify a trace drawn with one of the special plotting symbols.
    The legend fill only applies to the above special plot symbols and
    has no effect if one of these symbols is not contained in the
    legend text.
 
    The legend fills hold for all subsequent plots until defaulted (via
    the LEGEND ... FILL command with no arguments) or until overridden
    with new legend fills.
 
Syntax:
    LEGEND   <id>   FILL   <fill>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
    and   <fill> should be SOLID to generate a solid filled symbol and
              it should be OFF to generate the symbol with no fill.
 
Examples:
    LEGEND 1 FILL SIMPLEX
    LEGEND 2 FILL DUPLEX
    LEGEND 1 FILL
    LEGEND FILL
 
Note:
    The LEGEND FILL command only applies if the legend is drawn with
    a software font (enter HELP FONT for details).  It is ignored if
    the legend is drawn with a hardware font.
 
Note:
    Only solid fills are supported at this time.
 
Note:
    When specifying the special symbol to the CHARACTER command, the
    trailing () is omitted.  However, the trailing () is required when
    entering it into the LEGEND command.
 
Note:
    A LEGEND ... FILL command with no fill reverts the fill to default.
    Thus LEGEND 1 FILL with no fill reverts the fill of legend 1 to
    default.  A LEGEND ... FILL command with no <id> refers to all 100
    legends.  Thus LEGEND FILL SOLID assigns the fill SOLID to all 100
    legends.  LABEL FILL with no <id> and no fill reverts all 100
    legends to the default fill.
 
Note:
    The FILL command performs a function similar to the LEGEND FILL
    command for the TEXT command.
 
Default:
    All legend fills are off.
 
Synonyms:
    None
 
Related Commands:
    PLOT                 = Generates a data or function plot.
    LEGEND               = Specify the legends for subsequent plots.
    LEGEND ANGLE         = Sets the plot legend angles.
    LEGEND CASE          = Sets the plot legend cases.
    LEGEND COLOR         = Sets the plot legend colors.
    LEGEND COORDINATES   = Sets the plot legend locations.
    LEGEND DIRECTION     = Sets the plot legend directions.
    LEGEND FONT          = Sets the plot legend fonts.
    LEGEND HW            = Sets the plot legend heights and widths.
    LEGEND JUSTIFICATION = Sets the plot legend justifications.
    LEGEND SIZES         = Sets the plot legend sizes.
    LEGEND THICKNESS     = Sets the plot legend line thicknesses.
    FILL                 = Sets the fill for all text elements.
 
Applications:
    XX
 
Implementation Date:
    89/2
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER CIRCLE SQUARE
    CHARACTER FILL ON ALL
    LINE BLANK ALL
    LEGEND 1 CIRC() - POTASSIUM
    LEGEND 2 SQUA() - LEAD
    LEGEND FONT DUPLEX
    LEGEND FILL SOLID
    .
    TITLE DEMONSTRATE LEGEND FILL COMMAND
    LET X = SEQUENCE 1 1 17
    PLOT POT X AND
    PLOT LEAD X
 
-----LEGEND FONT-------------------------------------------------------
 
LEGEND FONT
 
Name:
    LEGEND ... FONT
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the font of the legends to appear on subsequent plots.
 
Description:
    The legends are the text which the analyst can position anywhere
    (via the LEGEND ... COORDINATES command) on a plot.  The legends
    appear on all subsequent plots until blanked out (via a LEGEND
    command with no arguments) or until overridden with new legends.
    100 such legends can be specified.
 
    The legend fonts hold for all subsequent plots until defaulted (via
    the LEGEND ... FONT command with no arguments) or until overridden
    with new legend fonts.
 
Syntax:
    LEGEND   <id>   FONT   <font>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
    and   <font> is the desired legend font (TEKTRONIX, SIMPLEX,
              DUPLEX, TRIPLEX, COMPLEX, ITALIC, COMPLEX SCRIPT,
              TRIPLEX ITALIC, SIMPLEX SCRIPT).
 
Examples:
    LEGEND 1 FONT SIMPLEX
    LEGEND 2 FONT DUPLEX
    LEGEND 1 FONT
    LEGEND FONT
 
Note:
    A LEGEND ... FONT command with no font reverts the font to default.
    Thus LEGEND 1 FONT with no font reverts the font of legend 1 to
    default.  A LEGEND ... FONT command with no <id> refers to all 100
    legends.  Thus LEGEND FONT SIMPLEX assigns the font SIMPLEX to all
    100 legends.  LABEL FONT with no <id> and no font reverts all 100
    legends to the default font.
 
Note:
    The FONT command sets the default font for a plot.  The LEGEND FONT
    command is used to override the default font for the legends only.
 
Default:
    All legend fonts are TEKTRONIX (i.e., hardware characters).
 
Synonyms:
    None
 
Related Commands:
    PLOT                 = Generates a data or function plot.
    LEGEND               = Specify the legends for subsequent plots.
    LEGEND ANGLE         = Sets the plot legend angles.
    LEGEND CASE          = Sets the plot legend cases.
    LEGEND COLOR         = Sets the plot legend colors.
    LEGEND COORDINATES   = Sets the plot legend locations.
    LEGEND DIRECTION     = Sets the plot legend directions.
    LEGEND HW            = Sets the plot legend heights and widths.
    LEGEND JUSTIFICATION = Sets the plot legend justifications.
    LEGEND SIZES         = Sets the plot legend sizes.
    LEGEND THICKNESS     = Sets the plot legend line thicknesses.
    FONT                 = Sets the font for all text elements.
 
Applications:
    XX
 
Implementation Date:
    89/2
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER X1 X2 Y1 Y2
    LINE BLANK ALL
    LEGEND 1 X - POTASSIUM
    LEGEND 2 Y - LEAD
    LEGEND 1 FONT DUPLEX
    LEGEND 2 FONT COMPLEX SCRIPT
    .
    TITLE DEMONSTRATE LEGEND FONT COMMAND
    LET X = SEQUENCE 1 1 17
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
 
-----LEGEND HW-------------------------------------------------------
 
LEGEND HW
 
Name:
    LEGEND ... HW
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the height and width of characters in legends to appear
    on subsequent plots.
 
Description:
    The legends are the text which the analyst can position anywhere
    (via the LEGEND ... COORDINATES command) on a plot.  The legends
    appear on all subsequent plots until blanked out (via a LEGEND
    command with no arguments) or until overridden with new legends.
    100 such legends can be specified.
 
    The hw is the height of the character from the visible bottom of
    the character to the visible top of the character and the width of
    the character from the visible left of the character to the visible
    right of the character.  The horizontal and vertical spacing
    between characters is not counted.  The size is in decimal units of
    0 to 100.  A height of 0 would be negligibly small while a height
    of 100 would be full screen vertical distance.  The legend hw's
    hold for all subsequent plots until defaulted (via the ...LABEL HW
    command with no arguments) or until overridden with new label
    height and widths.
 
    This command is most typically used in conjunction with the
    MULTIPLOT command when an unequal number of rows and columns causes
    a distortion in the appearance of characters.
 
Syntax:
    LEGEND  <id>  HW  <h> <w>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
          <h> is a decimal number or parameter in the range 0 to 100
              that specifies the desired character height;
    and   <w> is a decimal number or parameter in the range 0 to 100
              that specifies the desired character width.
 
Examples:
    LEGEND 1 HW 3 2
    LEGEND 2 HW 1. 0.75 2 1.5
    LEGEND 1 HW
    LEGEND HW
 
Note:
    A LEGEND ... HW command with no arguments reverts the hw to
    default.  Thus LEGEND 1 HW with no arguments reverts the first
    legend to the default hw.  A LEGEND ... HW command with no <id>
    refers to all 100 legends.  Thus LEGEND HW 2 1 assigns the height 2
    and width 1 to all 100 legends.  LEGEND HW with no <id> and no
    arguments reverts all 100 legends to the default hw.
 
Default:
    All legend heights are 2.0 and all legend widths are 1.0.
 
Synonyms:
    None
 
Related Commands:
    PLOT                 = Generates a data or function plot.
    LEGEND               = Specify the legends for subsequent plots.
    LEGEND ANGLE         = Sets the plot legend angles.
    LEGEND CASE          = Sets the plot legend cases.
    LEGEND COLOR         = Sets the plot legend colors.
    LEGEND COORDINATES   = Sets the plot legend locations.
    LEGEND DIRECTION     = Sets the plot legend directions.
    LEGEND FONT          = Sets the plot legend fonts.
    LEGEND JUSTIFICATION = Sets the plot legend justifications.
    LEGEND SIZES         = Sets the plot legend sizes.
    LEGEND THICKNESS     = Sets the plot legend line thicknesses.
    TITLE SIZE           = Sets the size for the plot title.
    LABEL SIZE           = Sets the size for plot labels.
    TIC SIZE             = Sets the size of plot tics.
    TIC LABEL SIZE       = Sets the size for plot tic labels.
    CHARACTER SIZES      = Sets the sizes for plot characters.
    HEIGHT               = Sets the height for TEXT characters.
    WIDTH                = Sets the width for TEXT characters.
    HW                   = Sets the height and width for TEXT
                           characters.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER X1 X2 Y1 Y2
    LINE BLANK ALL
    LEGEND FONT DUPLEX
    LEGEND 1 X - POTASSIUM
    LEGEND 2 Y - LEAD
    LEGEND 1 HW 2.0 0.6
    LEGEND 2 HW 2.0 1.6
    .
    TITLE DEMONSTRATE LEGEND HW COMMAND
    LET X = SEQUENCE 1 1 17
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
 
-----LEGEND JUSTIFICATION---------------------------------------------
 
LEGEND JUSTIFICATION
 
Name:
    LEGEND ... JUSTIFICATION
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the justification of the legends to appear on subsequent
    plots (i.e., left, right, center horizontally and top, center
    bottom vertically).
 
Description:
    The legends are the text which the analyst can position anywhere
    (via the LEGEND ... COORDINATES command) on a plot.  The legends
    appear on all subsequent plots until blanked out (via a LEGEND
    command with no arguments) or until overridden with new legends.
    100 such legends can be specified.
 
    The legend justifications hold for all subsequent plots until
    defaulted (via the LEGEND ...  JUSTIFICATION command with no
    arguments) or until overridden with new legend justifications.
 
Syntax:
    LEGEND   <id>   JUSTIFICATION   <just>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
    and   <just> is the desired legend justification (see the NOTE
              below for a list of available choices).
 
Examples:
    LEGEND 1 JUSTIFICATION LEFT
    LEGEND 2 JUSTIFICATION RIGHT
    LEGEND 1 JUSTIFICATION
    LEGEND JUSTIFICATION
 
Note:
    A LEGEND ... JUSTIFICATION command with no justification reverts
    the justification to default.  Thus LEGEND 1 JUSTIFICATION with no
    justification reverts the justification of legend 1 to default.  A
    LEGEND ...  JUSTIFICATION command with no <id> refers to all 100
    legends.  Thus LEGEND JUSTIFICATION LEFT assigns the justification
    LEFT to all 100 legends.  LABEL JUSTIFICATION with no <id> and no
    justification reverts all 100 legends to the default justification.
 
Note:
    The following justifications can be specified:
      LEFT   - left horizontally, bottom vertically
      CENTER - center horizontally, bottom vertically
      RIGHT  - right horizontally, bottom vertically
      LECE   - left horizontally, center vertically
      CECE   - center horizontally, center vertically
      RICE   - right horizontally, center vertically
      LETO   - left horizontally, top vertically
      CETO   - center horizontally, top vertically
      RITO   - right horizontally, top vertically
 
Default:
    All legend justifications are LEFT (i.e, left justified
    horizontally and bottom justified vertically).
 
Synonyms:
    None
 
Related Commands:
    PLOT                     = Generates a data or function plot.
    LEGEND                   = Specify the legends for subsequent
                               plots.
    LEGEND ANGLE             = Sets the plot legend angles.
    LEGEND CASE              = Sets the plot legend cases.
    LEGEND COLOR             = Sets the plot legend colors.
    LEGEND COORDINATES       = Sets the plot legend locations.
    LEGEND DIRECTION         = Sets the plot legend directions.
    LEGEND FONT              = Sets the plot legend fonts.
    LEGEND HW                = Sets the plot legend heights and widths.
    LEGEND SIZES             = Sets the plot legend sizes.
    LEGEND THICKNESS         = Sets the plot legend line thicknesses.
    JUSTIFICATION            = Sets the justification for text
                               characters.
    CHARACTER JUSTIFICATION  = Sets the justification for plot
                               characters.
    TITLE JUSTIFICATION      = Sets the justification for the plot
                               title.
 
Applications:
    XX
 
Implementation Date:
    89/2
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER X1 X2 Y1 Y2
    LINE BLANK ALL
    LEGEND 1 X - POTASSIUM
    LEGEND 2 Y - LEAD
    LEGEND 1 COORDINATES 50 85
    LEGEND 2 COORDINATES 50 80
    LEGEND 1 JUSTIFICATION RIGHT
    LEGEND 2 JUSTIFICATION LEFT
    .
    TITLE DEMONSTRATE LEGEND JUSTIFICATION
    LET X = SEQUENCE 1 1 17
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
 
-----LEGEND SIZE-------------------------------------------------------
 
LEGEND SIZE
 
Name:
    LEGEND ... SIZE
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the size (height) of characters in legends to appear on
    subsequent plots.
 
Description:
    The legends are the text which the analyst can position anywhere
    (via the LEGEND ... COORDINATES command) on a plot.  The legends
    appear on all subsequent plots until blanked out (via a LEGEND
    command with no arguments) or until overridden with new legends.
    100 such legends can be specified.
 
    The size is the height of the character from the visible bottom of
    the character to the visible top of the character.  The vertical
    spacing between characters is not counted.  The height is in
    decimal units of 0 to 100.  A height of 0 would be negligibly small
    while a height of 100 would be full screen vertical distance.  The
    width of the character is automatically set to one half the
    character height.  The label sizes hold for all subsequent plots
    until defaulted (via the ...LABEL SIZE command with no arguments)
    or until overridden with new label sizes.
 
Syntax:
    LEGEND   <id>   SIZE   <size>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
    and   <size> is a decimal number or parameter in the range 0 to 100
              that specifies the desired legend size.
 
Examples:
    LEGEND 1 SIZE 3
    LEGEND 2 SIZE 5
    LEGEND 3 SIZE 1.25
    LEGEND 1 SIZE A
    LEGEND 5 SIZE H
    LEGEND 1 SIZE
    LEGEND SIZE
 
Note:
    A LEGEND ... SIZE command with no arguments reverts the size to
    default.  Thus LEGEND 1 SIZE with no arguments reverts the first
    legend to default size.  A LEGEND ... SIZE command with no <id>
    refers to all 100 legends.  Thus LEGEND SIZE 2 assigns the size 2
    to all 100 legends.  LEGEND SIZE with no <id> and no arguments
    reverts all 100 legends to default size.
 
Default:
    All legend sizes are 2.0.
 
Synonyms:
    None
 
Related Commands:
    PLOT                 = Generates a data or function plot.
    LEGEND               = Specify the legends for subsequent plots.
    LEGEND ANGLE         = Sets the plot legend angles.
    LEGEND CASE          = Sets the plot legend cases.
    LEGEND COLOR         = Sets the plot legend colors.
    LEGEND COORDINATES   = Sets the plot legend locations.
    LEGEND DIRECTION     = Sets the plot legend directions.
    LEGEND FONT          = Sets the plot legend fonts.
    LEGEND HW            = Sets the plot legend heights and widths.
    LEGEND JUSTIFICATION = Sets the plot legend justifications.
    LEGEND THICKNESS     = Sets the plot legend line thicknesses.
    TITLE SIZE           = Sets the size for plot title.
    LABEL SIZE           = Sets the size for plot labels.
    TIC SIZE             = Sets the size of plot tics.
    TIC LABEL SIZE       = Sets the size for plot tic labels.
    CHARACTER SIZES      = Sets the sizes for plot characters.
    TEXT                 = Writes a text string.
    HEIGHT               = Sets the height for TEXT characters.
    WIDTH                = Sets the width for TEXT characters.
    HW                   = Sets the height and width for TEXT
                           characters.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER X1 X2 Y1 Y2
    LINE BLANK ALL
    LEGEND 1 X - POTASSIUM
    LEGEND 2 Y - LEAD
    LEGEND 1 SIZE 3.0
    LEGEND 2 SIZE 1.2
    .
    TITLE DEMONSTRATE LEGEND SIZE COMMAND
    LET X = SEQUENCE 1 1 17
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
 
-----LEGEND THICKNESS-------------------------------------------------
 
LEGEND THICKNESS
 
Name:
    LEGEND ... THICKNESS
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the thickness of the legends to appear on subsequent
    plots.
 
Description:
    The legends are the text which the analyst can position anywhere
    (via the LEGEND ... COORDINATES command) on a plot.  The legends
    appear on all subsequent plots until blanked out (via a LEGEND
    command with no arguments) or until overridden with new legends.
    100 such legends can be specified.
 
    The legend thicknesses hold for all subsequent plots until
    defaulted (via the LEGEND ... THICKNESS command with no arguments)
    or until overridden with new legend thicknesses.
 
Syntax:
    LEGEND   <id>   THICKNESS   <thick>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
    and   <thick> is a decimal number or parameter in the range 0 to
              100 that specifies the desired legend line thickness.
 
Examples:
    LEGEND 1 THICKNESS 0.2
    LEGEND 2 THICKNESS 0.1
    LEGEND 1 THICKNESS
    LEGEND THICKNESS
 
Note:
    A LEGEND ... THICKNESS command with no thickness reverts the
    thickness to the default.  Thus LEGEND 1 THICKNESS with no
    thickness reverts the thickness of legend 1 to the default.  A
    LEGEND ... THICKNESS command with no <id> refers to all 100
    legends.  Thus LEGEND THICKNESS 0.2 assigns the thickness 0.2 to
    all 100 legends.  LABEL THICKNESS with no <id> and no thickness
    reverts all 100 legends to the default thickness.
 
Note:
    The thickness only applies if the legend is drawn with a software
    font (e.g., SIMPLEX).  It can be effectively used in combination
    with a software font to produce bolder text (e.g., SIMPLEX font
    with thickness 0.2 can produce attractive text for transparencies).
 
Default:
    All legend thicknesses are 0.1.
 
Synonyms:
    None
 
Related Commands:
    PLOT                 = Generates a data or function plot.
    LEGEND               = Specify the legends for subsequent plots.
    LEGEND ANGLE         = Sets the plot legend angles.
    LEGEND CASE          = Sets the plot legend cases.
    LEGEND COLOR         = Sets the plot legend colors.
    LEGEND COORDINATES   = Sets the plot legend locations.
    LEGEND DIRECTION     = Sets the plot legend directions.
    LEGEND FONT          = Sets the plot legend fonts.
    LEGEND HW            = Sets the plot legend heights and widths.
    LEGEND JUSTIFICATION = Sets the plot legend justifications.
    LEGEND SIZES         = Sets the plot legend sizes.
 
Applications:
    XX
 
Implementation Date:
    89/2
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER X1 X2 Y1 Y2
    LINE BLANK ALL
    LEGEND FONT DUPLEX
    LEGEND 1 X - POTASSIUM
    LEGEND 2 Y - LEAD
    LEGEND 1 THICKNESS 0.1
    LEGEND 2 THICKNESS 0.3
    .
    TITLE DEMONSTRATE LEGEND THICKNESS
    LET X = SEQUENCE 1 1 17
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
 
-----LEGEND UNITS-------------------------------------------------------
 
LEGEND UNITS
 
Name:
    LEGEND ... UNITS
 
Type:
    Plot Control Command
 
Purpose:
    Specifies whether legend coordinates are given in Dataplot
    screen units (0 to 100) or in units of the current plot.
 
Description:
    The legends are the text which the analyst can position anywhere
    (via the LEGEND ... COORDINATES command) on a plot.  The legends
    appear on all subsequent plots until blanked out (via a LEGEND
    command with no arguments) or until overridden with new legends.
    100 such legends can be specified.
 
    The legend units hold for all subsequent plots until defaulted (via
    the LEGEND ... UNIT command with no arguments) or until overridden
    with new legend units.
 
Syntax:
    LEGEND   <id>   UNIT   <units>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the legend identifier;
    and   <units> is either SCREEN (for screen units) or DATA (for
              units of the most recent plot).
 
Examples:
    LEGEND 1 UNITS DATA
    LEGEND 2 UNITS SCREEN
    LEGEND 1 UNITS
    LEGEND UNITS
 
Note:
    A LEGEND ... UNITS command with no units reverts the units to
    default.  Thus LEGEND 1 UNITS with no units reverts the units of
    legend 1 to default.  A LEGEND ... UNITS command with no <id>
    refers to all 100 legends.  Thus LEGEND UNITS DATA specifies that
    all 100 legend units will be in the units of the most recent plot.
    LEGEND UNITS with no <id> and no units reverts all 100
    legends to the default units.
 
Default:
    All legend coordinates are specified in Dataplot screen units.
 
Synonyms:
    None
 
Related Commands:
    PLOT                 = Generates a data or function plot.
    LEGEND               = Specify the legends for subsequent plots.
    LEGEND ANGLE         = Sets the plot legend angles.
    LEGEND COLOR         = Sets the plot legend colors.
    LEGEND COORDINATES   = Sets the plot legend locations.
    LEGEND DIRECTION     = Sets the plot legend directions.
    LEGEND FONT          = Sets the plot legend fonts.
    LEGEND HW            = Sets the plot legend heights and widths.
    LEGEND JUSTIFICATION = Sets the plot legend justifications.
    LEGEND SIZES         = Sets the plot legend sizes.
    LEGEND THICKNESS     = Sets the plot legend line thicknesses.
 
Applications:
    XX
 
Implementation Date:
    2000/1
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    CHARACTER X1 X2 Y1 Y2
    LINE BLANK ALL
    LEGEND 1 MAX LEAD VALUE = 607
    LEGEND 2 MAX POT VALUE = 339
    LEGEND UNITS DATA
    LEGEND 1 COORDINATES 7.2 605
    LEGEND 2 COORDINATES 16.2 339
    .
    TITLE DEMONSTRATE LEGEND UNITS COMMAND
    LET X = SEQUENCE 1 1 17
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
 
-----LEGENDRE (LET)--------------------------------
 
LEGENDRE
 
Name:
    LEGENDRE (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Legendre polynomial of order N, the normalized
    Legendre polynomial of order N, the normalized associated
    Legendre polynomial of order N, the normalized Legendre function
    of the first or second kind, or the normalized associated
    Legendre function of the first or second kind.
 
Description:
    From Abramowitz and Stegum (see Reference below), a system of
    nth degree polynomials f(x,n) is called orthogonal on the
    interval a<=x<=b with respect to a weight function w(x) if it
    satisfies the equation:
        INTEGRAL[w(x)*f(x,n)*f(x,m)]dx = 0   m<>n, (m,n = 0, 1, 2, ...

    Legendre polynomials use the weight function 1 and are orthogonal
    for the interval -1 < x < 1.  Legendre polynomials can also be
    defined by the following equation:
                        [N/2]
        Pn(x) = (1/2**n)*SUM[(-1)**M*(n)*x**(n-2m)(2n - 2m)
                         m=0         (m)          (   n   )

    Normalized Legendre polynomials are a scaled version of the
    Legendre polynomial (the scaling is performed so that the integral
    defined above is equal to 1).

    Associated Legendre Polynomials are defined in terms of the
    standard Legendre polynomial as follows:
        Pn,m(x) = (-1)**m*(1-x**2)**(m/2)*(d**m/dx**m)Pn(x)
    where (d**m/dx**m) refers to the mth derivative of Pn(x).  The
    value of m defines the degree of the associated Legendre
    polynomial.

    The Legendre functions and associated Legendre functions are
    generalizations of Legendre polynomials and associated Legendre
    polynomials where non-integer values of n and m are allowed.

    DATAPLOT calculates the standard Legendre polynomial using the
    following recurrence relation:
        P(x,n) = x*P(x,n-1) + (n/(n+1))*(x*p(x,n-1) - P(x,n-2))
    where the first few terms for the recuurence were obtained from
    the Handbook of Mathematical Functions (see the REFERENCE below).
 
    The remaining Legendre polynomials and functions are computed
    using the NORMP set of routines from the Slatec library.  These
    routines use a technique called extended range arithmetic to
    avoid underflow and overflow problems.  However, DATAPLOT stores
    the result as a single precision real number.  If it is unable to
    do so, it prints an error message.

Syntax 1:
    LET <y> = LEGENDRE(<x>,<n>)     <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the range
              (-PI,PI);
          <n> is a non-negative integer number, parameter, or variable
              that specifies the order of the Legendre polynomial;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Legendre polynomial value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the un-normalized Legendre polynomials.

Syntax 2:
    LET <y> = LEGENDRE(<x>,<n>,<m>) <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the range
              (-PI,PI);
          <n> is a non-negative integer number, parameter, or variable
              that specifies the order of the Legendre polynomial;
          <m> is a non-negative integer number, parameter, or variable
              that specifies the degree of the Legendre polynomial;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Legendre polynomial value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the un-normalized associated Legendre
    polynomials.

Syntax 3:
    LET <y> = NRMLEG(<x>,<n>)     <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the range
              (-PI,PI);
          <n> is a non-negative integer number, parameter, or variable
              that specifies the order of the Legendre polynomial;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Legendre polynomial value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the normalized Legendre polynomials.

Syntax 4:
    LET <y> = NRMLEG(<x>,<n>,<m>)   <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the range
              (-PI,PI);
          <n> is a non-negative integer number, parameter, or variable
              that specifies the order of the Legendre polynomial;
          <m> is a non-negative integer number, parameter, or variable
              that specifies the degree of the Legendre polynomial;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Legendre polynomial value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the normalized associated Legendre
    polynomials.

Syntax 5:
    LET <y> = LEGP(<x>,<n>)     <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the range
              (-PI,PI);
          <n> is a non-negative integer number, parameter, or variable
              that specifies the order of the Legendre function;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Legendre function value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the normalized Legendre function of the first
    kind.

Syntax 6:
    LET <y> = LEGP(<x>,<n>,<m>)   <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the range
              (-PI,PI);
          <n> is a non-negative integer number, parameter, or variable
              that specifies the order of the Legendre function;
          <m> is a non-negative integer number, parameter, or variable
              that specifies the degree of the Legendre function;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Legendre function value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the normalized associated Legendre function
    of the first kind.

Syntax 7:
    LET <y> = LEGQ(<x>,<n>)     <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the range
              (-PI,PI);
          <n> is a non-negative integer number, parameter, or variable
              that specifies the order of the Legendre function;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Legendre function value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the normalized Legendre function of the 
    second kind.

Syntax 8:
    LET <y> = LEGQ(<x>,<n>,<m>)   <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the range
              (-PI,PI);
          <n> is a non-negative integer number, parameter, or variable
              that specifies the order of the Legendre function;
          <m> is a non-negative integer number, parameter, or variable
              that specifies the degree of the Legendre function;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Legendre function value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the normalized associated Legendre function
    of the second kind.

Examples:
    LET A = LEGENDRE(0.5,4)
    LET A = LEGENDRE(0.5,4,2)
    LET A = NRMLEG(0.5,4)
    LET A = NRMLEG(0.5,4,2)
    LET A = LEGP(0.5,4,2.5)
    LET A = LEGQ(0.5,4,2.5)
    LET X2 = LEGENDRE(X1,N)
    LET X2 = LEGENDRE(X1,N,A)
 
Note:
    Legendre polynomials are often specified with an angular input
    value.  That is,
        Pn(x) = Pn(cos(theta))
    where -PI < theta < PI.  DATAPLOT uses the convention in
    calculating the various Legendre polynomials and functions for
    better accuracy.  If your input value is in terms of the (-1,1)
    interval, use the command
        LET XNEW = ARCCOS(X)
    and then use XNEW as the input argument to the Legendre functions.

    By default, the angle is specified in radians.  Enter the command
    DEGREES to specify degree units.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHEBT    = Compute the Chebychev polynomial first kind, order N.
    CHEBU    = Compute the Chebychev polynomial second kind, order N.
    HERMITE  = Compute the Hermite polynomial of order N.
    JACOBIPE = Compute the Jacobi polynomial of order N.
    ULTRASPH = Compute the ultrasperical polynomial of order N.
    LAGUERRE = Compute the Laguerre polynomial of order N.
 
Reference:
    "Extended-Range Arithmetic and Normalized Legendre Polynomials",
    Smith, Olver, and Lozier, ACM Transactions On Mathematical
    Software, Vol. 7, No. 1, March, 1981 (pp. 93-105).

    "Associated Legendre Functions on the Cut", Smith, and Olver, 
    Journal of Computational Physics, Vol. 51, No. 3, September, 1983,
    (pp. 502-518).

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 22).

Applications:
    Mathematics
 
Implementation Date:
    95/7
 
Program 1:
    TITLE CASE ASIS; LABEL CASE ASIS
    LINE SOLID DASH DOT DASH2
    X1LABEL X
    DEGREES
    .
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE Legendre Polynomials (order 2 thru 5)
    Y1LABEL Pn(X)
    PLOT LEGENDRE(X,2) FOR X = -179 1 179 AND
    PLOT LEGENDRE(X,3) FOR X = -179 1 179 AND
    PLOT LEGENDRE(X,4) FOR X = -179 1 179 AND
    PLOT LEGENDRE(X,5) FOR X = -179 1 179
    .
    TITLE Associated Legendre Polynomials (order 2 thru 5)
    Y1LABEL P(X,N,M)
    X2LABEL Degree (M) = 3
    PLOT LEGENDRE(X,2,3) FOR X = 1 1 179 AND
    PLOT LEGENDRE(X,3,3) FOR X = 1 1 179 AND
    PLOT LEGENDRE(X,4,3) FOR X = 1 1 179 AND
    PLOT LEGENDRE(X,5,3) FOR X = 1 1 179
    .
    TITLE Normalized Legendre Polynomials (order 2 thru 5)
    Y1LABEL Pn(X)
    PLOT NRMLEG(X,2) FOR X = -179 1 179 AND
    PLOT NRMLEG(X,3) FOR X = -179 1 179 AND
    PLOT NRMLEG(X,4) FOR X = -179 1 179 AND
    PLOT NRMLEG(X,5) FOR X = -179 1 179
    .
    TITLE Normalized Associated Legendre Polynomials (order 2 thru 5)
    Y1LABEL P(X,N,M)
    X2LABEL Degree (M) = 3
    PLOT NRMLEG(X,2,3) FOR X = -179 1 179 AND
    PLOT NRMLEG(X,3,3) FOR X = -179 1 179 AND
    PLOT NRMLEG(X,4,3) FOR X = -179 1 179 AND
    PLOT NRMLEG(X,5,3) FOR X = -179 1 179
    END OF MULTIPLOT
 
Program 2:
    TITLE CASE ASIS; LABEL CASE ASIS
    LINE SOLID DASH DOT DASH2
    DEGREES
    .
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE Associated Legendre functions (first kind)
    Y1LABEL P(X,N)
    X1LABEL X
    X2LABEL Order (n) = 2.5, 3.5, 4.5, 5.5
    PLOT LEGP(X,2.5) FOR X = 1 1 89 AND
    PLOT LEGP(X,3.5) FOR X = 1 1 89 AND
    PLOT LEGP(X,4.5) FOR X = 1 1 89 AND
    PLOT LEGP(X,5.5) FOR X = 1 1 89
    .
    TITLE Associated Legendre functions (first kind)
    Y1LABEL P(X,N,M)
    X1LABEL X
    X2LABEL Order (n) = 2.5, 3.5, 4.5, 5.5, Degree (m) = 3
    PLOT LEGP(X,2.5,3) FOR X = 1 1 89 AND
    PLOT LEGP(X,3.5,3) FOR X = 1 1 89 AND
    PLOT LEGP(X,4.5,3) FOR X = 1 1 89 AND
    PLOT LEGP(X,5.5,3) FOR X = 1 1 89
    .
    TITLE associated Legendre functions (second kind)
    Y1LABEL Q(X,n)
    X1LABEL X
    X2LABEL Order (n) = 2.5, 3.5, 4.5, 5.5
    PLOT LEGQ(X,2.5) FOR X = 1 1 89 AND
    PLOT LEGQ(X,3.5) FOR X = 1 1 89 AND
    PLOT LEGQ(X,4.5) FOR X = 1 1 89 AND
    PLOT LEGQ(X,5.5) FOR X = 1 1 89
    .
    TITLE Associated Legendre functions (second kind)
    Y1LABEL Q(X,N,M)
    X1LABEL X
    X2LABEL Order (n) = 2.5, 3.5, 4.5, 5.5, Degree (m) = 3
    PLOT LEGP(X,2.5,3) FOR X = 1 1 89 AND
    PLOT LEGP(X,3.5,3) FOR X = 1 1 89 AND
    PLOT LEGP(X,4.5,3) FOR X = 1 1 89 AND
    PLOT LEGP(X,5.5,3) FOR X = 1 1 89
    END OF MULTIPLOT
 
-----LET-------------------------------------------------------
 
LET
 
Name:
    LET
 
Type:
    Analysis Command
 
Purpose:
    The LET command is DATAPLOT's most versatile command; it
    has a variety of uses:
       1) evaluating functions;
       2) transforming variables;
       3) specifying elements of variables;
       4) calculating statistics;
       5) creating a sequence;
       6) creating a pattern;
       7) generating random numbers;
       8) manipulating/sorting data;
       9) defining functions;
      10) carrying out math operations.
 
Syntax:
    The syntax varies depending on the type of operation performed.
 
Examples:
    LET A = SIN(2*PI*0.025)
    LET Y = (X**LAMBDA-1)/LAMBDA
    LET Y(3)=LOG(4.5)-2**3.8
    LET M = MEAN Y
    LET X = SEQUENCE 1 .1 10
    LET X=PATTERN 1 1 2 2 3 3 FOR I = 1 1 30
    LET X=NORMAL RANDOM NUMBERS FOR I=1 1 80
    LET Y2 = SORT Y
    LET FUNCTION F = C*EXP(-X*X/2)
    LET A = INTEGRAL F WRT X FOR X 0 TO 1
 
Default:
    None
 
Synonyms:
    None
 
Note:
    Help is available for the individual subcommands under LET.  For
    example, to get lists of available subcommands, enter one of the
    following:

        HELP MATH FUNCTIONS
        HELP TRIGONOMETRIC FUNCTIONS
        HELP PROBABILITY FUNCTIONS
        HELP STATISTICS
        HELP MATH OPERATIONS
        HELP RANDOM NUMBERS

    You can help for individual subommands by entering:
        HELP <subcommand>

    The help for the individual subcommands gives the syntax for that
    command.
 
    The capabilities under LET are documented in Volume II of the
    Dataplot Reference Manual.
 
Note:
    If you enter a command like

       Y = NORMAL RANDOM NUMBERS FOR I = 1 1 100

    Dataplot would previously return an error.  The 2018/10 version of
    Dataplot was updated so that if a command is not matched, the command
    does not start with LET, and the command contains an "=" character,
    Dataplot will insert a "LET " at the beginning of the command string
    and try to match the command again.

    Note that using "LET" to start the command is still the preferred
    syntax since this new syntax is only attempted if the first word of
    the command line does not match a Dataplot command.  For example, "X",
    "R", "S", and "W" are short-cuts to existing commands, so the
    following will not work

             X = X + 1
             W = W + 1
             R = R + 1
             S = S + 1

    Note that if the left hand side name matches an existing Dataplot
    command, this syntax of leaving off the LET will fail.

Related Commands:
    LET FUNCTION = Defines functions.
    LET STRING   = Defines a string.
    STATUS       = Displays dimension, variables, parameters, and
                   functions.
    WRITE        = Writes variables, parameters, and functions to
                   the screen or to a file.
 
Applications:
    Data Management
 
Implementation Date:
    Pre-1987
    2018/10: Syntax with "LET" omitted
 
Program 1:
    LET A = 2
 
Program 2:
    LET X = SEQUENCE -3.1  0.1 3.1
    LET FUNCTION F = SIN(X)
    LET Y = F

Program 3:
    LET Y = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET YMEAN = MEAN Y
    LET YSD = SD Y
 
-----LET FUNCTION-----------------------------------------------------
 
LET FUNCTION
 
Name:
    LET FUNCTION
 
Type:
    Analysis Command
 
Purpose:
    Defines a function.
 
Description:
    DATAPLOT allows users to define their own functions.  Functions
    are defined with a Fortran like syntax.  User defined functions can
    be used in subsequent PLOT and LET commands (basically any place
    that a built-in DATAPLOT function can be used).
 
Syntax:
    LET FUNCTION   <f1>   =    <f2>
    where <f1> is the name of the function;
    and where <f2> is a functional expression.
 
Examples:
    LET FUNCTION F1 = C*EXP(0.5*((X-U)/SIGM
    LET FUNCTION F4 = F1*F2*LOG(F3)
    LET FUNCTION G = DERIVATIVE F1 WRT X
 
Note:
    Functions can be nested.  For example:
       LET FUNCTION F1 = -0.5*((X**2)+(Y**2))
       LET FUNCTION F2 = (1/(2*PI))*EXP(F1)
    It is often easier to write a complex function as a series of
    simpler functions.
 
Note:
    Functions can depend on more than one variable.  For example,
       LET FUNCTION F1 = -0.5*((X**2)+(Y**2))
    This function depends on both X and Y.  In practice, user defined
    functions with one or two variables are common while more than two
    variables are fairly rare.
 
Note:
    To evaluate a function at a sequence of points, do something like
    the following:
       LET FUNCTION F1 = 3*X**2 + 2*X + 4
       LET X = SEQUENCE -3 .1 3
       LET Y1 = F1
    This evaluates function F1 at the points defined in the variable X.
    The computed values are stored in the variable Y1 (it has the same
    length as X).
 
    There is a distinction for functions with more than one variable.
    For example, the following only evaluates the function at the
    points (-2,-2), (-1.9,-1.9), ... , (2,2):
       LET FUNCTION F1 = -0.5*((X**2)+(Y**2))
       LET FUNCTION F2 = (1/(2*PI))*EXP(F1)
       LET X = SEQUENCE -2 .1 2
       LET Y = SEQUENCE -2 .1 2
       LET Z = F2
    If you really want a grid from -2 to 2 in both the X and Y
    directions, do the following:
       LET FUNCTION F1 = -0.5*((X**2)+(Y**2))
       LET FUNCTION F2 = (1/(2*PI))*EXP(F1)
       LET TEMP = SEQUENCE -2 .1 2
       LET NPTS = SIZE TEMP
       LET NPTS2 = NPTS*NPTS
       LET X = SEQUENCE -2 .1 2 FOR I = 1 1 NPTS2
       LET Y = SEQUENCE -2 NPTS .1 2
       LET Z = F2
 
Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default is 10,000 characters.  Previous versions set this limit at
    1,000 characters.  This limit applies to the combined number of
    characters for all functions and strings.
 
Note:
    All of DATAPLOT's built-in functions can be used in user defined
    functions.
 
Note:
    Error checking (e.g., matching parenthesis, valid number of
    arguments for a built-in function) is performed when the function
    is evaluated, not when it is created.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET    = Carries out variety of operations on variable,
             parameters, and functions.
    STATUS = Displays dimension, variables, parameters, functions, etc.
    WRITE  = Writes variables, parameters, functions to either the
             screen or to file.
 
Applications:
    Mathematics
 
Implementation Date:
    Pre-1987
 
Program:
   LET FUNCTION F1 = SIN(X)*COS(X)
   LET START = -PI/2
   LET STOP = PI/2
   LET X = SEQUENCE START 0.1 STOP
   LET D1 = DERIVATIVE F1 WRT X
   LINE SOLID DASH
   LET Y1 = F1
   TITLE PLOT OF FUNCTION AND ITS DERIVATIVE
   PLOT Y1 D1 VS X
 
-----LET PLOT --------------------------------------------------------
 
LET PLOT
 
Name:
    LET PLOT
 
Type:
    Let Subcommand
 
Purpose:
    Set values for CHARACTER, LINE, SPIKE, BAR, and REGION commands
    (and their associated attribute setting commands).
 
Description:
    The Dataplot CHARACTER, LINE, SPIKE, BAR, and REGION commands
    and the associated attribute setting commands (e.g., CHARACTER
    SIZE) support up to 100 settings.

    In most applications, only the first few settings need to be
    specified, so the CHARACTER, LINE, SPIKE, BAR, and REGION
    (and associated attribute setting) commands are straightforward
    to use.  However, there are occassions where we would like to be
    able to change the setting for a high trace number without entering
    the values for all the lower trace numbers.  This command was
    added to allow you to do that.

Syntax 1:
    LET PLOT <command> <index> = <setting>
    where <command> is the desired command;
          <index> is a number or parameter that specifies the
                  trace id;
    and   <setting> specifies the value being set.

    The available commands are listed in a NOTE section below.
    The <index> value should be an integer in the range 1 to
    100 (real numbers are rounded to the closest integer).  The
    allowed value for <setting> is dependent on <command>.

Syntax 2:
    LET PLOT <command> <index> = <setting>
    where <command> is the desired command;
          <index> is a variable containing one or more trace
                  id's;
    and   <setting> is a list of one or more values.

    This syntax allows you to set more than one value.  This syntax is
    demonstrated in the Program 3 section below.

Examples:
    LET PLOT CHARACTER      24 = CIRCLE
    LET PLOT CHARACTER FILL 24 = ON
 
    LET IINDEX = DATA 21 22 23 24
    LET PLOT CHARACTER FILL IINDEX = ON

    LET IINDEX = DATA 21 22 23 24
    LET PLOT CHARACTER FILL IINDEX = ON OFF ON OFF

Note:
    The available commands are

        CHARACTER
        CHARACTER ANGLE
        CHARACTER CASE
        CHARACTER COLOR
        CHARACTER FILL
        CHARACTER FONT
        CHARACTER HW
        CHARACTER JUSTIFICATION
        CHARACTER OFFSET
        CHARACTER SIZE
        CHARACTER THICKNESS

        LINE
        LINE COLOR
        LINE THICKNESS

        SPIKE
        SPIKE BASE
        SPIKE COLOR
        SPIKE DIRECTION
        SPIKE LINE
        SPIKE THICKNESS

        BAR
        BAR BASE
        BAR BORDER COLOR
        BAR BORDER LINE
        BAR BORDER THICKNESS
        BAR COLOR
        BAR FILL
        BAR FILL COLOR
        BAR PATTERN
        BAR PATTERN COLOR
        BAR PATTERN LINE
        BAR PATTERN SPACING
        BAR PATTERN THICKNESS
        BAR THICKNESS
        BAR WIDTH

        REGION
        REGION BASE
        REGION FILL
        REGION FILL COLOR
        REGION PATTERN
        REGION PATTERN COLOR
        REGION PATTERN LINE
        REGION PATTERN SPACING
        REGION PATTERN THICKNESS

    The Program examples below demonstrate many of these.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS          = Sets the types for plot characters.
    LINES               = Sets the types for plot lines.
    SPIKES              = Sets the on/off switches for plot spikes.
    BARS                = Sets the on/off switches for plot bars.
    REGION              = Sets the on/off switches for plot regions.

Applications:
    Plot Control
 
Implementation Date:
    2014/08
 
Program 1:
    skip 25
    read gear.dat y x
    .
    .  Generate box plot standard way
    .
    char box plot
    line box plot
    fences on
    box plot y x
    .
    .  Now use "let plot ..." to modify appearance of plot
    .
    let plot character 1 = blank
    let plot character 4 = circle
    let plot character 7 = blank
    let plot character fill 4 = on
    let iindex = 4
    let plot character hw iindex = 1.0 0.75
    let plot character hw 21 = 2.0 1.5
    let plot character hw 22 = 1.0 0.75
    let plot character hw 23 = 1.0 0.75
    let plot character hw 24 = 2.0 1.5
    let plot line 8  = dotted
    let plot line 13 = dashed
    let plot line thickness 14 = 0.2
    let plot line thickness 15 = 0.2
    let plot line thickness 16 = 0.2
    let plot line thickness 20 = 0.2
    let plot line color 14 = blue
    let plot line color 15 = blue
    let plot line color 16 = blue
    let plot line color 20 = blue
    .
    box plot y x

Program 2:
    .  This is similar to Program 1, except use Syntax 2 for
    .  some cases.
    skip 25
    read gear.dat y x
    .
    .  Generate box plot standard way
    .
    char box plot
    line box plot
    fences on
    box plot y x
    .
    .  Now reset some char/line settings
    .
    let indexv = data 1 4 7
    let plot character indexv = blank circle blank
    let plot character fill 4 = on
    let iindex = 4
    let plot character hw iindex = 1.0 0.75
    let plot character hw 21 = 2.0 1.5
    let plot character hw 22 = 1.0 0.75
    let plot character hw 23 = 1.0 0.75
    let plot character hw 24 = 2.0 1.5
    let plot line 8  = dotted
    let plot line 13 = dashed
    let indexv = data 14 15 16 17
    let plot line thickness indexv = 0.2
    let indexv = data 14 15 16 20
    let plot line color indexv = blue
    .
    box plot y x
 
Program 3:
    .  Following demonstrates the syntax for various spike,
    .  bar, and region settings.
    .
    let x = sequence 1 1 9
    let y = x**2
    .
    .  Generate plot standard way
    .
    xlimits 0 10
    plot y x
    .
    .  Now test spike settings
    .
    let plot line            1  = blank
    let plot spike           1  = on
    let plot spike line      1  = dotted
    let plot spike thickness 1  = 0.3
    let plot spike color     1  = red
    let plot spike base      1  = -5
    plot y x
    let plot spike           1  = off
    let plot spike line      1  = solid
    let plot spike thickness 1  = 0.1
    let plot spike color     1  = black
    let plot spike base      1  = 0
    .
    .  Now test bar settings - solid fill
    .
    let plot bar              1  = on
    let plot bar base         1  = -5
    let plot bar width        1  = 0.5
    let plot bar fill         1  = on
    let plot bar fill color   1  = blue
    let plot bar border color 1  = red
    let plot bar border line  1  = dash
    let plot bar border thick 1  = 0.3
    plot y x
    let plot bar              1  = off
    let plot bar base         1  = 0
    let plot bar width        1  = 1
    let plot bar fill         1  = off
    let plot bar fill color   1  = black
    let plot bar border color 1  = black
    let plot bar border line  1  = solid
    let plot bar border thick 1  = 0.1
    .
    .  Now test bar settings - pattern fill
    .
    let plot bar              1  = on
    let plot bar fill         1  = on
    let plot bar base         1  = -5
    let plot bar width        1  = 0.8
    let plot bar pattern      1  = d1
    let plot bar pattern colo 1  = red
    let plot bar pattern line 1  = dash
    let plot bar pattern thic 1  = 0.3
    let plot bar pattern spac 1  = 3
    plot y x
    let plot bar              1  = off
    let plot bar fill         1  = off
    let plot bar base         1  = 0
    let plot bar width        1  = 1
    let plot bar pattern      1  = blank
    let plot bar pattern colo 1  = black
    let plot bar pattern line 1  = solid
    let plot bar pattern thic 1  = 0.1
    let plot bar pattern spac 1  = 1
    .
    .  Now test region settings - solid fill
    .
    y1tic mark offset 10 0
    let plot line                1  = solid
    let plot region fill         1  = on
    let plot region fill color   1  = blue
    let plot region base         1  = -5
    plot y x
    let plot region fill         1  = off
    let plot region fill color   1  = black
    let plot region base         1  = 0
    .
    .  Now test region settings - pattern fill
    .
    y1tic mark offset 10 0
    let plot line                1  = solid
    let plot region fill         1  = on
    let plot region pattern      1  = d2
    let plot region pattern colo 1  = red
    let plot region pattern spac 1  = 5
    let plot region pattern thic 1  = 0.2
    let plot region pattern line 1  = dotted
    let plot region base         1  = -5
    plot y x
    let plot region fill         1  = off
    let plot region pattern      1  = blank
    let plot region pattern colo 1  = black
    let plot region pattern spac 1  = 1
    let plot region pattern thic 1  = 0.1
    let plot region pattern line 1  = solid
    let plot region base         1  = 0
 
-----LET STRING-----------------------------------------------------
 
LET STRING
 
Name:
    LET STRING
 
Type:
    Analysis Command
 
Purpose:
    Defines a string.
 
Description:
    In addition to parameters and vectors of real numbers, DATAPLOT allows
    you to define strings.  Strings can be created using either the
    READ STRING or the LET STRING commands.

    Strings are often used with the substitution character ("^" by
    default).  The substitution character inserts the value of a
    previously defined parameter or string into a DATAPLOT command.
    For example,

        LET STRING S = Glucose in Serum
        TITLE ^S

    Although in this example we could have simply entered the string
    directly in the title, this capability can be useful in writing general
    purpose macros and within loops.

Syntax:
    LET STRING  <sout>  =  <sin>
    where <sout> is the name of the string;
    and   <sin> is an expression that defines the contents of the string.
 
Examples:
    LET STRING S1 = Sample String
 
Note:
    Internally, Dataplot stores functions and strings together.  However,
    there is one important distinction between LET STRING and
    LET FUNCTION.  The LET STRING comamnd will preserve the case of the
    text used to define the string while LET FUNCTION will automatically
    convert lower case characters to upper case.

Note:
    Dataplot does not currently support string arrays.  You can
    mimic this capability to some extent using the substitution
    character ("^" by default).  For example, you could do somehting
    like

        let string s1 = Title for Plot One
        let string s2 = Title for Plot Two
        let string s3 = Title for Plot Three
        loop for k = 1 1 3
            title ^s^k
            plot y^k x
        end of loop

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to the
    combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET FUNCTION        = Defines a function.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    SUBTRING            = Extract a substring from an existing string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING LENGTH       = Return the length of a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    STRING EDIT         = Edit a string.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on the
                          ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on the
                          ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    Pre-1987
 
Program:
    .  Assume we have variables X and Y in the files "file1.dat" to
    .  "file10.dat" and we want to plot each of these in turn.
    .
    LET STRING S1 = file
    LET STRING S3 = .dat
    TITLE CASE ASIS
    LOOP FOR K = 1 1 10
        LET STRING S2 = ^K
        LET STRING FNAME = ^S1&^S2&^S3
        READ ^FNAME  Y X
        TITLE Data from File ^SOUT
        PLOT Y X
        DELETE Y X
    END OF LOOP
 
-----LEVENE TEST--------------------------------------------------
 
LEVENE TEST
 
Name:
    LEVENE TEST
 
Type:
    Analysis Command
 
Purpose:
    Perform a k-sample Levene test for the homogeneity of variances
    across samples.
 
Description:
    The F test used in analysis of variance problem with k factors
    can be sensitive to unequal standard deviations in the k factors.
    Levene's test is a test of the hypothesis that all factor 
    standard deviations (or equivalently variances) are equal against
    the alternative that the standard deviations are not all equal.

    The assumption of homogeneous variances arises in other
    contexts in addition to analysis of variance.  Levene's test
    can be applied in these cases as well.

    The Levene test is an alternative to the Bartlett test.
    Although it is more commonly used, the Bartlett test is known
    to be sensitive to departures from normality.  The Levene
    test is less sensitive to non-normality than the Bartlett
    test.

    The Levene test statistic is:

        W = [(n-k)/(k-1)]*SUM1/SUM2

    where n is the total sample size, k is the number of
    groups, and

        SUM1 = SUM[n(i)*(ZBAR(i.) - ZBAR(..))**2] 
        SUM2 = SUM[SUM(Z(ij) - ZBAR(i.))**2)]

    where the sum for SUM1 and for the outer sum of SUM2 is for
    i = 1, 2, ..., k and the inner sum for SUM2 is for
    j = 1, 2, ..., n(i) where n(i) is the sample size for group i.
    Z(ij) = ABS(X(ij) - XBAR(i.)) where i is the group and j is
    the sample within the group.  Therefore XBAR(i.) is the 
    mean for group i and ZBAR(i.) is the group i mean of the
    absolute deviations from the group mean.  ZBAR(..) is the
    overall mean of the absolute deviations from the group
    means.
        
    The sampling distribution of the Levene statistic is
    approximately F with (k-1) and (n-k) degrees of freedom.

    The Levene test can still be sensitive to skewed distributions.
    Modifications to the Levene test use a more robust estimator
    for XBAR(i.).  Specifically, the median or trimmed mean
    can be used in place of the mean.  Dataplot supports both
    of these options.  The same F approximation is still used.
    These alternatives are recommended if the distribution may
    be skewed.

Syntax 1:
    LEVENE TEST  <y>  <tag>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <tag> is a factor identifier variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the median based Levene test.

Syntax 2:
    MEDIAN LEVENE TEST  <y>  <tag>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <tag> is a factor identifier variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the median based Levene test.

Syntax 3:
    MEAN LEVENE TEST  <y>  <tag>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <tag> is a factor identifier variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the mean based Levene test.

Syntax 4:
    TRIMMED MEAN LEVENE TEST  <y>  <tag> 
                              <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <tag> is a factor identifier variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the trimmed mean based Levene test.
    It trims the lowest 10% and the highest 10% of the data.

Examples:
    LEVENE TEST Y1  GROUP
    LEVENE TEST Y1  GROUP  SUBSET GROUP > 2
    MEDIAN LEVENE TEST Y1  GROUP
    MEAN LEVENE TEST Y1  GROUP
    TRIMMED MEAN LEVENE TEST Y1  GROUP
 
Note 1:
    The various values printed by the LEVENE TEST command are
    saved as parameters that can be used later by the analyst.  Enter
    the command STATUS PARAMETERS after the LEVENE TEST command 
    to see a list of the saved parameters.
 
Note 2:
    The HOMOGENEITY PLOT is a graphical technique for testing for
    unequal variances.

Default:
    The default is to to compute the Levene test based on
    group medians.
 
Synonyms:
    None
 
Related Commands:
    BARTLETT TEST       = Compute Bartlett's test.
    HOMOGENEITY PLOT    = Plot group standard deviations against group
                          means.
    CONFIDENCE LIMITS   = Compute the confidence limits for the mean
                          of a sample.
    F TEST              = Performs a two-sample F test.
    T TEST              = Performs a two-sample t test.
    CHI-SQUARE TEST     = Performs a one sample chi-square test that
                          the standard deviation is equal to a given
                          value.
    STANDARD DEVIATION  = Computes the standard deviation of a
                          variable.
 
Reference:
    Levene, H. (1960).  "Contributions to Probability and Statistics:
    Essays in Honor of Harold Hotelling", I. Olkin, et. al., eds.
    Stanford University Press, Stanford, CA, pp. 278-292.

 
Applications:
    Analysis of Variance, Regression
 
Implementation Date:
    1998/5
 
Program:
    SKIP 50
    SET READ FORMAT 3F4.0,F5.0,F6.0,F3.0,2F9.0
    READ PBF11.DAT YEAR DAY BOT SD F11 FLAG WV CO2
    .
    RETAIN YEAR DAY BOT SD F11 WV CO2 FLAG SUBSET FLAG 0
    LET MONTH=INT(DAY/30.25)+1
    .
    SET WRITE DECIMALS 5
    LEVENE TEST WV MONTH
    STATUS PARAMETERS

-----LEXCDF (LET)--------------------------------
 
LEXCDF
 
Name:
    LEXCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the logistic-exponential cumulative distribution
    function with shape parameter beta.
 
Description:
    The standard logistic-exponential distribution has the following
    cumulative distribution function:

       F(x;beta) = 1 - 1/[1 + EXP(x) -1)**beta]
                   beta, x > 0
 
    with beta denoting the shape parameter.

    This distribution can be generalized with location and
    scale parameters in the usual way using the relation

       F(x;beta,loc,scale) = F((x-loc)/scale;beta,0,1)

Syntax:
    LET <y> = LEXCDF(<x>,<beta>,<loc>,<scale>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed logistic-exponential
              cdf value is stored;
          <beta> is a number, parameter, or variable that
              specifies the shape parameter;
          <loc> is a number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable
              that specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = LEXCDF(0.3,0.2)
    LET Y = LEXCDF(X,0.5,0,5)
    PLOT LEXCDF(X,0.7,0,3) FOR X = 0  0.01  5
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LEXCHAZ = Compute the logistic-exponential cumulative hazard
              function.
    LEXHAZ  = Compute the logistic-exponential hazard function.
    LEXPDF  = Compute the logistic-exponential probability density
              function.
    LEXPPF  = Compute the logistic-exponential percent point function.
    RAYPDF  = Compute the Rayleigh probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    EXPPDF  = Compute the exponential probability density function.
    GAMPDF  = Compute the gamma probability density function.
    EWEPDF  = Compute the exponentiated Weibull probability density
              function.
    B10PDF  = Compute the Burr type 10 probability density function.
 
Reference:
    Leemis and McQuestion (2008), "Univariate Distribution
    Relationships", The American Statistician Vol. 62, No. 1,
    pp. 45-53.

    Lan and Leemis (2008), "The Logistic-Exponential Survival
    Distribution", Naval Research Logistics, to appear.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2008/2
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.5
    TITLE BETA = ^BETA
    PLOT LEXCDF(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 1
    TITLE BETA = ^BETA
    PLOT LEXCDF(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 2
    TITLE BETA = ^BETA
    PLOT LEXCDF(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 5
    TITLE BETA = ^BETA
    PLOT LEXCDF(X,BETA) FOR X = 0.01  0.01  5
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Logistic-Exponential Cumulative Distribution Functions
 
-----LEXCHAZ (LET)--------------------------------
 
LEXCHAZ
 
Name:
    LEXCHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the logistic-exponential cumulative hazard function
    with shape parameter beta.
 
Description:
    The standard logistic-exponential distribution has the following
    cumulative hazard function:

       H(x;beta) = -LOG(1/[1 + EXP(x) -1)**beta])
                   beta, x > 0
 
    with beta denoting the shape parameter.

    This distribution can be generalized with location and
    scale parameters in the usual way using the relation

       H(x;beta,loc,scale) = H((x-loc)/scale;beta,0,1)

Syntax:
    LET <y> = LEXCHAZ(<x>,<beta>,<loc>,<scale>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed logistic-exponential
              cumulative hazard value is stored;
          <beta> is a number, parameter, or variable that
              specifies the shape parameter;
          <loc> is a number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable
              that specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = LEXCHAZ(0.3,0.2)
    LET Y = LEXCHAZ(X,0.5,0,5)
    PLOT LEXCHAZ(X,0.7,0,3) FOR X = 0  0.01  5
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LEXCDF  = Compute the logistic-exponential cumulative
              distribution function.
    LEXHAZ  = Compute the logistic-exponential hazard function.
    LEXPDF  = Compute the logistic-exponential probability density
              function.
    LEXPPF  = Compute the logistic-exponential percent point function.
    RAYPDF  = Compute the Rayleigh probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    EXPPDF  = Compute the exponential probability density function.
    GAMPDF  = Compute the gamma probability density function.
    EWEPDF  = Compute the exponentiated Weibull probability density
              function.
    B10PDF  = Compute the Burr type 10 probability density function.
 
Reference:
    Leemis and McQuestion (2008), "Univariate Distribution
    Relationships", The American Statistician Vol. 62, No. 1,
    pp. 45-53.

    Lan and Leemis (2008), "The Logistic-Exponential Survival
    Distribution", Naval Research Logistics, to appear.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2008/2
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.5
    TITLE BETA = ^BETA
    PLOT LEXCHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 1
    TITLE BETA = ^BETA
    PLOT LEXCHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 2
    TITLE BETA = ^BETA
    PLOT LEXCHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 5
    TITLE BETA = ^BETA
    PLOT LEXCHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Logistic-Exponential Cumulative Hazard Functions
 
-----LEXHAZ (LET)--------------------------------
 
LEXHAZ
 
Name:
    LEXHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the logistic-exponential hazard function with
    shape parameter beta.
 
Description:
    The standard logistic-exponential distribution has the
    following hazard function:

       h(x;beta) = beta*(EXP(x) - 1)**(beta-1)*EXP(x)/
                   [1 + (EXP(X) - 1)**beta]
                   beta, x > 0
 
    with beta denoting the shape parameter.

    This distribution can be generalized with location and
    scale parameters in the usual way using the relation

       h(x;beta,loc,scale) = (1/scale)*h((x-loc)/scale;beta,0,1)

Syntax:
    LET <y> = LEXHAZ(<x>,<beta>,<loc>,<scale>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed logistic-exponential
              hazard value is stored;
          <beta> is a number, parameter, or variable that
              specifies the shape parameter;
          <loc> is a number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable
              that specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = LEXHAZ(0.3,0.2)
    LET Y = LEXHAZ(X,0.5,0,5)
    PLOT LEXHAZ(X,0.7,0,3) FOR X = 0  0.01  5
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LEXCDF  = Compute the logistic-exponential cumulative
              distribution function.
    LEXCHAZ = Compute the logistic-exponential cumulative hazard
              function.
    LEXPDF  = Compute the logistic-exponential probability density
              function.
    LEXPPF  = Compute the logistic-exponential percent point function.
    RAYPDF  = Compute the Rayleigh probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    EXPPDF  = Compute the exponential probability density function.
    GAMPDF  = Compute the gamma probability density function.
    EWEPDF  = Compute the exponentiated Weibull probability density
              function.
    B10PDF  = Compute the Burr type 10 probability density function.
 
Reference:
    Leemis and McQuestion (2008), "Univariate Distribution
    Relationships", The American Statistician Vol. 62, No. 1,
    pp. 45-53.

    Lan and Leemis (2008), "The Logistic-Exponential Survival
    Distribution", Naval Research Logistics, to appear.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2008/2
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.5
    TITLE BETA = ^BETA
    PLOT LEXHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 1
    TITLE BETA = ^BETA
    PLOT LEXHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 2
    TITLE BETA = ^BETA
    PLOT LEXHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 5
    TITLE BETA = ^BETA
    PLOT LEXHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Logistic-Exponential Hazard Functions
 
-----LEXPDF (LET)--------------------------------
 
LEXPDF
 
Name:
    LEXPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the logistic-exponential probability density function
    with shape parameter beta.
 
Description:
    The standard logistic-exponential distribution has the following
    probability density function:

       f(x;beta) = beta*(EXP(x)-1)**(beta-1)*EXP(x)/
                   {(1+(EXP(x)-1)**beta)**2}
                   beta, x > 0
 
    with beta denoting the shape parameter.

    This distribution can be generalized with location and
    scale parameters in the usual way using the relation

       f(x;beta,loc,scale) = (1/scale)*f((x-loc)/scale;beta,0,1)

Syntax:
    LET <y> = LEXPDF(<x>,<beta>,<loc>,<scale>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed logistic-exponential
              pdf value is stored;
          <beta> is a number, parameter, or variable that
              specifies the shape parameter;
          <loc> is a number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable
              that specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = LEXPDF(0.3,0.2)
    LET Y = LEXPDF(X,0.5,0,5)
    PLOT LEXPDF(X,0.7,0,3) FOR X = 0  0.01  5
 
Note:
    Logistic-exponential random numbers, probability plots, and
    goodness of fit tests can be generated with the commands:

       LET BETA = <value>
       LET Y = LOGISTIC EXPONENTIAL RANDOM NUMBERS FOR I = 1 1 N
       LOGISTIC EXPONENTIAL PROBABILITY PLOT Y
       LOGISTIC EXPONENTIAL PROBABILITY PLOT Y2 X2
       LOGISTIC EXPONENTIAL PROBABILITY PLOT Y3 XLOW XHIGH
       LOGISTIC EXPONENTIAL KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       LOGISTIC EXPONENTIAL CHI-SQUARE GOODNESS OF FIT Y2 X2
       LOGISTIC EXPONENTIAL CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    The following commands can be used to estimate the beta
    shape parameter for the logistic-exponential distribution:

       LET BETA1 = <value>
       LET BETA2 = <value>
       LOGISTIC EXPONENTIAL PPCC PLOT Y
       LOGISTIC EXPONENTIAL PPCC PLOT Y2 X2
       LOGISTIC EXPONENTIAL PPCC PLOT Y3 XLOW XHIGH
       LOGISTIC EXPONENTIAL KS PLOT Y
       LOGISTIC EXPONENTIAL KS PLOT Y2 X2
       LOGISTIC EXPONENTIAL KS PLOT Y3 XLOW XHIGH

    The default values for BETA1 and BETA2 are 0.1 and 10.

    The probability plot can then be used to estimate the
    location and scale (location = PPA0, scale = PPA1).

    The 2-parameter logistic-exponential maximum likelihood
    estimates can be obtained using the command

       LOGISTIC EXPONENTIAL MAXIMUM LIKELIHOOD Y

    The maximum likelihood estimates for the full sample case
    are obtained as the solution of the following simultaneous
    equations (from Lan and Leemis):

      (n/beta) + SUM[i=1 to n][LOG(EXP(alpha*X(i)) - 1) -
      2*SUM[i=1 to n][(EXP(alpha*X(I) - 1)**beta*
      LOG(EXP(alpha*X(i)) -1)/{1 + (EXP(alpha*X(i)) - 1)**beta}
      = 0

      (n/alpha) + SUM[i=1 to n][(beta-1)*X(i)*EXP(alpha*X(i))/
      (EXP(ALHA*X(i)) - 1) + SUM[i=1 to n][X(i)] -
      2*SUM[i=1 to n][beta*(EXP(alpha*X(I) - 1)**(beta - 1)*
      X(I)*EXP(alpha*X(i))/{1 + (EXP(alpha*X(i)) - 1)**beta}
      = 0

    with beta and (1/alpha) denoting the shape and scale
    parameters, respectively.

    If the maximum likelihood estimates do not converge to
    reasonable values, you can try specifying starting values
    with the commands

        LET RSV = <value>
        LET SCALESV = <value>

    For example, the estimates obtained from the ppcc plot or
    ks plot method can be used as starting values for the
    maximum likelihood.

    The BOOTSTRAP DISTRIBUTION command can be used to find
    uncertainty intervals for the ppcc plot, the ks plot,
    and the maximum likelihood estimates.
       
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LEXCDF  = Compute the logistic-exponential cumulative
              distribution function.
    LEXCHAZ = Compute the logistic-exponential cumulative hazard
              function.
    LEXHAZ  = Compute the logistic-exponential hazard function.
    LEXPPF  = Compute the logistic-exponential percent point function.
    RAYPDF  = Compute the Rayleigh probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    EXPPDF  = Compute the exponential probability density function.
    GAMPDF  = Compute the gamma probability density function.
    EWEPDF  = Compute the exponentiated Weibull probability density
              function.
    B10PDF  = Compute the Burr type 10 probability density function.
 
Reference:
    Leemis and McQuestion (2008), "Univariate Distribution
    Relationships", The American Statistician Vol. 62, No. 1,
    pp. 45-53.

    Lan and Leemis (2008), "The Logistic-Exponential Survival
    Distribution", Naval Research Logistics, to appear.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2008/2
 
Program 1:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.5
    TITLE BETA = ^BETA
    PLOT LEXPDF(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 1
    TITLE BETA = ^BETA
    PLOT LEXPDF(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 2
    TITLE BETA = ^BETA
    PLOT LEXPDF(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 5
    TITLE BETA = ^BETA
    PLOT LEXPDF(X,BETA) FOR X = 0.01  0.01  5
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Logistic-Exponential Probability Density Functions
 
Program 2:
    let beta = 2.1
    let betasav = beta
    .
    let y = logistic exponential random numbers for i = 1 1 200
    let y = 10*y
    let amax = maximum y
    .
    label case asis
    title case asis
    .
    y1label Correlation Coefficient
    x1label Beta
    logistic exponential ppcc plot y
    let beta = shape
    justification center
    move 50 6
    text Betahat = ^beta (BETA = ^betasav)
    move 50 2
    text Maximum PPCC = ^maxppcc
    let beta1 = shape - 1
    let beta1 = max(0.1,beta1)
    let beta2 = shape + 1
    logistic exponential ppcc plot y
    let beta = shape
    justification center
    move 50 6
    text Betahat = ^beta (BETA = ^betasav)
    move 50 2
    text Maximum PPCC = ^maxppcc
    .
    y1label Data
    x1label Theoretical
    char x
    line bl
    logistic exponential prob plot y
    move 50 6
    text Location = ^ppa0, Scale = ^ppa1
    char bl
    line so
    .
    y1label Relative Frequency
    x1label
    relative hist y
    limits freeze
    pre-erase off
    line color blue
    plot lexpdf(x,beta,ppa0,ppa1) for x = 0.01 .01 amax
    line color black
    limits 
    pre-erase on
    .
    let ksloc = ppa0
    let ksscale = ppa1
    logistic exponential kolmogorov smirnov goodness of fit y
    .
    logistic exponential mle y
    let ksloc = 0
    let ksscale = alphaml
    let beta = betaml
    logistic exponential kolmogorov smirnov goodness of fit y

-----LEXPPF (LET)--------------------------------
 
LEXPPF
 
Name:
    LEXPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the logistic-exponential percent point function with
    shape parameter beta.
 
Description:
    The standard logistic-exponential distribution has the following
    percent point function:

       G(p;beta) = LOG[1 + (1/(1-p) - 1)**(1/beta)]
                   beta, 0 <= p < 1
 
    with beta denoting the shape parameter.  Note that if
    beta < 1, then 0 < p < 1.

    This distribution can be generalized with location and
    scale parameters in the usual way using the relation

       G(x;beta,loc,scale) = loc + scale*G(p;beta,0,1)

Syntax:
    LET <y> = LEXPPF(<p>,<beta>,<loc>,<scale>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, parameter, or variable in the
              interval (0,1];
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed logistic-exponential
              ppf value is stored;
          <beta> is a number, parameter, or variable that
              specifies the shape parameter;
          <loc> is a number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable
              that specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = LEXPPF(0.95,0.2)
    LET Y = LEXPPF(P,0.5,0,5)
    PLOT LEXPPF(P,2.7,0,3) FOR P = 0  0.01  0.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LEXCDF  = Compute the logistic-exponential cumulative
              distribution function.
    LEXCHAZ = Compute the logistic-exponential cumulative hazard
              function.
    LEXHAZ  = Compute the logistic-exponential hazard function.
    LEXPDF  = Compute the logistic-exponential probability density
              function.
    RAYPDF  = Compute the Rayleigh probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    EXPPDF  = Compute the exponential probability density function.
    GAMPDF  = Compute the gamma probability density function.
    EWEPDF  = Compute the exponentiated Weibull probability density
              function.
    B10PDF  = Compute the Burr type 10 probability density function.
 
Reference:
    Leemis and McQuestion (2008), "Univariate Distribution
    Relationships", The American Statistician Vol. 62, No. 1,
    pp. 45-53.

    Lan and Leemis (2008), "The Logistic-Exponential Survival
    Distribution", Naval Research Logistics, to appear.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2008/2
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.5
    TITLE BETA = ^BETA
    PLOT LEXPPF(P,BETA) FOR P = 0.01  0.01  0.99
    .
    LET BETA  = 1
    TITLE BETA = ^BETA
    PLOT LEXPPF(P,BETA) FOR P = 0.01  0.01  0.99
    .
    LET BETA  = 2
    TITLE BETA = ^BETA
    PLOT LEXPPF(P,BETA) FOR P = 0.01  0.01  0.99
    .
    LET BETA  = 5
    TITLE BETA = ^BETA
    PLOT LEXPPF(P,BETA) FOR P = 0.01  0.01  0.99
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Logistic-Exponential Percent Point Functions
 
-----LF-------------------------------------------------------
 
LF
 
Name:
    LF
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Specifies that there be a "line feed" after subsequent TEXT commands.
 
Description:
    If the line feed is "off", the beam remains on the same line as the
    old text after a TEXT command and new text is placed on the same
    line as old text.  If the line feed is "on", the beam is
    automatically advanced to the next line after a TEXT command and new
    text is placed on the next lines without an explicit MOVE command.
 
    The position of the next line is set via the HEIGHT and VERTICAL
    SPACING commands.  The HEIGHT command sets the height of a character
    (not counting inter-character gap).  The VERTICAL SPACING command
    sets the inter-character gap (not counting the height of the
    character).
 
    The LF command is frequently used in conjunction with the CR
    (= carriage return) command.  The CR command specifies whether or
    not the beam should revert to the "margin" after each subsequent
    TEXT command.  Judicious control of the "carriage return" and "line
    feed" allows the analyst to cut down on unnecessary MOVE statements
    between succeeding TEXT commands when generating a simple list of
    text strings (as is common in creating word charts).
 
Syntax:
    LF   <ON or OFF>
    where ON specifies that the beam moves to the next line while OFF
             specifies that it remains on the current line.
 
Examples:
    LF ON
    LF OFF
    LF
 
Note:
    The LF command with no arguments is equivalent to LF ON .
 
Default:
    The default is for the line feed to be "on".
 
Synonyms:
    None
 
Related Commands:
    CR                 = Sets the carriage return after text.
    CRLF               = Sets the carriage return/line feed after text.
    MARGIN             = Sets the carriage return column after text.
    TEXT               = Writes a text string.
    FONT               = Sets the font for TEXT characters.
    CASE               = Sets the case for TEXT characters.
    HEIGHT             = Sets the height for TEXT characters.
    WIDTH              = Sets the width for TEXT characters.
    HW                 = Sets the height and width for TEXT characters.
    VERTICAL SPACING   = Sets the vertical spacing between text lines.
    HORIZONTAL SPACING = Sets the horizontal spacing between text
                         characters.
    THICKNESS          = Sets the thickness of TEXT characters.
    COLOR              = Sets the color for TEXT characters.
    JUSTIFICATION      = Sets the justification for TEXT.
    ()                 = Allows math and Greek characters in text.
    MOVE               = Moves to a point.
    CROSS-HAIR (or CH) = Activates and reads the cross-hair.
    ERASE              = Erases the screen (immediately).
    COPY               = Copies the screen (immediately).
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    FEEDBACK OFF
    FONT DUPLEX
    CR OFF
    LF OFF
    HW 4 3
    MOVE 20 50
    TEXT SUB()TUNSB()NSUP()13UNSP()
    .
    HW 4 8
    TEXT RARR()
    .
    HW 4 3
    TEXT SUB()6UNSB()CSUP()13 + LC()BETA()SUP()+UNSP() + NU()
 
-----LGACDF (LET)--------------------------------
 
LGACDF
 
Name:
    LGACDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard form of the log-gamma cumulative
    distribution function.
 
Description:
    The standard form of the log-gamma distribution has the
    following cumulative distribution function:
       F(x,gamma) = I(EXP(x))(gamma)   x, gamma > 0
    where I(a)(x) is the incomplete gamma function ratio and gamma
    is the shape parameter.
 
Syntax:
    LET <y> = LGACDF(<x>,<gamma>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a positive number, a number, or a variable;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed log-gamma cdf value is saved;
          <gamma> is a number or parameter that specifies the shape
               parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LGACDF(3,1.5)
    LET X2 = LGACDF(X1,GAMMA)
 
 
Note:
    Prentice has given a reparameterized log-gamma probability
    density that many analysts prefer.  The pdf for this form
    is given on page 90 of Johnson, Kotz, and Balakrishnan
    (see the Reference section below).  Dataplot does not
    currently support this reparameterized form.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LGAPDF = Compute the log-gamma probability density function.
    LGAPPF = Compute the log-gamma percent point function.
    GAMPDF = Compute the gamma probability density function.
    WEIPDF = Compute the Weibull probability density function.
    EXPPDF = Compute the exponential probability density function.
    CHSPDF = Compute the chi-square probability density function.
    EV1PDF = Compute the extreme value type I probability density
             function.
 
Reference:
    "Continuous Univariate Distributions - Volume 2", 2nd. Ed.,
    Johnson, Kotz, and Balakrishnan, John Wiley, 1994 (pp. 89-90).
 
Applications:
    Extreme Value Analysis, Reliability Analysis
 
Implementation Date:
    1995/10
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    X1LABEL X
    Y1LABEL PROBABILITY
    .
    LET GAMMA = 0.1
    TITLE LOG-GAMMA PDF: GAMMA = ^GAMMA
    PLOT LGACDF(X,GAMNMA) FOR X = 0.01 0.01 5
    LET GAMMA = 0.5
    TITLE LOG-GAMMA PDF: GAMMA = ^GAMMA
    PLOT LGACDF(X,GAMMA) FOR X = 0.1 0.1 5.5
    LET GAMMA = 1
    TITLE LOG-GAMMA PDF: GAMMA = ^GAMMA
    PLOT LGACDF(X,GAMMA) FOR X = 0.1 0.1 5.5
    LET GAMMA = 2
    TITLE LOG-GAMMA PDF: GAMMA = ^GAMMA
    PLOT LGACDF(X,GAMMA) FOR X = 0.1 0.1 10
 
-----LGAPDF (LET)--------------------------------
 
LGAPDF
 
Name:
    LGAPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard form of the log-gamma probability density
    function.
 
Description:
    The standard form of the log-gamma distribution has the
    following probability density function:
       f(x,gamma) = EXP(gamma*x - EXP(x))/GAMMA(gamma)  x, gamma > 0
    where gamma is the shape parameter and GAMMA is the standard
    Gamma function.
 
Syntax:
    LET <y> = LGAPDF(<x>,<gamma>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a positive number, a number, or a variable;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed log-gamma pdf value is saved;
          <gamma> is a number or parameter that specifies the shape
               parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LGAPDF(3,1.5)
    LET X2 = LGAPDF(X1,GAMMA)
 
 
Note:
    The general form of the log-gamma distribution has the
    following probability density function:
       f(x,gamma,mu,sigma) = EXP(gamma*((x-mu)/sigma) -
                             EXP((x-mu)/sigma))/GAMMA(gamma)
                             x, gamma,sigma > 0
    where gamma is the shape parameter, GAMMA is the standard
    Gamma function, mu is the location parameter, and sigma is
    the scale parameter.
 
Note:
    Prentice has given a reparameterized log-gamma probability
    density that many analysts prefer.  The pdf for this form
    is given on page 90 of Johnson, Kotz, and Balakrishnan
    (see the Reference section below).  Dataplot does not
    currently support this reparameterized form.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LGACDF = Compute the log-gamma cumulative distribution function.
    LGAPPF = Compute the log-gamma percent point function.
    GAMPDF = Compute the gamma probability density function.
    WEIPDF = Compute the Weibull probability density function.
    EXPPDF = Compute the exponential probability density function.
    CHSPDF = Compute the chi-square probability density function.
    EV1PDF = Compute the extreme value type I probability density
             function.
 
Reference:
    "Continuous Univariate Distributions - Volume 2", 2nd. Ed.,
    Johnson, Kotz, and Balakrishnan, John Wiley, 1994 (pp. 89-90).
 
Applications:
    Extreme Value Analysis, Reliability Analysis
 
Implementation Date:
    1995/10
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    X1LABEL X
    Y1LABEL PROBABILITY
    .
    LET GAMMA = 0.1
    TITLE LOG-GAMMA PDF: GAMMA = ^GAMMA
    PLOT LGAPDF(X,GAMNMA) FOR X = 0.01 0.01 5
    LET GAMMA = 0.5
    TITLE LOG-GAMMA PDF: GAMMA = ^GAMMA
    PLOT LGAPDF(X,GAMMA) FOR X = 0.01 0.01 5
    LET GAMMA = 1
    TITLE LOG-GAMMA PDF: GAMMA = ^GAMMA
    PLOT LGAPDF(X,GAMMA) FOR X = 0.01 0.01 5
    LET GAMMA = 2
    TITLE LOG-GAMMA PDF: GAMMA = ^GAMMA
    PLOT LGAPDF(X,GAMMA) FOR X = 0.01 0.01 10
 
-----LGAPPF (LET)--------------------------------
 
LGAPPF
 
Name:
    LGAPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard form of the log-gamma percent point
    function.
 
Description:
    The standard form of the log-gamma distribution is computed
    from the log-gamma cumulative distribution function numerically
    using a bisection method.
 
Syntax:
    LET <y> = LGAPPF(<p>,<gamma>)  <SUBSET/EXCEPT/FOR qualification>
    where <p> is a positive number, a number, or a variable;
          <y> is a variable or a parameter (depending on what <p> is)
               where the computed log-gamma ppf value is saved;
          <gamma> is a number or parameter that specifies the shape
               parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LGAPPF(0.95,1.5)
    LET X2 = LGAPPF(P1,GAMMA)
 
 
Note:
    Prentice has given a reparameterized log-gamma probability
    density that many analysts prefer.  The pdf for this form
    is given on page 90 of Johnson, Kotz, and Balakrishnan
    (see the Reference section below).  Dataplot does not
    currently support this reparameterized form.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LGACDF = Compute the log-gamma cumulative distribution function.
    LGAPDF = Compute the log-gamma probability density function.
    GAMPDF = Compute the gamma probability density function.
    WEIPDF = Compute the Weibull probability density function.
    EXPPDF = Compute the exponential probability density function.
    CHSPDF = Compute the chi-square probability density function.
    EV1PDF = Compute the extreme value type I probability density
             function.
 
Reference:
    "Continuous Univariate Distributions - Volume 2", 2nd. Ed.,
    Johnson, Kotz, and Balakrishnan, John Wiley, 1994 (pp. 89-90).
 
Applications:
    Extreme Value Analysis, Reliability Analysis
 
Implementation Date:
    1995/10
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    Y1LABEL X
    X1LABEL PROBABILITY
    .
    LET GAMMA = 0.1
    TITLE LOG-GAMMA PDF: GAMMA = ^GAMMA
    PLOT LGAPPF(P,GAMNMA) FOR P = 0.01 0.01 0.99
    LET GAMMA = 0.5
    TITLE LOG-GAMMA PDF: GAMMA = ^GAMMA
    PLOT LGAPPF(P,GAMMA) FOR P = 0.01 0.01 0.99
    LET GAMMA = 1
    TITLE LOG-GAMMA PDF: GAMMA = ^GAMMA
    PLOT LGAPPF(P,GAMMA) FOR P = 0.01 0.01 0.99
    LET GAMMA = 2
    TITLE LOG-GAMMA PDF: GAMMA = ^GAMMA
    PLOT LGAPPF(P,GAMMA) FOR P = 0.01 0.01 0.99
 
-----LGNCDF (LET)--------------------------------
 
LGNCDF
 
Name:
    LGNCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard lognormal cumulative distribution function.
 
Description:
    The standard lognormal distribution has the following probability
    density function:
       f(x)=(1/(x**sigma*sqrt(2*PI)))*exp(-log(x)**2/(2*sigmaa**2))
                                     for x > 0,  sigma > 0
    where sigma is a shape parameter.  The cumulative distribution is
    the area from negative infinity to x (i.e., the integral of the
    above function).  The cdf of the lognormal distribution is
    calculated as NORCDF(LOG(x)/sigma) where NORCDF is standard normal
    cumulative distribution function.
 
Syntax:
    LET <y2> = LGNCDF(<y1>,<s>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a non-negative number, parameter, or variable;
          <s> is an optional positive number, parameter, or variable
               that specifies the shape parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed lognormal cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If the <s> parameter is omitted, it defaults to 1.

Examples:
    LET A = LGNCDF(3)
    LET X2 = LGNCDF(X1)
    LET X2 = LGNCDF(X1,0.5)
 
Note:
    A variable X is log-normally distributed if the variable Y=LOG(X)
    is normally distributed.
 
Note:
    The general lognormal distribution has the following probability
    density function:
       f(x)=(1/((x-u)*sigma*sqrt(2*PI)))*
               exp(-0.5*(log(x)-u)/sigma)**2)      for x > 0
    where u is a location parameter and sigma is a shape parameter.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LGNPDF = Compute the lognormal probability density function.
    LGNPPF = Compute the lognormal percent point function.
    PLNCDF = Compute the power-lognormal cumulative distribution
             function.
    PLNPDF = Compute the power-lognormal probability density function.
    PLNPPF = Compute the power-lognormal percent point function.
    HFNCDF = Compute the half-normal cumulative distribution function.
    HFNPDF = Compute the half-normal probability density function.
    HFNPPF = Compute the half-normal percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
 
Reference:
    "Continuous Univariate Distributions - 1", Johnson and Kotz,
    Houghton Mifflin, 1970 (chapter 14).
 
Applications:
    XX
 
Implementation Date:
    94/4 (support for the shape parameter added 95/4)
 
Program:
    YLIMITS 0 1
    MAJOR YTIC NUMBER 6
    MINOR YTIC NUMBER 1
    YTIC DECIMAL 1
    XLIMITS 0 10
    XTIC OFFSET 0.2 0.2
    TITLE AUTOMATIC
    PLOT LGNCDF(X) FOR X = 0.01 0.01 10.0
 
-----LGNCHAZ (LET)--------------------------------
 
LGNCHAZ
 
Name:
    LGNCHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the lognormal cumulative hazard function.
 
Description:
    The lognormal distribution has the following cumulative
    hazard function:

       H(x,sigma)=-LOG(1 - LGNCDF(x,sigma))   0 <= x < infinity

    where sigma is the shape parameter.

Syntax:
    LET <y2> = LGNCHAZ(<y1>,<s>,<loc>,<scale>) 
                               <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a non-negative number, parameter, or variable;
          <s> is an optional positive number, parameter, or variable
               that specifies the shape parameter;
          <loc> is an optional number, parameter, or variable
               that specifies the location parameter;
          <scale> is an optional number, parameter, or variable
               that specifies the shape parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed lognormal cumulative hazard value
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LGNCHAZ(3)
    LET X2 = LGNCHAZ(X1)
    LET X2 = LGNCHAZ(X1,0.5)
    LET X2 = LGNCHAZ(X1,0.5,10,50)
 
Note:
    A variable X is log-normally distributed if the variable Y=LOG(X)
    is normally distributed.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LGNHAZ  = Compute the lognormal hazard function.
    LGNPDF  = Compute the lognormal probability density function.
    WEIHAZ  = Compute the Weibull hazard function.
    EXPHAZ  = Compute the exponential hazard function.
    NORHAZ  = Compute the normal hazard function.
    PLNHAZ  = Compute the power-lognormal hazard function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", Johnson, Kotz,
    and Balakrishnin, John Wiley and Sons, 1994.
 
Applications:
    Reliability
 
Implementation Date:
    1998/5
 
Program:
    TITLE AUTOMATIC
    PLOT LGNCHAZ(X) FOR X = 0.01 0.01 10.0
 
-----LGNHAZ (LET)--------------------------------
 
LGNHAZ
 
Name:
    LGNHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the lognormal hazard function.
 
Description:
    The lognormal distribution has the following hazard function:

       h(x,sigma)=LGNPDF(x,sigma)/(1 - LGNCDF(x,sigma))   0 <= x < infinity

    where sigma is the shape parameter.
 
Syntax:
    LET <y2> = LGNHAZ(<y1>,<s>,<loc>,<scale>) 
                               <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a non-negative number, parameter, or variable;
          <s> is an optional positive number, parameter, or variable
               that specifies the shape parameter;
          <loc> is an optional number, parameter, or variable
               that specifies the location parameter;
          <scale> is an optional number, parameter, or variable
               that specifies the shape parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed lognormal hazard value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LGNHAZ(3)
    LET X2 = LGNHAZ(X1)
    LET X2 = LGNHAZ(X1,0.5)
    LET X2 = LGNHAZ(X1,0.5,10,50)
 
Note:
    A variable X is log-normally distributed if the variable Y=LOG(X)
    is normally distributed.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LGNCHAZ = Compute the lognormal cumulative hazard function.
    LGNPDF  = Compute the lognormal probability density function.
    WEIHAZ  = Compute the Weibull hazard function.
    EXPHAZ  = Compute the exponential hazard function.
    NORHAZ  = Compute the normal hazard function.
    PLNHAZ  = Compute the power-lognormal hazard function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", Johnson, Kotz,
    and Balakrishnin, John Wiley and Sons, 1994.
 
Applications:
    Reliability
 
Implementation Date:
    1998/5
 
Program:
    TITLE AUTOMATIC
    PLOT LGNHAZ(X) FOR X = 0.01 0.01 10.0
 
-----LGNPDF (LET)--------------------------------
 
LGNPDF
 
Name:
    LGNPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard lognormal probability density function.
 
Description:
    The standard lognormal distribution has the following probability
    density function:
       f(x)=(1/(x**sigma*sqrt(2*PI)))*exp(-log(x)**2/(2*sigmaa**2))
                                     for x > 0,  sigma > 0
    where sigma is the shape parameter.
 
Syntax:
    LET <y2> = LGNPDF(<y1>,<s>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a non-negative number, parameter, or variable;
          <s> is an optional positive number, parameter, or variable
               that specifies the shape parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed lognormal pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LGNPDF(3)
    LET X2 = LGNPDF(X1)
    LET X2 = LGNPDF(X1,0.5)
 
Note:
    A variable X is log-normally distributed if the variable Y=LOG(X)
    is normally distributed.
 
Note:
    The general lognormal distribution has the following probability
    density function:
       f(x)=(1/((x-u)*sigma*sqrt(2*PI)))*
               exp(-0.5*(log(x)-u)/sigma)**2)      for x > 0
    where u is a location parameter and sigma is a shape parameter.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LGNCDF = Compute the lognormal cumulative distribution function.
    LGNPPF = Compute the lognormal percent point function.
    PLNCDF = Compute the power-lognormal cumulative distribution
             function.
    PLNPDF = Compute the power-lognormal probability density function.
    PLNPPF = Compute the power-lognormal percent point function.
    HFNCDF = Compute the half-normal cumulative distribution function.
    HFNPDF = Compute the half-normal probability density function.
    HFNPPF = Compute the half-normal percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
 
Reference:
    "Continuous Univariate Distributions - 1", Johnson and Kotz,
    Houghton Mifflin, 1970 (chapter 14).
 
Applications:
    XX
 
Implementation Date:
    94/4 (support for the shape parameter added 95/4)
 
Program:
    XLIMITS 0 10
    XTIC OFFSET 0.2 0.2
    TITLE AUTOMATIC
    PLOT LGNPDF(X) FOR X = 0.01 0.01 10.0
 
-----LGNPPF (LET)--------------------------------
 
LGNPPF
 
Name:
    LGNPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the lognormal percent point function.
 
Description:
    The standard lognormal distribution has the following probability
    density function:
       f(x)=(1/(x**sigma*sqrt(2*PI)))*exp(-log(x)**2/(2*sigmaa**2))
                                     for x > 0,  sigma > 0
    where sigma is the shape parameter.

    The percent point function is the inverse of the cumulative
    distribution function.  The cumulative distribution sums the
    probability from 0 to the given x value (i.e., the integral of the
    above function).  The percent point function takes a cumulative
    probability value and computes the corresponding x value.  The
    formula for the lognormal percent point function is:
       G(p) = EXP(NORPPF((p))
    where NORPPF is the percent point function of the standard normal
    distribution.
 
    The input value is a real number between 0 and 1 (since it
    corresponds to a probability).
 
Syntax:
    LET <y2> = LGNPPF(<y1>,<s>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a number, parameter, or variable in the range 0 to 1;
          <s> is an optional positive number, parameter, or variable
               that specifies the shape parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed lognormal ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LGNPPF(0.9)
    LET X2 = LGNPPF(X1)
    LET X2 = LGNPPF(X1,0.5)
 
Note:
    A variable X is log-normally distributed if the variable Y=LOG(X)
    is normally distributed.
 
Note:
    The general lognormal distribution has the following probability
    density function:
       f(x)=(1/((x-u)*sigma*sqrt(2*PI)))*
               exp(-0.5*(log(x)-u)/sigma)**2)      for x > 0
    where u is a location parameter and sigma is a shape parameter.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LGNCDF = Compute the lognormal cumulative distribution function.
    LGNPDF = Compute the lognormal probability density function.
    PLNCDF = Compute the power-lognormal cumulative distribution
             function.
    PLNPDF = Compute the power-lognormal probability density function.
    PLNPPF = Compute the power-lognormal percent point function.
    HFNCDF = Compute the half-normal cumulative distribution function.
    HFNPDF = Compute the half-normal probability density function.
    HFNPPF = Compute the half-normal percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
 
Reference:
    "Continuous Univariate Distributions - 1", Johnson and Kotz,
    Houghton Mifflin, 1970 (chapter 14).
 
Applications:
    XX
 
Implementation Date:
    94/4
 
Program:
    XLIMITS 0 1
    MAJOR XTIC NUMBER 6
    MINOR XTIC NUMBER 1
    XTIC DECIMAL 1
    PLOT LGNPPF(X) FOR X = 0.01 .01 0.99
 
-----LIBPLOT----------------------------------------------------
 
LIBPLOT
 
Name:
    LIBPLOT
 
Type:
    Output Device Command
 
Purpose:
    Create graphics files using the LIBPLOT library.
 
Description:
    The LIBPLOT library is part of the "plotutils" package that is
    available under many Unix/Linux platforms (and can be easily installed
    if it is not already available).

    The LIBPLOT library allows graphics to be generated in the following
    formats:

        1) X11
        2) GIF
        3) Postscript
        4) HP-GL
        5) Scalable Vector Graphics (SVG)
        6) Portable Network Graphics (PNG)
        7) Tektronix 4014
        8) Regis

        9) netPBM format (PNM) in either binary or ASCII
       10) Adobe Illustrator
       11) xfig
       12) HP PCL (using HP-GL emulation)
       13) plotutils metafile format
       14) web CGM in either binary or ASCII format

    Devices 1-8 are redundant to devices that are already supported in
    Dataplot.  We will say a bit more about the remaining devices since
    these are not currently supported in Dataplot.

        1) The netPBM software package supports conversion between many
           types of bitmap formats (currently converters are available for
           over 100 graphics formats).  In addition, it supports a number
           of programs for manipulating bitmap files.  The netPBM software
           is freely downloadable and is supported on most major computing
           platforms.

           The netPBM programs do not convert directly from one format to
           the other.  Instead, they convert to the intermediate PNM
           format.  Then for a supported bitmap format, programs are
           available to convert to and from the PNM format.

           The primary utility for this format is that it greatly expands
           the potential number of bitmap formats that Dataplot can
           generate.  Dataplot can generate graphics output in PNG, JPEG,
           and GIF format using the GD library.  However, if you need a
           graphic in a bitmap format other than these, the PNM option
           provides an option.  In addition to the netPBM software, most
           bitmap conversion software supports the PNM format.  The PNM
           format is typically not of interest itself.  Rather, it is
           useful because it allows you to easily convert to many other
           bitmap formats.

           More information about the netPBM software and PPM format is
           available at the netPBM website:

               http://netpbm.sourceforge.net/

        2) The Adobe Illustrator program is a popular graphics editing
           program.  This driver generates graphs in Adobe Illustrator's
           native format.

        3) The xfig program is a graphics editing program that has been
           available on most Unix/Linux platforms for a long time.  This
           driver generates graphs in xfig's native format.

        4) The Printer Control Language (PCL) was developed by HP to
           support its desktop printers.  It has been adopted as the
           primary protocol by many desktop printers.

           Note that the LIBPLOT PCL driver does not generate native PCL
           bitmaps.  Instead, it uses the HP-GL emulation that is provided
           in PCL.  The HP-GL language is a vector-based format that HP
           originally introduced to support its penplotters.  The PCL
           driver will include the commands to put the printer into HP-GL
           emulation mode and to terminate HP-GL emulation mode.

           The primary utility of this driver is that it may allow you to
           create a graphics file that can be sent directly to a printer
           instead of generating Postscript and sending it through an
           intermediate software such as Ghostview.  The downside of this
           is that the HP-GL emulation is not as rich as the Postscript
           language (e.g., the color support is more limited).

        5) The LIBPLOT metafile format is used by the programs in
           the plotutils package.

        6) The webcgm format is an ANSI standard Computer Graphics Metafile
           (CGM) format.  Although CGM did not become a widely adopted
           standard, there are a number of word processing, graphics
           editing, and page publishing software programs that will import
           CGM files.  Note that libplot supports a newer version of CGM
           that was developed to support inclusion on web pages.

    In summary, most of the new formats provided by the LIBPLOT driver
    are most useful as ways of importing Dataplot graphics into other
    programs.

    Some of the features and limitations of the LIBPLOT driver are
    discussed in the Notes section below.

    The documentation for the Plotutils package (including LIBPLOT) is
    available at the web site

        http://www.gnu.org/software/plotutils/

Syntax 1:
    DEVICE <1/2/3> LIBPLOT <device>
    where <device> is one of the following:
          X            - for X11
          PNM          - netPBM PNM binary format
          PNM ASCII    - netPBM PNM ascii format
          GIF          - GIF format
          AI           - Adobe Illustrator format
          PS           - Postscript format
          FIG          - xfig format
          PCL          - PCL format using HP-GL emulation
          HPGL         - HP-GL format
          META         - LIBPLOT metafile binary format
          META ASCII   - LIBPLOT metafile ascii format
          SVG          - Scalable Vector Graphics format
          PNG          - Portable Network Graphics format
          TEK          - Tektronix 4014 format to the terminal screen
          TEK FILE     - Tektronix 4014 format to file
          REGIS        - Regis format to the terminal screen
          REGIS FILE   - Regis format to file
          CGM          - CGM binary format
          CGM ASCII    - CGM ascii format
 
    This form designates one of DATAPLOT's 3 devices (typically
    device 2) as a LIBPLOT device.
 
    Note that although Dataplot supports 3 concurrent devices, only
    one of these can be a LIBPLOT device.  Typically, it will be
    DEVICE 2 that you set to a LIBPLOT device.

Examples:
    DEVICE 2 LIBPLOT PNG
    DEVICE 2 LIBPLOT PNM
    DEVICE 2 LIBPLOT FIG
 
Note:
    If you build Dataplot from source, the LIBPLOT driver depends on
    plotutils being installed on your local platform.  Currently, LIBPLOT
    support is limited to Linux/Unix installations.
 
Note:
    The LIBPLOT library is currently limited to output only.  This means
    that the CROSS HAIR command is not supported.

Note:
    Dataplot typically uses "dppl1f.dat" and "dppl2f.dat" as the default
    names for the DEVICE 2 and DEVICE 3 output files.  These default
    names can be modified with the SET IPL1NA and SET IPL2NA commands.

    However, the LIBPLOT devices use their own names.  Specifically,
    the file name will be

        libplot.xx

    where xx is one of

        x      => for the X device
        pnm    => for the PNM device
        gif    => for the GIF device
        ai     => for the Adobe illustrator device
        ps     => for the Postscript device
        fig    => for the xfig device
        pcl    => for the HP PCL device
        hpgl   => for the HP GL device
        tek    => for the Tektronix 4014 device
        meta   => for the libplot metafile device
        svg    => for the SVG device
        png    => for the PNG device
        regis  => for the Regis device
        cgm    => for the cgm device

    There is no currently no way to change these default file names.

Note:
    The libplot devices are used to generate a single plot.  If
    you need to generate multiple plots, do something like the
    following (this example is for Linux)

        DEVICE 2 LIBPLOT FIG
           generate first plot
        DEVICE 2 CLOSE
        SYSTEM  mv  libplot.fig  plot1.fig
        DEVICE 2 LIBPLOT FIG
           generate second plot
        DEVICE 2 CLOSE
        SYSTEM  mv  libplot.fig  plot2.fig

    The exception is that the X device can be used for multiple
    plots.

Note:
    The default image size is 570x570 pixels.  This applies to
    the following devices: X, png, gif, and pnm.  To change
    the default image size, enter the command

        SET LIBPLOT X SIZE  <value>
        SET LIBPLOT Y SIZE  <value>

Note:
    The following commands are supported

        SET LIBPLOT CAP STYLE  <ROUND/PROJECT/BUTT>
        SET LIBPLOT JOIN STYLE <ROUND/BEVEL/MITER>
        SET LIBPLOT HARDWARE FILL <ON/OFF>
        SET LIBPLOT FONT  <font name>

     Appendix A (section A.1) of the plotutils manual describes the fonts
     that are supported by the libplot library.

     All devices support the following Hershey fonts:

        1) HersheySerif
        2) HersheySerif-Italic
        3) HersheySerif-Bold
        4) HersheySerif-BoldItalic
        5) HersheyCyrillic
        6) HersheyCyrillic-Oblique
        7) HersheyEUC
        8) HersheySans
        9) HersheySans-Oblique
       10) HersheySans-Bold
       11) HersheySans-BoldOblique
       12) HersheyScript
       13) HersheyScript-Bold
       14) HersheyGothicEnglish
       15) HersheyGothicGerman
       16) HersheyGothicItalian
       17) HersheySerifSymbol
       18) HersheySerifSymbol-Oblique
       19) HersheySerifSymbol-Bold
       20) HersheySerifSymbol-BoldOblique
       21) HersheySansSymbol
       22) HersheySansSymbol-Oblique

    In addition, libplot supports the 35 Postscript fonts, the 45
    PCL 5 fonts, 18 Hewlett-Packard vector fonts.  These non-Hershey
    fonts may not be available on all devices.

    The Postscript fonts are available for the X, Adobe Illustrator,
    Postscript, and fig devices.  The PCL fonts are available for the
    Adobe Illustrator, PCL, and HP-GL devices.  The HP vector fonts are
    available for the PCL and HP-GL devices.

    The X device can use any of the X11 fonts installed on your local
    system.

    The Postscript font names are

     1) Helvetica
     2) Helvetica-Oblique
     3) Helvetica-Bold
     4) Helvetica-BoldOblique
     5) Helvetica-Narrow
     6) Helvetica-Narrow-Oblique
     7) Helvetica-Narrow-Bold
     8) Helvetica-Narrow-BoldOblique
     9) Times-Roman
    10) Times-Italic
    11) Times-Bold
    12) Times-BoldItalic
    13) AvantGarde-Book
    14) AvantGarde-BookOblique
    15) AvantGarde-Demi
    16) AvantGarde-DemiOblique
    17) Bookman-Light
    18) Bookman-LightItalic
    19) Bookman-Demi
    20) Bookman-DemiItalic
    21) Courier
    22) Courier-Oblique
    23) Courier-Bold
    24) Courier-BoldOblique
    25) NewCenturySchlbk-Roman
    26) NewCenturySchlbk-Italic
    27) NewCenturySchlbk-Bold
    28) NewCenturySchlbk-BoldItalic
    29) Palatino-Roman
    30) Palatino-Italic
    31) Palatino-Bold
    32) Palatino-BoldItalic
    33) ZapfChancery-MediumItalic
    34) ZapfDingbats
    35) Symbol

    The PCL and HP fonts are given in the libplot manual.

    The default font is "Helvetica" for all devices except the
    PNM, GIF, HP-GL, Tektronix, and metafile devices.  For these,
    the default font is HersheySerif.

Note:
    The libplot device can handle many of Dataplot's supported special
    characters.  These special characters are mapped to the libplot's
    special characters.  There is not a 1-to-1 correspondence between
    Dataplot's special characters and the symbols available in libplot.
    The supported symbols below are ones that are available in both the
    Dataplot special symbol set and in libplot.

    Specifically, the following are supported:

      i) subscripts and superscripts
     ii) Greek characters
    iii) A subset of the mathematical symbols and other special
         characters.  The following is the list of Dataplot
         special characters that will be translated to
         equivalent characters in the Postscript symbol font:

             INTE(), SUMM(), PROD(), INFI(), DOTP(),
             DIVI(), LT(), GT(), LTEQ(), GTEQ(),
             NOT=(), +-(), TILD(), EQUI(), VARI(),
             CARA(), TIME(), PART(), RADI(), SUBS(),
             SUPE(), THEX(),
             THFO(), LBRA(), RBRA(), LCBR(),
             RCBR(), RARR(), UARR(),
             DARR(), HBAR(), DEGR() 

         The full set of special symbols supported by Dataplot
         is documented in chapter 13 of Volume I of the
         Reference Manual

            http://www.itl.nist.gov/div898/software/dataplot/
            refman1/ch13/homepage.pdf

    Alternatively, you can enter special symbols using the libplot
    escape sequences.  The available escape sequences are documented
    in Appendix A (section A.4) of the plotutils manual (available
    at the plotutils web site).  This includes a large number of
    special symbols not supported directly by Dataplot.

Default:
    None
 
Synonyms:
    None

Related Commands:
    POSTSCRIPT            = Direct graphical output to a Postscript
                            device.
    HPGL                  = Direct graphical output to an HPGL device.
    SVG                   = Generate graphical output in Scalable
                            Vector Graphics (SVG) format.
    DEVICE                = Specify certain actions for the graphics
                            output.
 
Applications:
    Web Applications, Graphics Import Into Other Programs
 
Implementation Date:
    2009/5
 
Program:
    DEVICE 1 LIBPLOT X
    TITLE SAMPLE PNG PLOT
    PLOT X**2 FOR X = 1 1 9
    DEVICE 1 CLOSE

-----LIMITS-------------------------------------------------------
 
LIMITS
 
Name:
    ...LIMITS
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the limits (minimum and maximum) to appear on the plot
    axes of subsequent plots.
 
Description:
    For most data analysis applications, the analyst need not bother
    with the LIMITS command since DATAPLOT generates neat limits based
    on the data.  If the default limits are not acceptable, then the
    analyst can make use of the MINIMUM, MAXIMUM, or LIMITS commands to
    specify the minimum, maximum, or both, respectively.
 
Syntax:
    <prefix>LIMITS   <n1>   <n2>
    where <n1> is a number or parameter that specifies the desired
               lower limit;
          <n2> is a number or parameter that specifies the desired
               upper limit;
    and   <prefix> is one of the following:
               X             refers to vertical axis
               Y             refers to horizontal axis
               no prefix     refers to both axes.
 
Examples:
    LIMITS 0.5 4.5
    XLIMITS 0 100
    YLIMITS 0 100
    XLIMITS A B
 
Note:
    The ...LIMITS command with no argument reverts the limits to the
    default.  A ...LIMITS command with no prefix refers to both axes.
    Thus LIMITS 3 7 sets the limits for both axes to 3 and 7.
 
Default:
    Automatically computed neat limits based on the data.
 
Synonyms:
    None
 
Related Commands:
    PLOT        = Generates a data or function plot.
    MINIMUM     = Sets the frame minima for all plots.
    MAXIMUM     = Sets the frame maxima for all plots.
    CLASS UPPER = Sets the upper class maximum for histograms,
                  frequency plots, and pie charts.
    CLASS LOWER = Sets the lower class minimum for histograms,
                  frequency plots, and pie charts.
    CLASS LOWER = Sets the class width for histograms, frequency plots,
                  and pie charts.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE LIMITS COMMAND
    X1LABEL LEAD
    Y1LABEL POTASSIUM
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    .
    XLIMITS 50 600
    XTIC OFFSET 10 15
    YLIMITS 50 450
    .
    PLOT POT VS LEAD
 
-----LIMITS OF DETECTTION ---------------------------------------

LIMITS OF DETECTION
 
Name:
    LIMITS OF DETECTION
 
Type:
    Analysis Command
 
Purpose:
    Perform a limits of detection (LOD) analysis based on the ASTM E-2677
    standard.
 
Description:
    There are a number of approaches to determining a limits of
    detection.  This command implements the method given in

        E2677 - 14 "Standard Test Method for Determining Limits of
        Detection in Explosive Trace Detectors," ASTM International,
        100 Barr Harbor Drive, PO BOX C700, West Conshohoceken, PA
        19428-2959, USA.

    The mathematical basis for this method is given in

        Rukhin, A. L. and Samarov, D. V., "Limit of Detection Determination
        for Censored Samples," Chemometrics and Intelligent Laboratory
        Systems, Vol 105, 2011, pp. 188-194.

    Although this method was developed in the context of explosive trace
    detectors, its use is not limited to this application.  We do not
    give the detailed mathematical formulation here (see the Rukhin and
    Samarov paper).  The following is a brief discussion of this standard.

    ASTM subcommittee E54.01 has developed a Standard Test Method for the
    determination of Limit of Detection (LOD) in trace explosive detectors.
    The Method was developed following ISO-IUPAC guidelines that harmonize
    concepts of detection limits and considers the observed behaviors of
    response signals in a wide range of trace detectors. Here, the LOD90
    is defined as the lowest amount of a particular substance for which
    there is 90% confidence that a single measurement will have a true
    detection probability of at least 90% while the true non-detection
    probability of a realistic process blank is at least 90%. The LOD90
    value is therefore a directly useful metric of trace detector
    performance and reliability, since the value reflects the practical
    detection capability of the detector system, influenced by the inherent
    sensitivity, selectivity, and response variability of the system under
    realistic deployment conditions.

    The standard specifies the LOD90 value which is based on a false
    positive probability of 10%.  You can specify an arbitrary false
    positive probability level by entering the command

        LET ALPHA = <value>

    The most typical values for ALPHA are 0.10 (LOD90), 0.05 (LOD95), or
    0.01 (LOD99) with the default being 0.10.

    Ideally, the data for the limits of detection should include a large
    number of process blank replicates as well as detector responses from
    a large number of replicates from two mass levels closely straddling
    the actual LOD90 mass level.

    By this strategy, the Method is insensitive to many pitfalls that are
    encountered in commercial trace detectors, including detector response
    saturation, truncated response distributions, and response
    heteroscedasticity, i.e. changes in response variation with signal
    level.  Practicalities dictate, however, that a limited number of
    replicates be analyzed and that mass levels be selected that are wide
    enough apart to guarantee the straddling of the unknown LOD90 value.
    By setting the minimum number of required replicates to ten, and by
    utilizing a short sequence of mass levels that increase by a factor
    of three, data for the calculation of an adequate LOD90 estimate may
    be obtained. This limits of detection method has been tested and
    validated with real and simulated data possessing several types of
    error structure.

    The data for the limits of detection command must be replicated
    mass-response pairs with the following requirements:

        1. at least 10 replications per level
        2. at least three distinct levels, including one for process
           blank response (mass = 0)

    Dimensional units for mass levels and responses, while not identified,
    must be consistent.  The limit of detection is reported in the same
    dimensional units as the mass inputs.

    Before calculating the limit of detection, the following data quality
    checks are performed (the limits of detection will not be calculated
    if these conditions are not satisfied):

        1. Less than 10 replicates in any level
        2. Less than three distinct levels
        3. Absence of a process blank level (mass = 0)
        4. Unequal number of values for the mass and the the repsonse
        5. Responses in the highest mass level are not significantly
           different from those in the process blank level

    If data quality passes, estimates will be returned for the limit of
    detection and the 90% upper confidence LOD90 limit (a measure of
    uncertainty).  Results may also be returned with a message that data
    quality was marginal, and offer a suggestion for improving the quality.

    The LOD90 value determined is the best estimate of the minimum mass of
    a particular analyte required to elicit a real and reliable response
    in the detector tested. This minimum detector response is the Critical
    Value (CV, an optional printed output), which should relate to the
    peak detection threshold value that can usually be set manually in the
    trace detector. The peak detection threshold value is usually set
    higher than the CV unless the LOD90 is determined using realistic
    chemical background. 

    Caveat: The LOD90 determination assumes normality for the non-zero
    measurements.  If your data is not normal or contains significant
    outliers, the LOD90 value will still be calculated.  However,
    non-normality or outliers can result in larges biases for the LOD90
    estimate.  Measurement data is often skewed right.  In this case, you
    may want to take the log of the non-zero values before using the
    LIMITS OF DETECTION command (i.e., a lognormal model of the data might
    be more realistic than a normal model).

    To check for outliers and non-normality, the following analyses and
    graphs may be useful.

       1. Perform a Grubbs test for a single outlier for each level of the
          mass for the non-zero measurements.

       2. Generate a scatter plot of the measurements against their
          associated mass levels.

       3. Generate a multiplot showing a normal probability plot of the
          non-zero measurements for each distinct level of the mass.

    In addition to the LOD value and confidence limit, two tables are
    generated.

        1. The first table provides a summary of the number of zero
           and non-zero response values, the mean, and the standard
           deviation for each mass level.

        2. The second table contains estimates obtained from the LOD
           computations for each mass level.  The last 4 columns are of
           particular interest.

             a. Column 4 contains the LOD estimate based on the cumulated
                sample.  The final LOD90 estimate should be one of the
                values from this column.

             b. Column 5 contains the standard error of the LOD estimate
                in Column 4.

             c. Column 6 contains the 90% upper confidence limit of the
                LOD value.

             d. Column 7 contains an upper tolerance limit on the LOD.

Syntax 1:
    LIMITS OF DETECTION <y> <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <x> is a variable containing the mass levels;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    Although it is typical for the data to be sorted by the value of
    the mass level, this is not required.  The <y> and <x> variables
    must have the same length.

Syntax 2:
    REPLICATED LIMITS OF DETECTION <y> <x> <batch>
                                   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <x> is a variable containing the mass levels;
          <batch> is a group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax can be used when multiple analytes are being tested.
    Each distinct value of <batch> denotes a specific analyte for which
    a limit of detection will be computed.  So if <batch> has three
    distinct values, three limit of detection computations will be
    performed.

    Although it is typical that the data be sorted by the value of the
    group-id variable and for the data within a specific group to be
    sorted by the mass level, this is not required.  The <y>,  <x> and
    <batch> variables must have the same length.

    The word REPLICATION is optional.  If exactly three variables are
    specified, the REPLICATION option is assumed.

Syntax 3:
    MULTIPLE LIMITS OF DETECTION <y1> ... <yk> <x>
                                 <SUBSET/EXCEPT/FOR qualification>
    where <y1> ... <yk> is a list of 1 to 30 response variables;
          <x> is a variable containing the mass levels;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax can be used when multiple analytes are being tested.
    Note that this syntax assumes each analyte has the same mass
    variable.  If this is not the case, the REPLICATED syntax should
    be used.

    Although it is typical for the data to be sorted by the value of
    the mass level, this is not required.  All the variables must have
    the same length.

    For this syntax, the word MULTIPLE is required.

Examples:
    LIMITS OF DETECTION Y X
    REPLICATED LIMITS OF DETECTION Y X GROUP
    LIMITS OF DETECTION Y X GROUP
    MULTIPLE LIMITS OF DETECTION Y1 Y2 Y3 Y4 Y5 X
    MULTIPLE LIMITS OF DETECTION Y1 TO Y5 X
    ONE SAMPLE PROFICIENCY TEST Y  LABID
    TWO SAMPLE PROFICIENCY TEST Y1  Y2  LABID

Note:
    The following commands can be used to specify variuous probability
    levels

         LET ALPHA = <value>
                   = probability of a false positive (no signal, alarm)
         LET BETA  = <value>
                   = probability of a false negative (signal, no alarm)
         LET GAMMA = <value>
                   = confidence level for the LOD and the tolerance bound
         LET PA    = <value>
                   = the coverage level for the tolerance bound

    The default for all four of the above is 0.10.  Values greater than
    0.5 are interpreted as 1 - the value (i.e., entering .9 is equivalent
    to entering 0.1).

    Some instruments may provide a vendor supplied critical value.  To
    specify a pre-defined critical value, enter

         LET CRITICAL VALUE = <value>

    If no critical value is given, the critical value is estimated from
    the data.  This value should typically only be given if supplied by
    the vendor for a specific instrument.

    The data quality checks are typically based on 90% of the values being
    either zero or 90% of the values being non-zero.  To specify a
    different threshold percentage for the data quality checks, enter

         LET THRESPR = <value>

    where <value> is between 80 and 100.  Values between 90 and 100 are
    most common and a value outside the (80,100) interval will be set to
    the default of 90.

    The defaults for all of the above parameters are those specified in
    the E-2677 standard.

Note:
    The following commands can be used to control what output is returned
    from the LIMITS OF DETECTION command

        SET LOD SUMMARY TABLE <ON/OFF>
        SET LOD TABLE <ON/OFF>

    To specify whether the critical value is printed, enter

        SET LOD PRINT CRITICAL VALUE <ON/OFF>

    All of the above are ON by default.

Note:
    There are two methods for computing the critical value from the
    data.  One is based on quantiles of the data and the other is
    based on the quantile of a normal distribution.  To specify which
    method to use, enter

        SET LOD CRITICAL VALUE <QUANTILE/NORMAL>  (ilodcv)

    The default is QUANTILE.

Note:
    By default, Dataplot writes the values from the Summary Table to
    dpst1f.dat and the values from the LOD Table to dpst2f.dat.  You
    can control whether the dpst1f.dat and dpst2f.dat files are
    generated by entering

        SET LOD OUTPUT FILES <ON/OFF>

    The default is ON.  Note that if the REPLICATION or MULTIPLE option
    is used to generate multiple limits of detection analyses, only the
    last limit of detection analysis will be contained in dpst1f.dat and
    dpst2f.dat.

Note:
    By default, Dataplot saves the following parameters

        LOD    = The LOD value.
        LODSE  = The standard error of the LOD value.
        LODCV  = The critical value.
        LODUCL = The upper confidence limit for the LOD value.

    If you use the MULTIPLE or REPLICATION options, these values are
    written to dpst3f.dat instead.  Each row of dpst3f.dat will contain
    the values for a specific limits of detection analysis.

Note:
    You can use the CAPTURE HTML command to generate these tables in
    HTML format.  You can use the CAPTURE LATEX command to generate
    these tables in Latex format.  You can use the CAPTURE RTF command
    to generate these tables in Rich Text Format (RTF).

Note:
    A unique feature of this standard is that a web-based calculator
    is defined as part of the standard.  This web-based calculator uses
    Dataplot as the computational back-end to generate the limits of
    detection analysis and to generate the supplementatry graphs and
    outlier analysis.

    The URL for this web-based calculator is

        https://www-s.nist.gov/loda/index.html

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    E691 INTERLAB      = Perform an interlaboratory analysis based on
                         E-691.
    PROFICIENTY TEST   = Perform one sample or two sample proficiency
                         test based on ASTM E-2489.
    GRUBBS TEST        = Perform a Grubbs outlier test.
    NORMAL PROB PLOT   = Generate a normal probability plot.
    CAPTURE HTML       = Generate output in HTML format.
    CAPTURE LATEX      = Generate output in Latek format.
    CAPTURE RTF        = Generate output in RTF format.

Reference:
    Rukhin, A. L. and Samarov, D. V., "Limit of Detection Determination
    for Censored Samples," Chemometrics and Intelligent Laboratory
    Systems, Vol 105, 2011, pp. 188-194.

    E2677 - 14 "Standard Test Method for Determining Limits of
    Detection in Explosive Trace Detectors," ASTM International,
    100 Barr Harbor Drive, PO BOX C700, West Conshohoceken, PA
    19428-2959, USA.

    Currie, L.A. (1999), "Detection and quantification limits: origins
    and historical overview," Analytica Chimica Acta 391, 103-134.

Applications:
    Detection Limits
 
Implementation Date:
    2009/08
    2011/01: Allow user-specified crtical value
    2012/01: Options for which outputs are printed
    2014/03: E2677 adopted, a few tweaks in the output
             to be consistent with the standard
    2018/07: Modified to accomodate negative response values
    2018/11: Support for REPLICATION/MULTIPLE options
    2018/11: A few minor tweaks in the output format
 
Program 1:
    . Step 1:   Read the data
    .
    dimension 40 columns
    skip 25
    set read format f4.0,2f15.1,4f15.0
    read std_lod.dat x y1 to y6
    skip 0
    set read format
    .
    . Step 2:   Run the limits of detection command
    .           and the Grubbs test for outliers
    .
    set write decimals 4
    limits of detection y1 x
    print " "
    print " "
    replicated grubbs test y1 x  subset y1 > 0
    .
    . Step 3:   Generate the scatter plot of the data
    .
    character x all
    line blank all
    label case asis
    y1label displacement 10
    x1label Mass Level
    y1label Measurement Response
    tic offset units screen
    tic offset 5 5
    plot y1 x
    label
    tic offset units
    tic offset 0 0
    .
    . Step 4:   Generate the scatter plot of the data but
    .           restrict plot to levels around critical value
    .
    .           Determine smallest level with
    .
    .           1.  All response values greater than the critical value
    .           2.  First mass level greater than LOD value
    .
    set let cross tabulate collapse
    let yminv = cross tabulate minimum y1 x
    let xd = distinct x
    let xd = sort xd
    let nd = size xd
    let nval1 = 0
    let nval1 = size yminv subset yminv < lodcv
    let nval1 = nval1 + 1
    .
    let nval2 = nd
    loop for k = 1 1 nd
        let aval = xd(k)
        if aval > lod
           let nval2 = k
           break loop
        end of if
    end of loop
    .
    let nval = max(nval1,nval2)
    let xval = xd(nval)
    let xval = max(xval,lod)
    let lodrnd = round(lod,2)
    let cvrnd = round(lodcv,2)
    .
    character x all
    character hw 2.0 1.50 all
    line blank all
    label case asis
    y1label displacement 10
    x1label Mass Level
    y1label Measurement Response
    title Critical Value: ^cvrnd, LOD: ^lodrnd
    tic offset units screen
    tic offset 5 5
    plot y1 x   subset x <= xval
    line dash
    line color red
    drawsdsd 15 lodcv 85 lodcv
    drawdsds lod 20 lod 90
    line blank
    line color black
    label
    title
    character hw 1.0 0.75 all
    tic offset units
    tic offset 0 0
    .
    . Step 5:   Generate a normal probability plot for the levels 
    .
    let ymin = minimum y1
    let ytemp = y1
    let xtemp = x
    if ymin >= 0
       retain ytemp xtemp subset ytemp > 0
    end of if
    let xdist = distinct xtemp
    let xdist = sort xdist
    let ndist = size xdist
    .
    let ntemp = sqrt(ndist)
    let ntemp = int(ntemp+1)
    let nrow = ntemp
    let ncol = ntemp
    if ndist <= 9
       let nrow = 3
       let ncol = 3
    end of if
    if ndist <= 6
       let nrow = 2
       let ncol = 3
    end of if
    if ndist <= 4
       let nrow = 2
       let ncol = 2
    end of if
    .
    multiplot nrow ncol
    multiplot scale factor nrow
    multiplot corner coordinates 5 5 100 95
    .
    line blank all
    character circle all
    character fill on all
    character hw 1.0 0.75 all
    title offset 2
    title case asis
    justification left
    .
    loop for k = 1 1 ndist
        let aval = xdist(k)
        title Mass Level = ^aval
        normal probability plot ytemp subset xtemp = aval
        let cc = round(ppcc,3)
        let ntemp = size ytemp subset xtemp = aval
        let cccv = norppcv(ntemp,0.05)
        move 17 85
        text PPCC: ^cc
        move 17 80
        let cccv = round(cccv,3)
        text PPCC 5% CV: ^cccv
    end of loop
    end of multiplot
    justification center
    move 50 97
    case asis
    text Normal Probability Plots of the Non-Zero Measurements

Program 2:
    skip 25
    set read format f4.0,2f15.1,4f15.0
    read std_lod.dat x y1 to y6
    skip 0
    set read format
    .
    set write decimals 4
    multiple limits of detection y1 y2 y3 y4 y5 y6 x

-----LINEAR COMBINATION (LET)----------------------------------------
 
LINEAR COMBINATION
 
Name:
    LINEAR COMBINATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the linear combination of a matrix and a vector.
 
Description:
    If a matrix M has p columns and n rows and C is a vector
    with p rows, then the linear combination of M and C is
    defined as:

         Y = c(1)*M1 + C(2)*M2 + c(3)*M3 + ... +c(p)*Mp

    where M1, M2, ... , Mp are the columns of M.  The result
    Y is a vector with n rows.

    Linear combinations are common in statistics, particularly in
    linear models and multivariate analysis.  In Dataplot
    applications, the LINEAR COMBINATION command is most typically
    used as an intermediate calculation in a larger macro.
 
Syntax:
    LET <y> = LINEAR COMBINATION <mat1>  <x>
    where <mat1> is a matrix for which the linear combination is to
              be computed;
          <x> is a vector for which the linear combination is to
              be computed;
    and where <mat2> is a matrix where the resulting linear 
             combination is saved.
 
Examples:
    LET A = LINEAR COMBINATION M X
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    READ MATRIX               = Read a matrix.
    MATRIX COLUMN DIMENSION   = Dimension maximum number of columns
                                for Dataplot matrices.

    MATRIX MEAN               = Compute the overall mean for a matrix.
    MATRIX COLUMN STATISTIC   = Compute column statistics for a
                                matrix.
    MATRIX ROW STATISTIC      = Compute row statistics for a matrix.
    QUADRATIC FORM            = Compute quadratic form of a
                                matrix and a vector.
 
Reference:
    "Applied Multivariate Statistical Analysis", Third Edition,
    Johnson and Wichern, Prentice-Hall, 1992.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    1998/8
 
Program:
    .  Perform a Fisher's dsicriminant analysis on Iris data.
    .
    .  READ DATA,  3 GROUPS (N1=N2=N3=3), 2 VARIABLES
    FEEDBACK OFF
    DIMENSION 200 COLUMNS
    SKIP 25
    READ IRIS.DAT SEPLENG SEPWIDTH PETLENG PETWIDTH TAG
    SKIP 0
    LET NTOT = SIZE SEPLENG
    LET X = MATRIX DEFINITION SEPLENG NTOT 4
    LET P = MATRIX NUMBER OF COLUMNS X
    .
    LET GROUPID = DISTINCT TAG
    LET NG = SIZE GROUPID
    LET XMGRAND = MATRIX COLUMN MEANS X
    .
    .  CALCULATE B0 = SUM (I=1,NG) (XBARi - XBARALL)(XBARi-XBARALL)'
    .
    LET DIAG = 0 FOR I = 1 1 P
    LET B0 = DIAGONAL MATRIX DIAG
    .
    LOOP FOR K = 1 1 NG
       LET N^K = SIZE TAG SUBSET TAG = K
       LET XMEANI = MATRIX COLUMN MEANS X SUBSET TAG = K
       LET XMEANI= XMEANI - XMGRAND
       LET B0TEMP = VECTOR TIMES TRANSPOSE XMEANI
       LET B0 = MATRIX ADDITION B0 B0TEMP
    END OF LOOP
    .
    .  CALCULATE Spooled = (N1-1)S1 + .. + (Ng-1)Sg)/(N1+ .. + Ng - g)
    LET SPOOL = POOLED VARIANCE-COVARIANCE MATRIX X TAG
    LET DENOM = NTOT - NG
    LET WINVB = MATRIX MULTIPLICATION SPOOL DENOM
    LET WINVB = MATRIX INVERSE WINVB
    LET WINVB = MATRIX MULTIPLICATION WINVB B0
    .
    .  COMPUTE EIGENVALUES AND SORT IN DECREASING ORDER
    .  COMPUTE EIGENVECTORS, ONLY KEEP REAL COMPONENT, SORT
    .
    LET E = MATRIX EIGENVALUES WINVB
    LET EV = MATRIX EIGENVECTORS WINVB
    LET INDX = SEQUENCE 1 1 P
    RETAIN E FOR I = 1 1 P
    LET ESORT = SORTC E INDX
    LET REVERSE = SEQUENCE P 1 1
    LET REVERSE = SORTC REVERSE ESORT INDX
    LET EVECT = DIAGONAL MATRIX DIAG
    .  NORMALIZE L'SpooledL =1
    .  DIST = L'SpooledL, MULTIPLY EIGENVECTOR BY 1/SQRT(DIST)
    LOOP FOR K = 1 1 P
        LET LTAG = INDX(K)
        RETAIN EV^K  FOR I = 1 1 P
        LET EVECT^LTAG = EV^K
        LET DIST = QUADRATIC FORM SPOOL EVECT^LTAG
        LET EVECT^LTAG = (1/SQRT(DIST))*EVECT^LTAG
    END OF LOOP
    .  PLOT FIRST 2 DISCRIMINANTS
    LET ZY = LINEAR COMBINATION X EVECT1
    LET ZX = LINEAR COMBINATION X EVECT2
    DEVICE 1 OFF
    MEAN PLOT ZY TAG
    LET GMEANY = YPLOT
    MEAN PLOT ZX TAG
    LET GMEANX = YPLOT
    RETAIN GMEANX GMEANY SUBSET TAGPLOT = 1
    DEVICE 1 ON
    Y1LABEL FIRST DISCRIMINANT
    X1LABEL SECOND DISCRIMINANT
    CHARACTER CIRCLE SQUARE TRIANGLE
    LINE BLANK ALL
    LEGEND 1 CIRC() - SPECIES 1
    LEGEND 2 SQUA() - SPECIES 2
    LEGEND 3 TRIA() - SPECIES 3
    LEGEND FONT DUPLEX
    LEGEND SIZE 1.2
    TITLE PLOT FIRST 2 DISCRIMINANT FUNCTIONS
    PLOT ZY ZX TAG
    PRINT "FISHER's DISCRIMINANT ANALYSIS"
    PRINT " "
    PRINT " "
    PRINT "B0 MATRIX (= between group sums of cross-products):"
    PRINT B0
    PRINT " "
    PRINT " "
    PRINT "POOLED VARIANCE-COVARIANCE MATRIX:"
    PRINT SPOOL
    PRINT " "
    PRINT " "
    PRINT "EIGENVALUES:"
    PRINT ESORT
    PRINT " "
    PRINT " "
    PRINT "COLUMNS ARE THE DISCRIMINANT FUNCTIONS:"
    PRINT EVECT
    PRINT " "
    PRINT " "
    PRINT "GROUP MEANS:"
    PRINT GMEANX GMEANY
 
-----LINEAR CORRELATION PLOT-------------------------------------
 
LINEAR CORRELATION PLOT
 
Name:
    LINEAR CORRELATION PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a (linear) correlation plot.
 
Description:
    A linear correlation plot consists of subsample correlations versus
    subsample index.  The subsample correlation is the usual Pearson
    product-moment correlation coefficient between 2 user-specified
    variables for the data in the subsample.  The linear correlation
    plot is used to answer the question--"Does the correlation between
    2 variables hold equally well from one subsample to the next?  In
    other words, does the linear relatedness of the 2 variables change
    from one subsample to the next?  It consists of:
       Vertical   axis = subsample correlation from a linear fit;
       Horizontal axis = subsample index.
    The linear correlation plot yields 2 traces:
       1. a subsample correlation trace; and
       2. a full-sample correlation reference line.
    Like usual, the appearance of these 2 traces is controlled by
    the first 2 settings of the LINES, CHARACTERS, SPIKES, BARS,
    and similar attributes.
 
Syntax:
    LINEAR CORRELATION PLOT   <y1>   <y2>   <x>
                      <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a response (= dependent) variable;
          <y2> is another response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
               appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LINEAR CORRELATION PLOT Y1 Y2 X
    LINEAR CORRELATION PLOT PRES TEMP DAY
    LINEAR CORRELATION PLOT CONC YEAR MONTH
    LINEAR CORRELATION PLOT FATALITIES MONTH STATE
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINEAR SLOPE PLOT       = Generates a linear slope plot.
    LINEAR INTERCEPT PLOT   = Generates a linear intercept plot.
    LINEAR RESSD PLOT       = Generates a linear residual standard
                              deviation plot.
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    FIT                     = Carries out a least squares fit.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    88/3
 
Program:
    LET Y1 = DATA 2 4 7 11 15 18 25.1 25.3 25.9
    LET Y2 = DATA 10 20 30 10 20 30 10 20 30
    LET X = DATA 1 1 1 2 2 3 3 3 3
    TITLE AUTOMATIC
    TIC OFFSET 0.2 0.2
    LINE BLANK DASH
    CHARACTER X BLANK
    Y1LABEL CORRELATION
    X1LABEL SAMPLE ID
    LINEAR CORRELATION PLOT Y1 Y2 X
 
-----LINEAR CORRELATION (LET)--------------------------
 
LINEAR CORRELATION
 
Name:
    LINEAR CORRELATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the correlation from a linear least squares fit between
    two variables.
 
Syntax:
    LET <par> = LINEAR CORRELATION <y> <x>
                                   <SUBSET/EXCEPT/FOR qualification>
    where <y> is dependent response variable;
          <x> is the independent response variable;
          <par> is a parameter where the correlation value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A1 = LINEAR CORRELATION Y X
    LET A1 = LINEAR CORRELATION Y X  SUBSET X > 1
 
Note:
    Dataplot's built-in statistics can be used with a number of
    commands.  For details, enter HELP STATISTIC.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINEAR SLOPE SD       = Compute the standard deviation of the slope
                            parameter from a linear least squares fit.
    LINEAR INTERCEPT      = Compute the intercept from a linear least
                            squares fit.
    LINEAR INTERCEPT SD   = Compute the standard deviation of the intercept
                            parameter from a linear least squares fit.
    LINEAR SLOPE          = Compute the slope from a linear least squares
                            fit.
    LINEAR RESSD          = Compute the residual standard deviation from
                            a linear least squares fit.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    1988/3
 
Program 1:
    SKIP 25
    READ BERGER1.DAT Y X
    LET A = LINEAR CORRELATION Y X
 
Program 2:
    SKIP 25
    READ BERGER1.DAT Y X BATCH
    .
    LABEL CASE ASIS
    TITLE CASE ASIS
    Y1LABEL Correlation
    X1LABEL Batch
    TITLE Linear Correlation Plot
    CHARACTER X BLANK
    LINE BLANK SOLID
    TIC OFFSET UNITS SCREEN
    TIC MARK OFFSET 3 3
    LINEAR CORRELATION PLOT Y X BATCH

-----LINEAR FIT----------------------------------------------------
 
LINEAR FIT
 
Name:
    ... FIT
 
Type:
    Analysis Command
 
Purpose:
    Estimate the parameters for a linear, polynomial, or multi-linear
    least squares fit.
 
Description:
    The Dataplot FIT command can fit either non-linear models or
    linear (including polynomial and multi-linear) models.

    Non-linear models are specified by entering an equation (e.g.,
    FIT Y = A + B*X).  For non-linear fits, Dataplot uses an iterative
    modified Levenberg-Marquardt algorithm.  Although this algorithm can
    handle linear and polynomial models, using non-iterative methods
    specifically designed for linear models are both more efficient and
    allow additional diagnostics to be computed.  The non-iterative
    fit method is described here (the help for the non-linear fit can
    be accessed with the HELP FIT command).

    When the FIT command gives a list of variables without a functional
    equation, the non-iterative (linear) algorithm is used.

    For linear fits, Dataplot adopted the fitting code from the
    OMNITAB II statistical program.  This is a modified Gramm-Schmidt
    with iterative refinement algorithm.  The Gramm-Schmidt algorithm
    is based on the QR decomposition and is intended for full rank
    models.  Since Gramm-Schmidt algorithms and QR decompositions are
    well documented in the literature, we do not give the mathematical
    details here.

    For linear fits, the FIT command generates the following output.

    1) A table containing the parameter estimates, the parameter standard
       deviations, and the parameter t-values is printed.  The t-value is
       used to determine if a given paramater is statistically
       significant.

       These values are also written to the file dpst1f.dat.  In addition,
       lower and upper Bonferroni joint confidence limits for the
       parameters are written to dpst1f.dat with a 5E15.7 format.  By
       default, 95% intervals are used for the Bonferroni intervals.  You
       can define the parameter ALPHA to change the significance level.
       For example, to use 90% intervals, enter the command:

           LET ALPHA = 0.9

       To read these values into Dataplot variables, enter the command

            SKIP 1
            READ DPST1F.DAT COEF COEFSD TVAL BONL BONU

    2) The following are written to the file dpst2f.dat

           Column 1: standard deviations of the predicted values
           Column 2: 95% lower confidence limit for the predicted values
           Column 3: 95% upper confidence limit for the predicted values
           Column 4: 99% lower confidence limit for the predicted values
           Column 5: 99% upper confidence limit for the predicted values
           Column 6: 95% lower joint Bonferroni confidence limit for the
                     predicted values
           Column 7: 95% upper joint Bonferroni confidence limit for the
                     predicted values
           Column 8: 95% lower joint Hotelling confidence limit for the
                     predicted values
           Column 9: 95% upper joint Hotelling confidence limit for the
                     predicted values

       These values are written with a 9E15.7 format.  By default, 95%
       intervals are used for the Bonferroni and Hotelling intervals.  You
       can define the parameter ALPHA to change the significance level.
       For example, to use 90% intervals, enter the command:

           LET ALPHA = 0.9

       To read these values into Dataplot after the FIT, enter the
       command

           SKIP 1
           SET READ FORMAT 9E15.7
           READ DPST2F.DAT PREDSD PRED95LL PRED95UL PREDBLL PREDBUL ...
                           PREDHLL PREDHUL

    3) The following are written to the file dpst3f.dat

       The variables written to this file are used in "regression
       diagnostics".  More will be said about this later.

           Column 1: the diagonals of the hat matrix (the hat matrix is
                     X(X'*X)X' where X' is the transpose of the X
                     matrix).  In themselves, the diagonal elements are
                     measures of the leverage of a given point.  The
                     minimum leverage is (1/N), the maximum leverage is
                     1.0 and the average leverage is (P/N) where P is
                     the number of variables in the fit.  These elements
                     are also used to calculate many other diagnostic
                     statistics.  Note that

                     H(ii) = VAR(Predicted value)/Residual Variance

           Column 2: the variance of the residuals.

                      VAR(res) = MSE*(1 - H(ii))

           Column 3: the standardized residuals.  These are the residuals
                     divided by the square root of the mean square error.

                     STRES = Residual/SQRT(MSE)

           Column 4: the internally studentized residuals.  These are
                     the residuals divided by their standard deviations.

           Column 5: the deleted residuals.  These are residuals obtained
                     from subtracting the predicted values with the ith
                     case omitted from the observed value.

           Column 6: the externally studentized residuals.  These are the
                     deleted residuals divided by their standard
                     deviation.

           Column 7: Cook's distance.  This is a measure of the
                     impact of the ith case on all of the estimated
                     regression coefficients.

                     Cook = (res**2/(p*MSE))*H(ii)/(1 - H(ii))**2

           Column 8: DFFITS = EXTSRES*SQRT(H(ii)*(1 - H(ii))

       Additional diagnostic statistics can be computed from these
       values.  Several of the texts in the REFERENCE section
       below discuss the use and interpretation of these statistics
       in more detail.  These variables can be read in as follows:

            SKIP 1
            SET READ FORMAT 8E15.7
            READ DPST3F.DAT HII VARRES STDRES ISTUDRES DELRES ...
                            ESTUDRES COOK DFFITS
            SKIP 0

       For more disucssion of how these variables can be used, enter

            HELP REGRESSION DIAGNOSTICS

    4) The variance-covariance matrix of the parameters and the inverse
       of the (X'*X) matrix are written to the file dpst4f.dat.  These
       values can be used in deriving additional statistics, intervals
       and tests.  The use of these matrices is demonstrated in the
       Program example given in the HELP REGRESSION DIAGNOSTICS section.

       To read these, you can do the following

           SKIP 1
           READ DPST4F.DAT TEMP1 TEMP2
           LET P = 2; . P denotes the number of parameters
           LET S2B    = VARIABLE TO MATRIX TEMP1 P
           LET XTXINV = VARIABLE TO MATRIX TEMP2 P

    5) A regression ANOVA table is written to dpst5f.dat.  In addition
       to the ANOVA table, the R**2, adjusted R**2, and Press P statistic
       are printed.  These three parameters are also saved as the
       internal parameters RSQUARE, ADJRSQUA, and PRESSP, respectively.

       To view the ANOVA table, enter

           LIST dpst5f.dat

       Starting with the August 2021 version, the following values
       printed in the ANOVA table are now saved as internal parameters

          RESSS   - the residual sum of squares
          SSREG   - the regression sum of squares
          SSTOTAL - the total sum of squares
          MSE     - the mean square error
          MSR     - the mean square of the regression
          FSTAT   - the value of the F statistic
          FCV95   - the 95% critical value for the F statistic
          FCV99   - the 99% critical value for the F statistic

    6) The residual standard deviation and its corresponding degrees of
       freedom are are stored in the parameters RESSD and RESDF,
       respectively.  RESDF is the number of observations minus the
       number of independent variables in the fit (including the
       constant term).  The formula for RESSD is:

            RESSD = SQRT(SUM(Y - PREDICTED VALUE)**2)/RESDF)

    7) If there is replication in the independent variables, the
       replication standard deviation and corresponding degrees of
       freedom are printed.  In addition, a lack of fit F test is
       performed.  These are stored in the parameters REPDF, REPSD, and
       LOFCDF respectively.  The formulas are:

             REPDF = SUM(number of observations in replication - 1)
             REPSD = SQRT(SUM((Y - replication mean)**2)/REPDF)
 
    8) Dataplot saves the predicted values from a fit in the variable
       PRED and the residual values in the variable RES.  These variables
       can be used in subsequent LET and PLOT commands to generate
       diagnostic plots of residuals and predicted values.

Syntax:
    <d>  FIT  <y>  <x1> ... <xk>  <SUBSET/EXCEPT/FOR qualification>
    where <d> is the optional specification of the desired degree:
              LINEAR    or FIRST-DEGREE  (the default)
              QUADRATIC or SECOND-DEGREE
              CUBIC     or THIRD-DEGREE
              QUARTIC   or FOURTH-DEGREE
              QUINTIC   or FIFTH-DEGREE
              SEXTIC    or SIXTH-DEGREE
              SEPTIC    or SEVENTH-DEGREE
              OCTIC     or EIGHT-DEGREE
              NONIC     or NINTH-DEGREE
              DEXIC     or TENTH-DEGREE;
          <y> is the response (= dependent) variable;
          <x1> ... <xk> is a list of 1 to 35 independent variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The estimated parameters are stored in A0, A1, ... , Ak.

    If <d> is omitted, a linear fit is performed.  In practice, the
    linear and quadratic fits receive heavy use while the other degrees
    are rarely used.
 
Examples:
    FIT Y X
    LINEAR FIT Y X
    FIT Y X1 X2 X5
    FIT Y X1 X2 X5  SUBSET TAG > 1
    QUADRATIC FIT PRESSURE TEMP
    CUBIC FIT V R
 
Note:
    Weighted fits are typically used in the following two situations.

       1. Weighting is one approach for dealing with non-constant
          variation in the residuals.  It is not uncommon for the
          variance of the residuals to increase for the largest (or
          smallest) values of the independent variable.  In this case,
          weights can be used to give less weight to the less precise
          measurements.  The NIST/SEMATECH e-Handbook contains a
          disucssion of weighted fits and an example of using weights
          to address non-constant variation in the following pages

          https://www.itl.nist.gov/div898/handbook/pmd/section4/pmd432.htm
          https://www.itl.nist.gov/div898/handbook/pmd/section6/pmd625.htm

       2. Weights can also used to implement certain types of robust
          fitting.  In this case, weights are used to down weight
          observations based on the size of the associated residual.
          Outlier observations can sometimes distort a fit (i.e., in
          trying to fit the outlier point(s), the bulk of the data
          is poorly fit).  Weighting based on the residuals can often
          provide a good fit to the bulk of the data without eliminating
          the outlier observations from the analysis.

          Enter HELP WEIGHTS and HELP BIWEIGHT for examples of this
          use of weighted fits in Dataplot.

    To specify weights for a least squares fit, enter the command

         WEIGHTS <var>

    where <var> is a variable containing the weights.

    Note that the RES variable contains the absolute value of the
    residuals after the fit.  For residual plots and analysis, it
    may be preferrable to work with the weighted residuals.  You can
    create this with the command

         LET RESW = W*RES

    where W contains the weight variable.

Note:
    When there are a large number of independent variables, subset
    selection procedures are often employed to identify the best
    candidate models.  The BEST CP command can be used to perform a
    "best subsets" analysis based on Mallows C(p).  Enter HELP BEST CP
    for details.

    Another approach is to generate principal components of the
    independent variables and to perform the fit the based on the
    first several principal components.  Although this approach can
    reduce problems introduced by multi-colinearity, the downside is
    that the model may be less interpretable.

Note:
    Dataplot supports the following plots:

        PARTIAL RESIDUAL PLOT
        PARTIAL REGRESSION PLOT
        PARTIAL LEVERAGE PLOT
        CCPR PLOT

    Enter HELP PARTIAL RESIDUAL PLOT, PARTIAL REGRESSION PLOT,
    HELP PARTIAL LEVERAGE PLOT, or HELP CCPR PLOT for details.  The
    Program example in the HELP REGRESSION DIAGNOSTICS also gives
    an example of using these plots.

Note:
    The following matrix commands can be useful in regresssion
    diagnostics:

        LET VIF = VARIANCE INFLATION FACTORS
        LET C = CONDITION INDICES X
        LET XTXINV = XTXINV MATRIX X
        LET C = CATCHER MATRIX X

    The Program example in the HELP REGRESSION DIAGNOSTICS also gives
    an example of using these commands.

Note:
    For multi-linear fits, enter the following command to omit the
    constant term from the model

        SET FIT ADDITIVE CONSTANT OFF

    To restore the default of including the constant term, enter

        SET FIT ADDITIVE CONSTANT ON

Note:
    Data transformations are often used to improve the quality of the
    fit.  For example, some types of non-linear fits can be restated as
    linear fits with an appropriate transformation.  Also,
    transformations are often applied to address non-homogeneous
    variation in the fit.  The NIST/SEMATECH e-Handbook contains a
    disucssion of this issue at

        https://www.itl.nist.gov/div898/handbook/pmd/section4/pmd452.htm

    Data transformations can be generated easily if needed via the
    LET command.  The BOX-COX LINEARITY PLOT can be a useful command for
    determining an approriate transformation.

    Some analysts prefer to standardize the indpendent variables
    and the dependent variable by subtracting the mean and dividing
    by the standard deviation.  This is done to provide numerical
    stability (note that Dataplot scales the data internally before
    performing the regression calculations) and also so that the
    data and regression coefficients are on a common scale.  The
    original regression and standardized model are related as followsL

         x'(i) = (x(i) - xbar)/s(x)
         y'(i) = (y(i) - ybar)/s(y)

    with xbar and s(x) denoting the mean and standard deviation of the
    independent variable and ybar and s(y) denoting the mean and
    standard deviation of the dependent variable.

    The parameters are related by

         Beta(k) = (s(y)/s(k)*Beta'(k)
         Beta'(0) = ybar - Beta(1)*xbar(1) - ... - Beta(p)*xbar(p)

    A variation on this is the correlation transformation (also called
    the standardized regression model).  Specifically

         y'(i) = (1/SQRT(n-1))*(y(i) - ybar)/s(y)
         x'(ik) = (1/SQRT(n-1))*(x(ik) - xbar(k))/s(x(k))

    With this transformation, the X'X matrix reduces to a correlation
    matrix of the independent variables.  If there are p independent
    variables, these transformations can be generated with the commands

         LET N = SIZE Y
         LET FACT = 1/SQRT(N-1)
         LOOP FOR K = 1 1 P
             LET Z^K = STANDARDIZE X^K
             LET Z^K = AFACT*Z^K
         END OF LOOP
         LET YT = STANDARDIZE Y
         LET YT = AFACT*YT

Note:
    It is recommended that a FIT be followed by a residual analysis to
    assess the model adequacy.  Specifically, the typical assumptions for
    the residuals are that they are independent with a common
    distribution having fixed location and variation.  It is usually
    assumed that the common distribution is a normal distribution.
    The 4-PLOT command generates 4 plots that are useful in testing
    these assumptions.  The NIST/SEMATECH e-Handbook contains a
    more detailed discussion of this issue at

        https://www.itl.nist.gov/div898/handbook/eda/section2/eda2.htm

    In addition, if there is a single independent variable in the model,
    it can be useful to plot the data with the fitted values overlaid.

    Linear fits allow a much richer set of diagnostics.  For a fuller
    description and an example demonstrating these, enter

        HELP REGRESSION DIAGNOSTICS

Note:
    If you want to suppress the output to files dpst1f.dat, dpst2f.dat,
    dpst3f.dat and dpst4f.dat, enter the command

        SET FIT AUXILLARY FILES OFF

Note:
    By default, the values written to dpst1f.dat, dpst2f.dat, dpst3f.dat
    and dpst4f.dat are written using a Fortran E15.7 format (that is,
    exponential format with 7 significant digits).  You can specify
    the number of signficant digits with the command

        SET AUXILLARY FILES DECIMAL POINTS <value>

    where the default is 7.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    FIT                = Generate a non-linear fit.
    WEIGHTS            = Sets the weights for the fit command.
    PRED               = A variable where predicted values are stored.
    RES                = A variable where residuals are stored.
    RESSD              = A parameter where the residual standard
                         deviation is stored.
    RESDF              = A parameter where the residual degrees of
                         freedom is stored.
    REPSD              = A parameter where the replication standard
                         deviation is stored.
    REPDF              = A parameter where the replication degrees of
                         freedom is stored.
    LOFCDF             = A parameter where the lack of fit cdf is
                         stored.
    EXACT RATIONAL FIT = Carries out an exact rational fit.
    SPLINE FIT         = Carries out a spline fit.
    SMOOTH             = Carries out a smoothing.
    ANOVA              = Carries out an ANOVA.
    MEDIAN POLISH      = Carries out a median polish.
    PLOT               = Generates a data/function plot.
 
References:
    Draper and Smith (1998), "Applied Regression Analysis", Third ed., 
    John Wiley.
 
    Mosteller and Tukey (1977), "Data Analysis and Regression",
    Addison-Wesley.
 
    Cook and Weisberg (1982), "Residuals and Influence in Regression",
    Chapman and Hall.
 
    Belsley, Kuh, and Welsch, (1980),  "Regression Diagnostics",
    John Wiley.

    Neter, Wasserman, and Kunter (1990), "Applied Linear Statistical
    Models", 3rd ed., Irwin.

    Note that linear regression is covered in great detail in many
    statistics textbooks.  

Applications:
    Fitting
 
Implementation Date:
    1987/06
    1988/09: Support for constant fit
    1992/03: Write COEF, SDCOEF, TCDF to dpst1f.dat
    1993/07: Write diagonal of hat matrix and parameter covariance
             matrix to file
    1994/01: Write SDPRED and limits to file
    1994/06: Fix bug in dpst4f.dat file for polynomial models
    1996/01: Fix bomb with constant fit
    2002/04: Support for no constant term
    2002/04: Print error message if singularity detected
    2002/06: Additional variables to dpst2f.dat and dpst3f.dat file
    2002/06: Write ANOVA table to dpst5f.dat
    2003/10: Support for HTML and LaTex output
    2013/10: Support for BIC statistic
    2014/06: User option to suppress writing to auxiliary files
    2019/04: User option to specify number of decimal points for
             auxiliary files
    2021/08: Save RESSS, SSREG, SSTOTAL, MSE, MSR, FSTAT, FCV95, and
             FCV99 as internal parameters

Program:
    . ALASKA PIPELINE RADIOGRAPHIC DEFECT BIAS CURVE
    . PERFORM A LINEAR REGRESSION
    SKIP 25
    READ BERGER1.DAT TRUE MEAS BATCH
    FIT MEAS TRUE
    .
    TITLE OFFSET 2
    TITLE CASE ASIS
    LABEL CASE ASIS
    CASE ASIS
    .
    TITLE Original Data with Predicted Values
    X1LABEL True Depth (in .001 inch)
    Y1LABEL Measured Depth
    CHARACTERS X
    LINES BLANK
    .
    PLOT MEAS PRED VS TRUE
    .
    LABEL
    TITLE
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    SET 4-PLOT MULTIPLOT ON
    TIC MARK LABEL SIZE 4
    CHARACTER SIZE 4
    .
    4-PLOT RES
    .
    END OF MULTIPLOT
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT 4-Plot of Residuals (BERGER1.DAT)

-----LINEAR INTERCEPT PLOT---------------------------------------
 
LINEAR INTERCEPT PLOT
 
Name:
    LINEAR INTERCEPT PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a linear intercept plot.
 
Description:
    A linear intercept plot consists of subsample intercepts (from a
    linear fit) versus subsample index.  The subsample intercept is the
    intercept resulting from a least squares linear fit (between 2
    user-specified variables) of the data in the subsample.  The linear
    intercept plot is used to answer the question--"Does the
    y-intercept of a fitted line between 2 variables change from one
    subsample to the next?  The plot consists of:
       Vertical   axis = subsample intercept from linear fit;
       Horizontal axis = subsample index.
    The linear intercept plot yields 2 traces:
       1. a subsample intercept trace; and
       2. a full-sample intercept reference line.
    Like usual, the appearance of these 2 traces is controlled by
    the first 2 settings of the LINES, CHARACTERS, SPIKES, BARS,
    and similar attributes.
 
Syntax:
    LINEAR INTERCEPT PLOT   <y1>   <y2>   <x>
                    <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a response (= dependent) variable;
          <y2> is another response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
               appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LINEAR INTERCEPT PLOT Y1 Y2 X
    LINEAR INTERCEPT PLOT PRES TEMP DAY
    LINEAR INTERCEPT PLOT CONC YEAR MONTH
    LINEAR INTERCEPT PLOT FATALITIES MONTH STATE
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINEAR SLOPE PLOT       = Generates a linear slope plot.
    LINEAR CORRELATION PLOT = Generates a linear correlation plot.
    LINEAR RESSD PLOT       = Generates a linear residual standard
                              deviation plot.
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    FIT                     = Carries out a least squares fit.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    1988/3
 
Program:
    LET Y1 = DATA 2 4 7 11 15 18 25.1 25.3 25.9
    LET Y2 = DATA 10 20 30 10 20 30 10 20 30
    LET X = DATA 1 1 1 2 2 3 3 3 3
    LINE BLANK DASH
    CHARACTER X BLANK
    Y1LABEL INTERCEPT
    X1LABEL SAMPLE ID
    TITLE AUTOMATIC
    LINEAR INTERCEPT PLOT Y1 Y2 X
 
-----LINEAR INTERCEPT SD (LET)--------------------------
 
LINEAR INTERCEPT SD
 
Name:
    LINEAR INTERCEPT SD (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the standard deviation of the intercept parameter from a
    linear least squares fit between two variables.
 
Syntax:
    LET <par> = LINEAR INTERCEPT SD <y> <x>
                                    <SUBSET/EXCEPT/FOR qualification>
    where <y> is dependent response variable;
          <x> is the independent response variable;
          <par> is a parameter where the sd of the linear intercept value
              is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A1 = LINEAR INTERCEPT SD Y X
    LET A1 = LINEAR INTERCEPT SD Y X  SUBSET X > 1
 
Note:
    Dataplot's built-in statistics can be used with a number of
    commands.  For details, enter HELP STATISTIC.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINEAR INTERCEPT      = Compute the intercept parameter from a linear
                            least squares fit.
    LINEAR SLOPE SD       = Compute the standard deviation of the slope
                            parameter from a linear least squares fit.
    LINEAR SLOPE          = Compute the slope from a linear least
                            squares fit.
    LINEAR RESSD          = Compute the residual standard deviation from
                            a linear least squares fit.
    LINEAR CORRELATION    = Compute the correlation from a linear least
                            squares fit.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    2010/7
 
Program 1:
    SKIP 25
    READ BERGER1.DAT Y X
    LET A = LINEAR INTERCEPT SD Y X
 
Program 2:
    SKIP 25
    READ BERGER1.DAT Y X BATCH
    .
    LABEL CASE ASIS
    TITLE CASE ASIS
    Y1LABEL SD of Linear Intercept
    X1LABEL Batch
    TITLE Linear Intercept SD Plot
    CHARACTER X BLANK
    LINE BLANK SOLID
    TIC OFFSET UNITS SCREEN
    TIC MARK OFFSET 3 3
    LINEAR INTERCEPT SD PLOT Y X BATCH

-----LINEAR INTERCEPT (LET)--------------------------
 
LINEAR INTERCEPT
 
Name:
    LINEAR INTERCEPT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the intercept parameter from a linear least squares fit
    between two variables.
 
Syntax:
    LET <par> = LINEAR INTERCEPT <y> <x>
                                 <SUBSET/EXCEPT/FOR qualification>
    where <y> is dependent response variable;
          <x> is the independent response variable;
          <par> is a parameter where the linear intercept value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A1 = LINEAR INTERCEPT Y X
    LET A1 = LINEAR INTERCEPT Y X  SUBSET X > 1
 
Note:
    Dataplot's built-in statistics can be used with a number of
    commands.  For details, enter HELP STATISTIC.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINEAR INTERCEPT SD   = Compute the standard deviation of the intercept
                            parameter from a linear least squares fit.
    LINEAR SLOPE SD       = Compute the standard deviation of the slope
                            parameter from a linear least squares fit.
    LINEAR SLOPE          = Compute the slope from a linear least
                            squares fit.
    LINEAR RESSD          = Compute the residual standard deviation from
                            a linear least squares fit.
    LINEAR CORRELATION    = Compute the correlation from a linear least
                            squares fit.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    1988/3
 
Program 1:
    SKIP 25
    READ BERGER1.DAT Y X
    LET A = LINEAR INTERCEPT Y X
 
Program 2:
    SKIP 25
    READ BERGER1.DAT Y X BATCH
    .
    LABEL CASE ASIS
    TITLE CASE ASIS
    Y1LABEL Linear Intercept
    X1LABEL Batch
    TITLE Linear Intercept Plot
    CHARACTER X BLANK
    LINE BLANK SOLID
    TIC OFFSET UNITS SCREEN
    TIC MARK OFFSET 3 3
    LINEAR INTERCEPT PLOT Y X BATCH

-----LINEAR INTERPOLATION (LET)---------------------------------------
 
LINEAR INTERPOLATION
 
Name:
    LINEAR INTERPOLATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Perform a linear interpolation of a series of data points.
 
Description:
    Interpolation takes a series of (x,y) points and generates
    estimated values for y's at new x points.  Interpolation is used
    when the function that generated the original (x,y) points is
    unknown.
 
    Interpolation is related to, but distinct from, fitting a function
    to a series of points.  In particular, an interpolated function
    goes through all the original points while a fitted function does
    not.
 
    There are various methods for performing interpolation.  Chapter 3
    of the Numerical Recipes book (see REFERENCE below) contains a nice
    discussion of various types of commonly used interpolation schemes
    (polynomial interpolation, rational function interpolation, cubic
    spline interpolation).  The INTERPOLATION command in DATAPLOT uses
    a cubic spline algorithm and is normally the preferred type of
    interpolation.  However, the LINEAR INTERPOLATION command can be
    used to perform linear interpolation (i.e., the given points are
    connected with a straight lines).
 
Syntax:
    LET <y2> = LINEAR INTERPOLATION <y1> <x1> <x2>
                 <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable containing the vertical axis data points;
          <x1> is a variable containing the horizontal axis data
               points;
          <x2> is a variable containing the horizontal points where the
               interpolation is to be performed;
          <y2> is a variable (same length as <x2>) where the
               interpolated values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y2 = LINEAR INTERPOLATION Y1 X1 X2
 
Note:
    The interpolation points (i.e., <x2>) must be within the range of
    the original data points (i.e., <x1>).  An error message is
    generated if this is not the case.
 
Note:
    The original data do not have to be in sorted order.  DATAPLOT
    sorts the original data (on <x1>) automatically.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    INTERPOLATION          = Compute a cubic spline interpolation of a
                             series of points.
    BILINEAR INTERPOLATION = Compute a bilinear interpolation of a
                             2D series of points.
    FIT                    = Perform a least squares fit.
 
Applications:
    Mathematics
 
Implementation Date:
    94/6
 
Program:
    .  DATA FROM SANTOS MAYO OF NIST
    .  EXAMPLE WHERE CUBIC INTERPOLATION DOESN'T WORK WELL.
    LET X1 = DATA ...
       295.5 290.65 290.2 289.2 288.4 280.5 281.6 280.4 280 278.8 276.5
    LET Y1 = DATA 8.53 8.34 8.33 8.30 8.29 8.06 8.1 8.07 8.07 8.02 7.94
    LET X2 = SEQUENCE 277 1 295
    .
    LET Y2 = INTERPOLATION Y1 X1 X2
    LET Y3 = LINEAR INTERPOLATION Y1 X1 X2
    CHARACTER CIRCLE BLANK BLANK
    CHARACTER SIZE 1.2
    CHARACTER FILL ON
    LINE BLANK SOLID DASH
    LEGEND 1 SOLID LINE - CUBIC SPLINE INTERPOLATION
    LEGEND 2 DASH LINE  - LINEAR INTERPOLATION
    PLOT Y1 X1 AND
    PLOT Y2 Y3 VS X2
 
-----LINE INTERSECTIONS--------------------------------------------------
 
LINE INTERSECTIONS
 
Name:
    LINE INTERSECTIONS
 
Type:
    LET Subcommand
 
Purpose:
    Find the point of intersection for two sets of lines.
 
Description:
    Given two sets of lines where each line is defined by two points,
    return the point of intersection.  That is, we have the variables

        X1 Y1 X2 Y2  X3 Y3 X4 Y4

    where each row of X1, Y1 X2, and Y2 defines line one and the
    corresponding row of X3, Y3, X4, and Y4 defines line two.  If there
    are N rows, then this command will return the x and y coordinates
    for each of the N rows.
    
    The variables can in fact be parameters (i.e., a single value), but
    all arguments that are variables must contain the same number of rows.

    If the lines are parallel, the x and y coordinates for that row will
    be set to the minimum real value on the machine.  You can enter the
    commands

         PROBE CPUMIN
         LET CPUMIN = PROBEVAL

    if you need to check for this value.

Syntax:
    LET <yout> <xout>= LINE INTERSECTIONS <x1> <y1> <x2> <y2>
                                          <x3> <y3> <x4> <y4>
                       <SUBSET/EXPCEPT/FOR qualification>
    where <x1> is a variable or parameter containing the x-coordinates for the
               first point of line one;
          <y1> is a variable or parameter containing the y-coordinates for the
               first point of line one;
          <x2> is a variable or parameter containing the x-coordinates for the
               second point of line one;
          <y2> is a variable or parameter containing the y-coordinates for the
               second point of line one;
          <x3> is a variable or parameter containing the x-coordinates for the
               first point of line two;
          <y3> is a variable or parameter containing the y-coordinates for the
               first point of line two;
          <x4> is a variable or parameter containing the x-coordinates for the
               second point of line two;
          <y4> is a variable or parameter containing the y-coordinates for the
               second point of line two;
          <yout> is a variable containing the y-coordinates of the
               intersection points;
          <xout> is a variable containing the x-coordinates of the
               intersection points;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET YOUT XOUT = LINE INTERSECTIONS X1 Y1 X2 Y2 X3 Y3 X4 Y4

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POINTS IN POLYGON  = Determine whether points are in the interior
                         of a convex polygon.
    CONVEX HULL        = Determine the convex hull of a set of points.
    TRANSFORM POINTS   = Perform location, scale, and rotation
                         transformation for a set of points.
    EXTREME POINTS     = Determine the extreme points of a set of points.
    LINE INTERSECTIONS = Determine the intersection points for a set of
                         lines.
    PARALLEL LINE      = Determine the coordinates for a point that defines
                         a parallel line determined by a point and a line
                         defined by two points.
    PERPINDICULAR LINE = Determine the coordinates for a point that defines
                         a perpindicular line determined by a point and a line
                         defined by two points.

Applications:
    Computational Geometry
 
Implementation Date:
    2012/10
 
Program:
    read  x y
      0.5333000E+02  0.2357000E+02
      0.5037000E+02  0.1668000E+02
      0.1686000E+02 -0.6469000E+02
      0.5521000E+02  0.2713000E+02
      0.1395000E+02 -0.6794000E+02
      0.5414000E+02  0.2781000E+02
      0.2704000E+02 -0.4195000E+02
      0.1830000E+02 -0.6416000E+02
     -0.8881000E+02 -0.2991900E+03
      0.6442000E+02  0.5613000E+02
     -0.1728800E+03 -0.5288300E+03
      0.4743000E+02  0.1766000E+02
      0.3282400E+03  0.4791700E+03
      0.2137600E+03  0.1424400E+03
      0.2067600E+03  0.1877700E+03
      0.3593000E+02 -0.2923600E+03
      0.3637600E+03  0.3094700E+03
      0.2974600E+03  0.6332000E+02
      0.1759800E+03 -0.1644000E+03
      0.4257500E+03  0.3561300E+03
      0.6733000E+02  0.9115000E+02
      0.5081000E+02  0.2532000E+02
     -0.2029900E+03 -0.5509600E+03
      0.7737000E+02  0.6375000E+02
      0.3363100E+03  0.3074700E+03
      0.1296400E+03 -0.1771600E+03
      0.2421000E+02 -0.5091200E+03
      0.1670100E+03 -0.1446500E+03
      0.2401100E+03 -0.3796800E+03
      0.5067400E+03  0.4129400E+03
      0.5173100E+03  0.4183700E+03
      0.8339000E+02 -0.6446200E+03
      0.1908800E+03  0.3463800E+03
      0.1629900E+03  0.3044400E+03
     -0.1138500E+03 -0.4050300E+03
      0.2787200E+03  0.4979900E+03
     -0.7125000E+02 -0.4863700E+03
      0.2147300E+03  0.1820300E+03
     -0.1757900E+03 -0.5140500E+03
     -0.1993500E+03 -0.5823900E+03
      0.1438700E+03  0.2333900E+03
      0.2134000E+02 -0.6915000E+02
     -0.4354000E+02 -0.4289700E+03
      0.3219800E+03  0.4268300E+03
      0.2507000E+02 -0.2689300E+03
     -0.8324000E+02 -0.5685300E+03
      0.8540000E+02 -0.4379000E+03
      0.7870000E+02 -0.3830800E+03
     -0.1064000E+02 -0.6613600E+03
      0.2023700E+03 -0.3954000E+02
      0.2877000E+02 -0.3549000E+02
      0.1908000E+02 -0.5440000E+02
      0.3766000E+02 -0.1542000E+02
      0.5360000E+02  0.1845000E+02
     -0.1782900E+03 -0.5311500E+03
     -0.9508000E+02 -0.5267900E+03
      0.1183700E+03 -0.6679000E+02
      0.4384000E+02 -0.4773700E+03
      0.1847200E+03 -0.5284000E+02
      0.1714300E+03  0.3265600E+03
      0.1928600E+03  0.3423200E+03
     -0.1705300E+03 -0.4889800E+03
      0.4415000E+02  0.8400000E+01
     -0.1434000E+03 -0.4216400E+03
      0.6579000E+02  0.2837000E+02
    end of data
    .
    let x1 = x(44)
    let y1 = y(44)
    let x2 = x(46)
    let y2 = y(46)
    let x3 = x(21)
    let y3 = y(21
    let x4 = x(29)
    let y4 = y(29)
    .
    let xout yout = line intersection x1 y1 x2 y2 x3 y3 x4 y4
    set write decimals 3
    print xout yout
    .
    let x5 = xout(1)
    let y5 = yout(1)
    let zx = combine x1 x2 x3 x4 x5
    let zy = combine y1 y2 y3 y4 y5
    let ztag = data 1 1 2 2 3
    char 1 2 circle
    char hw 1.0 0.75 all
    char fill on all
    .
    plot zy zx ztag
  
-----LINEAR RESSD PLOT-------------------------------------------
 
LINEAR RESSD PLOT
 
Name:
    LINEAR RESSD PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a linear residual standard deviation plot.
 
Description:
    A linear residual standard deviation plot consists of subsample
    residual standard deviations (from a linear fit) versus subsample
    index.  The subsample residual standard deviation is the residual
    standard deviation resulting from a least squares linear fit
    (between 2 user-specified variables) of the data in the subsample.
    The linear intercept plot is used to answer the question-- "Does
    the residual standard deviation of a fitted line between 2
    variables change from one subsample to the next?  In other words,
    does the quality and goodness of the linear fit change from one
    subsample to the next?  The plot consists of:
       Vertical   axis = subsample residual standard deviation from a
                         linear fit;
       Horizontal axis = subsample index.
    The linear ressd plot yields 2 traces:
       1. a subsample residual standard deviation trace; and
       2. a full-sample residual standard deviation reference line.
    Like usual, the appearance of these 2 traces is controlled by
    the first 2 settings of the LINES, CHARACTERS, SPIKES, BARS,
    and similar attributes.
 
Syntax:
    LINEAR RESSD PLOT <y1> <y2> <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a response (= dependent) variable;
          <y2> is another response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
               appears on horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LINEAR RESSD PLOT Y1 Y2 X
    LINEAR RESSD PLOT PRES TEMP DAY
    LINEAR RESSD PLOT CONC YEAR MONTH
    LINEAR RESSD PLOT FATALITIES MONTH STATE
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINEAR SLOPE PLOT       = Generates a linear slope plot.
    LINEAR CORRELATION PLOT = Generates a linear correlation plot.
    LINEAR INTERCEPT PLOT   = Generates a linear intercept plot.
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    FIT                     = Carries out a least squares fit.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    1988/3
 
Program:
    LET Y1 = DATA 2 4 7 11 15 18 25.1 25.3 25.9
    LET Y2 = DATA 10 20 30 10 20 30 10 20 30
    LET X = DATA 1 1 1 2 2 3 3 3 3
    LINE BLANK DASH
    CHARACTER X BLANK
    TIC OFFSET 0.5 0.5
    Y1LABEL RESSD
    X1LABEL SAMPLE ID
    TITLE AUTOMATIC
    LINEAR RESSD PLOT Y1 Y2 X
 
-----LINEAR RESSD (LET)--------------------------
 
LINEAR RESSD
 
Name:
    LINEAR RESSD (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the residual standard deviation from a linear least squares
    fit between two variables.
 
Syntax:
    LET <par> = LINEAR RESSD <y> <x>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is dependent response variable;
          <x> is the independent response variable;
          <par> is a parameter where the residual sd value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A1 = LINEAR RESSD Y X
    LET A1 = LINEAR RESSD Y X  SUBSET X > 1
 
Note:
    Dataplot's built-in statistics can be used with a number of
    commands.  For details, enter HELP STATISTIC.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINEAR SLOPE SD       = Compute the standard deviation of the slope
                            parameter from a linear least squares fit.
    LINEAR INTERCEPT      = Compute the intercept from a linear least
                            squares fit.
    LINEAR INTERCEPT SD   = Compute the standard deviation of the intercept
                            parameter from a linear least squares fit.
    LINEAR SLOPE          = Compute the slope from a linear least squares
                            fit.
    LINEAR CORRELATION    = Compute the correlation from a linear least
                            squares fit.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    1988/3
 
Program 1:
    SKIP 25
    READ BERGER1.DAT Y X
    LET A = LINEAR RESSD Y X
 
Program 2:
    SKIP 25
    READ BERGER1.DAT Y X BATCH
    .
    LABEL CASE ASIS
    TITLE CASE ASIS
    Y1LABEL Residual Standard Deviation
    X1LABEL Batch
    TITLE Linear RESSD Plot
    CHARACTER X BLANK
    LINE BLANK SOLID
    TIC OFFSET UNITS SCREEN
    TIC MARK OFFSET 3 3
    LINEAR RESSD PLOT Y X BATCH

-----LINEAR SLOPE PLOT-------------------------------------------
 
LINEAR SLOPE PLOT
 
Name:
    LINEAR SLOPE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a linear slope plot.
 
Description:
    A linear slope plot consists of subsample slopes (from a linear
    fit) versus subsample index.  The subsample slope is the slope
    resulting from a least squares linear fit (between 2 user-specified
    variables) of the data in the subsample.  The linear slope plot is
    used to answer the question--"Does the slope of a fitted line
    between 2 variables change from one subsample to the next?  The
    plot consists of:
       Vertical   axis = subsample slope from linear fit;
       Horizontal axis = subsample index.
    The linear slope plot yields 2 traces:
       1. a subsample slope trace; and
       2. a full-sample slope reference line.
    Like usual, the appearance of these 2 traces is controlled by
    the first 2 settings of the LINES, CHARACTERS, SPIKES, BARS,
    and similar attributes.
 
Syntax:
    LINEAR SLOPE PLOT <y1> <y2> <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a response (= dependent) variable;
          <y2> is another response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
               appears on horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LINEAR SLOPE PLOT Y1 Y2 X
    LINEAR SLOPE PLOT PRES TEMP DAY
    LINEAR SLOPE PLOT CONC YEAR MONTH
    LINEAR SLOPE PLOT FATALITIES MONTH STATE
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINEAR CORRELATION PLOT = Generates a linear correlation plot.
    LINEAR INTERCEPT PLOT   = Generates a linear intercept plot.
    LINEAR RESSD PLOT       = Generates a linear residual standard
                              deviation plot.
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    FIT                     = Carries out a least squares fit.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    1988/3
 
Program:
    LET Y1 = DATA 2 4 7 11 15 18 25.1 25.3 25.9
    LET Y2 = DATA 10 20 30 10 20 30 10 20 30
    LET X = DATA 1 1 1 2 2 3 3 3 3
    LINE BLANK DASH
    CHARACTER X BLANK
    TIC OFFSET 0.2 0.2
    Y1LABEL SLOPE
    X1LABEL SAMPLE ID
    TITLE AUTOMATIC
    LINEAR SLOPE PLOT Y1 Y2 X
 
-----LINEAR SLOPE SD (LET)--------------------------
 
LINEAR SLOPE SD
 
Name:
    LINEAR SLOPE SD (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the standard deviation of the slope parameter from a linear
    least squares fit between two variables.
 
Syntax:
    LET <par> = LINEAR SLOPE SD <y> <x>
                                <SUBSET/EXCEPT/FOR qualification>
    where <y> is dependent response variable;
          <x> is the independent response variable;
          <par> is a parameter where the sd of the linear slope value
              is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A1 = LINEAR SLOPE SD Y X
    LET A1 = LINEAR SLOPE SD Y X  SUBSET X > 1
 
Note:
    Dataplot's built-in statistics can be used with a number of
    commands.  For details, enter HELP STATISTIC.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINEAR SLOPE          = Compute the slope parameter from a linear
                            least squares fit.
    LINEAR INTERCEPT      = Compute the intercept from a linear least
                            squares fit.
    LINEAR INTERCEPT SD   = Compute the standard deviation of the intercept
                            parameter from a linear least squares fit.
    LINEAR RESSD          = Compute the residual standard deviation from
                            a linear least squares fit.
    LINEAR CORRELATION    = Compute the correlation from a linear least
                            squares fit.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    2010/7
 
Program 1:
    SKIP 25
    READ BERGER1.DAT Y X
    LET A = LINEAR SLOPE SD Y X
 
Program 2:
    SKIP 25
    READ BERGER1.DAT Y X BATCH
    .
    LABEL CASE ASIS
    TITLE CASE ASIS
    Y1LABEL SD of Linear Slope
    X1LABEL Batch
    TITLE Linear Slope SD Plot
    CHARACTER X BLANK
    LINE BLANK SOLID
    TIC OFFSET UNITS SCREEN
    TIC MARK OFFSET 3 3
    LINEAR SLOPE SD PLOT Y X BATCH

-----LINEAR SLOPE (LET)--------------------------
 
LINEAR SLOPE
 
Name:
    LINEAR SLOPE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the slope parameter from a linear least squares fit between
    two variables.
 
Syntax:
    LET <par> = LINEAR SLOPE <y> <x>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is dependent response variable;
          <x> is the independent response variable;
          <par> is a parameter where the linear slope value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A1 = LINEAR SLOPE Y X
    LET A1 = LINEAR SLOPE Y X  SUBSET X > 1
 
Note:
    Dataplot's built-in statistics can be used with a number of
    commands.  For details, enter HELP STATISTIC.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINEAR SLOPE SD       = Compute the standard deviation of the slope
                            parameter from a linear least squares fit.
    LINEAR INTERCEPT      = Compute the intercept from a linear least
                            squares fit.
    LINEAR INTERCEPT SD   = Compute the standard deviation of the intercept
                            parameter from a linear least squares fit.
    LINEAR RESSD          = Compute the residual standard deviation from
                            a linear least squares fit.
    LINEAR CORRELATION    = Compute the correlation from a linear least
                            squares fit.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    1988/3
 
Program 1:
    SKIP 25
    READ GEAR.DAT Y X
    LET A = LINEAR SLOPE Y X
 
Program 2:
    SKIP 25
    READ BERGER1.DAT Y X BATCH
    .
    LABEL CASE ASIS
    TITLE CASE ASIS
    Y1LABEL Linear Slope
    X1LABEL Batch
    TITLE Linear Slope Plot
    CHARACTER X BLANK
    LINE BLANK SOLID
    TIC OFFSET UNITS SCREEN
    TIC MARK OFFSET 3 3
    LINEAR SLOPE PLOT Y X BATCH

-----LINES-------------------------------------------------------
 
LINES
 
Name:
    LINES
 
Type:
    Plot Control Command
 
Purpose:
    Specifies line types (solid, dot, dash, dash2, dash3, dash4, blank
    (= none)) to appear between the plot points of each trace on
    subsequent plots.
 
Description:
    There are 8 available line types.  They can be spelled out in full,
    or the following 2- or 3-character abbreviations can be used:
       SOLID    SO
       DOT      DO
       DASH     DA
       DASH1    DA1
       DASH2    DA2
       DASH3    DA3
       DASH4    DA4
       BLANK    BL
 
Syntax 1:
    LINES  <type 1>  <type 2>  ... <type n>  etc.
    where <type1>, ..., <typen> speciy the desired line types.  Up to
    100 such line types can be specified.
 
Syntax 2:
    LIENS SAVE

    This syntax saves the current settings of the LINES command.

Syntax 3:
    LINES RESTORE

    This syntax restores the settings of the LINES command
    saved by a prior LINES SAVE command.

Examples:
    LINES SOLID DOT DASH
    LINES BLANK SOLID DASH DASH4
    LINES BLANK SOLID
    LINES ALL SOLID
    LINES SOLID ALL
    LINES
    LINES SO DO DA
    LINES BL SO DA DA4
 
Note:
    Many diagrammatic graphics commands use the LINE command to set the
    line type for a figure to be drawn.
 
Note:
    DATAPLOT generates all dash patterns in hardware.  This means that
    the appearance of dashed lines can vary between output devices.
    Also, a few devices do not support 8 distinct dash patterns.
 
Note:
    The LINES command with no arguments sets all line types to blank.
    The LINES command with the word ALL before or after the specified
    type assigns that line type to all traces.  Thus LINES DOTTED ALL
    or LINES ALL DOTTED assigns dotted lines to all traces.
 
Note:
    The LINES <SAVE/RESTORE> was motivated for use by the
    Tcl/Tk graphical interface.  However, it can also be used
    directly by the user.  A typical use would be to save the
    current settings before a command, such as the box plot,
    that requires special settings for the LINES command.
    The settings could then be easily restored after the special
    plot.

    This feature was implemented 1998/5.

Default:
    All line types are set to solid.
 
Synonyms:
    None
 
Related Commands:
    PLOT                = Generates a data or function plot.
    LINE THICKNESSES    = Sets the thicknesses for plot lines.
    LINE COLORS         = Sets the colors for plot lines.
    CHARACTERS          = Sets the types for plot characters.
    SPIKES              = Sets the on/off switches for plot spikes.
    BARS                = Sets the on/off switches for plot bars.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    LET N = SIZE LEAD; LET X = SEQUENCE 1 1 N
    .
    LINE DASH DOT
    .
    TITLE DEMONSTRATE LINE COMMAND
    PLOT POT LEAD VS X
 
-----LINE COLORS-------------------------------------------------------
 
LINE COLORS
 
Name:
    LINE COLORS
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the colors of the lines to appear between the plot points
    of each trace on subsequent plots.
 
Description:
    Dataplot defines the points on a plot by "traces".  A trace is a set
    of points that are drawn with the same attributes.  For example,

        PLOT Y1 X1 AND
        PLOT Y2 X2

    has two traces.  The first is the points defined by Y1 and X1 and the
    second is the points defined by Y2 and X2.  Attributes can be set for
    up to 100 traces.

    Dataplot provides two methods for specifying colors.

        1. Colors can be defined by name (or by the corresponding index).
           Dataplot adopted it's named colors from the X11 project.
           Currently, 162 named colors and 100 levels of grayscale are
           supported.  Grayscale can be specified with either G0, G1, ...,
           G100 (or -1, -2, ..., -100).  Many older devices support only a
           limited number of colors.  For these devices, unsupported colors
           will be mapped to one of the available colors.  To specify a
           named color, see Syntax 1.

        2. Most modern graphics devices support full RGB (RedBlueGreen)
           color.  You can alternatively specify RGB colors by entering
           three integer values to represent the Red, Green and Blue
           components, respectively.  These values should be in the range
           0 to 255.

    When setting the line color, Dataplot first checks if the device
    supports RGB colors. If not, the named color will be used.  If the
    device does support RGB color, Dataplot will check if an RGB color
    has been specified.  If yes, then that RGB color is used.  If not,
    the named color will be used.

    To see the list of supported named colors (with the associated index
    number), see

    https://www.itl.nist.gov/div898/software/dataplot/refman1/ch11/homepage.htm

Syntax 1:
    LINE COLORS  <color 1>  <color 2>  ... <color n>
    where <color 1>, ..., <color n> specify the desired line colors.

    Up to 100 such line colors may be specified.
 
Syntax 2:
    LINE RGB COLORS <red-1> <green-1> <blue-1> ...
                    <red-n> <green-n> <red-n>
    where <red-1>, <green-1>, <blue-1>, ..., <red-n>, <green-n>, <blue-n>
    is a list of integer values that specify the desired RGB line colors.

    Up to 100 such triplets of color values can be specified.

    To turn off the RGB color, set the values to -1 (any negative value
    will work).  Values greater than 255 will be set to 255.
 
Examples:
    LINE COLORS BLUE ORANGE
    LINE COLORS BLUE BLUE YELLOW YELLOW
    LINE COLORS ALL RED
    LINE COLORS RED ALL
    LINE COLORS
    LINE RGB COLORS 220 109 88 240 220 160
    LINE RGB COLORS 220 109 88 ALL
 
Note:
    The LINE COLORS command with no arguments sets all line colors to
    the default.  The LINE COLORS command with the word ALL before or
    after the specified color assigns that line color to all traces.
    Thus LINE COLOR GREEN ALL or LINE COLOR ALL GREEN assigns the line
    color green to all traces.
 
Note:
    Many diagrammatic graphics commands (e.g., DRAW, CIRCLE) use the
    LINE COLOR command to set the line color for the figure to be drawn.
    Diagrammatic graphics only use the settings for the first trace.
 
Default:
    All line colors are set to black and RGB colors are off.
 
Synonyms:
    None
 
Related Commands:
    PLOT                = Generates a data or function plot.
    LINES               = Sets the types for plot lines.
    LINE THICKNESSES    = Sets the thicknesses for plot lines.
    CHARACTER COLORS    = Sets the colors for plot characters.
    SPIKE COLORS        = Sets the colors for plot spikes.
    BAR FILL COLORS     = Sets the colors for plot bar fills.
    BAR PATTERN COLORS  = Sets the colors for plot bar patterns.
    BAR BORDER COLORS   = Sets the colors for plot bar borders.
    TITLE COLOR         = Sets the color for plot title.
    LABEL COLOR         = Sets the color for plot labels.
    LEGEND COLOR        = Sets the color for plot legends.
    BOX COLOR           = Sets the color for plot boxes.
    ARROW COLOR         = Sets the color for plot arrows.
    SEGMENT COLOR       = Sets the color for plot segments.
    FRAME COLOR         = Sets the color for plot frame.
    GRID COLOR          = Sets the color for plot grids.
    TIC COLOR           = Sets the color for plot tics.
    TIC LABEL COLOR     = Sets the color for plot tic labels.
    MARGIN COLOR        = Sets the color for plot margin.
    BACKGROUND COLOR    = Sets the color for plot background.
 
Applications:
    Graphics
 
Implementation Date:
    Pre-1987
    2020/11: RGB color support added
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    LET N = SIZE LEAD; LET X = SEQUENCE 1 1 N
    .
    LINE COLOR G20 G80
    TITLE DEMONSTRATE GRAYSCALE LINE COLOR
    PLOT POT LEAD VS X
    .
    LINE COLOR BLUE RED
    TITLE DEMONSTRATE LINE COLOR
    PLOT POT LEAD VS X
    .
    LINE RGB COLOR 175 238 238 220 20 60
    TITLE DEMONSTRATE LINE RGB COLOR
    PLOT POT LEAD VS X
 
-----LINE THICKNESS---------------------------------------------------
 
LINE THICKNESS
 
Name:
    LINE THICKNESS
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the thickness of the lines to appear between the plot
    points of each trace on subsequent plots.
 
Description:
    Line thickness are specified in 0.0 to 100.0 units where 100.0
    represents the full screen.  DATAPLOT uses hardware line thickness
    if it is available.  In this case, it rounds the requested
    thickness to the nearest thickness available on the device.  Also,
    most devices have a minimum thickness (typically 1 pixel wide) that
    can be drawn.  Requested thicknesses are typically in the range
    0.05 to 0.3.  For many devices, 0.1 corresponds to a 1 pixel wide
    line.
 
Syntax:
    LINE THICKNESS  <thick 1>  <thick 2>  ... <thick n>
    where <thick 1>, <thick 2>, .., <thick n> are decimal numbers or
    parameters in the range 0 to 100 that specify the desired line
    thicknesses.  Up to 100 such line thicknesses can be specified.
 
Examples:
    LINE THICKNESS 0.1 0.2 0.3
    LINE THICKNESS 0.1 0.1 0.2 0.2
    LINE THICKNESS ALL 0.2
    LINE THICKNESS 0.2 ALL
    LINE THICKNESS
 
Note:
    Many diagrammatic graphics commands use the LINE THICKNESS command
    to set the line thickness for a figure to be drawn.
 
Note:
    The THICKNESS command sets the default thickness.  The LINE
    THICKNESS command can be used to override the default for plot
    line traces only.
 
Note:
    DATAPLOT draws thick lines in hardware if possible.  For devices
    that do not support hardware line width, DATAPLOT draws multiple
    lines.  Occasionaly, DATAPLOT can generate "spikes" (particularly
    when lines are joined at angles very near zero degrees) when
    drawing multiple lines.  If line width is supported in hardware,
    DATAPLOT maps the requested thickness to the closest available
    hardware width.
 
Note:
    The default line width can vary between devices.  If regions fills
    show "gaps", you can specify what the size of a single width line
    is for a given device.  Enter HELP SET PEN WIDTH for details.
 
Note:
    The LINE THICKNESS command with no arguments sets all line
    thickness to the default.  The LINE THICKNESS command with the word
    ALL before or after the specified thickness assigns that line
    thickness to all traces.  Thus LINE COLOR THICKNESS 0.2 ALL or LINE
    THICKNESS ALL 0.2 assigns the line thickness 0.2 to all traces.
 
Default:
    All line thickness are set to 0.1.
 
Synonyms:
    None
 
Related Commands:
    PLOT                   = Generates a data or function plot.
    LINES                  = Sets the types for plot lines.
    LINE COLORS            = Sets the colors for plot lines.
    THICKNESS              = Sets the thicknesses for all lines.
    CHARACTER THICKNESS    = Sets the thicknesses for plot characters.
    SPIKE THICKNESS        = Sets the thicknesses for plot spikes.
    BAR FILL THICKNESS     = Sets the thicknesses for plot bar fills.
    BAR PATTERN THICKNESS  = Sets the thicknesses for plot bar
                             patterns.
    BAR BORDER THICKNESS   = Sets the thicknesses for plot bar borders.
    TITLE THICKNESS        = Sets the thicknesses for plot title.
    LABEL THICKNESS        = Sets the thicknesses for plot labels.
    LEGEND THICKNESS       = Sets the thicknesses for plot legends.
    BOX THICKNESS          = Sets the thicknesses for plot boxes.
    ARROW THICKNESS        = Sets the thicknesses for plot arrows.
    SEGMENT THICKNESS      = Sets the thicknesses for plot segments.
    FRAME THICKNESS        = Sets the thicknesses for plot frame.
    GRID THICKNESS         = Sets the thicknesses for plot grids.
    TIC THICKNESS          = Sets the thicknesses for plot tics.
    TIC LABEL THICKNESS    = Sets the thicknesses for plot tic labels.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    LET N = SIZE LEAD; LET X = SEQUENCE 1 1 N
    .
    LINE THICKNESS 0.1 0.3
    .
    TITLE DEMONSTRATE LINE THICKNESS
    PLOT POT LEAD VS X
 
-----LIST-------------------------------------------------------
 
LIST
 
Name:
    LIST
 
Type:
    Support Command
 
Purpose:
    Lists (i.e., print) the contents of a mass storage file.
 
Description:
    The file being listed can be any ASCII text file.  For example,
    you may want to see the contents of a data file, a Dataplot
    macro or the output from the Dataplot CAPTURE command.  However,
    you are not limited to Dataplot related files.

    There are a number of special keywords that are recognized for
    the LIST command.  Specifically,

         DICTIONARY      - lists the Dataplot dictionary file (dpdicf.tex)
         DIRECTORY       - lists the Dataplot directory file (dpdirf.tex)
         MASTER          - lists the Dataplot directory file (dpdirf.tex)
         DEFINITIONS     - lists any definitions that have been created
                           with the DEFINE command
         DATASETS        - lists Dataplot datasets (datasets)
         DESIGNS         - lists a number of experimental designs (designs)
         DISTRIBU        - lists probability distributions supported in
                           Dataplot (distribu)
         COMMANDS        - lists a number of Dataplot commands (commands)
         SYNTAX          - lists the syntax file (syntax)
         FUNCTION        - lists functions supported in Dataplot (function)
         PROGRAMS        - lists Dataplot programs (programs)
         MACROS          - lists Dataplot macros (macros)
         CONCLUSIONS     - lists the Dataplot conclusions file (dpconf.tex)
         CLIPBOARD       - lists the contents of the clipboard (operating
                           system dependent)
         FUNCTION BLOCK  - lists functions defined by the FUNCTION BLOCK
                           command
         STATISTIC BLOCK - lists functions defined by the STATISTIC BLOCK
                           command
         LOOP LINES      - lists the contents of the stored LOOP
                           commands
         COMMAND LINE ARGUMENTS - lists the currently defined command
                                  line arguments

Syntax 1:
    LIST
    L
 
    This lists the last 20 Dataplot commands.  The SET LIST LINES
    command can be used to specify how many commands are listed (up to
    a maximum of 200).  This command is typically used before a REPEAT
    or SAVE command to selectively re-execute recent Dataplot commands.
    Enter HELP REPEAT or HELP SAVE for details.
 
Syntax 2:
    LIST  <file name>
    where <file name> is the name of a file.
 
    This lists the entire contents of the specified file.  The SET LIST
    LINES command can be used to specify the number of lines to print
    at a time (to print one screen at a time).
 
Syntax 3:
    LIST  <file name> FOR I = <start> <inc> <stop>
    where <file name> is the file to list;
          <start> specifies the first line to list;
          <inc>   specifies the increment between lines (this is almost
                  always 1);
    and   <stop> specifies the last row to list.
 
    This syntax is useful for listing out selected parts of long files.
 
Syntax 4:
    LIST  <keyword>
    where <keyword> is one of DICTIONARY, DIRECTORY, MASTER, DEFINITIONS,
          DATASETS, PROGRAMS, MACROS, DESIGNS, DISTRIBU, COMMANDS,
          SYNTAX, FUNCTIONS, CONCLUSIONS, CLIPBOARD, FUNCTION BLOCK,
          STATISTIC BLOCK, LOOP LINES, or COMMAND LINE ARGUMENTS.

Syntax 5:
    LIST  NEW WINDOW <file name>
    where <file name> is the name of a file.
 
    This syntax displays the LIST output in a separate window.
    See the Note section below for details.

Syntax 6:
    LIST HEAD <file name>
    where <file name> is the name of a file.
 
    This syntax displays the first 10 lines of the file.  To
    modify the number of lines LIST HEAD prints, enter

       SET HEAD LINES <value>

    where <value> is a positive integer.

Syntax 7:
    LIST TAIL <file name>
    where <file name> is the name of a file.
 
    This syntax displays the last 10 lines of the file.  To
    modify the number of lines LIST TAIL prints, enter

       SET TAIL LINES <value>

    where <value> is a positive integer.

Syntax 8:
    LIST  EXCEL <file name>
    where <file name> is the name of a spreadsheet file.
 
    This syntax will display a spreadsheet file (not necessarily
    limited to Excel spreadsheets).

    See the Note section below for further information.

Syntax 9:
    LIST  WORD <file name>
    where <file name> is the name of a document file.
 
    This syntax will display a document file (not necessarily
    limited to Word files).

    See the Note section below for further information.

Syntax 10:
    LIST  POWER POINT <file name>
    where <file name> is the name of a presentation file.
 
    This syntax will display a presentation file (not necessarily
    limited to Power Point files).

    See the Note section below for further information.

Examples:
    LIST PLOTCALIB.
    LIST PROG.PLOTLAB
    LIST
    L
    LIST PLOT.DAT FOR I = 1 1 50
    LIST DATASETS
    LIST CLIPBOARD
 
Note:
    The LIST command lists 20 lines at a time.  You are then prompted
    with a "MORE?".  Enter <CR> to continue, NO to terminate the
    listing.  You can use the SET LIST LINES command to specify how
    many lines are listed at a time.
 
Note:
    The LIST command with a file name is often used to preview a file
    before carrying out a READ or a CALL--just to double-check the
    contents of the file.
 
Note:
    File names are currently limited to a maximum of 80 characters.
    File names are case sensitive on Linux/Unix/MacOS platforms, but
    not on Windows platforms.

    Dataplot will first try to open the file as given.  If it cannot
    find the file, it will then try to match the file with all
    upper case characters and then with all lower case characters.
    If it still cannot match the file name, it will search the Dataplot
    directories for the file.

    Currently, the maximum line length for the LIST command is
    255 characters.

Note:
    The CAT command is an alternative to the LIST command.  The CAT
    command issues an operating system command (cat for Linux/Unix/
    MacOS, TYPE for Windows) to list the file.

    The CAT command does not have the limits on the number of characters
    in the file name (the maximum number of characters on a command line
    is currently 255) and the limit on the number of characters on a
    single line.  However, the CAT command does not support the keywords
    in Syntax 4 and does not automatically search the Dataplot
    directories.

Note:
    The 2019/11 version of Dataplot added the following command

        SET LIST NEW WINDOW <ON/OFF>

    When this switch is set to ON, Dataplot will display the
    contents of the output from the LIST command in a separate
    window.

    Under Windows, the following command is issued to the operating
    system to display the dpst1f.dat file

       notepad  dpst1f.dat

    Under Linux/Unix/MacOS, the following command is issued to the
    operating system to display the dpst1f.dat file

       gnome-terminal -e "vi dpst1f.dat"

    You can specify a different viewer by entering the command

       SET LIST VIEWER <name>

    For example, you could enter the following

       SET LIST VIEWER emacs;   . Use emacs viewer for Linux

       . Use Notepad++ for Windows
       SET LIST VIEWER "C:\Program Files (x86)\Notepad++\notepad++.exe"

       . Use Wordpad for Windows
       SET LIST VIEWER write.exe; . Use Wordpad

    If <name> contains spaces or hypens, it should be enclosed
    in double quotes.

    For Linux/Unix/MacOS, you may need to specify something
    other than gnome-terminal to launch the new window.  We have
    tested the following

       SET LIST LAUNCHER  xterm -e
       SET LIST LAUNCHER  kconsole -e

    For Linux, the appropriate choice may depend on which
    desktops and applications are installed on your system.
    The gnome-terminal should be available if you run the
    gnome desktop and kconsole should be available if you
    run the KDE desktop.  Note that xterm is no longer
    installed by default on some newer Linux installations.

    Control is returned to the Dataplot window after the
    operating system command is entered (i.e., you can
    leave the LIST window open while you enter new Dataplot
    commands).

    To reset the default of LIST output appearing in the
    Dataplot window, enter

       SET LIST NEW WINDOW OFF

    For a single LIST command, you can enter

       LIST NEW WINDOW <file-name>

Note:
    The 2019/12 version of Dataplot added the following commands

        LIST EXCEL <file-name>
        LIST WORD <file-name>
        LIST POWER POINT <file-name>

    These commands are used to view various types of office files
    such as spreadsheets and document files.  Although we use EXCEL,
    WORD and POWER POINT in the command names, you are not limited
    to Microsoft Office files.

    By default, under Windows these commands will issue the following
    command

        SYSTEM <file-name>

    By default, under Linux/Unix these commands will issue the following
    command

        SYSTEM xdg-open <file-name>

    By default, under MacOS these commands will issue the following
    command

        SYSTEM open <file-name>

    These defaults will use the file name extension to determine the
    application to view the file.  This depends on an appropriate
    file association being defined on your system for a given file
    extension.  There may be cases where you do not want to use the
    default application.  For example, the default applications may
    be set by a system administrator and you prefer to use a different
    application.  Also, you may have a file with an extension for which
    no file association has been created.  Dataplot allows you to
    define a specific application to use for these types of files.

    To specify specific applications to use, you can enter the following
    commands

        SET EXCEL VIEWER "<application-name>"
        SET WORD VIEWER "<application-name>"
        SET POWER POINT VIEWER "<application-name>"

    Dataplot does no error checking to see if <application-name>
    is in fact installed on your system.

    For example, to explicitly use libreoffice applications under Linux,
    you could enter

        SET EXCEL VIEWER       "libreoffice --calc"
        SET WORD  VIEWER       "libreoffice --writer"
        SET POWER POINT VIEWER "libreoffice --impress"

    A few comments on this.

        i. The Dataplot LIST command does not check the file name
           extension.  You need to explicitly use LIST EXCEL, LIST WORD,
           or LIST POWER POINT to invoke the application.

       ii. Once the application is invoked, control returns to the
           Dataplot window.  So you can view the spreadsheet or document
           while still entering Dataplot commands.

      iii. There are a large number of spreadsheet and word processing
           programs each which tends to have their own file extensions.
           Although the Microsoft extensions (.xls, .xlsx, .doc, .docx,
           .ppt, .pptx) are likely to have file associations defined on
           most systems, this is less likely to be true for other
           spreadsheet or word processing programs.  In this case, you
           can either create the file association or use the
           SET EXCEL VIEWER, SET WORD VIEWER, or SET POWER POINT VIEWER
           commands to specify the desired application.

Note:
    If a Dataplot command starts with a file name, Dataplot interprets
    this as a CALL command.  For example, entering

        test.dp

    is equivalent to entering

        call test.dp

    Dataplot will now check the extension on the file name.
    Specifically

        i) If the file has a ".dat", ".DAT", ".csv", ".CSV", ".out",
           or ".OUT" extension, the following will be done

               LIST NEW WINDOW  <file-name>

       ii) If the file has a ".xls", ".XLS", ".xlsx", or ".XLSX"
           extension, the following will be done

               LIST EXCEL  <file-name>

           If the file has a ".doc", ".DOC", ".docx", or ".DOCX"
           extension, the following will be done

               LIST WORD  <file-name>

           If the file has a ".ppt", ".PPT", ".pptx", or ".PPTX"
           extension, the following will be done

               LIST POWER POINT  <file-name>

Default:
    If no file name or arguments are  provided, then the last 20
    entered Dataplot commands are listed.
 
Synonyms:
    L, VIEW, and PREVIEW are synonyms for LIST.
 
Related Commands:
    CAT              = List a file using an appropriate operating
                       system command.
    NLIST            = List a file with line numbers.
    SEARCH           = Search a file for a specified string.
    REPEAT           = Re-execute prior commands.
    SAVE             = Re-execute prior saved commands.
    READ             = Reads data (column-wise) into variables.
    WRITE            = Writes variables, parameters, or functions to
                       the screen or to a file.
    CALL             = Executes the commands in a "macro" file.
 
Applications:
    Interactive Usage
 
Implementation Date:
    Pre-1987
    1987/01: Support for DIRECTORY keyword
    1988/08: Support for DICTIONARY keyword
    1989/07: Support list output one page at a time
    1993/11: Support for DATASETS, DESIGNS, DISTRIBUTIONS, COMMANDS,
             SYNTAX, FUNCTIONS, PROGRAMS, and MACROS keywords
    2014/11: Support for CLIPBOARD keyword
    2015/09: Support for FUNCTION BLOCK keyword
    2016/08: Support for STATISTIC BLOCK keyword
    2016/10: Support for LIST COMMAND LINE ARGUMENTS keyword
    2017/07: Support for LOOP LINES keyword
    2018/06: Increase maximum line length from 80 to 255
    2019/11: Added LIST HEAD syntax
    2019/11: Added LIST TAIL syntax
    2019/11: Added LIST NEW WINDOW syntax
    2019/12: Added LIST EXCEL syntax
    2019/12: Added LIST WORD syntax
    2019/12: Added LIST POWER POINT syntax
 
Program:
    SKIP 25
    READ BERGER1.DAT Y X
    .
    SET WRITE DECIMALS 5
    CAPTURE FIT.OUT
    FIT Y X
    END OF CAPTURE
    .
    LIST FIT.OUT
 
-----LIST LINES (SET)--------------------------------------------
 
LIST LINES
 
Name:
    LIST LINES (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Define the number of lines to be printed to the screen when a LIST
    <file> command is entered.  Additionally, it is used to specify the
    number of commands listed when a LIST command with no arguments is
    entered.
 
Description:
    The LIST <file> command prints the contents of the file one screen
    at a time.  It then waits for a carriage return (or a "NO" to
    terminate the listing) to continue the listing.
 
    A LIST command with no arguments prints the most recently entered
    commands.  By default, the last 20 commands are listed.  The SET
    LIST LINES command can be used to change the number of commands
    that are listed  to any value between 1 and 200.  That is, SET
    LIST LINES 200 followed by a LIST with no arguments prints the
    200 most recent commands.
 
Syntax:
    SET LIST LINES <value>
    where <value> is an integer number or parameter in the range 1 to
               200 that specifies the number of lines for one screen.
 
Examples:
    SET LIST LINES 20
    SET LIST LINES 50
 
Default:
    Help screens are listed 20 lines at a time.
 
Synonyms:
    None
 
Related Commands:
    LIST               = List the contents of a file or list the most
                         recently entered commands.
    SET HELP LINES     = Define number of lines to a screen for the
                         HELP command.
 
Applications:
    Interactive usage
 
Implementation Date:
    Pre-1987
 
Program:
    SET LIST LINES 30
    LIST MACROS
 
-----LIST PLOT--------------------------------------------------
 
LIST PLOT
 
Name:
    LIST PLOT
 
Type:
    Support Command
 
Purpose:
    List the currently saved graphs (SAVE PLOT command) by
    sequence number, file name, and title.
 
Description:
    The SAVE PLOT and REPEAT PLOT commands allow you to save and
    recall graphs.  The primary use of this is to compare the current
    graph to previously created graphs.
 
    Dataplot maintains a list of saved graphs for the current
    session.  The "current list" consists of all plots saved in
    the current session and any plots from previous Dataplot
    sessions explicitly recalled with the REPEAT PLOT command.

    These commands are host dependent.  They are currently
    supported for the following platforms:
   
       1) Unix platforms via the X11 device driver;
       2) Windows 95/98/NT command line version built with the
          Microsoft Fortran compiler;
       3) Dataplot GUI (both Unix and Windows 95/98/NT).

Syntax:
    LIST  PLOT
 
Examples:
    READ FILE.DAT Y1 Y2 Y3
    HISTOGRAM Y1
    SAVE PLOT HIST.1
    HISTOGRAM Y2
    SAVE PLOT HIST.2
    HISTOGRAM Y3
    SAVE PLOT HIST.3
    LIST PLOTS
 
Default:
    None
 
Synonyms:
    LIST GRAPH, LP, and LG are all synonyms for LIST PLOT.

Note:
    The REPEAT PLOT command is used to display a plot saved
    with SAVE PLOT.  The LIST PLOT command lists the currently
    saved plots (by sequence number, file name, and title).
    The CYCLE PLOT command allows you to cycle through the
    pixmaps in the current list by clicking mouse buttons.
    The PIXMAP TITLE command allows you to specify the title
    for a saved plot.  This title is simply for ease of
    identification in listing the saved plots and is not
    saved as part of the plot.
 
Related Commands:
    LIST PLOT    = List saved plots.
    REPEAT PLOT  = Redraw a previously saved plot.
    SAVE PLOT    = Save a plot.
    CYCLE PLOT   = Cycle through previously saved graphs using 
                   mouse buttons.
    PIXMAP TITLE = Provide a temporary name for a saved graph.
 
Applications:
    Interactive Usage
 
Implementation Date:
    7/1997
 
Program:
    READ BERGER1.DAT Y X
    FIT Y X
    4-PLOT RES
    SAVE PLOT RES.1
    QUADRATIC FIT Y X
    4-PLOT RES
    SAVE PLOT RES.2
    LIST PLOT
 
-----LJUNG-BOX TEST------------------------------------
 
LJUNG BOX TEST
 
Name:
    LJUNG-BOX TEST
 
Type:
    Analysis Command
 
Purpose:
    Perform a Ljung-Box test for randomness.
 
Description:
    There are a large number of tests of randomness (e.g.,
    the runs tests).  Autocorrelation plots are one common method
    test for randomness.  The Ljung-Box test is based on the
    autocorrelation plot.  However, instead of testing randomness
    at each distinct lag, it tests the "overall" randomness based
    on a number of lags.  For this reason, it is often referred to
    as a "portmanteau" test.

    More formally, the Ljung-Box test can be defined as follows.

    H0:          The data are random.
    Ha:          The data are not random.

    Test         Q(LB) = n*(n+2)*SUM[j=1 to h][r(j)**2/(n-j)]
    Statistic:   where n is the sample size, r(j) is the
                 autocorrelation at lag j, and h is the number of
                 lags being tested.

    Significance alpha
    Level:
    
    Critical     The hypothesis of randomness is rejected if
    Region:          Q(LB) > CHSPPF((1-alpha),h)
                 where CHSPPF is the percent point function
                 of the chi-square distribution.
 
    The Ljung-Box test is commonly used in ARIMA modeling.  Note that
    it is applied to the residuals of a fitted ARIMA model, not the
    original series.

Syntax:
    LJUNG-BOX TEST   <y>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable being tested;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LJUNG-BOX TEST RES
    LJUNG-BOX TEST Y1 SUBSET TAG > 1
 
Note:
    The number of lags to test can be set by entering any of the
    following command (before entering the LJUNG-BOX command):

        LET LAGS = <value>
        LET LAG = <value>
        LET NUMLAG = <value>

    By default, Dataplot will use the same number of lags as the
    autocorrelation plot.  Typically, you will want to test fewer
    lags.  Although the choice is somewhat arbitrary, 25 is a
    reasonable number for many series.

Note:
    The following statistic is also supported:

        LET A = LJUNG BOX TEST Y<BR>

    In addition to the above LET command, built-in statistics are
    supported for about 20+ different commands (enter HELP STATISTICS
    for details).

Default:
    None
 
Synonyms:
    LJUNG TEST and  LJUNG-BOX are synonyms for LJUNG-BOX TEST.
 
Related Commands:
    AUTOCORRELATION PLOT   = Generate an autocorrelation plot.
    RUNS TEST              = Perform a runs test for randomness.
    ARMA                   = Perform an ARIMA fit.
 
Reference:
    "On a Measure of a Lack of Fit in Time Series Models",
    G. M. Ljung and G. E. P. Box, Biometrika, 1978, 65, pp. 297-303.

    "Introduction to Time Series and Forecasting", 2nd. Ed.,
    Peter Brockwell and Richard Davis, Springer, 2002, p. 36.
 
Applications:
    ARIMA Modeling
 
Implementation Date:
    2003/2
 
Program:
    READ NEGIZ4.DAT X1 X2 Y
    ARMA Y 2 1 0
    LET NUMLAG = 25
    LJUNG-BOX TEST RES

    The following output is generated:

           **************************
           **  ljung-box test res  **
           **************************


                   LJUNG-BOX TEST FOR RANDOMNESS

     1. STATISTICS:
           NUMBER OF OBSERVATIONS      =      559
           LAG TESTED                  =       25
           LAG 1 AUTOCORRELATION       =  -0.1012441E-02
           LAG 2 AUTOCORRELATION       =   0.6160716E-02
           LAG 3 AUTOCORRELATION       =   0.5182213E-02

        LJUNG-BOX TEST STATISTIC       =    31.93575

     2. PERCENT POINTS OF THE REFERENCE CHI-SQUARE DISTRIBUTION
        (REJECT HYPOTHESIS OF RANDOMNESS IF TEST STATISTIC VALUE
        IS GREATER THAN PERCENT POINT VALUE)
        FOR LJUNG-BOX TEST STATISTIC
           0          % POINT    =          0.
           50         % POINT    =    24.33659
           75         % POINT    =    29.33885
           90         % POINT    =    34.38158
           95         % POINT    =    37.65248
           99         % POINT    =    44.31411


     3. CONCLUSION (AT THE 5% LEVEL):
           THE DATA ARE RANDOM.
 
-----LLGCDF (LET)--------------------------------
 
LLGCDF
 
Name:
    LLGCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard form of the log-logistic cumulative
    distribution function with shape parameter delta.
 
Description:
    The standard form of the log-logistic distribution has the
    following cumulative distribution function:
       F(x,delta) = 1/(1+x**-delta)      x, delta > 0
 
Syntax:
    LET <y> = LLGCDF(<x>,<delta>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, number, or a parameter;
          <y> is a variable, number, or a parameter (depending
              on what <x> is) where the computed log-logistic pdf
              value is stored;
          <delta> is a variable, number, or a parameter that
              specifies the shape parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LLGCDF(3,2)
    LET X2 = LLGCDF(X1,DELTA)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LLGPDF = Compute the log-logistic probability density function.
    LLGPPF = Compute the log-logistic percent point function.
    LOGPDF = Compute the logistic probability density function.
    GLOPDF = Compute the generalized logistic probability density
             function.
    HFLPDF = Compute the half-logistic probability density function.
    NORPDF = Compute the normal probability density function.
    LGNPDF = Compute the logmormal probability density function.
 
Reference:
    "Measuring Skewness With Respect To The Mode", Arnold and
    Groeneveld, The American Statistician, February, 1995,
    (page 36).
 
Applications:
    Lifetime Analysis
 
Implementation Date:
    1995/5
 
Program:
    MULTIPLOT 3 3
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE AUTOMATIC
    LET D = DATA 0.1  0.5  1.0  1.5  2.0  2.5  5  10  20
    .
    LOOP FOR K = 1 1 9
       LET D1 = D(K)
       X1LABEL DELTA = ^D1
       PLOT LLGCDF(X,DELTA) FOR X = 0.01 0.01 5
    END OF LOOP
    END OF MULTIPLOT
 
-----LLGPDF (LET)--------------------------------
 
LLGPDF
 
Name:
    LLGPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard form of the log-logistic probability
    density function with shape parameter delta.
 
Description:
    The standard form of the log-logistic distribution has the
    following probability density function:
       f(x,delta) = delta*x**(delta-1)/[(1+x**delta)**2]  x, delta > 0
 
Syntax:
    LET <y> = LLGPDF(<x>,<delta>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, number, or a parameter;
          <y> is a variable, number, or a parameter (depending
              on what <x> is) where the computed log-logistic pdf
              value is stored;
          <delta> is a variable, number, or a parameter that
              specifies the shape parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LLGPDF(3,2)
    LET X2 = LLGPDF(X1,DELTA)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LLGCDF = Compute the log-logistic cumulative distribution
             function.
    LLGPPF = Compute the log-logistic percent point function.
    LOGPDF = Compute the logistic probability density function.
    GLOPDF = Compute the generalized logistic probability density
             function.
    HFLPDF = Compute the half-logistic probability density function.
    NORPDF = Compute the normal probability density function.
    LGNPDF = Compute the logmormal probability density function.
 
Reference:
    "Measuring Skewness With Respect To The Mode", Arnold and
    Groeneveld, The American Statistician, February, 1995,
    (page 36).
 
Applications:
    Lifetime Analysis
 
Implementation Date:
    1995/5
 
Program:
    MULTIPLOT 3 3
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE AUTOMATIC
    LET D = DATA 0.1  0.5  1.0  1.5  2.0  2.5  5  10  20
    .
    LOOP FOR K = 1 1 9
       LET D1 = D(K)
       X1LABEL DELTA = ^D1
       PLOT LLGPDF(X,DELTA) FOR X = 0.01 0.01 5
    END OF LOOP
    END OF MULTIPLOT
 
-----LLGPPF (LET)--------------------------------
 
LLGPPF
 
Name:
    LLGPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard form of the log-logistic percent point
    function with shape parameter delta.
 
Description:
    The standard form of the log-logistic distribution has the
    following percent point function:
       G(p,delta) = ((1-p)/p)**(-1/delta)    0 < p < 1,  delta > 0
 
Syntax:
    LET <y> = LLGPPF(<p>,<delta>)  <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, number, or a parameter;
          <y> is a variable, number, or a parameter (depending
              on what <p> is) where the computed log-logistic ppf
              value is stored;
          <delta> is a variable, number, or a parameter that
              specifies the shape parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LLGPPF(0.95,2)
    LET X2 = LLGPPF(P1,DELTA)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LLGCDF = Compute the log-logistic cumulative distribution
             function.
    LLGPDF = Compute the log-logistic probability density function.
    LOGPDF = Compute the logistic probability density function.
    GLOPDF = Compute the generalized logistic probability density
             function.
    HFLPDF = Compute the half-logistic probability density function.
    NORPDF = Compute the normal probability density function.
    LGNPDF = Compute the logmormal probability density function.
 
Reference:
    "Measuring Skewness With Respect To The Mode", Arnold and
    Groeneveld, The American Statistician, February, 1995,
    (page 36).
 
Applications:
    Lifetime Analysis
 
Implementation Date:
    1995/5
 
Program:
    MULTIPLOT 3 3
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE AUTOMATIC
    LET D = DATA 0.1  0.5  1.0  1.5  2.0  2.5  5  10  20
    .
    LOOP FOR K = 1 1 9
       LET D1 = D(K)
       X1LABEL DELTA = ^D1
       PLOT LLGPPF(P,DELTA) FOR P = 0.01 0.01 0.99
    END OF LOOP
    END OF MULTIPLOT
 
-----L MOMENTS (LET)------------------------------
 
L MOMENTS
 
Name:
    L MOMENTS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the sample L-moment ratios of a variable.
 
Description:
    Given a random variable X with a cumulative distribution
    function F, the probability weighted moments are defined
    to be:

        M(p,r,s) = E[X**p{F(X)}**r{1 - F(X)}**s]

    Two special cases are

        alpha(r) = M(1,0,r) = E[X{1 - F(X)}**r]
        beta(r)  = M(1,r,0) = E[X{F(X)}**r]

    The L-moments are defined as

        tau(r) = E{X*P*(r-1){F(X)}}

    with P*(r)(.) denoting the rth shifted Legendre ploynomials.
    The L-moment estimators are linear combinations of order
    statistics.

    L-moments are related to probability weighted moments by
    the equation

        lamda(r+1) - SUM[k=0 to r][p*(r,k)*beta(k)]

    where

        p*(r,k) = (-1)**(r-k)*(r k)*(r+k  k)

    with (a b) denoting the binomal coefficient

        (a b) = a!*/(b!*(a-b)!)

    The L-moment ratios are defined to be

        lambda(r) = lambda(r)/lambda(2)

    This command returns the L-moment estimates for orders 1 and 2
    and L-moment ratios for higher orders.

    For an ordered sample x(1:n) <= x(2:n) <= ... <= x(n:n),
    the sample probability weighted and l-moments are

        a(r) = (1/n)*SUM[j=1 to n][(n-j)*(n-j-1)* ... *(n-j-r+1)/
               ((n-1)*(n-2)* ... *(n-r))]*xj:n

        b(r) = (1/n)*SUM[j=1 to n][(j-1)*(j-2)* ... *(j-r)/
               ((n-1)*(n-2)* ,,,*(n-r))]*xj:n
        l(r+1) = SUM[k=0 to r][p*(r,k)*b(k)

    The primary use of probability weighted moments and L-moments
    is in the estimation of parameters for a probability
    distribution.  Estimates based on probability weighted moments
    and L-moments are generally superior to standard moment-based
    estimates.  The L-moment estimators have some desirable
    properties for parameter estimation.  In particular, they are
    robust with respect to outliers and their small sample bias
    tends to be small.  L-moment estimators can often be
    used when the maximum likelihood estimates are unavailable,
    difficult to compute, or have undesirable properties.  They
    may also be used as starting values for maximum likelihood
    estimates.

    Estimation methods based on L-moments are discussed 
    in the papers listed in the Reference section below (Dataplot
    generates L-moment based estimates for the maximum likelihood
    estimates for the generalized Pareto and the generalized
    extreme value distributions).

Syntax:
    LET <y> = L MOMENTS <x> <nmom>  <SUBSET/EXCEPT/FOR qualification>
    where <x> is the response variable;
          <nmom> is the number of L-moments that will be generated;
          <y> is a variable where the computed L-moments are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET XMOM = L MOMENTS Y 5
    LET XMOM = L MOMENTS Y 4  SUBSET Y > 0
 
Note:
    Dataplot computes L-moments using the SAMLMU routine written
    by Hoskings and documented in "Research Report: Fortran Routines
    for use with the Method of L-Moments" (see the Reference section
    below).

    Hoskings software provides L-moment estimators for 11 different
    distributions.  Dataplot currently implements the L-moment
    estimates for the generalized Pareto and generalized extreme
    value distributions.  To obtain these estimates, enter
    the commands

        GENERALIZED PARETO MAXIMUM LIKELIHOOD Y
        GENERALIZED EXTREME VALUE MAXIMUM LIKELIOHOOD Y

    We plan to implement the L-moment estimators for additional
    distributions in future releases of Dataplot.

Default:
    If the <nmom> parameter is omitted from the command, the
    first four sample l-moments are computed.

Synonyms:
    None
 
Related Commands:
    PROBABILITY WEIGHTED MOMENTS  = Compute the sample probability
                                    weighted moments of a variable.
    MAXIMUM LIKELIHOOD            = Compute maximum likelihood
                                    estimates for a probability
                                    distribution.

References:
    "Research Report: Fortran Routines for use with the Method
    of L-Moments", J. R. M. Hosking, IBM Research Division,
    T. J. Watson Research Center, Yorktown Heights, NY 10598,
    6/2000.
 
    "L-moments: Analysis and Estimation of Distribution using
    Linear Combinations of Order Statistics", Hoskings, Journal
    of the Royal Statistical Society, Series B, 52, 1990,
    pp. 105-124.

    "The Estimation of Extreme Quantiles of Wind Velocity Using
    L-Moments in the Peaks-Over-Threshold Approach", Pandey,
    Van Gelder, and Vrijling, Structural Safety, 23, 2001,
    pp. 179-192.

    "Probability Weighted Moments: Definition and Relation to
    Parameters of Several Distributions Expressable in Inverse
    Form", Greenwood, Landwehr, Matalas, and Wallis, Water
    Resources Research, 15, 1979, 1049-1054.

    "Estimation of the Generalized Extreme Value Distribution
    by the Method of Probability-Weighte Moments", Hosking,
    Wallis, and Wood, Technometrics, 27, 1985, 251-261.

    "Probability Weighted Moments Compared with Some Traditional
    Techniques in Estimating Gumbel Parameters and Quantiles",
    Landwehr, Matalas, Wallis, Water Resources Research,
    15, (1979a), 1055-1064.

    "Extreme Value and Related Models with Applications in
    Engineering and Science", Castillo, Hadi, Balakrishnan, and
    Sarabia, Wiley, 2005, pp. 117-119.

Applications:
    Distributional Modeling
 
Implementation Date:
    2005/6
 
Program:
    LET GAMMA = -0.3
    LET Y = GENERALIZED PARETO RANDOM NUMBERS FOR I = 1 1 100
    LET Y = 5*Y
    LET NMOM = 3
    LET XMOM = L MOMENTS Y NMOM
    PRINT XMOM
    GENERALIZED PARETO MLE Y

-----LN-------------------------------------------------------
 
LN
 
Name:
    LN (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the natural logarithm of a number.
 
Description:
    The natural logarithm is the inverse of the function:
          y = e**x
    That is, given the value of y, the log is the value of the
    exponent.  The input value must be greater than zero.
 
    Logarithms are a commonly used transformation.  The two primary
    reasons are to normalize a skewed data set or to reduce the
    magnitude of large scale numbers.
 
Syntax:
    LET <y2> = LN(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter containing positive decimal
               number(s);
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed natural logarithms are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LN(14)
    LET A = LN(A1)
    LET X2 = LN(X1)
    LET X2 = LN(X1-4)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
    None
 
Synonyms:
    LOG
 
Related Commands:
    OCTDEC = Perform an octal to decimal conversion of a number.
    MOD    = Compute the modulo.
    INT    = Compute the integer portion of number.
    FRACT  = Compute the fractional portion of number.
    LOG10  = Compute the base 10 logarithm of a number.
    LOG2   = Compute the base 2 logarithms of a number.
    LOG    = Specify logarithmic scales on either the X or Y axis.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    TITLE AUTOMATIC
    PLOT LN(X) FOR X = .01 .01 9.9
 
-----LNBETA (LET)--------------------------------
 
LNBETA
 
Name:
    LNBETA (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the logarithm of the Beta function.
 
Description:
    The logarithmic Beta function is defined as:
        LNBETA(A,B) = LN(INTEGRAL(t**(A-1)*(1-t)**(b-1)dt)
    where the integral is taken from 0 to 1 and A and B are positive
    real numbers.

Syntax:
    LET <y2> = LNBETA(<a>,<b>)  <SUBSET/EXCEPT/FOR qualification>
    where <a> is a positive number, variable, or parameter;
          <b> is a positive number, variable, or parameter;
          <y2> is a variable or a parameter (depending on what <a> and
               <b> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LNBETA(1,2)
    LET A = LNBETA(A1,B3)
    LET X2 = LNBETA(X,2)
 
Note:
    DATAPLOT uses the routine DLBETA from the SLATEC Common
    Mathematical Library to compute this function.  SLATEC is a large
    set of high quality, portable, public domain Fortran routines for
    various mathematical capabilities maintained by seven federal
    laboratories.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    LOGBETA is a synonym for LNBETA.
 
Related Commands:
    BETAI      = Compute the incomplete Beta function.
    BETA       = Compute the Beta function.
    GAMMA      = Compute the gamma function.
    LOGGAMMA   = Compute the log gamma function.
 
Reference:
    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 6).
 
Applications:
    Special Functions
 
Implementation Date:
    94/9
 
Program:
    TITLE AUTOMATIC
    PLOT LNBETA(X,4) FOR X = 1 1 100
 
-----LOBACH (LET)--------------------------------
 
LOBACH
 
Name:
    LOBACH (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Lobachevski's integral.
 
Description:
    The Lobachevski's integral is defined as:

        f(x) = INTEGRAL[LOG(ABS(COS(t)))dt],   x >= 0

    where the integral is defined from 0 to x.

    Dataplot computes this function using ACM Algorithm 757 (see
    Reference: below).
 
Syntax:
    LET <y> = LOBACH(<x>)    <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, variable or parameter;
          <y> is a variable or a parameter (depending on what <x> 
              is) where the computed Lobachevski's integral values
              are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOBACH(2)
    LET A = LOBACH(X) 
    LET X2 = LOBACH(X) FOR X1 = 0.1 0.1 3.0
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    ABRAM      = Compute the Abramowitz integral.
    CLAUSN     = Compute the Clausen integral.
    DEBYE      = Compute the Debye function.
    EXP3       = Compute the cubic exponential integral.
    GOODST     = Compute the Goodwin and Stanton integral.
    SYNCH1     = Compute the synchrotron radiation function.
    SYNCH2     = Compute the synchrotron radiation function.
    STROM      = Compute the Stromgren integral.
    TRAN       = Compute the transport integral.
 
Reference:
    "ACM Transactions of Mathematical Software", Allan MacLead,
    Vol. 22, No. 3, September, 1996, pp. 288-301.
 
Applications:
    Special Functions
 
Implementation Date:
    1999/6
 
Program:
    TITLE AUTOMATIC
    PLOT LOBACH(X) FOR X = 0 0.01 10
 
-----LOFCDF-------------------------------------------------------
 
LOFCDF
 
Name:
    LOFCDF
 
Type:
    Keyword
 
Purpose:
    An internal DATAPLOT parameter into which the lack of fit F test
    cumulative distribution function value (a measure of goodness of
    fit) is automatically placed whenever the FIT, SPLINE FIT, ANOVA,
    and MEDIAN POLISH commands are executed.
 
Description:
    The stored value is between 0 ands 100%.  The hypothesis being
    tested is that the given model is adequate.  As a rough rule of
    thumb, a value of the lack-of-fit cdf in the "body" of the F
    distribution (0 to 95%) indicates that no evidence exists from the
    data to reject this hypothesis (that is, the model is
    "acceptable");  a value of the lack-of-fit cdf larger than 95%
    indicates that evidence does exist from the data to reject the the
    model (that is, the model is not acceptable).
 
Syntax:
    None
 
Examples:
    WRITE LOFCDF
    WRITE CALIB. REPSD RESSD LOFCDF
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    FIT           = Carries out a least squares fit.
    SPLINE FIT    = Carries out a spline fit.
    ANOVA         = Carries out an ANOVA.
    MEDIAN POLISH = Carries out a median polish.
 
    RESSD         = A parameter where the residual standard deviation
                    is stored.
    RESDF         = A parameter where the residual degrees of freedom
                    is stored.
    REPSD         = A parameter where the replication standard
                    deviation is stored.
    REPDF         = A parameter where the replication degrees of
                    freedom is stored.
 
Applications:
    Fitting
 
Implementation Date:
    XX
 
Program:
    XX
 
-----LOG-------------------------------------------------------
 
LOG
 
Name:
    ...LOG
 
Type:
    Plot Control Command
 
Purpose:
    Specifies whether or not a log scale is to appear on plot axes of
    subsequent plots.
 
Description:
    There are 2 scales available--linear and log.  The default is
    linear.  The analyst can independently control the log scale of the
    horizontal and vertical axes by specifying the pre-fix in the
    command (see the SYNTAX section).
 
Syntax:
    <prefix>LOG   <ON or OFF>
    where ON specifies a LOG scale while OFF reverts back to a linear
             scale;
    and   <prefix> is one of the following:
             X             refers to vertical grids
             Y             refers to horizontal grids
             no prefix     refers to both grid lines.
 
Examples:
    LOG ON
    XLOG ON
    YLOG ON
    LOG OFF
    XLOG OFF
    YLOG OFF
    LOG
    XLOG
    YLOG
 
Note:
    If you use the LIMITS command, log scales are rounded to the
    nearest power of 10 that includes the values.  For example,
    LIMITS 15 975 goes from 10 to 1000.  Sometimes when you specify an
    exact power of 10 DATAPLOT goes to the next power of 10 (e.g.,
    LIMITS 0.001 100 might go from 0.0001 to 100).  This is caused by
    rounding and can be avoided by adding a small fudge factor.  In the
    example above, use LIMITS 0.0015 99.5.
 
Note:
    Sometimes log scales can have a large amount of empty space since
    DATAPLOT rounds to powers of 10.  For example, if your data go from
    1 to 1100, DATAPLOT sets the upper limit to 10,000.  The solution
    to this problem is to use the TIC OFFSET command:
       TIC OFFSET UNITS DATA
       YLOG ON
       YLIMITS 1.1 999
       YTIC OFFSET 0 120
    Enter HELP TIC OFFSET for details.
 
Note:
    The tic labels for log scales can be drawn in 3 different formats:
       1) The power of 10 (e.g., for 0.1 to 100, it prints -1, 0, 1, 2
          for the tic labels).  This is the default.
       2) The linear value (e.g., 0.1, 1, 10, 100).
       3) Exponential format (10 raised to the appropriate power).
          This format requires the tic labels to use a software font
          (use TIC LABEL FONT command to set) since the power of 10 is
          printed as a superscript.
    Enter HELP TIC LABEL FORMAT for details.
 
Note:
    The ...LOG command with no argument is equivalent to ...LOG ON.  A
    ...LOG command with no prefix refers to both axes.  Thus LOG ON
   sets both axes to log scale.
 
Default:
    The default is linear scales on both axes.
 
Synonyms:
    LOGLOG ON/OFF is equivalent to LOG ON/OFF.
 
Related Commands:
    PLOT           = Generates a data or function plot.
    LOG (LET)      = Compute the log of a number or variable.
    FRAME          = Sets the on/off switch for the plot frame.
    GRID           = Sets the on/off switch for the plot grid.
    TIC            = Sets the on/off switch for the plot tics.
    TIC LABEL      = Sets the on/off switch for the plot tic labels.
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
 
Program:
    SERIAL READ Y
       760.   2042.  2111.   1684.  3888.  1858.  11379.  17560.
     39287.  64382.  113159.  175108.  273291.  400186.  581243.
    811568.  1121004.  1506550.  2002767.  2611612.  3369180.
    END OF DATA
    SERIAL READ X
           0.  1.  32.  243.  1024.  3125.  7776.  16807.  32768.
       59049.   100000.  161051.  248832.  371293.  537824.  759375.
     1048576.  1419857.  1889568.  2476099.  3200000.
    END OF DATA
    .
    TITLE SIZE 2
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE LINEAR SCALE
    PLOT Y X
    TITLE LOG SCALES (POWER FORMAT)
    LOG ON
    LET X = 0.0001 SUBSET X <= 0
    PLOT Y X
    TITLE LOG SCALE (REAL FORMAT)
    TIC LABEL FORMAT REAL
    PLOT Y X
    TITLE LOG SCALE (EXPONENTIAL FORMAT)
    TIC LABEL FORMAT EXPONENTIAL
    TIC LABEL FONT DUPLEX
    PLOT Y X
    END OF MULTIPLOT
 
 
LOG
 
Name:
    LOG (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the natural logarithm of a number.
 
Description:
    The natural logarithm is the inverse of the function:
          y = e**x
    That is, given the value of y, the log is the value of the
    exponent.  The input value must be greater than zero.
 
    Logarithms are a commonly used transformation.  The two primary
    reasons are to normalize a skewed data set or to reduce the
    magnitude of large scale numbers.
 
Syntax:
    LET <y2> = LOG(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter containing positive decimal
               number(s);
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed natural logarithms are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOG(14)
    LET A = LOG(A1)
    LET X2 = LOG(X1)
    LET X2 = LOG(X1-4)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    LN
 
Related Commands:
    OCTDEC = Perform an octal to decimal conversion of a number.
    MOD    = Compute the modulo.
    INT    = Compute the integer portion of number.
    FRACT  = Compute the fractional portion of number.
    LOG10  = Compute the base 10 logarithm of a number.
    LOG2   = Compute the base 2 logarithms of a number.
    LOG    = Specify logarithmic scales on either the X or Y axis.
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
 
Program:
    TITLE AUTOMATIC
    PLOT LOG(X) FOR X = .01 .01 9.9
 
-----LOG2-------------------------------------------------------
 
LOG2
 
Name:
    LOG2 (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the base 2 logarithm of a number.
 
Description:
    The base 2 logarithm is the inverse of the function:
          y = 2**x
    That is, given the value of y, the log is the value of the
    exponent.  The input value must be greater than zero.
 
    Logarithms are a commonly used transformation.  The two primary
    reasons are to normalize a skewed data set or to reduce the
    magnitude of large scale numbers.
 
Syntax:
    LET <y2> = LOG2(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter containing decimal
               number(s);
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed base 2 logarithms are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOG2(14)
    LET A = LOG2(A1)
    LET X2 = LOG2(X1)
    LET X2 = LOG2(X1-4)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    OCTDEC = Perform an octal to decimal conversion of a number.
    MOD    = Compute the modulo.
    INT    = Compute the integer portion of number.
    FRACT  = Compute the fractional portion of number.
    LOG10  = Compute the base 10 logarithm of a number.
    LN     = Compute the natural logarithms of a number.
    LOG    = Specify logarithmic scales on either the X or Y axis.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    TITLE AUTOMATIC
    PLOT LOG2(X) FOR X = .01 .01 9.9
 
-----LOG10-------------------------------------------------------
 
LOG10
 
Name:
    LOG10 (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the base 10 logarithm of a number.
 
Description:
    The base 10 logarithm is the inverse of the function:
          y = 10**x
    That is, given the value of y, the log is the value of the
    exponent.  The input value must be greater than zero.
 
    Logarithms are a commonly used transformation.  The two primary
    reasons are to normalize a skewed data set or to reduce the
    magnitude of large scale numbers.
 
Syntax:
    LET <y2> = LOG10(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter containing decimal
               number(s);
          <y2> is a variable or a parameter (depending on what
               <y1> is) where the computed base 10 logarithms
               are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOG10(14)
    LET A = LOG10(A1)
    LET X2 = LOG10(X1)
    LET X2 = LOG10(X1-4)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    OCTDEC = Perform an octal to decimal conversion of a number.
    MOD    = Compute the modulo.
    INT    = Compute the integer portion of number.
    FRACT  = Compute the fractional portion of number.
    LOG2   = Compute the base 2 logarithms of a number.
    LN     = Compute the natural logarithm of a number.
    LOG    = Specify logarithmic scales on either the X or Y axis.
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
 
Program:
    TITLE AUTOMATIC
    PLOT LOG10(X) FOR X = .01 .01 9.9
 
-----LOGCDF (LET)--------------------------------
 
LOGCDF
 
Name:
    LOGCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard logistic (i.e, mean=0, sd=PI/sqrt(3))
    cumulative distribution function.
 
Description:
    The standard form of the logistic distribution has the following
    probability density function:
       f(x) = exp(x)/(1+exp(x))**2
    The cumulative distribution is the area from negative infinity to x
    (i.e., the integral of the above function).  It has the formula:
       F(x) = exp(x)/(1+exp(x))        for x <  0
       F(x) = 1/(1+exp(-x))            for x >= 0
 
Syntax:
    LET <y2> = LOGCDF(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed logistic cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOGCDF(3)
    LET X2 = LOGCDF(X1)
 
Note:
    The general form of the logistic distribution has the following
    probability density function:
       f(x) = exp((x-u)/sigma)/(sigma*(1+exp((x-u)/sigma))**2)
    where u is the location parameter and sigma is the scale
    parameter.  The general form of the cumulative distribution
    function is:
       F(x) = exp((x-u)/sigma)/(1+exp((x-u)/sigma))    for x <  0
       F(x) = 1/(1+exp(-(x-u)/sigma))                  for x >= 0
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGPDF = Compute the logistic probability density function.
    LOGPPF = Compute the logistic percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
    LGNCDF = Compute the logmormal cumulative distribution function.
    LGNPDF = Compute the logmormal probability density function.
    LGNPPF = Compute the logmormal percent point function.
    EXPCDF = Compute the exponential cumulative distribution function.
    EXPPDF = Compute the exponential probability density function.
    EXPPPF = Compute the exponential percent point function.
 
Reference:
    "Continuous Univariate Distributions - Volume 2", Johnson, Kotz,
    and Balakrisnan, Wiley, 1994, chapter 23.
 
    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 124-128.
 
    "Statistical Models and Methods for Lifetime Data", Lawless,
    John Wiley, 1982 (pp. 46-47).
 
Applications:
    Distributional Modeling
 
Implementation Date:
    94/4
 
Program:
    YLIMITS 0 1
    MAJOR YTIC NUMBER 6
    MINOR YTIC NUMBER 1
    YTIC DECIMAL 1
    XLIMITS -7 7
    XTIC OFFSET 0.6 0.6
    TITLE AUTOMATIC
    PLOT LOGCDF(X) FOR X = -7.5 0.01 7.5
 
-----LOGCHAZ (LET)--------------------------------
 
LOGCHAZ
 
Name:
    LOGCHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the logistic cumulative hazard function.
 
Description:
    The standard form of the logistic distribution has the following
    cumulative hazard function:

       H(x) = LOG(1 + EXP(-x))
 
Syntax:
    LET <y> = LOGCHAZ(<x>)     <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed logistic cumulative hazard value
              is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOGCHAZ(3)
    LET X2 = LOGCHAZ(X1)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGCDF  = Compute the logistic cumulative distribution function.
    LOGHAZ  = Compute the logistic hazard function.
    LOGPDF  = Compute the logistic probability density function.
    LOGPPF  = Compute the logistic percent point function.
    NORPDF  = Compute the normal probability density function.
    LGNPDF  = Compute the logmormal probability density function.
    EXPPDF  = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions - Volume 2", Johnson, Kotz,
    and Balakrisnan, Wiley, 1994, chapter 23.
 
    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 124-128.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2003/10
 
Program:
    XLIMITS -5 5
    XTIC OFFSET 0.5 0.5
    TITLE AUTOMATIC
    PLOT LOGCHAZ(X) FOR X = -5  0.01  5
 
-----LOGGAMMA-------------------------------------------------------
 
LOGGAMMA
 
Name:
    LOGGAMMA (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the natural logarithm of a gamma function.
 
Description:
    The gamma function is defined as:
        GAMMA(ALPHA) = INTEGRAL(X**(ALPHA-1)*EXP(-X)dx)
    where the integral is taken from 0 to infinity and ALPHA is a
    positive real number.  The loggamma function takes the natural
    logarithm of this number.
 
    The loggamma function is typically used for numerical stability
    (the regular gamma function tends to overflow for even moderate
    values of alpha).
 
Syntax:
    LET <y2> = LOGGAMMA(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter containing positive values;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed loggamma values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOGGAMMA(14)
    LET A = LOGGAMMA(A1)
    LET X2 = LOGGAMMA(X1)
    LET X2 = LOGGAMMA(X1-4)
 
Note:
    For integer values of ALPHA, the gamma function redues to a
    factorial.  Specifically,
        GAMMA(ALPHA)=(ALPHA-1)!
 
Note:
    The Beta function can be computed from the gamma function.
        BETA(Z,W) = GAMMA(Z)*GAMMA(W)/GAMMA(Z+W)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    LNGAMMA is a synonym for LOGGAMMA.
 
Related Commands:
    LOG    = Compute the natural logarithm of a number.
    GAMMA  = Compute the gamma function of a number.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    TITLE AUTOMATIC
    PLOT LOGGAMMA(X) FOR X = 0.01 0.01 9.9
 
-----LOGICAL (LET)-----------------------------------------------------
 
LOGICAL
The following are DATAPLOT logical commands:
    LOGICAL AND (LET)       = Carries out a logical and.
    LOGICAL OR (LET)        = Carries out a logical or.
    LOGICAL NAND (LET)      = Carries out a logical negative and.
    LOGICAL NOR (LET)       = Carries out a logical nor.
    LOGICAL XOR (LET)       = Carries out a logical xor.
    LOGICAL IFTHEN (LET)    = Carries out a logical if-then.
    LOGICAL IFF (LET)       = Carries out a logical if-and-only-if.
    LOGICAL NOT (LET)       = Carries out a logical not.
 
-----LOGICAL AND (LET)-------------------------------------------
 
LOGICAL AND
 
Name:
    LOGICAL AND (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the "and" (= logical conjunction) of 2 variables (with
    0-1 numeric elements).
 
Description:
    Logical and means that the result is true only if both the input
    values are true.  Otherwise, the result is false.  DATAPLOT codes
    logical values with 0 and 1's.  The value 1 means "true" and the
    value 0 means "false".
 
    The "and" of the 4-element variable--
          1 1 0 0
    and the 4-element variable--
          1 0 1 0
    is the 4-element variable--
          1 0 0 0
 
Syntax:
    LET <v3> = LOGICAL AND <v1> <v2> <SUBSET/EXCEPT/FOR qualification>
    where <v1> is the first     variable;
          <v2> is the second    variable;
          <v3> is the resultant variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Examples:
    LET Y3  = LOGICAL AND Y1 Y2
    LET Y3  = LOGICAL AND Y1 Y2 SUBSET Y1 = 1
    LET Y3  = LOGICAL AND Y1 Y2 FOR I = 1 1 3
 
Note:
    The following logical sequence (T = true, F = false)--
          T F T F T T F F F T F T
    can be coded as a "logical" variable in one of the following ways:
          LET Y = DATA 1 0 1 0 1 1 0 0 0 1 0 1
    or
          SERIAL READ Y
          1 0 1 0 1 1 0 0 0 1 0 1
          END OF DATA
    or
          LET Y = PATTERN 1 0 1 0 1 1 0 0 0 1 0 1
 
Note:
    The IND function can be helpful in converting a numeric variable
    that is not coded with 0 and 1's to one that is.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGICAL OR (LET)        = Carries out a logical or.
    LOGICAL NAND (LET)      = Carries out a logical negative and.
    LOGICAL NOR (LET)       = Carries out a logical nor.
    LOGICAL XOR (LET)       = Carries out a logical xor.
    LOGICAL IFTHEN (LET)    = Carries out a logical if-then.
    LOGICAL IFF (LET)       = Carries out a logical if-and-only-if.
    LOGICAL NOT (LET)       = Carries out a logical not.
 
    COMPLEX ADDITION (LET)  = Carries out a complex addition.
    POLY  ADDITION (LET)    = Carries out a polynomial addition.
    VECTOR ADDITION (LET)   = Carries out a vector addition.
    MATRIX ADDITION (LET)   = Carries out a matrix addition.
 
    PLOT                    = Plots data or functions.
 
Reference:
    Burington (1933).  Handbook of Mathematical Tables and Functions.
    McGraw-Hill.  Page 132 of Edition 5 (1973).
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 1 1 0 0
    LET Y2 = DATA 1 0 1 0
    LET Y3 = LOGICAL AND Y1 Y2
    SET WRITE DECIMALS 0
    WRITE Y1 Y2 Y3
 
-----LOGICAL IFF (LET)-------------------------------------------
 
LOGICAL IFF
 
Name:
    LOGICAL IFF (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the "iff" (= if-and-only-if) of 2 variables (with 0-1
    numeric elements).
 
Description:
    Logical if and only if can be set up as:
       IF a THEN b
       IF b THEN a
    Given true and false values for a and b means that a true or false
    value can be assigned to the IF-THEN statement.  DATAPLOT codes
    logical values with 0 and 1's.  The value 1 means "true" and the
    value 0 means "false".
 
    The "iff" of the 4-element variable--
          1 1 0 0
    and the 4-element variable--
          1 0 1 0
    is the 4-element variable--
          1 0 0 1
 
Syntax:
    LET <v3> = LOGICAL IFF <v1> <v2>  <SUBSET/EXCEPT/FOR/qualification>
    where <v1> is the first     variable;
          <v2> is the second    variable;
          <v3> is the resultant variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Examples:
    LET Y3  = LOGICAL IFF Y1 Y2
    LET Y3  = LOGICAL IFF Y1 Y2 SUBSET Y1 = 1
    LET Y3  = LOGICAL IFF Y1 Y2 FOR I = 1 1 3
 
Note:
    The following logical sequence (T = true, F = false)--
          T F T F T T F F F T F T
    can be coded as a "logical" variable in one of the following ways:
          LET Y = DATA 1 0 1 0 1 1 0 0 0 1 0 1
    or
          SERIAL READ Y
          1 0 1 0 1 1 0 0 0 1 0 1
          END OF DATA
    or
          LET Y = PATTERN 1 0 1 0 1 1 0 0 0 1 0 1
 
Note:
    The IND function can be helpful in converting a numeric variable
    that is not coded with 0 and 1's to one that is.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGICAL AND (LET)       = Carries out a logical and.
    LOGICAL OR (LET)        = Carries out a logical or.
    LOGICAL NAND (LET)      = Carries out a logical negative and.
    LOGICAL NOR (LET)       = Carries out a logical nor.
    LOGICAL XOR (LET)       = Carries out a logical xor.
    LOGICAL IFTHEN (LET)    = Carries out a logical if-then.
    LOGICAL NOT (LET)       = Carries out a logical not.
    PLOT                    = Plots data or functions.
 
Reference:
    Burington (1933).  Handbook of Mathematical Tables and Functions.
    McGraw-Hill.  Page 132 of Edition 5 (1973).
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 1 1 0 0
    LET Y2 = DATA 1 0 1 0
    LET Y3 = LOGICAL IFF Y1 Y2
    SET WRITE DECIMALS 0
    WRITE Y1 Y2 Y3
 
-----LOGICAL IFTHEN (LET)----------------------------------------
 
LOGICAL IFTHEN
 
Name:
    LOGICAL IFTHEN (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the "ifthen" (= implication) of 2 variables (with 0-1
    numeric elements).
 
Description:
    Logical if can be set up as:
       IF a THEN b
    Given true and false values for a and b means that a true or false
    value can be assigned to the IF-THEN statement.  DATAPLOT codes
    logical values with 0 and 1's.  The value 1 means "true" and the
    value 0 means "false".
 
    The "ifthen" of the 4-element variable--
          1 1 0 0
    and the 4-element variable--
          1 0 1 0
    is the 4-element variable--
          1 0 1 1
 
Syntax:
    LET <v3> = LOGICAL IFTHEN <v1> <v2>
              <SUBSET/EXCEPT/FOR qualification>
    where <v1> is the first     variable;
          <v2> is the second    variable;
          <v3> is the resultant variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Examples:
    LET Y3  = LOGICAL IFTHEN Y1 Y2
    LET Y3  = LOGICAL IFTHEN Y1 Y2 SUBSET Y1 = 1
    LET Y3  = LOGICAL IFTHEN Y1 Y2 FOR I = 1 1 3
 
Note:
    The following logical sequence (T = true, F = false)--
          T F T F T T F F F T F T
    can be coded as a "logical" variable in one of the following ways:
          LET Y = DATA 1 0 1 0 1 1 0 0 0 1 0 1
    or
          SERIAL READ Y
          1 0 1 0 1 1 0 0 0 1 0 1
          END OF DATA
    or
          LET Y = PATTERN 1 0 1 0 1 1 0 0 0 1 0 1
 
Note:
    The IND function can be helpful in converting a numeric variable
    that is not coded with 0 and 1's to one that is.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGICAL AND (LET)       = Carries out a logical and.
    LOGICAL OR (LET)        = Carries out a logical or.
    LOGICAL NAND (LET)      = Carries out a logical negative and.
    LOGICAL NOR (LET)       = Carries out a logical nor.
    LOGICAL XOR (LET)       = Carries out a logical xor.
    LOGICAL IFF (LET)       = Carries out a logical if-and-only-if.
    LOGICAL NOT (LET)       = Carries out a logical not.
    PLOT                    = Plots data or functions.
 
Reference:
    Burington (1933).  Handbook of Mathematical Tables and Functions.
    McGraw-Hill.  Page 132 of Edition 5 (1973).
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 1 1 0 0
    LET Y2 = DATA 1 0 1 0
    LET Y3 = LOGICAL IFTHEN Y1 Y2
    SET WRITE DECIMALS 0
    WRITE Y1 Y2 Y3
 
-----LOGICAL NAND (LET)------------------------------------------
 
LOGICAL NAND
 
Name:
    LOGICAL NAND (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the "nand" (= negative conjunction) of 2 variables (with
    0-1 numeric elements).
 
Description:
    Logical nand is the combination of a logical and followed by a
    logical not.  The result is false if both the input values are
    true and otherwise it is true.  DATAPLOT codes logical values with
    0 and 1's.  The value 1 means "true" and the value 0 means "false".
 
    The "nand" of the 4-element variable--
          1 1 0 0
    and the 4-element variable--
          1 0 1 0
    is the 4-element variable--
          0 1 1 1
 
Syntax:
    LET <v3> = LOGICAL NAND <v1> <v2> <SUBSET/EXCEPT/FOR/qualification>
    where <v1> is the first     variable;
          <v2> is the second    variable;
          <v3> is the resultant variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Examples:
    LET Y3  = LOGICAL NAND Y1 Y2
    LET Y3  = LOGICAL NAND Y1 Y2 SUBSET Y1 = 1
    LET Y3  = LOGICAL NAND Y1 Y2 FOR I = 1 1 3
 
Note:
    The following logical sequence (T = true, F = false)--
          T F T F T T F F F T F T
    can be coded as a "logical" variable in one of the following ways:
          LET Y = DATA 1 0 1 0 1 1 0 0 0 1 0 1
    or
          SERIAL READ Y
          1 0 1 0 1 1 0 0 0 1 0 1
          END OF DATA
    or
          LET Y = PATTERN 1 0 1 0 1 1 0 0 0 1 0 1
 
Note:
    The IND function can be helpful in converting a numeric variable
    that is not coded with 0 and 1's to one that is.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGICAL AND (LET)       = Carries out a logical and.
    LOGICAL OR (LET)        = Carries out a logical or.
    LOGICAL NOR (LET)       = Carries out a logical nor.
    LOGICAL XOR (LET)       = Carries out a logical xor.
    LOGICAL IFTHEN (LET)    = Carries out a logical if-then.
    LOGICAL IFF (LET)       = Carries out a logical if-and-only-if.
    LOGICAL NOT (LET)       = Carries out a logical not.
    PLOT                    = Plots data or functions.
 
Reference:
    Burington (1933).  Handbook of Mathematical Tables and Functions.
    McGraw-Hill.  Page 132 of Edition 5 (1973).
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 1 1 0 0
    LET Y2 = DATA 1 0 1 0
    LET Y3 = LOGICAL NAND Y1 Y2
    SET WRITE DECIMALS 0
    WRITE Y1 Y2 Y3
 
-----LOGICAL NOR (LET)-------------------------------------------
 
LOGICAL NOR
 
Name:
    LOGICAL NOR (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the "nor" (= negative disjunction) of 2 variables (with
    0-1 numeric elements).
 
Description:
    Logical nor is the combination of a logical or followed by a
    logical not.  The result is true if both the input values are false
    and otherwise it is false.  DATAPLOT codes logical values with 0
    and 1's.  The value 1 means "true" and the value 0 means "false".
 
    The "nor" of the 4-element variable--
          1 1 0 0
    and the 4-element variable--
          1 0 1 0
    is the 4-element variable--
          0 0 0 1
 
Syntax:
    LET <v3> = LOGICAL NOR <v1> <v2>  <SUBSET/EXCEPT/FOR/qualification>
    where <v1> is the first     variable;
          <v2> is the second    variable;
          <v3> is the resultant variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Examples:
    LET Y3  = LOGICAL NOR Y1 Y2
    LET Y3  = LOGICAL NOR Y1 Y2 SUBSET Y1 = 1
    LET Y3  = LOGICAL NOR Y1 Y2 FOR I = 1 1 3
 
Note:
    The following logical sequence (T = true, F = false)--
          T F T F T T F F F T F T
    can be coded as a "logical" variable in one of the following ways:
          LET Y = DATA 1 0 1 0 1 1 0 0 0 1 0 1
    or
          SERIAL READ Y
          1 0 1 0 1 1 0 0 0 1 0 1
          END OF DATA
    or
          LET Y = PATTERN 1 0 1 0 1 1 0 0 0 1 0 1
 
Note:
    The IND function can be helpful in converting a numeric variable
    that is not coded with 0 and 1's to one that is.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGICAL AND (LET)       = Carries out a logical and.
    LOGICAL OR (LET)        = Carries out a logical or.
    LOGICAL NAND (LET)      = Carries out a logical negative and.
    LOGICAL XOR (LET)       = Carries out a logical xor.
    LOGICAL IFTHEN (LET)    = Carries out a logical if-then.
    LOGICAL IFF (LET)       = Carries out a logical if-and-only-if.
    LOGICAL NOT (LET)       = Carries out a logical not.
    PLOT                    = Plots data or functions.
 
Reference:
    Burington (1933).  Handbook of Mathematical Tables and Functions.
    McGraw-Hill.  Page 132 of Edition 5 (1973).
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 1 1 0 0
    LET Y2 = DATA 1 0 1 0
    LET Y3 = LOGICAL NOR Y1 Y2
    SET WRITE DECIMALS 0
    WRITE Y1 Y2 Y3
 
-----LOGICAL NOT (LET)-------------------------------------------
 
LOGICAL NOT
 
Name:
    LOGICAL NOT (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the "not" (= negation) of a variable (with 0-1 numeric
    elements).
 
Description:
    Logical not returns the opposite of the input value (i.e., true
    becomes false and false becomes true).  DATAPLOT codes logical
    values with 0 and 1's.  The value 1 means "true" and the value 0
    means "false".
 
    The "not" of the 2-element variable--
          1 0
    is the 2-element variable--
          0 1
 
Syntax:
    LET <v3> = LOGICAL NOT <v1> <v2>  <SUBSET/EXCEPT/FOR qualification>
    where <v1> is the first     variable;
          <v2> is the second    variable;
          <v3> is the resultant variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Examples:
    LET Y2  = LOGICAL NOT Y1
    LET Y2  = LOGICAL NOT Y1 SUBSET Y1 = 1
    LET Y2  = LOGICAL NOT Y1 FOR I = 1 1 3
 
Note:
    The following logical sequence (T = true, F = false)--
          T F T F T T F F F T F T
    can be coded as a "logical" variable in one of the following ways:
          LET Y = DATA 1 0 1 0 1 1 0 0 0 1 0 1
    or
          SERIAL READ Y
          1 0 1 0 1 1 0 0 0 1 0 1
          END OF DATA
    or
          LET Y = PATTERN 1 0 1 0 1 1 0 0 0 1 0 1
 
Note:
    The IND function can be helpful in converting a numeric variable
    that is not coded with 0 and 1's to one that is.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGICAL AND (LET)       = Carries out a logical and.
    LOGICAL OR (LET)        = Carries out a logical or.
    LOGICAL NAND (LET)      = Carries out a logical negative and.
    LOGICAL NOR (LET)       = Carries out a logical nor.
    LOGICAL XOR (LET)       = Carries out a logical xor.
    LOGICAL IFTHEN (LET)    = Carries out a logical if-then.
    LOGICAL IFF (LET)       = Carries out a logical if-and-only-if.
    PLOT                    = Plots data or functions.
 
Reference:
    Burington (1933).  Handbook of Mathematical Tables and Functions.
    McGraw-Hill.  Page 132 of Edition 5 (1973).
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 1 0
    LET Y2 = LOGICAL NOT Y1
    SET WRITE DECIMALS 0
    WRITE Y1 Y2
 
-----LOGICAL OR (LET)--------------------------------------------
 
LOGICAL OR (LET)
 
Name:
    LOGICAL OR
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the "or" (= logical disjunction) of 2 variables
    (with 0-1 numeric elements).
 
Description:
    Logical or means that the result is true if either or both of the
    input values is true.  DATAPLOT codes logical values with 0 and
    1's.  The value 1 means "true" and the value 0 means "false".
 
    The "or" of the 4-element variable--
          1 1 0 0
    and the 4-element variable--
          1 0 1 0
    is the 4-element variable--
          1 1 1 0
 
Syntax:
    LET <v3> = LOGICAL OR <v1> <v2>  <SUBSET/EXCEPT/FOR qualification>
    where <v1> is the first     variable;
          <v2> is the second    variable;
          <v3> is the resultant variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Examples:
    LET Y3  = LOGICAL OR Y1 Y2
    LET Y3  = LOGICAL OR Y1 Y2 SUBSET Y1 = 1
    LET Y3  = LOGICAL OR Y1 Y2 FOR I = 1 1 3
 
Note:
    The following logical sequence (T = true, F = false)--
          T F T F T T F F F T F T
    can be coded as a "logical" variable in one of the following ways:
          LET Y = DATA 1 0 1 0 1 1 0 0 0 1 0 1
    or
          SERIAL READ Y
          1 0 1 0 1 1 0 0 0 1 0 1
          END OF DATA
    or
          LET Y = PATTERN 1 0 1 0 1 1 0 0 0 1 0 1
 
Note:
    The IND function can be helpful in converting a numeric variable
    that is not coded with 0 and 1's to one that is.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGICAL AND (LET)       = Carries out a logical and.
    LOGICAL NAND (LET)      = Carries out a logical negative and.
    LOGICAL NOR (LET)       = Carries out a logical nor.
    LOGICAL XOR (LET)       = Carries out a logical xor.
    LOGICAL IFTHEN (LET)    = Carries out a logical if-then.
    LOGICAL IFF (LET)       = Carries out a logical if-and-only-if.
    LOGICAL NOT (LET)       = Carries out a logical not.
    COMPLEX SUBT  (LET)     = Carries out complex subtraction.
    POLY  SUBTRACTION (LET) = Carries out polynomial subtraction.
    VECTOR SUBT  (LET)      = Carries out vector subtraction.
    MATRIX SUBT  (LET)      = Carries out matrix subtraction.
    PLOT                    = Plots data or functions.
 
Reference:
    Burington (1933).  Handbook of Mathematical Tables and Functions.
    McGraw-Hill.  Page 132 of Edition 5 (1973).
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 1 1 0 0
    LET Y2 = DATA 1 0 1 0
    LET Y3 = LOGICAL OR Y1 Y2
    SET WRITE DECIMALS 0
    WRITE Y1 Y2 Y3
 
-----LOGICAL XOR (LET)-------------------------------------------
 
LOGICAL XOR
 
Name:
    LOGICAL XOR (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the "xor" (= exclusive disjunction) of 2 variables (with
    0-1 numeric elements).
 
Description:
    Logical xor means the result is true if either (but not both
    together) of the input values is true.  DATAPLOT codes logical
    values with 0 and 1's.  The value 1 means "true" and the value 0
    means "false".
 
    The "xor" of the 4-element variable--
          1 1 0 0
    and the 4-element variable--
          1 0 1 0
    is the 4-element variable--
          0 1 1 0
 
Syntax:
    LET <v3> = LOGICAL XOR <v1> <v2>  <SUBSET/EXCEPT/FOR qualification>
    where <v1> is the first     variable;
          <v2> is the second    variable;
          <v3> is the resultant variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Examples:
    LET Y3  = LOGICAL XOR Y1 Y2
    LET Y3  = LOGICAL XOR Y1 Y2 SUBSET Y1 = 1
    LET Y3  = LOGICAL XOR Y1 Y2 FOR I = 1 1 3
 
Note:
    The following logical sequence (T = true, F = false)--
          T F T F T T F F F T F T
    can be coded as a "logical" variable in one of the following ways:
          LET Y = DATA 1 0 1 0 1 1 0 0 0 1 0 1
    or
          SERIAL READ Y
          1 0 1 0 1 1 0 0 0 1 0 1
          END OF DATA
    or
          LET Y = PATTERN 1 0 1 0 1 1 0 0 0 1 0 1
 
Note:
    The IND function can be helpful in converting a numeric variable
    that is not coded with 0 and 1's to one that is.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGICAL AND (LET)       = Carries out a logical and.
    LOGICAL OR (LET)        = Carries out a logical or.
    LOGICAL NAND (LET)      = Carries out a logical negative and.
    LOGICAL NOR (LET)       = Carries out a logical nor.
    LOGICAL IFTHEN (LET)    = Carries out a logical if-then.
    LOGICAL IFF (LET)       = Carries out a logical if-and-only-if.
    LOGICAL NOT (LET)       = Carries out a logical not.
    PLOT                    = Plots data or functions.
 
Reference:
    Burington (1933).  Handbook of Mathematical Tables and Functions.
    McGraw-Hill.  Page 132 of Edition 5 (1973).
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 1 1 0 0
    LET Y2 = DATA 1 0 1 0
    LET Y3 = LOGICAL XOR Y1 Y2
    SET WRITE DECIMALS 0
    WRITE Y1 Y2 Y3
 
-----LOGINT (LET)--------------------------------
 
LOGINT
 
Name:
    LOGINT (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the logarithmic integral.
 
Description:
    The logarithmic integral is defined as:
        li(x) = INTEGRAL(1/ln(t))dt            x > 0, X <> 1
    where INTEGRAL is the integral from 0 to x.

Syntax:
    LET <y> = LOGINT(<x>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a positive number, variable, or parameter;
          <y> is a variable or a parameter (depending on what <x> is
               where the computed LOGINT integral values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOGINT(0.1)
    LET A = LOGINT(10)
    LET X2 = LOGINT(X)
 
Note:
    DATAPLOT uses the routine ALI from the SLATEC Common Mathematical
    Library to compute this function.  SLATEC is a large set of high
    quality, portable, public domain Fortran routines for various
    mathematical capabilities maintained by seven federal laboratories.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    EXPINT1    = Compute the exponential integral of order 1.
    EXPINTN    = Compute the exponential integral of order N.
    EXPINTE    = Compute the principla value of the exponential
                 integral.
    ERF        = Compute the error function.
    SININT     = Compute the sine integral.
    COSINT     = Compute the cosine integral.
 
Reference:
    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 5).
 
Applications:
    Special Functions
 
Implementation Date:
    94/9
 
Program:
    TITLE LOGARITHMIC INTEGRAL
    PLOT LOGINT(X) FOR X = 0.01 0.01 0.99 AND
    PLOT LOGINT(X) FOR X = 1.01 0.01 9.99
 
-----LOGISTIC NUMBERS (LET)-----------------------------------------
 
LOGISTIC NUMBERS
 
Name:
    LOGISTIC NUMBERS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate a sequence of Logistic numbers.
 
Description:
    The Logistic sequence is defined by the following equation:
        X(N+1) = K*X(N)*(1-X(N))
    where K is a user defined constant.  The user also provides a
    starting value (i.e., X(1)).
 
Syntax:
    LET <resp> = LOGISTIC NUMBERS FOR I = <start> <inc> <stop>
    where <resp> is a variable where the Logistic numbers are stored;
          <start>, <inc>, and <stop> identify the start, increment, and
              stop points of the Logistic sequence.  The <start> and
              <inc> values are almost always 1.  If they are not,
              <resp> will still contain <stop> elements, but the
              skipped elements will contain zeros.
 
Examples:
    LET YlOG = LOGISTIC NUMBERS FOR I = 1 1 100
 
Note:
    The user must specify the constant and the starting value as
    follows:
        LET X0 = <value>
        LET K = <value>
    where X0 should be a decimal number between 0 and 1 (inclusive) and
    K should be a decimal number between 0 and 4 (exclusive).
 
Note:
    This sequence converges to 0 for values of K less than 1.0.  For
    values of K between 1 and 3 it converges to a single number.  For
    values of K greater than 3 it begins to exhibit chaotic behavior.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    FRACTAL PLOT         = Generate a fractal plot.
    CANTOR NUMBERS       = Generate a sequence of Cantor numbers.
    FRACTAL              = Generate a fractal sequence.
    JULIA                = Compute a Julia set.
    PHASE PLANE DIAGRAM  = Generate a phase plane diagram.
    PLOT                 = Plots data or functions.
 
Reference:
    "Chaos, Fractals, and Dynamics", Robert Devaney, Addison-Wesley,
    1990, (pp. 26-31).
 
Applications:
    Chaos
 
Implementation Date:
    88/7
 
Program:
    DIMENSION 20 COLUMNS
    LET KINC=0.3
    LET X0 = 0.05
    LOOP FOR L = 1 1 10
    LET K = (L-1)*KINC + 0.5
    LET Y^L = LOGISTIC NUMBERS FOR I = 1 1 40
    END OF LOOP
    LET X = SEQUENCE 1 1 40
    XLIMITS 0 40
    XTIC OFFSET 2 2
    YLIMITS 0 0.8
    YTIC OFFSET 0.1 0
    TITLE LOGISTIC SEQUENCE FOR 10 VALUES OF K
    LINE SOLID DA DA DA DA DA DA DA DA DO
    PLOT Y1 Y2 Y3 Y4 Y5 Y6 Y7 Y8 Y9 Y10 VS X
 
-----LOGHAZ (LET)--------------------------------
 
LOGHAZ
 
Name:
    LOGHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the logistic hazard function.
 
Description:
    The standard form of the logistic distribution has the following
    hazard function:

       h(x) = 1/(1+exp(-x))
 
Syntax:
    LET <y> = LOGHAZ(<x>)     <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed logistic hazard value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOGHAZ(3)
    LET X2 = LOGHAZ(X1)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGCDF  = Compute the logistic cumulative distribution function.
    LOGCHAZ = Compute the logistic cumulative hazard function.
    LOGPDF  = Compute the logistic probability density function.
    LOGPPF  = Compute the logistic percent point function.
    NORPDF  = Compute the normal probability density function.
    LGNPDF  = Compute the logmormal probability density function.
    EXPPDF  = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions - Volume 2", Johnson, Kotz,
    and Balakrisnan, Wiley, 1994, chapter 23.
 
    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 124-128.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/4
 
Program:
    XLIMITS -5 5
    XTIC OFFSET 0.5 0.5
    TITLE AUTOMATIC
    PLOT LOGHAZ(X) FOR X = -5  0.01  5
 
-----LOGNORMAL MOMENT ESTIMATES (LET)-------------------------------------
 
LOGNORMAL MOMENT ESTIMATES
 
Name:
    LOGNORMAL MOMENT ESTIMATES (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Estimate the parameters of the 3-parameter lognormal distribution based
    on summary statistics.
 
Description:
    In most cases, we prefer to estimate the parameters of the 3-parameter
    lognormal distribution using the 3-PARAMETER LOGNORMAL MLE Y command.
    However, this assumes that we have the full data set.  In some cases,
    we may only have summary statistics available.

    The input array, say X, should contain the following values:

        X(1) = the sample mean
        X(2) = the sample standard deviation
        X(3) = the sample skewness
        X(4) = the sample minimum
        X(5) = the sample size

    If one of the values is not available, then you can enter either
    CPUMIN or the statistic missing value.  For example, if the skewness
    is not available, you can do one of the following:

        PROBE CPUMIN
        LET CPUMIN = PROBVAL
        LET X(3) = CPUMIN

    or

        SET STATISTIC MISSING VALUE -9999
        LET X(3) = -9999

    The following output vector, say Y, is returned:

        Y(1) = 3-parameter moment estimate for location
        Y(2) = 3-parameter moment estimate for scale
        Y(3) = 3-parameter moment estimate for shape
        Y(4) = 3-parameter moment estimate for mu (= log(scale))
        Y(5) = 3-parameter modified moment estimate for location
        Y(6) = 3-parameter modified moment estimate for scale
        Y(7) = 3-parameter modified moment estimate for shape
        Y(8) = 3-parameter modified moment estimate for mu
               (= log(scale))

    Any of these moment estimates that cannot be computed will be set to
    CPUMIN.  This can happen if certain summary statistics are not provided
    or if the equation solvers are not able to find a solution.

    The 3-parameter moment and modified moment estimates are computed using
    the codes provided on pages 352-354 of Cohen and Whitten.

Syntax:
    LET <y> = LOGNORMAL MOMENT ESTIMATES  <x>
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is the variable containing the summary statistics;
          <y> is a variable containing the lognormal moment estimates;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and rarely
          used for this command.
 
Examples:
    LET Y = LOGNORMAL MOMENT ESTIMATES X
 
Default:
    None
 
Synonyms:
    None
 
Reference:
    Cohen and Whitten (1988), "Parameter Estimation in Reliability and Life
    Span Models", Marcel Dekker, p. 61 and pp. 352 -354.

Related Commands:
    GAMMA MOMEMENT ESTIMATE        = Generate moment estimates for the
                                     gamma distribution.
    WEIBULL MOMEMENT ESTIMATE      = Generate moment estimates for the
                                     Weibull distribution.
    INVERSE GAUSSIAN MOME ESTIMATE = Generate moment estimates for the
                                     inverse gaussian distribution.
    MAXIMUM LIKELIHOOD             = Perform maximum likelihood estimation
                                     for various distributions.
    BEST DISTRIBUTIONAL FIT        = Perform a best distributional fit
                                     analysis.
    PPCC PLOT                      = Generate a probability plot
                                     correlation coefficient plot.
    PROBABILITY PLOT               = Generate a probability plot.
 
Applications:
    Reliability
 
Implementation Date:
    2014/4
 
Program:
    . Purpose:  Test LOGNORMAL MOMENT ESTIMATES command
    .
    . Step 1:   Read data
    .
    .           Data from
    .
    .           Cohen and Whitten (1988), "Parameter Estimation in
    .           Reliability  and Life Span Models", Dekker, p. 54.
    .
    serial read x
    0.654  0.613  0.315  0.449  0.297
    0.402  0.379  0.423  0.379  0.3225
    0.269  0.740  0.418  0.412  0.494
    0.416  0.338  0.392  0.484  0.265
    end of data
    .
    let xmean = mean x
    let xsd   = sd   x
    let xmin  = mini x
    let xskew = skew x
    let n = size x
    let z = data xmean xsd xskew xmin n
    .
    let y = lognormal moment estimates z
    .
    let numdec = 5
    .
    let locmom   = y(1); let locmom   = round(locmom,numdec)
    let scalemom = y(2); let scalemom = round(scalemom,numdec)
    let sigmamom = y(3); let sigmamom = round(sigmamom,numdec)
    let uhatmom  = y(4); let uhatmom  = round(uhatmom,numdec)
    let locmmom  = y(5); let locmmom  = round(locmmom,numdec)
    let scalmmom = y(6); let scalmmom = round(scalmmom,numdec)
    let sigmmmom = y(7); let sigmmmom = round(sigmmom,numdec)
    let uhatmmom = y(8); let uhatmmom = round(uhatmmom,numdec)
    .
    let xmean = round(xmean,numdec)
    let xsd   = round(xsd,numdec)
    let xskew = round(xskew,numdec)
    let xmin  = round(xmin,numdec)
    .
    capture screen on
    capture lmom.out
    print "Lognormal Parameter Estimates From Summary Data"
    print " "
    print " "
    print "Sample Mean:      ^xmean"
    print "Sample SD:        ^xsd"
    print "Sample Skewness:  ^xskew"
    print "Sample Minimum:   ^xmin"
    print "Sample Size:      ^n"
    print " "
    print " "
    print "3-Parameter Lognormal Moment Estimates:"
    print "Location:         ^locmom"
    print "Scale:            ^scalemom"
    print "Shape:            ^sigmamom"
    print "Uhat:             ^uhatmom"
    print " "
    print " "
    print "3-Parameter Lognormal Modified Moment Estimates:"
    print "Location:         ^locmmom"
    print "Scale:            ^scalmmom"
    print "Shape:            ^sigmmmom"
    print "Uhat:             ^uhatmmom"
    end of capture

-----LOG ODDS RATIO (LET)--------------------------------
 
LOG ODDS RATIO
 
Name:
    LOG ODDS RATIO (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the bias corrected log odds ratio between two
    binary variables.
 
Description:
    Given two variables where each variable has exactly two
    possible outcomes (typically defined as success and failure),
    we define the odds ratio as:

        o = (N11/N12)/(N21/N22)
          = (N11*N22)/(N12*N21)

    where

        N11 = number of successes in sample 1 
        N21 = number of failures in sample 1 
        N12 = number of successes in sample 2 
        N22 = number of failures in sample 2

    The first definition shows the meaning of the odds ratio
    clearly, although it is more commonly given in the literature
    with the second definition.

    The log odds ratio is the logarithm of the odds ratio:

        l(o) = LOG{(N11/N12)/(N21/N22)}
             = LOG{(N11*N22)/(N12*N21)}

    Alternatively, the log odds ratio can be given in terms of
    the proportions

      l(o) = LOG{(p11/p12)/(p21/p22)}
           = LOG{(p11*p22)/(p12*p21)}

    where

        p11 = N11/(N11 + N21) = proportion of successes in sample 1
        p21 = N21/(N11 + N21) = proportion of failures in sample 1
        p12 = N12/(N12 + N22) = proportion of successes in sample 2
        p22 = N22/(N12 + N22) = proportion of failures in sample 2

    Success and failure can denote any binary response.
    Dataplot expects "success" to be coded as "1" and "failure"
    to be coded as "0".

    Dataplot actually returns the bias corrected version of the
    statistic:

       l'(o) = LOG[{(N11+0.5)*(N22+0.5)}/{(N12+0.5)*(N21+0.5)}]

    In addition to reducing bias, this statistic also has the
    advantage that the log odds ratio is still defined even when
    N12 or N21 is zero (the uncorrected statistic will be
    undefined for these cases).

    In practice, the log odds ratio is more often used than
    the odds ratio.

Syntax:
    LET <par> = LOG ODDS RATIO <y1> <y2>
                              <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed log odds ratio
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOG ODDS RATIO Y1 Y2
    LET A = LOG ODDS RATIO Y1 Y2 SUBSET TAG > 2
 
Note:
    The two variables need not have the same number of elements.
 
Note:
    There are two ways you can define the response variables:

       1) Raw data - in this case, the variables contain
          0's and 1's.

          If the data is not coded as 0's and 1's, Dataplot
          will check for the number of distinct values.  If
          there are two distinct values, the minimum value
          is converted to 0's and the maximum value is
          converted to 1's.  If there is a single distinct
          value, it is converted to 0's if it is less than
          0.5 and to 1's if it is greater than or equal to
          0.5.  If there are more than two distinct values,
          an error is returned.

       2) Summary data - if there are two observations, the
          data is assummed to be the 2x2 summary table.
          That is,

              Y1(1) = N11
              Y1(2) = N21
              Y2(1) = N12
              Y2(2) = N22
 
Note:
    The following additional commands are supported

        TABULATE LOG ODDS RATIO  Y1 Y2 X
        CROSS TABULATE LOG ODDS RATIO Y1 Y2 X1 X2

        LOG ODDS RATIO PLOT Y1 Y2 X
        CROSS TABULATE LOG ODDS RATIO PLOT Y1 Y2 X1 X2

        BOOTSTRAP LOG ODDS RATIO PLOT Y1 Y2
        JACKNIFE  LOG ODDS RATIO PLOT Y1 Y2

Default:
    None
 
Synonyms:
    LOGIT is a synonym for LOG ODDS RATIO
 
Related Commands:
    LOG ODDS RATIO STAND ERROR  = Compute the standard error of the
                                  bias corrected log(odds ratio).
    ODDS RATIO                  = Compute the bias corrected odds
                                  odds ratio.
    FALSE POSITIVES             = Compute the proportion of
                                  false positives.
    FALSE NEGATIVES             = Compute the proportion of
                                  false negatives.
    TRUE NEGATIVES              = Compute the proportion of
                                  true negatives.
    TRUE POSITIVES              = Compute the proportion of
                                  true positives.
    TEST SENSITIVITY            = Compute the test sensitivity.
    TEST SPECIFICITY            = Compute the test specificity.
    TABULATE                    = Compute a statistic for data with
                                  a single grouping variable.
    CROSS TABULATE              = Compute a statistic for data with
                                  two grouping variables.
    STATISTIC PLOT              = Generate a plot of a statistic for
                                  data with a single grouping
                                  variable.
    CROSS TABULATE PLOT         = Generate a plot of a statistic for
                                  data with two grouping variables.
    BOOTSTRAP PLOT              = Generate a bootstrap plot for a
                                  given statistic.
 
Reference:
    Fleiss, Levin, and Paik (2003), "Statistical Methods for
    Rates and Proportions", Third Edition, Wiley, chapter 6.
 
Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/4
 
Program:
    let n = 1
    .
    let p = 0.2
    let y1 = binomial rand numb for i = 1 1 100
    let p = 0.1
    let y2 = binomial rand numb for i = 1 1 100
    .
    let p = 0.4
    let y1 = binomial rand numb for i = 101 1 200
    let p = 0.08
    let y2 = binomial rand numb for i = 101 1 200
    .
    let p = 0.15
    let y1 = binomial rand numb for i = 201 1 300
    let p = 0.18
    let y2 = binomial rand numb for i = 201 1 300
    .
    let p = 0.6
    let y1 = binomial rand numb for i = 301 1 400
    let p = 0.45
    let y2 = binomial rand numb for i = 301 1 400
    .
    let p = 0.3
    let y1 = binomial rand numb for i = 401 1 500
    let p = 0.1
    let y2 = binomial rand numb for i = 401 1 500
    .
    let x = sequence 1 100 1 5
    .
    let a = log odds ratio y1 y2 subset x = 1
    tabulate log odds ratio y1 y2 x
    .
    label case asis
    xlimits 1 5
    major xtic mark number 5
    minor xtic mark number 0
    xtic mark offset 0.5 0.5
    y1label Bias Corrected Log Odds Ratio
    x1label Group ID
    character x blank
    line blank solid
    .
    log odds ratio plot y1 y2 x
 
-----LOG ODDS RATIO STANDARD ERROR (LET)---------------------------
 
LOG ODDS RATIO STANDARD ERROR
 
Name:
    LOG ODDS RATIO STANDARD ERROR (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the standard error of the bias corrected log odds ratio
    between two binary variables.
 
Description:
    Given two variables where each variable has exactly two
    possible outcomes (typically defined as success and failure),
    we define the log odds ratio as:

        l(o) = LOG{(N11/N12)/(N21/N22)}
             = LOG{(N11*N22)/(N12*N21)}

    where

        N11 = number of successes in sample 1 
        N21 = number of failures in sample 1 
        N12 = number of successes in sample 2 
        N22 = number of failures in sample 2

    The first definition shows the meaning of the log odds ratio
    clearly, although it is more commonly given in the literature
    with the second definition.

    Success and failure can denote any binary response.
    Dataplot expects "success" to be coded as "1" and "failure"
    to be coded as "0".

    Dataplot actually returns the bias corrected version of the
    statistic:

       l'(o)  = LOG[{(N11+0.5)*(N22+0.5)}/{(N12+0.5)*(N21+0.5)}]

    In addition to reducing bias, this statistic also has the
    advantage that the odds ratio is still defined even when
    N12 or N21 is zero (the uncorrected statistic will be
    undefined for these cases).

    The standard error of this bias corrected log odds ratio is then

      SE(l'(o)) = SQRT{1/(N11+0.5) + 1/(N21+0.5) + 1/(N12+0.5) +
                 1/(N22+0.5)}

Syntax:
    LET <par> = LOG ODDS RATIO STANDARD ERROR <y1> <y2>
                              <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed log odds ratio
               standard error is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOG ODDS RATIO STANDARD ERROR Y1 Y2
    LET A = LOG ODDS RATIO STANDARD ERROR Y1 Y2 SUBSET TAG > 2
 
Note:
    The two variables need not have the same number of elements.
 
Note:
    There are two ways you can define the response variables:

       1) Raw data - in this case, the variables contain
          0's and 1's.

          If the data is not coded as 0's and 1's, Dataplot
          will check for the number of distinct values.  If
          there are two distinct values, the minimum value
          is converted to 0's and the maximum value is
          converted to 1's.  If there is a single distinct
          value, it is converted to 0's if it is less than
          0.5 and to 1's if it is greater than or equal to
          0.5.  If there are more than two distinct values,
          an error is returned.

       2) Summary data - if there are two observations, the
          data is assummed to be the 2x2 summary table.
          That is,

              Y1(1) = N11
              Y1(2) = N21
              Y2(1) = N12
              Y2(2) = N22
 
Note:
    The following additional commands are supported

        TABULATE LOG ODDS RATIO STANDARD ERROR  Y1 Y2 X
        CROSS TABULATE LOG ODDS RATIO STANDARD ERROR Y1 Y2 X1 X2

        LOG ODDS RATIO STANDARD ERROR PLOT Y1 Y2 X
        CROSS TABULATE LOG ODDS RATIO STANDARD ERROR PLOT Y1 Y2 X1 X2

        BOOTSTRAP LOG ODDS RATIO STANDARD ERROR PLOT Y1 Y2
        JACKNIFE  LOG ODDS RATIO STANDARD ERROR PLOT Y1 Y2

    Note that the above commands expect the variables to have
    the same number of observations.  If the two samples are
    in fact of different sizes, there are two ways to address
    the issue:

       1) Y1 and Y2 can contain the summary data.  That is,

            Y1(1) = N11
            Y1(2) = N21
            Y2(1) = N12
            Y2(2) = N22

          This is a useful option in that the data is sometimes
          only available in summary form.  Note that this will
          not work for the BOOTSTRAP PLOT and JACKNIFE PLOT
          commands (these require raw data).

       2) You can specify a missing value for the smaller
          sample.  For example, if Y1 has 100 observations and
          Y2 has 200 observations, you can do something like

              SET STATISTIC MISSING VALUE -99
              LET Y1 = -99 FOR I = 101  1  200

Default:
    None
 
Synonyms:
    LOGIT STANDARD ERROR
    STANDARD ERROR LOG ODDS RATIO
    STANDARD ERROR LOGIT
 
Related Commands:
    LOG ODDS RATIO             = Compute the bias corrected
                                 log(odds ratio).
    ODDS RATIO                 = Compute the bias corrected
                                 odds ratio.
    ODDS RATIO STANDARD ERROR  = Compute the standard error of the
                                 bias corrected odds ratio.
    FALSE POSITIVES            = Compute the proportion of
                                 false positives.
    FALSE NEGATIVES            = Compute the proportion of
                                 false negatives.
    TRUE NEGATIVES             = Compute the proportion of
                                 true negatives.
    TRUE POSITIVES             = Compute the proportion of
                                 true positives.
    TEST SENSITIVITY           = Compute the test sensitivity.
    TEST SPECIFICITY           = Compute the test specificity.
    TABULATE                   = Compute a statistic for data with
                                 a single grouping variable.
    CROSS TABULATE             = Compute a statistic for data with
                                 two grouping variables.
    STATISTIC PLOT             = Generate a plot of a statistic for
                                 data with a single grouping
                                 variable.
    CROSS TABULATE PLOT        = Generate a plot of a statistic for
                                 data with two grouping variables.
    BOOTSTRAP PLOT             = Generate a bootstrap plot for a
                                 given statistic.
    STATISTIC MISSING VALUE    = Define a missing value for several
                                 plots and commands for unpaired
                                 samples that may be of different
                                 sizes.
 
Reference:
    Fleiss, Levin, and Paik (2003), "Statistical Methods for
    Rates and Proportions", Third Edition, Wiley, chapter 6.
 
Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/5
 
Program:
    let n = 1
    .
    let p = 0.2
    let y1 = binomial rand numb for i = 1 1 100
    let p = 0.1
    let y2 = binomial rand numb for i = 1 1 100
    .
    let p = 0.4
    let y1 = binomial rand numb for i = 101 1 200
    let p = 0.08
    let y2 = binomial rand numb for i = 101 1 200
    .
    let p = 0.15
    let y1 = binomial rand numb for i = 201 1 300
    let p = 0.18
    let y2 = binomial rand numb for i = 201 1 300
    .
    let p = 0.6
    let y1 = binomial rand numb for i = 301 1 400
    let p = 0.45
    let y2 = binomial rand numb for i = 301 1 400
    .
    let p = 0.3
    let y1 = binomial rand numb for i = 401 1 500
    let p = 0.1
    let y2 = binomial rand numb for i = 401 1 500
    .
    let x = sequence 1 100 1 5
    .
    let a = log odds ratio standard error y1 y2 subset x = 1
    tabulate log odds ratio standard error y1 y2 x
    .
    label case asis
    xlimits 1 5
    major xtic mark number 5
    minor xtic mark number 0
    xtic mark offset 0.5 0.5
    y1label Bias Corrected Log Odds Ratio Standard Error
    x1label Group ID
    character x blank
    line blank solid
    .
    log odds ratio standard error plot y1 y2 x
 
-----LOGPDF (LET)--------------------------------
 
LOGPDF
 
Name:
    LOGPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard logistic (i.e, mean=0, sd=PI/sqrt(3))
    probability density function.
 
Description:
    The standard form of the logistic distribution has the following
    probability density function:
       f(x) = exp(x)/(1+exp(x))**2
 
Syntax:
    LET <y2> = LOGPDF(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed logistic pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOGPDF(3)
    LET X2 = LOGPDF(X1)
 
Note:
    The general form of the logistic distribution has the following
    probability density function:
       f(x) = exp((x-u)/sigma)/(sigma*(1+exp((x-u)/sigma))**2)
    where u is the location parameter and sigma is the scale
    parameter.  The mean is u.  The standard deviation is
    sigma*PI/sqrt(3).
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGCDF = Compute the logistic cumulative distribution function.
    LOGPPF = Compute the logistic percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
    LGNCDF = Compute the logmormal cumulative distribution function.
    LGNPDF = Compute the logmormal probability density function.
    LGNPPF = Compute the logmormal percent point function.
    EXPCDF = Compute the exponential cumulative distribution function.
    EXPPDF = Compute the exponential probability density function.
    EXPPPF = Compute the exponential percent point function.
 
Reference:
    "Continuous Univariate Distributions - Volume 2", Johnson, Kotz,
    and Balakrisnan, Wiley, 1994, chapter 23.
 
    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 124-128.
 
    "Statistical Models and Methods for Lifetime Data", Lawless,
    John Wiley, 1982 (pp. 46-47).
 
Applications:
    Distributional Modeling
 
Implementation Date:
    94/4
 
Program:
    YLIMITS 0 0.25
    MAJOR YTIC NUMBER 5
    MINOR YTIC NUMBER 1
    YTIC OFFSET 0 0.02
    YTIC DECIMAL 2
    XLIMITS -7 7
    XTIC OFFSET 0.6 0.6
    PLOT LOGPDF(X) FOR X = -7.5 0.01 7.5
 
-----LOGPPF (LET)--------------------------------
 
LOGPPF
 
Name:
    LOGPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard logistic percent point function.
 
Description:
    The standard form of the logistic distribution has the following
    probability density function:
       f(x) = exp(x)/(1+exp(x))**2
    The percent point function is the inverse of the cumulative
    distribution function.  The cumulative distribution sums the
    probability from 0 to the given x value (i.e., the integral of the
    above function).  The percent point function takes a cumulative
    probability value and computes the corresponding x value.  The
    percent point function has the formula:
       G(p) = log(p/(1-p))
 
    The input value is a real number between 0 and 1 (since it
    corresponds to a probability).  The output value can be any real
    number.
 
Syntax:
    LET <y2> = LOGPPF(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter in the range 0 to 1;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed logistic ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOGPPF(0.9)
    LET A = LOGPPF(A1)
    LET X2 = LOGPPF(X1)
 
Note:
    The general form of the logistic distribution has the following
    probability density function:
       f(x) = exp((x-u)/sigma)/(sigma*(1+exp((x-u)/sigma))**2)
    where u is the location parameter and sigma is the scale
    parameter.  The mean is u.  The standard deviation is
    sigma*PI/sqrt(3).
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGCDF = Compute the logistic cumulative distribution function.
    LOGPDF = Compute the logistic probability density function.
    LOGSF  = Compute the logistic sparsity function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
    LGNCDF = Compute the logmormal cumulative distribution function.
    LGNPDF = Compute the logmormal probability density function.
    LGNPPF = Compute the logmormal percent point function.
    EXPCDF = Compute the exponential cumulative distribution function.
    EXPPDF = Compute the exponential probability density function.
    EXPPPF = Compute the exponential percent point function.
 
Reference:
    "Continuous Univariate Distributions - Volume 2", Johnson, Kotz,
    and Balakrisnan, Wiley, 1994, chapter 23.
 
    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 124-128.
 
    "Statistical Models and Methods for Lifetime Data", Lawless,
    John Wiley, 1982 (pp. 46-47).
 
Applications:
    Distributional Modeling
 
Implementation Date:
    94/4
 
Program:
    XLIMITS 0 1
    MAJOR XTIC NUMBER 6
    MINOR XTIC NUMBER 1
    XTIC DECIMAL 1
    TITLE AUTOMATIC
    PLOT LOGPPF(X) FOR X = 0.01 .01 0.99
 
-----LOGSF (LET)--------------------------------
 
LOGSF
 
Name:
    LOGSF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard logistic sparsity function.
 
Description:
    The standard form of the logistic distribution has the following
    probability density function:
       f(x) = exp(x)/(1+exp(x))**2
    The sparsity function is the derivative of the percent point
    function, which is the inverse of the cumulative distribution
    function.  The cumulative distribution sums the probability from 0
    to the given x value (i.e., the integral of the probability
    density function).  The percent point function takes a cumulative
    probability value and computes the corresponding x value.  The
    sparsity function has the formula:
       G(p) = 1/(p-p**2)
    The input value is a real number between 0 and 1 (since it
    corresponds to a probability).  The output value can be any real
    number.
 
Syntax:
    LET <y2> = LOGSF(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter in the range 0 to 1;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed logistic sf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOGSF(0.9)
    LET X2 = LOGSF(X1)
 
Note:
    The general form of the logistic distribution has the following
    probability density function:
       f(x) = exp((x-u)/sigma)/(sigma*(1+exp((x-u)/sigma))**2)
    where u is the location parameter and sigma is the scale
    parameter.  The mean is u.  The standard deviation is
    sigma*PI/sqrt(3).
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGCDF = Compute the logistic cumulative distribution function.
    LOGPDF = Compute the logistic probability density function.
    LOGPPF = Compute the logistic percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
    LGNCDF = Compute the logmormal cumulative distribution function.
    LGNPDF = Compute the logmormal probability density function.
    LGNPPF = Compute the logmormal percent point function.
    EXPCDF = Compute the exponential cumulative distribution function.
    EXPPDF = Compute the exponential probability density function.
    EXPPPF = Compute the exponential percent point function.
 
Reference:
    "Continuous Univariate Distributions - Volume 2", Johnson, Kotz,
    and Balakrisnan, Wiley, 1994, chapter 23.
 
    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 124-128.
 
    "Statistical Models and Methods for Lifetime Data", Lawless,
    John Wiley, 1982 (pp. 46-47).
 
Applications:
    Distributional Modeling
 
Implementation Date:
    94/4
 
Program:
    XLIMITS 0 1
    MAJOR XTIC NUMBER 6
    MINOR XTIC NUMBER 1
    XTIC DECIMAL 1
    TITLE AUTOMATIC
    PLOT LOGSF(X) FOR X = 0.01 .01 0.99
 
-----LOOP----------------------------------------------------------
 
LOOP
 
Name:
    LOOP
 
Type:
    Support Command
 
Purpose:
    Execute a sequential loop.
 
Description:
    A sequential loop is one that has a defined start and stop value
    and a constant increment.  The values for the start, increment,
    and stop can have real values (i.e., DATAPLOT is not limited to
    integer loops).  DATAPLOT loops can have either a positive or a
    negative increment.
 
Syntax:
    LOOP  FOR <param> = <start>  <inc> <stop>
    where <param> is a parameter that specifies the loop index
               variable;
          <start> is a number or parameter that is the value for
               <param> on the first iteration of the loop;
          <inc> is a number or parameter that <param> is incremented by
               after each iteration is completed;
          <stop> is a number or parameter that determines when the loop
               is terminated (i.e., when <param> exceeds this value, no
               more iterations are performed).
 
Examples:
    LOOP FOR K = 1 1 100
    LOOP FOR K = START INC STOP
    LOOP FOR K = 10 -2 1
 
Note:
    The stop condition is tested at the end of the loop.  This means
    all loops are executed at least once even if <stop> is less than
    <start>.
 
Note:
    Loops can be nested up to 7 levels.  A unique index variable should
    be used for each loop.
 
Note:
    A maximum of 200 commands can be contained in a loop.  If you need
    more, put some of the commands in a macro file and use the CALL
   command.
 
   Note: This maximum was upped to 500 commands 1998/5.

Note:
    Loops only save the first 80 characters of a command.  If you use
    the continue character ("..."), this counts as a single command and
    only the first 80 characters are stored.
 
Note:
    There is currently no mechanism for exiting a loop other than
    <param> exceeding <stop>.  That is, you can not break out of a loop
    when some condition is met.  However, you can nest an IF block
    inside the loop to inhibit execution of commands.
 
Note:
    IF blocks can be nested inside of a loop and a loop can be nested
    inside an IF block.
 
Note:
    Although loops can be used for data manipulations, it is more
    efficient to do this without loops when possible.  As a rule of
    thumb, it is usually efficient to loop over the number of variables
    (i.e., columns) while it is usually rather slow to loop over the
    number of observations (i.e., rows), particularly if N is fairly
    large.  DATAPLOT's wide array of data manipulation commands
    combined with clever use of tag variables and the SUBSET command
    can often be used to avoid writing loops.
 
Note:
    The command BREAK LOOP can be used to terminate a loop before
    all iterations are completed.  Enter HELP BREAK LOOP for details.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    END OF LOOP    = Terminate a loop.
    IF             = Conditionally execute commands.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBER FOR I = 1 1 100
    LET Y2 = EXPONENTIAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y3 = T RANDOM NUMBERS FOR I = 1 1 100
    LET Y4 = CAUCHY RANDOM NUMBERS FOR I = 1 1 100
    LET STRING T1 = NORMAL RANDOM NUMBERS
    LET STRING T2 = EXPONENTIAL RANDOM NUMBERS
    LET NU = 20
    LET STRING T3 = T RANDOM NUMBERS
    LET STRING T4 = CAUCHY RANDOM NUMBERS
    LET X = SEQUENCE 1 1 100
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    LOOP FOR K = 1 1 4
       TITLE ^T^K
       HISTOGRAM Y^K
    END OF LOOP
    END OF MULTIPLOT
 
-----LORENZ CURVE--------------------------------------------------
 
LORENZ CURVE
 
Name:
    LORENZ CURVE
 
Type:
    Graphics Command
 
Purpose:
    Generates a Lorenz curve.
 
Description:
    The Lorenz curve is sometimes used by economists to show how unequally
    income is distributed.  Given a response variable (typically income),
    the Lorenz curve is formed by

       1. Sort the response variable.

       2. The i-th x-axis coordinate is i/n where n is the number of
          observations in the response variable.

       3. The i-th y-axis coordinate is

             SUM[k=1 to i][Y(k)]/SUM[k=1 to n][Y(k)]

    The Lorenz curve will have a 0 to 1 scale in both the horizontal
    and vertical directions.  A reference line is drawn from (0,0) to
    (1,1).  This curve represents perfect equality in the income
    distribution.  The greater the distance from the reference line to the
    Lorenz curve the greater the inequality of the income distribution.

    The Gini index can be used to summarize the income inequality.  The
    Gini index can be computed from the Lorenz curve as

        0.5 - the integral of the plotted Lorenz curve

    The Gini index has been criticized for not distinguishing whether the
    inequality is in the center of the distribution or from the tails.

Syntax 1:
    LORENZ CURVE  <y>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that <y> can be either a variable or a matrix.  If <y> is a
    matrix, the Lorenz curve will be generated for all values in the
    matrix.

    The Gini index will be saved in the internal parameter GINI.

Syntax 2:
    MULTIPLE LORENZE CURVE  <y1> ... <yk>
                                  <SUBSET/EXCEPT/FOR qualification>
    where <y1> ... <yk> is a list of response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax will overlay multiple Lorenz curves on the same plot.

    Note that the response variables (<y1> ... <yk>) can be either
    variables or matrices (or a mix of variables and matrices).  For
    matrices, a Lorenz curve will be generated for all values in the
    matrix.

    The Gini indices will be saved in the internal parameters GINI1,
    GINI2, and so on.

Syntax 3:
    REPLICATED LORENZ CURVE  <y>  <x1>
                                  <SUBSET/EXCEPT/FOR qualification>
    where <y>  is the response variable;
          <x1> is a group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax will generate a Lorenz curve for each distinct value in
    the group-id variable.  The Lorenz curves will be generated on the
    same page.

    Matrix arguments are not accepted for the REPLICATED case.

    The Gini indices will be saved in the internal parameters GINI1,
    GINI2, and so on.  There will be a Gini index for each distinct
    group.

Syntax 4:
    REPLICATED LORENZ CURVE  <y>  <x1> <x2>
                                  <SUBSET/EXCEPT/FOR qualification>
    where <y>  is the response variable;
          <x1> is the first group-id variable;
          <x2> is the second group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax will cross tabulate the group-id variables and generate a
    Lorenz curves for each unique combination of values for the <x1> and
    <x2> group-id variables.  The Lorenz curves will be generated on the
    same page.

    Matrix arguments are not accepted for the REPLICATED case.

    The Gini indices will be saved in the internal parameters GINI1,
    GINI2, and so on.  There will be a Gini index for each distinct
    group.

Examples:
    LORENZ CURVE Y
    LORENZ CURVE Y  SUBSET TAG = 2
    MULTIPLE LORENZ CURVE Y1 Y2 Y3
    REPLICATED LORENZ CURVE Y X1 X2
 
Note:
    The Lorenz curve will not be generated if the response variable
    contains negative numbers.  The response variable does not need
    to be pre-sorted.

Note:
    The LORENZ CURVE supports the TO syntax for the list
    of variable names.  This is most useful for the MULTIPLE
    case.

Note:
    The interdecile ratio provides an alternative to the Gini index that
    can be more sensitive to differences in the lower and upper tails.

Default:
    None
 
Synonyms:
    LORENZ PLOT is a synonym for LORENZ CURVE

Related Commands:
    INTERDECILE RATIO        = Compute the interdecile ratio.
    VARIATIONAL DISTANCE     = Compute the variational distance (a measure
                               of departure from uniformity).
    UNIFORM PROBABILITY PLOT = Generate a uniform probability plot.
 
Reference:
    Cobham and Sumner (2014), "Is Ineqaulity All About the Tails",
    Significance, Vol. 11, No. 1, pp. 10-13.
 
Applications:
    Income Distribution
 
Implementation Date:
    2015/01
 
Program 1:
    . Step 1:   Read the data
    .
    skip 25
    read electric.dat y x1 x2 x3
    skip 0
    .
    . Step 2:   Generate the Lorenz curve
    .
    case asis
    label case asis
    title case asis
    title offset 2
    title Lorenz Curve
    y1label Proportion of Income
    x1label Proportion of People
    .
    region fill on on
    region pattern solid solid
    region fill color yellow green
    .
    lorenz curve y
    .
    let gini = round(gini,2)
    justification center
    move 50 5
    text Gini Index: ^gini
 
Program 2:
    . Step 1:   Read the data
    .
    skip 25
    read weibbury.dat y1
    read frechet.dat  y2
    read exp.dat      y3
    skip 0
    .
    . Step 2:   Generate the Lorenz curve
    .
    case asis
    label case asis
    title case asis
    title offset 2
    title Lorenz Curve
    y1label Proportion of Income
    x1label Proportion of People
    .
    line color black blue green red
    .
    multiple lorenz curve y1 y2 y3
    .
    let gini1 = round(gini1,2)
    let gini2 = round(gini2,2)
    let gini3 = round(gini3,2)
    justification center
    move 50 7
    text Blue: WEIBBURY.DAT - Gini Index: ^gini1
    move 50 4.5
    text Green: FRECHET.DAT - Gini Index: ^gini2
    move 50 2
    text Red: EXP.DAT - Gini Index: ^gini3

-----LOSCDF (LET)--------------------------------
 
LOSCDF
 
Name:
    LOSCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the lost games cumulative distribution function.
 
Description:
    The formula for the lost games probability mass function is

        p(x;p,r) = (2*x-r  x)*(1-p)**(x-r)*(p)**x*(r/(2*x-r))
                   X = r, r + 1, ...; 0.5 < p < 1

    with p and r denoting the shape parameters.  The
    r parameter is restricted to non-negative integers.

    The cumulative distribution function is computed by summing
    the probability mass function.

        
Syntax:
    LET <y> = LOSCDF(<x>,<p>,<r>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is a positive integer variable, number, or
               parameter;
          <p> is a number or parameter in the range (0.5,1)
               that specifies the first shape parameter;
          <r> is a number or parameter denoting a positive
               integer that specifies the second shape parameter;
          <y> is a variable or a parameter where the computed
               lost games cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOSCDF(3,0.7,3)
    LET Y = LOSCDF(X1,0.7,2)
    PLOT LOSCDF(X,0.6,5) FOR X = 5  1  50
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOSPDF                   = Compute the lost games probability
                               mass function.
    LOSPPF                   = Compute the lost games percent point
                               function.
    BTAPDF                   = Compute the Borel-Tanner probability
                               mass function.
    POIPDF                   = Compute the Poisson probability
                               density function.
    HERPDF                   = Compute the Hermite probability
                               mass function.
    BINPDF                   = Compute the binomial probability
                               mass function.
    NBPDF                    = Compute the negative binomial
                               probability mass function.
    GEOPDF                   = Compute the geometric probability
                               mass function.

Reference:
    Luc Devroye (1986), "Non-Uniform Random Variate Generation",
    Springer-Verlang, pp. 758-759.
 
    Kemp and Kemp (1968), "On a Distribution Associated with
    Certain Stochastic Processes", Journal of the Royal
    Statistical Society, Series B, 30, pp. 401-410.

    Haight (1961), "A Distribution Analogous to the Borel-Tanner
    Distribution", Biometrika, 48, pp. 167-173.

    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 445-447.

Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    title size 3
    tic label size 3
    label size 3
    legend size 3
    height 3
    multiplot scale factor 1.5
    x1label displacement 12
    y1label displacement 17
    .
    multiplot corner coordinates 0 0 100 95
    multiplot scale factor 2
    label case asis
    title case asis
    case asis
    tic offset units screen
    tic offset 3 3
    title displacement 2
    y1label Probability
    x1label X
    .
    ylimits 0 1
    major ytic mark number 6
    minor ytic mark number 3
    xlimits 0 20
    line blank
    spike on
    .
    multiplot 2 2
    .
    title P = 0.6, R = 3
    plot loscdf(x,0.6,3) for x = 1 1 20
    .
    title P = 0.7, R = 3
    plot loscdf(x,0.7,3) for x = 1 1 20
    .
    title P = 0.8, R = 3
    plot loscdf(x,0.8,3) for x = 1 1 20
    .
    title P = 0.9, R = 3
    plot loscdf(x,0.9,3) for x = 1 1 20
    .
    end of multiplot
    .
    justification center
    move 50 97
    text Cumulative Distribution for Lost Games
 
-----LOSPDF (LET)--------------------------------
 
LOSPDF
 
Name:
    LOSPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the lost games probability mass function.
 
Description:
    The formula for the lost games probability mass function is

        p(x;p,r) = (2*x-r  x)*(1-p)**(x-r)*(p)**x*(r/(2*x-r))
                   X = r, r + 1, ...; 0.5 < p < 1

    with p and r denoting the shape parameters.  The
    r parameter is restricted to non-negative integers.

    This distribution is used to model the "gamblers ruin"
    problem.  For this problem, p is the probability that the
    gambler loses one unit (1 - p is the probability that the
    gambler wins one unit).  The value of r is the number of
    units the gambler starts with.  The lost games distribution
    is then the distribution of the number of games lost until
    the gambler loses all of his fortune.  This problem is
    referred to as the gambler's ruin since if the probability
    of winning is less than 0.5, the gambler will eventually
    lose all of his fortune with probability 1.

    Although this distribution was developed to model gambling,
    Kemp and Kemp demonstrated its applicability to a number of
    other important applications.  For example, Haight used it
    to model the queue with r initial customers, where new
    customers arrive according to a homogeneous Poisson process
    with shape parameter lambda, and the service time follows
    an exponential distribution with shape parameter mu
    (mu >=  lambda).  The p parameter in our formula can be
    expressed as

         p = 1 - lambda/(lambda+mu)

    Note that Haight use the parameterization

         alpha = mu/lambda

    Assuming a constant service time (rather than an
    exponential service time) results in the Borel-Tanner
    distribution.

Syntax:
    LET <y> = LOSPDF(<x>,<p>,<r>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is a positive integer variable, number, or
               parameter;
          <p> is a number or parameter in the range (0.5,1)
               that specifies the first shape parameter;
          <r> is a number or parameter denoting a positive
               integer that specifies the second shape parameter;
          <y> is a variable or a parameter where the computed
               lost games pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOSPDF(3,0.7,3)
    LET Y = LOSPDF(X1,0.7,2)
    PLOT LOSPDF(X,0.6,5) FOR X = 5  1  50
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Note:
    For a number of commands utilizing the lost games
    distribution, it is convenient to bin the data.  There
    are two basic ways of binning the data.

      1) For some commands (histograms, maximum likelihood
         estimation), bins with equal size widths are
         required.  This can be accomplished with the
         following commands:

            LET AMIN = MINIMUM Y
            LET AMAX = MAXIMUM Y
            LET AMIN2 = AMIN - 0.5
            LET AMAX2 = AMAX + 0.5
            CLASS MINIMUM AMIN2
            CLASS MAXIMUM AMAX2
            CLASS WIDTH 1
            LET Y2 X2 = BINNED

      2) For some commands, unequal width bins may be
         helpful.  In particular, for the chi-square goodness
         of fit, it is typically recommended that the minimum
         class frequency be at least 5.  In this case, it may
         be helpful to combine small frequencies in the tails.
         Unequal class width bins can be created with the
         commands

            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = INTEGER FREQUENCY TABLE Y

         If you already have equal width bins data, you can
         use the commands
         
            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = COMBINE FREQUENCY TABLE Y2 X2

         The MINSIZE parameter defines the minimum class
         frequency.  The default value is 5.

Note:
    You can generate lost games random numbers, probability plots,
    and chi-square goodness of fit tests with the following
    commands:

       LET N = VALUE
       LET R = <value>
       LET P = <value>
       LET Y = LOST GAMES RANDOM NUMBERS FOR I = 1 1 N

       LOST GAMES PROBABILITY PLOT Y
       LOST GAMES PROBABILITY PLOT Y2 X2
       LOST GAMES PROBABILITY PLOT Y3 XLOW XHIGH

       LOST GAMES CHI-SQUARE GOODNESS OF FIT Y
       LOST GAMES CHI-SQUARE GOODNESS OF FIT Y2 X2
       LOST GAMES CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    To obtain the maximum likelihood estimate of p assuming
    that r is known, enter the command

        LOST GAMES MAXIMUM LIKELIHOOD Y
        LOST GAMES MAXIMUM LIKELIHOOD Y2 X2

    The maximum likelihood estimate of p is

        phat = xbar/(2*xbar - r)

    with xbar denoting the mean.

    For a given value of r, generate an estimate of p based on
    the maximum ppcc value or the minimum chi-square goodness of
    fit with the commands

        LET R = <value>
        LET P1 = <value>
        LET P2 = <value>
        LOST GAMES KS PLOT Y
        LOST GAMES KS PLOT Y2 X2
        LOST GAMES KS PLOT Y3 XLOW XHIGH
        LOST GAMES PPCC PLOT Y
        LOST GAMES PPCC PLOT Y2 X2
        LOST GAMES PPCC PLOT Y3 XLOW XHIGH

    The default values of p1 and p2 are 0.51 and 0.95,
    respectively.  The value of r should typically be
    set to the minimum value of the data.  Due to the discrete
    nature of the percent point function for discrete
    distributions, the ppcc plot will not be smooth.  For that
    reason, if there is sufficient sample size the KS PLOT
    (i.e., the minimum chi-square value) is typically preferred.
    Also, since the data is integer values, one of the binned
    forms is preferred for these commands.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOSCDF                   = Compute the lost games cumulative
                               distribution function.
    LOSPPF                   = Compute the lost games percent point
                               function.
    BTAPDF                   = Compute the Borel-Tanner probability
                               mass function.
    POIPDF                   = Compute the Poisson probability
                               mass function.
    HERPDF                   = Compute the Hermite probability
                               mass function.
    BINPDF                   = Compute the binomial probability
                               mass function.
    NBPDF                    = Compute the negative binomial
                               probability mass function.
    GEOPDF                   = Compute the geometric probability
                               mass function.
    INTEGER FREQUENCY TABLE  = Generate a frequency table at
                               integer values with unequal bins.
    COMBINE FREQUENCY TABLE  = Convert an equal width frequency
                               table to an unequal width frequency
                               table.
    KS PLOT                  = Generate a minimum chi-square plot.
    MAXIMUM LIKELIHOOD       = Perform maximum likelihood
                               estimation for a distribution.

Reference:
    Luc Devroye (1986), "Non-Uniform Random Variate Generation",
    Springer-Verlang, pp. 758-759.
 
    Kemp and Kemp (1968), "On a Distribution Associated with
    Certain Stochastic Processes", Journal of the Royal
    Statistical Society, Series B, 30, pp. 401-410.

    Haight (1961), "A Distribution Analogous to the Borel-Tanner
    Distribution", Biometrika, 48, pp. 167-173.

    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 445-447.

Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    let r = 3
    let p = 0.6
    let y = lost games random numbers for i = 1 1 500
    .
    let y3 xlow xhigh = integer frequency table y
    class lower 1.5
    class width 1
    let amax = maximum y
    let amax2 = amax + 0.5
    class upper amax2
    let y2 x2 = binned y
    .
    lost games mle y
    let p = pml
    lost games chi-square goodness of fit y3 xlow xhigh
    relative histogram y2 x2
    limits freeze
    pre-erase off
    line color blue
    title Lost Games MLE FIt: Phat = ^pml (r = ^r)
    plot lospdf(x,pml,r) for x = r  1  amax
    title
    limits
    pre-erase on
    line color black
    .
    label case asis
    x1label P
    y1label Minimum Chi-Square
    let p1 = 0.5
    let p2 = 0.9
    lost games ks plot y3 xlow xhigh
    let p = shape
    case asis
    justification center
    move 50 5
    text P = ^p
    lost games chi-square goodness of fit y3 xlow xhigh
 
-----LOSPPF (LET)--------------------------------
 
LOSPPF
 
Name:
    LOSPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the lost games percent point function.
 
Description:
    The formula for the lost games probability mass function is

        p(x;p,r) = (2*x-r  x)*(1-p)**(x-r)*(p)**x*(r/(2*x-r))
                   X = r, r + 1, ...; 0.5 < p < 1

    with p and r denoting the shape parameters.  The
    r parameter is restricted to non-negative integers.

    The cumulative distribution function is computed by summing
    the probability mass function.  The percent point function
    is the inverse of the cumulative distribution function and
    is obtained by computing the cumulative distribution function
    until the specified probability is reached.
        
Syntax:
    LET <y> = LOSPPF(<x>,<p>,<r>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is an integer variable, number, or parameter
               in the interval (0,1);
          <p> is a number or parameter in the range (0.5,1)
               that specifies the first shape parameter;
          <r> is a number or parameter denoting a positive
               integer that specifies the second shape parameter;
          <y> is a variable or a parameter where the computed
               lost games ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOSPPF(0.95,0.7,3)
    LET Y = LOSPPF(P1,0.7,2)
    PLOT LOSPPF(P,0.6,5) FOR P = 0  0.01  0.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOSCDF                   = Compute the lost games cumulative
                               distribution function.
    LOSPDF                   = Compute the lost games probability
                               mass function.
    BTAPDF                   = Compute the Borel-Tanner probability
                               mass function.
    POIPDF                   = Compute the Poisson probability
                               mass function.
    HERPDF                   = Compute the Hermite probability
                               mass function.
    BINPDF                   = Compute the binomial probability
                               mass function.
    NBPDF                    = Compute the negative binomial
                               probability mass function.
    GEOPDF                   = Compute the geometric probability
                               mass function.

Reference:
    Luc Devroye (1986), "Non-Uniform Random Variate Generation",
    Springer-Verlang, pp. 758-759.
 
    Kemp and Kemp (1968), "On a Distribution Associated with
    Certain Stochastic Processes", Journal of the Royal
    Statistical Society, Series B, 30, pp. 401-410.

    Haight (1961), "A Distribution Analogous to the Borel-Tanner
    Distribution", Biometrika, 48, pp. 167-173.

    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 445-447.

Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    title size 3
    tic label size 3
    label size 3
    legend size 3
    height 3
    multiplot scale factor 1.5
    x1label displacement 12
    y1label displacement 17
    .
    multiplot corner coordinates 0 0 100 95
    multiplot scale factor 2
    label case asis
    title case asis
    case asis
    tic offset units screen
    tic offset 3 3
    title displacement 2
    x1label Probability
    y1label X
    .
    xlimits 0 1
    major xtic mark number 6
    minor xtic mark number 3
    .
    multiplot 2 2
    .
    title P = 0.6, R = 3
    plot losppf(p,0.6,3) for p = 0  0.01  0.99
    .
    title P = 0.7, R = 3
    plot losppf(p,0.7,3) for p = 0  0.01  0.99
    .
    title P = 0.8, R = 3
    plot losppf(p,0.8,3) for p = 0  0.01  0.99
    .
    title P = 0.9, R = 3
    plot losppf(p,0.9,3) for p = 0  0.01  0.99
    .
    end of multiplot
    .
    justification center
    move 50 97
    text Percent Point for Lost Games
 
-----LOWER CASE-----------------------------------------------------
 
LOWER CASE
 
Name:
    LOWER CASE
 
Type:
    Let Subcommand
 
Purpose:
    Convert a string to all lower case characters.
 
Syntax:
    LET <sout> = LOWER CASE  <sorg>
    where <sout> is the resulting all lower case string;
    and   <sorg> is the name of the original string.
 
Examples:
    LET SOUT = LOWER CASE S1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    UPPER CASE          = Convert a string to upper case.
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    SUBTRING            = Extract a substring from an existing string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING EDIT         = Edit a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    STRING LENGTH       = Return the length of a string.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    11/2008
 
Program:
    LET STRING S1 = FILE23.DAT
    LET SOUT = LOWER CASE S1

    The resulting string is file23.dat.

-----LOWER HINGE (LET)--------------------------------
 
LOWER HINGE
 
Name:
    LOWER HINGE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the lower hinge for a variable.
 
Description:
    The lower hinge is a pseudo 25% point of the variable (it is the
    median of the points between the minimum and the full sample
    median).
 
Syntax:
    LET <param> = LOWER HINGE <y1> <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the response variable;
          <param> is a parameter where the computed lower hinge is
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOWER HINGE Y1
    LET A = LOWER HINGE Y1 SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None, although LOWER QUARTILE is closely related.
 
Related Commands:
    UPPER HINGE        = Compute the upper hinge.
    LOWER QUARTILE     = Compute the lower quartile.
    UPPER QUARTILE     = Compute the upper quartile.
    MEAN               = Compute the mean.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    XX
 
Program:
    LET Y1 = EXPONENTIAL RANDOM NUMBERS FOR I = 1 1 100
    LET A1 = LOWER HINGE Y1
 
-----LOWER HINGE PLOT--------------------------------------------
 
LOWER HINGE PLOT
 
Name:
    LOWER HINGE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a lower hinge plot.
 
Description:
    The lower hinge is a pseudo lower quartile (it is the median of the
    points between the median and the minimum).  The lower hinge plot
    consists of subsample lower hinge versus subsample index.
    The lower hinge plot is used to answer the question--"Does the
    subsample variation change over different subsamples?"   The plot
    consists of:
       Vertical   axis = subsample lower hinge;
       Horizontal axis = subsample index.
    The lower hinge plot yields 2 traces:
       1. a subsample lower hinge trace; and
       2. a full-sample lower hinge reference line.
    Like usual, the appearance of these 2 traces is controlled by
    the first 2 settings of the LINES, CHARACTERS, SPIKES, BARS,
    and similar attributes.
 
Syntax:
    LOWER HINGE PLOT <y> <x>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LOWER HINGE PLOT Y X
    LOWER HINGE PLOT Y X1
    LOWER HINGE PLOT Y X
 
Default:
    None
 
Synonyms:
    LH PLOT
 
Related Commands:
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    UPPER HINGE  PLOT       = Generates an upper hinge plot.
    LOWER QUARTILE  PLOT    = Generates a lower quartile plot.
    UPPER QUARTILE  PLOT    = Generates an upper quartile plot.
    MINIMUM  PLOT           = Generates a minimum plot.
    MAXIMUM  PLOT           = Generates a maximum plot.
    RANGE  PLOT             = Generates a range plot.
    STANDARD DEVIATION PLOT = Generates a stand deviation plot.
    VARIANCE  PLOT          = Generates a variance plot.
    MEAN PLOT               = Generates a mean plot.
    MEDIAN PLOT             = Generates a median plot.
    BOX PLOT                = Generates a box plot.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    LET Y = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET NU = 20
    LET Y = T RANDOM NUMBERS FOR I = 101 1 200
    LET NU = 5
    LET Y = CHI-SQUARE RANDOM NUMBERS FOR I = 201 1 300
    LET X = 1 FOR I = 1 1 100
    LET X = 2 FOR I = 101 1 200
    LET X = 3 FOR I = 201 1 300
    .
    TITLE DEMONSTRATE HINGE PLOT
    XTIC OFFSET 0.2 0.2
    XLIMITS 1 3
    MAJOR XTIC MARK NUMBER 3
    MINOR XTIC MARK NUMBER 0
    XTIC MARK LABEL FORMAT ALPHA
    XTIC MARK LABEL CONTENT NORMAL T CHI-SQUARE
    LINE BLANK SOLID
    CHARACTER L BLANK
    LOWER HINGE PLOT Y X
 
-----LOWER QUARTILE (LET)--------------------------------
 
LOWER QUARTILE
 
Name:
    LOWER QUARTILE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the lower quartile for a variable.
 
Description:
    The lower quartile is the 25% point of the variable.
 
Syntax:
    LET <param> = LOWER QUARTILE <y1> <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the response variable;
          <param> is a parameter where the computed lower quartile is
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOWER QUARTILE Y1
    LET A = LOWER QUARTILE Y1 SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None, although LOWER HINGE is closely related.
 
Related Commands:
    UPPER HINGE        = Compute the upper hinge.
    LOWER HINGE        = Compute the lower hinge.
    UPPER QUARTILE     = Compute the upper quartile.
    MEAN               = Compute the mean.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    XX
 
Program:
    LET Y1 = EXPONENTIAL RANDOM NUMBERS FOR I = 1 1 100
    LET A1 = LOWER QUARTILE Y1
 
-----LOWER QUARTILE PLOT-----------------------------------------
 
LOWER QUARTILE PLOT
 
Name:
    LOWER QUARTILE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a lower quartile plot.
 
Description:
    A lower quartile plot consists of subsample lower quartile versus
    subsample index.  The subsample lower quartile is the estimated 25%
    point of the subsample.  The lower quartile plot is used to answer
    the question--"Does the subsample variation change over different
    subsamples?"  The plot consists of:
       Vertical   axis = subsample lower quartile;
       Horizontal axis = subsample index.
    The lower quartile plot yields 2 traces:
       1. a subsample lower quartile trace; and
       2. a full-sample lower quartile reference line.
    Like usual, the appearance of these 2 traces is controlled
    by the first 2 settings of the LINES, CHARACTERS, SPIKES,
    BARS, and similar attributes.
 
Syntax:
    LOWER QUARTILE PLOT <y> <x>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LOWER QUARTILE PLOT Y X
    LOWER QUARTILE PLOT Y X1
 
Default:
    None
 
Synonyms:
    LQ PLOT
 
Related Commands:
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    UPPER QUARTILE  PLOT    = Generates an upper quartile plot.
    LOWER HINGE  PLOT       = Generates a lower hinge plot.
    UPPER HINGE  PLOT       = Generates an upper hinge plot.
    MINIMUM  PLOT           = Generates a minimum plot.
    MAXIMUM  PLOT           = Generates a maximum plot.
    RANGE  PLOT             = Generates a range plot.
    STANDARD DEVIATION PLOT = Generates a stand deviation plot.
    VARIANCE  PLOT          = Generates a variance plot.
    MEAN PLOT               = Generates a mean plot.
    MEDIAN PLOT             = Generates a median plot.
    BOX PLOT                = Generates a box plot.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    LET Y = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET NU = 20
    LET Y = T RANDOM NUMBERS FOR I = 101 1 200
    LET NU = 5
    LET Y = CHI-SQUARE RANDOM NUMBERS FOR I = 201 1 300
    LET X = 1 FOR I = 1 1 100
    LET X = 2 FOR I = 101 1 200
    LET X = 3 FOR I = 201 1 300
    .
    TITLE DEMONSTRATE HINGE PLOT
    XTIC OFFSET 0.2 0.2
    XLIMITS 1 3
    MAJOR XTIC MARK NUMBER 3
    MINOR XTIC MARK NUMBER 0
    XTIC MARK LABEL FORMAT ALPHA
    XTIC MARK LABEL CONTENT NORMAL T CHI-SQUARE
    LINE BLANK SOLID
    CHARACTER L BLANK
    LOWER QUARTILE PLOT Y X
 
-----LOWESS DEGREE-----------------------------------------
 
LOWESS DEGREE
 
Name:
    LOWESS DEGREE
 
Type:
    Support
 
Purpose:
    Specifies whether the LOWESS command performs local linear fitting
    or local quadratic fitting.

Description:
    Quadratic fits are recommended if there are local minimum and
    maximum points in the data.  Otherwise, linear fitting should be
    adequate.  Linear fitting is the default.
 
Syntax:
    LOWESS DEGREE  <1/2>
    where 1 specifies local linear fitting and 2 specifies local 
            quadratic fitting.
 
Examples:
    LOWESS DEGREE 1
    LOWESS DEGREE 2
 
Default:
    The default is local linear fitting (i.e., LOWESS DEGREE 1).
 
Synonyms:
    None
 
Related Commands:
    LOWESS SMOOTH  = Carries out lowess smoothing.
    LOWESS PERCENT = Sets the width as a percentage rather than a
                     fraction.
    SMOOTH         = Carries out least squares smoothing.
    FILTER WIDTH   = Sets smoothing width for least squares smoothing.
 
Applications:
    Robust Smoothing, Time Series Analysis
 
Implementation Date:
    94/6
 
Program:
    SKIP 25
    READ HAYES1.DAT X ST Y
    .
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    CHARACTER CIRCLE BLANK; LINE BLANK SOLID
    TITLE RAW DATA
    PLOT Y X
    LOWESS FRACTION 0.3
    LOWESS Y X
    TITLE LINEAR LOWESS (0.3)
    PLOT Y PRED VS X
    LOWESS DEGREE 2
    TITLE QUADRATIC LOWESS (0.3)
    LOWESS Y X
    PLOT Y PRED VS X
    LOWESS FRACTION 0.15
    LOWESS Y X
    TITLE QUADRATIC LOWESS (0.15)
    PLOT Y PRED VS X
    END OF MULTIPLOT
 
-----LOW PASS FILTER (LET)--------------------------------------------
 
LOW PASS FILTER
 
Name:
    LOW PASS FILTER (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute a low-pass filter or a high-pass filter for a variable.
 
Description:
    Low-pass filters are used to remove high frequency noise from a time
    series where the time series is assummed to contain equally spaced
    points.  Dataplot computes the low-pass filter using the LOPASS routine
    from the STARPAC library (developed by Janet Rodgers and Peter Tyrone
    formerly of NIST).  The LOPASS routine is in turn based on the codes
    of Peter Bloomfield (see Reference section below). 

    The low-pass filter contains two basic steps:

        1. Compute symmetric low-pass filter coefficients using a least
           squares approximation to an ideal low-pass filter (this step is
           perfomed by the Starpac LPCOEF routine).  This routine has
           convergence factors to reduce overshoot and ripple and has a
           transfer function which changes from approximately one to zero
           in a transition band about the ideal cutoff frequency, FC.
           That is, from (FC - 1/K) to (FC + 1/K).

           You need to specify the cutoff frequency in cycles per sample
           interval and the number of filter coefficients.  The conditions
           on these choices are:

           a. FC must be between 0.0 and 0.5.

           b. The number of filter coefficients must be odd.

           c. (FC - 1/K) > 0  and  (FC + 1/K) < 0.5.

           d. Sharp cutoffs occur when 1/K is small. 

           e. (K-1)/2 data points will be lost from the filtered series.

           The Program example below demonstrates setting these parameters.

        2. The coefficients computed in step 1 are used to filter the
           original series.

    For any low-pass filter, there is a corresponding high-pass filter 
    equivalent to subtracting the low-pass filtered series from the
    original series (i.e., you are extracting the high frequency
    component).  Dataplot uses the Starpac HIPASS routine to compute
    the high-pass filter.

Syntax 1:
    LET <y> = LOW PASS FILTER  <x>     <SUBSET/EXCEPT/FOR qualification>
    where <x> is a response variable;
          <y> is the response variable after computing the low-pass
               filter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <y> = HIGH PASS FILTER  <x>     <SUBSET/EXCEPT/FOR qualification>
    where <x> is a response variable;
          <y> is the response variable after computing the high-pass
               filter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET YOUT = LOW PASS FILTER Y
    LET YOUT = HIGH PASS FILTER Y
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    FFT                = Compute the fast Fourier transform.
    INVERSE FFT        = Compute the inverse of the fast Fourier
                         transform.
    COSINE TRANS       = Compute the cosine transformation.
    SINE TRANS         = Compute the sine transformation.
    SPECTRAL PLOT      = Generate a spectral plot.
 
Reference:
    Peter Bloomfield, 1976, "Fourier Analysis of Time Series: An
    Introduction", John Wiley and Sons, p. 149.
 
    Janet R. Donaldson and Peter V. Tryon (10/5/1987), "User's Guide to
    STARPAC The Standards Time Series and Regression Package", U.S.
    Department of Commerce Center for Applied Mathematics National Bureau
    of Standards Boulder, Colorado  80303

Applications:
    Signal Processing, Time Series
 
Implementation Date:
    2012/9
 
Program:
    . PURPOSE--REMOVE HIGH FREQUENCY CONTAMINATION FROM A SIGNAL
    . ANALYSIS TECHNIQUE--LOW PASS FILTER (STARPAC ROUTINE LOPASS)
    .
    . -----START POINT-----------------------------------
    .
    DIMENSION 20 VARIABLES
    .
    .      STEP 1-- DEFINE THE PURE SIGNAL DEFINE THE CONTAIMINATION
    .               COMBINE PURE + CONTAMINATION TO YIELD THE OBSERVED
    .               RESPONSE PLOT
    .
    LET X = SEQUENCE 0 .1 25.55
    LET YS = SIN(X)
    LET YN = NORMAL RANDOM NUMBERS FOR I = 1 1 256
    LET YN = YN/10
    LET Y = YS+YN
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    MULTIPLOT 2 2
    YLIMITS -2 2
    Y1LABEL AUTOMATIC
    PLOT YS
    PLOT YN
    PLOT Y
    YLIMITS
    END OF MULTIPLOT
    .
    LET N = SIZE Y
    LET X = SEQUENCE 8 1 249
    MULTIPLOT 2 3
    LET KTERM  = 15
    LET FC = 0.05
    LET YFILTL0 = LOW  PASS FILTER Y
    TITLE FC = 0.05
    PLOT YFILTL0 X
    LET FC = 0.1
    LET YFILTL1 = LOW  PASS FILTER Y
    TITLE FC = 0.1
    PLOT YFILTL1 X
    LET FC = 0.2
    LET YFILTL2 = LOW  PASS FILTER Y
    TITLE FC = 0.2
    PLOT YFILTL2 X
    LET FC = 0.3
    LET YFILTL3 = LOW  PASS FILTER Y
    TITLE FC = 0.3
    PLOT YFILTL3 X
    LET FC = 0.4
    LET YFILTL4 = LOW  PASS FILTER Y
    TITLE FC = 0.4
    PLOT YFILTL4 X
    END OF MULTIPLOT
 
-----LOWESS SMOOTH-----------------------------------------------
 
LOWESS SMOOTH
 
Name:
    LOWESS SMOOTH
 
Type:
    Analysis Command
 
Purpose:
    Carries out (robust) locally-weighted time series and scatter plot
    smoothing for both equispaced and non-equispaced data.  LOWESS
    stands for "locally weighted least squares".
 
Description:
    Lowess is a data analysis technique for producing a "smooth" set of
    values from a time series which has been contaminated with noise,
    or from a scatter plot with a "noisy" relationship between the 2
    variables.  In a time series context, the technique is an
    improvement over least squares smoothing when the data is not
    equally spaced (as least squares smoothing assumes).  For lowess
    smoothing, the analyst can vary the size of the smoothing
    window.  This size is given as the fraction (0 to 1) of the data
    that the window should cover.  The default window size is .1 (which
    states that the smoothing window has a total width of 10% of the
    horizontal axis variable).  To specify the width of the lowess
    smooth, use the LOWESS FRACTION command prior to using the LOWESS
    SMOOTH command.  This width must be a decimal value between 0 and
    1.
 
Syntax:
    LOWESS SMOOTH   <y>   <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the vertical axis variable under analysis;
          <x> is the horizontal axis variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LOWESS SMOOTH Y X
    LOWESS SMOOTH Y
    LOWESS SMOOTH CONC DAY
    LOWESS SMOOTH CONC
 
    LOWESS FRACTION .3
    LOWESS SMOOTH Y X
 
Note:
    The LOWESS fraction controls the smoothness of the curve.  For
    example, if it is 1.0, then the LOWESS curve is a single straight
    line.  In general, the smaller the fraction, the more that LOWESS
    curve follows individual data points.  To obtain a smoother LOWESS
    curve, increase the value of the LOWESS FRACTION.
 
Note:
    The LOWESS DEGREE command is used to specify whether local linear
    or local quadratic fits are applied to the points in the current
    data window.  Quadratic fits are recommended if there are local
    minimum and maximum points in the data.  Otherwise, linear fitting
    should be adequate.  Linear fitting is the default.

Note:
    The following is a brief sketch of the LOWESS algorithm.
       1) Compute the number of points in the neighborhood.  This is
          the LOWESS fraction times the number of data points rounded
          to the nearest integer.  Call this number q.
       2) Use a tricube function to generate a weighted least squares
          fit.  Let d(i) be the distance from x(i) to its qth nearest
          neighbor.  The weight given to point (x(k),y(k)) is:
              T(i)(x(k)) = T[(x(i)-x(k))/d(i)]
          where T is the tri-cube weight function.
       3) Compute the residuals of this fit.
       4) Compute a bi-square weight function of the residuals.
       5) Use the horizontal weights (from the tri-cube function)
          multiplied by the vertical weights (from the bi-square of the
          residuals) in a weighted least squares fit.
    See the documentation for TRICUBE and BIWEIGHT for the details on
    these weighting functions.
 
Default:
    For lowess smoothing, the default width is .1 (that is, 10% of the
    range of the horizontal axis variable).
 
Synonyms:
    None
 
Related Commands:
    LOWESS FRACTION    = Sets the width for lowess.
    LOWESS DEGREE      = Specify the degree for lowess smoothing.
    SMOOTH             = Carries out a least squares smoothing.
    MEDIAN SMOOTH      = Carries out a median smoothing.
    ROBUST SMOOTH      = Carries out a robust smoothing.
    FIT                = Carries out a least squares fit.
 
Reference:
    "Graphical Methods for Data Analysis", Chambers, Cleveland,
    Kleiner, and Tukey.  Wadsworth, 1983.
 
Applications:
    Robust Smoothing, Time Series Analysis
 
Implementation Date:
    88/3
 
Program:
    SERIAL READ Y
    18 14 25 19 13 31 14 13 28 14 11 21 20 16 31
    15 21 18 25 23 32 13 15 25 43 20 18 20 21 34
    END OF DATA
    SERIAL READ X
    130 225 95 100 170 65 175 130 80 150 150 107 122 110 52
    72 110 97 92 90 70 130 130 88 48 85 139 103 110 65
    END OF DATA
    LOWESS FRACTION 0.3
    LOWESS SMOOTH Y X
    CHAR X BLANK
    LINES BLANK SOLID
    TITLE LOWESS SMOOTH
    PLOT Y PRED VS X
 
-----LOWESS FRACTION-----------------------------------------
 
LOWESS FRACTION
 
Name:
    LOWESS FRACTION
 
Type:
    Support
 
Purpose:
    Sets the width of lowess smoothing (which carries out robust
    locally-weighted time series and scatter plot smoothing).
 
Description:
    For lowess smoothing, the analyst can vary the size of the
    smoothing window.  This size is given as the fraction (0 to 1) of
    the data that the window should cover.  The default window size is
    0.1 (which states that the smoothing window has a total width of
    10% of the horizontal axis variable).  This width must be a decimal
    value between 0 and 1.  To specify the width of the lowess smooth,
    use the LOWESS FRACTION command prior to using the LOWESS SMOOTH
    command.
 
Syntax:
    LOWESS FRACTION   <w>
    where <w> is a number or a parameter in the range 0 to 1
              (exclusive).
 
Examples:
    LOWESS FRACTION .3
    LOWESS FRACTION .45
    LOWESS FRACTION P
 
    LET W = .45
    LOWESS FRACTION W
    LOWESS SMOOTH Y X
 
Default:
    The default width is 0.1 (that is, 10% of the range of the
    horizontal axis variable).
 
Synonyms:
    LOWESS DECIMAL
 
Related Commands:
    LOWESS SMOOTH  = Carries out lowess smoothing.
    LOWESS PERCENT = Sets the width as a percentage rather than a
                     fraction.
    SMOOTH         = Carries out least squares smoothing.
    FILTER WIDTH   = Sets smoothing width for least squares smoothing.
 
Applications:
    Robust Smoothing, Time Series Analysis
 
Implementation Date:
    88/7
 
Program:
    SERIAL READ Y
    18 14 25 19 13 31 14 13 28 14 11 21 20 16 31
    15 21 18 25 23 32 13 15 25 43 20 18 20 21 34
    END OF DATA
    SERIAL READ X
    130 225 95 100 170 65 175 130 80 150 150 107 122 110 52
    72 110 97 92 90 70 130 130 88 48 85 139 103 110 65
    END OF DATA
    .
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    CHAR X BLANK
    LINES BLANK SOLID
    TITLE LOWESS SMOOTH
    .
    LOWESS FRACTION 0.2
    XLABEL LOWESS FRACTION = 0.2
    LOWESS SMOOTH Y X
    PLOT Y PRED VS X
    .
    LOWESS FRACTION 0.3
    X1LABEL LOWESS FRACTION = 0.3
    LOWESS SMOOTH Y X
    PLOT Y PRED VS X
    .
    LOWESS FRACTION 0.5
    X1LABEL LOWESS FRACTION = 0.5
    LOWESS SMOOTH Y X
    PLOT Y PRED VS X
    .
    LOWESS FRACTION 0.7
    X1LABEL LOWESS FRACTION = 0.7
    LOWESS SMOOTH Y X
    PLOT Y PRED VS X
    END OF MULTIPLOT
 
-----LOWESS PERCENT-----------------------------------------
 
LOWESS PERCENT
 
Name:
    LOWESS PERCENT
 
Type:
    Support
 
Purpose:
    Sets the width of lowess smoothing (which carries out robust
    locally-weighted time series and scatter plot smoothing).
 
Description:
    For lowess smoothing, the analyst can of vary the size of the
    smoothing window.  This size is given as the percentage (0 to 100)
    of the data that the window should cover.  The default window size
    is 10 (which states that the smoothing window has a total width of
    10% of the horizontal axis variable).  This width must be a decimal
    value between 0 and 100.  To specify the width of the lowess
    smooth, use the LOWESS PERCENT command prior to using the LOWESS
    SMOOTH command.
 
Syntax:
    LOWESS PERCENT   <w>
    where <w> is a number or a parameter in the range 0 to 100
              (exclusive).
 
Examples:
    LOWESS PERCENT 30
    LOWESS PERCENT 45
    LOWESS PERCENT P
 
    LET W = 45
    LOWESS PERCENT W
    LOWESS SMOOTH Y X
 
Default:
    The default width is 10 (that is, 10% of the range of the
    horizontal axis variable).
 
Synonyms:
    LOWESS PROPORTION
 
Related Commands:
    LOWESS SMOOTH  = Carries out lowess smoothing.
    LOWESS FRACTION= Sets the width as a fraction.
    SMOOTH         = Carries out least squares smoothing.
    FILTER WIDTH   = Sets the smoothing width for least squares
                     smoothing.
 
Applications:
    Robust Smoothing, Time Series Analysis
 
Implementation Date:
    88/7
 
Program:
    SERIAL READ Y
    18 14 25 19 13 31 14 13 28 14 11 21 20 16 31
    15 21 18 25 23 32 13 15 25 43 20 18 20 21 34
    END OF DATA
    SERIAL READ X
    130 225 95 100 170 65 175 130 80 150 150 107 122 110 52
    72 110 97 92 90 70 130 130 88 48 85 139 103 110 65
    END OF DATA
    .
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    CHAR X BLANK
    LINES BLANK SOLID
    TITLE LOWESS SMOOTH
    .
    LOWESS PERCENT 20
    XLABEL LOWESS PERCENT = 20
    LOWESS SMOOTH Y X
    PLOT Y PRED VS X
    .
    LOWESS PERCENT 30
    X1LABEL LOWESS PERCENT = 30
    LOWESS SMOOTH Y X
    PLOT Y PRED VS X
    .
    LOWESS PERCENT 50
    X1LABEL LOWESS PERCENT = 50
    LOWESS SMOOTH Y X
    PLOT Y PRED VS X
    .
    LOWESS PERCENT 70
    X1LABEL LOWESS PERCENT = 70
    LOWESS SMOOTH Y X
    PLOT Y PRED VS X
    END OF MULTIPLOT

-----LP LOCATION (LET)-----------------------------------------
 
LP LOCATION
 
Name:
    LP LOCATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the Lp (least power) location estimate of a variable.
 
Description:
    This description is summarized from the more thorough discussion
    given in the Pennecchi and Callegaro paper (see the Reference section
    below).

    The univariate measurement model (or location model) is

        y(i) = alpha + e(i)

    where alpha is the unknown value to be estimated and the y(i) are the
    sample observations affected by the measurement errors e(i).

    The least power (Lp) provides a broad class of location estimators.
    This class includes the mean, the median, and the mid-range as special
    cases.

    The Lp norm (for p >= 1) is defined as

         ||x||p = (SUM[i=1 to n][|x(i)|**p])**(1/p)

    For p = 1, 2, and infinity, these become the following norms

         ||x||1   = SUM[i=1 to n][|x(i)|]
         ||x||2   = SQRT{SUM[i=1 to n][x(i)**2]
         ||x||inf = max(i=1, 2, ..., n} {|x(i)|}

    The Lp norm estimation is based on the minimization of the Lp norm
    of a suitable residual vector.  Specifically, the Lp estimator of
    alpha is

        Lp(x(i)) = ARG(alpha)
                   MIN{(SUM[i=1 to n][|x(i) - alpha|**p)**(1/p)}
                         
    where ARGMIN means the argument of the minimum.  That is, the value
    of alpha that results in the minimum value of the expression.

    The Lp estimate is the solution of the equation

        SUM[i=1 to n][|x(i)-alpha|**(p-1)*SIGN(x(i)-alpha)] = 0

    The special cases mentioned above correspond to

        p = 1   - sample median
        p = 2   - sample mean
        p = INF - sample mid-range

    Values of p between 1 and 2 are of most interest as these have
    efficiency and robustness properties between the median (p = 1)
    and the mean (p = 2).

    The Pennecchi and Callegaro paper provides the following guidelines
    for choosing a suitable value for p.  Compute the sample kurtosis,
    khat, of the sample observations (note that the standard kurtosis
    formula should be used, not the version that subtracts 3 to make
    the kurtosis of a normal distribution equal to 0).  Then 

        khat < 2.2         - use the mid-range (i.e., p = infinity)
        2.2 <= khat <= 3   - use the mean (i.e., p = 2)
        3   <  khat <  6   - use p = 1.5
        khat >=  6         - use the median (i.e., p = 1)

    Pennecchi and Callegaro propose the following as an estimate of
    the asymptotic variance

        [m(2*p-2)/[(p-1)*m(p-2)]**2]/n

    where

        m(r) = (1/n)*SUM[i=1 to n][|x(i)-Lp(x(i))|**r]

Syntax 1:
    LET <par> = LP LOCATION  <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed lp location
              value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Use this syntax to compute the Lp location estimate.

Syntax 2:
    LET <par> = VARIANCE OF LP LOCATION  <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed variance of the
              lp location value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Use this syntax to compute the variance of the Lp location estimate.

Syntax 3:
    LET <par> = SD OF LP LOCATION  <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed sd of the
              lp location value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Use this syntax to compute the standard deviation of the Lp location
    estimate.

Examples:
    LET P = 1.5
    LET ALOC = LP LOCATION Y
    LET AVAR = LP VARIANCE Y
    LET ASD  = LP SD Y
    LET ALOC = LP LOCATION Y  SUBSET Y > 0
 
Note:
    Specify the value of p (before using the LP LOCATION or LP VARIANCE
    commands) by entering the following command

        LET P = <value>

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    STANDARD DEVIATION OF LP LOCATION is a synonym for SD OF LP LOCATION
    SD LP LOCATION is a synonym for SD OF LP LOCATION
    VARIANCE LP LOCATION is a synonym for VARIANCE OF LP LOCATION
 
Related Commands:
    MEAN                   = Compute the mean of a variable.
    MEDIAN                 = Compute the median of a variable.
    MIDRANGE               = Compute the midrange of a variable.
    H15                    = Compute the H15 estimate of location.
    VARIANCE               = Compute the variance of a variable.
    STANDARD DEVIATION     = Compute the standard deviation of a variable.
    MAD                    = Compute the median absolute deviation of a
                             variable.
 
Applications:
    Data Analysis, Key Comparisons
 
Reference:
    Francesca Pennecchi and Luca Callegaro (2006), "Between the Mean and
    the Median: the Lp Estimator," Metrologia, 43, pp. 213-219.

Implementation Date:
    2007/11
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 50
    LET Y2 = LAPLACE RANDOM NUMBERS FOR I = 1 1 50
    LET Y3 = UNIFORM RANDOM NUMBERS FOR I = 1 1 50
    LET Y4 = SLASH RANDOM NUMBERS FOR I = 1 1 50
    LET Y X = STACKED Y1 Y2 Y3 Y4
    .
    MULTIPLOT SCALE FACTOR 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    LABEL CASE ASIS
    TIC MARK LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    Y1LABEL DISPLACEMENT 15
    XLIMITS 1 4
    MAJOR XTIC MARK NUMBER 4
    MINOR XTIC MARK NUMBER 0
    X1TIC MARK LABEL FORMAT ALPHA
    X1TIC MARK LABEL CONTENT Normal Laplace Uniform Slash
    TIC MARK OFFSET UNITS DATA
    X1TIC MARK OFFSET 0.5 0.5
    CHARACTER X BLANK
    LINE BLANK SOLID
    .
    MULTIPLOT 2 2
    LET P = 1
    Y1LABEL L(1) Location
    LP LOCATION PLOT Y X
    LET P = 1.5
    Y1LABEL L(1.5) Location
    LP LOCATION PLOT Y X
    LET P = 2
    Y1LABEL L(2) Location
    LP LOCATION PLOT Y X
    LET P = 100
    Y1LABEL L(100) Location
    LP LOCATION PLOT Y X
    END OF MULTIPLOT
    .
    SET WRITE DECIMALS 4
    SET LET CROSS TABULATE COLLAPSE
    LET P = 1.5
    LET XGROUP = CROSS TABULATE GROUP ONE X
    LET YMEAN = CROSS TABULATE LP LOCATION Y X
    LET YSD   = CROSS TABULATE SD OF LP LOCATION Y X
    PRINT XGROUP YMEAN YSD
 
-----LPOCDF (LET)--------------------------------
 
LPOCDF
 
Name:
    LPOCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Lagrange-Poisson cumulative distribution
    function.
 
Description:
    The Lagrange Poisson distribution has probability mass
    function

       p(x;lambda,theta) = theta*(theta+x*lambda)**(x-1)*
                          EXP(-theta-x*lambda)/x!
                          x = 0, 1, ...;
                          0 < lambda < 1; theta > 0

    The cumulative distribution function is computed by summing
    the probability mass function.

Syntax:
    LET <y> = LPOCDF(<x>,<lambda>,<theta>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is a positive integer variable, number, or
               parameter;
          <lambda> is a number or parameter in the range (0,1)
               that specifies the first shape parameter;
          <theta> is a positive number or parameter that specifies
               the second shape parameter;
          <y> is a variable or a parameter where the computed
               Lagrange-Poisson cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LPOCDF(3,0.5,3)
    LET Y = LPOCDF(X1,0.3,2)
    PLOT LPOCDF(X,0.3,2) FOR X = 0  1  20
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LPOPDF                   = Compute the Lagrange-Poisson
                               probability mass function.
    LPOPPF                   = Compute the Lagrange-Poisson
                               percent point function.
    BTAPDF                   = Compute the Borel-Tanner probability
                               mass function.
    LOSPDF                   = Compute the lost games probability
                               mass function.
    POIPDF                   = Compute the Poisson probability
                               density function.
    HERPDF                   = Compute the Hermite probability
                               density function.
    BINPDF                   = Compute the binomial probability
                               density function.
    NBPDF                    = Compute the negative binomial
                               probability density function.
    GEOPDF                   = Compute the geometric probability
                               density function.

Reference:
    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 394-400.

    P. C. Consul (1989), "Generalized Poisson Distributions",
    Dekker, New York.

Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    title size 3
    tic label size 3
    label size 3
    legend size 3
    height 3
    multiplot scale factor 1.5
    x1label displacement 12
    y1label displacement 17
    .
    multiplot corner coordinates 0 0 100 95
    multiplot scale factor 2
    label case asis
    title case asis
    case asis
    tic offset units screen
    tic offset 3 3
    title displacement 2
    y1label Probability
    x1label X
    .
    ylimits 0 1
    major ytic mark number 6
    minor ytic mark number 3
    xlimits 0 20
    line blank
    spike on
    .
    multiplot 2 2
    .
    title Lambda = 0.3, Theta = 1
    plot lpocdf(x,0.3,1) for x = 1 1 20
    .
    title Lambda = 0.5, Theta = 1
    plot lpocdf(x,0.5,1) for x = 1 1 20
    .
    title Lambda = 0.7, Theta = 1
    plot lpocdf(x,0.7,1) for x = 1 1 20
    .
    title Lambda = 0.9, Theta = 1
    plot lpocdf(x,0.9,1) for x = 1 1 20
    .
    end of multiplot
    .
    justification center
    move 50 97
    text Cumulative Distribution for Lagrange-Poisson
 
-----LPOPDF (LET)--------------------------------
 
LPOPDF
 
Name:
    LPOPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Lagrange-Poisson probability mass function.
 
Description:
    Given a single queue with random arrival times of customers
    at constant rate l, constant service time beta, and k
    initial customers, the Borel-Tanner distribution is the
    distribution of the total number of customers served 
    before the queue vanishes.  The distribution is parameterized
    with lambda = l*beta.

    If the Borel-Tanner distribution is shifted to start at
    X = 0 and is reparameterized with

       theta  = k*lambda
       lambda = lambda

    the resulting distribution is referred to as the
    Lagrange-Poisson distribution (or the Consul generalized
    Poisson distribution).  This distribution has probability
    mass function

       p(x;lambda,theta) = theta*(theta+x*lambda)**(x-1)*
                          EXP(-theta-x*lambda)/x!
                          x = 0, 1, ...;
                          0 < lambda < 1; theta > 0

    Consul has investigated the case where lambda can be
    negative.  At the current time, Dataplot only supports
    positive values of lambda (and 0 < lambda < 1).

    The moments of the Lagrange-Poisson distribution are

        mean     = theta/(1-lambda)
        variance = theta/(1-lambda)**3
        skewness = (1+2*lambda)**2/(theta*(1-lambda))
        kurtosis = 3 + (1+8*lambda+6*lambda**2)/(theta*(1-lambda))
        
Syntax:
    LET <y> = LPOPDF(<x>,<lambda>,<theta>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is a positive integer variable, number, or
               parameter;
          <lambda> is a number or parameter in the range (0,1)
               that specifies the first shape parameter;
          <theta> is a positive number or parameter that specifies
               the second shape parameter;
          <y> is a variable or a parameter where the computed
               Lagrange-Poisson pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LPOPDF(3,0.5,3)
    LET Y = LPOPDF(X1,0.3,2)
    PLOT LPOPDF(X,0.3,2) FOR X = 0  1  20
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Note:
    For a number of commands utilizing the Lagrange-Poisson
    distribution, it is convenient to bin the data.  There
    are two basic ways of binning the data.

      1) For some commands (histograms, maximum likelihood
         estimation), bins with equal size widths are
         required.  This can be accomplished with the
         following commands:

            LET AMIN = MINIMUM Y
            LET AMAX = MAXIMUM Y
            LET AMIN2 = AMIN - 0.5
            LET AMAX2 = AMAX + 0.5
            CLASS MINIMUM AMIN2
            CLASS MAXIMUM AMAX2
            CLASS WIDTH 1
            LET Y2 X2 = BINNED

      2) For some commands, unequal width bins may be
         helpful.  In particular, for the chi-square goodness
         of fit, it is typically recommended that the minimum
         class frequency be at least 5.  In this case, it may
         be helpful to combine small frequencies in the tails.
         Unequal class width bins can be created with the
         commands

            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = INTEGER FREQUENCY TABLE Y

         If you already have equal width bins data, you can
         use the commands
         
            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = COMBINE FREQUENCY TABLE Y2 X2

         The MINSIZE parameter defines the minimum class
         frequency.  The default value is 5.

Note:
    You can generate Lagrange-Poisson random numbers, probability
    plots, and chi-square goodness of fit tests with the following
    commands:

       LET N = VALUE
       LET THETA = <value>
       LET LAMBDA = <value>
       LET Y = LAGRANGE POISSON RANDOM NUMBERS FOR I = 1 1 N

       LAGRANGE POISSON PROBABILITY PLOT Y
       LAGRANGE POISSON PROBABILITY PLOT Y2 X2
       LAGRANGE POISSON PROBABILITY PLOT Y3 XLOW XHIGH

       LAGRANGE POISSON CHI-SQUARE GOODNESS OF FIT Y
       LAGRANGE POISSON CHI-SQUARE GOODNESS OF FIT Y2 X2
       LAGRANGE POISSON CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    To obtain the method of moments, the method of zero frequency
    and the mean, and the weighted discrepancies estimates of
    lambda and theta, enter the command

        LAGRANGE POISSON MAXIMUM LIKELIHOOD Y
        LAGRANGE POISSON MAXIMUM LIKELIHOOD Y2 X2

    The method of moments estimates are

        thetahat  = SQRT(xbar**3/xvar)
        lambdahat = thetahat*[SQRT(xvar/xbar**3) - 1/xbar]

    with xbar and xvar denoting the sample mean and sample
    variance, respectively.

    The mean and zero frequency estimates are

        thetahat  = LOG(f0/N)
        lambdahat = 1 - thetahat/xbar

    with f0 denoting the zero frequency.

    The method of weighted discrepancies (a modification of
    the maximum likelihood estimates) are the solution to the
    following equations:

       SUM[i=1 to k][Y(i) - LPOPDF(X(i))]*
          [(X(i)*(THETA+LAMBDA)/(THETA*(THETA+LAMBDA*X(i))) - 1]
          = 0

       SUM[i=1 to k][Y(i) - LPOPDF(X(i))]*
          [(X(i)*(X(i)-1)/(THETA+LAMBDA*X(i))) - X(i)] = 0

    with k, X(i), and Y(i) denoting the number of classes,
    the class mid-point, and the class frequency, respectively.
    If you have raw data, Dataplot will automatically bin the
    data (you can use the CLASS LOWER, CLASS UPPER and CLASS
    WIDTH commands to specify the binning algorithm).

    You can generate estimates of lambda and theta based on the
    maximum ppcc value or the minimum chi-square goodness of fit
    with the commands

        LET THETA1 = <value>
        LET THETA2 = <value>
        LET LAMBDA1 = <value>
        LET LAMBDA2 = <value>
        LAGRANGE POISSON KS PLOT Y
        LAGRANGE POISSON KS PLOT Y2 X2
        LAGRANGE POISSON KS PLOT Y3 XLOW XHIGH
        LAGRANGE POISSON PPCC PLOT Y
        LAGRANGE POISSON PPCC PLOT Y2 X2
        LAGRANGE POISSON PPCC PLOT Y3 XLOW XHIGH

    The default values of lambda1 and lambda2 are 0.05 and
    0.95, respectively.  The default values of theta1 and theta2
    are 0.5 and 10, respectively.  Due to the discrete nature of
    the percent point function for discrete distributions, the
    ppcc plot will not be smooth.  For that reason, if there is
    sufficient sample size the KS PLOT (i.e., the minimum
    chi-square value) is typically preferred.  However, it may
    sometimes be useful to perform one iteration of the PPCC PLOT
    to obtain a rough idea of an appropriate neighborhood for the
    shape parameters since the minimum chi-square statistic can
    generate extremely large values for non-optimal values of the
    shape parameter.  Also, since the data is integer values, one
    of the binned forms is preferred for these commands.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LPOCDF                   = Compute the Lagrange-Poisson
                               cumulative distribution function.
    LPOPPF                   = Compute the Lagrange-Poisson
                               percent point function.
    BTAPDF                   = Compute the Borel-Tanner probability
                               mass function.
    LOSPDF                   = Compute the lost games probability
                               mass function.
    POIPDF                   = Compute the Poisson probability
                               mass function.
    HERPDF                   = Compute the Hermite probability
                               mass function.
    BINPDF                   = Compute the binomial probability
                               mass function.
    NBPDF                    = Compute the negative binomial
                               probability mass function.
    GEOPDF                   = Compute the geometric probability
                               mass function.
    INTEGER FREQUENCY TABLE  = Generate a frequency table at
                               integer values with unequal bins.
 
    COMBINE FREQUENCY TABLE  = Convert an equal width frequency
                               table to an unequal width frequency
                               table.
    KS PLOT                  = Generate a minimum chi-square plot.
    MAXIMUM LIKELIHOOD       = Perform maximum likelihood
                               estimation for a distribution.

Reference:
    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 394-400.

    Felix Famoye and Carl M. -S. Lee (1992), "Estimation of
    Generalized Poisson Distribution", Communications in
    Statistics -- Simulation, 21(1), pp. 173-188.

    P. C. Consul (1989), "Generalized Poisson Distributions",
    Dekker, New York.

Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    let theta = 0.4
    let lambda = 0.8
    let y = lagrange poisson random numbers for i = 1 1 500
    .
    let y3 xlow xhigh = integer frequency table y
    class lower 1.5
    class width 1
    let amax = maximum y
    let amax2 = amax + 0.5
    class upper amax2
    let y2 x2 = binned y
    .
    let k = minimum y
    lagrange poisson mle y
    relative histogram y2 x2
    limits freeze
    pre-erase off
    line color blue
    plot lpopdf(x,lambdawd,thetawd) for x = 0 1 amax
    limits
    pre-erase on
    line color black
    let lambda = lambdawd
    let theta = thetawd
    lagrange poisson chi-square goodness of fit y3 xlow xhigh
    case asis
    justification center
    move 50 97
    text Lambda = ^lambdawd, Theta = ^thetawd
    move 50 93
    text Minimum Chi-Square = ^minks, 95% CV = ^cutupp95
    .
    label case asis
    x1label Lambda
    y1label Minimum Chi-Square
    let theta1 = 0.1
    let theta2 = 5
    let lambda1 = 0.5
    let lambda2 = 0.95
    lagrange poisson ks plot y3 xlow xhigh
    let lambda = shape1
    let theta = shape2
    lagrange poisson chi-square goodness of fit y3 xlow xhigh
    case asis
    justification center
    move 50 97
    text Lambda = ^lambda, Theta = ^theta
    move 50 93
    text Minimum Chi-Square = ^minks, 95% CV = ^cutupp95
 
-----LPOPPF (LET)--------------------------------
 
LPOPPF
 
Name:
    LPOPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Lagrange-Poisson percent point function.
 
Description:
    The Lagrange Poisson distribution has probability mass
    function

       p(x;lambda,theta) = theta*(theta+x*lambda)**(x-1)*
                          EXP(-theta-x*lambda)/x!
                          x = 0, 1, ...;
                          0 < lambda < 1; theta > 0

    The cumulative distribution function is computed by summing
    the probability mass function.  The percent point function
    is the inverse of the cumulative distribution function and
    is obtained by computing the cumulative distribution function
    until the specified probability is reached.

Syntax:
    LET <y> = LPOPPF(<p>,<lambda>,<theta>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <p> is a positive integer variable, number, or
               parameter in the range (0,1);
          <lambda> is a number or parameter in the range (0,1)
               that specifies the first shape parameter;
          <theta> is a positive number or parameter that specifies
               the second shape parameter;
          <y> is a variable or a parameter where the computed
               Lagrange-Poisson ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LPOPPF(0.95,0.5,3)
    LET Y = LPOPPF(P,0.3,2)
    PLOT LPOPPF(P,0.3,2) FOR P = 0  0.01  0.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LPOCDF                   = Compute the Lagrange-Poisson
                               cumulative distribution function.
    LPOPDF                   = Compute the Lagrange-Poisson
                               probability mass function.
    BTAPDF                   = Compute the Borel-Tanner probability
                               mass function.
    LOSPDF                   = Compute the lost games probability
                               mass function.
    POIPDF                   = Compute the Poisson probability
                               density function.
    HERPDF                   = Compute the Hermite probability
                               density function.
    BINPDF                   = Compute the binomial probability
                               density function.
    NBPDF                    = Compute the negative binomial
                               probability density function.
    GEOPDF                   = Compute the geometric probability
                               density function.

Reference:
    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 394-400.

    P. C. Consul (1989), "Generalized Poisson Distributions",
    Dekker, New York.

Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    title size 3
    tic label size 3
    label size 3
    legend size 3
    height 3
    multiplot scale factor 1.5
    x1label displacement 12
    y1label displacement 17
    .
    multiplot corner coordinates 0 0 100 95
    multiplot scale factor 2
    label case asis
    title case asis
    case asis
    tic offset units screen
    tic offset 3 3
    title displacement 2
    x1label Probability
    y1label X
    .
    xlimits 0 1
    major xtic mark number 6
    minor xtic mark number 3
    .
    multiplot 2 2
    .
    title Lambda = 0.3, Theta = 1
    plot lpoppf(p,0.3,1) for p = 0  0.01  0.99
    .
    title Lambda = 0.5, Theta = 1
    plot lpoppf(p,0.5,1) for p = 0  0.01  0.99
    .
    title Lambda = 0.7, Theta = 1
    plot lpoppf(p,0.7,1) for p = 0  0.01  0.99
    .
    title Lambda = 0.9, Theta = 1
    plot lpoppf(p,0.9,1) for p = 0  0.01  0.99
    .
    end of multiplot
    .
    justification center
    move 50 97
    text Percent Point for Lagrange-Poisson
 
-----LSNCDF (LET)--------------------------------
 
LSNCDF
 
Name:
    LSNCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the log-skew-normal cumulative distribution function.
 
Description:
    The log-skew-normal distribution can be defined in terms of
    the skew-normal distribution as follows:

       f(x,lambda,sd)=(1/(sd*x))*SNPDF(LOG(x)/sd,lambda)
                                     0 < x, sd < infinity
                                     -infinity < lambda < infinity
 
    This is analogous to how the lognormal distribution is defined
    in terms of the normal distribution.  If lamba = 0, the
    log-skew-normal distribution reduces to the lognormal
    distributiion.
 
    The log-skew-normal cumulative distribution is computed
    by numerically integrating the probability density function.

    The standard skew-normal distribution can be generalized with
    location and scale parameters.

Syntax:
    LET <y> = LSNCDF(<x>,<lambda>,<sd>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <lambda> is a number of parameter that specifies the
              value of the first shape parameter;
          <sd> is a number of parameter that specifies the
              value of the second shape parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed log-skew-normal cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LSNCDF(3,1,1)
    LET A = LSNCDF(A1,LAMBDA,SD)
    LET X2 = LSNCDF(X1,0.5,1.5)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LSNPDF = Compute the log-skew-normal probability density
             function.
    LSNPPF = Compute the log-skew-normal percent point function.
    SNPDF  = Compute the skew-normal probability density function.
    NORPDF = Compute the normal density function.
    LGNPDF = Compute the lognormal density function.
    CHIPDF = Compute the chi probability density function.
    CHSPDF = Compute the chi-square probability density function.
    WEIPDF = Compute the Weibull probability density function.
 
Reference:
    "Log-Skew-Normal and Log-Skew-t Distributions as Models for
    Family Income Data", Azzalini, Dal Cappello, and Kotz,
    Journal of Income Distribution, Vol. 11, No. 3-4, 2003, pp. 12-20.

    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

    "Continuous Univariate Distributions: Volume I", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, p. 454.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    3/2004
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE LOG-SKEW-NORMAL: LAMBDA = 0
    PLOT LSNCDF(X,0) FOR X = 0.01  0.01  5
    TITLE LOG-SKEW-NORMAL: LAMBDA = 1
    PLOT LSNCDF(X,1) FOR X = 0.01  0.01  5
    TITLE LOG-SKEW-NORMAL: LAMBDA = 5
    PLOT LSNCDF(X,5) FOR X = 0.01  0.01  5
    TITLE LOG-SKEW-NORMAL: LAMBDA = 10
    PLOT LSNCDF(X,10) FOR X = 0.01  0.01  5
    END OF MULTIPLOT
 
-----LSNPDF (LET)--------------------------------
 
LSNPDF
 
Name:
    LSNPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the log-skew-normal probability density function.
 
Description:
    The log-skew-normal distribution can be defined in terms of
    the skew-normal distribution as follows:

       f(x,lambda,sd)=(1/(sd*x))*SNPDF(LOG(x)/sd,lambda)
                                     0 < x, sd < infinity
                                     -infinity < lambda < infinity
 
    This is analogous to how the lognormal distribution is defined
    in terms of the normal distribution.  If lamba = 0, the
    log-skew-normal distribution reduces to the lognormal
    distributiion.
 
    The standard skew-normal distribution can be generalized with
    location and scale parameters.

Syntax:
    LET <y> = LSNPDF(<x>,<lambda>,<sd>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <lambda> is a number of parameter that specifies the
              value of the first shape parameter;
          <sd> is a number of parameter that specifies the
              value of the second shape parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed log-skew-normal pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LSNPDF(3,1,1)
    LET A = LSNPDF(A1,LAMBDA,SD)
    LET X2 = LSNPDF(X1,0.5,1.5)
 
Note:
    Log-skew-normal random numbers, probability plots, and goodness
    of fit tests can be generated with the commands:

       LET LAMBDA = <value>
       LET SD = <value>
       LET Y = LOG SKEW NORMAL RANDOM NUMBERS FOR I = 1 1 N
       LOG SKEW NORMAL PROBABILITY PLOT Y
       LOG SKEW NORMAL KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       LOG SKEW NORMAL CHI-SQUARE GOODNESS OF FIT Y

    
    The following commands can be used to estimate the shape
    parameters for the log-skew-normal distribution:

       LET LAMBDA1 = <value>
       LET LAMBDA2 = <value>
       LET SD1 = <value>
       LET SD2 = <value>
       LOG SKEW NORMAL PPCC PLOT Y
       LOG SKEW NORMAL KS PLOT Y

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LSNCDF = Compute the log-skew-normal cumulative distribution
             function.
    LSNPPF = Compute the log-skew-normal percent point function.
    SNPDF  = Compute the skew-normal probability density function.
    NORPDF = Compute the normal density function.
    LGNPDF = Compute the lognormal density function.
    CHIPDF = Compute the chi probability density function.
    CHSPDF = Compute the chi-square probability density function.
    WEIPDF = Compute the Weibull probability density function.
 
Reference:
    "Log-Skew-Normal and Log-Skew-t Distributions as Models for
    Family Income Data", Azzalini, Dal Cappello, and Kotz,
    Journal of Income Distribution, Vol. 11, No. 3-4, 2003, pp. 12-20.

    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

    "Continuous Univariate Distributions: Volume I", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, p. 454.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    3/2004
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE LOG-SKEW-NORMAL: LAMBDA = 0
    PLOT LSNPDF(X,0) FOR X = 0.01  0.01  5
    TITLE LOG-SKEW-NORMAL: LAMBDA = 1
    PLOT LSNPDF(X,1) FOR X = 0.01  0.01  5
    TITLE LOG-SKEW-NORMAL: LAMBDA = 5
    PLOT LSNPDF(X,5) FOR X = 0.01  0.01  5
    TITLE LOG-SKEW-NORMAL: LAMBDA = 10
    PLOT LSNPDF(X,10) FOR X = 0.01  0.01  5
    END OF MULTIPLOT
 
-----LSNPPF (LET)--------------------------------
 
LSNPPF
 
Name:
    LSNPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the log-skew-normal percent point function.
 
Description:
    The log-skew-normal distribution can be defined in terms of
    the skew-normal distribution as follows:

       f(x,lambda,sd)=(1/(sd*x))*SNPDF(LOG(x)/sd,lambda)
                                     0 < x, sd < infinity
                                     -infinity < lambda < infinity
 
    This is analogous to how the lognormal distribution is defined
    in terms of the normal distribution.  If lamba = 0, the
    log-skew-normal distribution reduces to the lognormal
    distributiion.
 
    The log-skew-normal percent point is computed by numerically
    inverting the cumulative distribution function using a
    bisection method.

    The standard skew-normal distribution can be generalized with
    location and scale parameters.

Syntax:
    LET <y> = LSNPPF(<p>,<lambda>,<sd>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, parameter, or number in the range (0,1);
          <lambda> is a number of parameter that specifies the
              value of the first shape parameter;
          <sd> is a number of parameter that specifies the
              value of the second shape parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed log-skew-normal ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LSNPPF(0.95,1,1)
    LET A = LSNPPF(P,LAMBDA,SD)
    PLOT LSNPPF(P,LAMBDA,SD)  FOR P = 0.01  0.01 0.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LSNCDF = Compute the log-skew-normal cumulative distribution
             function.
    LSNPDF = Compute the log-skew-normal probability density
             function.
    SNPDF  = Compute the skew-normal probability density function.
    NORPDF = Compute the normal density function.
    LGNPDF = Compute the lognormal density function.
    CHIPDF = Compute the chi probability density function.
    CHSPDF = Compute the chi-square probability density function.
    WEIPDF = Compute the Weibull probability density function.
 
Reference:
    "Log-Skew-Normal and Log-Skew-t Distributions as Models for
    Family Income Data", Azzalini, Dal Cappello, and Kotz,
    Journal of Income Distribution, Vol. 11, No. 3-4, 2003, pp. 12-20.

    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

    "Continuous Univariate Distributions: Volume I", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, p. 454.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    3/2004
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE LOG-SKEW-NORMAL: LAMBDA = 0
    PLOT LSNPPF(P,0,1) FOR P = 0.01  0.01  0.99
    TITLE LOG-SKEW-NORMAL: LAMBDA = 1
    PLOT LSNPPF(P,1,1) FOR P = 0.01  0.01  0.99
    TITLE LOG-SKEW-NORMAL: LAMBDA = 5
    PLOT LSNPPF(P,5,1) FOR P = 0.01  0.01  0.99
    TITLE LOG-SKEW-NORMAL: LAMBDA = 10
    PLOT LSNPPF(P,10,1) FOR P = 0.01  0.01  0.99
    END OF MULTIPLOT
 
-----LSTCDF (LET)--------------------------------
 
LSTCDF
 
Name:
    LSTCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the log-skew-t cumulative distribution function.
 
Description:
    The log-skew-t distribution has the following probability density
    function:

       f(x,nu,lambda,sd)=(1/(sd*x))**STPDF(LOG(x)/sd,nu,lambda,sd)
                                     x, lambda > 0
 
    with STPDF denoting the skew-t distribution (enter HELP STPDF
    for details).

    The cumulative distribution function is computed by numerically
    integrating the log-skew-t probability density function.

    For lambda = 0, the log-skew-t reduces to a log-t distribution.
 
    The standard log-skew-t distribution can be generalized with
    location and scale parameters in the usual way.

Syntax:
    LET <y> = LSTCDF(<x>,<nu>,<lambda>,<sd>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <nu> is a number of parameter that specifies the
              value of the degrees of freedom shape parameter;
          <lambda> is a number of parameter that specifies the
              value of the skewness shape parameter;
          <sd> is a number or parameter that specifies the
              value of the standard deviation parameter;
          <loc> is a number or parameter that specifies the
              value of the location parameter;
          <scale> is a number or parameter that specifies the
              value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed log-skew-t cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LSTCDF(3,5,1,2)
    LET A = LSTCDF(A1,DF,LAMBDA,2)
    PLOT LSTCDF(X,NU,LAMBDA,SD) FOR X = 0.01 0.01 10
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LSTPDF = Compute the log-skew-t probability density function.
    LSTPPF = Compute the log-skew-t percent point function.
    STPDF  = Compute the skew-t probability density function.
    SNPDF  = Compute the skew-normal probability density function.
    TPDF   = Compute the t probability density function.
    FTPDF  = Compute the folded t probability density function.
    NORPDF = Compute the normal density function.
    CHSPDF = Compute the chi-square probability density function.
 
Reference:
    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

    "Log-Skew-Normal and Log-Skew-t Distributions as Models for
    Family Income Data", Azzalini, Dal Cappello, and Kotz,
    Journal of Income Distribution, Vol. 11, No. 3-4, 2003, pp. 12-20.

Applications:
    Distributional Modeling
 
Implementation Date:
    1/2004
 
Program:
    Y1LABEL Probability
    X1LABEL X
    LABEL CASE ASIS
    X1LABEL DISPLACEMENT 12
    Y1LABEL DISPLACEMENT 12
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    LET SD = 1
    TITLE LOG-SKEW-T (NU=3, SD=1): LAMBDA = 0
    PLOT LSTCDF(X,3,0,SD) FOR X = 0.01  0.01  5
    TITLE LOG-SKEW-T (NU=3, SD=1): LAMBDA = 1
    PLOT LSTCDF(X,3,1,SD) FOR X = 0.01  0.01  5
    TITLE LOG-SKEW-T (NU=3, SD=1): LAMBDA = 5
    PLOT LSTCDF(X,3,5,SD) FOR X = 0.01  0.01  5
    TITLE LOG-SKEW-T (NU=3, SD=1): LAMBDA = 10
    PLOT LSTCDF(X,3,10,SD) FOR X = 0.01  0.01  5
    END OF MULTIPLOT
 
-----LSTPDF (LET)--------------------------------
 
LSTPDF
 
Name:
    LSTPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the log-skew-t probability density function.
 
Description:
    The log-skew-t distribution has the following probability density
    function:

       f(x,nu,lambda,sd)=(1/(sd*x))**STPDF(LOG(x)/sd,nu,lambda,sd)
                                     x, lambda > 0
 
    with STPDF denoting the skew-t distribution (enter HELP STPDF
    for details).

    For lambda = 0, the log-skew-t reduces to a log-t distribution.
 
    The standard log-skew-t distribution can be generalized with
    location and scale parameters.

Syntax:
    LET <y> = LSTPDF(<x>,<nu>,<lambda>,<sd>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <nu> is a number of parameter that specifies the
              value of the degrees of freedom shape parameter;
          <lambda> is a number of parameter that specifies the
              value of the skewness shape parameter;
          <sd> is a number or parameter that specifies the
              value of the standard deviation parameter;
          <loc> is a number or parameter that specifies the
              value of the location parameter;
          <scale> is a number or parameter that specifies the
              value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed log-skew-t pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LSTPDF(3,5,1,2)
    LET A = LSTPDF(A1,DF,LAMBDA,2)
    PLOT LSTPDF(X,NU,LAMBDA,SD) FOR X = 0.01 0.01 10
 
Note:
    Log-skew-t random numbers, probability plots, and goodness
    of fit tests can be generated with the commands:

       LET NU = <value>
       LET LAMBDA = <value>
       LET SD = <value>
       LET Y = LOG SKEW T RANDOM NUMBERS FOR I = 1 1 N
       LOG SKEW T PROBABILITY PLOT Y
       LOG SKEW T KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       LOG SKEW T CHI-SQUARE GOODNESS OF FIT Y

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LSTCDF = Compute the log-skew-t cumulative distribution function.
    LSTPPF = Compute the log-skew-t percent point function.
    STPDF  = Compute the skew-t probability density function.
    SNPDF  = Compute the skew-normal probability density function.
    TPDF   = Compute the t probability density function.
    FTPDF  = Compute the folded t probability density function.
    NORPDF = Compute the normal density function.
    CHSPDF = Compute the chi-square probability density function.
 
Reference:
    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

    "Log-Skew-Normal and Log-Skew-t Distributions as Models for
    Family Income Data", Azzalini, Dal Cappello, and Kotz,
    Journal of Income Distribution, Vol. 11, No. 3-4, 2003, pp. 12-20.

Applications:
    Distributional Modeling
 
Implementation Date:
    1/2004
 
Program:
    Y1LABEL Probability
    X1LABEL X
    LABEL CASE ASIS
    X1LABEL DISPLACEMENT 12
    Y1LABEL DISPLACEMENT 12
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    LET SD = 1
    TITLE LOG-SKEW-T (NU=3, SD=1): LAMBDA = 0
    PLOT LSTPDF(X,3,0,SD) FOR X = 0.01  0.01  5
    TITLE LOG-SKEW-T (NU=3, SD=1): LAMBDA = 1
    PLOT LSTPDF(X,3,1,SD) FOR X = 0.01  0.01  5
    TITLE LOG-SKEW-T (NU=3, SD=1): LAMBDA = 5
    PLOT LSTPDF(X,3,5,SD) FOR X = 0.01  0.01  5
    TITLE LOG-SKEW-T (NU=3, SD=1): LAMBDA = 10
    PLOT LSTPDF(X,3,10,SD) FOR X = 0.01  0.01  5
    END OF MULTIPLOT
 
-----LSTPPF (LET)--------------------------------
 
LSTPPF
 
Name:
    LSTPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the log-skew-t percent point function.
 
Description:
    The log-skew-t distribution has the following probability
    density function:

       f(x,nu,lambda,sd)=(1/(sd*x))**STPDF(LOG(x)/sd,nu,lambda,sd)
                                     x, lambda > 0
 
    with STPDF denoting the skew-t distribution (enter HELP STPDF
    for details).

    The percent point function is computed by numerically inverting
    the cumulative distribution function using a bisection mehtod.
    The cumulative distribution function is computed by numerically
    integrating the log-skew-t probability density function.

    For lambda = 0, the log-skew-t reduces to a log-t distribution.
 
    The standard log-skew-t distribution can be generalized with
    location and scale parameters in the usual way.

Syntax:
    LET <y> = LSTPPF(<p>,<nu>,<lambda>,<sd>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, number or a parameter in the range
               (0,1];
          <nu> is a number of parameter that specifies the
              value of the degrees of freedom shape parameter;
          <lambda> is a number of parameter that specifies the
              value of the skewness shape parameter;
          <sd> is a number or parameter that specifies the
              value of the standard deviation parameter;
          <loc> is a number or parameter that specifies the
              value of the location parameter;
          <scale> is a number or parameter that specifies the
              value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed log-skew-t ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LSTPPF(0.95,5,1,2)
    LET A = LSTPPF(P,DF,LAMBDA,2)
    PLOT LSTPPF(P,NU,LAMBDA,SD) FOR P = 0.01 0.01 0.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LSTCDF = Compute the log-skew-t cumulative distribution function.
    LSTPDF = Compute the log-skew-t probability density function.
    STPDF  = Compute the skew-t probability density function.
    SNPDF  = Compute the skew-normal probability density function.
    TPDF   = Compute the t probability density function.
    FTPDF  = Compute the folded t probability density function.
    NORPDF = Compute the normal density function.
    CHSPDF = Compute the chi-square probability density function.
 
Reference:
    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

    "Log-Skew-Normal and Log-Skew-t Distributions as Models for
    Family Income Data", Azzalini, Dal Cappello, and Kotz,
    Journal of Income Distribution, Vol. 11, No. 3-4, 2003, pp. 12-20.

Applications:
    Distributional Modeling
 
Implementation Date:
    1/2004
 
Program:
    X1LABEL Probability
    Y1LABEL X
    LABEL CASE ASIS
    X1LABEL DISPLACEMENT 12
    Y1LABEL DISPLACEMENT 12
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    LET SD = 1
    TITLE LOG-SKEW-T (NU=3, SD=1): LAMBDA = 0
    PLOT LSTPPF(P,3,0,SD) FOR P = 0.01 0.01 0.99
    TITLE LOG-SKEW-T (NU=3, SD=1): LAMBDA = 1
    PLOT LSTPPF(P,3,1,SD) FOR P = 0.01 0.01 0.99
    TITLE LOG-SKEW-T (NU=3, SD=1): LAMBDA = 5
    PLOT LSTPPF(P,3,5,SD) FOR P = 0.01 0.01 0.99
    TITLE LOG-SKEW-T (NU=3, SD=1): LAMBDA = 10
    PLOT LSTPPF(P,3,10,SD) FOR P = 0.01 0.01 0.99
    END OF MULTIPLOT
 
-----LT (LET)--------------------------------
 
LT
 
Name:
    LT (LET)
 
Type:
    Library Function
 
Purpose:
    Return a 1 if the first number is less than the second and return a
    0 otherwise.

Description:
    SUBSET clauses do not support syntax like the following:

         LET Y = Y1  SUBSET Y1 > Y2
         LET Y = Y1  SUBSET Y1 >= Y2
         LET Y = Y1  SUBSET Y1 < Y2
         LET Y = Y1  SUBSET Y1 <= Y2
         LET Y = Y1  SUBSET Y1 = Y2
         LET Y = Y1  SUBSET Y1 <> Y2

    where Y1 and Y2 are both variables.

    This command is most typically used to create a tag variable
    that can be used on subsequent SUBSET clauses.  For example,
    suppose that Y1 and Y2 are two previously created variables and
    we want to sum the values of Y1 that are less than the corresponding
    rows of Y2.

        LET TAG = LT(Y1,Y2)
        LET Y1SUM = SUM Y1 SUBSET TAG = 1
 
Syntax:
    LET <tag> = LT(<y1>,<y2>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter;
          <tag> is a variable or a parameter (depending on what <y1> and
               <y2> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET TAG = LT(Y1,Y2)
    LET A = LT(3,2)

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LE       = Return 1 where the first number is less than or
               equal to the second number and zero otherwise.
    GT       = Return 1 where the first number is greater than the second
               number and 0 otherwise.
    GE       = Return 1 where the first number is greater than or
               equal to the second number and 0 otherwise.
    EQ       = Return 1 where the first number is equal to the second
               number and zero otherwise.
    NE       = Return 1 where the first number is not equal to the second
               number and zero otherwise.
 
Applications:
    Data Management
 
Implementation Date:
    2021/06
 
Program:
    SKIP 25
    READ NATR332.DAT Y1 Y2
    LET TAG = GT(Y1,Y2)
    LET NGT = SUM TAG SUBSET TAG = 1
    LET TAG = LT(Y1,Y2)
    LET NLT = SUM TAG SUBSET TAG = 1
    LET TAG = EQ(Y1,Y2)
    LET NEQ = SUM TAG SUBSET TAG = 1
    PRINT "Number of rows where Y1 > Y2:   ^NGT"
    PRINT "Number of rows where Y1 < Y2:   ^NLT"
    PRINT "Number of rows where Y1 = Y2:   ^NEQ"
 
-----LV (LET)--------------------------------
 
LV
 
Name:
    LV (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the modified Struve function.
 
Description:
    The modified Struve function can be expressed as:

        L(x,v) = SUM[(x/2)**(2*k+v+1)/(GAMMA(k+3/2)*GAMMA(v+k+3/2)]

    where v is the order of the modified Struve function, GAMMA is the
    gamma function, and the summation is over k from 0 to
    positive infinity.

    Dataplot computes this function using the STVL0, STVL1, and
    STVLV routines from "Computation of Special Functions" (see
    the Reference section below).
 
Syntax 1:
    LET <y> = LV(<x>,<v>)    <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, variable or parameter;
          <v> is a number, parameter, or variable;
          <y> is a variable or a parameter (depending on what <x> 
               and <v> are) where the computed modified Struve
               function values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Dataplot supports the modified Struve function for non-negative
    real x and for orders between -8.5 and 12.5.  This syntax is
    used for arbitrary order.

Syntax 2:
    LET <y> = H0(<x>)    <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, variable or parameter;
          <y> is a variable or a parameter (depending on what <x> 
               is) where the computed modified Struve function
               values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Dataplot supports the modified Struve function for non-negative
    real x.  This syntax is used for the modified Struve function
    of order 0.

Syntax 3:
    LET <y> = H1(<x>)    <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, variable or parameter;
          <y> is a variable or a parameter (depending on what <x> 
               is) where the computed modified Struve function
               values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Dataplot supports the modified Struve function for non-negative
    real x.  This syntax is used for the modified Struve function
    of order 1.

Examples:
    LET A = LV(2.3,1)
    LET A = LV(X,A1)
    LET X2 = LV(X1,4) FOR X1 = 0.1 0.1 3.0
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    HV         = Compute the Struve function.
    BESSJN     = Compute the Bessel function of the first kind.
    BESSYN     = Compute the Bessel function of the second kind.
    BESSIN     = Compute the modified Bessel function.
    BESSKN     = Compute the modified Bessel function of the third
                 kind.
 
Reference:
    "Computation of Special Functions", Shanjie Zhang and Jianming
    Jin, John Wiley and Sons, 1996, chapter 11.
 
    "AMS 55: Handbook of Mathematical Functions", Abramowitz and
    Stegun, Eds., Washington, DC, National Bureau of Standards,
    1964.

Applications:
    Special Functions
 
Implementation Date:
    1997/12
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    TITLE ORDER 0
    PLOT LV(X,0) FOR X = 0 0.01 10
    TITLE ORDER 1
    PLOT LV(X,1) FOR X = 0 0.01 10
    TITLE ORDER 2
    PLOT LV(X,2) FOR X = 0 0.01 10
    TITLE ORDER 3
    PLOT LV(X,3) FOR X = 0 0.01 10
    END OF MULTIPLOT
    MOVE 50 97
    CENTER JUSTIFICATION
    TEXT MODIFIED STRUVE FUNCTIONS
 
--------------------------------------------------------------
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 








-------------------------  *M*  ZZZZZ--------------------

-----MACHINE CONSTANTS (SET)--------------------------------------------
 
MACHINE CONSTANTS
 
Name:
    MACHINE CONSTANTS (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Probe for values pertaining to certain machine constants used by
    Dataplot.
 
Description:
    The values for certain machine constants used by Dataplot can be
    extracted using the PROBE command.  Note that these machine constants
    cannot be modified with the SET command.  These are specific to the
    platform that you are running Dataplot on and are typically set when
    Dataplot is compiled.

    The list of available machine constants is

        CPUMIN  - The value for the smallest real number.
        CPUMAX  - The value for the largest real number.
        NUMBPC  - The number of bits per character.
        NUMCPW  - The number of characters per word.
        NUMBPW  - The number of bits per word.

Syntax:
    PROBE <MACHINE CONSTANT>
    where <MACHINE CONSTANT> is one of the names listed above.
 
Examples:
    PROBE CPUMIN
    PROBE CPUMAX

Note:
    It is sometimes useful to define a parameter to denote machine
    infinity or machine negative infinity.  This can be done as follows

       PROBE CPUMIN
       LET CPUMIN = PROBEVAL
       PROBE CPUMAX
       LET CPUMAX = PROBEVAL

    The parameters CPUMIN and CPUMAX can then be used as parameters in
    subsequent Dataplot commands.  For example, these value can be useful
    for defining missing values or for defining lower or upper limits on
    SUBSET clauses.

Default:
    The defaults are set for the specific platform when Dataplot is
    compiled.
 
Synonyms:
    None
 
Related Commands:
    BUG SWITCHES       = Turn debugging switches on or off.
    WORKSPACE SWITCHES = Return the values pertaining to the Dataplot
                         workspace.

Applications:
    Machine Constants
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----MACRO SUBSTITUTION CHARACTER----------------------------------
 
MACRO SUBSTITUTION CHARACTER
 
Name:
    MACRO SUBSTITUTION CHARACTER
 
Type:
    Support Command
 
Purpose:
    Specify the character to use in macros to signify an
    argument to the macro.
 
Description:
    You can now pass arguments to macros.  Recall that Dataplot
    macros are simply ASCII files containing Dataplot commands
    (i.e., there is no compilation of macros).

    To pass arguments to a macro, do something like

        CALL SAMPLE.DP  arg1  arg2 arg3

    Up tp 10 arguments may be passed (although limits on command
    line lengths still apply).  Arguments containing spaces or
    hyphens should be enclosed in quotes.  The character limit for
    a single argument is 40 characters.

    In the SAMPLE.DP macro, if a $1 is encountered, it will be
    replaced with "arg1", if a $2 is encountered, it will be
    replaced with "arg2" and so on.  A $0 will substitute the
    number of arguments given on the CALL command.

    This substitution will only occur if a command line is contained
    within a macro (i.e., if no macro is active, the "$" will not
    signal any substitution and it will remain in the command line
    as given).

    Dataplot currently only supports one level of argument
    substitition for macros.  That is, the values of the macro
    arguments (i.e., the $1, $2, etc.) will contain the values
    given by the most recent CALL command that specified at least
    one argument.  If you need to nest CALL commands with macro
    arguments, the recommended work around is to have the
    higher level macro extract any macro arguments passed to it
    into temporary variables or strings before calling any other
    macros.  For example, supposse SAMPLE.DP needs to call
    SAMPLE2.DP with arguments.  You could do something like
    the following in SAMPLE.DP:

        .  Start of SAMPLE.DP macro
        let string zzzzs1 = $1
        let string zzzzs2 = $2
        let string zzzzs3 = $3
            ...
        call sample2.dp  newarg1  newarg2

    The default character for argument substitution is the
    "$".  To use a different character, enter the command

    The MACRO SUBSTITUTION CHARACTER command allows you to specify
    a character other than "$" to signify argument substitution.

Syntax:
    MACRO SUBSTITUTION CHARACTER  <char>
    where <char> is the character to use as the macro substitution
                 character.
 
Examples:
    MACRO SUBSTITUTION CHARACTER @
    MACRO SUBSTITUTION CHARACTER $
 
Note:
    Substitutions for the value of a parameter or a string
    (signified by a "^") are performed before the substitutions
    for a macro argument.  Both of these substitutions are
    performed before the command line is interpreted.

Note:
    By default, quotes are stripped off the command line arguments.  For
    example, you can have the file SUB.DP that contains

        print "Arg 1: $1"
        print "Arg 2: $2"

    If you initiate this macro with the command

        call sub.dp  "arg 1"  "arg 2"

    then the sub.dp macro will print

        Arg 1: arg 1
        Arg 2: arg 2

    If you enter

        set macro quote strip off
        call sub.dp  "arg 1"  "arg 2"

    then the sub.dp macro will print

        Arg 1: "arg 1"
        Arg 2: "arg 2"

    That is, the quotes enclosing the arguments will not be stripped off.
    This may be useful if you want the called macro to distinguish between
    arguments that denote literal text from those that denote the name of
    a previously defined string or parameter.  That is, arguments to be
    interpreted as literal text will be enclosed in quotes and those that
    denote previously defined parameters or strings will not be enclosed
    in quotes.  Note that in this case it is the responsibility of the
    called macro to decide how to interpret the arguments and to strip off
    the enclosing quotes if needed.

    To restore the default of stripping off the enclosing quotes, enter

        set macro quote strip off

Note:
    The command line arguments remain defined until another macro is called
    with command line arguments.  There may be times you want to clear the
    currently defined command line arguments.  You can do this in either of
    the following two ways.

    The first way is to call a macro with NULL as the first argument.
    This clears the command line argument list and sets the number of
    arguments to 0 (i.e., $0 will be 0).

    The second way is to enter the comamnd

         RESET COMMAND LINE ARGUMENTS

Note:
    The 2016/10 version of Dataplot added support for named command
    line arguments.  For example,

        call macro.dp  y=y1 x=x2 "title = Scatter Plot for Sample Data"

    Then in "macro.dp", substitutions would occur for $y, $x, and
    $title.

    Analogous to how $0 returns the number of command line arguments,
    the sequence $00 returns the number of named command line arguments.

    If a particular argument has spaces or hypens, it should be enclosed
    in quotes.  The "<name>=" should be enclosed in quotes.  That is, use

         call macro.dp "title=Scatter Plot for Sample Data"

    rather than

         call macro.dp title="Scatter Plot for Sample Data"

    You may include one or more spaces on either side of the "="
    sign.  The use of spaces around the "=" sign is optional.

    The use of named arguments can be useful when you have multiple
    arguments and you would like one or more of the arguments to be
    optional (i.e., a default value will be used if the argument is
    not provided).

    The use of ordered arguments ($1, $2, etc.) and named arguments
    (e.g., $y, $title, etc.) can be mixed.  For example, $4 in the
    called subroutine will substitute the fourth argument in the
    list regardless of whether it is a named argument in the calling
    macro.

    It is up to the called macro to support either orded arguments only,
    named arguments only, or both orded and named arguments.

    Although ordered arguments and named arguments can be mixed, the
    called macro will typically be simpler if they are not mixed.

    Arguments names should be 8 characters or fewer.  They should not
    start with a numeric value (e.g.,  1Y should not be used) to avoid
    ambiguity with ordered arguments.  That is, $1Y will actually
    substitute for "$1" rather than "$1Y.

Note:
    The 2018/04 version of Dataplot made several enhancements in how
    arguments can be passed.

    1. The argument list can be enclosed in parentheis.  Note that the
       use of parenthesis is optional.  You can optionally include one or
       more spaces between the arguments and the parenthesis.

    2. For named arguments with quoted values, you can include only the
       value of named argument in quotes.  That is,

            file="c:\my data\test.txt"

       Previously, this had to be entered as

            "file=c:\my data\test.txt"

       If the argument name is not inside the quotes, then you cannot have
       spaces around the equal sign.  If the argument name is inside the
       quotes, then spaces around the equal sign are optional.

    3. Commas can optionally be used as an argument delimiter.  You can
       mix the use of spaces and commas as the delimiter.  For example

           call test.dp  zx=x,zy=y  zz=z

       Although this is allowed, it is recommended that if you use commas
       that you do so consistently.  That is,

           call test.dp  zx=x,zy=y,zz=z

    4. Previously, calling a macro without arguments would clear the
       current command arguments.  This was changed so that a CALL
       command without arguments will not modify the current command
       list arguments.


    Specifically, the following are all acceptable ways to enter the
    same argument list.

    Previously supported:

        call test.dp  y "for i = 1 1 50" x
        call test.dp  zy=y "target=for i = 1 1 50" x

    New formats:

        call test.dp  y,"for i = 1 1 50",x
        call test.dp  zy=y,"target=for i = 1 1 50",x
        call test.dp  (y,"for i = 1 1 50",x)
        call test.dp  ( y, "for i = 1 1 50",x )
        call test.dp  (zy=y, "target=for i = 1 1 50",zx=x)
        call test.dp  ( zy=y, "target=for i = 1 1 50",zx=x )
        call test.dp  (zy=y, target="for i = 1 1 50",zx=x)
        call test.dp  ( zy=y, target="for i = 1 1 50",zx=x )

    The choice of which syntax to use is primarily a matter of personal
    preference.

Note:
    The 2016/10 version added the command

        LIST COMMAND LINE ARGUMENTS

    This will list the currently defined ordered command line
    arguments and then list the currently defined named arguments.

Note:
    The 2016/10 version added the command

        PROBE COMMAND LINE ARGUMENT <name>

    where <name> is the command line argument name you are checking
    for.  If <name> is found in the current list of command line
    arguments, a value of 1 is returned.  If <name> is not found, a
    value of 0 is returned.  This provides a way for the called macro
    to check if a specific named argument was given.  For example,

        PROBE COMMAND LINE ARGUMENT Y
        IF PROBEVAL = 1
           LET Y = $Y
        ELSE
           PRINT "The Y argument was not specified"
        ENDIF

    Alternatively, you can use

        IF COMMAND LINE ARGUMENT <name> EXISTS

    So the above example would be

        IF COMMAND LINE ARGUMENT Y EXISTS
           LET Y = $Y
        ELSE
           PRINT "The Y argument was not specified"
        ENDIF

Default:
    The default macro substitution character is $  .

Synonyms:
    None
 
Related Commands:
    CALL                  = Execute the commands stored in a file.
    SUBSTITUTE CHARACTER  = Define the character that specifies the
                            substitution of the value of a parameter
                            or a string in a command line.
    TERMINATOR CHARACTER  = Define the character that terminates a
                            command.
    CONTINUE CHARACTER    = Define the character that specifies that
                            a command is continued onto the next line.
 
Applications:
    Macros
 
Implementation Date:
    2005/11
    2016/05: Added SET MACRO QUOTE STRIP command
    2016/09: Added NULL option and RESET COMMAND LINE ARGUMENTS
    2016/10: Support for named arguments
    2018/04: Support for additional methods for passing arguments
 
Program:
    MACRO SUBSTITUTION CHARACTER @
    LET Y = NORMAL RAND NUMBERS FOR I = 1 1 100
    CALL HIST.DP  "Title for Sample Plot" Y

    where HIST.DP contains the lines

    TITLE @1
    HISTOGRAM @2
 
-----MACROS-------------------------------------------------------
 
MACROS
 
Name:
    MACROS
 
Type:
    Keyword
 
Purpose:
    Symbolic name for DATAPLOT's macros file.  It is used with the
    SEARCH and LIST commands.
 
Description:
    The DATAPLOT distribution files come with a large number of on-line
    macro files.  These files are stored in the DATAPLOT directory (the
    same directory where the on-line help files are stored).  These
    files can be executed with the CALL command and examined with the
    LIST command without specifying the full path name.  DATAPLOT's
    macros file contains an alphabetic list of the DATAPLOT macro files
    with a brief (one line) description.  It is a subset of the
    dictionary file.  The dictionary file also includes commands,
    functions, program files, and data files.
 
Syntax:
    None
 
Examples:
    SEARCH MACROS 3DPLOT
    LIST MACROS FOR I = 1 1 35
 
Note:
    The MACROS file is stored in the DATAPLOT directory.  It has the
    name MACROS (or macros for Unix systems).  The exact file name and
    the directory where it is stored can vary depending on the
    installation (see your local DATAPLOT implementor to find the exact
    name on your system).
 
Note:
    If DATAPLOT is unable to open the macros file, it is most likely
    because the directory name is not specified correctly in the local
    DATAPLOT code.  See your local DATAPLOT implementor to have this
    corrected.  If you try to list or execute one of the listed macros
    (with a CALL or LIST command) and DATAPLOT is not able to open the
    file, contact your local DATAPLOT implementor.  The DATAPLOT
    routine DPOPFI probably needs to be modified.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SEARCH        = Search a file for a string.
    LIST          = Lists the contents of a file.
    CALL          = Execute DATAPLOT commands stored in a file.
    DIRECTORY     = Symbolic name for DATAPLOT's directory file.
    DICTIONAY     = Symbolic name for DATAPLOT's dictionary file.
    DATASETS      = Symbolic name for DATAPLOT's data sets file.
    DESIGNS       = Symbolic name for DATAPLOT's design of experiments
                    file.
    SYNTAX        = Symbolic name for DATAPLOT's syntax file.
    COMMANDS      = Symbolic name for DATAPLOT's commands file.
    PROGRAMS      = Symbolic name for DATAPLOT's programs file.
    DISTRIBU      = Symbolic name for DATAPLOT's distributions file.
    FUNCTION      = Symbolic name for DATAPLOT's function file.
 
Applications:
    XX
 
Implementation Date:
    1993/12
 
Program:
    XX
 
-----MAD TO MEDIAN (LET)------------------------------
 
MAD TO MEDIAN
 
Name:
    MAD TO MEDIAN (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the coefficient of dispersion based on the median
    absolute deviation (AAD) and the median of a variable.
 
Description:
    There are a number of definitions for the coefficient of dispersion.
    Dataplot uses the definition based on the ratio of the mean
    absolute deviation (AAD) to the median.  An alternative definition is
    based on the median absoulte deviation from the median (MAD)  and the
    median.  Specifically,

         d = MAD/xmedian

    where MAD and xmedian denote the median absolute deviation from the
    median and the median, respectively.  This is the statistic computed
    by this command.

    This statistic is a robust alternative to the coefficient of
    variation.

Syntax 1:
    LET <par> = MAD TO MEDIAN <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <par> is a parameter where the MAD to median value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Syntax 2:
    LET <par> = DIFFERENCE OF MAD TO MEDIAN <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the first response variable;
          <par> is a parameter where the difference of the MAD to median
               values is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET D = MAD TO MEDIAN Y1
    LET D = MAD TO MEDIAN Y1  SUBSET TAG > 2

    LET D = DIFFERENCE OF MAD TO MEDIAN Y1 Y2

Note:
    The 2017/12 version of Dataplot changed the definition for the
    coefficient of dispersion to use the mean absolute difference from
    the median rather than the median absolute difference from the
    median.  The name of this command was changed from AAD TO MEDIAN
    to MAD TO MEDIAN and the computation was changed to use the MAD
    rather than the AAD.  That is, the COEFFICIENT OF DISPERSION
    command was modified to compute what was previously 

    This change was made to reflect the more common

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    COEFFICIENT OF DISPERSION  = Compute the coefficient of dispersion
                                 of a variable.
    QUARTILE COEF OF DISP      = Compute the quartile coefficient of
                                 dispersion of a variable.
    COEFFICIENT OF VARIATION   = Compute the coefficient of variation.
    RELATIVE STAND DEVI        = Compute the relative standard
                                 deviation of a variable.
    MEDIAN                     = Compute the median of a variable.
    MEAN                       = Compute the mean of a variable.
    AVERAGE ABSOLUTE DEVIATION = Compute the average absolute deviation
                                 of a variable.
    STANDARD DEVIATION         = Compute the standard deviation of a
                                 variable.
 
Applications:
    Data Analysis
 
Implementation Date:
    2017/01
    2017/06: Added DIFFERENCE OF AAD TO MEDIAN
    2017/12: Changed definition and name of command
 
Program 1:
    LET Y1 = DOUBLE EXPONENTIAL NUMBERS FOR I = 1 1 100
    LET D = MAD TO MEDIAN Y1
 
Program 2:
    . Step 1:   Create the data
    .
    skip 25
    read gear.dat y x
    skip 0
    set write decimals 6
    .
    . Step 2:   Define plot control
    .
    title case asis
    title offset 2
    label case asis
    .
    y1label Coefficient of Dispersion (MAD of Median)
    x1label Group
    title MAD to Median for GEAR.DAT
    let ngroup = unique x
    xlimits 1 ngroup
    major x1tic mark number ngroup
    minor x1tic mark number 0
    tic mark offset units data
    x1tic mark offset 0.5 0.5
    y1tic mark label decimals 3
    .
    character X
    line blank
    .
    set statistic plot reference line average
    mad of median plot y x
    .
    tabulate mad of median y x

Program 3:
    SKIP 25
    READ IRIS.DAT Y1 TO Y4 X
    .
    LET A = DIFFERENCE OF MAD TO MEDIAN Y1 Y2
    SET WRITE DECIMALS 4
    TABULATE DIFFERENCE OF MAD TO MEDIAN Y1 Y2 X
    .
    XTIC OFFSET 0.2 0.2
    X1LABEL GROUP ID
    Y1LABEL DIFFERENCE OF MAD TO MEDIAN
    CHAR X
    LINE BLANK
    DIFFERENCE OF MAD TO MEDIAN PLOT Y1 Y2 X
    CHAR X ALL
    LINE BLANK ALL
    BOOTSTRAP DIFFERENCE OF MAD TO MEDIAN PLOT Y1 Y2 X 
 
-----MAIL-------------------------------------------------------
 
MAIL
 
Name:
    MAIL
 
Type:
    Support Command
 
Purpose:
    Prints out the specific mail messages from the DATAPLOT service
    organization to an individual user.
 
Syntax:
    MAIL   <user's last name>
 
Examples:
    MAIL SMITH
    MAIL JONES
    MAIL JOHNSON
 
Note:
    This command is essentially obsolete since most operating systems
    have far more sophisticated electronic mail capabilities than
    provided with this command.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    BUGS = Lists the bugs file.
    NEWS = Lists the news file.
    HELP = Lists portions of the help file.
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----MAJOR TIC MARK NUMBER---------------------------------------------
 
MAJOR TIC MARK NUMBER
 
Name:
    MAJOR ...TIC MARK NUMBER
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the number of major tic marks to appear on an axis.
 
Description:
    DATAPLOT can automatically scale the axis and select an appropriate
    number of major tic marks.  However, it is sometimes desirable to
    override the default choice and generate your own axis scale
    specification.  This command is normally used with the LIMITS
    command to generate a "neat" axis scale.
 
Syntax:
    <prefix>MAJOR TIC MARK NUMBER  <value>
    where
            no prefix     refers to all 4 sides;
            the prefix X  refers to both horizontal sides;
            the prefix Y  refers to both vertical sides;
            the prefix X1 refers to the lower horizontal side;
            the prefix X2 refers to the upper horizontal side;
            the prefix Y1 refers to the left  vertical   side;
            the prefix Y2 refers to the right vertical   side;
    and <value> is an integer number or parameter that specifies the
            desired number of major tic marks.
 
Examples:
    MAJOR TIC MARK NUMBER 5
    MAJOR XTIC MARK NUMBER 6
    MAJOR YTIC MARK NUMBER 4
    MAJOR TIC MARK NUMBER
 
Note:
    A ...MAJOR TIC MARK NUMBER command with no arguments reverts the
    setting to default; thus X1MAJOR TIC MARK NUMBER with no arguments
    reverts the bottom horizontal tic labels to on.  A ...TIC
    MARK LABEL command with no prefix refers to all 4 sides; thus
    MAJOR TIC MARK NUMBER OFF suppresses tic mark label for all 4 frame
    lines.  Note also that MAJOR TIC MARK NUMBER with no prefix and no
    arguments reverts the tic label settings on all 4 sides to
    default.
 
Default:
    DATAPLOT selects an appropriate number of tic marks.
 
Synonyms:
    MAJOR TIC NUMBER is a synonym for MAJOR TIC MARK NUMBER, as in
    MAJOR TIC NUMBER 6.
 
Related Commands:
    MINOR TIC MARK NUMB = Specifies the number of minor tic mark
                          numbers to appear between major tic marks.
    LIMITS              = Specifies the axis minimum and maximum
                          values.
    TIC MARK            = Specifies whether or not tics are drawn.
    TIC MARK OFFSET     = Sets the offset for the first and last tic
                           marks.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE LIMITS COMMAND
    X1LABEL LEAD
    Y1LABEL POTASSIUM
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    .
    XLIMITS 0 600; XTIC OFFSET 0 15
    MAJOR XTIC MARK NUMBER 7
    YLIMITS 100 400; YTIC OFFSET 50 50
    MAJOR YTIC MARK NUMBER 4
    .
    PLOT POT VS LEAD
 
-----MAKCDF (LET)--------------------------------
 
MAKCDF
 
Name:
    MAKCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Gompertz-Makeham cumulative distribution function.
 
Description:
    The Gompertz-Makeham distribution is effectively a
    smallest extreme value distribution truncated at zero.

    There are a number of parameterizations of the Gompertz-Makeham
    distribution in the literature.  Dataplot supports several
    different parameterizations.

    1) The Digital Library of Mathematical Functions (DLMF) uses
       the following parameterization of the cumulative
       distribution function:

           F(x;xi,lambda,theta) =
               1 - EXP(-xi*(EXP(lambda*x) - 1) - xi*theta*lambda*x)
               x > 0; lambda, xi, theta > 0

       Note that this definition uses three shape parameters.

    2) Meeker and Escobar use a parameterization based on the
       parameters gamma, k, and lambda.  This can be translated
       to the DLMF definition as follows:

           xi(DLMF)     = gamma(Meeker)/k(Meeker)
           lambda(DLMF) = k(Meeker)
           theta(DLMF)  = lambda(Meeker)/gamma(Meeker)

       After making the above substitutions, it is equivalent to
       the DLMF definition.  The cumulative distribution function
       can be written as

           F(x;xgamma,k,lambda) =
               1 - EXP[-(lambda*k*x + gamma*EXP(k*x) - gamma)/k]
               x > 0; gamma, k > 0, lambda >= 0

       Note that Meeker and Escobar parameterization can be
       expressed in terms of the DLMF parameterization:

           lambda(Meeker) = theta(DLMF)*lambda(DLMF)*xi(DLMF)
           gamma(Meeker)  = lambda(DLMF)*xi(DLMF)
           k(Meeker)     = lambda(DLMF)

    3) Given the three shape parameters definition of Meeker and
       Escobar,  Meeker and Escobar reparameterize the distribution
       in the following way:

           theta = (1/k)
           eta   = LOG(k/gamma)
           zeta  = lambda/k

       An attractive feature of this parameterization is that
       it reduces the three shape parameters to two shape
       parameters (eta and zeta) and a scale parameter (theta).
       The cumulative distribution function is:

          F(x;zeta,eta) = 1 - EXP[EXP(-zeta) - EXP(x-zeta) - eta*x]
                          x > 0; eta >= 0

    The default parameterization is the Meeker and Escobar definition
    with two shape parameters.

    To specify the DLMF parameterization, enter the command

       SET GOMPERTZ MAKEHAM DEFINITION DLMF

    To specify the Meeker and Escobar parameterization with three
    shape parameters, enter the command

       SET GOMPERTZ MAKEHAM DEFINITION MEEKER

    To reset the default Meeker and Escobar definition with two
    shape parameters, enter

       SET GOMPERTZ MAKEHAM DEFINITION REPARAMETERIZED MEEKER

    The Gompertz-Makeham distribution can be generalized with
    location and scale parameters in the usual way.  Simply replace
    x with (x-loc)/scale in the above equations.

Syntax 1:
    LET <y> = MAKCDF(<x>,<zeta>,<eta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <zeta> is a non-negative number, parameter, or variable
              that specifies the first shape parameter;
          <eta> is a number, parameter, or variable that specifies
              the second shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the definition as given by Meeker and
    Escobar that reparameterizes the distribution to have only
    two shape parameters.

Syntax 2:
    LET <y> = MAKCDF(<x>,<xi>,<lambda>,<theta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <xi> is a positive number, parameter, or variable that
              specifies the XI shape parameter;
          <lambda> is a positive number, parameter, or variable that
              specifies the LAMBDA shape parameter;
          <theta> is a positive number, parameter, or variable that
              specifies the THETA shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the DLMF definition.

Syntax 3:
    LET <y> = MAKCDF(<x>,<gamma>,<k>,<lambda>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <gamma> is a positive number, parameter, or variable that
              specifies the gamma shape parameter;
          <k> is a positive number, parameter, or variable that
              specifies the k shape parameter;
          <lambda> is a positive number, parameter, or variable that
              specifies the lambda shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the definition for three shape parameters
    as given by Meeker and Escobar.

Examples:
    SET GOMPERTZ MAKEHAM DEFINITION REPARAMETERIZED MEEKER
    LET A = MAKCDF(0.3,0.5,2)
    LET A = MAKCDF(X,ETA,ZETA)
    PLOT MAKCDF(X,ETA,ZETA) FOR X = 0.01  0.01  5
 
    SET GOMPERTZ MAKEHAM DEFINITION DLMF
    LET A = MAKCDF(0.3,0.5,2,1.4)
    LET A = MAKCDF(X,XI,LAMBDA,THETA)
    PLOT MAKCDF(X,XI,LAMBDA,THETA) FOR X = 0.01  0.01  5
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MAKPDF  = Compute the Gompertz-Makeham probability density
              function.
    MAKPPF  = Compute the Gompertz-Makeham percent point function.
    MAKHAZ  = Compute the Gompertz-Makeham hazard function.
    MAKCHAZ = Compute the Gompertz-Makeham cumulative hazard function.
    GOMCDF  = Compute the Gompertz probability density function.
    EXPCDF  = Compute the exponential probability density function.
    WEICDF  = Compute the Weibull probability density function.
    EV1CDF  = Compute the extreme value type I probability density
              function.
    EV2CDF  = Compute the extreme value type II probability density
              function.
 
Reference:
    "Statistical Methods for Reliability Data",
    Meeker and Escobar, Wiley, 2000, pp. 108-109.
 
Applications:
    Survival Analysis, Distributional Modeling
 
Implementation Date:
    2003/12: Original implementation (using the DLMF definition)
    2004/7:  Added support for alternate parameterizations
 
Program:
    Y1LABEL Probability
    X1LABEL X
    LABEL CASE ASIS
    Y1LABEL DISPLACEMENT 12
    X1LABEL DISPLACEMENT 12
    TITLE DISPLACEMENT 2
    .
    MULTIPLOT 2 3
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    TITLE ZETA = 0.5, ETA = 0.2
    PLOT MAKCDF(X,0.5,0.2) FOR X = 0.01  0.01  3
    TITLE ZETA = 0.5, ETA = 2
    PLOT MAKCDF(X,0.5,2) FOR X = 0.01  0.01  3
    TITLE ZETA = 3, ETA = 0.2
    PLOT MAKCDF(X,3,0.2) FOR X = 0.01  0.01  3
    TITLE ZETA = 3, ETA = 2
    PLOT MAKCDF(X,3,2) FOR X = 0.01  0.01  3
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Gompertz-Makeham CDF
 
-----MAKCHAZ (LET)--------------------------------
 
MAKCHAZ
 
Name:
    MAKCHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Gompertz-Makeham cumulative hazard function.
 
Description:
    The Gompertz-Makeham distribution is effectively a
    smallest extreme value distribution truncated at zero.

    There are a number of parameterizations of the Gompertz-Makeham
    distribution in the literature.  Dataplot supports several
    different parameterizations.

    1) The Digital Library of Mathematical Functions (DLMF) uses
       the following parameterization of the cumulative hazard
       function:

           H(x;xi,lambda,theta) =
               -[-xi*(EXP(lambda*x) - 1) - xi*theta*lambda*x]
               x > 0; lambda, xi, theta > 0

       Note that this definition uses three shape parameters.

    2) Meeker and Escobar use a parameterization based on the
       parameters gamma, k, and lambda.  This can be translated
       to the DLMF definition as follows:

           xi(DLMF)     = gamma(Meeker)/k(Meeker)
           lambda(DLMF) = k(Meeker)
           theta(DLMF)  = lambda(Meeker)/gamma(Meeker)

       After making the above substitutions, it is equivalent to
       the DLMF definition.  The cumulative hazard function
       can be written as

           H(x;gamma,k,lambda) =
               (lambda*k*x - gamma*EXP(k*x) + gamma)/k
               x > 0; gamma, k > 0, lambda >= 0

       Note that Meeker and Escobar parameterization can be
       expressed in terms of the DLMF parameterization:

           lambda(Meeker) = theta(DLMF)*lambda(DLMF)*xi(DLMF)
           gamma(Meeker)  = lambda(DLMF)*xi(DLMF)
           k(Meeker)      = lambda(DLMF)

    3) Given the three shape parameters definition of Meeker and
       Escobar,  Meeker and Escobar reparameterize the distribution
       in the following way:

           theta = (1/k)
           zeta  = LOG(k/gamma)
           eta   = lambda/k

       An attractive feature of this parameterization is that
       it reduces the three shape parameters to two shape
       parameters (eta and zeta) and a scale parameter (theta).
       The cumulative hazard function is:

          H(x;zeta,eta) = -EXP(-zeta) + EXP(x-zeta) + eta*x
                          x > 0; eta >= 0

    The default parameterization is the Meeker and Escobar definition
    with two shape parameters.

    To specify the DLMF parameterization, enter the command

       SET GOMPERTZ MAKEHAM DEFINITION DLMF

    To specify the Meeker and Escobar parameterization with three
    shape parameters, enter the command

       SET GOMPERTZ MAKEHAM DEFINITION MEEKER

    To reset the default Meeker and Escobar definition with two
    shape parameters, enter

       SET GOMPERTZ MAKEHAM DEFINITION REPARAMETERIZED MEEKER

    The Gompertz-Makeham distribution can be generalized with
    location and scale parameters in the usual way.  Simply replace
    x with (x-loc)/scale in the above equations.

Syntax 1:
    LET <y> = MAKCHAZ(<x>,<zeta>,<eta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <zeta> is a non-negative number, parameter, or variable
              that specifies the first shape parameter;
          <eta> is a number, parameter, or variable that specifies
              the second shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham cumulative hazard
              value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the definition as given by Meeker and
    Escobar that reparameterizes the distribution to have only
    two shape parameters.

Syntax 2:
    LET <y> = MAKCHAZ(<x>,<xi>,<lambda>,<theta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <xi> is a positive number, parameter, or variable that
              specifies the XI shape parameter;
          <lambda> is a positive number, parameter, or variable that
              specifies the LAMBDA shape parameter;
          <theta> is a positive number, parameter, or variable that
              specifies the THETA shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham cumulative hazard
              value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the DLMF definition.

Syntax 3:
    LET <y> = MAKCHAZ(<x>,<gamma>,<k>,<lambda>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <gamma> is a positive number, parameter, or variable that
              specifies the gamma shape parameter;
          <k> is a positive number, parameter, or variable that
              specifies the k shape parameter;
          <lambda> is a positive number, parameter, or variable that
              specifies the lambda shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham cumulative hazard
              value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the definition for three shape parameters
    as given by Meeker and Escobar.

Examples:
    SET GOMPERTZ MAKEHAM DEFINITION REPARAMETERIZED MEEKER
    LET A = MAKCHAZ(0.3,0.5,2)
    LET A = MAKCHAZ(X,ETA,ZETA)
    PLOT MAKCHAZ(X,ETA,ZETA) FOR X = 0.01  0.01  5
 
    SET GOMPERTZ MAKEHAM DEFINITION DLMF
    LET A = MAKCHAZ(0.3,0.5,2,1.4)
    LET A = MAKCHAZ(X,XI,LAMBDA,THETA)
    PLOT MAKCHAZ(X,XI,LAMBDA,THETA) FOR X = 0.01  0.01  5
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MAKCDF  = Compute the Gompertz-Makeham cumulative distribution
              function.
    MAKPDF  = Compute the Gompertz-Makeham probability density
              function.
    MAKPPF  = Compute the Gompertz-Makeham percent point function.
    MAKHAZ  = Compute the Gompertz-Makeham hazard function.
    GOMCDF  = Compute the Gompertz probability density function.
    EXPCDF  = Compute the exponential probability density function.
    WEICDF  = Compute the Weibull probability density function.
    EV1CDF  = Compute the extreme value type I probability density
              function.
    EV2CDF  = Compute the extreme value type II probability density
              function.
 
Reference:
    "Statistical Methods for Reliability Data",
    Meeker and Escobar, Wiley, 2000, pp. 108-109.
 
Applications:
    Survival Analysis, Distributional Modeling
 
Implementation Date:
    2003/12: Original implementation (using the DLMF definition)
    2004/7:  Added support for alternate parameterizations
 
Program:
    Y1LABEL Cumulative Hazard
    X1LABEL X
    LABEL CASE ASIS
    Y1LABEL DISPLACEMENT 12
    X1LABEL DISPLACEMENT 12
    TITLE DISPLACEMENT 2
    .
    MULTIPLOT 2 3
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    TITLE ZETA = 0.5, ETA = 0.2
    PLOT MAKCHAZ(X,0.5,0.2) FOR X = 0.01  0.01  3
    TITLE ZETA = 0.5, ETA = 2
    PLOT MAKCHAZ(X,0.5,2) FOR X = 0.01  0.01  3
    TITLE ZETA = 3, ETA = 0.2
    PLOT MAKCHAZ(X,3,0.2) FOR X = 0.01  0.01  3
    TITLE ZETA = 3, ETA = 2
    PLOT MAKCHAZ(X,3,2) FOR X = 0.01  0.01  3
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Gompertz-Makeham Cumulative Hazard

-----MAKHAZ (LET)--------------------------------
 
MAKHAZ
 
Name:
    MAKHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Gompertz-Makeham hazard function.
 
Description:
    The Gompertz-Makeham distribution is effectively a
    smallest extreme value distribution truncated at zero.

    There are a number of parameterizations of the Gompertz-Makeham
    distribution in the literature.  Dataplot supports several
    different parameterizations.

    1) The Digital Library of Mathematical Functions (DLMF) uses
       the following parameterization of the hazard
       function:

           h(x;xi,lambda,theta) =
               xi*theta*lambda + xi*lambda*EXP(lambda*x)
               x > 0; lambda, xi, theta > 0

       Note that this definition uses three shape parameters.

    2) Meeker and Escobar use a parameterization based on the
       parameters gamma, k, and lambda.  This can be translated
       to the DLMF definition as follows:

           xi(DLMF)     = gamma(Meeker)/k(Meeker)
           lambda(DLMF) = k(Meeker)
           theta(DLMF)  = lambda(Meeker)/gamma(Meeker)

       After making the above substitutions, it is equivalent to
       the DLMF definition.  The hazard function can be written as

           h(x;gamma,k,lambda) = lambda + gamma*EXP(k*x)
                                 x > 0; gamma, k > 0, lambda >= 0

       Note that Meeker and Escobar parameterization can be
       expressed in terms of the DLMF parameterization:

           lambda(Meeker) = theta(DLMF)*lambda(DLMF)*xi(DLMF)
           gamma(Meeker)  = lambda(DLMF)*xi(DLMF)
           k(Meeker)      = lambda(DLMF)

    3) Given the three shape parameters definition of Meeker and
       Escobar,  Meeker and Escobar reparameterize the distribution
       in the following way:

           theta = (1/k)
           zeta  = LOG(k/gamma)
           eta   = lambda/k

       An attractive feature of this parameterization is that
       it reduces the three shape parameters to two shape
       parameters (eta and zeta) and a scale parameter (theta).
       The hazard function is:

          h(x;zeta,eta) = eta + EXP(-zeta)*EXP(x)
                          x > 0; eta >= 0

    The default parameterization is the Meeker and Escobar definition
    with two shape parameters.

    To specify the DLMF parameterization, enter the command

       SET GOMPERTZ MAKEHAM DEFINITION DLMF

    To specify the Meeker and Escobar parameterization with three
    shape parameters, enter the command

       SET GOMPERTZ MAKEHAM DEFINITION MEEKER

    To reset the default Meeker and Escobar definition with two
    shape parameters, enter

       SET GOMPERTZ MAKEHAM DEFINITION REPARAMETERIZED MEEKER

    The Gompertz-Makeham distribution can be generalized with
    location and scale parameters in the usual way.  Simply replace
    x with (x-loc)/scale in the above equations.

Syntax 1:
    LET <y> = MAKHAZ(<x>,<zeta>,<eta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <zeta> is a non-negative number, parameter, or variable
              that specifies the first shape parameter;
          <eta> is a number, parameter, or variable that specifies
              the second shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham hazard
              value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the definition as given by Meeker and
    Escobar that reparameterizes the distribution to have only
    two shape parameters.

Syntax 2:
    LET <y> = MAKHAZ(<x>,<xi>,<lambda>,<theta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <xi> is a positive number, parameter, or variable that
              specifies the XI shape parameter;
          <lambda> is a positive number, parameter, or variable that
              specifies the LAMBDA shape parameter;
          <theta> is a positive number, parameter, or variable that
              specifies the THETA shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham hazard
              value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the DLMF definition.

Syntax 3:
    LET <y> = MAKHAZ(<x>,<gamma>,<k>,<lambda>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <gamma> is a positive number, parameter, or variable that
              specifies the gamma shape parameter;
          <k> is a positive number, parameter, or variable that
              specifies the k shape parameter;
          <lambda> is a positive number, parameter, or variable that
              specifies the lambda shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham hazard
              value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the definition for three shape parameters
    as given by Meeker and Escobar.

Examples:
    SET GOMPERTZ MAKEHAM DEFINITION REPARAMETERIZED MEEKER
    LET A = MAKHAZ(0.3,0.5,2)
    LET A = MAKHAZ(X,ETA,ZETA)
    PLOT MAKHAZ(X,ETA,ZETA) FOR X = 0.01  0.01  5
 
    SET GOMPERTZ MAKEHAM DEFINITION DLMF
    LET A = MAKHAZ(0.3,0.5,2,1.4)
    LET A = MAKHAZ(X,XI,LAMBDA,THETA)
    PLOT MAKHAZ(X,XI,LAMBDA,THETA) FOR X = 0.01  0.01  5
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MAKCDF  = Compute the Gompertz-Makeham cumulative distribution
              function.
    MAKPDF  = Compute the Gompertz-Makeham probability density
              function.
    MAKPPF  = Compute the Gompertz-Makeham percent point function.
    MAKCHAZ = Compute the Gompertz-Makeham cumulative hazard function.
    GOMCDF  = Compute the Gompertz probability density function.
    EXPCDF  = Compute the exponential probability density function.
    WEICDF  = Compute the Weibull probability density function.
    EV1CDF  = Compute the extreme value type I probability density
              function.
    EV2CDF  = Compute the extreme value type II probability density
              function.
 
Reference:
    "Statistical Methods for Reliability Data",
    Meeker and Escobar, Wiley, 2000, pp. 108-109.
 
Applications:
    Survival Analysis, Distributional Modeling
 
Implementation Date:
    2003/12: Original implementation (using the DLMF definition)
    2004/7:  Added support for alternate parameterizations
 
Program:
    Y1LABEL Hazard
    X1LABEL X
    LABEL CASE ASIS
    Y1LABEL DISPLACEMENT 12
    X1LABEL DISPLACEMENT 12
    TITLE DISPLACEMENT 2
    .
    MULTIPLOT 2 3
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    TITLE ZETA = 0.5, ETA = 0.2
    PLOT MAKHAZ(X,0.5,0.2) FOR X = 0.01  0.01  3
    TITLE ZETA = 0.5, ETA = 2
    PLOT MAKHAZ(X,0.5,2) FOR X = 0.01  0.01  3
    TITLE ZETA = 3, ETA = 0.2
    PLOT MAKHAZ(X,3,0.2) FOR X = 0.01  0.01  3
    TITLE ZETA = 3, ETA = 2
    PLOT MAKHAZ(X,3,2) FOR X = 0.01  0.01  3
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Gompertz-Makeham Hazard

-----MAKPDF (LET)--------------------------------
 
MAKPDF
 
Name:
    MAKPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Gompertz-Makeham probability density function.
 
Description:
    The Gompertz-Makeham distribution is effectively a
    smallest extreme value distribution truncated at zero.

    There are a number of parameterizations of the Gompertz-Makeham
    distribution in the literature.  Dataplot supports several
    different parameterizations.

    1) The Digital Library of Mathematical Functions (DLMF) uses
       the following parameterization of the probability density
       function:

           f(x;xi,lambda,theta) =
               xi*lambda*(theta+EXP(lambda*x)*
               EXP(-xi*(EXP(lambda*x) - 1) - xi*theta*lambda*x)
               x > 0; lambda, xi, theta > 0

       Note that this definition uses three shape parameters.

    2) Meeker and Escobar use a parameterization based on the
       parameters gamma, k, and lambda.  This can be translated
       to the DLMF definition as follows:

           xi(DLMF)     = gamma(Meeker)/k(Meeker)
           lambda(DLMF) = k(Meeker)
           theta(DLMF)  = lambda(Meeker)/gamma(Meeker)

       After making the above substitutions, the DLMF definition
       can be used.

       Note that Meeker and Escobar parameterization can be
       expressed in terms of the DLMF parameterization:

           lambda(Meeker) = theta(DLMF)*lambda(DLMF)*xi(DLMF)
           gamma(Meeker)  = lambda(DLMF)*xi(DLMF)
           k(Meeker)     = lambda(DLMF)

    3) Given the three shape parameters definition of Meeker and
       Escobar,  Meeker and Escobar reparameterize the distribution
       in the following way:

           theta = (1/k)
           zeta  = LOG(k/gamma)
           eta   = lambda/k

       An attractive feature of this parameterization is that
       it reduces the three shape parameters to two shape
       parameters (eta and zeta) and a scale parameter (theta).
       The probability density function is:

          f(x;zeta,eta) = (eta + EXP(x - zeta))*
                          EXP[EXP(-zeta) - EXP(x-zeta) - eta*x]
                          x > 0; eta >= 0

    The default parameterization is the Meeker and Escobar definition
    with two shape parameters.

    To specify the DLMF parameterization, enter the command

       SET GOMPERTZ MAKEHAM DEFINITION DLMF

    To specify the Meeker and Escobar parameterization with three
    shape parameters, enter the command

       SET GOMPERTZ MAKEHAM DEFINITION MEEKER

    To reset the default Meeker and Escobar definition with two
    shape parameters, enter

       SET GOMPERTZ MAKEHAM DEFINITION REPARAMETERIZED MEEKER

    The Gompertz-Makeham distribution can be generalized with
    location and scale parameters in the usual way.  Simply replace
    x with (x-loc)/scale in the above equations.

Syntax 1:
    LET <y> = MAKPDF(<x>,<zeta>,<eta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <zeta> is a non-negative number, parameter, or variable
              that specifies the first shape parameter;
          <eta> is a number, parameter, or variable that specifies
              the second shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the definition as given by Meeker and
    Escobar that reparameterizes the distribution to have only
    two shape parameters.

Syntax 2:
    LET <y> = MAKPDF(<x>,<xi>,<lambda>,<theta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <xi> is a positive number, parameter, or variable that
              specifies the XI shape parameter;
          <lambda> is a positive number, parameter, or variable that
              specifies the LAMBDA shape parameter;
          <theta> is a positive number, parameter, or variable that
              specifies the THETA shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the DLMF definition.

Syntax 3:
    LET <y> = MAKPDF(<x>,<gamma>,<k>,<lambda>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <gamma> is a positive number, parameter, or variable that
              specifies the gamma shape parameter;
          <k> is a positive number, parameter, or variable that
              specifies the k shape parameter;
          <lambda> is a positive number, parameter, or variable that
              specifies the lambda shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the definition for three shape parameters
    as given by Meeker and Escobar.

Examples:
    SET GOMPERTZ MAKEHAM DEFINITION REPARAMETERIZED MEEKER
    LET A = MAKPDF(0.3,0.5,2)
    LET A = MAKPDF(X,ETA,ZETA)
    PLOT MAKPDF(X,ETA,ZETA) FOR X = 0.01  0.01  5
 
    SET GOMPERTZ MAKEHAM DEFINITION DLMF
    LET A = MAKPDF(0.3,0.5,2,1.4)
    LET A = MAKPDF(X,XI,LAMBDA,THETA)
    PLOT MAKPDF(X,XI,LAMBDA,THETA) FOR X = 0.01  0.01  5
 
Note:
    Gompertz-Makeham random numbers, probability plots, and goodness
    of fit tests can be generated with the following commands:

    If the DLMF definition is used, define the parameters with
    the commands:

       LET XI = <value>
       LET LAMBDA = <value>
       LET THETA = <value>

    If the three shape parameters Meeker and Escobar definition is
    used, define the parameters with the commands:

       LET GAMMA = <value>
       LET K = <value>
       LET LAMBDA = <value>

    If the two shape parameters Meeker and Escobar definition is
    used, define the parameters with the commands:

       LET ETA = <value>
       LET ZETA = <value>

    Then use the commands

       LET Y = GOMPERTZ MAKEHAM RANDOM NUMBERS FOR I = 1 1 N
       GOMPERTZ MAKEHAM PROBABILITY PLOT Y
       GOMPERTZ MAKEHAM KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       GOMPERTZ MAKEHAM CHI-SQUARE GOODNESS OF FIT Y


    If the two shape parameters Meeker and Escobar definition
    is used, the shape parameters can be estimated with the
    ks plot or ppcc plot:

       LET ETA1 = <value>
       LET ETA2 = <value>
       LET ZETA1 = <value>
       LET ZETA2 = <value>
       GOMPERTZ MAKEHAM KS PLOT Y
       GOMPERTZ MAKEHAM PPCC PLOT Y

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MAKCDF  = Compute the Gompertz-Makeham cumulative distribution
              function.
    MAKPPF  = Compute the Gompertz-Makeham percent point function.
    MAKHAZ  = Compute the Gompertz-Makeham hazard function.
    MAKCHAZ = Compute the Gompertz-Makeham cumulative hazard function.
    GOMPDF  = Compute the Gompertz probability density function.
    EXPPDF  = Compute the exponential probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    EV1PDF  = Compute the extreme value type I probability density
              function.
    EV2PDF  = Compute the extreme value type II probability density
              function.
 
Reference:
    "Statistical Methods for Reliability Data",
    Meeker and Escobar, Wiley, 2000, pp. 108-109.
 
Applications:
    Survival Analysis, Distributional Modeling
 
Implementation Date:
    2003/12: Original implementation (using the DLMF definition)
    2004/7:  Added support for alternate parameterizations
 
Program:
    Y1LABEL Probability
    X1LABEL X
    LABEL CASE ASIS
    Y1LABEL DISPLACEMENT 12
    X1LABEL DISPLACEMENT 12
    TITLE DISPLACEMENT 2
    .
    MULTIPLOT 2 3
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    TITLE ZETA = 0.5, ETA = 0.2
    PLOT MAKPDF(X,0.5,0.2) FOR X = 0.01  0.01  3
    TITLE ZETA = 0.5, ETA = 2
    PLOT MAKPDF(X,0.5,2) FOR X = 0.01  0.01  3
    TITLE ZETA = 3, ETA = 0.2
    PLOT MAKPDF(X,3,0.2) FOR X = 0.01  0.01  3
    TITLE ZETA = 3, ETA = 2
    PLOT MAKPDF(X,3,2) FOR X = 0.01  0.01  3
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Gompertz-Makeham PDF
 
-----MAKPPF (LET)--------------------------------
 
MAKPPF
 
Name:
    MAKPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Gompertz-Makeham percent point function.
 
Description:
    The Gompertz-Makeham distribution is effectively a
    smallest extreme value distribution truncated at zero.

    There are a number of parameterizations of the Gompertz-Makeham
    distribution in the literature.  Dataplot supports several
    different parameterizations.

    1) The Digital Library of Mathematical Functions (DLMF) uses
       the following parameterization of the cumulative
       distribution function:

           F(x;xi,lambda,theta) =
               1 - EXP(-xi*(EXP(lambda*x) - 1) - xi*theta*lambda*x)
               x > 0; lambda, xi, theta > 0

       Note that this definition uses three shape parameters.

    2) Meeker and Escobar use a parameterization based on the
       parameters gamma, k, and lambda.  This can be translated
       to the DLMF definition as follows:

           xi(DLMF)     = gamma(Meeker)/k(Meeker)
           lambda(DLMF) = k(Meeker)
           theta(DLMF)  = lambda(Meeker)/gamma(Meeker)

       After making the above substitutions, it is equivalent to
       the DLMF definition.  The cumulative distribution function
       can be written as

           F(x;xgamma,k,lambda) =
               1 - EXP[-(lambda*k*x + gamma*EXP(k*x) - gamma)/k]
               x > 0; gamma, k > 0, lambda >= 0

       Note that Meeker and Escobar parameterization can be
       expressed in terms of the DLMF parameterization:

           lambda(Meeker) = theta(DLMF)*lambda(DLMF)*xi(DLMF)
           gamma(Meeker)  = lambda(DLMF)*xi(DLMF)
           k(Meeker)     = lambda(DLMF)

    3) Given the three shape parameters definition of Meeker and
       Escobar,  Meeker and Escobar reparameterize the distribution
       in the following way:

           theta = (1/k)
           eta   = LOG(k/gamma)
           zeta  = lambda/k

       An attractive feature of this parameterization is that
       it reduces the three shape parameters to two shape
       parameters (eta and zeta) and a scale parameter (theta).
       The cumulative distribution function is:

          F(x;zeta,eta) = 1 - EXP[EXP(-zeta) - EXP(x-zeta) - eta*x]
                          x > 0; eta >= 0

    In all three cases, the percent point function does not
    have a simple closed form.  It is computed by numerically
    inverting the cumulative distribution function.  The SLATEC
    routine FZERO is used to solve the inverse equation.

    The default parameterization is the Meeker and Escobar definition
    with two shape parameters.

    To specify the DLMF parameterization, enter the command

       SET GOMPERTZ MAKEHAM DEFINITION DLMF

    To specify the Meeker and Escobar parameterization with three
    shape parameters, enter the command

       SET GOMPERTZ MAKEHAM DEFINITION MEEKER

    To reset the default Meeker and Escobar definition with two
    shape parameters, enter

       SET GOMPERTZ MAKEHAM DEFINITION REPARAMETERIZED MEEKER

    The Gompertz-Makeham distribution can be generalized with
    location and scale parameters in the usual way.  Simply replace
    x with (x-loc)/scale in the above equations.

Syntax 1:
    LET <y> = MAKPPF(<p>,<zeta>,<eta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, parameter, or variable;
          <zeta> is a non-negative number, parameter, or variable
              that specifies the first shape parameter;
          <eta> is a number, parameter, or variable that specifies
              the second shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the definition as given by Meeker and
    Escobar that reparameterizes the distribution to have only
    two shape parameters.

Syntax 2:
    LET <y> = MAKPPF(<p>,<xi>,<lambda>,<theta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, parameter, or variable;
          <xi> is a positive number, parameter, or variable that
              specifies the XI shape parameter;
          <lambda> is a positive number, parameter, or variable that
              specifies the LAMBDA shape parameter;
          <theta> is a positive number, parameter, or variable that
              specifies the THETA shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the DLMF definition.

Syntax 3:
    LET <y> = MAKPPF(<p>,<gamma>,<k>,<lambda>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, parameter, or variable;
          <gamma> is a positive number, parameter, or variable that
              specifies the gamma shape parameter;
          <k> is a positive number, parameter, or variable that
              specifies the k shape parameter;
          <lambda> is a positive number, parameter, or variable that
              specifies the lambda shape parameter;
          <loc> is a positive number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable that
              specifies the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Gompertz-Makeham ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

    This syntax implements the definition for three shape parameters
    as given by Meeker and Escobar.

Examples:
    SET GOMPERTZ MAKEHAM DEFINITION REPARAMETERIZED MEEKER
    LET A = MAKPPF(0.95,0.5,2)
    LET A = MAKPPF(P,ETA,ZETA)
    PLOT MAKPPF(X,ETA,ZETA) FOR X = 0.01  0.01  5
 
    SET GOMPERTZ MAKEHAM DEFINITION DLMF
    LET A = MAKPPF(0.95,0.5,2,1.4)
    LET A = MAKPPF(P,XI,LAMBDA,THETA)
    PLOT MAKPPF(P,XI,LAMBDA,THETA) FOR P = 0.01  0.01  0.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MAKCDF  = Compute the Gompertz-Makeham cumulative distribution
              function.
    MAKPDF  = Compute the Gompertz-Makeham probability density
              function.
    MAKHAZ  = Compute the Gompertz-Makeham hazard function.
    MAKCHAZ = Compute the Gompertz-Makeham cumulative hazard function.
    GOMCDF  = Compute the Gompertz probability density function.
    EXPCDF  = Compute the exponential probability density function.
    WEICDF  = Compute the Weibull probability density function.
    EV1CDF  = Compute the extreme value type I probability density
              function.
    EV2CDF  = Compute the extreme value type II probability density
              function.
 
Reference:
    "Statistical Methods for Reliability Data",
    Meeker and Escobar, Wiley, 2000, pp. 108-109.
 
Applications:
    Survival Analysis, Distributional Modeling
 
Implementation Date:
    2003/12: Original implementation (using the DLMF definition)
    2004/7:  Added support for alternate parameterizations
 
Program:
    X1LABEL Probability
    Y1LABEL X
    LABEL CASE ASIS
    Y1LABEL DISPLACEMENT 12
    X1LABEL DISPLACEMENT 12
    TITLE DISPLACEMENT 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    TITLE ZETA = 0.5, ETA = 0.2
    PLOT MAKPPF(P,0.5,0.2) FOR P = 0.01  0.01  0.99
    TITLE ZETA = 0.5, ETA = 2
    PLOT MAKPPF(P,0.5,2) FOR P = 0.01  0.01  0.99
    TITLE ZETA = 3, ETA = 0.2
    PLOT MAKPPF(P,3,0.2) FOR P = 0.01  0.01  0.99
    TITLE ZETA = 3, ETA = 2
    PLOT MAKPPF(P,3,2) FOR P = 0.01  0.01  0.99
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Gompertz-Makeham PPF
 
-----MANHATTAN DISTANCE (LET)-------------------------------------
 
MANHATTAN DISTANCE
 
Name:
    MANHATTAN DISTANCE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the Manhattan distance between two variables.
 
Description:
    The Manhattan distance between two variabes X and Y is
    defined as
 
        d = SUM[i=1 to n][|X(i) - Y(i)|]

    The Manhattan distance is also referred to as the city block
    distance or the taxi-cab distance.  It is equivalent to a
    Minkowsky distance with P = 1.

    The Manhattan distance is the distance measured along axes at
    right angles.

Syntax:
    LET <par> = MANHATTAN DISTANCE <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed Manhattan distance
              is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET A = MANHATTAN DISTANCE Y1 Y2
    LET A = MANHATTAN DISTANCE Y1 Y2  SUBSET Y1 > 0 SUBSET Y2 > 0

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    COSINE DISTANCE         = Compute the cosine distance.
    EUCLIDEAN DISTANCE      = Compute the Euclidean distance.
    MATRIX DISTANCE         = Compute various distance metrics for
                              a matrix.

Applications:
    Mathematics
 
Implementation Date:
    2017/03
 
Program:
    SKIP 25
    READ IRIS.DAT Y1 TO Y4 X
    .
    LET DIST  = MANHATTAN DISTANCE Y1 Y2
    SET WRITE DECIMALS 4
    TABULATE MANHATTAN DISTANCE Y1 Y2 X
    .
    XTIC OFFSET 0.2 0.2
    X1LABEL GROUP ID
    LET NDIST = UNIQUE X
    XLIMITS 1 NDIST
    MAJOR X1TIC MARK NUMBER NDIST
    MINOR X1TIC MARK NUMBER 0
    CHAR X
    LINE BLANK
    LABEL CASE ASIS
    CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    TITLE Manhattan Distance (IRIS.DAT)
    Y1LABEL Manhattan Distance
    MANHATTAN DISTANCE PLOT Y1 Y2 X

-----MANN WHITNEY U STATISTIC---------------------------------
 
MANN WHITNEY U STATISTIC
 
Name:
    MANN WHITNEY U STATISTIC (LET)
 
Type:
    Analysis Command
 
Purpose:
    Compute the test statistic or alternatively the frequencies and CDF
    values for the U version of the Mann Whitney rank sum test.
 
Description:
    The t-test is the standard test for testing that the difference
    between population means for two non-paired samples are equal.  The
    Mann Whitney rank sum test is a non-parameteric alternative to the
    t-test.

    The Mann Whitney rank sum test statistic is computed by:

         1) Rank the combined samples.

         2) Compute the sum of the ranks for each sample (call these
            T1 and T2).

         3) If the sample sizes are equal. the test statistic is

               T = min(T1,T2)

         4) If the sample sizes are unequal, let T1 be the sum of the
            smaller sample size and the test statistic is

               T = MIN(T1,N1*(N1 + N2 + 1) - T1)

    Sufficiently small values of T cause rejection of the null hypothesis
    that the sample locations are equal.  Significance levels have been
    tabulated for small values of N1 and N2.  For sufficiently large N1
    and N2, the following normal approximation is used:

         Z = (ABS(u - T) - 0.5)/sigma

    where

         u = N1*(N1 + N2 + 1)/2
         sigma = SQRT(N2*u/6)

    Some analysts prefer a slightly different formulation for this test

         U = N1*N2 + 0.5*N1*(N1 + 1) - W

    This form of the statistic can be computed with the command (Syntax 1)

         LET U = MANN WHITNEY U STATISTIC Y1 Y2

    Dataplot uses Applied Statistics algorithm 62 (as updated by
    Alan Miller) to obtain the cumulative frequencies and the
    corresponding CDF values of the U test statistic.

    That is, Syntax 1 is used to compute the value of the test statistic
    and Syntax 2 is used to obtain the CDF for the test statistic.

Syntax 1:
    LET <U> = MANN WHITEY U STATISTIC <y1> <y2>
              <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <U> is a parameter where the U version of the Mann Whitney
               rank sum statistic is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax returns the value of U version of the Mann-Whitney
    statistic.

Syntax 2:
    LET <x> <freq> <cdf> = MANN WHITEY U STATISTIC <n1> <n2>
                           <SUBSET/EXCEPT/FOR qualification>
    where <n1> is a parameter that specifies the sample size for the first
               response variable;
          <n2> is a parameter that specifies the sample size for the second
               response variable;
          <x> is a variable that returns the potential values of the test
               statistic;
          <freq> is a variable containing the cumulative frequencies
               corresponding to <x>;
          <cdf> is a variable containing the CDF values corresponding
               to <x>;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax returns the cumulative frequency table (and the
    corresponding CDF value) for the U version of the Mann Whitney
    statistic.  Note that it only depends on the samples sizes for the
    two variables, not the data.

Examples:
    LET U = MANN WHITNEY U STATISTIC Y1 Y2

    LET N1 = SIZE Y1
    LET N2 = SIZE Y2
    LET X FREQ CDF = MANN WHITNEY U STATISTIC FREQUENCY  N1  N2

Default:
    None
 
Synonyms:
    None

Related Commands:
    RANK SUM TEST              = Compute a Mann Whitney rank sum test.
    T-TEST                     = Compute a t-test.
    SIGNED RANK TEST           = Compute a signed rank test.
    SIGN TEST                  = Compute a sign test.
    CHI-SQUARED 2 SAMPLE TEST  = Compute a two sample chi-square test.
    BIHISTOGRAM                = Generates a bihistogram.
    QUANTILE-QUANTILE PLOT     = Generate a quantile-quantile plot.
 
Reference:
    Applied Statistics, AS 62.

    Conover (1999), "Practical Non-Parametric Statistics", Third Edition,
    Wiley, pp. 272-281.

    "Statistical Methods", Eigth Edition, Snedecor and Cochran, 
    1989, Iowa State University Press, pp. 142-144.
 
Applications:
    Non-Parametric Analysis, Two Sample Tests
 
Implementation Date:
    2011/5
 
Program:
    . Step 1: Read Data (example 2 from pp. 278-279 of Conover)
    .
    let y1 = data 1 2 3 5
    let y2 = data 4 6 7 8 9
    .
    let u = mann whitney u statistic y1 y2
    let n1 = size y1
    let n2 = size y2
    let x freq cdf = mann whitney u statistic frequency  n1 n2
    print x freq cdf

-----MANTEL-HAENSZEL TEST (LET)--------------------------------
 
MANTEL-HAENSZEL TEST
 
Name:
    MANTEL-HAENSZEL TEST (LET)
 
Type:
    Analysis Command
 
Purpose:
    Perform a Mantel-Haenszel test of a series of fourfold (2x2)
    tables.

Description:
    Given two variables where each variable has exactly two
    possible outcomes (typically defined as success and failure),
    we define the odds ratio as:

        o = (N11/N12)/(N21/N22)
          = (N11*N22)/(N12*N21)

    where

        N11 = number of successes in sample 1 
        N21 = number of failures in sample 1 
        N12 = number of successes in sample 2 
        N22 = number of failures in sample 2

    The log odds ratio is the logarithm of the odds ratio:

        l(o) = LOG{(N11/N12)/(N21/N22)}
             = LOG{(N11*N22)/(N12*N21)}

    Alternatively, the log odds ratio can be given in terms of
    the proportions

      l(o) = LOG{(p11/p12)/(p21/p22)}
           = LOG{(p11*p22)/(p12*p21)}

    where

        p11 = N11/(N11 + N21) = proportion of successes in sample 1
        p21 = N21/(N11 + N21) = proportion of failures in sample 1
        p12 = N12/(N12 + N22) = proportion of successes in sample 2
        p22 = N22/(N12 + N22) = proportion of failures in sample 2

    Success and failure can denote any binary response.
    Dataplot expects "success" to be coded as "1" and "failure"
    to be coded as "0".

    The bias corrected version of the log odds ratio is:

       l'(o) = LOG[{(N11+0.5)*(N22+0.5)}/{(N12+0.5)*(N21+0.5)}]

    In addition to reducing bias, this statistic also has the
    advantage that the log odds ratio is still defined even when
    N12 or N21 is zero (the uncorrected statistic will be
    undefined for these cases).

    Note that N11, N21, N12, and N22 defines a 2x2 contingency
    table.  These types of contingency tables are also referred
    to as fourfold tables.

    Fleiss, Levin, and Paik also use the following formulation
    for the ith 2x2 table:

              |     Outcome Variable          |
       Sample |  Present        Absent        |  Total
       ===============================================
         1    |    X(i)         n(i1) - X(i)  |  n(i1)
         2    |  m(i) - X(i)    X(i) - l(i)   |  n(i2)
       ===============================================
       Total  |    m(i)      n(i.) - m(i)     |  n(i.)

    where l(i) = m(i) + n(i2) - n(i.).

    The Mantel-Haenszel test can be used to estimate the
    common odds ratio and to test whether the overall
    degree of association is significant.  It is a consistent
    estimator in the following two cases:

       1) When the number of tables is fixed, and possibly
          small, but each table has large marginal frequencies.

       2) The number of tables is large.  The marginal
          frequencies can be small in the individual tables.

    Define the following quantities

        R(i) = X(i)*(X(i) - l(i))/n(i.)
        S(i) = (m(i) - X(i))*(n(i1) - X(i))/n(i.)

        R = SUM[i=1 to g][R(i)]
        S = SUM[i=1 to g][S(i)]

        P(i) = (X(i) + X(i) - l(i))/n(i.)
        Q(i) = 1 - P(i)
             = (m(i) - X(i) + n(i1) - X(i))/n(i.)
              
    The Mantel-Haenszel estimate of the common odds ratio is

    what(MH) = SUM[i=1 to g][(n(i1)*n(i2)/n(i.))*p(i1)*(1-p(i2))]/
               SUM[i=1 to g][(n(i1)*n(i2)/n(i.))*p(i2)*(1-p(i1))]
               
             = SUM[i=1 to g][X(i)*(X(i)-l(i))/n(i.)]/
               SUM[i=1 to g][m(i) - X(i))*(n(i1 - X(i))/n(i.)]

             = R/S

    where g denotes the number of groups.

    An estimate of the variance of LOG(What(MH)) is

       0.5*{SUM=1 to g][P(i)*R(i)]/R**2 +
       SUM[i=1 to g][(P(i)*S(i) + Q(i)*R(i)]/(R*S) +
       SUM[i=1 to g][Q(i)*S(i)]/S**2}
   
    A confidence interval for the log(odds ratio) is then

       LOG(What(MH)) +/- NORPPF(1 - alpha/2)*SE

    where NORPPF is the normal percent point function and SE
    is the standard error of the estimate (= square root of
    the variance).

    The Mantel-Haenszel chi-square statistic for the significance
    of the overall degree of association is

    Chi-Square(MH) = {|SUM[i=1 to g]
                     [n(i1)*n(i2)*(p(i1)-p(i2)/n(i.)]| - 0.5}**2/
                     SUM[i=1 to g]
                     [n(i1)*n(i2)*pbar(i)*qbar(i)/(n(i.) - 1)]

    where

        P(i1) = n(11)/n(i1)
        P(i2) = n(12)/n(i2)

        pbar(i) = (n(i1)*P(i1) + n(i2)*P(i2))/n(i.)
        qbar(i) = 1 - pbar(i)

    The test statistic is compared to a chi-square distribution
    with one degree of freedom.

    The MANTEL-HAENSZEL TEST generates the following
    output:

       1) A summary table of various statistics (odds ratio,
          log(odds ratio), standard error of log(odds ratio))
          for each group.

       2) The estimates of the common log(odds ratio) and the
          standard error of the common log(odds ratio).

       3) A table for the Mantel-Haenszel chi-square test for
          the overall degree of association.

       5) A large sample confidence interval for the
          log(odds ratio).

Syntax 1:
    MANTEL-HAENSZEL TEST <y1> <y2>
                         <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where <y1> and <y2> denote
    a series of 2x2 tables (i.e., rows 1 and 2 are group 1,
    rows 3 and 4 are group 2, and so on).

Syntax 2:
    MANTEL-HAENSZEL TEST <y1> <y2> <groupid>
                         <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <groupid> is a group id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where you have raw data (i.e.,
    the data has not yet been cross tabulated into a two-way table).
    In this case, the two response variables have an equal
    number of cases for each group.

Syntax 3:
    MANTEL-HAENSZEL TEST <y1> <groupid1> <y2> <groupid2>
                              <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <groupid1> is a group id variable corresponding to
              <y1>;
          <y2> is the second response variable;
          <groupid2> is a group id variable corresponding to
              <y2>;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where you have raw data (i.e.,
    the data has not yet been cross tabulated into a two-way table).
    In this case, the two response variables may have an unequal
    number of cases for each group, so <y1> and <y2> require
    different group id variables.

Examples:
    MANTEL-HAENSZEL TEST Y1 Y2
    MANTEL-HAENSZEL TEST Y1 Y2 X
    MANTEL-HAENSZEL TEST Y1 X1 Y2 X2

Note:
    This test is similar to the odds ratio chi-square test.
    Fleiss, Levin, and Paik make the following recommendations
    in regard to these two tests (they include other tests in
    their comparison).

       1) If the number of groups is small or moderate and
          the sample sizes within each group are large,
          the log(odds ratio) test performs well.

       2) If the number of groups is large, but the sample
          sizes within  the groups are small to moderate,
          then the Mantel-Haenszel test can be recommended.
          The log(odds ratio) test may performs poorly for
          this case.

       3) If the number of groups and the sample sizes
          within the groups are both small, exact methods
          may be required.  Dataplot does not currently
          support any exact methods for this problem.

Note:
    The following information is written to the file dpst1f.dat
    (in the current directory):

        Column 1   - significance level
        Column 2   - lower confidence limit for common
                     log(odds ratio)
        Column 3   - upper confidence limit for common
                     log(odds ratio)
        Column 4   - lower confidence limit for common
                     odds ratio
        Column 5   - upper confidence limit for common
                     odds ratio

     To read this information into Dataplot, enter

        SET READ FORMAT F10.5,1X,4E15.7
        READ DPST1F.DAT SIGLEV LOGLOWCL LOGUPPCL ODDLOWCL ODDUPPCL

    The following information is written to the file dpst2f.dat
    (in the current directory):

        Column 1   - R(i)
        Column 2   - S(i)
        Column 3   - P(i)
        Column 4   - Q(i)
        Column 5   - P(i)bar

     To read this information into Dataplot, enter

        SET READ FORMAT 5E15.7
        READ DPST1F.DAT RI SI PI QI PIBAR

     Dataplot saves the following internal parameters:

        STATVAL   = the Mantel-Haenszel test statistic
        STATCDFL  = the cdf for the Mantel-Haesnzel test statistic

Default:
    None
 
Synonyms:
    None

Related Commands:
    ODDS RATIO CHI-SQUARE TEST    = Perform an odds ratio chi-square
                                    test.
    ODDS RATIO INDEPENDENCE TEST  = Perform a log(odds ratio)
                                    independence test.
    CHI-SQUARE INDEPENDENCE TEST  = Perform a chi-square independence
                                    test.
    FISHER EXACT TEST             = Perform Fisher's exact test.
    ASSOCIATION PLOT              = Generate an association plot.
    SIEVE PLOT                    = Generate a sieve plot.
    ROSE PLOT                     = Generate a Rose plot.
    BINARY TABULATION PLOT        = Generate a binary tabulation plot.
    ROC CURVE                     = Generate a ROC curve.
    ODDS RATIO                    = Compute the bias corrected odds
                                    ratio.
    LOG ODDS RATIO                = Compute the bias corrected
                                    log(odds ratio).

Reference:
    Fleiss, Levin, and Paik (2003), "Statistical Methods for
    Rates and Proportions", Third Edition, pp. 250-253.

Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/5
 
Program:
    let n1 = 105
    let n2 = 192
    let n3 = 145
    let n = n1 + n2 + n3
    let x = 3 for i = 1 1 n
    let istop = n1 + n2
    let x = 2 for i = 1 1 istop
    let x = 1 for i = 1 1 n1
    .
    set statistic missing value -99
    .
    .  Group 1 values
    .
    let y1 = 0 for i = 1 1 n
    let y2 = 0 for i = 1 1 n
    let y1 = 1 for i = 1 1  81
    let y2 = 1 for i = 1 1  34
    .
    .  Group 2 values (have unequal samples here, so fill
    .          with missing values
    .
    let istrt = n1 + 1
    let istop1 = istrt + 118 - 1
    let istop2 = istrt + 69 - 1
    let y1 = 1 for i = istrt 1 istop1
    let y2 = 1 for i = istrt 1 istop2
    let istrt2 = n1 + 174 + 1
    let istop2 = n1 + n2
    let y2 = -99 for i = istrt2 1 istop2
    .
    .  Group 3 values
    .
    let istrt = n1 + n2 + 1
    let istop1 = istrt + 82 - 1
    let istop2 = istrt + 52 - 1
    let y1 = 1 for i = istrt 1 istop1
    let y2 = 1 for i = istrt 1 istop2
    .
    mantel haenszel test y1 y2 x

-----MARGIN-------------------------------------------------------
 
MARGIN
 
Name:
    MARGIN
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Specifies the x-coordinate of the margin.
 
Description:
    The margin is the horizontal position which the beam moves to if
    the "carriage return" switch is "on" (see the CR command) after a
    subsequent TEXT command.  If the carriage return is "off", the beam
    remains at the end of the string after a subsequent TEXT command
    (and thus new text is placed at the end position of old text).  If
    the carriage return is "on", the beam reverts to the margin value
    after a subsequent TEXT command and new text is placed at the
    margin position without an explicit MOVE command.
 
    MARGIN can also be judiciously used in conjunction with the
    JUSTIFICATION command.  If the justification switch is "left", the
    margin is the start point for text from succeeding TEXT commands.
    If the justification switch is "center", the margin is the center
    point for text from succeeding TEXT commands.  If the justification
    switch is "right", the margin is the end point for text from
    succeeding TEXT commands.
 
Syntax:
    MARGIN   <x>
    where <x> is a number or parameter in the decimal range 0 to 100 that
              specifies the desired x-coordinate.
 
Examples:
    MARGIN 20
    MARGIN 10
    MARGIN 70
    MARGIN X
    MARGIN
 
Note:
    The MARGIN command with no arguments reverts the margin to default.
 
Default:
    The default margin is 50 (that is, half way across the screen).
 
Synonyms:
    None
 
Related Commands:
    CR                 = Sets the carriage return after text.
    LF                 = Sets the line feed after text.
    CRLF               = Sets the carriage return/line feed after text.
    TEXT               = Writes a text string.
    FONT               = Sets the font for TEXT characters.
    CASE               = Sets the case for TEXT characters.
    HEIGHT             = Sets the height for TEXT characters.
    WIDTH              = Sets the width for TEXT characters.
    HW                 = Sets the height and width for TEXT characters.
    VERTICAL SPACING   = Sets the vertical spacing between text lines.
    HORIZONTAL SPACING = Sets the horizontal spacing between text
                         characters.
    THICKNESS          = Sets the thickness of TEXT characters.
    COLOR              = Sets the color for TEXT characters.
    JUSTIFICATION      = Sets the justification for TEXT.
    ()                 = Allows math and Greek characters in text.
    MOVE               = Moves to a point.
    CROSS-HAIR (or CH) = Activates and reads the cross-hair.
    ERASE              = Erases the screen (immediately).
    COPY               = Copies the screen (immediately).
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    CRLF ON
    MARGIN 5
    FONT DUPLEX
    .
    HEIGHT 4
    MOVE 5 95
    VERTICAL SPACING 3
    TEXT JAPAN's 6-POINT PROGRAM FOR
    MARGIN 10
    VERTICAL SPACING 12
    TEXT QUALITY MANUFACTURING
    HEIGHT 2.2
    VERTICAL SPACING 6
    TEXT CIRC() QUALITY AUDITS
    TEXT CIRC() COMPANY-WIDE QUALITY CONTROL (CWQC)
    TEXT CIRC() QUALITY TRAINING AND EDUCATION
    TEXT CIRC() APPLICATION OF STATISTICAL METHODS
    TEXT CIRC() QUALITY CIRCLE ACTIVITIES
    MARGIN 5
    VERTICAL SPACING 25
    TEXT CIRC() NATION-WIDE QUALITY CONTROL PROMOTIONAL ACTIVITIES
    HEIGHT 2
    TEXT SOURCE: Q.C. TRENDS WINTER 1985, PAGES 22-23.
 
-----MARGIN COLOR-----------------------------------------------------
 
MARGIN COLOR
 
Name:
    MARGIN COLOR
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the color of the margin (the margin is the region outside
    the frame) on subsequent plots.  The margin is "painted" whenever a
    subsequent screen erasure takes place.
 
    Dataplot provides two methods for specifying colors.

        1. Colors can be defined by name (or by the corresponding index).
           Dataplot adopted it's named colors from the X11 project.
           Currently, 162 named colors and 100 levels of grayscale are
           supported.  Grayscale can be specified with either G0, G1, ...,
           G100 (or -1, -2, ..., -100).  Many older devices support only a
           limited number of colors.  For these devices, unsupported colors
           will be mapped to one of the available colors.  To specify a
           named color, see Syntax 1.

        2. Most modern graphics devices support full RGB (RedBlueGreen)
           color.  You can alternatively specify RGB colors by entering
           three integer values to represent the Red, Green and Blue
           components, respectively.  These values should be in the range
           0 to 255.

    When setting the margin color, Dataplot first checks if the device
    supports RGB colors. If not, the named color will be used.  If the
    device does support RGB color, Dataplot will check if an RGB color
    has been specified.  If yes, then that RGB color is used.  If not,
    the named color will be used.

    To see the list of supported named colors (with the associated index
    number), see

    https://www.itl.nist.gov/div898/software/dataplot/refman1/ch11/homepage.htm

Syntax 1:
    MARGIN COLOR   <color>
    where <color> specifies the desired margin color.
 
Syntax 2:
    MARGIN RGB COLOR  <ired>  <igreen>  <iblue>
    where <ired> specifies the red component of the margin color;
          <igreen> specifies the green component of the margin color;
    and   <iblue> specifies the blue component of the margin color.

    The components should be integer values in the range 0 - 255.  To turn
    off the RGB color, set the components to -1 (any negative value will
    work and if any of the three components is negative the RGB color will
    be turned off).

Examples:
    MARGIN COLOR GREEN
    MARGIN COLOR YELLOW
    MARGIN RGB COLOR 90 167 102
 
Note:
    When you enter the BACKGROUND COLOR command, this will also set the
    MARGIN COLOR to the same color.  If you want the MARGIN COLOR to be
    different than the BACKGROUND COLOR, then enter the MARGIN COLOR
    after the BACKGROUND COLOR command.

Note:
    The MARGIN COLOR command with no arguments reverts the margin color
    to default.
 
Default:
    White
 
Synonyms:
    None
 
Related Commands:
    BACKGROUND COLOR   = Sets the color for plot background.
    PLOT               = Generates a data or function plot.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
    2021/03: Support for RGB margin color
 
Program:
    background color cyan
    background rgb color 110 205 65
    margin color yellow
    margin rgb color 90 167 102
    .
    line thickness 0.5
    line color yellow
    title case asis
    title offset 2
    title Sample Plot
    label case asis
    x1label x
    y1label x**2
    .
    plot x**2 for x = 1 1 9
 
-----MATCDF (LET)--------------------------------
 
MATCDF
 
Name:
    MATCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the classical matching cumulative distribution
    function.
 
Description:
    The classical matching distribution has the following
    probability mass function:

       p(x;k) = (1/X!)*SUM[i=1 to k-x][(-1)**i/i!]
                X = 0, 1, ..., k
 
    The cumulative distribution function is computed by
    summing the probability density function.

Syntax:
    LET <y> = MATCDF(<x>,<k>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter containing
              values between 0 and <k>;
          <k> is a number or parameter that defines the upper limit
              of the matching distribution;
          <y> is a variable or a parameter (depending on what <x>
              is) where the computed cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MATCDF(3,20)
    LET Y = MATCDF(X,100)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Note:
    For sufficiently large values of k, the classical matching
    distribution can be accurately approximated with a Poisson
    distribution with lambda = 1.  Dataplot computes MATCDF from
    the above definition for values of k < 20.  For values of
    k >= 20, Dataplot computes MATCDF using the Poisson cdf
    with lambda = 1.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATPDF = Compute the matching probability mass function.
    MATPPF = Compute the matching percent point function.
    POIPDF = Compute the Poisson probability mass function.
    LCTPDF = Compute the leads in coin tossing probability mass
             function.
    DISPDF = Compute the discrete uniform probability mass
             function.
    LOSPDF = Compute the lost games probability mass function.
    ARSPDF = Compute the arcsine probability density function.
    BETPDF = Compute the beta probability density function.
    UNIPDF = Compute the uniform probability mass function.
 
Reference:
    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 409-410.

    Feller (1957), "Introduction to Probability Theory",
    Third Edition, John Wiley and Sons, pp. 107-109.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    TITLE CASE ASIS
    TITLE Matching Cumulative Distribution Function CR() ...
          (N = 50)
    LABEL CASE ASIS
    Y1LABEL Probability
    X1LABEL X
    LINE BLANK
    SPIKE ON
    TIC OFFSET UNITS SCREEN
    TIC OFFSET 3 3
    PLOT MATCDF(X,50) FOR X = 0 1 50

-----MATCH (LET)-------------------------------------
 
MATCH
 
Name:
    MATCH (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Match a column of values to another column of numbers
    and return the index of the matching value.
 
Description:
    This command works on two columns of numbers.  The first
    column contains a set of numbers.  Each value in the
    second column is matched against the first column.  The
    closest value, as determined by the smallest absolute
    value in the difference between the numbers, is considered
    the match.  This command returns the index, not the actual
    value, of the first array where the match occurs.  The
    returned column of numbers will then be an array of index
    numbers.

    This is a utility operation.  That is, the index numbers
    are generally not of interest themselves but are used
    in subsequent computations.

    An alternative syntax supplies a third variable.  Instead
    of returning an index, the MATCH command uses the index
    to extract the value corresponding to the index of this
    third variable.  Generally, this is the ultimate goal
    (i.e., we would use the index to extract values of another
    variable).

Syntax 1:
    LET <y> = MATCH <x>  <val>     <SUBSET/EXCEPT/FOR qualification>
    where <x> is the variable containing a set of numbers;
          <val> is a number, parameter, or variable that will be
              matched against the values in <x>;
          <y> is a variable (of length equal to <val>) that contains
              the index (of <x>) where the match occurs;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax returns the index value.

Syntax 2:
    LET <y> = MATCH <x>  <val>  <z>
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is the variable containing a set of numbers;
          <val> is a number, parameter, or variable that will be
              matched against the values in <x>;
          <z> is a variable (of length equal to <x>) that contains
              the values to be extracted and placed in <y>;
          <y> is a variable (of length equal to <val>) that contains
              the values of <z> corresponding to the matched
              indices (of <x>);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax returns values of <z> corresponding to the
    matched indices.

Examples:
    LET Y = MATCH X VALUE
    LET Y = MATCH X VALUE SUBSET X > 0 1
    LET Y = MATCH X VALUE Z
    LET Y = MATCH X VALUE Z  SUBSET X > 0
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SEQUENCE           = Generate a patterned sequence of values.
    SORT               = Sort a column of numbers.
    RANK               = Rank a column of numbers.
    CODE               = Code a column of numbers.
 
Applications:
    Data Transformation
 
Implementation Date:
    2001/10
 
Program 1:
    LET Y = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET VAL = SEQUENCE -3 1 3
    LET Y2 = MATCH Y VAL
    SET WRITE DECIMALS 3
    PRINT VAL Y2
   
Program 2:
    LET Y = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET VAL = SEQUENCE -3 1 3
    LET Z = SEQUENCE -10 1 -1
    LET Y2 = MATCH Y VAL Z
    SET WRITE DECIMALS 3
    PRINT Y Z
    PRINT VAL Z2

-----MATPDF (LET)--------------------------------
 
MATPDF
 
Name:
    MATPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the classical matching probability mass function.
 
Description:
    The classical matching distribution has the following
    probability mass function:

       p(x;k) = (1/X!)*SUM[i=1 to k-x][(-1)**i/i!]
                X = 0, 1, ..., k

    with k a non-negative integer denoting the number of
    items parameter.

    Given k items numbered 1, 2, ..., k that are
    arranged in a random order, the classical matching distribution
    is the distribution of the number of items were the original
    numbering and the random ordering are the same.

    Feller (see References below) formulates this as
    the problem where we have two matching decks of cards
    and we want to determine the probability of matching
    X cards in the two decks.

Syntax:
    LET <y> = MATPDF(<x>,<k>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter containing
              values between 0 and <k>;
          <k> is a number or parameter that defines the upper limit
              of the matching distribution;
          <y> is a variable or a parameter (depending on what <x>
              is) where the computed pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MATPDF(3,20)
    LET Y = MATPDF(X,100)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Note:
    For a number of commands utilizing the matching distribution,
    it is convenient to bin the data.  There are two basic ways
    of binning the data.

      1) For some commands (histograms, maximum likelihood
         estimation), bins with equal size widths are
         required.  This can be accomplished with the
         following commands:

            LET AMIN = MINIMUM Y
            LET AMAX = MAXIMUM Y
            LET AMIN2 = AMIN - 0.5
            LET AMAX2 = AMAX + 0.5
            CLASS MINIMUM AMIN2
            CLASS MAXIMUM AMAX2
            CLASS WIDTH 1
            LET Y2 X2 = BINNED

      2) For some commands, unequal width bins may be
         helpful.  In particular, for the chi-square goodness
         of fit, it is typically recommended that the minimum
         class frequency be at least 5.  In this case, it may
         be helpful to combine small frequencies in the tails.
         Unequal class width bins can be created with the
         commands

            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = INTEGER FREQUENCY TABLE Y

         If you already have equal width bins data, you can
         use the commands
         
            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = COMBINE FREQUENCY TABLE Y2 X2

         The MINSIZE parameter defines the minimum class
         frequency.  The default value is 5.

Note:
    You can generate matching random numbers, probability plots,
    and chi-square goodness of fit tests with the following commands:

       LET N = VALUE
       LET K = <value>
       LET Y = MATCHING RANDOM NUMBERS FOR I = 1 1 N

       MATCHING PROBABILITY PLOT Y
       MATCHING PROBABILITY PLOT Y2 X2
       MATCHING PROBABILITY PLOT Y3 XLOW XHIGH

       MATCHING CHI-SQUARE GOODNESS OF FIT Y
       MATCHING CHI-SQUARE GOODNESS OF FIT Y2 X2
       MATCHING CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    Dataplot does not provide any explicit parameter estimation
    methods.  It is assummed that the number of objects is a
    known quantity.  We can then apply goodness of fit tests
    (i.e., the probability plot or the chi-square goodness of fit)
    to see if the classical matching distribution is an appropriate
    distribution.

Note:
    For sufficiently large values of k, the classical matching
    distribution can be accurately approximated with a Poisson
    distribution with lambda = 1.  Dataplot computes MATPDF from
    the above definition for values of k < 20.  For values of
    k >= 20, Dataplot computes MATPDF using the Poisson pdf
    with lambda = 1.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATCDF = Compute the matching cumulative distribution function.
    MATPPF = Compute the matching percent point function.
    POIPDF = Compute the Poisson probability mass function.
    LCTPDF = Compute the leads in coin tossing probability mass
             function.
    DISPDF = Compute the discrete uniform probability mass
             function.
    LOSPDF = Compute the lost games probability mass function.
    ARSPDF = Compute the arcsine probability density function.
    BETPDF = Compute the beta probability density function.
    UNIPDF = Compute the uniform probability mass function.
 
Reference:
    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 409-410.

    Feller (1957), "Introduction to Probability Theory",
    Third Edition, John Wiley and Sons, pp. 107-109.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    TITLE CASE ASIS
    TITLE Matching Probability Mass Function CR() ...
          (N = 50)
    LABEL CASE ASIS
    Y1LABEL Probability Mass
    X1LABEL X
    LINE BLANK
    SPIKE ON
    TIC OFFSET UNITS SCREEN
    TIC OFFSET 3 3
    PLOT MATPDF(X,50) FOR X = 0 1 50
 
-----MATPPF (LET)--------------------------------
 
MATPPF
 
Name:
    MATPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the classical matching percent point function.
 
Description:
    The classical matching distribution has the following
    probability mass function:

       p(x;k) = (1/X!)*SUM[i=1 to k-x][(-1)**i/i!]
                X = 0, 1, ..., k
 
    The cumulative distribution function is computed by summing
    the probability mass function.  The percent point function
    is the inverse of the cumulative distribution function and
    is obtained by computing the cumulative distribution function
    until the specified probability is reached.

Syntax:
    LET <y> = MATPPF(<p>,<k>)  <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, a number, or a parameter in the
              interval (0,1);
          <k> is a number or parameter that defines the upper limit
              of the matching distribution;
          <y> is a variable or a parameter (depending on what <x>
              is) where the computed ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MATPPF(0.95,20)
    LET Y = MATPPF(X,100)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Note:
    For sufficiently large values of k, the classical matching
    distribution can be accurately approximated with a Poisson
    distribution with lambda = 1.  Dataplot computes MATPPF from
    the above definition for values of k < 20.  For values of
    k >= 20, Dataplot computes MATPPF using the Poisson ppf
    with lambda = 1.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATCDF = Compute the matching cumulative distribution
             function.
    MATPDF = Compute the matching probability mass function.
    POIPDF = Compute the Poisson probability mass function.
    LCTPDF = Compute the leads in coin tossing probability mass
             function.
    DISPDF = Compute the discrete uniform probability mass
             function.
    LOSPDF = Compute the lost games probability mass function.
    ARSPDF = Compute the arcsine probability density function.
    BETPDF = Compute the beta probability density function.
    UNIPDF = Compute the uniform probability mass function.
 
Reference:
    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 409-410.

    Feller (1957), "Introduction to Probability Theory",
    Third Edition, John Wiley and Sons, pp. 107-109.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    TITLE CASE ASIS
    TITLE Matching Percent Point Function CR() ...
          (N = 50)
    LABEL CASE ASIS
    X1LABEL Probability
    Y1LABEL X
    LINE BLANK
    SPIKE ON
    TIC OFFSET UNITS SCREEN
    TIC OFFSET 3 3
    PLOT MATPPF(P,50) FOR P = 0  0.01  1
 
-----MATRIX (LET)-----------------------------------------------------
 
MATRIX
The following are DATAPLOT matrix commands:
    1-SAMPLE HOTELLING T-SQUARE  = Perform a 1-sample Hotelling
                          T-square test of a matrix.
    2-SAMPLE HOTELLING T-SQUARE  = Perform a 2-sample Hotelling
                          T-square test of a matrix.
    ... COLUMN DISTANCE = Compute the <EUCLIDEAN/MAHALANOBIS/
                           MINKOWSKY/CHEBYCHEV/BLOCK> column distance
                           of a matrix.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    DISTANCE FROM MEAN   = Compute the distance from the mean for
                           a matrix.
    LINEAR COMBINATION   = Compute the linear combination of a
                           matrix and a vector.
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADD ROW       = Add a row to a matrix.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX COLUMN SCALE  = Scale a matrix by columns.
    MATRIX COLUMN STAT   = Compute column statistics for a matrix.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DELETE ROW    = Delete a row from a matrix.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX DIMENSION     = Specify the size matrix that Dataplot can
                           accomodate.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX GROUP MEANS   = Compute group means for a matrix.
    MATRIX GROUP SD      = Compute group standard deviations for
                           a matrix.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MEAN          = Compute the mean of a matrix.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX ROW SCALE     = Scale a matrix by rows.
    MATRIX ROW STATISTIC = Compute row statistics for a matrix.
    MATRIX SCALE (SET)   = Define the type of Scaling for a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    POOLED VARIANCE-COVA MATRIX = Compute the pooled
                           variance-covariance matrix of a matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    QUADRATIC FORM       = Compute the quadratic form of a matrix
                           and a vector.
    READ MATRIX          = Read a matrix.
    ... ROW DISTANCE     = Compute the <EUCLIDEAN/MAHALANOBIS/
                           MINKOWSKY/CHEBYCHEV/BLOCK> row distance
                           of a matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
    TRIANGULAR SOLUTION  = Solve a triangular system of equations.
    TRIANGULAR INVERSE   = Compute the inverse of a triangular matrix.
    TRIDIAGONAL SOLUTION = Solve a tridiagonal system of equations.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    VECTOR TIMES TRANSPOSE = Compute X*X' for the vector X.
 
-----MATRIX ADDITION (LET)--------------------------------------------
 
MATRIX ADDITION
 
Name:
    MATRIX ADDITION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Add 2 matrices, a matrix and a vector, or a matrix and a parameter.
 
Description:
    Matrix addition is carried out by adding the corresponding elements
    of the two matrices.  If a parameter is added to a matrix, the
    parameter is added to each element of the matrix.  If a vector is
    added to a matrix, the vector is added to each column of the
    matrix (i.e., the corresponding rows are added).
 
Syntax 1: (2 matrices)
    LET <mat3> = MATRIX ADDITION <mat1> <mat2>
              <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix;
          <mat2> is a matrix;
          <mat3> is a matrix where the resulting matrix addition is
               saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Syntax 2: (a matrix and a parameter)
    LET <mat3> = MATRIX ADDITION <mat1> <par>
              <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix;
          <par> is a number or a parameter;
          <mat3> is a matrix where the resulting matrix addition is
               saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Syntax 3: (a matrix and a vector)
    LET <mat3> = MATRIX ADDITION <mat1> <var>
              <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix;
          <var> is a variable;
          <mat3> is a matrix where the resulting matrix addition is
               saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Examples:
    LET C = MATRIX ADDITION A B
    LET A = MATRIX ADDITION A 2
    LET C = MATRIX ADDITION A V
 
Note:
    Matrices to be added must have the same number of rows and columns.
    A matrix and a vector to be added must have the same number of
    rows.  An error message is printed if they do not.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    READ MATRIX A
    1 2 3
    4 5 6
    7 8 9
    END OF DATA
    READ MATRIX B
    1 1 1
    2 2 2
    3 3 3
    END OF DATA
    LET C = MATRIX ADDITION A B
    PRINT C
    The resulting matrix C contains:
       2  3  4
       6  7  8
      10 11 12
 
-----MATRIX ADD ROW (LET)----------------------------------------
 
MATRIX ADD ROW
 
Name:
    MATRIX ADD ROW (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Add a row to an existing matrix.
 
Description:
    It is sometimes convenient to add an observaton (i.e., a 
    row) to an already existing data matrix.  This command
    allows you to do that in a simple way.
 
Syntax:
    LET <mat2> = MATRIX ADD ROW <mat1>  <x>
    where <mat1> is the original data matrix;
          <x> is a vector containing the data values for the new
              row of data;
    and where <mat2> is the resulting  matrix.
 
    Note that <mat2> is typically the same as <mat1>.  Also, the
    number of rows in <x> should be equal to the number of 
    columns in <mat1>.

Examples:
    LET M = MATRIX ADD ROW M X
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    READ MATRIX               = Read a matrix.
    MATRIX COLUMN DIMENSION   = Dimension maximum number of columns
                                for Dataplot matrices.

    MATRIX DELETE ROW         = Delete a row from a matrix.
    MATRIX ROW                = Copy a row of a matrix to a column.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    1998/8
 
Program:
    READ MATRIX M
    1 2 3
    4 5 6
    7 8 9
    END OF DATA
    LET X = DATA 10 11 12
    LET M = MATRIX ADD ROW M X
    PRINT M
 
-----MATRIX ADJOINT (LET)--------------------------------------------
 
MATRIX ADJOINT
 
Name:
    MATRIX ADJOINT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the classical adjoint of a matrix.
 
Description:
    The classical adjoint of a matrix is the matrix of cofactors.  That
    is, if Bij is the determinant of matrix A with row i and column j
    omitted, then the cofactor of row i and column j is
    (-1)**(i+j)*Bij.
 
Syntax:
    LET <mat2> = MATRIX ADJOINT <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix;
          <mat2> is a matrix where the resulting matrix adjoint is
               saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Examples:
    LET C = MATRIX ADJOINT A
 
Note:
    Matrices for which the adjoint is computed  must have the same
    number of rows and columns.  An error message is printed if they
    do not.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Linear Algebra
 
Implementation Date:
    93/8
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
    16 16 19 21 20
    14 17 15 22 18
    24 23 21 24 20
    18 17 16 15 20
    18 11  9 18  7
    END OF DATA
    LET A = MATRIX ADJOINT X
    PRINT X A
 
-----MATRIX AUGMENT (LET)-----------------------------------------
 
MATRIX AUGMENT
 
Name:
    MATRIX AUGMENT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Append columns to a matrix.
 
Description:
    This command is most typically used to create a large matrix from
    a series of smaller ones.  For example, when creating a large
    system of linear equations, the variables may be stored in
    multiple files.
 
Syntax:
    LET <mat3> = MATRIX AUGMENT <mat1> <mat2>
    where <mat1> is a matrix with N1 columns;
          <mat2> is a matrix whose N2 columns will be appended to
                 <mat1>;
    and   <mat3> is a matrix with N1+N2 columns where the resulting
                 matrix is saved (it typically is the same name as
                 <mat1>, but this is not required).
 
Examples:
    .  Both A and B are matrices
    LET C = MATRIX AUGMENT A B
 
Note:
    Matrices are created with the READ MATRIX command or the MATRIX
    DEFINITION command.  Enter HELP READ MATRIX or HELP MATRIX
    DEFINITION for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
 
Applications:
    Linear Algebra
 
Implementation Date:
    93/10
 
Program:
    READ MATRIX MA
    1 2 3
    4 5 6
    7 8 9
    END OF DATA
    READ MATRIX MB
    10 11
    12 13
    14 15
    END OF DATA
    LET MA = MATRIX AUGMENT MA MB
    PRINT MA
 
-----MATRIX BIN (LET)--------------------------------
 
MATRIX BIN
 
Name:
    MATRIX BIN (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate s frequency table for the elements in a matrix.
 
Description:
    There are times when you may want to generate a histogram
    for all the elements in a matrix.  This command can
    help perform that task.

    The same rules that a histogram uses to determine classes
    apply to this command as well.

    Specifically, the default class widths are determined
    as follows:

       1) The defalt class width is 0.3 times the sample
          standard deviation.

       2) The lower class limit is the sample mean minus
          six times the sample standard deviation.

       3) The upper class limit is the sample mean plus
          six times the sample standard deviation.

    You can override these defaults with the commands

       CLASS WIDTH <value>
       CLASS LOWER <value>
       CLASS UPPER <value>
   
    The SET HISTOGRAM CLASS WIDTH lets you set several
    other alternatives for the default class width.


Syntax:
    LET <Y2> <X2> = MATRIX BIN <M>
    where <M> is a matrix;
          <X2> is a variable where the computed class mid-points
               are returned;
    and   <Y2> is a variable where the computed class frequencies
               are returned.

Examples:
    LET Y2 X2 = MATRIX BIN M

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    HISTOGRAM            = Generate a histogram.
    CLASS WIDTH          = Specify the class width for subsequent
                           histograms.
    CLASS LOWER          = Specify the lower limit for subsequent
                           histograms.
    CLASS UPPER          = Specify the upper limit for subsequent
                           histograms.
    SET HIST CLASS WIDTH = Specify alternative default class width
                           algorithms for subsequent histograms.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2006/3
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX SIGMA
    1.0     -0.707  0.0    0.0    0.0
    -0.707   1.0    0.5    0.5    0.5
    0.0      0.5    1.0    0.5    0.5
    0.0      0.5    0.5    1.0    0.5
    0.0      0.5    0.5    0.5    1.0
    END OF DATA
    .
    LET MU = DATA 0 0 0 0 0
    LET N = 200
    LET M = MULTIVARIATE NORMAL RANDOM NUMBERS MU SIGMA N
    .
    LET Y2 X2 = MATRIX BIN M
    HISTOGRAM Y2 X2

-----MATRIX COFACTOR (LET)--------------------------------------------
 
MATRIX COFACTOR
 
Name:
    MATRIX COFACTOR (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the matrix cofactors of a matrix.
 
Description:
    If Bij is the determinant of matrix A with row i and column j
    omitted, then the cofactor of row i and column j is (-1)**(i+j)*Bij
    (the Bij are called the minors).
 
Syntax:
    LET <param> = MATRIX COFACTOR <mat1> <rowid> <colid>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which a cofactor is to be computed;
          <rowid> is the row of <mat1> for which a cofactor is to be
                  computed;
          <colid> is the column of <mat1> for which a cofactor is to be
                  computed;
          <param> is a parameter where the computed cofactor is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                  rarely used in this context).
 
Examples:
    LET C = MATRIX COFACTOR A 2 3
 
Note:
    Matrices for which cofactors are computed  must have the same
    number of rows and columns.  An error message is printed if they do
    not.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
    16 16 19 21 20
    14 17 15 22 18
    24 23 21 24 20
    18 17 16 15 20
    18 11  9 18  7
    END OF DATA
    LET NROW = MATRIX NUMBER OF ROWS X
    LET NCOL = MATRIX NUMBER OF COLUMNS X
    LOOP FOR J = 1 1 NCOL
        LOOP FOR I = 1 1 NROW
            LET B = MATRIX COFACTOR X I J
            LET TEMP(^I) = B
        END OF LOOP
        LET A^J = TEMP
    END OF LOOP
    LET A = MATRIX DEFINITION A1 NROW NCOL
    PRINT A
 
-----MATRIX COLUMN STATISTIC (LET)--------------------------------
 
MATRIX COLUMN STATISTIC
 
Name:
    MATRIX COLUMN STATSITIC (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute a user specified statistic for the columns of a matrix.
 
Description:
    The resulting computed statistics are saved in array.  The
    first row of the array is the statistic for column 1, the
    second row of the array is the statistic for column 2, and
    so on.
 
Syntax:
    LET <y> = MATRIX COLUMN <stat> <mat>
                            <SUBSET/EXCEPT/FOR qualification>
    where <mat> is a matrix for which the column statistic is
                to be computed;
          <stat> is the desired statistic to compute;
          <y> is a variable where the resulting column statistic
                is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    The specified statistic can be any of the following:
        MEAN, MIDMEAN, MEDIAN, TRIMMED MEAN, WINSORIZED MEAN,
        GEOMETRIC MEAN, HARMONIC MEAN, HODGES LEHMAN,
        BIWEIGHT LOCATION,
        SUM, PRODUCT, SIZE (or NUMBER or SIZE),
        STANDARD DEVIATION, STANDARD DEVIATION OF MEAN,
        VARIANCE, VARIANCE OF THE MEAN,
        TRIMMED MEAN STANDARD ERROR,
        AVERAGE ABSOLUTE DEVIATION (or AAD),
        MEDIAN ABSOLUTE DEVIATION (or MAD),
        IQ RANGE, BIWEIGHT MIDVARIANCE, BIWEIGHT SCALE,
        PERCENTAGE BEND MIDVARIANCE,
        WINSORIZED VARIANCE, WINSORIZED STANDARD DEVIATION,
        RELATIVE STANDARD DEVIATION, RELATIVE VARIANCE (or
           COEFFICIENT OF VARIATION),
        RANGE, MIDRANGE, MAXIMUM, MINIMUM, EXTREME,
        LOWER HINGE, UPPER HINGE, LOWER QUARTILE, UPPER QUARTILE,
        <FIRST/SECOND/THIRD/FOURTH/FIFTH/SIXTH/SEVENTH/EIGHTH/
            NINTH/TENTH> DECILE,
        PERCENTILE, QUANTILE, QUANTILE STANDARD ERROR,
        SKEWNESS, KURTOSIS, NORMAL PPCC,
        AUTOCORRELATION, AUTOCOVARIANCE,
        SINE FREQUENCY, SINE AMPLITUDE,
        CP, CPK, CNPK, CPM, CC,
        EXPECTED LOSS, PERCENT DEFECTIVE,
        TAGUCHI SN0 (or SN), TAGUCHI SN+ (or SNL),
        TAGUCHI SN- (or SNS), TAGUCHI SN00 (or SN2);

Examples:
    LET MMEAN = MATRIX COLUMN MEAN M
    LET MMEAN = MATRIX COLUMN MEDIAN M
    LET MMEAN = MATRIX COLUMN MEDIAN M  SUBSET TAG = 1 TO 2
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    Statistics for the rows of a matrix can be computed
    using the MATRIX ROW STATISTIC command.  Enter
    HELP MATRIX ROW STATISTIC for details.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ROW STATISTIC      = Compute row statistics for a matrix.
    MATRIX COLUMN DIMENSION   = Dimension maximum number of columns
                                for Dataplot matrices.
 
Reference:
    "Applied Multivariate Statistical Analysis", Third Edition,
    Johnson and Wichern, Prentice-Hall, 1992.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    1998/8
    2002/8: List of supported statistics expanded.
 
Program:
    SKIP 25
    READ MATRIX IRIS.DAT M
    LET YM = MATRIX COLUMN MEANS M
    LET YSD = MATRIX COLUMN SD M
    SET WRITE DECIMALS 3
    PRINT YM YSD

-----MATRIX COMBINE COLUMNS (LET)----------------------------------------
 
MATRIX COMBINE COLUMNS
 
Name:
    MATRIX COMBINE COLUMNS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Combine two matrices by columns.
 
Description:
    It is sometimes convenient to extend the columns of one matrix
    with the columns of another matrix.
 
    For example, given the matrices

        M1 = | 1   2 |
             | 3   4 |

    and

        M2 = | 5   6 |
             | 7   8 |

    this command will generate the matrix

        M3 = | 1   2  5  6 |
             | 3   4  7  8 |

    This command requires that the two input matrices have the
    same number of rows.

Syntax:
    LET <m3> = MATRIX COMBINE COLUMNS <m1>  <m2>
    where <m1> is the first input matrix;
          <m2> is the second input matrix;
    and where <m3> is the resulting  matrix.
 
    Note that <m3> can be the same name as either <m1> or <m2>.

Examples:
    LET M3 = MATRIX COMBINE COLUMNS M1 M2
    LET MOUT = MATRIX COMBINE COLUMNS M1 M2
 
Note:
    Matrices can be created with the READ MATRIX, CREATE MATRIX or
    MATRIX DEFINITION commands.
 
Default:
    None
 
Synonyms:
    MATRIX AUGMENT
 
Related Commands:
    MATRIX COMBINE ROWS       = Combine the rows of two matrices.
    READ MATRIX               = Read a matrix.
    CREATE MATRIX             = Create a matrix from existing columns.
    MATRIX COLUMN DIMENSION   = Dimension maximum number of columns
                                for Dataplot matrices.

Applications:
    Multivariate Analysis
 
Implementation Date:
    2011/1
 
Program:
    dimension 100 columns
    .
    read matrix m1
    1 2
    3 4
    end of data
    .
    read matrix m2
    5 6
    7 8
    end of data
    .
    let m3 = matrix combine columns m1 m2
    .
    set write decimals 0
    print m3
 
-----MATRIX COMBINE ROWS (LET)----------------------------------------
 
MATRIX COMBINE ROWS
 
Name:
    MATRIX COMBINE ROWS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Combine two matrices by rows.
 
Description:
    It is sometimes convenient to extend the rows of one matrix
    with the rows of another matrix.
 
    For example, given the matrices

        M1 = | 1   2 |
             | 3   4 |

    and

        M2 = | 5   6 |
             | 7   8 |

    this command will generate the matrix

        M3 = | 1   2 |
             | 3   4 |
             | 5   6 |
             | 7   8 |

    This command requires that the two input matrices have the
    same number of columns.

Syntax:
    LET <m3> = MATRIX COMBINE ROWS <m1>  <m2>
    where <m1> is the first input matrix;
          <m2> is the second input matrix;
    and where <m3> is the resulting  matrix.
 
    Note that <m3> can be the same name as either <m1> or <m2>.

Examples:
    LET M3 = MATRIX COMBINE ROWS M1 M2
    LET MOUT = MATRIX COMBINE ROWS M1 M2
 
Note:
    Matrices can be created with the READ MATRIX, CREATE MATRIX or
    MATRIX DEFINITION commands.
 
Default:
    None
 
Synonyms:
    MATRIX COMBINE ROW
 
Related Commands:
    MATRIX COMBINE COLUMNS    = Combine the columns of two matrices.
    READ MATRIX               = Read a matrix.
    CREATE MATRIX             = Create a matrix from existing columns.
    MATRIX DIMENSION          = Dimension maximum number of rows or
                                columns for Dataplot matrices.
    MATRIX ADD ROW            = Add a single row to a matrix.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    2011/1
 
Program:
    dimension 100 columns
    .
    read matrix m1
    1 2
    3 4
    end of data
    .
    read matrix m2
    5 6
    7 8
    end of data
    .
    let m3 = matrix combine row m1 m2
    .
    set write decimals 0
    print m3
 
-----MATRIX CONDITION NUMBER (LET)-------------------------------------
 
MATRIX CONDITION NUMBER
 
Name:
    MATRIX CONDITION NUMBER (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the condition number (or the reciprocal of the condition
    number) of a matrix.
 
Description:
    The determinant, the matrix inverse, and the solution to a
    system of equations are all closely related.  Each of these
    can be calculated from the LU decomposition of a matrix.
 
    For each of these, the condition number gives a bound on the
    accuracy that can be obtained (this does not include the effects
    of round-off error, algorithm choice, or the floating point
    accuracy of the computer) for finding the matrix inverse, the
    determinant, or solving a system of equations.

    A rule of thumb is that if the condition number is approximately
    10**(d), then the elements of the LU decomposed matrix generally
    have d fewer significant digits than the original matrix.

    A matrix with high condition numbers are referred to as
    ill-conditioned matrix and a matrix with a low condition number
    is referred to a well-conditioned matrix.

    Some analysts prefer to use the reciprocal of the condition
    number (see Syntax 2 below).

Syntax 1:
    LET <par> = MATRIX CONDITION NUMBER <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the condition number is to be
                 computed;
          <par> is a parameter where the resulting condition number is
                 saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Syntax 2:
    LET <par> = MATRIX RECIPROCAL CONDITION NUMBER <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the reciprocal of the condition
                 number is to be computed;
          <par> is a parameter where the resulting reciprocal of the
                 condition number is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET C = MATRIX CONDITION NUMBER A
    LET C = MATRIX RECIPROCAL CONDITION NUMBER A
 
Note:
    Matrices for which a condition number is to be computed  must
    have the same number of rows and columns.  An error message is
    printed if they do not.
 
Note:
    Matrices are created with either the READ MATRIX, CREATE MATRIX, or
    the MATRIX DEFINITION command.  Enter HELP READ MATRIX, HELP CREATE
    MATRIX, or HELP MATRIX DEFINITION for details.
 
Note:
    DATAPLOT uses the LINPACK routine SGECO to compute the condition
    number.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX DETERMINANT   = Compute the determinant of a matrix.
    MATRIX SOLUTION      = Solve a system of linear equations.
 
Reference:
    Dongarra, Bunch, Moler, Stewart (1979), "LINPACK User's Guide,"
    Siam.

Applications:
    Linear Algebra
 
Implementation Date:
    2011/9
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
    16 16 19 21 20
    14 17 15 22 18
    24 23 21 24 20
    18 17 16 15 20
    18 11  9 18  7
    END OF DATA
    LET C  = MATRIX CONDITION NUMBER X
    LET RC = MATRIX RECIPROCAL CONDITION NUMBER X
    SET WRITE DECIMALS 2
    PRINT C RC
 
-----MATRIX CORRELATION DIRECTION (SET)-----------------------------
 
MATRIX CORRELATION DIRECTION
 
Name:
    MATRIX <CORRELATION/COVARIANCE> DIRECTION (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify whether correlation (or covariance) matrices are
    computed based on column-wise or row-wise correlations
    (covariances).
 
Description:
    Given a nxp matrix, the CORRELATION MATRIX command computes
    all the column-wise correlations.  This results in a
    kxk correlation matrix.

    There may be situations in which you are interested in the
    row-wise correlations (which results in a nxn correlation
    matrix).  This command allows you to specify which of
    these cases to compute.

Syntax 1:
    SET MATRIX CORRELATION DIRECTION  <COLUMN/ROW>
    where COLUMN specifies subsequent correlation matrices will
          be based on column-wise correlations and ROW specifies
          they will be based on row-wise correlations.
 
    This syntax is used to specify the column/row direction
    for subsequent correlation matrices.

Syntax 2:
    SET MATRIX COVARIANCE DIRECTION  <COLUMN/ROW>
    where COLUMN specifies subsequent covariance matrices will
          be based on column-wise covariances and ROW specifies
          they will be based on row-wise covariances.
 
    This syntax is used to specify the column/row direction
    for subsequent covariance matrices.

Examples:
    SET MATRIX CORRELATION DIRECTION ROW
    SET MATRIX CORRELATION DIRECTION COLUMN
    SET MATRIX COVARIANCE DIRECTION ROW
    SET MATRIX COVARIANCE DIRECTION COLUMN

Default:
    Correlation and covariance matrices are computed column-wise.
 
Synonyms:
    None
 
Related Commands:
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    COVARIANCE MATRIX    = Compute the covariance matrix of a matrix.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    2004/11
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX C
    -6.07 -4.83 -5.15 -5.96 -4.61 -4.35 -4.21 -5.71 -4.54 -3.26
    -0.04 -0.72 -0.25 -1.56 -0.21 -0.79 -0.02 -1.42 -0.01 -1.47
     4.79  5.76  5.47  4.19  5.08  5.70  6.10  3.99  4.64  4.31
    END OF DATA
    SET MATRIX CORRELATION DIRECTION ROW
    LET CORR = CORRELATION MATRIX C
    SET WRITE FORMAT 3F6.2
    PRINT CORR

    This results in the following output:

      1.00  0.03  0.31
      0.03  1.00  0.59
      0.31  0.59  1.00

-----MATRIX DIAGONAL (LET)------------------------------------------
 
MATRIX DIAGONAL
 
Name:
    MATRIX DIAGONAL (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Extract the matrix diagonal and save it in a variable.
 
Syntax:
    LET <v> = MATRIX DIAGONAL <m1> <SUBSET/EXCEPT/FOR qualification>
    where <m1> is a square matrix of dimension N;
          <v> is a variable where the matrix diagonals are saved (it
                will have length N);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Examples:
    LET S = MATRIX DIAGONAL M
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    DIAGONAL MATRIX      = Create a diagonal matrix.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Linear Algebra
 
Implementation Date:
    93/10
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
     1.55 1.26 1.41  1.78
     3.39 3.47 2.82  3.89
     1.95 1.91 1.74  2.29
    10.47 9.12 9.55 17.78
     1.45 1.51 1.41  1.70
     3.72 3.55 3.09  4.27
     4.47 4.07 3.98  4.47
    END OF DATA
    LET S = VARIANCE-COVARIANCE MATRIX X
    LET VAR = MATRIX DIAGONAL S
    PRINT VAR
 
-----MATRIX DEFINITION (LET)-----------------------------------------
 
MATRIX DEFINITION
 
Name:
    MATRIX DEFINITION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Define a new matrix from a previously created matrix or a group of
    previously created variables.
 
Description:
    The columns of a matrix are identified by appending a column number
    to the matrix name (e.g., matrix C would have columns C1, C2, and
    so on).  The matrix definition command allows you to take variables
    (C1, C2, and so on) and put them in a matrix.
 
    One caution is that DATAPLOT assumes that the columns to be placed
    in the matrix are stored contiguously (variables are stored in the
    order that they are created).  If this assumption is not valid, you
    can get unpredictable results.  To get around this problem, you
    can do something like the following:
        WRITE JUNK.DAT X1 X2 X3
        DELETE X1 X2 X3
        READ JUNK.DAT X1 X2 X3
    This code sample will now store X1, X2, and X3 in contiguous
    positions.
 
Syntax 1:
    LET <mat> = MATRIX DEFINITION <var> <rows> <cols>
               <SUBSET/EXCEPT/FOR qualification>
    where <var> is a is a variable that defines the first column of the
                matrix;
          <rows> is a number or parameter that defines the number of
                rows to use in the variables (should be less than or
                equal to number of rows in <var>);
          <cols> is a number or parameter that defines the variables to
                use (e.g., if <var> is A1 and <cols> is 3, then A1, A2,
                and A3 should already exist and they will make up the
                columns of <mat>);
          <mat> is a matrix where the resulting matrix is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                rarely used in this context).
 
    This syntax copies from column 1 to column <cols> and from row 1 to
    row <rows>.
 
Syntax 2:
    LET <mat> = MATRIX DEFINITION <mat2> <rows> <cols>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat2> is a matrix from which another matrix is created
                 (starts at position (1,1) of <mat2>);
          <rows> is a number or parameter that defines the number of
                 rows to use in <mat2>;
          <cols> is a number or parameter that defines the number of
                 columns to use in <mat2>;
          <mat> is a matrix where the resulting matrix is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (rarely
                 used in this context).
 
    This syntax copies the <cols> columns starting with <var> (stored
    in the order the variables were created, not alphabetically) and
    from row 1 to row <rows>.
 
Syntax 3:
    LET <mat> = MATRIX DEFINITION <var> <rows> <cols> <row1>
               <SUBSET/EXCEPT/FOR qualification>
    where <var> is a is a variable that defines the first column of the
                matrix;
          <rows> is a number or parameter that defines the last row of
                 <mat2> to use;
          <rows> is a number or parameter that defines the number of
                rows to use in the variables (should be less than or
                equal to number of rows in <var>);
          <cols> is a number or parameter that defines the variables to
                use (e.g., if <var> is A1 and <cols> is 3, then A1, A2,
                and A3 should already exist and they will make up the
                columns of <mat>);
          <row1> is a number or parameter that defines the first row of
                 <mat2> to use;
          <mat> is a matrix where the resulting matrix is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                rarely used in this context).
 
    This syntax copies the <cols> columns starting with <var> (stored
    in the order the variables were created, not alphabetically) and
    from row <row1> to row <rows>.
 
Syntax 4:
    LET <mat> = MATRIX DEFINITION <mat2> <rows> <cols> <row1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat2> is a matrix from which another matrix is created
                 (starts at position (1,1) of <mat2>);
          <rows> is a number or parameter that defines the last row of
                 <mat2> to use;
          <cols> is a number or parameter that defines the number of
                 columns to use in <mat2>;
          <row1> is a number or parameter that defines the first row of
                 <mat2> to use;
          <mat> is a matrix where the resulting matrix is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (rarely
                 used in this context).
 
    This syntax copies from column 1 to column <cols> and from row
    <row1> to row <rows>.  It is useful for generating a partitioned
    matrix.
 
Examples:
    LET C = MATRIX DEFINITION A1 4 4
    LET C = MATRIX DEFINITION FACT1 10 3
    LET C = MATRIX DEFINITION M 10 3
 
Note:
    Matrices can also be created with the READ MATRIX command.  Enter
    HELP READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    READ X Y
    -99 -99
    1 0
    0 1
    -1 0
    END OF DATA
    LET C1 = X**2 + Y**2
    LET C2 = X
    LET C3 = Y
    LET C4 = 1 FOR I = 1 1 4
    LET A = MATRIX DEFINITION C1 4 4
    PRINT A
 
-----MATRIX DELETE ROW (LET)----------------------------------------
 
MATRIX DELETE ROW
 
Name:
    MATRIX DELETE ROW (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Delete a row from an existing matrix.
 
Description:
    It is sometimes convenient to delete an observaton (i.e., a 
    row) to an already existing data matrix.  This command
    allows you to do that in a simple way.
 
Syntax:
    LET <mat2> = MATRIX DELETE ROW <mat1>  <rowid>
    where <mat1> is the original data matrix;
          <rowid> is a number or parameter that specifies which
              row of the matrix is to be deleted;
    and where <mat2> is the resulting  matrix.
 
    Note that <mat2> is typically the same as <mat1>.

Examples:
    LET M = MATRIX DELETE ROW M X
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    READ MATRIX               = Read a matrix.
    MATRIX COLUMN DIMENSION   = Dimension maximum number of columns
                                for Dataplot matrices.

    MATRIX ADD ROW            = Add a row to a matrix.
    MATRIX ROW                = Copy a row of a matrix to a column.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    1998/8
 
Program:
    READ MATRIX M
    1 2 3
    4 5 6
    7 8 9
    END OF DATA
    LET M = MATRIX DELETE ROW M 2
    PRINT M
 
-----MATRIX DETERMINANT (LET)----------------------------------------
 
MATRIX DETERMINANT
 
Name:
    MATRIX DETERMINANT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the determinant of a matrix.
 
Description:
    The determinant of an NxN matrix A is defined as--
       det A = A11a1 - A12a2 + A13a3 - ... - (-1)**(N+1)*A1nan
    where A1j is the entry in row 1 and column j of A and aj is the
    determinant of the matrix obtained by omitting the first row and
    column j of A.  This is a recursive definition.  The determinant of
    a 2x2 matrix:
            [a  b]
            [c  d]
    is ab - cd.
 
    A determinant of zero means that a matrix is singular and does not
    have an inverse.  Values close to zero indicate that a matrix is
    near singular (and that there may be numerical difficulties in
    calculating the inverse).
 
    In practice, the determinant, the matrix inverse, and the solution
    to a system of equations are all closely related.  Each of these
    can be calculated from the LU decomposition of a matrix.  After a
    LU decomposition, the determinant is simply the product of the
    diagonal elements of the LU decomposed matrix.
 
Syntax:
    LET <param> = MATRIX DETERMINANT <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the determinant is to be
                 computed;
          <param> is a parameter where the resulting determinant is
                 saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET C = MATRIX DETERMINANT A
 
Note:
    Matrices for which a determinant is to be computed  must have the
    same number of rows and columns.  An error message is printed if
    they do not.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Note:
    DATAPLOT uses LINPACK routines to calculate the LU decomposition
    (versions prior to 7/93 use the LUDCMP and LUBKSB routines from
    the Numerical Recipes book).
 
    The reciprocal of the condition number is printed.  This number
    gives an indication of the numerical accuracy that was obtained
    when calculating the determinant.  If this number is approximately
    10**(-d), then the elements of the LU decomposed matrix generally
    have d fewer significant digits than the original matrix.  If this
    number is effectively zero, then DATAPLOT does not try to compute
    the determinant.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    "LINPACK User's Guide", Dongarra, Bunch, Moler, Stewart.  Siam,
    1979.
 
    "Numerical Recipes: The Art of Scientific Programming (FORTRAN
    Version)", Press, Flannery, Teukolsky, and Vetterling.  Cambridge
    University Press, 1989 (chapter 2).
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
    16 16 19 21 20
    14 17 15 22 18
    24 23 21 24 20
    18 17 16 15 20
    18 11  9 18  7
    END OF DATA
    LET A = MATRIX DETERMINANT X
    PRINT A
 
-----MATRIX DIMENSION------------------------------------------------
 
MATRIX DIMENSION
 
Name:
    MATRIX DIMENSION
 
Type:
    Support Command
 
Purpose:
    Specifies the row and column dimensions for matrix operations.
 
Description:
    The matrix operations were significantly rewritten 1998/5
    to make better use of scratch storage.  This significantly
    increased the size matrices Dataplot can handle.

    There are 920,000/3 = 306,666 elements for temporary matrices
    when performing matrix manipulations.  The default is to
    use 3,000 rows and 100 columns.  The largest square matrix
    is about 550x550.

    The MATRIX DIMENSION allows you to modify the rows and
    columns for the temporary matrices.  The number of rows cannot
    be set greater than the maximum number of rows for a variable
    (set to 20,000 on the default implementation).

    Since this command only dimensions temporary matrices during
    the computations, you can enter this command as often as you
    wish during a single Dataplot session.

Syntax 1:
    MATRIX DIMENSION COLUMNS   <ncols> 
    where <ncols> is a number or parameter that specifies the
             maximum number of columns for the temporary matrices.
 
Syntax 2:
    MATRIX DIMENSION ROWS  <nrows>
    where <nrows> is a number or parameter that specifies the
             maximum number of rows for the temorary matrices.
 
Examples:
    MATRIX DIMENSION ROWS 2000
    MATRIX DIMENSION COLUMNS 500
 
Default:
    The default is 3,000 rows by 100 columns.
 
Synonyms:
    None
 
Related Commands:
    DIMENSION  = Dimension the Dataplot workspace.
    STATUS     = Displays dimension, variables, parameters, functions,
                 etc.
    PROBE      = Displays the value of an internal variable.
    SET        = Sets the value of an internal variable.
 
Applications:
    Data Manipulation
 
Implementation Date:
    1998/5
 
Program:
    MATRIX DIMENSION 550 COLUMNS
    LET Y = NORM RAND NUMB FOR I = 1 1 500
    LET D = DIAGNONAL MATRIX Y
 
-----MATRIX DISTANCE (LET)----------------------------------------
 
MATRIX DISTANCE
 
Name:
    MATRIX DISTANCE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the distance matrix of a matrix.
 
Description:
    Dataplot can compute the distances relative to either rows
    or columns.

    Given an nxp data matrix X, we compute a distance matrix D.
    For row distances, the D(ij) element of the distance matrix
    is the distance between row i and row j, which results in a
    nxn D matrix.  For column distances, the D(ij) element of the
    distance matrix is the distance between column i and column j,
    which results in a pxp D matrix.

    Five distance metrics are available.

      1) The Euclidean row distance is defined as

           D(ij) = SQRT(SUM(X(ik) - X(jk))**2)
   
         where the summation is relative to k over columns 1 to p.

         The Euclidean column distance is defined as

           D(ij) = SQRT(SUM(X(ki) - X(kj))**2)

         where the summation is relative to k over rows 1 to n.

         The Euclidean distance is simply the square root of the
         squared differences between corresponding elements of
         the rows (or columns).  This is probably the most 
         commonly used distance metric.

      2) The Mahalanobis row distance is defined as

           D(ij) = SQRT[(X(i) - X(j))'SINV(X(i) - X(j))]
   
         where SINV is the variance-covariance matrix of X.
         The row distances are obtained by letting X(i) and X(j)
         represent the ith and jth row while the column distances
         are obtained by letting X(i) and X(j) represent the ith
         and jth columns.

         The Mahalanobis distance is is effectively a weighted
         Euclidean distance where the weighting is determined
         by the sample variance-covariance matrix.

      3) The Minkowsky row distance is defined as

             Dij=SUM(ABS|(X(ik) - X(jk))|**P)**(1/P)
    
         The sum is from k = 1 to the number of columns.  The
         column distance is similar, but the summation is over
         the number of rows rather than the number of columns.


         The Minkowsky distance is the pth root of the sum of
         the absolute differences to the pth power between
         corresponding elements of the rows (or columns).
         The Euclidean distance is the special case of P=2.

      4) The block row distance is defined as

             Dij=SUM(ABS|(X(ik) - X(jk))|)
    
         The sum is from k = 1 to the number of columns.  The
         column distance is similar, but the summation is over
         the number of rows rather than the number of columns.


         The block distance is the sum of the absolute differences
         between corresponding elements of the rows (or columns).
         Note that this is a special case of the Minkowsky
         distance with p=1.

         The block distance is also known as the city block or
         Manhattan distance.

      5) The Chebychev row distance is defined as

             Dij=MAX(ABS|(X(ik) - X(jk))|)
    
         The maximum is over the number of columns.  The column distance
         is similar, but the maximum is over the rows rather than the
         columns.

    The 2018/10 version of Dataplot added the following
    additional distances

      6) The cosine row similarity is defined as
 
            Cosine Similarity = SUM[k=1 to n][X(ik)*Y(jk)]/
                                {SQRT(SUM{k=1 to n][X(ik)**2])*
                                SQRT(SUM{k=1 to n][Y(jk)**2])}

         The cosine distance is then defined as

            Cosine Distance = 1 - Cosine Similarity

         The cosine distance above is defined for positive values
         only.  It is also not a proper distance in that the Schwartz
         inequality does not hold.  However, the following angular
         definitions are proper distances:

           angular cosine distance = fact*ACOS(cosine similarity)/PI
           angular cosine similarty = 1 - angular cosine distance

          with ACOS designating the arccosine function and where
          fact = 2 if there are no negative values and fact = 1 if
          there are negative values.

          If negative values are encountered in the input, the
          cosine distances will not be computed.  However, the
          cosine similarities will be computed.

           The column distance and similarity are defined similarly, but
           the summations are over the rows rather than the columns.

      7) The Canberra row distance is defined as

             D(ij) = SUM[k=1 to n][(|X(ik) - Y(jk)|)/(|X(ik)| + |Y(jk)|)]

           The column distance is similar, but the summation is over the
           rows rather than the columns.

           The Canberra distance is a weighted version of the block
           (Manhattan) distance.

      8) The Jaccard similarity is defined as

             S(ij) = SUM[k=1 to n][MIN(X(ik),Y(jk))/
                     SUM[k=1 to n][MAX(X(ik),Y(jk))]

          Then the Jaccard distance is defined as

             D = 1 - Jaccard Similarity

           The Jaccard column distance and similarity are defined
           similarly, but the summation is over the rows rather than
           the columns.

      9) The Pearson row distance is defined as

             D(ij) = (1 - R(ij))/2  where R is the correlation coefficient
                                    between rows i and j

         The Pearson row similarity is then defined as

             S(ij) = 1 - D(ij)

         The Pearson column distance and similarity are defined
         similarly, but the correlation is over the rows rather than
         the columns.

     10) The Hamming distance is defined as

             D(ij) = number of elements that differ between rows i and j

    Many multivariate techniques are based on distance matrices.
 
Syntax 1:
    LET <mat2> = <type> ROW DISTANCE <mat1>
    where <mat1> is a matrix for which the matrix distance is to
              be computed;
          <type> is EUCLIDEAN, MAHALANOBIS, MINKOWSKY, BLOCK,
              CHEBYCHEV, CANBERRA, JACCARD, PEARSON, COSINE,
              ANGULAR COSINE, or HAMMING and defines the type
              of distance to compute;
    and where <mat2> is a matrix where the resulting distance 
             matrix is saved.
 
    This syntax computes row distances.

Syntax 2:
    LET <mat2> = <type> COLUMN DISTANCE <mat1>
    where <mat1> is a matrix for which the matrix distance is to
              be computed;
          <type> is EUCLIDEAN, MAHALANOBIS, MINKOWSKY, BLOCK,
              CHEBYCHEV, CANBERRA, JACCARD, PEARSON, COSINE,
              ANGULAR COSINE, or HAMMING and defines the type
              of distance to compute;
    and where <mat2> is a matrix where the resulting distance 
             matrix is saved.
 
    This syntax computes column distances.

Syntax 3:
    LET <mat2> = <type> ROW SIMILARITY <mat1>
    where <mat1> is a matrix for which the matrix similarity is to
              be computed;
          <type> is JACCARD, COSINE, or ANGULAR COSINE and defines
              the type of similarity to compute;
    and where <mat2> is a matrix where the resulting similarity 
             matrix is saved.
 
    This syntax computes row similarities.

Syntax 4:
    LET <mat2> = <type> COLUMN SIMILARITY <mat1>
    where <mat1> is a matrix for which the matrix similarity is to
              be computed;
          <type> is JACCARD, COSINE, or ANGULAR COSINE and defines
              the type of similarity to compute;
    and where <mat2> is a matrix where the resulting similarity
             matrix is saved.
 
    This syntax computes column similarities.

Examples:
    LET D = EUCLIDEAN ROW DISTANCE M
    LET D = EUCLIDEAN COLUMN DISTANCE M
 
    LET D = BLOCK ROW DISTANCE M
    LET D = BLOCK COLUMN DISTANCE M
 
    LET D = MAHALANOBIS ROW DISTANCE M
    LET D = MAHALANOBIS COLUMN DISTANCE M
 
    LET P = 1.5
    LET D = MINKOWSKY ROW DISTANCE M
    LET D = MINKOWSKY COLUMN DISTANCE M
 
    LET D = COSINE ROW DISTANCE M
    LET D = COSINE COLUMN DISTANCE M
 
    LET D = COSINE ROW SIMILARITY M
    LET D = COSINE COLUMN SIMILAITY M
 
    LET D = JACCARD ROW DISTANCE M
    LET D = JACCARD COLUMN DISTANCE M
 
    LET D = JACCARD ROW SIMILARITY M
    LET D = JACCARD COLUMN SIMILAITY M
 
    LET D = PEARSON ROW DISTANCE M
    LET D = PEARSON COLUMN DISTANCE M
 
    LET D = PEARSON ROW SIMILARITY M
    LET D = PEARSON COLUMN SIMILARITY M
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    For the Minkowsky distance, you need to specify the value of
    P.  This is done by entering the following command before
    entering the MINKOWSKY DISTANCE command:

        LET P = <value>

Note:
    It is often desirable to scale the matrix before computing
    the distances.  Dataplot provides several scaling options.
    Enter HELP MATRIX SCALE for details.

Note:
    The correlation matrix and covariance matrix can be 
    considered distance matrices as well.  

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    READ MATRIX                  = Read a matrix.
    CREATE MATRIX                = Create a matrix from columns of
                                   data.
    MATRIX COLUMN DIMENSION      = Dimension maximum number of
                                   columns for Dataplot matrices.

    CORRELATION MATRIX           = Compute the correlation matrix.
    VARIANCE-COVARIANCE MATRIX   = Compute the correlation matrix.
    DISTANCE FROM MEAN           = Compute the distance from the
                                   mean for a matrix.
 
References:
    "Graphical Exploratory Data Analysis", Du Toit, Steyn, and
    Stumpf, Springer-Verlang, 1986, pp. 74-77.

    "Applied Multivariate Statistical Analysis", Third Edition,
    Johnson and Wichern, Prentice-Hall, 1992.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    1998/08
    2018/10: Added COSINE DISTANCE
    2018/10: Added COSINE SIMILARITY
    2018/10: Added ANGULAR COSINE DISTANCE
    2018/10: Added ANGULAR COSINE SIMILARITY
    2018/10: Added JACCARD DISTANCE
    2018/10: Added JACCARD SIMILARITY
    2018/10: Added PEARSON DISTANCE
    2018/10: Added PEARSON SIMILARITY
    2018/10: Added CANBERRA DISTANCE
    2018/10: Added HAMMING DISTANCE
 
Program:
    dimension 100 columns
    set write decimals 4
    set read missing value -999
    .
    let iflag1 = 1
    . let iflag1 = 2
    . let iflag1 = 3
    . let iflag1 = 4
    . let iflag1 = 5
    . let iflag1 = 6
    . let iflag1 = 7
    . let iflag1 = 8
    . let iflag1 = 9
    . let iflag1 = 10
    . let iflag1 = 11
    let iflag2 = 1
    . let iflag2 = 2
    .
    skip 25
    read matrix iris.dat x
    .
    if iflag1 = 1
       if iflag2 = 1
          let v = euclidean column distance x
       else if iflag2 = 2
          let v = euclidean row distance x
       end of if
    else if iflag1 = 2
       if iflag2 = 1
          let v = block column distance x
       else if iflag2 = 2
          let v = block row distance x
       end of if
    else if iflag1 = 3
       let p = 1.5
       if iflag2 = 1
          let v = minkowski column distance x
       else if iflag2 = 2
          let v = minkowski row distance x
       end of if
    else if iflag1 = 4
       if iflag2 = 1
          let v = chebychev column distance x
       else if iflag2 = 2
          let v = chebychev row distance x
       end of if
    else if iflag1 = 5
       if iflag2 = 1
          let v = jaccard column distance x
       else if iflag2 = 2
          let v = jaccard row distance x
       end of if
    else if iflag1 = 6
       if iflag2 = 1
          let v = jaccard column similarity x
       else if iflag2 = 2
          let v = jaccard row similarity x
       end of if
    else if iflag1 = 7
       if iflag2 = 1
          set isubro cdis
          let v = cosine column distance x
          set isubro
       else if iflag2 = 2
          let v = cosine row distance x
       end of if
    else if iflag1 = 8
       if iflag2 = 1
          let v = cosine column similarity x
       else if iflag2 = 2
          let v = cosine row similarity x
       end of if
    else if iflag1 = 9
       if iflag2 = 1
          let v = hamming column distance x
       else if iflag2 = 2
          let v = hamming row distance x
       end of if
    else if iflag1 = 10
       if iflag2 = 1
          let v = canberra column distance x
       else if iflag2 = 2
          let v = canberra row distance x
       end of if
    else if iflag1 = 11
       if iflag2 = 1
          let v = pearson column distance x
       else if iflag2 = 2
          let v = pearson row distance x
       end of if
    end of if
    .
    print v

-----MATRIX EIGENVALUES (LET)----------------------------------------
 
MATRIX EIGENVALUES
 
Name:
    MATRIX EIGENVALUES (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the eigenvalues of a matrix.
 
Description:
    A vector v is a eigenvector (or characteristic vector) of matrix A
    belonging to eigenvalue (or characteristic value) lambda if
         Av = lambda*v
    or
         (lambda*I - A)v = 0
    The eigenvalues are the solutions to the characteristic equation
    (det(lambda*I-A)).  The corresponding eigenvectors are computed by
    substituting the value of lambda in the formulas lambda*I-A and
    solving for v.
 
Syntax:
    LET <var> = MATRIX EIGENVALUES <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the eigenvalues are to be
                 computed;
          <var> is a matrix where the resulting eigenvalues are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Examples:
    LET C = MATRIX EIGENVALUES A
 
Note:
    If the matrix is symmetric, the eigenvalues are all real.  If the
    matrix is not symmetric, the eigenvalues may be either real or
    complex.  DATAPLOT handles this by putting the real components in
    the first N (where N is the number of rows in the matrix) rows of
    the returned variable and the corresponding complex components in
    rows N+1 through 2*N.  If you prefer to have the real and complex
    components in separate variables, do something like the following:
       LET E = MATRIX EIGENVALUES M
       LET M = SIZE E
       LET N = M/2
       LET N1 = N + 1
       LET EC = E
       LET ER = E
       RETAIN ER FOR I = 1 1 N
       RETAIN EC FOR I = N1 1 M
 
Note:
    DATAPLOT uses EISPACK to compute the eigenvalues.  DATAPLOT uses
    the routines for either a real symmetric matrix or a real
    non-symmetric matrix.  It does not handle complex matrices.
    Previous versions (before August 1993) used the routines from the
    Numerical Recipes book (which were limited to symmetric matrices).
 
Note:
    The matrix must have the same number of rows and columns.  An error
    message is printed if this is not the case.
 
Note:
    Matrices are created with either the READ MATRIX command or
    the MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION
    and HELP READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by
    appending an index to the matrix name.  For example, the 4x4
    matrix C has columns C1, C2, C3, and C4.  These columns can
    be operated on like any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    EIGENVALUES for MATRIX EIGENVALUES
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10 (extended to non-symmetric matrices 93/8)
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
    16 16 19 21 20
    14 17 15 22 18
    24 23 21 24 20
    18 17 16 15 20
    18 11  9 18  7
    END OF DATA
    LET A = MATRIX EIGENVECTORS X
    PRINT A
 
-----MATRIX EIGENVECTORS (LET)----------------------------------------
 
MATRIX EIGENVECTORS
 
Name:
    MATRIX EIGENVECTORS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the eigenvector of a matrix.
 
Description:
    A vector v is a eigenvector (or characteristic vector) of matrix A
    belonging to eigenvalue (or characteristic value) lambda if
         Av = lambda*v
    or
         (lambda*I - A)v = 0
    The eigenvalues are the solutions to the characteristic equation
    (det(lambda*I-A)).  The corresponding eigenvectors are computed by
    substituting the value of lambda in the formulas lambda*I-A and
    solving for v.
 
Syntax:
    LET <mat2> = MATRIX EIGENVECTORS <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the eigenvectors are to be
                 computed;
          <mat2> is a matrix where the resulting eigenvectors
                 are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET C = MATRIX EIGENVECTORS A
 
Note:
    If the matrix is symmetric, the eigenvectors are all real.  If the
    matrix is not symmetric, the eigenvectors may be either real or
    complex.  DATAPLOT handles this by putting the real components in
    the first N (where N is the number of rows in the matrix) rows of
    the returned matrix and the corresponding complex components in
    rows N+1 through 2*N.  If you prefer to have the real and complex
    components in separate variables, do something like the following:
       LET E = MATRIX EIGENVECTORS M
       LET M = SIZE E
       LET N = M/2
       LET N1 = N + 1
       LOOP FOR K = 1 1 N
           LET EC^K = E^K
           LET ER^K = E^K
           RETAIN ER^K FOR I = 1 1 N
           RETAIN EC^K FOR I = N1 1 M
       END OF LOOP
 
Note:
    The matrix must have the same number of rows and columns.  In
    addition, the matrix must be symmetric.  An error message is printed
    if this is not the case.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    EIGENVECTORS for MATRIX EIGENVECTORS
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10 (non-symmetric case implemented 93/8)
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
    16 16 19 21 20
    14 17 15 22 18
    24 23 21 24 20
    18 17 16 15 20
    18 11  9 18  7
    END OF DATA
    LET A = MATRIX EIGENVECTORS X
    PRINT A
 
-----MATRIX ELEMENT (LET)----------------------------------------
 
MATRIX ELEMENT
 
Name:
    MATRIX ELEMENT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Copy an element of a matrix (i.e., the value for a specific row and
    column of the matrix) into a parameter.
 
Description:
    This command is typically useful in loops.  Note that the following
    syntax does NOT work:
        LET A = M^K(J)
    where M is a matrix and K is a loop index.  The MATRIX ELEMENT
    command can be used in this case.
 
Syntax:
    LET <par> = MATRIX ELEMENT <mat1> <rowid> <colid>
    where <mat1> is a matrix for which the element is to be extracted;
          <rowid> is a number or parameter that specifies the row
               to be extracted;
          <colid> is a number or parameter that specifies the column
               to be extracted;
          <par> is a parameter where the resulting element is saved.
 
Examples:
    LET C = MATRIX ELEMENT A 3 2
    LET C = MATRIX ELEMENT A K J
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX ROW           = Extract a row of the matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Applications:
    Linear Algebra
 
Implementation Date:
    93/10
 
Program:
    . EXTRACT THE DIAGONAL OF THE MATRIX
    READ MATRIX M
    14  37  32
    19  42  17
    12  17  10
    END OF DATA
    .
    LET NROW = MATRIX NUMBER OF COLUMNS M
    .
    LOOP FOR K = 1 1 NROW
       LET A = MATRIX ELEMENT M K K
       LET DIAG(K) = A
    END OF LOOP
    PRINT DIAG
 
-----MATRIX EUCLIDEAN NORM (LET)--------------------------------------
 
MATRIX EUCLIDEAN NORM
 
Name:
    MATRIX EUCLIDEAN NORM (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the euclidean norm of a matrix.
 
Description:
    The euclidean norm of a matrix A is:
          EN = SQRT(SUM(Aij**2))
    where Aij is the ith row and jth column of the matrix A.
 
Syntax:
    LET <param> = MATRIX EUCLIDEAN NORM <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the euclidean norm is to be
                 computed;
          <param> is a parameter where the resulting euclidean norm is
                  saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                  rarely used in this context).
 
Examples:
    LET C = MATRIX EUCLIDEAN NORM A
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    "A First Course in Numerical Analysis", 2nd ed., Ralston and
     Rabinowitz, 1978, McGraw-Hill.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
    16 16 19 21 20 23
    14 17 15 22 18 22
    24 23 21 24 20 23
    18 17 16 15 20 19
    18 11  9 18  7 14
    END OF DATA
    LET EN = MATRIX EUCLIDEAN NORM X
    PRINT EN
 
-----MATRIX FIT (LET)----------------------------------------
 
MATRIX FIT
 
Name:
    MATRIX FIT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute linear least squares fits for each column (or row) of a
    matrix with an independent variable.
 
Description:
    This command will perform a linear least squares fit of each
    column (or row) of a matrix with the same independent variable.
    It returns the intercept and slope parameters with their
    corresponding standard deviations.
    
Syntax 1:
    LET <a0> <a0sd> <a1> <a1sd> = MATRIX COLUMN FIT <mat> <x>
                                  <SUBSET/EXCEPT/FOR qualification>
    where <mat> is a matrix for which the fits are to be generated;
          <x> is a response variable that contains the independent
                 variable for the fit;
          <a0> is a variable where the intercepts from the fits are saved;
          <a0sd> is a variable where the standard deviations of the
                 intercepts from the fits are saved;
          <a1> is a variable where the slopes from the fits are saved;
          <a1sd> is a variable where the standard deviations of the
                 slopes from the fits are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
    rarely used in this context.

    With this syntax, each column of <mat> is used as the dependent
    variable in a linear least squares fit with <x> as the independent
    variable.  The number of rows in <mat> must be the same as the
    number of rows in <x>.
 
Syntax 2:
    LET <a0> <a0sd> <a1> <a1sd> = MATRIX ROW FIT <mat> <x>
                                  <SUBSET/EXCEPT/FOR qualification>
    where <mat> is a matrix for which the fits are to be generated;
          <x> is a response variable that contains the independent
                 variable for the fit;
          <a0> is a variable where the intercepts from the fits are saved;
          <a0sd> is a variable where the standard deviations of the
                 intercepts from the fits are saved;
          <a1> is a variable where the slopes from the fits are saved;
          <a1sd> is a variable where the standard deviations of the
                 slopes from the fits are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
    rarely used in this context.

    With this syntax, each row of <mat> is used as the dependent
    variable in a linear least squares fit with <x> as the independent
    variable.  The number of columns in <mat> must be the same as the
    number of rows in <x>.
 
Examples:
    LET A0 A0SD A1 A1SD = MATRIX COLUMN FIT M X
 
Synonyms:
    None
 
Related Commands:
    FIT               = Perform a linear or non-linear least squares fit.
    LINEAR SLOPE      = Compute the slope from a linear least squares fit.
    LINEAR INTERCEPT  = Compute the intercept from a linear least squares
                        fit.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    2010/07
 
Program:
    dimension 500 columns
    skip 25
    read gear.dat y tag
    .
    let tagdist = distinct tag
    let tagdist = sort tagdist
    let ngroup = size tagdist
    .
    loop for k = 1 1 ngroup
        let aval = tagdist(k)
        let y^k  = y
        retain y^k  subset tag = aval
    end of loop
    .
    let nrow = 10
    let x = sequence 1 1 nrow
    let m = create matrix y1 y2 y3 y4 y5 y6 y7 y8 y9 y10
    set write decimals 5
    .
    let b0 b1 b0sd b1sd = matrix column fit m x
    .
    print b0 b1 b0sd b1sd
    pause
    .
    let mt = matrix transpose m
    let c0 c1 c0sd c1sd = matrix row fit mt x
    print c0 c1 c0sd c1sd
 
-----MATRIX GRAND STATISTIC (LET)--------------------------------
 
MATRIX GRAND STATISTIC
 
Name:
    MATRIX GRAND STATSITIC (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute a user specified statistic for all elements of a matrix.
 
Description:
    This command allows you to compute one of 50+ statistics for
    all elements of an array.  The most common use of this command
    is to compute the sum of all elements in the matrix or some
    location statistic such as the mean or median.
 
Syntax:
    LET <a> = MATRIX GRAND <stat> <mat>
                           <SUBSET/EXCEPT/FOR qualification>
    where <mat> is a matrix for which the statistic is to be
                computed;
          <stat> is the desired statistic to compute;
          <a> is a parameter where the resulting statistic is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    The specified statistic can be any of the following:
        MEAN, MIDMEAN, MEDIAN, TRIMMED MEAN, WINSORIZED MEAN,
        GEOMETRIC MEAN, HARMONIC MEAN, HODGES LEHMAN,
        BIWEIGHT LOCATION,
        SUM, PRODUCT,
        STANDARD DEVIATION, STANDARD DEVIATION OF MEAN,
        VARIANCE, VARIANCE OF THE MEAN,
        TRIMMED MEAN STANDARD ERROR,
        AVERAGE ABSOLUTE DEVIATION (or AAD),
        MEDIAN ABSOLUTE DEVIATION (or MAD),
        IQ RANGE, BIWEIGHT MIDVARIANCE, BIWEIGHT SCALE,
        PERCENTAGE BEND MIDVARIANCE,
        WINSORIZED VARIANCE, WINSORIZED STANDARD DEVIATION,
        RELATIVE STANDARD DEVIATION, RELATIVE VARIANCE (or
           COEFFICIENT OF VARIATION),
        RANGE, MIDRANGE, MAXIMUM, MINIMUM, EXTREME,
        LOWER HINGE, UPPER HINGE, LOWER QUARTILE, UPPER QUARTILE,
        <FIRST/SECOND/THIRD/FOURTH/FIFTH/SIXTH/SEVENTH/EIGHTH/
            NINTH/TENTH> DECILE,
        PERCENTILE, QUANTILE, QUANTILE STANDARD ERROR,
        SKEWNESS, KURTOSIS, NORMAL PPCC,
        AUTOCORRELATION, AUTOCOVARIANCE,
        SINE FREQUENCY, SINE AMPLITUDE,
        CP, CPK, CNPK, CPM, CC,
        EXPECTED LOSS, PERCENT DEFECTIVE,
        TAGUCHI SN0 (or SN), TAGUCHI SN+ (or SNL),
        TAGUCHI SN- (or SNS), TAGUCHI SN00 (or SN2)

Examples:
    LET A = MATRIX GRAND MEAN M
    LET A = MATRIX GRAND MEDIAN M
    LET A = MATRIX GRAND SD M
 
Note:
    Matrices can be created with the READ MATRIX, CREATE MATRIX,
    and MATRIX DEFINITION commands.  Enter HELP MATRIX DEFINITION,
    HELP READ MATRIX, and HELP CREATE MATRIX for details.
 
Note:
    Row and column statistics for a matrix can be computed
    using the MATRIX ROW STATISTIC and MATRIX COLUMN STATISTIC
    commands.  Enter HELP MATRIX ROW STATISTIC and
    HELP MATRIX COLUMN STATISTIC for details.
 
    Statistics for equi-sized sub-matrices of the original matrix
    can be computed with the MATRIX PARTITION STATISTIC command.
    Enter HELP MATRIX PARTITION STATISTIC for details.

Default:
    None
 
Synonyms:
    MATRIX MEAN is a synonym for MATRIX GRAND MEAN
    MATRIX SUM  is a synonym for MATRIX GRAND SUM
 
Related Commands:
    MATRIX COLUMN STATISTIC     = Compute column statistics for a
                                  matrix.
    MATRIX ROW STATISTIC        = Compute row statistics for a matrix.
    MATRIX PARTITION STATISTIC  = Compute statistics for equi-sized
                                  sub-matrices of a matrix.
    MATRIX COLUMN DIMENSION     = Dimension maximum number of columns
                                  for Dataplot matrices.
 
 
Reference:
    "Applied Multivariate Statistical Analysis", Third Edition,
    Johnson and Wichern, Prentice-Hall, 1992.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    2005/6
 
Program:
    READ MATRIX DAT M
    1 2 3 4
    5 6 7 8
    9 10 11 12
    13 14 15 16
    END OF DATA
    .
    LET AMEAN = MATRIX GRAND MEAN M
    LET ASD   = MATRIX GRAND SD   M
    SET WRITE DECIMALS 2
    PRINT AMEAN ASD
 
-----MATRIX GROUP MEANS (LET)-------------------------------------
 
MATRIX GROUP MEANS
 
Name:
    MATRIX GROUP MEANS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the group means of a matrix.
 
Description:
    This command operates on a matrix (M) and a group id variable
    (TAG).  The TAG variable has the same number of rows as the
    matrix M.  The values of TAG are typically integers that
    identify the group to which the corresponding row of the
    matrix belongs.

    The MATRIX GROUP MEANS command returns a matrix with the
    same number of columns as the original matrix M and with
    the number or rows equal the number of groups identified
    by the TAG variable.  That is, MEANS(2,3) is the mean of
    of the third variable of the second group.
 
Syntax:
    LET <mat2> = MATRIX GROUP MEANS <mat1>  <tag>
                       <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the group means are to
              be computed;
          <tag> is the group-id variable;
          <mat2> is a matrix where the resulting group means
             are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET MMEAN = MATRIX GROUP MEANS M TAG
    LET MMEAN = MATRIX GROUP MEANS M TAG  SUBSET TAG = 1 TO 2
 
Note:
    Matrices are created with either the READ MATRIX command or
    the MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION
    and HELP READ MATRIX for details.
 
Note:
    Row and column statistics for a matrix can be computed
    using the MATRIX ROW STATISTIC and MATRIX COLUMN STATISTIC
    commands.  Enter HELP MATRIX ROW STATISTIC and
    HELP MATRIX COLUMN STATISTIC for details.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX GROUP SD           = Compute the group standard deviations
                                for a matrix.
    MATRIX MEAN               = Compute the overall mean for a matrix.
    MATRIX COLUMN STATISTIC   = Compute column statistics for a
                                matrix.
    MATRIX ROW STATISTIC      = Compute row statistics for a matrix.
    MATRIX COLUMN DIMENSION   = Dimension maximum number of columns
                                for Dataplot matrices.
 
Reference:
    "Applied Multivariate Statistical Analysis", Third Edition,
    Johnson and Wichern, Prentice-Hall, 1992.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    1998/8
 
Program:
    DIMENSION 50 COLUMNS
    SKIP 25
    READ IRIS.DAT Y1 Y2 Y3 Y4 TAG
    LET N = SIZE Y1
    LET M = MATRIX DEFINITION Y1 N 4
    LET Z = MATRIX GROUP MEANS M TAG
 
-----MATRIX GROUP SD (LET)----------------------------------------
 
MATRIX GROUP SD
 
Name:
    MATRIX GROUP SD (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the group standard deviations of a matrix.
 
Description:
    This command operates on a matrix (M) and a group id variable
    (TAG).  The TAG variable has the same number of rows as the
    matrix M.  The values of TAG are typically integers that
    identify the group to which the corresponding row of the
    matrix belongs.

    The MATRIX GROUP SD command returns a matrix with the
    same number of columns as the original matrix M and with
    the number or rows equal the number of groups identified
    by the TAG variable.  That is, SD(2,3) is the standard 
    deviation of of the third variable of the second group.
 
Syntax:
    LET <mat2> = MATRIX GROUP SD <mat1>  <tag>
                       <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the group standard deviations
              are to be computed;
          <tag> is the group-id variable;
          <mat2> is a matrix where the resulting group standard
             deviations are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET MMEAN = MATRIX GROUP SD M TAG
    LET MMEAN = MATRIX GROUP SD M TAG  SUBSET TAG = 1 TO 2
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    Row and column statistics for a matrix can be computed
    using the MATRIX ROW STATISTIC and MATRIX COLUMN STATISTIC
    commands.  Enter HELP MATRIX ROW STATISTIC and
    HELP MATRIX COLUMN STATISTIC for details.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX GROUP MEANS        = Compute the group means for a matrix.
    MATRIX MEAN               = Compute the overall mean for a matrix.
    MATRIX COLUMN STATISTIC   = Compute column statistics for a
                                matrix.
    MATRIX ROW STATISTIC      = Compute row statistics for a matrix.
    MATRIX COLUMN DIMENSION   = Dimension maximum number of columns
                                for Dataplot matrices.
 
Reference:
    "Applied Multivariate Statistical Analysis", Third Edition,
    Johnson and Wichern, Prentice-Hall, 1992.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    1998/8
 
Program:
    DIMENSION 50 COLUMNS
    SKIP 25
    READ IRIS.DAT Y1 Y2 Y3 Y4 TAG
    LET N = SIZE Y1
    LET M = MATRIX DEFINITION Y1 N 4
    LET Z = MATRIX GROUP SD M TAG
 
-----MATRIX INVERSE (LET)----------------------------------------
 
MATRIX INVERSE
 
Name:
    MATRIX INVERSE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the inverse of a matrix.
 
Description:
    The inverse is the matrix that when multiplied by the original
    matrix yields the identity matrix (i.e., AA'=I where I has one's on
    the diagonal and zero's everywhere else).
 
    In practice, the matrix inverse, the determinant, and the solution
    of a system of a linear equations are all closely related.  Each of
    these can be computed from the LU decomposition of a matrix.
 
Syntax:
    LET <mat2> = MATRIX INVERSE <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the inverse is to be computed;
          <mat2> is a matrix where the resulting inverse is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET C = MATRIX INVERSE A
 
Note:
    Matrices for which the inverse to be computed  must have the same
    number of rows and columns.  An error message is printed if they do
    not.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Note:
    DATAPLOT uses LINPACK routines to calculate the LU decomposition
    (versions prior to 7/93 use the LUDCMP and LUBKSB routines from
    the Numerical Recipes book).
 
    The reciprocal of the condition number is printed.  This number
    gives an indication of the numerical accuracy that was obtained
    when calculating the inverse.  If this number is approximately
    10**(-d), then the elements of the LU decomposed matrix generally
    have d fewer significant digits than the original matrix.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    "LINPACK User's Guide", Dongarra, Bunch, Moler, Stewart.  Siam,
    1979.
 
    "Numerical Recipes: The Art of Scientific Programming (FORTRAN
    Version)", Press, Flannery, Teukolsky, and Vetterling.  Cambridge
    University Press, 1989 (chapter 2).
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
    16 16 19 21 20
    14 17 15 22 18
    24 23 21 24 20
    18 17 16 15 20
    18 11  9 18  7
    END OF DATA
    LET A = MATRIX INVERSE X
    PRINT A
 
-----MATRIX ITERATIVE SOLUTION (LET)--------------------------------
 
MATRIX ITERATIVE SOLUTION
 
Name:
    MATRIX ITERATIVE SOLUTION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Solve a system of linear equations in the following form:
          A*X=B
    where A is the matrix of coefficients, B is a vector of constants,
    and X are the variables to be solved for.  After finding the
    solution, use the method of iterative improvement to provide
    greater precision to the solution vector.
 
Description:
    In practice, the solution of a system of linear equations, finding
    the inverse of a matrix, and computing the determinant of a matrix
    are all closely related.  Each of these can be computed from the
    LU decomposition of a matrix.  The method of iterative improvement
    is described in the LINPACK manual (DATAPLOT uses the algorithm
    they provide).  Iterative improvement is used to make the precision
    of the solution vector equivalent to the original matrix.  In most
    cases, the MATRIX SOLUTION command should be adequate.
 
Syntax:
    LET <resp> = MATRIX ITERATIVE SOLUTION <mat1> <vector>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix containing the coefficients of the
                 equation;
          <vector> is an array of constants (i.e., the values for the
                 right hand side of the equation;
          <resp> is a vector where the resulting matrix solution is
                 saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET X = MATRIX SOLUTION A B
 
Note:
    DATAPLOT uses LINPACK routines to calculate the LU decomposition
    (versions prior to 7/93 use the LUDCMP and LUBKSB routines from
    the Numerical Recipes book).
 
Note:
    Matrices used to solve systems of linear equations must have the
    same number of rows and columns.  An error message is printed if
    they do not.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
    TRIANGULAR SOLUTION  = Solve an upper triangular system of linear
                           equations.
    TRIDIAGONAL SOLUTION = Solve a tridiagonal system of linear
                           equations.
 
Reference:
    "LINPACK User's Guide", Dongarra, Bunch, Moler, Stewart.  Siam,
    1979.
 
    "Numerical Recipes: The Art of Scientific Programming (FORTRAN
    Version)", Press, Flannery, Teukolsky, and Vetterling.  Cambridge
    University Press, 1989 (chapter 2).
 
Applications:
    Linear Algebra
 
Implementation Date:
    93/10
 
Program:
    . THIS IS THE DATAPLOT PROGRAM FILE     CHEMMIX.DP
    . PURPOSE--DETERMINE PROPER FEED RATE OF 4 INPUT COMPOSITIONS
    .          TO YIELD A PRE-SPECIFIED OUTPUT COMPOSITION AT A
    .          PRE-SPECIFIED OUTPUT RATE.
    . ANALYSIS TECHNIQUE--SOLVING A SYSTEM OF 4 LINEAR EQUATIONS
    . APPLICATION--CHEMICAL MIXING
    . SOURCE--FOGIEL, THE LINEAR ALGEBRA PROBLEM SOLVER RESEARCH
    .         RESEARCH AND EDUCATION ASSOCIATION, 1980 (PAGE 792)
    . GIVEN--INPUT PROPORTIONS--
    .                               IN1     IN2     IN3     IN4
    .           SULFURIC ACID       80%      0%     30%     10%
    .           NITRIC ACID          0%     80%     10%     10%
    .           WATER               16%     20%     60%     72%
    .           INERT                4%      0%      0%      8%
    . GIVEN--DESIRED OUTPUT (2000 LB/HR) AT THE FOLLOWING
    .        PROPORTIONS--
    .           SULFURIC ACID       40% (800 LB PER HOUR)
    .           NITRIC ACID         27% (540 LB PER HOUR)
    .           WATER               31% (620 LB PER HOUR)
    .           INERT                2% (40 LB PER HOUR)
    . TO FIND X1 = FLOW RATE OF INPUT STREAM 1
    .         X2 = FLOW RATE OF INPUT STREAM 2
    .         X3 = FLOW RATE OF INPUT STREAM 3
    .         X4 = FLOW RATE OF INPUT STREAM 4
    . NOTE--TO SET UP THE 4 EQUATIONS (ONE FOR EACH COMPOUND)
    .       APPLY CONSERVATION OF MASS (MASS BALANCES)
    . NOTE--FOR TESTING PURPOSES, THE SOLUTION IS
    .       800  600  500  100   LB PER HOUR
    . -----START POINT-----------------------------------
    .
    .      STEP 1-- DEFINE THE LEFT-HAND SIDE.
    .
    READ MATRIX A
    .80 .00 .30 .10
    .00 .80 .10 .10
    .16 .20 .60 .72
    .04 .00 .00 .08
    END OF DATA
    .      STEP 2-- DEFINE THE RIGHT-HAND SIDE.
    LET B = DATA 800 540 620 40
    PRINT A B
    .      STEP 3-- SOLVE THE LINEAR SYSTEM
    LET X = MATRIX ITERATIVE SOLUTION A B
    PRINT X
 
-----MATRIX MEAN (LET)----------------------------------------
 
MATRIX MEAN
 
Name:
    MATRIX MEAN (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the overall mean of a matrix.
 
Description:
    The overall mean of the matrix is the mean of all the
    data in the matrix.
 
Syntax:
    LET <par> = MATRIX MEAN <mat> <SUBSET/EXCEPT/FOR qualification>
    where <mat> is a matrix for which the mean is to be computed;
          <par> is a parameter where the resulting mean is saved.
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET MMEAN = MATRIX MEAN M
    LET MMEAN = MATRIX MEAN M SUBSET TAG = 1 TO 2
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    Row and column statistics for a matrix can be computed
    using the MATRIX ROW STATISTIC and MATRIX COLUMN STATISTIC
    commands.  Enter HELP MATRIX ROW STATISTIC and
    HELP MATRIX COLUMN STATISTIC for details.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX COLUMN STATISTIC   = Compute column statistics for a
                                matrix.
    MATRIX ROW STATISTIC      = Compute row statistics for a matrix.
    MATRIX COLUMN DIMENSION   = Dimension maximum number of columns
                                for Dataplot matrices.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    1998/8
 
Program:
    SKIP 25
    READ IRIS.DAT Y1 Y2 Y3 Y4
    LET N = SIZE Y1
    LET M = MATRIX DEFINITION Y1 N 4
    LET A = MATRIX MEAN M
 
-----MATRIX MINOR (LET)----------------------------------------
 
MATRIX MINOR
 
Name:
    MATRIX MINOR (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the matrix minors of a matrix.
 
Description:
    The minor Bij is the determinant of matrix A with row i and column
    j omitted.  The corresponding cofactor is (-1)**(i+j)*Bij.
 
    The determinant of the reduced matrix is calculated with an LU
    decomposition.
 
Syntax:
    LET <param> = MATRIX MINOR <mat1> <rowid> <colid>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the minor is to be computed;
          <rowid> is the row of <mat1> for which a minor is to be
                  computed;
          <colid> is the column of <mat1> for which a minor is to be
                  computed;
          <param> is a parameter where the resulting minor is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                  rarely used in this context).
 
Examples:
    LET C = MATRIX MINOR A
 
Note:
    Matrices for which a minor is computed  must have the same number of
    rows and columns.  An error message is printed if they do not.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
    16 16 19 21 20 23
    14 17 15 22 18 22
    24 23 21 24 20 23
    18 17 16 15 20 19
    18 11  9 18  7 14
    END OF DATA
    LET C = VARIANCE-COVARIANCE MATRIX X
    LET NC = MATRIX NUMBER OF COLUMNS C
    LET NR = NC
    LOOP FOR J = 1 1 NC
        LOOP FOR I = 1 1 NR
            LET TEMP = MATRIX MINOR C I J
            LET B(^I) = TEMP
        END OF LOOP
        LET A^J = B
    END OF LOOP
    LET A = MATRIX DEFINITION A1 NR NC
    PRINT A
 
-----MATRIX MULTIPLICATION (LET)--------------------------------------
 
MATRIX MULTIPLICATION
 
Name:
    MATRIX MULTIPLICATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Multiply 2 matrices, a matrix and a vector, or a matrix and a
    parameter.
 
Description:
    In matrix multiplication, each row of matrix 1 is multiplied by
    each column of matrix 2.  For example:
      A = 1  2  3      B = 4 7
          3  2  1          5 8
                           6 9
      AB = (1x4+2x5+3x6)  (1x7+2x8+3x9)
           (3x4+2x5+1x6)  (3x7+2x8+1x9)
 
    If a matrix is multiplied by a parameter, each element of the
    matrix is multiplied by the parameter.  If a matrix is multiplied by
    a vector, the vector is multiplied with each column of the matrix
    (i.e., the corresponding rows are multiplied).
 
Syntax 1: (2 matrices)
    LET <mat3> = MATRIX MULTIPLICATION <mat1> <mat2>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix;
          <mat2> is a matrix;
          <mat3> is a matrix where the resulting matrix multiplication
                 is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Syntax 2: (a matrix and a parameter)
    LET <mat3> = MATRIX MULTIPLICATION <mat1> <par>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix;
          <par> is a number or a parameter;
          <mat3> is a matrix where the resulting matrix multiplication
                 is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Syntax 3: (a matrix and a vector)
    LET <mat3> = MATRIX MULTIPLICATION <mat1> <var>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix;
          <var> is a variable;
          <mat3> is a matrix where the resulting matrix multiplication
                 is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET C = MATRIX MULTIPLICATION A B
    LET C = MATRIX MULTIPLICATION A 2
    LET C = MATRIX MULTIPLICATION A V
 
Note:
    For 2 matrices, the number of columns in the first matrix must
    match the number of rows in the second matrix. For a matrix and a
    vector, the number of rows must be the same.  An error message is
    printed if either one of these conditions is violated.  For 2
    matrices, the resulting matrix has a dimension equal to the number
    of rows in matrix 1 and the number of columns in matrix 2.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    READ MATRIX A
    1 2 3
    3 2 1
    END OF DATA
    READ MATRIX B
    4 7
    5 8
    6 9
    END OF DATA
    LET C = MATRIX MULTIPLICATION A B
    PRINT C
    The resulting matrix C contains:
       32 50
       28 46
 
-----MATRIX NUMBER OF COLUMNS (LET)-----------------------------------
 
MATRIX NUMBER OF COLUMNS
 
Name:
    MATRIX NUMBER OF COLUMNS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the number of columns in a matrix.
 
Syntax:
    LET <param> = MATRIX NUMBER OF COLUMNS <mat1>
    where <mat1> is a matrix;
          <param> is a parameter where the resulting number of columns
                 is saved.
 
Examples:
    LET C = MATRIX NUMBER OF COLUMNS A
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    READ MATRIX C
    -99 -99
    1 0
    0 1
    -1 0
    END OF DATA
    LET ACOL = MATRIX NUMBER OF COLUMNS A
 
-----MATRIX NUMBER OF ROWS (LET)-----------------------------------
 
MATRIX NUMBER OF ROWS
 
Name:
    MATRIX NUMBER OF ROWS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the number of rows in a matrix.
 
Syntax:
    LET <param> = MATRIX NUMBER OF ROWS <mat1>
    where <mat1> is a matrix;
          <param> is a parameter where the resulting number of rows is
                 saved.
 
Examples:
    LET C = MATRIX NUMBER OF ROWS A
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    READ MATRIX C
    -99 -99
    1 0
    0 1
    -1 0
    END OF DATA
    LET ACOL = MATRIX NUMBER OF ROWS A
 
-----MATRIX PARTITION STATISTIC (LET)--------------------------------
 
MATRIX PARTITION STATISTIC
 
Name:
    MATRIX PARTITION STATSITIC (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute a user specified statistic for either equi-spaced
    sub-matrices or arbitrary sub-matrices of a matrix.
 
Description:
    Previous versions of Dataplot allowed you to compute various
    column or row statistics (HELP MATRIX COLUMN STATISTIC or
    HELP MATRIX ROW STATISTIC for details).  This capability has
    been extended to the case where the matrix is divided into
    equi-sized partitions and the specified statistic is computed
    in each of these partitions.

    Note that this command returns a matrix of statistic values.

    For this command, you specify the number of rows and columns
    for each of the sub-matrices.  Dataplot starts the partitioning
    with position 1,1 of the original matrix.

    For example, if you have a matrix with 5 rows and 5 columns
    and you specify sub-matrices with 2 rows and 2 columns, the
    following partitioning will be performed:

        Matrix 1,1      Matrix 1,2    Matrix 1,3
         1   2           3   4         5
         6   7           8   9        10
 
        Matrix 2,1      Matrix 2,2    Matrix 2,3
        11  12          13  14        15
        16  17          18  19        20
 
        Matrix 3,1      Matrix 3,2    Matrix 3,3
        21  22          23  24        25

    A 3x3 matrix of computed statistics will be returned.

    This command was extended to the case of unequal partitions where
    the partitions need not be contiguous.  For this case, we define
    two vectors.  The first corresponds to the rows of the matrix
    while the second corresponds to the number of columns in the
    matrix.  The elements of these two vectors identify which
    partition each element of the original matrix belongs to.
    For the 5x5 example above, suppose we want rows 1, 3, and 5
    and columns 1, 4, and 5 to belong to partition 1 and rows 2 and
    4  and columns 2 and 3 to belong to partition 2, we would create
    the following vectors:

        row vector          column vector
        ----------          -------------
           1                      1 
           2                      2 
           1                      2 
           2                      1 
           1                      1 

    This results in the following partitioning:

        Matrix 1,1      Matrix 1,2
         1   4   5       2   3
        11  14  15      12  13
        21  24  25      22  23

        Matrix 2,1      Matrix 2,2
         6   8   9       7   8
        16  19  20      17  18

    One possible application of this case is to compute statistics
    for grouped data (you can do this explicitly for the mean and
    standard deviation using the MATRIX GROUP MEAN and MATRIX
    GROUP SD commands, but this command allows it for a broader
    range of statistics).

Syntax 1:
    LET <mout> = MATRIX PARTITION <stat> <mat> <nrow> <ncol>
                           <SUBSET/EXCEPT/FOR qualification>
    where <mat> is a matrix for which the statistic is to be
                computed;
          <stat> is the desired statistic to compute;
          <nrow> is the number of rows in each sub-matrix;
          <ncol> is the number of columns in each sub-matrix;
          <mout> is a matrix where the computed statistics are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    The specified statistic can be any of the following:
        MEAN, MIDMEAN, MEDIAN, TRIMMED MEAN, WINSORIZED MEAN,
        GEOMETRIC MEAN, HARMONIC MEAN, HODGES LEHMAN,
        BIWEIGHT LOCATION,
        SUM, PRODUCT,
        STANDARD DEVIATION, STANDARD DEVIATION OF MEAN,
        VARIANCE, VARIANCE OF THE MEAN,
        TRIMMED MEAN STANDARD ERROR,
        AVERAGE ABSOLUTE DEVIATION (or AAD),
        MEDIAN ABSOLUTE DEVIATION (or MAD),
        IQ RANGE, BIWEIGHT MIDVARIANCE, BIWEIGHT SCALE,
        PERCENTAGE BEND MIDVARIANCE,
        WINSORIZED VARIANCE, WINSORIZED STANDARD DEVIATION,
        RELATIVE STANDARD DEVIATION, RELATIVE VARIANCE (or
           COEFFICIENT OF VARIATION),
        RANGE, MIDRANGE, MAXIMUM, MINIMUM, EXTREME,
        LOWER HINGE, UPPER HINGE, LOWER QUARTILE, UPPER QUARTILE,
        <FIRST/SECOND/THIRD/FOURTH/FIFTH/SIXTH/SEVENTH/EIGHTH/
            NINTH/TENTH> DECILE,
        PERCENTILE, QUANTILE, QUANTILE STANDARD ERROR,
        SKEWNESS, KURTOSIS, NORMAL PPCC,
        AUTOCORRELATION, AUTOCOVARIANCE,
        SINE FREQUENCY, SINE AMPLITUDE,
        CP, CPK, CNPK, CPM, CC,
        EXPECTED LOSS, PERCENT DEFECTIVE,
        TAGUCHI SN0 (or SN), TAGUCHI SN+ (or SNL),
        TAGUCHI SN- (or SNS), TAGUCHI SN00 (or SN2)

    This syntax is for the case where the partititons are
    equi-spaced and contiguous.

Syntax 2:
    LET <mout> = MATRIX PARTITION <stat> <mat> <tagrow> <tagcol>
                           <SUBSET/EXCEPT/FOR qualification>
    where <mat> is a matrix for which the statistic is to be
                computed;
          <stat> is the desired statistic to compute;
          <tagrow> is a vector that specifies which partition
                each row of the matrix belongs to;
          <tagcol> is a vector that specifies which partition
                each column of the matrix belongs to;
          <mout> is a matrix where the computed statistics are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is for the case where the partitions need not be
    be equi-spaced or contiguous.  The list of supported statistics
    is the same as for syntax 1.

Examples:
    LET MOUT = MATRIX PARTITION MEAN M 5 5
    LET MOUT = MATRIX PARTITION MEDIAN M 10 5
    LET MOUT = MATRIX PARTITION SD M 2 2
 
Note:
    Matrices can be created with the READ MATRIX, CREATE MATRIX,
    and MATRIX DEFINITION commands.  Enter HELP MATRIX DEFINITION,
    HELP READ MATRIX, and HELP CREATE MATRIX for details.
 
Note:
    Row and column statistics for a matrix can be computed
    using the MATRIX ROW STATISTIC and MATRIX COLUMN STATISTIC
    commands.  Enter HELP MATRIX ROW STATISTIC and
    HELP MATRIX COLUMN STATISTIC for details.
 
    Statistics for all elements of a matrix can be computed with
    the MATRIX GRAND STATISTIC command.  Enter
    HELP MATRIX GRAND STATISTIC for details.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX COLUMN STATISTIC     = Compute column statistics for a
                                  matrix.
    MATRIX ROW STATISTIC        = Compute row statistics for a matrix.
    MATRIX GRAND STATISTIC      = Compute statistics for all elements
                                  of a matrix.
    MATRIX COLUMN DIMENSION     = Dimension maximum number of columns
                                  for Dataplot matrices.
 
 
Reference:
    "Applied Multivariate Statistical Analysis", Third Edition,
    Johnson and Wichern, Prentice-Hall, 1992.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    2005/6
 
Program 1:
    READ MATRIX DAT M
    1 2 3 4
    5 6 7 8
    9 10 11 12
    13 14 15 16
    END OF DATA
    .
    LET MATMEAN = MATRIX PARTITION MEAN M 2 2
    LET MATSD   = MATRIX PARTITION SD   M 2 2
    LET MATSUM  = MATRIX PARTITION SUM  M 2 2
 
Program 2:
    dimension 50 columns
    skip 25
    read iris.dat y1 y2 y3 y4 x
    let m = create matrix y1 y2 y3 y4
    .
    let coltag = data 1 2 3 4
    .
    let matmed = matrix partition median m x coltag
    set write decimals 2
    print matmed

-----MATRIX PERMANENT (LET)----------------------------------------
 
MATRIX PERMANENT
 
Name:
    MATRIX PERMANENT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the permanent of a matrix.
 
Description:
    The determinant of an NxN matrix A is defined as

       det A = a1*A11 - a2*A12 + a3*A13 - ... - (-1)**(N+1)*an*A1N

    where A1j is the entry in row 1 and column j of A and aj is the
    determinant of the matrix obtained by omitting the first row and
    column j of A.  This is a recursive definition.  The determinant
    of a 2x2 matrix:

            [a  b]
            [c  d]

    is ab - cd.
 
    The permanent of a matrix is similar to the determinant.
    However, the sign is postive for all terms in the sum.

    The permanent of a matrix has applications in combinatorial
    analysis.
 
Syntax:
    LET <par> = MATRIX PERMANENT <mat>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat> is a matrix for which the permanent is to be
                 computed;
          <par> is a parameter where the resulting permanent is
                 saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET P = MATRIX PERMANENT A
 
Note:
    Matrices for which a permanent is to be computed  must have the
    same number of rows and columns.  An error message is printed if
    they do not.
 
Note:
    Matrices are created with the READ MATRIX, CREATE MATRIX and
    MATRIX DEFINITION commands.
 
Note:
    The columns of a matrix are accessible as variables by appending
    an index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  Enter HELP DIMENSION
    and HELP MATRIX DIMENSION for details.
 
Note:
    DATAPLOT computes the permanent using the PERMAN subroutine
    given in Nijenhuis and Wilf (see the Reference section below).
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX DETERMINANT   = Compute the determinant of a matrix.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    CREATE MATRIX        = Create a matrix from a list of variables.
    MATRIX DEFINITION    = Create a matrix from the rows and columns
                           of previously defined variables.
    MATRIX MINOR         = Compute a matrix minor.
    READ MATRIX          = Read a matrix from the terminal or a file.
 
Reference:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 23.

Applications:
    Combinatorial Analysis
 
 
Implementation Date:
    2009/1
 
Program:
    .  Following example from Nijenhuis and Wilf
    DIMENSION 100 COLUMNS
    LET ICNT = 0
    .
    READ MATRIX M
    0  1
    1  0
    END OF DATA
    LET A = MATRIX PERMANENT M
    LET ICNT = ICNT + 1
    LET NVAL(ICNT) = 2
    LET PERM(ICNT) = A
    DELETE M
    .
    READ MATRIX M
    0  1  1
    1  0  1
    1  1  0
    END OF DATA
    LET A = MATRIX PERMANENT M
    LET ICNT = ICNT + 1
    LET NVAL(ICNT) = 3
    LET PERM(ICNT) = A
    DELETE M
    .
    READ MATRIX M
    0  1  1  1
    1  0  1  1
    1  1  0  1
    1  1  1  0
    END OF DATA
    LET A = MATRIX PERMANENT M
    LET ICNT = ICNT + 1
    LET NVAL(ICNT) = 4
    LET PERM(ICNT) = A
    DELETE M
    .
    READ MATRIX M
    0  1  1  1  1
    1  0  1  1  1
    1  1  0  1  1
    1  1  1  0  1
    1  1  1  1  0
    END OF DATA
    LET A = MATRIX PERMANENT M
    LET ICNT = ICNT + 1
    LET NVAL(ICNT) = 5
    LET PERM(ICNT) = A
    DELETE M
    .
    READ MATRIX M
    0  1  1  1  1  1
    1  0  1  1  1  1
    1  1  0  1  1  1
    1  1  1  0  1  1
    1  1  1  1  0  1
    1  1  1  1  1  0
    END OF DATA
    LET A = MATRIX PERMANENT M
    LET ICNT = ICNT + 1
    LET NVAL(ICNT) = 6
    LET PERM(ICNT) = A
    DELETE M
    .
    READ MATRIX M
    0  1  1  1  1  1  1
    1  0  1  1  1  1  1
    1  1  0  1  1  1  1
    1  1  1  0  1  1  1
    1  1  1  1  0  1  1
    1  1  1  1  1  0  1
    1  1  1  1  1  1  0
    END OF DATA
    LET A = MATRIX PERMANENT M
    LET ICNT = ICNT + 1
    LET NVAL(ICNT) = 7
    LET PERM(ICNT) = A
    DELETE M
    .
    READ MATRIX M
    0  1  1  1  1  1  1  1
    1  0  1  1  1  1  1  1
    1  1  0  1  1  1  1  1
    1  1  1  0  1  1  1  1
    1  1  1  1  0  1  1  1
    1  1  1  1  1  0  1  1
    1  1  1  1  1  1  0  1
    1  1  1  1  1  1  1  0
    END OF DATA
    LET A = MATRIX PERMANENT M
    LET ICNT = ICNT + 1
    LET NVAL(ICNT) = 8
    LET PERM(ICNT) = A
    DELETE M
    .
    READ MATRIX M
    0  1  1  1  1  1  1  1  1
    1  0  1  1  1  1  1  1  1
    1  1  0  1  1  1  1  1  1
    1  1  1  0  1  1  1  1  1
    1  1  1  1  0  1  1  1  1
    1  1  1  1  1  0  1  1  1
    1  1  1  1  1  1  0  1  1
    1  1  1  1  1  1  1  0  1
    1  1  1  1  1  1  1  1  0
    END OF DATA
    LET A = MATRIX PERMANENT M
    LET ICNT = ICNT + 1
    LET NVAL(ICNT) = 9
    LET PERM(ICNT) = A
    DELETE M
    .
    READ MATRIX M
    0  1  1  1  1  1  1  1  1  1
    1  0  1  1  1  1  1  1  1  1
    1  1  0  1  1  1  1  1  1  1
    1  1  1  0  1  1  1  1  1  1
    1  1  1  1  0  1  1  1  1  1
    1  1  1  1  1  0  1  1  1  1
    1  1  1  1  1  1  0  1  1  1
    1  1  1  1  1  1  1  0  1  1
    1  1  1  1  1  1  1  1  0  1
    1  1  1  1  1  1  1  1  1  0
    END OF DATA
    LET A = MATRIX PERMANENT M
    LET ICNT = ICNT + 1
    LET NVAL(ICNT) = 10
    LET PERM(ICNT) = A
    DELETE M
    .
    SET WRITE DECIMALS 0
    PRINT NVAL PERM
 
-----MATRIX RANK (LET)----------------------------------------
 
MATRIX RANK
 
Name:
    MATRIX RANK (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the rank of a matrix.
 
Description:
    The rank is the number of rows in a matrix with non-zero rows after
    the matrix has been reduced.
 
    DATAPLOT uses the singular value decomposition (SVD) to compute
    the rank.  The SVD computes the singular values and the rank is
    equal to the number of non-zero singular values.
 
    Since the rounding involved in using floating point arithmetic on
    a computer can result in only approximate zeros, one ambiguity is
    distinguishing between zeros and small singular values.  DATAPLOT
    uses the following default criterion:
        TOLERANCE = MAXIMUM(NUMBER OF ROWS, NUMBER OF COLUMNS) X
                         (FIRST SINGULAR VALUE) X EPS
    where
        EPS = 1./(1 + (134217727/2.0))
    Values smaller than the tolerance are considered to be zero.  An
    alternate form of the command allows you to specify your own
    tolerance value.
 
Syntax 1:
    LET <param> = MATRIX RANK <mat1>
    where <mat1> is a matrix for which the rank is to be
                 computed;
          <param> is a parameter where the resulting rank
                 is saved.
 
Syntax 2:
    LET <param> = MATRIX RANK <mat1> <tol>
    where <mat1> is a matrix for which the rank is to be
                 computed;
          <tol> is a number or parameter that specifies the tolerance
                 to use in determining zero singular values;
          <param> is a parameter where the resulting rank
                 is saved.
 
Examples:
    LET C = MATRIX RANK A
    LET C = MATRIX RANK A 0.0000001
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Linear Algebra
 
Implementation Date:
    93/8
 
Program:
    READ X Y
    -99 -99
    1 0
    0 1
    -1 0
    END OF DATA
    LET C1 = X**2 + Y**2
    LET C2 = X
    LET C3 = Y
    LET C4 = 1 FOR I = 1 1 4
    LET A = MATRIX DEFINITION C1 4 4
    LET ARANK = MATRIX RANK A
 
-----MATRIX RENUMBER (LET)----------------------------------------
 
MATRIX RENUMBER
 
Name:
    MATRIX RENUMBER (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Reorder the rows and columns of a matrix.
 
Description:
    It is on occassion useful to reorder the rows and/or the columns
    of a matrix.
 
Syntax:
    LET <mout> = MATRIX RENUMBER <m> <rows>  <cols>
                 <SUBSET/EXCEPT/FOR qualification>
    where <m> is the original matrix;
          <rows> is a variable containing the desired row order;
          <cols> is a variable containing the desired column order;
          <mout> is the matrix after the rows and columns have been
                 reordered;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET MOUT = MATRIX RENUMBER M VROWS VCOLS
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    READ MATRIX           = Read a matrix.
    MATRIX ADD ROW        = Add a row to a matrix.
    MATRIX COMBINE ROW    = Combine two matrices by rows.
    MATRIX COMBINE COLUMN = Combine two matrices by columns.
 
Reference:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 17.

Applications:
    Combinatorial Analysis
 
Implementation Date:
    2008/05
 
Program:
    .  Following example from page 157 of Nijenhuis and Wilf
    DIMENSION 100 COLUMNS
    READ MATRIX M
    23 24 25 26 27 28 29 21 22
    33 34 35 36 37 38 39 31 32
    93 94 95 96 97 98 99 91 92
    63 64 65 66 67 68 69 61 62
    73 74 75 76 77 78 79 71 72
    83 84 85 86 87 88 89 81 82
    53 54 55 56 57 58 59 51 52
    43 44 45 46 47 48 49 41 42
    13 14 15 16 17 18 19 11 12
    END OF DATA
    .
    LET ROWIND = DATA 2 3 9 6 7 8 5 4 1
    LET COLIND = DATA 3 4 5 6 7 8 9 1 2
    .
    LET MOUT = MATRIX RENUMBER M ROWIND COLIND
    SET WRITE DECIMALS 0
    PRINT MOUT

-----MATRIX REPLACE ELEMENT (LET)---------------------------------
 
MATRIX REPLACE ELEMENT
 
Name:
    MATRIX REPLACE ELEMENT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Replace an element of a matrix with a parameter.
 
Description:
    This command is typically useful in loops.  Note that the following
    syntax can also be used:
        LET M^K(J) = A
    where M is a matrix and K is a loop index.
 
Syntax:
    LET <mat2> = MATRIX REPLACE ELEMENT <mat1> <par> <rowid> <colid>
    where <mat1> is a matrix for which the element is to be replaced.
          <par> is a parameter;
          <rowid> is a number or parameter that specifies the row
               to be replaced;
          <colid> is a number or parameter that specifies the column
               to be replaced;
          <mat2> is a matrix where the replaced element is saved (it
               typically has the same name as <mat1>).
 
Examples:
    LET C = MATRIX MATRIX ELEMENT C A 3 2
    LET C = MATRIX REPLACE ELEMENT C A K J
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX ROW           = Extract a row of the matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Applications:
    Linear Algebra
 
Implementation Date:
    93/10
 
Program:
    . REPLACE THE DIAGONAL OF THE MATRIX WITH 1's
    READ MATRIX M
    14  37  32
    19  42  17
    12  17  10
    END OF DATA
    .
    LET NROW = MATRIX NUMBER OF COLUMNS M
    LET A = 1
    .
    LOOP FOR K = 1 1 NROW
       LET M = MATRIX REPLACE ELEMENT M A K K
    END OF LOOP
 
-----MATRIX REPLACE ROW (LET)---------------------------------
 
MATRIX REPLACE ROW
 
Name:
    MATRIX REPLACE ROW (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Copy a variable into a row of a matrix.
 
Description:
    This command is useful when operating on rows (rather than columns)
    of a matrix.  You can loop over the rows, extract a row, operate
    on the row, and then replace the row.  An example might be to
    subtract the row means from a matrix.  An alternative is to
    take the transpose of the matrix and loop over the columns of the
    transposed matrix.  Although this is simpler, it does not work
    when there are too many rows (the limits for matrices are 500 rows
    by 100 columns).
 
Syntax:
    LET <mat2> = MATRIX REPLACE ROW <mat1> <var> <rowid>
    where <mat1> is a matrix for which the row is to be replaced;
          <rowid> is the row number to be replaced;
          <var> is a variable;
    and   <mat2> is a matrix where the replaced row is saved (it
          typically has the same name as <mat1>).
 
Examples:
    LET C = MATRIX REPLACE ROW C A 3
    LET C = MATRIX REPLACE ROW C A 5
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX ELEMENT       = Extract an element of the matrix.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX ROW           = Extract a row of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Applications:
    Linear Algebra
 
Implementation Date:
    93/10
 
Program:
    .  MULTIPLYING A MATRIX BY A DIAGONAL MATRIX IS EQUIVALENT TO
    .  MULTIPLYING EACH ROW BY THE CORRESPONDING DIAGONAL ELEMENT.
    READ MATRIX M
    14  37  32
    19  42  17
    12  17  10
    END OF DATA
    .
    LET DIAG = DATA -6 8 4
    LET NROW = MATRIX NUMBER OF COLUMNS M
    .
    LOOP FOR K = 1 1 NROW
       LET TEMP = MATRIX ROW M K
       LET A = DIAG(K)
       LET TEMP = A*TEMP
       LET M = MATRIX REPLACE ROW M TEMP K
    END OF LOOP
    PRINT M
 
-----MATRIX ROW (LET)----------------------------------------
 
MATRIX ROW
 
Name:
    MATRIX ROW (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Copy a row of a matrix into a variable.
 
Description:
    This command is useful for generating row statistics for matrices.
    For small matrices, the matrix transpose command can be used (and
    then the rows of the original matrix correspond to columns in the
    transposed matrix).  However, if the number of rows is large, the
    transposed matrix can exceed the variable limit or the maximum
    number of columns for a matrix limit.  The MATRIX ROW can be used
    in conjunction with the LOOP command to handle these cases.
 
Syntax:
    LET <var> = MATRIX ROW <mat1> <rowid>
    where <mat1> is a matrix for which the row is to be extracted;
          <rowid> is the row number to be extracted;
          <var> is a variable where the resulting row is saved.
 
Examples:
    LET C = MATRIX ROW A 3
    LET C = MATRIX ROW A 5
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX ELEMENT       = Extract an element of the matrix.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Applications:
    Linear Algebra
 
Implementation Date:
    93/10
 
Program:
    .  COMPUTE ROW MEANS FOR THE FOLLOWING MATRIX
    READ MATRIX M
    14  37  32
    19  42  17
    12  17  10
    END OF DATA
    .
    LET NROW = MATRIX NUMBER OF COLUMNS M
    .
    LOOP FOR K = 1 1 NROW
       LET TEMP = MATRIX ROW M K
       LET A = MEAN TEMP
       LET ROWMEAN(K) = A
    END OF LOOP
    PRINT ROWMEAN
 
-----MATRIX ROW STATISTIC (LET)------------------------------------
 
MATRIX ROW STATISTIC
 
Name:
    MATRIX ROW STATSITIC (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute a user specified statistic for the rows of a matrix.
 
Description:
    The resulting computed statistics are saved in array.  The
    first row of the array is the statistic for row 1, the
    second row of the array is the statistic for row 2, and
    so on.
 
Syntax:
    LET <y> = MATRIX ROW <stat> <mat>
                            <SUBSET/EXCEPT/FOR qualification>
    where <mat> is a matrix for which the row statistic is
                to be computed;
          <stat> is the desired statistic to compute;
          <y> is a variable where the resulting row statistic
                is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    The specified statistic can be any of the following:
        MEAN, MIDMEAN, MEDIAN, TRIMMED MEAN, WINSORIZED MEAN,
        GEOMETRIC MEAN, HARMONIC MEAN, HODGES LEHMAN,
        BIWEIGHT LOCATION,
        SUM, PRODUCT, SIZE (or NUMBER or SIZE),
        STANDARD DEVIATION, STANDARD DEVIATION OF MEAN,
        VARIANCE, VARIANCE OF THE MEAN,
        TRIMMED MEAN STANDARD ERROR,
        AVERAGE ABSOLUTE DEVIATION (or AAD),
        MEDIAN ABSOLUTE DEVIATION (or MAD),
        IQ RANGE, BIWEIGHT MIDVARIANCE, BIWEIGHT SCALE,
        PERCENTAGE BEND MIDVARIANCE,
        WINSORIZED VARIANCE, WINSORIZED STANDARD DEVIATION,
        RELATIVE STANDARD DEVIATION, RELATIVE VARIANCE (or
           COEFFICIENT OF VARIATION),
        RANGE, MIDRANGE, MAXIMUM, MINIMUM, EXTREME,
        LOWER HINGE, UPPER HINGE, LOWER QUARTILE, UPPER QUARTILE,
        <FIRST/SECOND/THIRD/FOURTH/FIFTH/SIXTH/SEVENTH/EIGHTH/
            NINTH/TENTH> DECILE,
        PERCENTILE, QUANTILE, QUANTILE STANDARD ERROR,
        SKEWNESS, KURTOSIS, NORMAL PPCC,
        AUTOCORRELATION, AUTOCOVARIANCE,
        SINE FREQUENCY, SINE AMPLITUDE,
        CP, CPK, CNPK, CPM, CC,
        EXPECTED LOSS, PERCENT DEFECTIVE,
        TAGUCHI SN0 (or SN), TAGUCHI SN+ (or SNL),
        TAGUCHI SN- (or SNS), TAGUCHI SN00 (or SN2);

Examples:
    LET MMEAN = MATRIX ROW MEAN M
    LET MMEAN = MATRIX ROW MEDIAN M
    LET MMEAN = MATRIX ROW MEDIAN M  SUBSET TAG = 1 TO 2
 
Note:
    Matrices are created with either the READ MATRIX command or
    the MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION
    and HELP READ MATRIX for details.
 
Note:
    Statistics for the columns of a matrix can be computed
    using the MATRIX COLUMN STATISTIC command.  Enter
    HELP MATRIX COLUMN STATISTIC for details.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX COLUMN STATISTIC   = Compute column statistics for a
                                matrix.
    MATRIX COLUMN DIMENSION   = Dimension maximum number of columns
                                for Dataplot matrices.
 
Reference:
    "Applied Multivariate Statistical Analysis", Third Edition,
    Johnson and Wichern, Prentice-Hall, 1992.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    1998/8
    2002/8: List of supported statistics expanded.
 
Program:
    SKIP 25
    READ MATRIX IRIS.DAT M
    LET YM = MATRIX ROW MEANS M
    LET YSD = MATRIX ROW SD M
    SET WRITE DECIMALS 3
    PRINT YM YSD
 
-----MATRIX SCALE (LET)----------------------------------------
 
MATRIX SCALE
 
Name:
    MATRIX SCALE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Scale a matrix.
 
Description:
    For some computations, such as computing a distance matrix,
    it may be desirable to scale the matrix first.  The scaling
    may be performed over either over rows or over columns.

    Dataplot supports the following types of scaling.

      1) MEAN - subtract the column mean from each column of
         the matrix (or subtract the row mean from each row).

      2) SD - divide each column by the column standard 
         deviation (or divide each row by the row standard
         deviation).

      3) ZSCORE - subtract the column mean and then divide by
         the column standard deviation for each column (or
         subtract the row mean and divide by the row standard
         deviation for each row).
  
      4) RANGE - divide each column by the column range 
         (or divide each row by the row range).

    The type of scaling is specified by entering the command

        SET MATRIX SCALE <NONE/MEAN/SD/ZSCORE/RANGE>

    Specifying NONE applies no scaling.

Syntax 1:
    LET <mat2> = MATRIX ROW SCALE <mat1>
    where <mat1> is a matrix for which the matrix scaling is to
              be computed;
    and where <mat2> is a matrix where the resulting scaled 
             matrix is saved.
 
    This syntax scales relative to rows.  The scaled matrix can
    be the same as the original data matrix.

Syntax 2:
    LET <mat2> = MATRIX COLUMN SCALE <mat1>
    where <mat1> is a matrix for which the matrix scaling is to
              be computed;
    and where <mat2> is a matrix where the resulting scaled 
             matrix is saved.
 
    This syntax scales relative to columns.  The scaled matrix can
    be the same as the original data matrix.

Examples:
    SET MATRIX SCALE MEAN
    LET M = MATRIX ROW SCALE M
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    READ MATRIX                  = Read a matrix.
    MATRIX COLUMN DIMENSION      = Dimension maximum number of
                                   columns for Dataplot matrices.

    MATRIX DISTANCE              = Compute a distance matrix.
 
Reference:
    "Applied Multivariate Statistical Analysis", Third Edition,
    Johnson and Wichern, Prentice-Hall, 1992.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    1998/8
 
Program:
    DIMENSION 200 COLUMNS
    SKIP 25
    READ IRIS.DAT SEPLENG SEPWIDTH PETLENG PETWIDTH TAG
    SKIP 0
    LET NTOT = SIZE SEPLENG
    LET X = MATRIX DEFINITION SEPLENG NTOT 4
    SET MATRIX SCALE ZSCORE
    LET X = MATRIX COLUMN SCALING X

-----MATRIX SIMPLEX SOLUTION (LET)--------------------------------
 
MATRIX SIMPLEX SOLUTION
 
Name:
    MATRIX SIMPLEX SOLUTION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the simplex solution to a linear programming problem.
 
Description:
    Linear programming problems are used to solve problems where a
    number (call it m) of limited resources are to be allocated among a
    number (call it n) of competing activities.  The linear programming
    problem can be formulated as follows:
      1) Let Xj represent the level of activity j (for j = 1 to n).
      2) Let Bi represent the amount of resource i available (for
         i = 1 to m).
      3) Let Aij represent the amount of resource i consumed by
         activity j.
      4) Let Z be the overall measure of effectiveness and let Cj be
         the increase in Z that would result from each unit increase in
         Xj.
      This can be represented mathematically as
          Maximize Z = C1X1 + C2X2 + ... + CnXn
      subject to the restrictions
          A11X1 + A12X2 + ... + A1nXn <=  B1
          A21X1 + A22X2 + ... + A2nXn <=  B2
                     ...
          Am1X1 + Am2X2 + ... + AmnXn <=  Bm
     The function being maximized is called the objective function and
     the series of equations are called the constraints.  It is assumed
     that the A, B, and C parameters are known.  The MATRIX SIMPLEX
     SOLUTION command solves the series of constraints for the Xj.  The
     VECTOR DOT PRODUCT command is then used to find the value for the
     objective function (i.e., Z).  The above model also assumes that
     the Xj are non-negative.  It can also handle greater than
     inequalities in the constraint functions.
 
Syntax:
    LET <resp> = MATRIX SIMPLEX SOLUTION <obj>  <coef mat>
               <SUBSET/EXCEPT/FOR qualification>
    where <obj> is a variable containing the coefficients for the
                objective function;
          <resp> is a variable containing the values for Xj computed by
                the simplex solution;
          <coef mat> is a matrix containing the coefficients for the
                constraint equations.  It has the following form:
                      <coef mat> = [ Aij | tag | Bi]
                 where Aij and Bi are as defined above and tag is a
                 column that defines the type of inequality (-1 for <=,
                 0 for =, 1 for >=);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET X = MATRIX SIMPLEX SOLUTION F C
    LET PROFIT = VECTOR DOT PRODUCT F X
 
Note:
    Matrices are created with either the READ MATRIX command or
    the MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION
    and HELP READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by
    appending an index to the matrix name.  For example, the 4x4
    matrix C has columns C1, C2, C3, and C4.  These columns can
    be operated on like any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    "Numerical Recipes: The Art of Scientific Computing (FORTRAN
    Version)", Press, Flannery, Teukolsky, and Vetterling.  Cambridge
    University Press, 1989 (chapter 10).
 
    "Operations Research", Hiller and Lieberman.  Holden-Day, 1974.
 
Applications:
    Linear Programming
 
Implementation Date:
    87/10
 
Program:
    . PURPOSE--DETERMINE PRODUCTION MIX OF 2 OILS TO MAXIMIZE
    . PROFITS.  ANALYSIS TECHNIQUE--SIMPLEX METHOD IN LINEAR
    . PROGRAMMING. (4 VARIABLES, 10 CONSTRAINTS)
    . APPLICATION--PRODUCTION OPTIMIZATION
    . TO FIND--4 PRODUCTIONS SETTINGS--
    .          X1 = NUMBER OF BARRELS OF DOMESTIC OIL TO BLEND
    .               INTO REGULAR GAS.
    .          X2 = NUMBER OF BARRELS OF FOREIGN  OIL TO BLEND
    .               INTO REGULAR  GAS.
    .          X3 = NUMBER OF BARRELS OF DOMESTIC OIL TO BLEND
    .               INTO PREMIUM GAS.
    .          X4 = NUMBER OF BARRELS OF FOREIGN  OIL TO BLEND
    .               INTO PREMIUM GAS.
    . CONSTRAINTS ARE BASED ON--
    .    COST (/BBL)       --DOMESTIC = $8       FOREIGN = $14
    .    INVENTORY (BBL)   --DOMESTIC = 40,000   FOREIGN = 60,000
    .    OCTANE RATING     --DOMESTIC = 87       FOREIGN = 98
    .    VAPOR PRESSURE    --DOMESTIC = 25       FOREIGN = 15
    .    REVENUE (/BBL)    --REGULAR  = $12      PREMIUM = $14
    .    MAX DEMAND (BBL/WK)-REGULAR  = 100,000  PREMIUM = 20,000
    .    MIN OCTANE        --REGULAR  = 88       PREMIUM = 93
    .    MAX VAPOR PRESSURE--REGULAR  = 23       PREMIUM = 23
    . NOTE--A   FEASIBLE SOLUTION IS 0, 50000, 0, 5000.  (BUT
    .       WITH A LOSS OF $155000).  THE OPTIMAL SOLUTION IS
    .       37727.3, 12272.7, 2272.7, 2727.3. (PROFIT OF $125000)
    ECHO
    DIMENSION 100 VARIABLES
    .      DEFINE THE COEFFICIENTS OF THE OBJECTIVE FUNCTION
    LET F = DATA 4 -3 6 -1
    .      DEFINE THE CONSTRAINTS CONSISTING OF LEFT-SIDE
    .      COEFFICIENTS CODED INEQUALITY (< AS -1, = AS 0,
    .       > AS +1)  AND RIGHT-SIDE LIMITS.
    READ MATRIX C
    1 1 0 0     -1   100000
    0 0 1 1     -1    20000
    1 0 1 0     -1    40000
    0 1 0 1     -1    60000
    1 -10 0 0   -1        0
    0 0 6 -5    -1        0
    2 -8 0 0    -1        0
    0 0 2 -8    -1        0
    1 1 0 0     +1    50000
    0 0 1 1     +1     5000
    END OF DATA
    PRINT F C
    .      GENERATE THE SIMPLEX SOLUTION
    LET X = MATRIX SIMPLEX SOLUTION F C
    LET PROFIT = VECTOR DOT PRODUCT F X
    PRINT F X PROFIT
 
-----MATRIX SOLUTION (LET)--------------------------------------------
 
MATRIX SOLUTION
 
Name:
    MATRIX SOLUTION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Solve a system of linear equations in the following form:
          A*X=B
    where A is the matrix of coefficients, B is a vector of constants,
    and X are the variables to be solved for.
 
 
Description:
    In practice, the solution of a system of linear equations, finding
    the inverse of a matrix, and computing the determinant of a matrix
    are all closely related.  Each of these can be computed from the
    LU decomposition of a matrix.
 
Syntax:
    LET <resp> = MATRIX SOLUTION <mat1> <vector>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix containing the coefficients of the
                 equation;
          <vector> is an array of constants (i.e., the values for the
                 right hand side of the equation;
          <resp> is a vector where the resulting matrix solution is
                 saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET X = MATRIX SOLUTION A B
 
Note:
    DATAPLOT uses LINPACK routines to calculate the LU decomposition
    (versions prior to 7/93 use the LUDCMP and LUBKSB routines from
    the Numerical Recipes book).
 
    The reciprocal of the condition number is printed.  This number
    gives an indication of the numerical accuracy that was obtained
    when calculating the solution.  If this number is approximately
    10**(-d), then the elements of the LU decomposed matrix generally
    have d fewer significant digits than the original matrix.
 
    The MATRIX ITERATIVE SOLUTION command can be used to generate a
    solution vector with higher precision.
 
Note:
    The TRIDIAGONAL SOLVE and TRIANGULAR SOLVE can be used to solve
    tridiagonal and triangular systems of equations.  These commands
    are faster than MATRIX SOLUTION when they apply, and in the case
    of TRIDIAGONAL SOLVE can be used to handle larger systems of
    equations.
 
Note:
    Matrices used to solve systems of linear equations must have the
    same number of rows and columns.  An error message is printed if
    they do not.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX ITERATIVE SOLU= Solve a system of linear equations and
                           apply iterative improvement.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
    TRIANGULAR SOLVE     = Solve a triangular system of linear
                           equations.
    TRIDIAGONAL SOLVE    = Solve a tridiagonal system of linear
                           equations.
 
Reference:
    "LINPACK User's Guide", Dongarra, Bunch, Moler, Stewart.  Siam,
    1979.
 
    "Numerical Recipes: The Art of Scientific Programming (FORTRAN
    Version)", Press, Flannery, Teukolsky, and Vetterling.  Cambridge
    University Press, 1989 (chapter 2).
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    . THIS IS THE DATAPLOT PROGRAM FILE     CHEMMIX.DP
    . PURPOSE--DETERMINE PROPER FEED RATE OF 4 INPUT COMPOSITIONS
    .          TO YIELD A PRE-SPECIFIED OUTPUT COMPOSITION AT A
    .          PRE-SPECIFIED OUTPUT RATE.
    . ANALYSIS TECHNIQUE--SOLVING A SYSTEM OF 4 LINEAR EQUATIONS
    . APPLICATION--CHEMICAL MIXING
    . SOURCE--FOGIEL, THE LINEAR ALGEBRA PROBLEM SOLVER RESEARCH
    .         RESEARCH AND EDUCATION ASSOCIATION, 1980 (PAGE 792)
    . GIVEN--INPUT PROPORTIONS--
    .                               IN1     IN2     IN3     IN4
    .           SULFURIC ACID       80%      0%     30%     10%
    .           NITRIC ACID          0%     80%     10%     10%
    .           WATER               16%     20%     60%     72%
    .           INERT                4%      0%      0%      8%
    . GIVEN--DESIRED OUTPUT (2000 LB/HR) AT THE FOLLOWING
    .        PROPORTIONS--
    .           SULFURIC ACID       40% (800 LB PER HOUR)
    .           NITRIC ACID         27% (540 LB PER HOUR)
    .           WATER               31% (620 LB PER HOUR)
    .           INERT                2% (40 LB PER HOUR)
    . TO FIND X1 = FLOW RATE OF INPUT STREAM 1
    .         X2 = FLOW RATE OF INPUT STREAM 2
    .         X3 = FLOW RATE OF INPUT STREAM 3
    .         X4 = FLOW RATE OF INPUT STREAM 4
    . NOTE--TO SET UP THE 4 EQUATIONS (ONE FOR EACH COMPOUND)
    .       APPLY CONSERVATION OF MASS (MASS BALANCES)
    . NOTE--FOR TESTING PURPOSES, THE SOLUTION IS
    .       800  600  500  100   LB PER HOUR
    . -----START POINT-----------------------------------
    .
    .      STEP 1-- DEFINE THE LEFT-HAND SIDE.
    .
    READ MATRIX A
    .80 .00 .30 .10
    .00 .80 .10 .10
    .16 .20 .60 .72
    .04 .00 .00 .08
    END OF DATA
    .      STEP 2-- DEFINE THE RIGHT-HAND SIDE.
    LET B = DATA 800 540 620 40
    PRINT A B
    .      STEP 3-- SOLVE THE LINEAR SYSTEM
    LET X = MATRIX SOLUTION A B
    PRINT X
 
-----MATRIX SPECTRAL NORM (LET)--------------------------------------
 
MATRIX SPECTRAL NORM
 
Name:
    MATRIX SPECTRAL NORM (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the spectral norm of a matrix.
 
Description:
    The spectral norm of a matrix is the square root of the largest
    eigenvalue of the matrix times its transpose.
 
Syntax:
    LET <param> = MATRIX SPECTRAL NORM <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the spectral norm is to be
                 computed;
          <param> is a parameter where the spectral norm is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 used in this context).
 
Examples:
    LET C = MATRIX SPECTRAL NORM A
 
Note:
    Matrices for which the spectral norm is computed  must have the
    same number of rows and columns.  An error message is printed if
    they do not.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    "A First Course in Numerical Analysis", 2nd ed., Ralston and
     Rabinowitz, 1978, McGraw-Hill.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
    16 16 19 21 20 23
    14 17 15 22 18 22
    24 23 21 24 20 23
    18 17 16 15 20 19
    18 11  9 18  7 14
    END OF DATA
    LET SN = MATRIX SPECTRAL NORM X
 
-----MATRIX SPECTRAL RADIUS (LET)--------------------------------------
 
MATRIX SPECTRAL RADIUS
 
Name:
    MATRIX SPECTRAL RADIUS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the spectral radius of a matrix.
 
Description:
    The spectral radius is the maximum of the absolute values of the
    eigenvalues of a matrix.
 
Syntax:
    LET <param> = MATRIX SPECTRAL RADIUS <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the spectral radius is to be
                 computed;
          <param> is a parameter where the resulting spectral radius is
                 saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET C = MATRIX SPECTRAL RADIUS A
 
Note:
    Matrices for which the spectral radius is computed must have the
    same number of rows and columns.  An error message is printed if
    they do not.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    "A First Course in Numerical Analysis", 2nd ed., Ralston and
     Rabinowitz, 1978, McGraw-Hill.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
    16 16 19 21 20 23
    14 17 15 22 18 22
    24 23 21 24 20 23
    18 17 16 15 20 19
    18 11  9 18  7 14
    END OF DATA
    LET C = VARIANCE-COVARIANCE MATRIX X
    LET SR = MATRIX SPECTRAL RADIUS C
    PRINT SR
 
-----MATRIX SUBMATRIX (LET)--------------------------------------------
 
MATRIX SUBMATRIX
 
Name:
    MATRIX SUBMATRIX (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Create a new matrix with row i and column j of the original
    (square) matrix removed.
 
Syntax:
    LET <mat2> = MATRIX SUBMATRIX <mat1> <rowid> <colid>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is the original matrix;
          <mat2> is a matrix where the desired submatrix is saved;
          <rowid> is the row of the original matrix to remove;
          <colid> is the column of the original matrix to remove;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET C = MATRIX SUBMATRIX A 2 3
 
Note:
    The original matrix must have an equal number of rows and columns.
    If this is not the case, an error message is printed.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
    16 16 19 21 20
    14 17 15 22 18
    24 23 21 24 20
    18 17 16 15 20
    18 11  9 18  7
    END OF DATA
    LET A = MATRIX SUBMATRIX X 2 3
    PRINT A
 
-----MATRIX SUBTRACTION (LET)-----------------------------------------
 
MATRIX SUBTRACTION
 
Name:
    MATRIX SUBTRACTION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Subtract 2 matrices, a vector from a matrix, or a parameter from
    a matrix.
 
Description:
    Matrix subtraction is carried out by subtracting the corresponding
    elements of the two matrices.  If a parameter is subtracted from a
    matrix, the parameter is subtracted from each element of the
    matrix.  If a vector is subtracted from a matrix, the vector is
    subtracted from each column of the matrix (i.e., the corresponding
    rows are subtracted).
 
Syntax 1: (2 matrices)
    LET <mat3> = MATRIX SUBTRACTION <mat1> <mat2>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix;
          <mat2> is a matrix;
          <mat3> is a matrix where the resulting matrix subtraction is
                 saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Syntax 2: (a matrix and a parameter)
    LET <mat3> = MATRIX SUBTRACTION <mat1> <par>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix;
          <par> is a number or a parameter;
          <mat3> is a matrix where the resulting matrix subtraction is
                 saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Syntax 3: (a matrix and a variable)
    LET <mat3> = MATRIX SUBTRACTION <mat1> <var>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix;
          <var> is a variable;
          <mat3> is a matrix where the resulting matrix subtraction is
                 saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET C = MATRIX SUBTRACTION A B
    LET C = MATRIX SUBTRACTION A 2
    LET C = MATRIX SUBTRACTION A V
 
Note:
    Matrices to be subtracted must have the same number of rows and
    columns.  A vector to be subtracted from a matrix must have the
    same number of rows as the matrix.  An error message is printed if
    either of these conditions is violated.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    READ MATRIX A
    1 2 3
    4 5 6
    7 8 9
    END OF DATA
    READ MATRIX B
    1 1 1
    2 2 2
    3 3 3
    END OF DATA
    LET C = MATRIX SUBTRACTION A B
    PRINT C
    The resulting matrix C contains:
       0  1  2
       2  3  4
       4  5  6
 
-----MATRIX SUM (LET)----------------------------------------
 
MATRIX SUM
 
Name:
    MATRIX SUM (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the sum of all elements of a matrix.
 
Syntax:
    LET <par> = MATRIX SUM <mat> <SUBSET/EXCEPT/FOR qualification>
    where <mat> is a matrix for which the sum is to be computed;
          <par> is a parameter where the resulting sum is saved.
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MATRIX SUM M
    LET A = MATRIX SUM M SUBSET TAG = 1 TO 2
 
Note:
    Matrices can be created with the READ MATRIX, CREATE MATRIX,
    and MATRIX DEFINITION commands.  Enter HELP MATRIX DEFINITION,
    HELP READ MATRIX, and HELP CREATE MATRIX for details.
 
Note:
    Row and column statistics for a matrix can be computed
    using the MATRIX ROW STATISTIC and MATRIX COLUMN STATISTIC
    commands.  Enter HELP MATRIX ROW STATISTIC and
    HELP MATRIX COLUMN STATISTIC for details.
 
    Statistics for equi-sized sub-matrices of the original matrix
    can be computed with the MATRIX PARTITION STATISTIC command.
    Enter HELP MATRIX PARTITION STATISTIC for details.

    Other statistics for the entire matrix can be computed with
    the command MATRIX GRAND STATISTIC.  Enter HELP GRAND STATISTIC
    for details.

Default:
    None
 
Synonyms:
    MATRIX GRAND SUM is a synonym for MATRIX SUM.
 
Related Commands:
    MATRIX COLUMN STATISTIC     = Compute column statistics for a
                                  matrix.
    MATRIX ROW STATISTIC        = Compute row statistics for a matrix.
    MATRIX PARTITION STATISTIC  = Compute statistics for equi-sized
                                  sub-matrices of a matrix.
    MATRIX GRAND STATISTIC      = Compute statistics for all elements
                                  of a matrix.
    MATRIX MEAN                 = Compute the mean for all elements
                                  of a matrix.
    MATRIX COLUMN DIMENSION     = Dimension maximum number of columns
                                  for Dataplot matrices.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    2005/6
 
Program:
    READ MATRIX M
    1 2 3 4
    5 6 7 8
    0 10 11 12
    13 14 15 16
    END OF DATA
    LET A = MATRIX SUM A
 
-----MATRIX TO VARIABLE--------------------------------------------
 
MATRIX TO VARIABLE
 
Name:
    MATRIX TO VARIABLE
 
Type:
    LET Subcommand
 
Purpose:
    Convert a matrix to a variable.
 
Description:
    There may be times when it is desirable to convert a matrix
    to a variable.  This command provides a simple and convenient
    method for converting a matrix to a variable.

Syntax:
    LET <y> = MATRIX TO VARIABLE <m>
              <SUBSET/EXPCEPT/FOR qualification>
    where <m> is the previously created matrix;
          <y> is the resulting response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y = MATRIX TO VARIABLE M
 
Note:
    By default, the variable is created in column order from the
    matrix.  That is, column 1 of the matrix is extracted, then
    column 2 of the matrix, and so on.  To create the variable in
    row order, enter the command

        SET MATRIX TO VARIABLE ROW

    To restore column order, enter

        SET MATRIX TO VARIABLE COLUMN

Note:
    It is also sometimes desirable to convert a variable to a
    matrix.  This can be done with the command

        LET M = VARIABLE TO MATRIX Y

    where Y is a previously created variable.

Default:
    None.
 
Synonyms:
    None
 
Related Commands:
    VARIABLE TO MATRIX   = Convert a variable to a matrix.
 
Applications:
    Data Management
 
Implementation Date:
    2010/11
 
Program 1:
    READ MATRIX M
    1 2 3
    4 5 6
    7 8 9
    END OF DATA
    .
    LET Y1 = MATRIX TO VARIABLE M
    SET WRITE DECIMALS 1
    PRINT Y1 Y2

-----MATRIX TRACE (LET)----------------------------------------
 
MATRIX TRACE
 
Name:
    MATRIX TRACE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the trace of a matrix.
 
Description:
    The trace is the sum of the diagonal entries of a matrix.
 
Syntax:
    LET <param> = MATRIX TRACE <mat1> <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the trace is to be computed;
          <param> is a parameter where the resulting trace is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET C = MATRIX TRACE A
 
Note:
    The matrix for which the trace is computed must have the same
    number of rows and columns.  An error message is printed if they do
    not match.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    READ MATRIX X
    16 16 19 21 20
    14 17 15 22 18
    24 23 21 24 20
    18 17 16 15 20
    18 11  9 18  7
    END OF DATA
    LET A = MATRIX TRACE X
    PRINT A
 
-----MATRIX TRANSPOSE (LET)----------------------------------------
 
MATRIX TRANSPOSE
 
Name:
    MATRIX TRANSPOSE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the transpose of a matrix.
 
Description:
    The transpose of a matrix is another matrix in which the rows and
    columns have been reversed.  For example,
 
          A = a11  a12  a13
              a21  a22  a23
              a31  a32  a33
    would have the transpose--
          T = a11  a21  a31
              a12  a22  a32
              a13  a23  a33
 
Syntax:
    LET <mat2> = MATRIX TRANSPOSE <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the transpose is to be computed;
          <mat2> is a matrix where the resulting transpose is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
               rarely used in this context).
 
Examples:
    LET C = MATRIX TRANSPOSE A
 
Note:
    The row and column dimensions for the transposed matrix are
    the opposite dimensions of the original matrix.  This means that
    the number of rows in the original matrix cannot be larger than the
    column limit for matrices (100 in the current implementation).
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Note:
    DATAPLOT can compute column statistics for matrices fairly easily.
    For example, to compute the means of the 5 columns of matrix M, do
    the following:
       LOOP FOR K = 1 1 5
          LET MEAN^K = MEAN M^K
       END OF LOOP
    However, DATAPLOT does not compute statistics for rows directly.
    The MATRIX TRANSPOSE command can be used for this purpose (the
    columns of the transpose correspond to the rows of the original
    matrix).  For example, to compute the row means for the above
    matrix M, do the following:
       LET N = SIZE M1
       LET MT = MATRIX TRANSPOSE M
       LOOP FOR K = 1 1 N
          LET ROWM^K = MEAN MT^K
       END OF LOOP
    The program example shows how this can be used to compute a
    chi-square (the CROSS TABULATE command does it directly).
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPLE COMPONENTS = Compute the principle components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Linear Algebra
 
Implementation Date:
    87/10
 
Program:
    .  COMPUTE CHI-SQUARE TEST FOR FOLLOWING FREQUENCY MATRIX:
    READ MATRIX M
    14  37  32
    19  42  17
    12  17  10
    END OF DATA
    LET NROW = SIZE M1
    LET NCOL = MATRIX NUMBER OF COLUMNS M
    LOOP FOR K = 1 1 NCOL
       LET COLT^K = SUM M^K
    END OF LOOP
    LET MT = MATRIX TRANSPOSE M
    LOOP FOR K = 1 1 NROW
       LET TEMP = SUM MT^K
       LET ROWT(K) = TEMP
    END OF LOOP
    LET GT = SUM ROWT
    LET CHISQ = 0
    LOOP FOR K = 1 1 NCOL
      LET E = ROWT*(COLT^K/GT)
      LET E = (M^K - E)**2/E
      LET A = SUM E
      LET CHISQ = CHISQ + A
    END OF LOOP
    LET DF = (NROW-1)*(NCOL-1)
    LET CV = CHSPPF(.95,DF)
    PRINT "THE CHI-SQUARE TEST STATISTIC = ^CHISQ"
    PRINT "THE CRITICAL VALUE (ALPHA = .05) = ^CV"
 
-----MATRIX TRUNCATION (LET)--------------------------------
 
MATRIX TRUNCATION
 
Name:
    MATRIX TRUNCATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Set all elements in a matrix less than (or greater than)
    a specified value to that value.

 
Description:
    The primary motivation for this command is to subtract
    a background value from a matrix.  This can be accomplished
    by using the MATRIX SUBTRACT command to subtract the
    background value and then using the MATRIX TRUNCATION
    command to set all negative values to zero.

Syntax 1:
    LET <Z> = MATRIX TRUNCATION <M> <VALUE>
    where <M> is a matrix;
          <VALUE> is a parameter or a number that specifies
               the truncation value;
    and   <Z> is the matrix that is returned after the
               truncation is applied.
 
    This syntax is used to perform lower truncation (that is,
    any values less than <VALUE> are set equal to <VALUE>.
    The <Z> matrix can be the same as the <M> matrix.

Syntax 2:
    LET <Z> = MATRIX UPPER TRUNCATION <M> <VALUE>
    where <M> is a matrix;
          <VALUE> is a parameter or a number that specifies
               the truncation value;
    and   <Z> is the matrix that is returned after the
               truncation is applied.
 
    This syntax is used to perform upper truncation (that is,
    any values greater than <VALUE> are set equal to <VALUE>.
    The <Z> matrix can be the same as the <M> matrix.

Examples:
    LET VALUE = 8
    LET M = MATRIX TRUNCATION M VALUE

Default:
    None
 
Synonyms:
    MATRIX LOWER TRUNCATION is a synonym for MATRIX TRUNCATION
 
Related Commands:
    MATRIX SUBTRACTION     = Perform matrix subtraction.
    MATRIX ADDITION        = Perform matrix addition.
    MATRIX MULTIPLICATION  = Perform matrix truncation.
 
Applications:
    Matrix Arithmetic
 
Implementation Date:
    2006/3
 
Program:
    READ MATRIX M
     1  2  3
     4  5  6
     7  8  9
    10 11 12
    END OF DATA
    .
    LET ZERO = 0
    LET AVAL = 4
    LET M = MATRIX SUBTRACTION M AVAL
    LET M = MATRIX TRUNCATION M ZERO
    .
    SET WRITE DECIMALS 0
    PRINT M

-----MAX (LET)--------------------------------
 
MAX
 
Name:
    MAX (LET)
 
Type:
    Library Function
 
Purpose:
    Return the maximum of 2 to 8 numbers.
 
Syntax:
    LET <yout> = MAX(<y1>, ..., <yk>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1>, ..., <yk> is a list of two to eight variables, parameters
               or number(s);
          <yout> is a variable or a parameter (depending on what <y1>
               ... <yk> are) where the computed maximum values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MAX(14,10)
    LET A = MAX(A1,A2)
    LET A = MAX(A1,A2,A3,A4)
    LET X2 = MAX(X1,X4)
    LET X2 = MAX(X1-4,X2+6)
 
Note:
    This function is distinct from the LET subcommand MAXIMUM.  This
    command compares two through eight parameters (or a comparison of the
    corresponding elements in two through eight variables) while MAXIMUM
    returns the largest value in a single variable.
 
Note:
    The 2010/12 version of Dataplot added support for up to eight input
    arguments.  For example,

        LET AMAX = MAX(A1,A2,A3,A4,A5,A6,A7,A8)

    Versions prior to this only accepted two input arguments.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MIN      = Compute the minimum of two to eight numbers.
    MAXIMUM  = Compute the maximum value in a variable.
    MINIMUM  = Compute the minimum value in a variable.
    ABS      = Compute the absolute value of a number.
 
Applications:
    Data Management
 
Implementation Date:
    Pre-1987
    2010/12: Support for up to eight arguments.
 
Program:
    LET X = SEQUENCE 0 .1 3
    LET Y1 = X**2
    LET Y2 = X**(1/2)
    LET Y3 = MAX(Y1,Y2)
    PRINT Y1 Y2 Y3
 
-----MAXIMUM--------------------------------------------------
 
 
Name:
    ...MAXIMUM
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the maximum value to appear on the plot axes of
    subsequent plots.
 
Description:
    For most data analysis applications, the analyst need not bother
    with the MAXIMUM command since DATAPLOT generates neat limits based
    on the data.  If the default limits are not acceptable, then the
    analyst can make use of the MINIMUM, MAXIMUM, or LIMITS commands to
    specify the minimum, maximum, or both, respectively.
 
Syntax:
    <prefix>MAXIMUM   <n>
    where <n> is a number or parameter that specifies the desired upper
              limit;
    and   <prefix> is one of the following:
              X             refers to vertical axis
              Y             refers to horizontal axis
              no prefix     refers to both axes.
 
Examples:
    MAXIMUM 4.5
    XMAXIMUM 100
    YMAXIMUM 100
    XMAXIMUM A
 
Note:
    The ...MAXIMUM command with no argument reverts the maxima to the
    default.  A ...MAXIMUM command with no prefix refers to both axes.
    Thus MAXIMUM 3 sets the maxima for both axes to 3.
 
Default:
    Automatically computed neat maxima based on the data.
 
Synonyms:
    MAX
 
Related Commands:
    PLOT        = Generates a data or function plot.
    MINIMUM     = Sets the frame minima for all plots.
    LIMITS      = Sets the frame limits for all plots.
    CLASS UPPER = Sets the upper class maximum for histograms,
                  frequency plots, and pie charts.
    CLASS LOWER = Sets the lower class minimum for histograms,
                  frequency plots, and pie charts.
    CLASS LOWER = Sets the class width for histograms, frequency plots,
                  and pie charts.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE MAXIMUM COMMAND
    X1LABEL LEAD
    Y1LABEL POTASSIUM
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    .
    XMAXIMUM 600
    XTIC OFFSET 0 15
    YMAXIMUM 450
    .
    PLOT POT VS LEAD
 
 
 
 
Name:
    MAXIMUM (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the maximum value in a variable.
 
Syntax:
    LET <param> = MAXIMUM <resp>   <SUBSET/EXCEPT/FOR qualification>
    where <resp> is the variable for which the maximum is to be
                 computed;
          <param> is a parameter where the maximum value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A1 = MAXIMUM Y1
    LET A1 = MAXIMUM Y1 SUBSET Y1 > 0
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MINIMUM   = Compute the minimum of a variable.
    MEAN      = Compute the mean of a variable.
    MAX       = Library function to compute the maximum of 2 numbers.
 
Applications:
    Data Transformation
 
Implementation Date:
    Pre-1987
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET A = MAXIMUM Y1
 
-----MAXCDF (LET)--------------------------------
 
MAXCDF
 
Name:
    MAXCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Maxwell-Boltzman cumulative distribution function.
 
Description:
    The Maxwell-Boltzman distribution has the following cumulative
    distribution function:

       F(x;mu,sigma)=2*GAMMAI(3/2,0.5*(1/sigma**2)*(x-mu)**2)/SQRT(PI)
                     x >= mu; sigma > 0
 
    with mu and sigma denoting the location and scale parameters,
    respectively, and GAMMAI denoting the incomplete gamma function.

    The case where mu = 0 and sigma = 1 is referred to as the
    standard Maxwell-Boltzman distribution.

    The Maxwell-Boltzman distribution is equivalent to the chi
    distribution with 3 degrees of freedom.

    The Maxwell-Boltzman distribution is sometimes parameterized
    using

        a = 1/sigma**2

    In scientific applications, the sigma parameter may be
    parameterized in a way that has physical meaning.

Syntax:
    LET <y> = MAXCDF(<x>,<loc>,<sigma>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, number, or parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <sigma> is an optional number or parameter that specifies the
              value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Maxwell-Boltzman cdf value
              is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <sigma> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET Y = MAXCDF(3)
    LET Y = MAXCDF(3,0,0.3)
    LET Y = MAXCDF(X1,MU,SIGMA)
    PLOT MAXCDF(X,0,SIGMA) FOR X = 0  0.01  5
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MAXPDF = Compute the Maxwell probability density function.
    MAXPPF = Compute the Maxwell percent point function.
    CHCDF  = Compute the chi probability density function.
    RAYCDF = Compute the Rayleigh probability density function.
    WEICDF = Compute the Weibull probability density function.
    NORCDF = Compute the normal probability density function.
    LGNCDF = Compute the lognormal probability density function.
 
Reference:
    Johnson, Kotz, and Balakrishnan (1994), "Continuous Univariate
    Distributions: Volume I", Second Edition, Wiley, p. 451.

Applications:
    Distributional Modeling, Statistical Physics
 
Implementation Date:
    7/2004
    2/2008: Corrected sigma to be a scale parameter rather than
            a shape parameter
 
Program:
    Y1LABEL Probability
    X1LABEL X
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE Maxwell Cumulative Distribution
    PLOT MAXCDF(X) FOR X = 0  0.01  5
 
-----MAXPDF (LET)--------------------------------
 
MAXPDF
 
Name:
    MAXPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Maxwell-Boltzman probability density function.
 
Description:
    The Maxwell-Boltzman distribution has the following
    probability density function:

       f(x;mu,sigma)=SQRT(2/PI)*(1/sigma**2)**(3/2)*(x-mu)**2*
                     EXP(-(x-mu)**2/(2*sigma**2))
                     x >= mu; sigma > 0
 
    with mu and sigma denoting the location and scale parameters,
    respectively.

    The case where mu = 0 and sigma = 1 is referred to as the
    standard Maxwell-Boltzman distribution.

    The Maxwell-Boltzman distribution is equivalent to the chi
    distribution with 3 degrees of freedom.

    The Maxwell-Boltzman distribution is sometimes parameterized
    using

        a = 1/sigma**2

    In scientific applications, the sigma parameter may be
    parameterized in a way that has physical meaning.

Syntax:
    LET <y> = MAXPDF(<x>,<loc>,<sigma>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, number, or parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <sigma> is an optional number or parameter that specifies the
              value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Maxwell-Boltzman pdf value
              is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <sigma> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET Y = MAXPDF(3)
    LET Y = MAXPDF(3,0,0.3)
    LET Y = MAXPDF(X1,MU,SIGMA)
    PLOT MAXPDF(X,0,SIGMA) FOR X = 0  0.01  5
 
Note:
    To generate Maxwell random numbers, probability plots, and
    goodness of fit tests, enter the following commands

        LET Y = MAXWELL RANDOM NUMBERS FOR I = 1 1 N
        MAXWELL PROBABILITY PLOT Y
        MAXWELL PROBABILITY PLOT Y X
        MAXWELL PROBABILITY PLOT Y XLOW XHIGH
        MAXWELL KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
        MAXWELL CHI-SQUARE GOODNESS OF FIT Y X
        MAXWELL CHI-SQUARE GOODNESS OF FIT Y XLOW XHIGH

      You can use the probability plot to estimate mu and
      sigma:

            MAXWELL PROBABILITY PLOT Y
            LET SIGMA = PPA1
            LET MU = PPA0

      You can obtain a maximum likelihood estimate of sigma
      with the command

           MAXWELL MAXIMUM LIKELIHOOD Y

      This command will generate an estimate of sigma using 0 as the
      estimate of location and an estimate of sigma using the
      minimum of the data as an estimate of location.
      If the data minimum is negative, then both cases will
      use the data minimum as the estimate of location (i.e.,
      the estimate of sigma will be the same).  If you have a
      different estimate of locaiton, enter the command

           LET MAXWLOC = <value>

      before the MAXWELL MAXIMUM LIKELIHOOD command.  This will
      be used in place of the data minimum estimate of location.

      Uncertainty estimates can be obtained using the
      DISTRIBUTIONAL BOOTSTRAP command for the both the
      probability plot and maximum likelihood cases.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MAXCDF = Compute the Maxwell cumulative distribution function.
    MAXPPF = Compute the Maxwell percent point function.
    CHPDF  = Compute the chi probability density function.
    RAYPDF = Compute the Rayleigh probability density function.
    WEIPDF = Compute the Weibull probability density function.
    NORPDF = Compute the normal probability density function.
    LGNPDF = Compute the lognormal probability density function.
 
Reference:
    Johnson, Kotz, and Balakrishnan (1994), "Continuous Univariate
    Distributions: Volume I", Second Edition, Wiley, p. 451.

Applications:
    Distributional Modeling, Statistical Physics
 
Implementation Date:
    7/2004
    2/2008: Corrected sigma to be a scale parameter rather than
            a shape parameter
 
Program:
    Y1LABEL Probability
    X1LABEL X
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE Maxwell Probability Density
    PLOT MAXPDF(X,1) FOR X = 0  0.01  5
 
-----MAXPPF (LET)--------------------------------
 
MAXPPF
 
Name:
    MAXPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Maxwell-Boltzman percent point function.
 
Description:
    The Maxwell-Boltzman distribution has the following cumulative
    distribution function:

       F(x;mu,sigma) = 2*GAMMAI(3/2,0.5*(1/sigma**2)*(x-mu)**2)/SQRT(PI)
                       x >= mu; sigma > 0
 
    with mu and sigma denoting the location and scale parameters,
    respectively, and GAMMAI denoting the incomplete gamma function.

    The percent point function is the inverse of the cumulative
    distribution function and the Maxwell-Boltzman percent point
    function is computed by numerically inverting the above
    cumulative distribution function.

    The case where mu = 0 and sigma = 1 is referred to as the
    standard Maxwell-Boltzman distribution.

    The Maxwell-Boltzman distribution is equivalent to the chi
    distribution with 3 degrees of freedom.

    The Maxwell-Boltzman distribution is sometimes parameterized
    using

        a = 1/sigma**2

    In scientific applications, the sigma parameter may be
    parameterized in a way that has physical meaning.

Syntax:
    LET <y> = MAXPPF(<p>,<loc>,<sigma>)
              <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, number, or parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <sigma> is an optional number or parameter that specifies the
              value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Maxwell-Boltzman ppf value
              is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <sigma> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET Y = MAXPPF(0.95)
    LET Y = MAXPPF(0.95,0,0.3)
    LET Y = MAXPPF(P1,MU,SIGMA)
    PLOT MAXPPF(P,0,SIGMA) FOR P = 0  0.01  0.99
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MAXCDF = Compute the Maxwell cumulative distribution function.
    MAXPDF = Compute the Maxwell probability density function.
    CHPDF  = Compute the chi probability density function.
    RAYPDF = Compute the Rayleigh probability density function.
    WEIPDF = Compute the Weibull probability density function.
    NORPDF = Compute the normal probability density function.
    LGNPDF = Compute the lognormal probability density function.
 
Reference:
    Johnson, Kotz, and Balakrishnan (1994), "Continuous Univariate
    Distributions: Volume I", Second Edition, Wiley, p. 451.

Applications:
    Distributional Modeling, Statistical Physics
 
Implementation Date:
    7/2004
    2/2008: Corrected sigma to be a scale parameter rather than
            a shape parameter
 
Program:
    X1LABEL Probability
    Y1LABEL X
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE Maxwell Percent Point
    PLOT MAXPPF(P,1) FOR P = 0  0.01  0.99
 
-----MAXIMUM LIKELIHOOD---------------------------------
 
MAXIMUM LIKELIHOOD
 
Name:
    ... MAXIMUM LIKELIHOOD
 
Type:
    Analysis Command
 
Purpose:
    Compute the maximum likelihood estimates for the parameters of a
    statistical distribution.

Description:
    There are a number of approaches to estimating the parameters of a
    statistical distribution from a set of data.  Maximum likelihood
    estimates are widely used because they have excellent statistical
    properties.  The likelihood equations have to be derived for each
    specific distribution (other approaches, such as least squares or
    PPCC plots, allow a more general approach).  In some cases, the
    maximum likelihood estimates are trivial while in other cases they
    are quite complex and may require specialized methods to solve.

    For some distributions, maximum likelihood methods may have
    theoretical issues (e.g., the maximum likelihood solution may not
    exist) or numerical issues (e.g., non-convergence).

    As maximum likelihood methods are well documented in the statistical
    literature, we will not discuss them here.

    CONTINUOUS DISTRIBUTIONS

    For some distributions, Dataplot will also generate estimates based
    on other methods.  Specifically, for continuous distributions the
    following methods may also be used:

       1. ML        - maximum likelihood
       2. MOM       - moments
       3. MODMOM    - modified moments
       4. LMOM      - L-moments
       5. PERC      - Percentile methods
       6. ELEM PERC - Elemental Percentiles
       7. OS        - Order Statistics
       8. WOS       - Weighted Order Statistics

    In some cases, these methods are used to obtain starting values.  In
    other cases, they are used where maximum likehood methods are known to
    have performance issues.

    We distinguish the following types of data.

       1. Ungrouped, uncensored data
       2. Grouped, uncensored data
       3. Ungrouped, censored data
       4. Grouped, censored data

    The Dataplot MAXIMUM LIKELIHOOD command primarily supports case 1
    (i.e., ungrouped, uncensored data).  Censored data is supported for
    some distributions commonly used in reliability/lifetime applications.

    There is a distinction between censored and truncated data.  The
    distinction is that for censored data the number of censored points is
    known while for truncated data the number of censored points is
    unknown.  Censoring is common in life testing where we test a fixed
    known number of units.  In this case, the censored data are those units
    that have not failed when the test is ended.  On the other hand,
    an example of truncated data might be a sensor where we have a limit of
    detection (that is, there is a minimum level of something that must be
    present before the instrument can detect its presence).  That is, for
    truncated data the number of truncated units is unknown.

    The following types of information may be reported by the maximum
    likelihood command:

       1. Point estimates for the parameters
       2. Standard errors for the parameter estimates and the associated
          confidence intervals for the estimated parameters
       3. Values for the log-likelihood and AIC/BIC/AICC information crition
          statistics
       4. Standard errors and confidence intervals for select percentiles

    At a minimum, point estimates will be reported.  Items 2 - 4 depend
    on the specific distribution.  For distributions where only point
    estimates are generated, the DISTRIBUTIONAL BOOTSTRAP command may
    be used to generate confidence intervals for the parameter estimates
    and for selected percentiles.

    The following distributions are currently supported.

    I. Ungrouped, Uncensored Data:
    
       1. Location/Scale
    
                                         Point     Parameter              Percentile
          Name           Methods     Estimates            CI       AIC            CI
          ==========================================================================
          Normal             ML            Yes           Yes       Yes          Yes
          Logistic           ML            Yes         90/95       Yes           No
          Double Expo        ML            Yes           Yes       Yes           No
          Cauchy             ML            Yes         90/95       Yes           No
                         OS/WOS
          Slash              ML            Yes            No       Yes           No
          Uniform            ML            Yes            No       Yes           No
                            MOM
          1-par Exponential  ML            Yes           Yes       Yes          Yes
          2-par Exponential  ML            Yes           Yes       Yes        Lower
          1-par Rayleigh     ML            Yes           Yes       Yes          Yes
          2-par Rayleigh     ML            Yes           Yes       Yes           No
              LMOM/MOM/MOD MOM
                    Percentile
          1-par Maxwell      ML            Yes            No       Yes           No
          2-par Maxwell      ML            Yes            No       Yes           No
          Gumbel             ML            Yes           Yes       Yes          Yes
                           MOM
    
       2. One Shape Parameter
    
                                                 Point     Parameter              Percentile
          Name                  Methods      Estimates            CI       AIC            CI
          ==================================================================================
          Topp and Leone             ML            Yes            No       Yes           No
          Triangular                 ML            Yes            No        No           No
          Power                      ML          Shape         Shape       Yes           No
          Reflected Power            ML          Shape         Shape       Yes           No
          Von Mises                  ML            Yes            No        No           No
          Gene Logi Type 5         LMOM            Yes            No        No           No
          Pearson Type 3           LMOM            Yes            No        No           No
          2-par Weibull              ML            Yes           Yes       Yes          Yes
          3-par Weibull              ML            Yes           Yes       Yes          Yes
                                   PERC
                                    MOM
                                 MODMOM
          2-par Inverted Weib        ML            Yes           Yes       Yes          Yes
          2-par Gamma                ML            Yes           Yes       Yes          Yes
                                    MOM
          3-par Gamma                ML            Yes           Yes       Yes           No
                                    MOM
                                 MODMOM
          2-par Inverted Gamma       ML            Yes           Yes        No          Yes
                                    MOM
          2-par Lognormal            ML            Yes           Yes       Yes          Yes
          3-par Lognormal            ML            Yes           Yes       Yes          Yes
                                    MOM
                                 MODMOM
          2-par Fatigue Life         ML            Yes            No        No           No
                                    MOM
          2-par Burr Type 10         ML            Yes            No       Yes           No
          2-par Logistic Expo        ML            Yes            No        No           No
          2-par Frechet              ML            Yes           Yes        No          Yes
          2-par Geom Extr Expo       ML            Yes            No        No           No
          2-par Inverse Gauss        ML            Yes           Yes       Yes           No
          3-par Inverse Gauss        ML            Yes           Yes       Yes           No
                                   MMOM
          2-par Alpha                ML            Yes            No        No           No
                                    MOM
          2-par Expo Power           ML            Yes            No        No           No
            (needs work)
          Pareto                 MOD-ML            Yes           Yes       Yes           No
                                 MODMOM
          Generalized Pareto         ML            Yes           Yes       Yes           Yes
                                    MOM
                                   LMOM
                              ELEM PERC
          Generalized Extreme      LMOM            Yes            No       Yes            No
             Value            ELEM PERC
          Asymmetric Lapalce         ML            Yes            No        No           No
    
    
    
       3. Two or More Shape Parameters
    
                                                 Point     Parameter              Percentile
          Name                  Methods      Estimates            CI       AIC            CI
          ==================================================================================
          2-Par Beta                 ML            Yes           Yes       Yes           Yes
                                   MOM
          4-Par Beta                 ML            Yes            No       Yes            No
                                   MOM
          Gompertz                  ML             Yes            No        No            No
          Reflected Gene TL         ML             Yes            No       Yes            No
          Two-Sided Power           ML             Yes            No        No            No
          Johnson SB              PERC             Yes            No        No            No
                                   MOM
          Johnson SU              PERC             Yes            No        No            No
                                   MOM
          Log Beta                  ML             Yes             ?         ?             ?
          Kappa                   LMOM             Yes            No        No            No
          Beta Normal               ML             Yes            No        No            No
          Wakeby                  LMOM             Yes            No        No            No
          Folded Normal             ML             Yes            No       Yes            No
    
     II. Ungrouped, Censored (right censoring) Data:
    
       1. Location/Scale
    
                                         Point     Parameter              Percentile
          Name           Methods     Estimates            CI       AIC            CI
          ==========================================================================
          Normal             ML            Yes           Yes       Yes           Yes
          2-par Exponential  ML            Yes           Yes       Yes         Lower
    
    
    
       2. One Shape Parameter
    
                                                 Point     Parameter              Percentile
          Name                  Methods      Estimates            CI       AIC            CI
          ==================================================================================
          2-par Weibull              ML            Yes           Yes       Yes          Yes
          2-par Inverted Weib        ML            Yes           Yes       Yes          Yes
          2-par Lognormal            ML            Yes           Yes       Yes          Yes
          2-par Gamma                ML            Yes           Yes       Yes          Yes
                                    MOM
          2-par Inverted Gamma       ML            Yes           Yes        No          Yes
                                    MOM
    
    
    III. Grouped, Uncensored Data:
    
       1. Location/Scale
    
                                         Point     Parameter              Percentile
          Name           Methods     Estimates            CI       AIC            CI
          ==========================================================================
          2-par Exponential  ML            Yes           Yes        No           No
    
    
    
       2. One Shape Parameter
    
                                                 Point     Parameter              Percentile
          Name                  Methods      Estimates            CI       AIC            CI
          ==================================================================================
          Power                      ML          Shape         Shape       Yes           No
          Reflected Power            ML          Shape         Shape       Yes           No
    
    
    
       3. Two or More Shape Parameters
    
                                                 Point     Parameter              Percentile
          Name                  Methods      Estimates            CI       AIC            CI
          ==================================================================================
          Gompertz                  ML             Yes            No        No            No
          Johnson SB              PERC             Yes            No        No            No
                                   MOM
          Johnson SU              PERC             Yes            No        No            No
                                   MOM
          Reflected Gene TL         ML             Yes            No       Yes            No
    
    
     IV. Grouped, Censored Data:

         This is currently not supported.

    DISCRETE DISTRIBUTIONS

    Data for discrete data can be either raw data or in the form of a
    frequency table.  Dataplot currently requires that frequency tables
    have equal group sizes (data will sometimes be reported with frequency
    tables with unequal group sizes, typically due to groups in the upper
    tail being combined).

    The following methods may be used to compute point estimates

       1. ML        - maximum likelihood
       2. MOM       - moments
       3. EP        - method of even points
       4. ZF        - method of zero frequency and mean
       5. FF        - method of first frequency and mean
       6. RF        - method of ratio of frequencies
       7. WD        - method of weighted discrepancies (a modification of
                      the ML estimates)

                                                           Unequal
                                   Point   Parameter         Group
    Name           Methods     Estimates          CI         Sizes
    ==============================================================
    Binomial            ML           Yes         Yes            No
    Borel Tanner    ML=MOM           Yes          No            No
    Consul       FF/MOM/ML           Yes          No            No
      (generalized geometric)
   *Generalized     MOM/ML           Yes          No            No
      Lost Games
    Geeta        FF/MOM/ML           Yes          No            No
    Geometric           ML           Yes         Yes            No
   *Hermite      EP/MOM/ML           Yes          No            No
    Katz               MOM           Yes          No            No
    Lagrange     ZF/MOM/WD           Yes          No            No
      Poisson
    Logarithmic     ML=MOM           Yes         Yes            No
      Series
    Lost Games          ML           Yes          No            No
   *Negative Binomial   ML           Yes Conditional            No
    Poisson             ML           Yes         Yes            No
    Yule            ML/MOM           Yes          No            No
   *Zeta         RF/ML/MOM           Yes          No            No

Syntax 1:
    <DIST> MAXIMUM LIKELIHOOD <y>
                              <SUBSET/EXCEPT/FOR qualification>
    where <DIST> is one of the supported distributions;
          <y> is the response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This generates maximum likelihood estimates for the raw data (no
    grouping) case with no censoring.

Syntax 2:
    <DIST> MAXIMUM LIKELIHOOD <y> <x> 
                              <SUBSET/EXCEPT/FOR qualification>
    where <DIST> is one of the supported distributions;
          <y> is a variable containing frequencies;
          <x> is a variable containing the bin mid-points;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for grouped (frequency table) data.  The bins
    are assumed to have equal width.

Syntax 3:
    <DIST> MAXIMUM LIKELIHOOD <y> <xlow>  <xhigh>
                              <SUBSET/EXCEPT/FOR qualification>
    where <DIST> is one of the supported distributions;
          <y> is a variable containing frequencies;
          <xlow> is a variable containing the lower value for the bins;
          <xhigh> is a variable containing the upper value for the bins;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for grouped (frequency table) data where the bins
    do not have equal width.

Syntax 4:
    <DIST> CENSORED MAXIMUM LIKELIHOOD <y> <x> 
                              <SUBSET/EXCEPT/FOR qualification>
    where <DIST> is one of the supported distributions;
          <y> is the response variable;
          <x> is the censoring variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This is for the raw data (ungrouped) case with censoring.
    The censoring variable should contain 1's and 0's where 1
    indicates a failure time and 0 indicates a censoring time.

Syntax 5:
    <DIST> MULTIPLE MAXIMUM LIKELIHOOD <y1> ... <yk>
                                       <SUBSET/EXCEPT/FOR qualification>
    where <DIST> is one of the supported distributions;
          <y1> ... <yk> is a list of 1 to 30 response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax will perform maximum likelihood estimation for each
    of the listed response variables.  Censoring is not supported for
    this syntax.

    The TO keyword can be used with this sytax (see Examples below).

Examples:
    NORMAL MAXIMUM LIKELIHOOD Y
    LOGNORMAL MAXIMUM LIKELIHOOD Y
    EXPONENTIAL MAXIMUM LIKELIHOOD Y
    WEIBULL CENSORED MAXIMUM LIKELIHOOD Y  X
    WEIBULL MAXIMUM LIKELIHOOD Y SUBSET TAG = 1
    WEIBULL MULTIPLE MAXIMUM LIKELIHOOD Y1 Y2 Y3
    WEIBULL MULTIPLE MAXIMUM LIKELIHOOD Y1 TO Y5

Note:
    Typically after a maximum likelihood analysis, many parameters will
    automatically be saved.  For example, the point estimates and
    standard errors (if computed) are saved.  To see what parameters have
    been saved, enter STATUS PARAMETERS.

Note:
    The Weibull, Gumbel, Frechet, generalized extreme value, and
    generalized Pareto distributions support parameterizations based on
    either the minimum order statistic or the maximum order statistic.

    To specify the minimum order statistic case, enter

        SET MINMAX 1

    To specify the maximum order statistic case, enter

        SET MINMAX 2

    The default is the minimum order statistic case for the Weibull
    distribution and the maximum order statistic case for the other
    distributions.

Note:
    By default, confidence intervals for percentiles are not computed.
    If you want these computed, enter the command

        SET MAXIMUM LIKELIHOOD PERCENTILES DEFAULT

    This will compute 17 select percentiles.  If you would like to specify
    the specific percentiles, do something like the following

        LET YPERC = DATA 0.01 0.05 0.10
        SET MAXIMUM LIKELIHOOD PERCENTILES YPERC

    To turn off the percentile confidence limits, enter

        SET MAXIMUM LIKELIHOOD PERCENTILES NONE

    By default, two-sided confidence intervals are generated for the
    percentiles.  To specify lower one-sided intervals, enter

         SET DISTRIBUTIONAL PERCENTILE LOWER

    To specify upper one-sided intervals, enter

         SET DISTRIBUTIONAL PERCENTILE UPPER

    To reset two-sided intervals, enter

         SET DISTRIBUTIONAL PERCENTILE TWO SIDED

    Note that one-sided percentiles are also one-sided tolerance
    intervals.

    See the tables above to determine which distributions support
    percentile confidence intervals.

    Confidence intervals for percentiles are by default 95% confidence
    intervals.  To change the confidence level, enter the command

        LET ALPHA = <value>

    where <value> is typically 0.10, 0.05, or 0.01.

    By default, the percentile column (i.e., the first column in the
    table) is printed with 3 digits to the right of the decimal point.
    If you are generating percentiles that are close to zero or one
    (e.g., 0.00005), you may need to increase the number of digits.  You
    can do this with the command

          SET PERCENTILE DIGITS <value>

    where <value> specifies the number of digits to the right of the
    decimal point.

Note:
    For a few distributions, there is an option for "bias corrected"
    estimates.  Note that both the biased and bias corrected estimates
    will be printed.  However, confidence intervals will only be
    generated for one set of estimates.  If the bias correction is
    turned on, then the confidence intervals will be based on the bias
    corrected estimates.  Otherwise, the confidence intervals will be for
    the uncorrected estimates.

    Bias correction can be specified for the following distributions

         SET EXPONENTIAL BIAS CORRECTED <ON/OFF>
         SET FRECHET BIAS CORRECTED <ON/OFF>
         SET GUMBEL BIAS CORRECTED <ON/OFF>
         SET WEIBULL BIAS CORRECTED <ON/OFF>

    The default is OFF for all of these.

Note:
    In some cases, you may be able to specify starting values or to
    fix certain parameters to known values.

    If available for a particular distribution, these will typically
    be documented in the PDF routine (e.g., NBPDF).

Note:
    Dataplot supports a number of different methods for estimating the
    parameters of a 3-parameter Weibull distribution.  You can optionally
    specify which of these methods to use with the commands

        SET WEIBULL ELEMENTAL PERCENTILES <ON/OFF>
        SET WEIBULL MOMENTS <ON/OFF>
        SET WEIBULL L MOMENTS <ON/OFF>
        SET WEIBULL MODIFIED MOMENTS <ON/OFF>
        SET WEIBULL MAXIMUM LIKELIHOOD <ON/OFF>

    The elemental percentiles and L moment methods are OFF and the others
    are ON by default.

    The maximum likelihood method is described in the Bury, Rhinne, and
    Cohen and Whitten references.  The moment, modified moment  and L
    moment methods are described in the Cohen and Whitten reference.  The
    elemental percentile method is described in Castillo, et. al.

    Maximum likelihood for the 3-parameter Weibull can be problematic for
    small values of the shape parameter.  Lawless proposed the profile
    method to address this.  In this method, a grid of location values
    is created from the minimum value to zero.  For each value on this
    grid, a 2-parameter Weibull is estimated via maximum likelihood.  The
    value of the location parameter that generates the optimal 2-parameter
    Weibull estimates is the estimate of location for the 3-parameter
    Weibull distribution (the scale and shape are the estimates from the
    2-parameter Weibull estimation).

    To specify the Lawless profile method be used for the maximum
    likelihood estimates, enter the command

          SET WEIBULL MAXIMUM LIKELIHOOD METHOD PROFILE

    To turn off the profile method, enter

          SET WEIBULL MAXIMUM LIKELIHOOD METHOD COHEN

    By default, the grid is created from zero to the minimum of the data.
    If you want to restrict the location to something other than zero,
    then you can enter the command

          SET WEIBULL MAXIMUM LIKELIHOOD MINIMUM <value>

    That is, the grid will be created from <value> to the minimum of the
    data.

    In the materials field, the Weibull distribution is typically
    parameterized with a gauge length parameter (enter HELP WEIPDF for
    details).  This gauge length parameter modifies the value of the
    scale parameter, but otherwise the estimation is equivalent to the
    typical parameterization of the Weibull distribution.  To utilize
    the gauge length parameterization for the 3-parameter Weibull
    estimation, enter the command

          SET WEIBULL GAUGE LENGTH ON

    To specify the value of the gauge length, enter

          LET L = <value>

Note:
    The Lawless profile method for the 3-parameter Weibull distribution
    can also be applied to the 3-parameter lognormal and 3-parameter gamma
    distributions.  Specifically, the following commands are available

          SET LOGNORMAL MAXIMUM LIKELIHOOD METHOD <PROFILE/COHEN>
          SET LOGNORMAL MAXIMUM LIKELIHOOD MINIMUM <value>

          SET GAMMA MAXIMUM LIKELIHOOD METHOD <PROFILE/COHEN>
          SET GAMMA MAXIMUM LIKELIHOOD MINIMUM <value>

Note:
    For the generalized extreme value distribution, the maximum
    likelihood algorithm has issues and is turned off by default
    (the L moment and elemental percentile methods are still available).

    To turn on the maximum likelihood estimation method (this is intended
    primarily for testing at this time), enter the command

          SET GENERALIZED EXTREME VALUE MAXIMUM LIKELIHOOD ON

Note:
    The generalized Pareto distribution is estimated using a number of
    different methods (maximum likelihood can be problematic for this
    distribution).  You can specify the start values for the maximum
    likelihood estimates based on one of the other supported methods with
    one of the following command

         SET GENERALIZED PARETO MLE START VALUES MOMENTS
         SET GENERALIZED PARETO MLE START VALUES L MOMENTS
         SET GENERALIZED PARETO MLE START VALUES ELEMENTAL PERCENTILES
         SET GENERALIZED PARETO MLE START VALUES USER SPECIFIED

    The default is to use the elemental percentile estimates as the start
    values for the maximum likelihood method.  If USER SPECIFIED is
    entered, you can specify the start values with the commands

         LET SCALESV = <value>
         LET GAMMASV = <value>

Note:
    There are several SET commands that apply to the binomial maximum
    likelihood case.

        1) SET BINOMIAL METHOD <WILSON/ADJUSTED WALD/JEFFREYS>

           When Dataplot computes the confidence interval for p, it does
           so using two methods.

           a) It generates the confidence interval based on the exact
              method.  If the number of trials is large enough (see
              SET BINOMOIAL NORMAL APPROXIMATION THRESHOLD below), the
              normal approximation to the exact method will be used.

              For the details on how the exact and normal approximations
              are computed, enter

                  HELP EXACT BINOMIAL CONFIDENCE LIMITS

           b) In addition, Agresti-Coull intervals will be computed.
              There are actually several alternatives for these
              Agresti-Coull intervals.  The SET BINOMIAL METHOD command
              specifies which specific method is used for the
              Agresti-Coull confidence limits.  For details on the
              specific methods, enter

                  HELP AGRESTI COULL CONFIDENCE LIMITS

        2) SET CONTINUITY CORRECTION <ON/OFF>

           Given an array Y of N 0 and 1 values (where 1 denotes success
           and 0 denotes failure), the standard formulas for estimating p
           (the probability of success) and the standard deviation of p
           are

              phat     = SUM[Y(i)]/N
              sd(phat) = SQRT(phat*(1-phat)/N)

           With the continuity correction, these formulas are

              phat     = (SUM[Y(i)] + 0.5)/(N + 1)
              sd(phat) = SQRT(phat*(1-phat)/N)

           Dataplot will print phat and sd(phat) for both the corrected
           and uncorrected case.  However, it will use this switch to
           determine whether the corrected or uncorrected value will be
           used in determining a confidence interval for p (ON means the
           continuity corrected values will be used while OFF means the
           uncorrected values will be used).

           This applies to the exact (or normal approximation) confidence
           interval, not the Agresti-Coull interval.

        3) SET BINOMIAL NORMAL APPROXIMATION THRESHOLD <value>

           This command specifies the sample size at which the exact
           method confidence intervals will be generated using the normal
           approximation.  The default is 30.  That is, if the sample size
           is 30 or greater, the normal approximation method will be used.
           If the sample size is less than 30, the normal approximation
           will not be used.

Note:
    Dataplot also supports several graphical methods for estimating the
    distribution parameters.

    The PPCC PLOT and PROBABILITY PLOT commands document fitting
    parameters by maximizing the probability plot correlation coefficient.
    The PPCC PLOT has variants where you can minimize the Anderson-Darling,
    Kolmogorov-Smirnov, and chi-square goodness of fit statistic.

    The NORMAL PLOT, WEIBULL PLOT and FRECHET PLOT can be used for the
    normal, 2-parameter Weibull (minimum case), and 2-parameter Frechet
    (maximum case).

Note:
    You can use the fit command to perform a least squares fit to the
    percentiles of the data.  For example, if you have a response variable
    Y and you would like to fit it to a 2-parameter Weibull distribution,
    do something like the following

       let y = sort y
       let n = size y
       let p = uniform order statistic medians for i = 1 1 n
       let gamma = 3.5; . Specify a starting value for the shape
       let scale = 10;  . Specify a starting value for the scale
       fit y = weippf(p,gamma,0,scale)

    Be aware that the standard indpendence assumptions for least squares
    fitting are not satisfied.  However, this method can often give a
    reasonable fit.  It can also sometimes be used to provide better
    starting values for the maximum likelihood fit.

Note:
    The bootstrap can be used to obtain confidence intervals for
    parameters and selected percentiles.  Enter HELP DISTRIBUTIONAL
    BOOTSTRAP for details.

Note:
    After fitting the data, the GOODNESS OF FIT command can be used to
    perform various goodness of fit tests.

Note:
    The BEST DISTRIBUTIONAL FIT command and the DISTRIBUTIONAL FIT PLOT
    commands can be used as screening tools to compare distributional
    models for the data.

Default:
    None.
 
Synonyms:
    MLE is a synonymn for MAXIMUM LIKELIHOOD

Related Commands:
    FIT                          = Perform a least squares fit.
    PPCC PLOT                    = Generate a ppcc plot.
    PROBABILITY PLOT             = Generate a probability plot.
    GOODNESS OF FIT              = Perform a goodness of fit test
                                   (Anderson-Darling, Kolmogorov Smirnov,
                                   chi-square, PPCC).
    DISTRIBUTIONAL BOOTSTRAP     = Generate confidence intervals for
                                   distributional models.
    BEST DISTRIBUTIONAL FIT      = Fit (and rank) many distributional
                                   models for a data set.
    DISTRIBUTIONAL FIT PLOT      = Display results of BEST DISTRIBUTIONAL
                                   FIT graphically.
 
Reference:
    Johnson, Kotz, and Balakrishnan (1994), "Continuous Univariate
    Distributions: Volume I", 2nd. ed., John Wiley and Sons.

    Johnson, Kotz, and Balakrishnan (1994), "Continuous Univariate
    Distributions: Volume II", 2nd. ed., John Wiley and Sons.

    Johnson, Kotz, and Kemp (1994), "Univariate Discrete Distributions",
    2nd. ed., John Wiley and Sons.

    Karl Bury (1999), "Statistical Distributions in Engineering",
    Cambridge University Press.

    Cohen and Whitten (1988), "Parameter Estimation in Reliability and Life
    Span Models", Marcel Dekker, p. 31 and pp. 341-344.

    Rinne (2009), "The Weibull Distribution: A Handbook", CRC Press.

    Castillo, Hadi, Balakrishnan, and Sarabia (2005), "Extreme Value and
    Related Models with Applications in Engineering and Science", Wiley.

    Lawless (2003), "Statistical Models and Methods for Lifetime Data",
    Wiley, pp. 187-190.

    Evans, Hastings, and Peacock (2000), "Statistical Distributions",
    Third Edition, John Wiley and Sons.

Applications:
    Reliability, Data Analysis, Distributional Modeling
 
Implementation Date:
    1998/5
    New distributions have been continually added since the original
    implementation
 
Program 1:
    skip 25
    read vangel31.dat y
    .
    set write decimals 4
    exponential mle y
    weibull mle y
    lognormal mle y
    gamma mle y

Program 2:
    . Purpose:  Example of fitting 2-parameter Weibull using
    .           maximum likelihood
    .
    . Step 1:   Read the data
    .
    skip 25
    read weibbury.dat y
    skip 0
    .
    . Step 2:   Maximum likelihood estimates
    .
    set write decimals 5
    set maximum likelihood percentiles default
    set distributional percentile two-sided
    feedback off
    capture screen on
    capture wei2.out
    weibull mle y
    let ksloc = 0
    let ksscale = alphaml
    let gamma = gammaml
    .
    . Step 3:   Goodness of fit via Anderson-Darling and by
    .           probability plot
    .
    set goodness of fit fully specified on
    set anderson darling critical value simulation
    weibull anderson darling goodness of fit y
    end of capture
    .
    let pploc   = ksloc
    let ppscale = ksscale
    .
    title case asis
    label case asis
    title Weibull Probability Plot
    y1label Sorted Data
    x1label Percentiles for Fitted Weibull Distribution
    character circle
    character hw 1 0.75
    character fill on
    line blank
    .
    weibull probability plot y
    .
    let gamma = round(gamma,2)
    move 20 85
    text Gamma = ^gamma
    let ksscale = round(ksscale,2)
    move 20 82
    text Scale = ^ksscale
    let ppcc = round(ppcc,3)
    move 20 79
    text PPCC = ^ppcc

-----MAXIMUM PLOT------------------------------------------------
 
MAXIMUM PLOT
 
Name:
    MAXIMUM PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a maximum plot.
 
Description:
    A maximum plot consists of subsample maxima versus subsample index.
    The subsample maximum is the largest data value in the subsample.
    The maximum plot is used to answer the question--"Does the
    subsample variation change over different subsamples?"  The plot
    consists of:
       Vertical   axis = subsample maximum;
       Horizontal axis = subsample index.
    The maximum plot yields 2 traces:
       1. a subsample maximum trace; and
       2. a full-sample maximum reference line.
    Like usual, the appearance of these 2 traces is controlled
    by the first 2 settings of the LINES, CHARACTERS, SPIKES,
    BARS, and similar attributes.
 
Syntax:
    MAXIMUM PLOT   <y>   <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    MAXIMUM PLOT Y X
    MAXIMUM PLOT Y X1
 
Default:
    None
 
Synonyms:
    MAX PLOT
 
Related Commands:
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    MINIMUM  PLOT           = Generates a minimum plot.
    RANGE  PLOT             = Generates a range plot.
    MAXIMUM  PLOT           = Generates a lower quartile plot.
    UPPER QUARTILE  PLOT    = Generates a upper quartile plot.
    LOWER HINGE  PLOT       = Generates a lower hinge plot.
    UPPER HINGE  PLOT       = Generates a upper hinge plot.
    FIRST DECILE  PLOT      = Generates a first decile plot.
    SECOND DECILE  PLOT     = Generates a second decile plot.
    NINTH DECILE  PLOT      = Generates a ninth decile plot.
    STANDARD DEVIATION PLOT = Generates a stand deviation plot.
    VARIANCE  PLOT          = Generates a variance plot.
    MEAN PLOT               = Generates a mean plot.
    MEDIAN PLOT             = Generates a median plot.
    BOX PLOT                = Generates a box plot.
    RANGE CHART             = Generates a maximum control chart.
    S CHART                 = Generates a standard deviation control
                              chart.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    LET Y = DATA 2 4 6 11 12 21 25 28 29
    LET X = DATA 1 1 1 2 2 3 3 3 3
    LINE BLANK DASH
    CHARACTER X BLANK
    XTIC OFFSET 0.2 0.2
    Y1LABEL MAXIMUM
    X1LABEL SAMPLE ID
    TITLE AUTOMATIC
    MAXIMUM PLOT Y X
 
-----MAXIMUM RECORD LENGTH-------------------------------------------
 
MAXIMUM RECORD LENGTH
 
Name:
    MAXIMUM RECORD LENGTH
 
Type:
    Support Command
 
Purpose:
    Specifies the maximum size record that can be read during
    subsequent READ and SERIAL READ commands.
 
Description:
    Prior to the 2/2003 version, Dataplot would read 132 columns
    from external data files.  The COLUMN LIMITS could be used
    to specify which columns between 1 and 132 were read, but
    it could not specify columns past 132.  The only way around this
    restriction was to use the SET READ FORMAT command (i.e.,
    specify a Fortran-like format statement for the read).  However,
    this required a fixed and consistent format for the data (and
    the user had to know what that format was).

    The MAXIMUM RECORD LENGTH command can now be used to specify
    a maximum record length for data files.  This record length
    can be any value between 132 (if you request a value less
    than 132, the maximum record length will be set to 132) and
    a maximum record length (currently set to 9999).
 
    Also, the default maximum record length has been increased
    from 132 to 255.

    If you specify a maximum record length greater than 255, you
    still need to enter a COLUMN LIMITS command to access those
    columns.

Syntax:
    MAXIMUM RECORD LENGTH   <value>
    where  <value> is a number or parameter between 132 and 9999
    that specifies the desired maximum record length.
 
    Entering AUTO, OM, OFF, or DEFAULT will reset the default
    value (255).  Entering a question mark ("?") will print the
    current value and the default value for the maximum record
    length.

Examples:
    MAXIMUM RECORD LENGTH 500
    MAXIMUM RECORD LENGTH 132
    MAXIMUM RECORD LENGTH DEFAULT
 
Note:
    This command specifies the number of characters that are
    read from a data record.  Be aware that some Fortran
    compilers may have their own limit for the maximum record
    length (this value does not tend to be well documented by
    most Fortran compilers).  Dataplot currently does not try
    to determine if the given Fortran compiler limit has been
    exceeded.

    Some Fortran compilers allow you to up this limit when you
    open the file.  However, this option is not part of the
    Fortran standard (and is not available on all Fortran
    compilers).  For now, Dataplot does not use the maximum
    record length when opening the file.  As we gain more
    experience with this capability, we may add the maximum
    record length when opening the data file.

    This should rarely be an issue.  The Fortran compiler limit,
    if it exists, tends to be rather large.  Unless your data
    records exceed 750 columns, you are unlikely to run into
    this limitation.

Note:
    This command only applies to data read from external files.
    Reads from the terminal are still restricted to a maximum of
    80 columns.

Default:
    DATAPLOT reads columns 1 to 255.
 
Synonyms:
    None
 
Related Commands:
    READ            = Reads data (column-wise) into variables.
    SERIAL READ     = Reads data (row-wise) into variables.
    ROW LIMITS      = Sets file lines to be included in read.
    SKIP            = Sets the number of lines to skip over at the
                      beginning of a file in subsequent reads.
    SET READ FORMAT = Defines a Fortran like format to use in
                      subsequent reads.
    COLUMN LIMITS   = Sets the columns to be included in read.
 
Applications:
    Data Input
 
Implementation Date:
    2/2003
 
Program:
    DIMENSION 100 VARIABLES
    .
    .  Write out some data with long records
    .
    LET XTEMP = SEQUENCE 1 1 20
    LOOP FOR K = 1 1 50
        LET X^K = K*XTEMP
    END OF LOOP
    .
    SET WRITE FORMAT (50f10.0)
    WRITE TEST.OUT X1 TO X50
    .
    .  Now, read them back in
    .
    MAXIMUM RECORD LENGTH 600
    COLUMN LIMITS 1 600
    RESET DATA
    READ TEST.OUT Y1 TO Y50
 
-----MCCOOL WEIBULL LOCATION TEST---------------------------------
 
MCCOOL WEIBULL LOCATION TEST
 
Name:
    MCCOOL WEIBULL LOCATION TEST
 
Type:
    Analysis Command
 
Purpose:
    Perform the McCool test to distinguish between a 2-parameter and a
    3-parameter Weibull distribution.
 
Description:
    When modelling Weibull data, it is often desired to determine whether a
    2-parameter Weibull or a 3-parameter Weibull is more appropriate.  This
    can be determined by testing whether the location parameter is equal to
    zero.

    McCool described a test for this purpose that can be applied to either
    censored or uncensored data.  The derivation of this test is given
    in the references listed below.

    The test statistic is

        W = Gammahat(L)/Gammahat(A)

    where Gammahat(A) is the maximum likelihood estimate of the shape
    parameter from a 2-parameter Weibull distribution based on the full data
    set and Gammahat(L) is the maximum likelihood estimate of the shape
    parameter based on the first r1 uncensored observations.

    McCool performed power studies to determine the optimal value of r1.  He
    recommends 

       r1 = 5   for n < 30
       r1 = 7   for n = 40 to 60
       r1 = 9   for n = 80 to 100

    The critical values for this test are determined via simulation.  The
    simulation uses 10,000 samples from a 2-parameter Weibull distribution
    with a shape parameter of 1 and a scale parameter of 10 (this
    corresponds to a tenth percentile of 1.0).

    Currently, Dataplot limits this test to values of n between 10 and 100.
    Also, the number of uncensored  observations must be greater than r1.
    Although the test and simulation can be computed for n > 100, optimal
    values of r1 have not been published.

Syntax:
    MCCOOL WEIBULL LOCATION TEST  <y> <x>
                                  <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable containing failure times;
          <x> is a censoring variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    MCCOOL WEIBULL LOCATION TEST Y X
 
Note:
    Dataplot performs the simulation dynamically.  The critical values
    generated by Dataplot may differ slightly from McCool's published
    values.  This is due to a different random number generator being
    used.

    Dataplot uses the combined Fibonacci/multiplicative congruential
    generator.  If you do not set the seed for the generator explicitly,
    then a default value of 23709 will be used.  If you choose to use a
    different value for the seed, you may see slight differences in the
    critical values.

    These slight differences in the critical values should be small enough
    for practical applications of the test.

Note:
    The censoring variable should have a value of 1 to specify an uncensored
    observation and a value of 0 to specify a censored observation.
    Note that Dataplot will treat any value with an absolute value less than
    0.5 as a zero and any value with an absolute value greater than 0.5 as 1.

    If you have uncensored data, you can create the censoring variable as
    follows

        LET N = SIZE Y
        LET X = 1 FOR I = 1 1 N
        MCCOOL WEIBULL LOCATION TEST Y X
 
Note:
    Dataplot saves the following internal parameters after a
    sign test:

        STATVAL   = the value of the test statistic
        STATCDF   = the CDF of the test statistic
        PVALUE    = the p-value for the two-sided test
        CUTOFF50  = the 50% critical value
        CUTOFF75  = the 75% critical value
        CUTOFF90  = the 90% critical value
        CUTOFF95  = the 95% critical value
        CUTOF975  = the 97.5% critical value
        CUTOFF99  = the 99% critical value
        CUTOF999  = the 99.9% critical value

Note:
    The following statistics are also supported

       LET A = MCCOOL WEIBULL LOCATION TEST Y X
       LET A = MCCOOL WEIBULL LOCATION TEST CDF Y X
       LET A = MCCOOL WEIBULL LOCATION TEST PVALUE Y X
       LET A = MCCOOL WEIBULL LOCATION TEST CV50 Y X
       LET A = MCCOOL WEIBULL LOCATION TEST CV90 Y X
       LET A = MCCOOL WEIBULL LOCATION TEST CV95 Y X

    Enter HELP STATISTICS for a list of commands that can be used
    with Dataplot supported statistics.  See the Program section below
    for an example.

Note:
    If you want to perform this test for data sets with more than
    100 observations, enter the command

        SET MCCOOL WEIBULL LOCATION TEST R1 <value>

    This defines the r1 value to use for the test.  Be aware that the
    optimal value (in the sense of maximizing the power of the test) of
    r1 is not known in this case.

Note:
    Another approach to this problem is to compare the AIC/BIC values
    for the 2-parameter and 3-parameter models (i.e., does adding the
    location parameter decrease these values).

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MAXIMUM LIKELIHOOD         = Perform maximum likelihood estimation for
                                 various distributions.
    GOODNESS OF FIT            = Perform various types of distributional
                                 goodness of fit tests.
    PPCC PLOT                  = Generate a ppcc plot.
    PROBABILITY PLOT           = Generate a probability plot.
 
Reference:
    John McCool (1998), "Inference on the Weibull Location Parameter",
    Journal of Quality Technology, Vol. 30, No. 2, pp. 119-126.

    John McCool (2012), "Using the Weibull Distribution: Reliability,
    Modeling, and Inference", Wiley, pp. 301-307.

    Horst Rinne (2009), "The Weibull Distribution: A Handbook", CRC Press,
    pp. 640-642.

Applications:
    Distributional Modeling
 
Implementation Date:
    2013/8
 
Program:
    . Data set from McCool's paper
    .
    let y = data 90.4 94.2 97.8 101.8 104.6 113.0 118.0 154.9 181.3 186.2
    let n = size y
    let tag = 1 for i = 1 1 n
    .
    let statval = mccool weibull location test y tag
    let statcdf = mccool weibull location test cdf y tag
    let pvalue  = mccool weibull location test pvalue y tag
    let cv50    = mccool weibull location test cv50 y tag
    let cv90    = mccool weibull location test cv90 y tag
    let cv95    = mccool weibull location test cv95 y tag
    .
    set write decimals 4
    print statval statcdf pvalue cv50 cv90 cv95
    .
    mccool weibull location test y tag

-----MCLCDF (LET)--------------------------------
 
MCLCDF
 
Name:
    MCLCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the McLeish cumulative distribution function.
 
Description:
    The standard form of the McLeish distribution has the
    following probability density function:

        f(x;alpha) = [1/(SQRT(PI)*GAMMA(ALPHA))]*
                     (ABS(X)/2)**(ALPHA-1/2)*K(X,ALPHA-1/2)

    where K(lambda)(.) is the modified Bessel function of the
    of the third kind of order lambda and GAMMA is the gamma
    function.

    The standard McLeish distribution can be generalized with
    location and scale parameters in the usual way.

    The cumulative distribution function is computed by
    numerically integrating the probability density function.
    Dataplot performs the integration using the DQAG routine
    from the Slatec library.

Syntax:
    LET <y> = MCLCDF(<x>,<alpha>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <alpha> is a positive number of parameter that specifies
              the value of the shape parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <scale> is an optional positive number or parameter that
              specifies the value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed McLeish cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y = MCLCDF(3,1.5)
    LET Y = MCLCDF(X1,ALPHA)
    PLOT MCLCDF(X,ALPHA) FOR X = -10  0.01  10
 
Note:
    DATAPLOT uses the routine BESK from the SLATEC Common Mathematical
    Library to compute the modified Bessel function of the third
    kind.  SLATEC is a large set of high quality, portable, public
    domain Fortran routines for various mathematical capabilities
    maintained by seven federal laboratories.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MCLPDF = Compute the McLeish probability density function.
    MCLPPF = Compute the McLeish percent point function.
    GMCPDF = Compute the generalized McLeish probability density
             function.
    GALPDF = Compute the generalized asymmetric Laplace probability
             density function.
    GIGPDF = Compute the generalized inverse Gaussian probability
             density function.
    BEIPDF = Compute the Bessel I-function probability density
             function.
    BEKPDF = Compute the Bessel K-function probability density
             function.
 
Reference:
    Johnson, Kotz, and Balakrisnan, "Continuous Univariate
    Distributions--Volume I", Second Edition, Wiley, 1994,
    pp. 50-53.

Applications:
    Distributional Modeling
 
Implementation Date:
    8/2004
 
Program:
    Y1LABEL Probability
    X1LABEL X
    LABEL CASE ASIS
    TITLE CASE ASIS
    CASE ASIS
    Y1LABEL DISPLACEMENT 16
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    TITLE Alpha = 1
    PLOT MCLCDF(X,1) FOR X = -10  0.01 10
    TITLE Alpha = 2
    PLOT MCLCDF(X,2) FOR X = -10  0.01 10
    TITLE Alpha = 5
    PLOT MCLCDF(X,5) FOR X = -10  0.01 10
    TITLE Alpha = 10
    PLOT MCLCDF(X,10) FOR X = -10  0.01 10
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT McLeish Distribution
 
-----MCLPDF (LET)--------------------------------
 
MCLPDF
 
Name:
    MCLPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the McLeish probability density function.
 
Description:
    The standard form of the McLeish distribution has the
    following probability density function:

        f(x;alpha) = [1/(SQRT(PI)*GAMMA(ALPHA))]*
                     (ABS(X)/2)**(ALPHA-1/2)*K(X,ALPHA-1/2)

    where K(lambda)(.) is the modified Bessel function of the
    of the third kind of order lambda and GAMMA is the gamma
    function.

    The standard McLeish distribution can be generalized with
    location and scale parameters in the usual way.

Syntax:
    LET <y> = MCLPDF(<x>,<alpha>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <alpha> is a positive number of parameter that specifies
              the value of the shape parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <scale> is an optional positive number or parameter that
              specifies the value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed McLeish pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y = MCLPDF(3,1.5)
    LET Y = MCLPDF(X1,ALPHA)
    PLOT MCLPDF(X,ALPHA) FOR X = -10  0.01  10
 
Note:
    DATAPLOT uses the routine BESK from the SLATEC Common Mathematical
    Library to compute the modified Bessel function of the third
    kind.  SLATEC is a large set of high quality, portable, public
    domain Fortran routines for various mathematical capabilities
    maintained by seven federal laboratories.

Note:
    To generate McLeish random numbers, enter the commands

        LET ALPHA = <value>
        LET Y = MCLEISH RANDOM NUMBERS FOR I = 1 1 N

    To generate a McLeish probability plot or a McLeish
    Kolmogorov-Smirnov or chi-square goodness of fit test, enter
    the following commands

        LET ALPHA = <value>
        MCLEISH PROBABILITY PLOT Y
        MCLEISH KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
        MCLEISH CHI-SQUARE GOODNESS OF FIT Y
       
    To generate a PPCC or Kolmogorov-Smirnov plot, enter the
    following commands

        LET ALPHA1 = <value>
        LET ALPHA2 = <value>
        MCLEISH PPCC PLOT Y
        MCLEISH KS PLOT Y

    The default values for ALPHA1 and ALPHA2 are 1.0 and 15.5.

    For the McLeish distribution, the shape parameter acts a bit like
    a scale parameter.  For this reason, the KS PLOT with the
    location and scale parameters fixed will probably work better
    than the PPCC PLOT.  One recommendation is to set the scale
    parameter to 1 and the location parameter to the mode of the
    data (the McLeish distribution is symmetric).  You can use
    the relative histogram or the kernel density plot to determine
    a useful value for the location.  For example,

        LET KSLOC = 0
        LET KSSCALE = 1
        MCLEISH KS PLOT Y

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MCLCDF = Compute the McLeish cumulative distribution function.
    MCLPPF = Compute the McLeish percent point function.
    GMCPDF = Compute the generalized McLeish probability density
             function.
    GALPDF = Compute the generalized asymmetric Laplace cumulative
             distribution function.
    GIGPDF = Compute the generalized inverse Gaussian probability
             density function.
    BEIPDF = Compute the Bessel I-function probability density
             function.
    BEKPDF = Compute the Bessel K-function probability density
             function.
 
Reference:
    Johnson, Kotz, and Balakrisnan, "Continuous Univariate
    Distributions--Volume I", Second Edition, Wiley, 1994,
    pp. 50-53.

Applications:
    Distributional Modeling
 
Implementation Date:
    8/2004
 
Program:
    Y1LABEL Probability
    X1LABEL X
    LABEL CASE ASIS
    TITLE CASE ASIS
    CASE ASIS
    Y1LABEL DISPLACEMENT 16
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    TITLE Alpha = 1
    PLOT MCLPDF(X,1) FOR X = -10  0.01 10
    TITLE Alpha = 2
    PLOT MCLPDF(X,2) FOR X = -10  0.01 10
    TITLE Alpha = 5
    PLOT MCLPDF(X,5) FOR X = -10  0.01 10
    TITLE Alpha = 10
    PLOT MCLPDF(X,10) FOR X = -10  0.01 10
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT McLeish Distribution
 
-----MCLPPF (LET)--------------------------------
 
MCLPPF
 
Name:
    MCLPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the McLeish percent point function.
 
Description:
    The standard form of the McLeish distribution has the
    following probability density function:

        f(x;alpha) = [1/(SQRT(PI)*GAMMA(ALPHA))]*
                     (ABS(X)/2)**(ALPHA-1/2)*K(X,ALPHA-1/2)

    where K(lambda)(.) is the modified Bessel function of the
    of the third kind of order lambda and GAMMA is the gamma
    function.

    The standard McLeish distribution can be generalized with
    location and scale parameters in the usual way.

    The cumulative distribution function is computed by
    numerically integrating the probability density function.
    Dataplot performs the integration using the DQAG routine
    from the Slatec library.  The percent point function is
    then computed by numerically inverting the cumulative
    distribution function using the DFZERO subroutine from
    the Slatec library.


Syntax:
    LET <y> = MCLPPF(<p>,<alpha>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, a number, or a parameter in the range
              (0,1);
          <alpha> is a positive number of parameter that specifies
              the value of the shape parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <scale> is an optional positive number or parameter that
              specifies the value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed McLeish ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y = MCLPPF(0.95,1.5)
    LET Y = MCLPPF(P1,ALPHA)
    PLOT MCLPPF(P,ALPHA) FOR P = 0.01  0.01 0.99
 
Note:
    DATAPLOT uses the routine BESK from the SLATEC Common Mathematical
    Library to compute the modified Bessel function of the third
    kind.  SLATEC is a large set of high quality, portable, public
    domain Fortran routines for various mathematical capabilities
    maintained by seven federal laboratories.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MCLPDF = Compute the McLeish probability density function.
    MCLPPF = Compute the McLeish percent point function.
    GMCPDF = Compute the generalized McLeish probability density
             function.
    GALPDF = Compute the generalized asymmetric Laplace probability
             density function.
    GIGPDF = Compute the generalized inverse Gaussian probability
             density function.
    BEIPDF = Compute the Bessel I-function probability density
             function.
    BEKPDF = Compute the Bessel K-function probability density
             function.
 
Reference:
    Johnson, Kotz, and Balakrisnan, "Continuous Univariate
    Distributions--Volume I", Second Edition, Wiley, 1994,
    pp. 50-53.

Applications:
    Distributional Modeling
 
Implementation Date:
    8/2004
 
Program:
    X1LABEL Probability
    Y1LABEL X
    LABEL CASE ASIS
    TITLE CASE ASIS
    CASE ASIS
    Y1LABEL DISPLACEMENT 16
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    TITLE Alpha = 1
    PLOT MCLPPF(P,1) FOR P = 0.01  0.01  0.99
    TITLE Alpha = 2
    PLOT MCLPPF(P,2) FOR P = 0.01  0.01  0.99
    TITLE Alpha = 5
    PLOT MCLPPF(P,5) FOR P = 0.01  0.01  0.99
    TITLE Alpha = 10
    PLOT MCLPPF(P,10) FOR P = 0.01  0.01  0.99
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT McLeish Distribution
 
-----MCNEMAR TEST (LET)--------------------------------
 
MCNEMAR TEST
 
Name:
    MCNEMAR TEST (LET)
 
Type:
    Analysis Command
 
Purpose:
    Perform a McNemar test for independence in a 2x2 table.

Description:
    Given two paired variables where each variable has exactly two
    possible outcomes (coded as 0 and 1), the McNemar test can
    be used to test if there is a statistically significant
    difference between the probability of a (0,1) pair and
    the probability of a (1,0) pair.  For example, this test
    is often used for the situation where we are testing
    for the prescence (= 1) or absence (= 0) of something and
    variable 1 is the state before an experiment and variable 2
    is the state after the experiment (i.e., did the experiment
    have an effect?).  

    We can summarize the data in the following table.  We
    call variable 1 X and variable 2 Y.

                  | Y(i) = 0   Y(i) = 1  |
        ==================================
        X(i) = 0  |     a          b     |
        X(i) = 1  |     c          d     |
        ==================================

    The McNemar test has the the following assumptions:

        1) The pairs (X(i),Y(i)) are mutually independent.

        2) Each X(i) and Y(i) can be assigned to one of
           two possible categories.

        3) If P1 = P(X(i) = 0, Y(i) = 1) - P(X(i) = 1,
           Y(i) = 0), then P1 - P2 is negative for all i
           or zero for all i or positive for all i.

    The McNemar test can then be formulated as follows.

       H0: P1 = P2     for all i
       Ha: P1 <> P2    for all i
       Test Statistic: If b + c > 20,

                          T1 = (b - c)**2/(b+c)

                       If b + c <= 20,

                          T2 = b

                       There is also a continuity corrected
                       version of the T1:

                         T1' = (|b - c| - 1)**2/(b+c)

       Signifiance Level: alpha
       Critical Region: T1 > CHIPPF(1-alpha,1)

                        T2 <= BINPPF(alpha/2,0.5,b+c)
                        T2 >= BINPPF(1-alpha/2,0.5,b+c)

Syntax 1:
    MCNEMAR TEST <y1> <y2> <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the raw data case (i.e., <y1> and
    <y2> are variable containing 0's and 1's).

Syntax 2:
    MCNEMAR TEST <m>    <SUBSET/EXCEPT/FOR qualification>
    where <m> is a matrix containing the two-way table;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where we the data have already
    been cross-tabulated into a two-way table.

Syntax 3:
    MCNEMAR TEST <n11> <n12> <n21> <n22>
    where <n11> is a parameter containing the value for row 1,
                column 1 of a 2x2 table (i.e, a);
          <n12> is a parameter containing the value for row 1,
                column 2 of a 2x2 table (i.e., b);
          <n21> is a parameter containing the value for row 2,
                column 1 of a 2x2 table (i.e., c);
          <n22> is a parameter containing the value for row 2,
                column 2 of a 2x2 table (i.e., d).

    This syntax is used for the special case where you have a
    2x2 table.  In this case, you can enter the 4 values directly,
    although you do need to be careful that the parameters are
    entered in the order expected above.

Examples:
    MCNEMAR TEST Y1 Y2
    MCNEMAR TEST M
    MCNEMAR TEST N11 N12 N21 N22

Note:
    The McNemar test is essentially a sign test.  Conover
    discusses how to transform a McNemar test to the
    explicit sign test.

    The McNemar test is also a special case of the
    Cochran test with c = 2 (enter HELP COCHRAN TEST
    for details).

Note:
     Dataplot saves the following internal parameters:

        STATVAL   = the value of the McNemar test statistic
        STATCDF   = the cdf for the McNemar test statistic

Default:
    None
 
Synonyms:
    None

Related Commands:
    SIGN TEST                     = Perform a sign test.
    COCHRAN TEST                  = Perform a Cochran test.
    MANTEL-HAENSZEL TEST          = Perform a Mantel-Haenszel test.
    ODDS RATIO CHI-SQUARE TEST    = Perform an odds ratio chi-square
                                    test.
    ODDS RATIO INDEPENDENCE TEST  = Perform a log(odds ratio)
                                    independence test.
    CHI-SQUARE INDEPENDENCE TEST  = Perform a chi-square independence
                                    test.
    FISHER EXACT TEST             = Perform Fisher's exact test.
    ASSOCIATION PLOT              = Generate an association plot.
    SIEVE PLOT                    = Generate a sieve plot.
    ROSE PLOT                     = Generate a Rose plot.
    BINARY TABULATION PLOT        = Generate a binary tabulation plot.
    ROC CURVE                     = Generate a ROC curve.
    ODDS RATIO                    = Compute the bias corrected odds
                                    ratio.
    LOG ODDS RATIO                = Compute the bias corrected
                                    log(odds ratio).

Reference:
    Conover (1999), "Practical Nonparametric Statistics",
    Third Edition, Wiley, pp. 166-169.

    Fleiss, Levin, and Paik (2003), "Statistical Methods for
    Rates and Proportions", Third Edition, p. 375.

Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/3
 
Program:
    let n11 = 63
    let n21 = 4
    let n12 = 21
    let n22 = 12
    .
    read matrix m
    2 4
    4 6
    end of data
    .
    mcnear test n11 n21 n12 n22
    mcnemar test m

-----MEAN (LET)-----------------------------------------
 
MEAN
 
Name:
    MEAN (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the mean for a variable.
 
Description:
    The mean is the sum of the observations divided by the number of
    observations.
 
Syntax:
    LET <param> = MEAN <y1> <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the response variable;
          <param> is a parameter where the computed mean is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MEAN Y1
    LET A = MEAN Y1 SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MEAN STATISTICS PLOT = Generate a mean vs. subset plot.
    MEDIAN               = Compute the median.
    STANDARD DEVIATION   = Compute the standard deviation.
 
Applications:
    Data Analysis
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET A1 = MEAN Y1
 
-----MEAN PLOT---------------------------------------------------
 
MEAN PLOT
 
Name:
    MEAN PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a mean plot.
 
Description:
    A mean plot consists of subsample means versus subsample index.
    The subsample mean is the mean of the data in the subsample.  The
    mean plot is used to answer the question--"Does the subsample
    location change over different subsamples?"  The plot consists of:
       Vertical   axis = subsample mean;
       Horizontal axis = subsample index.
    The mean plot yields 2 traces:
       1. a subsample mean trace; and
       2. a full-sample mean reference line.
    Like usual, the appearance of these 2 traces is controlled by
    the first 2 settings of the LINES, CHARACTERS, SPIKES, BARS,
    and similar attributes.
 
Syntax:
    MEAN PLOT   <y>   <x>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    MEAN PLOT Y X
    MEAN PLOT Y X1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    MEDIAN PLOT             = Generates a median plot.
    MIDMEAN PLOT            = Generates a midmean plot.
    MIDRANGE PLOT           = Generates a midrange plot.
    TRIMMED MEAN PLOT       = Generates a trimmed mean plot.
    WINDSORIZED MEAN PLOT   = Generates a Windsorized mean plot
    SD   PLOT               = Generates a standard deviation plot.
    BOX PLOT                = Generates a box plot.
    XBAR CHART              = Generates an xbar control chart.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    88/2
 
Program:
    LET Y = DATA 2 4 6 11 12 21 25 28 29
    LET X = DATA 1 1 1 2 2 3 3 3 3
    LINE BLANK DASH
    CHARACTER X BLANK
    XTIC OFFSET 0.2 0.2
    Y1LABEL MEAN
    X1LABEL SAMPLE ID
    TITLE AUTOMATIC
    MEAN PLOT Y X
 
-----MEAN RANK (LET)---------------------------------------------------
 
MEAN RANK
 
Name:
    MEAN RANK (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute an average (mean) rank for a response variable over one to
    six group-id variables.
 
Description:
    Given a response variable, one to six group-id variables, and a
    sequence variable this command does the following

       1. Cross-tabulate the response variable based on the group-id
          variables.  Each cell of the cross-tabulation will contain
          all the response values for that cell.

          For each row of the response variable within the cell there
          will be a corresponding sequence number.

          The sequence number is used so that missing values can be
          accommodated and so that the response values do not have to
          be in a specific order.  If the response values do not have
          missing data and are already sorted in the correct order, you
          can use the SEQUENCE command to create the sequence variable.
          For example, if there are eight cells with 10 responses each,
          enter

               LET XSEQ = SEQUENCE 1 10 1 8

          In other cases, the sequence id might be another group-id
          variable such as a batch id or a method id.

       2. Within each cross-tabulation cell, rank the response values.

       3. The final step is to then compute the mean rank for each
          distinct value of the sequence variable over all the
          cross-tabulation cells.

    A typical use of this command is to see how a method (or batch or some
    other variable of interest) performs across various conditions of
    several other factor variables.

Syntax:
    LET <yrank> = MEAN RANK <y> <xseq> <x1> ... <xk>
                  <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <xseq> is a variable that defines the sequence number for
              the response variable;
          <x1> ... <x6> is a list of one to six group-id variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET AVERANK = MEAN RANK Y XSEQ X1 X2 X3
    LET AVERANK = MEAN RANK Y XSEQ X1 X2 X3  SUBSET XSEQ = 2 TO 10
 
Note:
    The response values are ranked in ascending order.

Note:
    By default, the output variable will have the same number of elements
    as the input variables.  However, if you enter the command

        SET LET CROSS TABULATE COLLAPSE

    only a single value will be saved in the output variable for each
    distinct combination of the group-id variables.

    In order to preserve the appropriate values of the group-id variables,
    you can enter the commands (this assumes six group-id variables)

        LET X1D = CROSS TABULATE GROUP ONE   X1 X2 X3 X4 X5 X6
        LET X2D = CROSS TABULATE GROUP TWO   X1 X2 X3 X4 X5 X6
        LET X3D = CROSS TABULATE GROUP THREE X1 X2 X3 X4 X5 X6
        LET X4D = CROSS TABULATE GROUP FOUR  X1 X2 X3 X4 X5 X6
        LET X5D = CROSS TABULATE GROUP FIVE  X1 X2 X3 X4 X5 X6
        LET X6D = CROSS TABULATE GROUP SIX   X1 X2 X3 X4 X5 X6

    To restore the default, enter

        SET LET CROSS TABULATE EXPAND

Note:
    The groups in the data do not need to be pre-sorted or
    contiguous.  The ranked response variable will be in the
    same order as the original response variable (i.e., the
    groups are not sorted on output).

Default:
    None
 
Synonyms:
    AVERAGE RANK
 
Related Commands:
    RANK         = Rank the elements of a variable.
    SORT         = Sort the elements of a variable.
    SORTC        = Sort the elements of a variable and carry one or
                   more variables along.
    CODE         = Generate a coded variable.
    SEQUENCE     = Generate a sequence of numbers.
 
Applications:
    Data Management
 
Implementation Date:
    2018/07
 
Program:
    . Step 1:   Read the data
    .
    dimension 20 columns
    set write decimals 2
    .
    skip 25
    read sheesle2.dat y x1 x2 x3 x4 x5
    let n = size y
    let xseq = sequence 1 1 6 for i = 1 1 n
    .
    . Step 2:   Execute the command
    .
    let yout = mean rank y xseq x2 x3
    print yout y xseq x2 x3
 
-----MEAN REPAIR FUNCTION PLOT--------------------------------------
 
MEAN REPAIR FUNCTION PLOT
 
Name:
    MEAN REPAIR FUNCTION PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a plot of repair times where there may be
    multiple groups and a censoring time for each group.
 
Description:
    In reliability studies, it is often necessary to
    analyze repair times.  A first step in analyzing these
    repair times is to simply plot the repair data.

    The repair data consists of the following:

       1) The repair times.

       2) A system id corresponding to each of the repair
          times.

       3) If the test continued to run after the last failure
          time, then a censoring time needs to be included.
          Note that there should be at most one censoring time
          for each system.

          The Dataplot convention is to code the repair times
          as 1 and censoring times as 0.

    The vertical coordinate is the system id and the horizontal
    coordinates are the repair/censoring times.

    The appearance of the plot can be controlled by appropriate
    settings for the LINE and CHARACTER commands.  The traces
    (i.e., curves) are defined as follows:

        1) The first trace consists of all the repair times.
           For this trace, the line setting is typically set to
           a blank value while the character is set to some
           non-blank value.

        2) If there are N systems, traces 2 through N+1 correspond
           to the repair and censoring times for each of these
           systems.  The line settings are typically set to a
           non-blank value while the character settings are
           typically set to blank.
   
    A typical sequence of commands to set the character and
    line settings would be

        LINES SOLID ALL
        CHARACTER BLANK ALL
        LINE BLANK
        CHARACTER *
    

    The system id and censoring variables are optional.  If you
    specify a censoring variable, a group variable must be
    given.  If you have a single system with a censoring time,
    simply create a variable the same length as the response
    variable that has all values equal to 1.  For example,

        LET N = SIZE Y
        LET GROUPID = 1 FOR I = 1 1 N
     
Syntax 1:
    REPAIR PLOT <y> <x> <cens>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a variable containing repair times;
          <x> is a variable containing the group id's;
          <cens> is a variable containing the censoring values;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used to plot repair times for the case where
    there multiple systems, but there are no censoring times.

Syntax 2:
    REPAIR PLOT <y> <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a variable containing repair times;
          <x> is a variable containing the group id's;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used to plot repair times for the case where
    there multiple systems, but there are no censoring times.

Syntax 3:
    REPAIR PLOT <y>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a variable containing repair times;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used to plot repair times for the case where
    there is only a single system and there is no censoring time.

Examples:
    REPAIR PLOT Y BATCH CENSOR
    REPAIR PLOT Y BATCH
    REPAIR PLOT Y BATCH CENSOR  SUBSET BATCH > 1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINES                     = Sets the type for plot lines.
    CHARACTERS                = Sets the type for plot characters.
    MEAN REPAIR FUNCTION PLOT = Generates a mean repair function
                                plot.
    DUANE PLOT                = Generates a Duane plot.
    KAPLAM-MEIER PLOT         = Generates a Kaplan-Meier plot.
    PLOT                      = Generates a data or function plot.
 
Applications:
    Reliability (Repairable Systems)
 
Implementation Date:
    2006/10
 
Program:
    skip 25
    read tob312.dat  y  x  cens
    .
    ylimits 1 3
    major ytic mark number 3
    minor ytic mark number 0
    line blank
    char *
    title Repair Plot
    y1label System ID
    x1label System Age
    title case asis
    title offset 2
    label case asis
    .
    repair plot y x cens
 
-----MEAN SUCCESSIVE DIFFERENCES TEST---------------------------------
 
MEAN SUCCESSIVE DIFFERENCES TEST
 
Name:
    MEAN SUCCESSIVE DIFFERENCES TEST
 
Type:
    Analysis Command
 
Purpose:
    Perform a mean successive differences test for randomness for a
    univariate data set.
 
Description:
    The mean successive differences test is computed as

         M = (1/(N-1))*SUM[i=1 to N-1][(X(i+1) - X(i))**2]/
             (1/(N-1))*SUM[i=1 to N][(X(i) - XBAR)**2]
           = SUM[i=1 to N-1][(X(i+1) - X(i))**2]/
             SUM[i=1 to N][(X(i) - XBAR)**2]

    The numerator term is a measure of variance adjusted for trend
    while the denominator is the standard variance.

    For N > 20, Dataplot computes critical values based on the
    following formula from Dixon:

        T = (1 - (M/2))/SQRT((N-2)/((N-1)*(N+1)))

    T is compared to a standard normal distribution.

    For N <= 20, critical values are taken from tables given by
    Neubauer.

    If the data are random and from an underlying normal distribution,
    the average value of M is 2.  Large values of M indicate excessive
    fluctuations in the data.  Small values of M indicate long term
    trend.

    There are several variations of this test in the literature.  For
    example, the numerator term is sometimes given as an absolute value
    rather than a square.  Early versions of the test used N rather than
    N - 1 in the denominator.  There are also been a number of different
    approximations proposed for the critical values for this test.
    The approximation used here should be adequate for practical purposes.

    The Durbin Watson test is a variant of this test that is commonly
    used to test for serial correlation in regression problems.  The
    mean successive differences test is applied to the residuals.  Since
    the mean of the residuals is zero, the XBAR in the formula above
    drops out.

    This test is also sometimes referred to as the adjacency test.

Syntax 1:
    MEAN SUCCESSIVE DIFFERENCES TEST  <y>
                                      <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Syntax 2:
    MEAN SUCCESSIVE DIFFERENCES TEST  <y1>  ... <yk>
                                      <SUBSET/EXCEPT/FOR qualification>
    where <y1> ... <yk> is a list of 1 to 30 response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax will perform a mean successive differences test for each
    of the response variables.  For example,

         MEAN SUCCESSIVE DIFFERENCES TEST Y1 TO Y4

    is equivalent to

         MEAN SUCCESSIVE DIFFERENCES TEST Y1
         MEAN SUCCESSIVE DIFFERENCES TEST Y2
         MEAN SUCCESSIVE DIFFERENCES TEST Y3
         MEAN SUCCESSIVE DIFFERENCES TEST Y4

Syntax 3:
    REPLICATED MEAN SUCCESSIVE DIFFERENCES TEST  <y> <x1>  ... <xk>
                               <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <x1> ... <xk> is a list of 1 to 6 group-id variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax will compute the test for each unique combination of the
    group-id variables.

Examples:
    MEAN SUCCESSIVE DIFFERENCES TEST Y
    MEAN SUCCESSIVE DIFFERENCES TEST Y1 TO Y5
    REPLICATED MEAN SUCCESSIVE DIFFERENCES TEST Y X1 X2
 
Note:
    The MEAN SUCCESSIVE DIFFERENCES TEST will accept matrix arguments.  If
    a matrix is given, the data elements in the matrix will be collected in
    column order to form a vector before performing the mean successive
    differences test.  Matrices are not supported for the REPLICATED
    case (Syntax 3).
 
Note:
    Dataplot saves the following internal parameters after a
    sign test:

        STATVAL   = the value of the test statistic
        STATVAL2  = the value of the normalized test statistic
        STATCDF   = the CDF of the test statistic
        PVALUE    = the p-value for the two-sided test
        CUTLOW50  = the 50% lower tailed critical value
        CUTUPP50  = the 50% upper tailed critical value
        CUTLOW80  = the 80% lower tailed critical value
        CUTUPP80  = the 80% upper tailed critical value
        CUTLOW90  = the 90% lower tailed critical value
        CUTUPP90  = the 90% upper tailed critical value
        CUTLOW95  = the 95% lower tailed critical value
        CUTUPP95  = the 95% upper tailed critical value
        CUTLOW99  = the 99% lower tailed critical value
        CUTUPP99  = the 99% upper tailed critical value
        CUTLO999  = the 99.9% lower tailed critical value
        CUTUP999  = the 99.9% upper tailed critical value

    For N <= 20, critical values are obtained from tabulated
    values and some of these parameters are not defined.  In this
    case, these parameters will be set to the minimum machine value.
    You can retrieve this value with the commands

       PROBE CPUMIN
       LET CPUMIN = PROBVEVAL

Note:
    The following statistics are also supported

       LET A = MEAN SUCCESSIVE DIFFERENCES TEST Y
       LET A = MEAN SUCCESSIVE DIFFERENCES TEST NORMALIZED Y
       LET A = MEAN SUCCESSIVE DIFFERENCES TEST CDF Y
       LET A = MEAN SUCCESSIVE DIFFERENCES TEST PVALUE Y

    The NORMALIZED form returns the Dixon-Massey transformation of
    the statistic described above.  Note that the CDF and PVALUE
    are not computed for N < 20 (they will be set to the minimum
    machine value in this case).

    Enter HELP STATISTICS for a list of commands that can be used
    with Dataplot supported statistics.  See Program 2 below for an
    example.

Note:
    Dataplot provides a number of plots and tests for assessing the
    randomness of continuous data.

    The run sequence plot, the lag plot, and the auto-correlation plots
    can be used to graphically assess whether or not there is trend or
    auto-correlation in the data.  The 4-plot can be used to assess the
    more general assumption of "independent, identically distributed"
    data.

    The Cox Stuart test is a non-parametric test for trend.  The Ljung Box
    test is a test for randomness based on the auto-correlation for a
    number of lags (i.e., more than first order auto-correlation).  The runs
    test is a test for randomness based on the number of runs (i.e., sequences
    of increasing values or sequences of decreasing values).

    The frequency test, the frequency within a block test, and the cusum test
    can be used to test the randomness of sequence of zeros and ones.

Default:
    None
 
Synonyms:
    MEAN SUCCESSIVE DIFFERENCES
    DURBIN WATSON TEST
    DURBIN WATSON
    ADJACENCY RANDOMNESS TEST
    ADJACENCY RANDOMNESS
    ADJACENCY TEST
    ADJACENCY
 
Related Commands:
    RUN SEQUENCE PLOT          = Generate a run sequence plot.
    LAG PLOT                   = Generate a lag plot.
    AUTOCORRELATION PLOT       = Generate an autocorrelation plot.
    4-PLOT                     = Generate a 4-plot.
    COX STUART TEST            = Perform a Cox Stuart test for randomness.
    LJUNG BOX TEST             = Perform a Ljung-Box test for randomness.
    RUNS TEST                  = Perform a runs test for randomness.
    FREQUENCY TEST             = Perform a frequency test for randomness.
    CUSUM TEST                 = Perform a cusum test for randomness.
 
Reference:
    Neumann, Kent, Bellinson, Hart (1941), "The Mean Square Successive
    Difference", Annals of Mathematical Statistics, 12, 153-162.

    John V. Neumann (1941), "Distribution of the Ratio of the Mean
    Successive Difference to the Variance", Annals of Mathematical
    Statistics, 12, 367-395.

    Dean Neubauer, "Testing for Randomness: The Mean Successive Differences
    Test", ASTM Standardization News, September/October 2012, pp. 12-13.

    Dixon and Massey (1957), "Introduction to Statistical Analysis",
    McGraw Hill, p. xxx.
 
Applications:
    Assessing Randomness
 
Implementation Date:
    2013/01
    2015/03: Added ADJACENCY TEST as a synonym
 
Program 1:
    . Purpose: Mean Successive Difference Test for Randomness
    .
    . Step 1:  Read the Data
    .
    .          The ZAR110.DAT file contains the data from the Neubauer
    .          article.
    .
    skip 25
    read zarr110.dat y1
    read lew.dat     y2
    skip 0
    .
    .          Sample data from example 2 on page 171 of Conover.
    .
    let y3 = data 45.25 45.83 41.77 36.26 45.37 52.25 35.37 57.16 35.37 ...
                  58.32 41.05 33.72 45.73 37.90 41.72 36.07 49.83 36.24 ...
                  39.90
    .
    let y x = stack y1 y2 y3
    .
    set write decimals 4
    mean successive difference test y1 y2 y3
    replicated mean successive difference test y x

Program 2:
    skip 25
    read splett2.dat y  x
    skip 0
    .
    title case asis
    title offset 2
    label case asis
    x1label displacement 12
    multiplot scale factor 2
    multiplot corner coordinates 5 5 95 95
    multiplot 2 2
    .
    let ntemp = size y
    let xseq = sequence 1 1 ntemp
    char 1 2 3 4
    line blank blank blank blank
    y1label Absorbed Energy
    x1label Sequence
    title Raw Data
    plot y xseq x
    char blank all
    line solid all
    .
    xlimits 1 4
    major xtic mark number 4
    minor xtic mark number 0
    tic mark offset units data
    x1tic mark offset 0.5 0.5
    tic mark label case asis
    x1tic mark label format alpha
    x1tic mark label content Tinius1 Tinius2 Satec Tokyo
    x1label Manufacterer
    .
    char X
    line blank
    y1label
    title MSD Test Statistic
    mean successive differences test normalized plot y x
    title MSD Test Statistic CDF
    mean successive differences test cdf plot y x
    title MSD Test Statistic P-Value
    mean successive differences test pvalue plot y x
    .
    end of multiplot
    .
    case asis
    justification center
    move 50 97
    text Mean Successive Differences Test for SPLETT2.DAT
-----MEDIAN (LET)-----------------------------------------
 
MEDIAN
 
Name:
    MEDIAN (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the median for a variable.
 
Description:
    The median is the value of the observation for which half the
    observations are larger and half are smaller.  If there are an even
    number of data points, the mean is taken of the 2 middle points.
    The median is sometimes used instead of the mean because it is less
    affected by outliers.
 
Syntax:
    LET <param> = MEDIAN <y1> <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the response variable;
          <param> is a parameter where the computed median is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MEDIAN Y1
    LET A = MEDIAN Y1 SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MEDIAN STATISTIC PLOT = Generate a median vs. subset plot.
    MEAN                  = Compute the mean.
    STANDARD DEVIATION    = Compute the standard deviation.
 
Applications:
    Data Analysis
 
Implementation Date:
    Pre-1987
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET A1 = MEDIAN Y1
 
-----MEDIAN CONFIDENCE LIMITS--------------------------------------
 
MEDIAN CONFIDENCE LIMITS
 
Name:
    MEDIAN CONFIDENCE LIMITS
 
Type:
    Analysis Command
 
Purpose:
    Generates a median based confidence interval for the location
    of a variable.
 
Description:
    Mosteller and Tukey (see Reference section below) define
    two types of robustness:

      1) resistance means that changing a small part, even by a
         large amount, of the data does not cause a large change
         in the estimate

      2) robustness of efficiency means that the statistic has
         high efficiency in a variety of situations rather than
         in any one situation.  Efficiency means that the estimate
         is close to optimal estimate given that we distribution
         that the data comes from.  A useful measure of efficiency
         is:

              Efficiency = (lowest variance feasible)/
                           (actual variance)
   
    Standard confidence intervals are based on the mean and
    variance.  These are the optimal estimators if the data
    are in fact from a Gaussian population.  However, the
    mean lacks both resistance and robustness of efficiency.
    The median is less affected by outliers (i.e., resistance)
    than the mean.  However, the median is not particularly
    robust with regards to efficiency.

    Dataplot generates confidence intervals for the median using
    the following two methods:

    1) Method 1 is the Hettmansperger-Sheather interpolation
       method.  The steps in this method are:

       a) Suppose W is a binomial random variable with n trials and
          a probability of success p = 0.5.  For any integer, k,
          between 0 and [n/2], let gamma(k) = P(k<= W <= n-k).

          A 95% confidence interval for the median is:

             (X(k),X(n-k+1))

          where X are the sorted observations.

       b) Determine k such that gamma(k+1) < 1 - alpha < gamma(k).

       c) Compute 

             I = (gamma(k) -1 - alpha)/(gamma(k) - gamma(k+1))

          and

             lambda = (n-k)*I/(k + (n-2*k)*I)

       d) An approximate (1-alpha) confidence interval is

             LCL = lambda*X(k+1) + (1-lambda)*X(k)
             UCL = lambda*X(n-k) + (1-lambda)*X(n-k+1)

    2) Method 2, based on a method given by Wilcox (see Reference
       below) on page 87, is based on the Maritz-Jarrett estimate
       of the standard error for a quantile.  Specifically,

         xhat(q) +/- NORPPPF(1-alpha/2)*sigmahat(mj)

       where

         q             = the desired quantile (q = 0.5 for the median)
         xhat(q)       = the estimated sample quantile
         NORPPF        = the percent point function of the standard
                         normal distribution
         alpha         = the significance level
         sigmahat(mj)  = the quantile standard error based on the
                         Maritz-Jarrett method
       
       Note that this method can be applied to quantiles other
       than the median.  However, the accuracy of this method has
       not been studied for quantiles other than 0.5.

Syntax 1:
    MEDIAN CONFIDENCE LIMITS  <y>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable,
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    QUANTILE CONFIDENCE LIMITS <y>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable,
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    MEDIAN CONFIDENCE LIMITS Y1

    LET P100 = 0.25
    QUANTILE CONFIDENCE LIMITS Y1  SUBSET TAG = 2
 
Note:
    For quantiles other than the median, the desired quantile is
    specified with the LET command.  Specifically, define the
    parameter P100.  For example,

       LET P100 = 0.25

    Only the method based on the Maritz-Jarrett standard error
    is supported for quantiles other than the median.

Note:
    A table of confidence intervals is printed for alpha levels of
    50.0, 75.0, 90.0, 95.0, 99.0, 99.9, 99.99, and 99.999.
 
Note:
    Alternative methods for generating confidence intervals for
    medians or quantiles are available.

    1) You can use the BOOTSTRAP MEDIAN PLOT or the
       BOOTSTRAP QUANTILE PLOT command.  For example,

          LET Y = CAUCHY RANDOM NUMBERS FOR I = 1 1 100
          BOOTSTRAP MEDIAN PLOT Y
          LET LCL = B025
          LET UCL = B975
          .
          LET XQ = 0.75
          BOOTSTRAP QUANTILE PLOT Y
          LET LCL = B025
          LET UCL = B975

    2) Wilcox suggests the following method for quantiles (the
       median is a special case with the quantile = 0.5)
       on page 86.

             thetahat(q) +/- chat*sigmahat(hd)

       where     
  
          thetahat(q)   = the Herrell-Davis quantile estimate
          sigmahat(hd)  = the bootstrap estimate of the
                          Herrell-Davis quantile standard error
          chat          = 0.5064*N**(-0.25) + 1.96
                          for N >= 11, 0.3 <= q <= 0.7
                          for N > 21, 0.2 <= q <= 0.8
                          for N > 41, 0.1 <= q <= 0.9
                        = -6.23*(1/N) + 5.01
                          for 11 <= N <= 21, q = 0.2, 0.8
                        = 36.2*(1/N) + 1.31
                          for N > 41, q = 0.1, 0.9
  
      This can be coded in the following Dataplot macro:

           SET QUANTILE METHOD HERRELL DAVIS
           LET P100 = 0.5
           LET THETAHAT = QUANTILE Y
           BOOTSTRAP QUANTILE STANDARD ERROR PLOT Y
           LET SIGMAHAT = B50
           LET N = SIZE Y
           IF N < 11
             QUIT
           END OF IF
           LET C = 0.5064*N**(-0.25) + 1.96
           LET IQFLAG = 1
           IF P100 <= 0.19
             IF N > 41
               LET C = 36.2*(1/N) + 1.31
             END OF IF
           ELSEIF P100 <= 0.29
             IF N <= 21
               LET C = -6.23*(1/N) + 5.01
             END OF IF
           ELSE IF P100 >= 0.81
             IF N > 41
               LET C = 36.2*(1/N) + 1.31
             END OF IF
           ELSE IF P100 >= 0.71
             IF N <= 21
               LET C = -6.23*(1/N) + 5.01
             END OF IF
           ENDIF
           LET LOWLIMIT = THETAHAT - C*B50
           LET UPPLIMIT = THETAHAT + C*B50

Default:
    None
 
Synonyms:
    MEDIAN CONFIDENCE INTERVAL
 
Related Commands:
    MEDIAN                   = Compute the median.
    MEDIAN PLOT              = Generate a trimmed mean (versus
                               subset plot).
    BOOTSTRAP PLOT           = Generate a bootstrap plot.
    CONFIDENCE LIMITS        = Compute a Gaussian based confidence
                               limit.
    BIWEIGHT CONF LIMITS     = Compute a biweight location based
                               confidence limit.
    TRIMMED MEAN CONF LIMITS = Compute a trimmed mean based confidence
                               limit.
    T-TEST                   = Perform a t-test.
 
Reference:
    "Introduction to Robust Estimation and Hypothesis Testing",
    Rand R. wilcox, Academic Press, 1997.
 
    "Confidence Interval Based on Interpolated Order Statistics",
    T. P. Hettmansperger and S. J. Sheather, Statistical Probability
    Letters 4, 1986, 75-79.

Applications:
    Robust Data Analysis
 
Implementation Date:
    2003/2
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y2 = LOGISTIC RANDOM NUMBERS FOR I = 1 1 100
    LET Y3 = CAUCHY RANDOM NUMBERS FOR I = 1 1 100
    LET Y4 = DOUBLE EXPONENTIAL RANDOM NUMBERS FOR I = 1 1 100
    MEDIAN CONFIDENCE LIMITS Y1
    MEDIAN CONFIDENCE LIMITS Y2
    MEDIAN CONFIDENCE LIMITS Y3
    MEDIAN CONFIDENCE LIMITS Y4
 
-----MEDIAN PLOT-------------------------------------------------
 
MEDIAN PLOT
 
Name:
    MEDIAN PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a median plot.
 
Description:
    A median plot consists of subsample medians versus subsample index.
    The subsample median is the middle of the ordered data from the
    subsample.  The median plot is used to answer the question--"Does
    the subsample location change over different subsamples?"  The plot
    consists of:
       Vertical   axis = subsample median;
       Horizontal axis = subsample index.
    The median plot yields 2 traces:
       1. a subsample median trace; and
       2. a full-sample median reference line.
    Like usual, the appearance of these 2 traces is controlled by the
    first 2 settings of the LINES, CHARACTERS, SPIKES, BARS, and
    similar attributes.
 
Syntax:
    MEDIAN PLOT   <y>   <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    MEDIAN PLOT Y X
    MEDIAN PLOT Y X1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    MEAN   PLOT             = Generates a mean plot.
    MIDMEAN PLOT            = Generates a midmean plot.
    MIDRANGE PLOT           = Generates a midrange plot.
    TRIMMED MEAN PLOT       = Generates a trimmed mean plot.
    WINDSORIZED MEAN PLOT   = Generates a Windsorized mean plot
    SD   PLOT               = Generates a standard deviation plot.
    BOX PLOT                = Generates a box plot.
    XBAR CHART              = Generates an xbar control chart.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    LET Y = DATA 2 4 6 11 12 21 25 28 29
    LET X = DATA 1 1 1 2 2 3 3 3 3
    LINE BLANK DASH
    CHARACTER X BLANK
    XTIC OFFSET 0.2 0.2
    Y1LABEL MEDIAN
    X1LABEL SAMPLE ID
    TITLE AUTOMATIC
    MEDIAN PLOT Y X
 
-----MEDIAN ABSOLUTE DEVIATION (LET)-------------------------------
 
MEDIAN ABSOLUTE DEVIATION
 
Name:
    MEDIAN ABSOLUTE DEVIATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the median absolute deviation for a variable.
 
Description:
    The median absolute deviation is:

        MAD = MEDIAN(ABS(X-XMED))

    where ABS is the absolute value and XMED is the median of the
    variable.  This statistic is sometimes used as a robust
    alternative to the standard deviation as a measure of scale.

    The scaled MAD is defined as

       MADN = MAD/0.6745

    For normally distributed data, the scaled MAD is approximately
    equal to the standard deviation.
 
Syntax 1:
    LET <par> = MEDIAN ABSOLUTE DEVIATION <y>
             <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed median absolute
               deviation is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <par> = SCALED MEDIAN ABSOLUTE DEVIATION <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed scaled median absolute
               deviation is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MEDIAN ABSOLUTE DEVIATION Y1
    LET A = MEDIAN ABSOLUTE DEVIATION Y1 SUBSET TAG > 2
    LET A = SCALED MEDIAN ABSOLUTE DEVIATION Y1
 
Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    MAD is a synonym for MEDIAN ABSOLUTE DEVIATION
    MADN is a synonym for SCALED MEDIAN ABSOLUTE DEVIATION
    NORMALIZED is a synomym for SCALED
 
Related Commands:
    AVERAGE ABSOLUTE DEVIATION = Compute the average absolute
                                 deviation of a variable.
    STANDARD DEVIATION         = Compute the standard deviation of a
                                 variable.
    VARIANCE                   = Compute the variance of a variable.
    RANGE                      = Compute the range of a variable.
 
Applications:
    Data Analysis
 
Implementation Date:
    1995/04
    2016/02: Added SCALED MEDIAN ABSOLUTE DEVIATION
 
Program 1:
    LET Y1 = LOGISTIC RANDOM NUMBERS FOR I = 1 1 100
    LET A1 = MEDIAN ABSOLUTE DEVIATION Y1
    LET A2 = SCALED MEDIAN ABSOLUTE DEVIATION Y1
 
Program 2:
    SKIP 25
    READ GEAR.DAT DIAMETER BATCH
    TITLE AUTOMATIC
    XLIMITS 1 10
    MAJOR XTIC MARK NUMBER 10
    MINOR XTIC MARK NUMBER 0
    XTIC OFFSET 1 1
    X1LABEL BATCH
    Y1LABEL MEDIAN ABSOLUTE DEVIATION OF DIAMETER
    MAD PLOT DIAMETER BATCH
 
-----MEDIAN CONFIDENCE LIMITS--------------------------------------
 
MEDIAN CONFIDENCE LIMITS
 
Name:
    MEDIAN CONFIDENCE LIMITS
 
Type:
    Analysis Command
 
Purpose:
    Generates a median based confidence interval for the location
    of a variable.
 
Description:
    Mosteller and Tukey (see Reference section below) define
    two types of robustness:

      1) resistance means that changing a small part, even by a
         large amount, of the data does not cause a large change
         in the estimate

      2) robustness of efficiency means that the statistic has
         high efficiency in a variety of situations rather than
         in any one situation.  Efficiency means that the estimate
         is close to optimal estimate given that we distribution
         that the data comes from.  A useful measure of efficiency
         is:

              Efficiency = (lowest variance feasible)/
                           (actual variance)
   
    Standard confidence intervals are based on the mean and
    variance.  These are the optimal estimators if the data
    are in fact from a Gaussian population.  However, the
    mean lacks both resistance and robustness of efficiency.
    The median is less affected by outliers (i.e., resistance)
    than the mean.  However, the median is not particularly
    robust with regards to efficiency.

    The confidence interval used here is based on a method
    given by Wilcox (see Reference below) on page 87.  Specifically,

       xhat(q) +/- NORPPPF(1-alpha/2)*sigmahat(mj)

    where

       q             = the desired quantile (q = 0.5 for the median)
       xhat(q)       = the estimated sample quantile
       NORPPF        = the percent point function of the standard
                       normal distribution
       alpha         = the significance level
       sigmahat(mj)  = the quantile standard error based on the
                       Maritz-Jarrett method
       
    Note that this method can be applied to quantiles other
    than the median.  However, the accuracy of this method has
    not been studied for quantiles other than 0.5.

Syntax 1:
    MEDIAN CONFIDENCE LIMITS  <y>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable,
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    QUANTILE CONFIDENCE LIMITS  <y>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable,
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    MEDIAN CONFIDENCE LIMITS Y1

    LET P100 = 0.25
    QUANTILE CONFIDENCE LIMITS Y1  SUBSET TAG = 2
 
Note:
    For quantiles other than the median, the desired quantile is
    specified with the LET command.  Specifically, define the
    parameter P100.  For example,

       LET P100 = 0.25

Note:
    A table of confidence intervals is printed for alpha levels of
    50.0, 75.0, 90.0, 95.0, 99.0, 99.9, 99.99, and 99.999.  The sample
    quantile and the sample quantile standard error are also printed.
    The normal percent point value (Z) and Z X standard error
    are printed in the table.
 
Note:
    Several alternative methods for generating confidence
    intervals for a quantile are available.

       1) You can use the QQUANTILE BOOTSTRAP PLOT command.


       2) Wilcox suggests the following additional method
          (on page 86).  This method can be applied for quantiles
          other than the median.

             thetahat(q) +/- chat*sigmahat(hd)

          where     
     
             thetahat(q)   = the Herrell-Davis quantile estimate
             sigmahat(hd)  = the bootstrap estimate of the
                             Herrell-Davis quantile standard error
             chat          = 0.5064*N**(-0.25) + 1.96
                             for N >= 11, 0.3 <= q <= 0.7
                             for N > 21, 0.2 <= q <= 0.8
                             for N > 41, 0.1 <= q <= 0.9
                           = -6.23*(1/N) + 5.01
                             for 11 <= N <= 21, q = 0.2, 0.8
                           = 36.2*(1/N) + 1.31
                             for N > 41, q = 0.1, 0.9
  
         This can be coded in the following Dataplot macro:

              SET QUANTILE METHOD HERRELL DAVIS
              LET P100 = 0.5
              LET THETAHAT = QUANTILE Y
              BOOTSTRAP QUANTILE STANDARD ERROR PLOT Y
              LET SIGMAHAT = B50
              LET N = SIZE Y
              IF N < 11
                QUIT
              END OF IF
              LET C = 0.5064*N**(-0.25) + 1.96
              LET IQFLAG = 1
              IF P100 <= 0.19
                IF N > 41
                  LET C = 36.2*(1/N) + 1.31
                END OF IF
              ELSEIF P100 <= 0.29
                IF N <= 21
                  LET C = -6.23*(1/N) + 5.01
                END OF IF
              ELSE IF P100 >= 0.81
                IF N > 41
                  LET C = 36.2*(1/N) + 1.31
                END OF IF
              ELSE IF P100 >= 0.71
                IF N <= 21
                  LET C = -6.23*(1/N) + 5.01
                END OF IF
              ENDIF
              LET LOWLIMIT = THETAHAT - C*B50
              LET UPPLIMIT = THETAHAT + C*B50

Default:
    None
 
Synonyms:
    MEDIAN CONFIDENCE INTERVAL
 
Related Commands:
    MEDIAN                     = Compute the median.
    MEDIAN PLOT                = Generate a trimmed mean (versus
                                 subset plot).
    CONFIDENCE LIMITS          = Compute a Gaussian based confidence
                                 limit.
    BIWEIGHT CONFIDENCE LIMITS = Compute a trimmed mean based confidence
                                 limit.
    T-TEST                     = Perform a t-test.
    WINSORIZED MEAN            = Compute a Winsorized mean.
 
Reference:
    "Introduction to Robust Estimation and Hypothesis Testing",
    Rand R. wilcox, Academic Press, 1997.
 
Applications:
    Robust Data Analysis
 
Implementation Date:
    2003/2
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y2 = LOGISTIC RANDOM NUMBERS FOR I = 1 1 100
    LET Y3 = CAUCHY RANDOM NUMBERS FOR I = 1 1 100
    LET Y4 = DOUBLE EXPONENTIAL RANDOM NUMBERS FOR I = 1 1 100
    MEDIAN CONFIDENCE LIMITS Y1
    MEDIAN CONFIDENCE LIMITS Y2
    MEDIAN CONFIDENCE LIMITS Y3
    MEDIAN CONFIDENCE LIMITS Y4
 
-----MEDIAN POLISH----------------------------------------------------
 
MEDIAN POLISH
 
Name:
    MEDIAN POLISH
 
Type:
    Analysis Command
 
Purpose:
    Carries out a median polish.
 
Description:
    Median polish is a data analysis technique (more robust than ANOVA)
    for examining the significance of the various factors in a
    multi-factor model.  The number of factors (= independent
    variables) must be between 1 and 5, inclusive.  Each factor then
    has a certain number of values it can have (these are referred to
    as the levels of a factor).  The number of levels does not have to
    be the same for each factor.  Each factor and level combination is
    a cell (the number of cells is the product of the number of levels
    in each factor).  Balanced designs are those in which each cell has
    the same number of observations and unbalanced designs are those in
    which the number of observations can vary between cells.  The
    MEDIAN POLISH command can work with unbalanced designs (unlike the
    ANOVA command).  The number of arguments specifies whether
    1-factor, 2-factor, or higher order median polish is performed.
 
    Median polish models the response variable as:
        data = common value + factor-1 effects + ... + factor-n effects
                    + residual
    More complex models can also include interaction terms.  However,
    the DATAPLOT MEDIAN POLISH command does not compute interaction
    terms.
 
Syntax 1:
    MEDIAN POLISH   <y>  <x1 ... Xn>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x1 ... xn> is a list of 1 to 5 independent variables (1
              variable for 1-factor median polish, 5 variables for
              5-factor median polish, etc.);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    MEDIAN POLISH Y X1
    MEDIAN POLISH Y X1 X2
    MEDIAN POLISH Y X1 X2  SUBSET X2 > 3
 
Note:
    The following is the basic algorithm for median polish.
 
    For each factor, do the following:
       1) Calculate the medians for each level of a factor (these are
          the factor effects).
       2) For each value of the response variable, subtract the
          corresponding level median.
    The above steps are repeated until the ratio of the sum of the
    residuals from the current step and the residuals from the previous
    step are less than some cut-off value (normally only 2 or 3 passes
    are required).
 
Note:
    The factor effects for a given factor are the sum over all
    iterations of the medians computed for each level.  The predicted
    value for a given response value is the sum of the factor effects
    for the corresponding levels of each factor.  The residuals are the
    response variable minus the predicted value.  The residuals and
    predicted values are stored in the internal variables RES and PRED
    respectively.  These variables can be used in subsequent LET and
    PLOT commands for additional analysis.
 
Note:
    The common term is incorporated into the factor-1 effects.  If you
    want to split these, subtract off the grand median from the factor
    1 effects.
 
Note:
    The MEDIAN POLISH command can work with raw data or with summary
    value for each cell (e.g., the mean, median, or some other summary
    measure).
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    ANOVA              = Carries out an ANOVA.
    YATES ANALYSIS     = Analyze a Yate's design.
    BLOCK PLOT         = Generate a block plot.
    DEX SCATTER PLOT   = Generates a dex scatter plot.
    DEX ... PLOT       = Generates a dex plot for a statistic.
    T TEST             = Carries out a t test.
    PLOT               = Plots (e.g., residuals and GANOVA).
 
Reference:
    "Data Analysis and Regression", Mosteller and Tukey,
    Addison-Wesley, 1977 (chapter 9).
 
Applications:
    Analysis of Variance
 
Implementation Date:
    Pre-1987
 
Program:
    . READ FILE "SHEESLEY.DAT" IN DATAPLOT REFERENCE CATALOG
    . THIS IS DATAPLOT DATA FILE   SHEESLEY.DAT     (RAW DATA)
    . LIGHT BULB LEAD WIRE WELD PROCESS COMPARISON
    . JOHN SHEESLEY (GE) ARTICLE IN
    . EXPERIMENTS IN INDUSTRY  (ED. BY SNEE, HARE, TROUT) PAGES 54-57
    . NUMBER OF OBSERVATIONS = 96
    . ORDER OF VARIABLES ON A LINE IMAGE--
    .    RESPONSE = AVERAGE NUMBER OF WELDED LEAD WIRES MISSED PER HOUR
    .    FACTOR 1 = WELDING PROCESS (2 LEVELS) (PRIMARY)
    .    FACTOR 2 = SHIFT (3 LEVELS)
    .    FACTOR 3 = MACHINE (2 LEVELS)
    .    FACTOR 4 = PLANT (2 LEVELS)
    .    FACTOR 5 = REPLICATION (4 LEVELS) (A RANDOM FACTOR)
    SKIP 25
    READ SHEESLEY.DAT Y WELD SHIFT MACH PLANT REP
    MEDIAN POLISH Y WELD SHIFT MACH PLANT
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE AUTOMATIC
    CHARACTER 1 2; LINES BLANK BLANK
    BLOCK PLOT Y SHIFT MACH PLANT WELD
    CHARACTER CIRCLE
    CHARACTER SIZE 1.0
    LINES BLANK
    PLOT RES
    PLOT RES VS PRED
    NORMAL PROBABILITY PLOT RES
    END OF MULTIPLOT
 
-----MEDIAN SCORE (LET)-----------------------------------------------
 
MEDIAN SCORE
 
Name:
    MEDIAN SCORE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the median scores of a variable.
 
Description:
    The median scores are defined as

        s(R(j)) = 1      if R(j) >  (n+1)/2
                = 0      if R(j) <= (n+1)/2

    where R(j) is the rank of the j-th observation and n is the number
    of observations.  That is, ranks that are greater than the median of
    the ranks are given a value of 1 and ranks that are less than are
    equal to the median rank are given a value of 0.

    Median scores are typically used in nonparametric statistics.  For
    example, using median scores in the two sample linear rank test
    generates the two sample median test and using median scores in a
    one-way ANOVA generates the Brown-Mood test.

Syntax:
    LET <s> = MEDIAN SCORE <y>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <s> is a variable where the computed median scores are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET MEDSCORE = MEDIAN SCORE Y
 
Note:
    Ties are assigned an average rank.  For example, if the 2nd and 3rd
    highest values are equal, each is assigned a rank of 2.5.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MEDIAN TEST             = Perform a median test.
    ANOVA                   = Perform a fixed effects analysis of variance.
    MOOD SCORES             = Generate Mood scores.
    VAN DER WAERDEN SCORES  = Generate Van Der Waerden scores.
    SAVAGE SCORES           = Generate Savage scores.
    KLOTZ SCORES            = Generate Klotz scores.
    CONOVER SCORES          = Generate Conover scores.
    ANSARI BRADLEY SCORES   = Generate Ansari Bradley scores.
    PLACEMENT SCORES        = Generate placement scores.
    RANK                    = Generate the ranks of a variable. 
 
Applications:
    Nonparametric statistics
 
Implementation Date:
    2023/06
 
Program:
    . Step 1:   Define the data
    .
    let y1 = data 16.55 15.36 15.94 16.43 16.01
    let y2 = data 16.05 15.98 16.10 15.88 15.91
    let n1 = size y1
    let n2 = size y2
    let n = n1 + n2
    .
    . Step 2:   Combine into single array
    .
    let y tag = stack y1 y2
    if n1 <= n2
       let tag = tag - 1
       let n1t = n1
    else
       let tag = 0 subset tag = 2
       let n1t = n2
    end of if
    .
    . Step 3:   Compute the median scores
    .
    let ymedian = median scores y
    .
    . Step 4:   Two-sample median test
    .
    .            Two-Sample Linear Rank Test
    .
    let temp = tag*ymedian
    let s = sum temp
    .
    let aval = sum ymedian
    let smean = (n1t/n)*aval
    let meanrank = mean ymedian
    let temp = (ymedian - meanrank)**2
    let aval = sum temp
    let svar = ((n1*n2)/(n*(n-1)))*aval
    let statval = (s - smean)/sqrt(svar)
    let statval = round(statval,3)
    let cv = norppf(0.975)
    let upplim = round(cv,2)
    let lowlim = -upplim
    feedback off
    print "Two Sample Linear Rank Sum Test Based on Median Scores"
    print "H0: Medians are Equal"
    print "Ha: Medians are Not Equal"
    print "alpha: 0.05"
    print "Test Statistic: ^statval"
    print "Lower Critical Value: ^lowlim"
    print "Upper Critical Value: ^upplim"
    if statval < cv
       print "Conclusion: Accept H0"
    else
       print "Conclusion: Reject H0"
    end of if
 
-----MEDIAN TEST (LET)--------------------------------
 
MEDIAN TEST
 
Name:
    MEDIAN TEST (LET)
 
Type:
    Analysis Command
 
Purpose:
    Perform the median k-sample test for equal medians.

Description:
    The median test is a special case of the chi-square test for
    independence.  Given k samples with n1, n2, ..., nk observations,
    compute the grand median of all n1 + n2 + ... + nk observations.
    Then construct a 2xk contingency table where row one contains
    the number of observations above the grand median for each
    of the k samples and row two contains the number of observations
    below or equal to the grand median for each of the k samples.
    The chi-square test for independence can then be applied to
    this table.  More specifically

       H0: All k populations have the same median
       Ha: All least two of the populations have different medians
       Test Statistic: T = (N**2/(a*b))*
                           SUM[i=1 to k][(O(1i) - n(i)*a/N)**2/n(i)] 
                       where

                       a     = the number of observations greater than
                               the median for all samples
                       b     = the number of observations less than or
                               equal to the median for all samples
                       N     = the total number of observations
                       O(1i) = the number of observations greater than
                               the median for sample i

       Significance Level:  alpha
       Critical Region: T > CHSPPF(alpha,k-1)

                        where CHSPPF is the percent point function of the
                        chi-square distribution and k-1 is the degrees of
                        freedom
       Conclusion: Reject the independence hypothesis if the value of the
                   test statistic is greater than the chi-square value.

    Note that the chi-square critical value is a large sample
    approximation.  Conover recommends dropping all samples with
    only one observation from the analysis in order for the
    approximation to be valid.

Syntax 1:
    MEDIAN TEST <y> <x>      <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x> is the group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Syntax 2:
    MULTIPLE MEDIAN TEST <y1> ... <yk>  <SUBSET/EXCEPT/FOR qualification>
    where <y1> ... <yk> is a list of 2 to 30 response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax can be used when the data for each sample is in a
    separate variable.  This syntax supports the TO syntax for the
    variable list and also supports matrix arguments.

Examples:
    MEDIAN TEST Y X
    MULTIPLE MEDIAN TEST Y1 TO Y5

Note:
    This test is based on the following assumptions.

        1) Each sample is a random sample.
 
        2) The samples are independent of each other.

        3) The measurement scale is at least ordinal (i.e., the
           data can be ranked).

        4) If all populations have the same median, the all
           populations have the same probability of an observation
           exceeding the grand median.

Note:
    The following information is written to the file dpst1f.dat
    (in the current directory):

        Column 1   - group-id
        Column 2   - the number of observations above the median for
                     group k
        Column 3   - the total number of observations for group k

    In addition, the following internal parameters are saved

        STATVAL   = the value of the test statistic
        STATCDF   = the CDF of the test statistic
        PVALUE    = the p-value
        CUTOFF0   = the 0-th percentile of the reference chi-square
                    distribution
        CUTOFF50  = the 50-th percentile of the reference chi-square
                    distribution
        CUTOFF75  = the 75-th percentile of the reference chi-square
                    distribution
        CUTOFF90  = the 90-th percentile of the reference chi-square
                    distribution
        CUTOFF95  = the 95-th percentile of the reference chi-square
                    distribution
        CUTOF975  = the 97.5-th percentile of the reference chi-square
                    distribution
        CUTOFF99  = the 99-th percentile of the reference chi-square
                    distribution
        CUTOF999  = the 99.9-th percentile of the reference chi-square
                    distribution

Note:
    The following statistics are also supported:

        LET A = MEDIAN TEST         Y X
        LET A = MEDIAN TEST CDF     Y X
        LET A = MEDIAN TEST PVALUE  Y X

    Enter HELP STATISTICS to see what commands can use these
    statistics.

Note:
    Conover recomends the following procedure for performing
    multiple comparisons.

    If the median test indicates the medians are not all equal, you
    can determine which pairs of medians are not equal by performing
    the median test on each pairwise set of observations.  For
    example, you could do something like

        MULTIPLE MEDIAN TEST Y1 Y2 Y3 Y4
        MEDIAN TEST Y1 Y2
        MEDIAN TEST Y1 Y3
        MEDIAN TEST Y1 Y4
        MEDIAN TEST Y2 Y4
        MEDIAN TEST Y3 Y4

Note:
    Although this command is typically used to test for equal medians,
    you can also use it to test for other quantile values by entering
    the command

        SET MEDIAN TEST QUANTILE <value>

    where <value> is a quantile between 0 and 1.  The default value is
    0.5 (i.e., the median).

Default:
    None
 
Synonyms:
    None

Related Commands:
    MEDIAN CONFIDENCE LIMITS      = Compute confidence intervals for the
                                    median.
    CHI-SQUARE INDEPENDENCE TEST  = Perform a chi- test for independence.
    ODDS RATIO INDEPENDENCE TEST  = Perform a log(odds ratio) test for
                                    independence.
    FISHER EXACT TEST             = Perform Fisher's exact test.
    ASSOCIATION PLOT              = Generate an association plot.

Reference:
    Conover (1999), "Practical Nonparametric Statistics," Third Edition,
    Wiley, pp. 218-224.

Applications:
    Nonparameteric Analysis
 
Implementation Date:
    2011/5
 
Program 1:
    . Purpose: Test Median Test command
    .
    . Step 1: Read Data (example 1 from pp. 304-305 of Conover)
    .
    let y1 = data 10.8 11.1 10.4 10.1 11.3
    let y2 = data 10.8 10.5 11.0 10.9 10.8 10.7 10.8
    .
    let y x = stacked y1 y2
    set write decimals 4
    .
    .  Step 2: Check the statistic
    .
    let stat2 = median test         y x
    let cdf2  = median test cdf     y x
    let pval2 = median test pvalue  y x
    print stat2 cdf2 pval2
    .
    .  Step 3: Perform the median test
    .
    median test y x

Program 2:
    . Purpose: Test Median Test command
    .
    . Step 1: Read Data (example 1 from pp. 221 of Conover)
    .
    let y1 = data 83 91 94 89 89 96 91 92 90
    let y2 = data 91 90 81 83 84 83 88 91 89 84
    let y3 = data 101 100 91 93 96 95 94
    let y4 = data 78 82 81 77 79 81 80 81
    .
    set write decimals 4
    multiple median test y1 y2 y3 y4
.
-----MERGE (LET)---------------------------------------------------
 
MERGE
 
Name:
    MERGE (LET)
 
Type:
    Library Function
 
Purpose:
    Merge two values based on the value of a tag value.

Description:
    Given values Y1 and Y2 and a tag value TAG, the merged value
    is Y1 if TAG = 0 and Y2 if TAG = 1.

    Note that any value of TAG less than or equal to 0 will be
    treated as a 0 and any value of TAG that is greater than 0
    will be treated as a 1.

    There is an alternate version of this command (see Syntax 2) that
    selects one of three values depending on whether the value of
    TAG is negative, zero, or positive.
 
Syntax 1:
    LET <y> = MERGE(<y1>,<y2>,<tag>)   <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter;
          <tag> is a variable or a parameter;
          <y>  is a variable or a parameter (depending on what <y1>,
               <y2>, and <tag> are) where the computed merged values
               are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <y> = MERGE3(<y1>,<y2>,<y3>,<tag>)
              <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter;
          <y3> is a variable or a parameter;
          <tag> is a variable or a parameter;
          <y>  is a variable or a parameter (depending on what <y1>,
               <y2>, <y3>, and <tag> are) where the computed merged
               values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MERGE(14,10,1)
    LET A = MERGE(14,10,0)
    LET A = MERGE(A1,A2,TAG)
    LET X2 = MERGE(X1,X4,TAG)
    LET Y = MERGE3(X1,X2,X3,TAG)
 
Note:
    If more than one argument is a variable, the variables must
    be the same length.

 
Note:
    This command is distinct from the MERGE LET sub-command.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PERCDIF  = Compute the percent difference of two numbers.
    PERCERR  = Compute the percent error of two numbers.
    MIN      = Compute the minimum of two numbers.
    MAX      = Compute the maximum of two numbers.
    ABS      = Compute the absolute value of a number.
 
Applications:
    Data Management
 
Implementation Date:
    2010/12
 
Program:
    let y1 = sequence 1 1 20
    let y2 = sequence -1 -1 -20
    let y3 = 0 for i = 1 1 20
    let tag = sequence 0 1 1 for i = 1 1 20
    let tag2 = sequence -1 1 1 for i = 1 1 20
    .
    let yout = merge(y1,y2,tag)
    set write decimals 1
    print yout
    .
    let yout = merge3(y1,y2,y3,tag2)
    set write decimals 1
    print yout
 
MERGE
 
Name:
    MERGE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Merge two data sets.
 
Description:
    This command operates on two sets of data to generate a
    third merged set of data.

    For each of the two data sets, we define "match" variables
    and "carry" variables.  We assume that both sets of data have
    the same number of match and the same number of carry variables.

    The number of match variables is specified by entering the
    command (before the MERGE command)

        SET MERGE MATCH VARIABLES <value>

    The number of carry variables is specified by entering the
    command (before the MERGE command)

        SET MERGE CARRY VARIABLES <value>

    If these commands are not entered, the default is one
    match variable and one carry variable.  Currently, a maximum
    of three match variables and eight carry variables are allowed.

    The merge is performed as follows:

        1) Loop through data set one.  For each row, extract the
           values of the match variables for data set one.

        2) For a given row of data set one, loop through data
           set two and find all rows where the values of the
           data set two match variables are equal to the given
           row of data set one match variables.  These define
           "merged" rows.

        3) For each each "merged" row, we output the value
           of the match variables (which will be the same for
           data set one and data set two), then the values of
           the carry variables for data set one, and finally the
           values of the carry variables for data set two.

    Note that values of the "match" variables which exist for
    only one of the data sets are omitted in the merged data
    set.

Syntax:
    LET <mz1> ... <mzk> <cz1> ... <cz2l> = MERGE
                  <mx1> ... <mxk>  <cx1> ... <cxl>
                  <my1> ... <myk>  <cy1> ... <cyl>
                  <SUBSET/EXCEPT/FOR qualification>
    where <mx1> ... <mxk> are the k match variables for data set one;
          <cx1> ... <cxl> are the l carry variables for data set one;
          <my1> ... <myk> are the k match variables for data set two;
          <cy1> ... <cyl> are the l carry variables for data set two;
          <mz1> ... <mzk> are the k match variables for the merged data;
          <cz1> ... <cz2l> are the 2*l carry variables for the merged
                data;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If there are NMATCH match variables and NCARRY carry variables,
    then there will be NMATCH + 2*NCARRY variables to the left of
    the "=" and 2*(NMATCH + NCARRY) to the right of the "=".

Examples:
    SET MERGE MATCH VARIABLES 2
    SET MERGE CARRY VARIABLES 1
    LET INST SRC P  = MERGE INST1 SRC1 P1 INST2 SRC2 P2
    LET INST SRC P  = MERGE INST1 SRC1 P1 INST2 SRC2 P2  SUBSET INST1 > 2

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SORT         = Sort the elements of a variable.
    SORTC        = Sort the elements of a variable and carry one or
                   more variables along.
    CODE         = Generate a coded variable.
    SEQUENCE     = Generate a sequence of numbers.

Applications:
    Data Management
 
Implementation Date:
    2008/9
 
Program:
    DIMENSION 100 COLUMNS
    .  READ DATA SET 1  - 2 GROUP VARIABLES, A BINOMIAL PROPORTION AND
    .                     A CORREPSONDING SAMPLE SIZE
    READ INST1  SRC1  P1  N1
     1   1   0.81  40
     1   2   0.92  40
     1   3   0.62  50
     2   1   0.45  25
     2   2   0.98  25
     2   3   0.74  25
    END OF DATA
    .  READ DATA SET 2  - 2 GROUP VARIABLES, A BINOMIAL PROPORTION AND
    .                     A CORREPSONDING SAMPLE SIZE
    READ INST2  SRC2  P2  N2
     1   2    0.40  20
     2   2    0.32  20
     1   1    0.29  30
     2   1    0.18  30
     1   3    0.81  40
     2   3    0.66  40
    END OF DATA
    . NOW CREATE A MERGED DATA SET AND PERFORM A DIFFERENCE OF PROPORTIONS
    . HYPOTHSES TEST
    SET MERGE MATCH VARIABLES 2
    SET MERGE CARRY VARIABLES 2
    LET INST SRC X1 ZN1 X2 ZN2 = MERGE INST1 SRC1 P1 N1 INST2 SRC2 P2 N2
    LET ALPHA = 0.05
    FEEDBACK OFF
    SET WRITE FORMAT 2F5.0,2(F7.2,F5.0)
    PRINT INST SRC X1 ZN1 X2 ZN2
    LET PVAL = DIFFERENCE OF PROPORTION HYPOTHESIS TEST  X1 ZN1 X2 ZN2 ALPHA
    SET WRITE FORMAT
    SET WRITE DECIMALS 3
    PRINT PVAL
 
-----MESSAGE-------------------------------------------------------
 
MESSAGE
 
Name:
    MESSAGE
 
Type:
    Support Command
 
Purpose:
    Sends a message to the DATAPLOT service group.  This message is
    placed in a file which can be scanned periodically by members of
    the DATAPLOT service group.
 
Syntax:
    MESSAGE   <message>
 
Examples:
    MESSAGE HAVE MODELING QUESTION
    MESSAGE PLEASE CALL J. SMITH (EXT. 3862)
 
Note:
    This command is essentially obsolete since most operating systems
    have sophisticated electronic mail capabilities.
 
Default:
    None
 
Synonyms:
    QUERY
 
Related Commands:
    MAIL    = Lists the mail file.
    HELP    = Lists portions of the help file.
    NEWS    = Lists the news file.
    BUGS    = Lists the bugs file.
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----MIDMEAN (LET)-----------------------------------------
 
MIDMEAN
 
Name:
    MIDMEAN (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the midmean for a variable.
 
Description:
    The midmean of a variable is the mean of the observations between
    the 25th and 75th percentiles.  It is sometimes used instead of
    the mean because it is more resistant to outliers.
 
Syntax:
    LET <param> = MIDMEAN <y1> <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the response variable;
          <param> is a parameter where the computed midmean is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MIDMEAN Y1
    LET A = MIDMEAN Y1 SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MIDMEAN STATISTICS PLOT = Generate a midmean vs. subset plot.
    MEAN                    = Compute the mean.
    MEDIAN                  = Compute the median.
    STANDARD DEVIATION      = Compute the standard deviation.
 
Applications:
    Data Analysis
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET A1 = MIDMEAN Y1
 
-----MIDMEAN PLOT------------------------------------------------
 
MIDMEAN PLOT
 
Name:
    MIDMEAN PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a midmean plot.
 
Description:
    A midmean plot consists of subsample midmeans versus subsample
    index.  The subsample midmean is the mean of the middle 50% of the
    ordered data in the subsample.  The midmean plot is used to answer
    the question--"Does the subsample location change over different
    subsamples?"  The plot consists of:
       Vertical   axis = subsample midmean;
       Horizontal axis = subsample index.
    The midmean plot yields 2 traces:
       1. a subsample midmean trace; and
       2. a full-sample midmean reference line.
    Like usual, the appearance of these 2 traces is
    controlled by the first 2 settings of the LINES,
    CHARACTERS, SPIKES, BARS, and similar attributes.
 
Syntax:
    MIDMEAN PLOT   <y>   <x>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    MIDMEAN PLOT Y X
    MIDMEAN PLOT Y X1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    MEAN   PLOT             = Generates a mean plot.
    MEDIAN PLOT             = Generates a median plot.
    MIDRANGE PLOT           = Generates a midrange plot.
    TRIMMED MEAN PLOT       = Generates a trimmed mean plot.
    WINDSORIZED MEAN PLOT   = Generates a Windsorized mean plot
    SD   PLOT               = Generates a standard deviation plot.
    BOX PLOT                = Generates a box plot.
    XBAR CHART              = Generates an xbar control chart.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    LET Y = DATA 2 4 6 11 12 21 25 28 29
    LET X = DATA 1 1 1 2 2 3 3 3 3
    LINE BLANK DASH
    CHARACTER X BLANK
    XTIC OFFSET 0.2 0.2
    Y1LABEL MIDMEAN
    X1LABEL SAMPLE ID
    TITLE AUTOMATIC
    MIDMEAN PLOT Y X
 
-----MIDRANGE (LET)-----------------------------------------
 
MIDRANGE
 
Name:
    MIDRANGE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the sample midrange for a variable.
 
Description:
    The sample midrange of a variable is the mean of the sample minimum
    and the sample maximum (i.e., (minimum + maximum)/2.).
 
Syntax:
    LET <param> = MIDRANGE <y1> <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the response variable;
          <param> is a parameter where the computed midrange is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MIDRANGE Y1
    LET A = MIDRANGE Y1 SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MIDRANGE STATISTIC PLOT = Generate a midrange vs. subset plot.
    MEAN                    = Compute the mean.
    MEDIAN                  = Compute the median.
    STANDARD DEVIATION      = Compute the standard deviation.
 
Applications:
    Data Analysis
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET A1 = MIDRANGE Y1
 
-----MIDRANGE PLOT-----------------------------------------------
 
MIDRANGE PLOT
 
Name:
    MIDRANGE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a midrange plot.
 
Description:
    A midrange plot consists of subsample midranges The subsample
    midrange is the average of the middle 50% versus subsample index.
    The midrange plot is used to answer the question--"Does the
    subsample location change over different subsamples?"  The plot
    consists of:
       Vertical   axis = subsample midrange;
       Horizontal axis = subsample index.
    The midrange plot yields 2 traces:
       1. a subsample midrange trace; and
       2. a full-sample midrange reference line.
    Like usual, the appearance of these 2 traces is
    controlled by the first 2 settings of the LINES,
    CHARACTERS, SPIKES, BARS, and similar attributes.
 
Syntax:
    MIDRANGE PLOT   <y>   <x>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    MIDRANGE PLOT Y X
    MIDRANGE PLOT Y X1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    MEAN   PLOT             = Generates a mean plot.
    MEDIAN PLOT             = Generates a median plot.
    MIDMEAN PLOT            = Generates a midmean plot.
    TRIMMED MEAN PLOT       = Generates a trimmed mean plot.
    WINDSORIZED MEAN PLOT   = Generates a Windsorized mean plot
    SD   PLOT               = Generates a standard deviation plot.
    BOX PLOT                = Generates a box plot.
    XBAR CHART              = Generates an xbar control chart.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    LET Y = DATA 2 4 6 11 12 21 25 28 29
    LET X = DATA 1 1 1 2 2 3 3 3 3
    LINE BLANK DASH
    CHARACTER X BLANK
    XTIC OFFSET 0.2 0.2
    Y1LABEL MIDRANGE
    X1LABEL SAMPLE ID
    TITLE AUTOMATIC
    MIDRANGE PLOT Y X
 
-----MIECDF (LET)--------------------------------
 
MIECDF
 
Name:
    MIECDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Mielke's beta-kappa cumulative distribution function
    with shape parameters k and theta.
 
Description:
    The standard form of Mielke's beta-kappa distribution has the
    following cumulative distribution function:

       F(x;k,theta) = {x**theta/(1 + x**theta)}**(k/theta)
                      x > 0; k, theta > 0

    The Mielke's beta-kappa distribution can be generalized
    with location and shape parameters using the formula

       F(x;k,theta,loc,scale) = (1/scale)*F(x;k,theta,0,1)

Syntax:
    LET <y> = MIECDF(<x>,<k>,<theta>,<u>,<beta>)
                             <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <k> is a number, parameter, or variable that specifies the
              first shape parameter;
          <theta> is a number, parameter, or variable that specifies
              the second shape parameter;
          <u> is a number, parameter, or variable that specifies the
              location parameter;
          <beta> is a number, parameter, or variable that specifies
              the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Mielke's beta-kappa cdf value is
              stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The <u> and <beta> parameters are optional.

Examples:
    LET A = MIECDF(3,0.5,2,0,1.5)
    LET X2 = MIECDF(X1,K,THETA)

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MIEPDF = Compute Miekle's beta-kappa probability density
             function.
    MIEPPF = Compute Miekle's beta-kappa percent point function.
    KAPPDF = Compute the Kappa probability density function.
    BETPDF = Compute the beta probability density function.
    FPDF   = Compute the F probability density function.
    GAMPDF = Compute the gamma probability density function.
    NCBCDF = Compute the non-central beta cumulative distribution
             function.
    NORPDF = Compute the normal probability density function.
 
Reference:
    Hosking and Wallis (1997), "Regional Frequency Analysis",
    Cambridge University Press, Appendix A10.

    Johnson, Kotz, and Balakrishnan (1994), "Continuous Univariate
    Distributions: Volume 2", 2nd. Ed., John Wiley and Sons, p. 351.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1996/1: Original implementation as KAPCDF 
    2008/5: Renamed as MIECDF (KAPPDF now refers to regular Kappa
            distribution)
    2008/5: Beta parameter now properly treated as a scale
            parameter (was previously treated as a shape parameter)
 
Program:
    LET KP = DATA 0.5  1  1.5  2.0
    LET T1 = 0.5
    LET T2 = 1
    LET T3 = 1.5
    LET T4 = 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 95 95
    MULTIPLOT SCALE FACTOR 2
    TITLE CASE ASIS
    TITLE OFFSET 2
    X3LABEL
    LINE COLOR BLACK BLUE RED GREEN
    .
    LOOP FOR LL = 1 1 4
       LET K = KP(LL)
       TITLE K = ^K, Theta = 0.5, 1, 1.5, 2
       PLOT MIECDF(X,K,T1) FOR X = 0.01  0.01  5  AND
       PLOT MIECDF(X,K,T2) FOR X = 0.01  0.01  5  AND
       PLOT MIECDF(X,K,T3) FOR X = 0.01  0.01  5  AND
       PLOT MIECDF(X,K,T4) FOR X = 0.01  0.01  5
    END OF LOOP
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Mielke's Beta-Kappa CDF Functions
 
-----MIEPDF (LET)--------------------------------
 
MIEPDF
 
Name:
    MIEPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Mielke's beta-kappa probability density function
    with shape parameters k and theta.
 
Description:
    The general form of Mielke's beta-kappa distribution has the
    following probability density function:

       f(x;k,theta,u,beta) = (k/beta)*((x-u)/beta)**(k-1)/
                             [(1 + ((x-u)/beta)**theta)**(1 + k/theta)]
                             x > u; k, theta, beta > 0

    with k and theta denoting shape parameters and u and beta
    denoting the location and scale parameters, respectively.
 
    The standard form of the distribution is

       f(x;k,theta) = k*(x**(k-1)/[(1 + x**theta)**(1 + k/theta)]
                      x > 0; k, theta > 0

    Mielke's beta-kappa distribution is a special case of a
    reparameterized generalized F distribution of the form
    a*(F(v1,v2)**b).  The details of the reparameterization are
    given in Johnson, Kotz, and Balakrishnan.  This reference
    also discusses several forms of generalized F distributions.

    This distribution is also closely related to the Kappa
    distribution (see Hosking and Wallis for details).

Syntax:
    LET <y> = MIEPDF(<x>,<k>,<theta>,<u>,<beta>)
                             <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <k> is a number, parameter, or variable that specifies the
              first shape parameter;
          <theta> is a number, parameter, or variable that specifies
              the second shape parameter;
          <u> is a number, parameter, or variable that specifies the
              location parameter;
          <beta> is a number, parameter, or variable that specifies
              the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Mielke's beta-kappa pdf value is
              stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The <u> and <beta> parameters are optional.

Examples:
    LET A = MIEPDF(3,0.5,2,0,1.5)
    LET X2 = MIEPDF(X1,K,THETA)

Note:
    Mielke's beta-kappa random numbers, probability plots, and
    goodness of fit tests can be generated with the commands:

       LET K = <value>
       LET THETA = <value>
       LET Y = MIELKE BETA KAPPA RANDOM NUMBERS FOR I = 1 1 N
       MIELKE BETA KAPPA PROBABILITY PLOT Y
       MIELKE BETA KAPPA PROBABILITY PLOT Y2 X2
       MIELKE BETA KAPPA PROBABILITY PLOT Y3 XLOW XHIGH
       MIELKE BETA KAPPA KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       MIELKE BETA KAPPA CHI-SQUARE GOODNESS OF FIT Y2 X2
       MIELKE BETA KAPPA CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    The following commands can be used to estimate the k and theta
    shape parameter for the Mielke's beta-kappa distribution:

       LET K1 = <value>
       LET K2 = <value>
       LET THETA1 = <value>
       LET THETA2 = <value>
       MIELKE BETA KAPPA PPCC PLOT Y
       MIELKE BETA KAPPA PPCC PLOT Y2 X2
       MIELKE BETA KAPPA PPCC PLOT Y3 XLOW XHIGH
       MIELKE BETA KAPPA KS PLOT Y
       MIELKE BETA KAPPA KS PLOT Y2 X2
       MIELKE BETA KAPPA KS PLOT Y3 XLOW XHIGH

    The default values for K1 and K2 are 0.5 and 10, respectively.
    The default values for THETA1 and THETA2 are 0.5 and 10,
    respectively.

    The probability plot can then be used to estimate the
    location and scale (location = PPA0, scale = PPA1).

    The BOOTSTRAP DISTRIBUTION command can be used to find
    uncertainty intervals for the ppcc plot and the ks plot.
       
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MIECDF = Compute Miekle's beta-kappa cumulative distribution
             function.
    MIEPPF = Compute Miekle's beta-kappa percent point function.
    KAPPDF = Compute the Kappa probability density function.
    BETPDF = Compute the beta probability density function.
    FPDF   = Compute the F probability density function.
    GAMPDF = Compute the gamma probability density function.
    NCBCDF = Compute the non-central beta cumulative distribution
             function.
    NORPDF = Compute the normal probability density function.
 
Reference:
    Hosking and Wallis (1997), "Regional Frequency Analysis",
    Cambridge University Press, Appendix A10.

    Johnson, Kotz, and Balakrishnan (1994), "Continuous Univariate
    Distributions: Volume 2", 2nd. Ed., John Wiley and Sons, p. 351.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1996/1: Original implementation as KAPPDF 
    2008/5: Renamed as MIEPDF (KAPPDF now refers to regular Kappa
            distribution)
    2008/5: Beta parameter now properly treated as a scale
            parameter (was previously treated as a shape parameter)
 
Program 1:
    LET KP = DATA 0.5  1  1.5  2.0
    LET T1 = 0.5
    LET T2 = 1
    LET T3 = 1.5
    LET T4 = 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 95 95
    MULTIPLOT SCALE FACTOR 2
    TITLE CASE ASIS
    TITLE OFFSET 2
    X3LABEL
    LINE COLOR BLACK BLUE RED GREEN
    .
    LOOP FOR LL = 1 1 4
       LET K = KP(LL)
       TITLE K = ^K, Theta = 0.5, 1, 1.5, 2
       PLOT MIEPDF(X,K,T1) FOR X = 0.01  0.01  5  AND
       PLOT MIEPDF(X,K,T2) FOR X = 0.01  0.01  5  AND
       PLOT MIEPDF(X,K,T3) FOR X = 0.01  0.01  5  AND
       PLOT MIEPDF(X,K,T4) FOR X = 0.01  0.01  5
    END OF LOOP
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Mielke's Beta-Kappa PDF Functions
 
Program 2:
    let k = 1.8
    let theta = 1.2
    let ksav = k
    let thetasav = theta
    .
    let y = mielke beta-kappa rand numb for i = 1 1 200
    .
    let k1 = 0.5
    let k2 = 5
    let theta1 = 0.5
    let theta2 = 5
    .
    title automatic
    x3label
    mielke beta-kappa ppcc plot y
    just center
    move 50 6
    text K = ^shape1, Theta = ^shape2
    move 50 2
    text KSAV = ^ksav, THETASAV = ^thetasav
    .
    mielke beta-kappa ks plot y
    just center
    move 50 6
    text K = ^shape1, Theta = ^shape2
    move 50 2
    text KSAV = ^ksav, THETASAV = ^thetasav
    let k = shape1
    let theta = shape2
    .
    char x
    line blank
    mielke beta-kappa prob plot y
    just center
    move 50 6
    text PPA0 = ^ppa0, PPA1 = ^ppa1, PPCC = ^ppcc
    move 50 2
    text PPA0BW = ^ppa0bw, PPA1BW = ^ppa1bw
    line solid
    char blank
    .
    relative hist y
    let amin = minimum y
    let loc = max(ppa0bw,amin)
    let amax = maximum y
    title
    limits freeze
    pre-erase off
    plot miepdf(x,k,theta,loc,ppa1bw) for x = loc  0.01  amax
    limits
    pre-erase on
    .
    let ksloc = loc
    let ksscale = ppa1bw
    mielke beta kappa kolm smir goodness of fit y

-----MIEPPF (LET)--------------------------------
 
MIEPPF
 
Name:
    MIEPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Mielke's beta-kappa percent point function with
    shape parameters k and theta.
 
Description:
    The standard form of Mielke's beta-kappa distribution has the
    following percent point function:

       G(p;k.theta) = [p**(theta/k)/(1-p**(theta/k))]**(1/theta)
                      0 < p < 1; k, theta > 0

    The Mielke's beta-kappa distribution can be generalized
    with location and shape parameters using the formula

       G(p;k,theta,loc,scale) = loc + scale)*G(p;k,theta,0,1)

Syntax:
    LET <y> = MIEPPF(<p>,<k>,<theta>,<u>,<beta>)
                             <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the range [0,1];
          <k> is a number, parameter, or variable that specifies the
              first shape parameter;
          <theta> is a number, parameter, or variable that specifies
              the second shape parameter;
          <u> is a number, parameter, or variable that specifies the
              location parameter;
          <beta> is a number, parameter, or variable that specifies
              the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed Mielke's beta-kappa ppf value is
              stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The <u> and <beta> parameters are optional.

Examples:
    LET A = MIEPPF(0.95,0.5,2,0,1.5)
    LET X2 = MIEPPF(P1,K,THETA)

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MIECDF = Compute Miekle's beta-kappa cumulative distribution
             function.
    MIEPDF = Compute Miekle's beta-kappa probability density
             function.
    KAPPDF = Compute the Kappa probability density function.
    BETPDF = Compute the beta probability density function.
    FPDF   = Compute the F probability density function.
    GAMPDF = Compute the gamma probability density function.
    NCBCDF = Compute the non-central beta cumulative distribution
             function.
    NORPDF = Compute the normal probability density function.
 
Reference:
    Hosking and Wallis (1997), "Regional Frequency Analysis",
    Cambridge University Press, Appendix A10.

    Johnson, Kotz, and Balakrishnan (1994), "Continuous Univariate
    Distributions: Volume 2", 2nd. Ed., John Wiley and Sons, p. 351.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1996/1: Original implementation as KAPPPF 
    2008/5: Renamed as MIEPPF (KAPPPF now refers to regular Kappa
            distribution)
    2008/5: Beta parameter now properly treated as a scale
            parameter (was previously treated as a shape parameter)
 
Program:
    LET KP = DATA 0.5  1  1.5  2.0
    LET T1 = 0.5
    LET T2 = 1
    LET T3 = 1.5
    LET T4 = 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 95 95
    MULTIPLOT SCALE FACTOR 2
    TITLE CASE ASIS
    TITLE OFFSET 2
    X3LABEL
    LINE COLOR BLACK BLUE RED GREEN
    .
    LOOP FOR LL = 1 1 4
       LET K = KP(LL)
       TITLE K = ^K, Theta = 0.5, 1, 1.5, 2
       PLOT MIEPPF(P,K,T1) FOR P = 0.01  0.01  0.99  AND
       PLOT MIEPPF(P,K,T2) FOR P = 0.01  0.01  0.99  AND
       PLOT MIEPPF(P,K,T3) FOR P = 0.01  0.01  0.99  AND
       PLOT MIEPPF(P,K,T4) FOR P = 0.01  0.01  0.99
    END OF LOOP
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Mielke's Beta-Kappa PPF Functions
 
-----MIN (LET)--------------------------------
 
MIN
 
Name:
    MIN (LET)
 
Type:
    Library Function
 
Purpose:
    Return the minimum of 2 to 8 numbers.
 
Syntax:
    LET <yout> = MIN(<y1>, ..., <yk>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1>, ..., <yk> is a list of two to eight variables, parameters
               or number(s);
          <yout> is a variable or a parameter (depending on what <y1>
               ... <yk> are) where the computed maximum values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MIN(14,10)
    LET A = MIN(A1,A2)
    LET A = MIN(A1,A2,A3,A4)
    LET X2 = MIN(X1,X4)
    LET X2 = MIN(X1-4,X2+6)
 
Note:
    This function is distinct from the LET subcommand MINIMUM.  This
    command compares two through eight parameters (or a comparison of
    the corresponding elements in two through eight variables) while
    MINIMUM returns the smallest value in a single variable.
 
Note:
    The 2010/12 version of Dataplot now accepts up to eight input
    arguments.  For example,

        LET AMIN = MIN(A1,A2,A3,A4,A5,A6,A7,A8)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MAX      = Compute the maximum of two to eight numbers.
    MAXIMUM  = Compute the maximum value in a variable.
    MINIMUM  = Compute the minimum value in a variable.
    ABS      = Compute the absolute value of a number.
 
Applications:
    Data Management
 
Implementation Date:
    Pre-1987
    2010/12: Added support for more than two arguments.
 
Program:
    LET X = SEQUENCE 0 .1 3
    LET Y1 = X**2
    LET Y2 = X**(1/2)
    LET Y3 = MIN(Y1,Y2)
    PRINT Y1 Y2 Y3
 
-----MINIMUM-------------------------------------------------------
 
MINIMUM
 
Name:
    ...MINIMUM
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the minimum value to appear on the plot axes of
    subsequent plots.
 
Description:
    For most data analysis applications, the analyst need not bother
    with the MINIMUM command since DATAPLOT generates neat limits based
    on the data.  If the default limits are not acceptable, then the
    analyst can make use of the MINIMUM, MAXIMUM, or LIMITS commands to
    specify the minimum, maximum, or both, respectively.
 
Syntax:
    <prefix>MINIMUM   <n>
    where <n> is a number or parameter that specifies the desired lower
              limit;
    and   <prefix> is one of the following:
              X             refers to vertical axis
              Y             refers to horizontal axis
              no prefix     refers to both axes.
 
Examples:
    MINIMUM 4.5
    XMINIMUM 100
    YMINIMUM 100
    XMINIMUM A
 
Note:
    The ...MINIMUM command with no argument reverts the minima to the
    default.  A ...MINIMUM command with no prefix refers to both axes.
    Thus MINIMUM 3 sets the minima for both axes to 3.
 
Default:
    Automatically computed neat minima based on the data.
 
Synonyms:
    MIN
 
Related Commands:
    PLOT        = Generates a data or function plot.
    LIMITS      = Sets the frame limits for all plots.
    MAXIMUM     = Sets the frame maxima for all plots.
    CLASS UPPER = Sets the upper class maximum for histograms,
                  frequency plots, and pie charts.
    CLASS LOWER = Sets the lower class minimum for histograms,
                  frequency plots, and pie charts.
    CLASS LOWER = Sets the class width for histograms, frequency plots,
                  and pie charts.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE MINIMUM COMMAND
    X1LABEL LEAD
    Y1LABEL POTASSIUM
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    .
    XMINIMUM 50
    XTIC OFFSET 10
    YMINIMUM 50
    .
    PLOT POT VS LEAD
 
 
 
Name:
    MINIMUM (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the minimum value in a variable.
 
Syntax:
    LET <param> = MINIMUM <resp>   <SUBSET/EXCEPT/FOR qualification>
    where <resp> is the variable for which the minimum is to be
                 computed;
          <param> is a parameter where the minimum value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A1 = MINIMUM Y1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MAXIMUM   = Compute the maximum of a variable.
    MEAN      = Compute the mean of a variable.
    MAX       = Library function to compute the maximum of 2 numbers.
    MIN       = Library function to compute the minimum of 2 numbers.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET A = MINIMUM Y1
 
-----MINIMUM PLOT------------------------------------------------
 
MINIMUM PLOT
 
Name:
    MINIMUM PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a minimum plot.
 
Description:
    A minimum plot consists of subsample minima versus subsample index.
    The subsample minimum is the smallest data value in the subsample.
    The minimum plot is used to answer the question--"Does the
    subsample variation change over different subsamples?"  The plot
    consists of:
       Vertical   axis = subsample minimum;
       Horizontal axis = subsample index.
    The minimum plot yields 2 traces:
       1. a subsample minimum trace; and
       2. a full-sample minimum reference line.
    Like usual, the appearance of these 2 traces is
    controlled by the first 2 settings of the LINES,
    CHARACTERS, SPIKES, BARS, and similar attributes.
 
Syntax:
    MINIMUM PLOT   <y>   <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    MINIMUM PLOT Y X
    MINIMUM PLOT Y X1
 
Default:
    None
 
Synonyms:
    MIN PLOT
 
Related Commands:
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    MAXIMUM  PLOT           = Generates a maximum plot.
    RANGE  PLOT             = Generates a range plot.
    MAXIMUM  PLOT           = Generates a lower quartile plot.
    UPPER QUARTILE  PLOT    = Generates a upper quartile plot.
    LOWER HINGE  PLOT       = Generates a lower hinge plot.
    UPPER HINGE  PLOT       = Generates a upper hinge plot.
    FIRST DECILE  PLOT      = Generates a first decile plot.
    SECOND DECILE  PLOT     = Generates a second decile plot.
    NINTH DECILE  PLOT      = Generates a ninth decile plot.
    STANDARD DEVIATION PLOT = Generates a stand deviation plot.
    VARIANCE  PLOT          = Generates a variance plot.
    MEAN PLOT               = Generates a mean plot.
    MEDIAN PLOT             = Generates a median plot.
    BOX PLOT                = Generates a box plot.
    RANGE CHART             = Generates a maximum control chart.
    S CHART                 = Generates a standard deviation control
                              chart.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    LET Y = DATA 2 4 6 11 12 21 25 28 29
    LET X = DATA 1 1 1 2 2 3 3 3 3
    LINE BLANK DASH
    CHARACTER X BLANK
    XTIC OFFSET 0.2 0.2
    Y1LABEL MINIMUM
    X1LABEL SAMPLE ID
    TITLE AUTOMATIC
    MINIMUM PLOT Y X
 
-----MINIMUM SPANNING TREE----------------------------------------
 
MINIMUM SPANNING TREE
 
Name:
    MINIMUM SPANNING TREE
 
Type:
    LET Subcommand
 
Purpose:
    Compute the minimum spanning tree of either a set of vertices
    or a distance matrix.
 
Description:
    A spanning tree of a connected, undirected graph is a subgraph
    which is a tree that connects all the vertices together.  A
    graph can more than one spanning tree.  Distances are defined
    for each edge in the graph (alternatively, edges could be
    represented by weights or costs).
    the edges 

    The minimum spanning tree is the spanning tree for which
    the sum of the distances over the edges in the spanning
    tree is a minimum.

    Dataplot supports two forms of the minimum spanning tree.

       1) The input is a set of x and y coordinates for the
          vertices in the graph.  In this case, the distance
          between two vertices is simply the Euclidean distance
          between the vertices.

      2) The input is a distance matrix.  In this case, the
         distance can denote a weight or a cost instead of a
         distance.

Syntax 1:
    LET <y2> <x2> <tag> = MINIMUM SPANNING TREE  <y>  <x>
                  <SUBSET/EXPCEPT/FOR qualification>
    where <y> is a variable containing the y-coordinates of
               the full data set;
          <x> is a variable containing the x-coordinates of
               the full data set;
          <y2> is a variable that will contain the y-coordinats
               of the returned minimum spanning tree;
          <x2> is a variable that will contain the x-coordinats
               of the returned minimum spanning tree;
          <tag> is a variable that will contain a trace-id
               (i.e., points that will be connected) of the
               returned minimum spanning tree;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <edge1> <edge2> = MINIMUM SPANNING TREE  <dist>
                  <SUBSET/EXPCEPT/FOR qualification>
    where <dist> is a matrix containing the distances (or weights
               or costs);
          <edge1> is a variable that will contain the first vertex
               of the edges in the mimimum spanning tree;
          <edge2> is a variable that will contain the second vertex
               of the edges in the mimimum spanning tree;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET Y2 X2 TAG = MINIMUM SPANNING TREE Y X
    LET EDGE1 EDGE2 =  MINIMUM SPANNING TREE DIST
 
Note:
    Dataplot uses the MINSPT algorithm given in Nijenhuis and
    Wilf (see the Reference section below).

Default:
    None.
 
Synonyms:
    None
 
Related Commands:
    MATRIX DISTANCE    = Compute a distance matrix.
    2D CONVEX HULL     = Compute the 2D convex hull of a set of
                         vertices.
    SPANNING FOREST    = Determine the spanning forest.
    NEXT PERMUTATION   = Generate the next permutation of a positive
                         integer.
    RANDOM PERMUTATION = Generate a random permutation of a positive
                         integer.
 
References:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 30.

Applications:
    Graph Theory
 
Implementation Date:
    2008/4
 
Program 1:
    read matrix d
      0  100  125  120  110
    100    0   40   65   60
    125   40    0   45   55
    120   65   45    0   50
    110   60   55   50    0
    end of data
    .
    let y2 x2 = minimum spanning tree d
    set write decimals 1
    print y2 x2
  
Program 2:
    skip 1
    read convex_hull.dat x y
    .
    let y2 x2 tag = minimum spanning tree y x
    .
    title case asis
    title offset 2
    title Minimum Spanning Tree
    y1label Y
    x1label X
    tic offset units screen
    tic offset 3 3
    x3label
    .
    plot y2 x2 tag
  
-----MINKOWSKI DISTANCE (LET)-------------------------------------

MINKOWSKI DISTANCE

Name:
    MINKOWSKI DISTANCE (LET)

Type:
    Let Subcommand

Purpose:
    Compute the Minkowski distance between two variables.

Description:
    The Minkowski distance between two variabes X and Y is
    defined as

        d = {SUM[i=1 to N][(ABS|(X(i) - X(k))|**P]}**(1/P)

    The case where P = 1 is equivalent to the Manhattan distance and
    the case where P = 2 is equivalent to the Euclidean distance.

    Although P can be any real value, it is typically set to a value
    between 1 and 2.  For values of P less than 1, the formula
    above does not define a valid distance metric since the
    triange inequality is not satisfied.

    The value of P is specified by entering the command

        LET P = <value>

    before entering the MINKOWSKI DISTANCE command.  If P is not
    specified, a default value of P = 1 will be used.

Syntax:
    LET <par> = MINKOWSKI DISTANCE <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed Minkowski distance
              is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET P = 1
    LET A = MINKOWSKI DISTANCE Y1 Y2
    LET A = MINKOWSKI DISTANCE Y1 Y2  SUBSET Y1 > 0 SUBSET Y2 > 0

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    COSINE DISTANCE         = Compute the cosine distance.
    MANHATTAN DISTANCE      = Compute the Euclidean distance.
    EUCLIDEAN DISTANCE      = Compute the Euclidean distance.
    CHEBYSHEV DISTANCE      = Compute the Chebyshev distance.
    MATRIX DISTANCE         = Compute various distance metrics for
                              a matrix.
    GENERATE MATRIX <stat>  = Compute a matrix of pairwise statistic
                              values.

Applications:
    Mathematics
 
Implementation Date:
    2017/08
 
Program 1:
    SKIP 25
    READ IRIS.DAT Y1 TO Y4 X
    LET P = 1.5
    .
    LET DIST  = MINKOWSKI DISTANCE Y1 Y2
    SET WRITE DECIMALS 4
    TABULATE MINKOWSKI DISTANCE Y1 Y2 X
    .
    XTIC OFFSET 0.2 0.2
    X1LABEL GROUP ID
    LET NDIST = UNIQUE X
    XLIMITS 1 NDIST
    MAJOR X1TIC MARK NUMBER NDIST
    MINOR X1TIC MARK NUMBER 0
    CHAR X
    LINE BLANK
    LABEL CASE ASIS
    CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    TITLE Minkowski Distance with P = 1.5 (IRIS.DAT)
    Y1LABEL Minkowski Distance
    MINKOWSKI DISTANCE PLOT Y1 Y2 X
 
Program 2:
    set write decimals 3
    dimension 100 columns
    .
    skip 25
    read iris.dat y1 y2 y3 y4
    skip 0
    .
    let p = 1.5
    let z = generate matrix minkowski distance y1 y2 y3 y4
    print z

-----MINMAX (SET)--------------------------------------------
 
MINMAX
 
Name:
    MINMAX (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify whether extreme value distributions are based on the
    minimum order statistic or the maximum order statistic.
 
Description:
    The Weibull, Extreme Value Type I (or Gumbel), and Extreme Value
    II (or Frechet) distributions are used to model extreme values.
    Extreme value analysis can be based on either the minimum order
    statistic or the maximum order statistic.  The distributions of the
    minimum and maximum based distributions have similar shapes, but
    are mirror images of each other.
 
    This SET command output affects the output of:
         <WEIBULL/GUMBEL/FRECHET> PROBABILITY PLOT
         <WEIBULL/FRECHET> PPCC PLOT
         <WEIBULL/FRECHET> KS PLOT
         <WEIBULL/GUMBEL/FRECHET> RANDOM NUMBERS
    
         WEICDF, WEIPDF, WEIPPF, WEIHAZ, WEICHAZ
         EV1CDF, EV1PDF, EV1PPF, EV1HAZ, EV1CHAZ
         EV2CDF, EV2PDF, EV2PPF, EV2HAZ, EV2CHAZ
 
Syntax:
    SET MINMAX <MIN/MAX>
    where MIN specifies that the distribution is based on the minimum
              order statistic while MAX specifies that it is based on
              the maximum order statistic.
 
    The value 1 is equivalent to MIN and the value 2 is equivalent
    to MAX.

Examples:
    SET MINMAX MIN
    SET MINMAX MAX
    SET MINMAX 1
    SET MINMAX 2
 
Note:
    The 5/2005 version extended support for the MINMAX option
    to the generalized extreme value distribution.

Note:
    For the Weibull distribution, the standard case is generally
    considered to be "minimum" form.  However, for the Gumbel,
    Frechet, and generalized extreme value distributions, the
    standard case is generally considered to be the "maximum"
    form.

    The 5/2005 version added a "0" choice (which is now the
    default).  If MINMAX is set to 0, Dataplot will select a
    distribution-specific default.  This default is MIN for the
    Weibull distribution and MAX for the other distributions.

    
Default:
    The distributions are based on the minimum order statistic.
 
Synonyms:
    SET MINMAX 1 is a synonym for SET MINMAX MIN.
    SET MINMAX 2 is a synonym for SET MINMAX MAX.
 
Related Commands:
    RANDOM NUMBERS (LET)  = Generate random numbers.
    PPCC PLOT             = Generate a probability plot correlation
                            coefficient plot.
    PROBABILITY PLOT      = Generate a probability plot.
 
References:
    "Contributions to Order Statistics", Sarhan and Greenburg, John
    Wiley, 1962 (page 69).
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1993/8
    2005/5: Extended to include the generalized extreme value
            distribution
    2005/5: Added support for "0" to set a distribution-specific
            default
 
Program:
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE AUTOMATIC
    LEGEND 1 MINMAX = 1
    SET MINMAX 1
    PLOT WEIPDF(X,2) FOR X = 0.01 0.01 3
    PLOT WEIPDF(X,0.5) FOR X = 0.05 0.01 2
    SET MINMAX 2
    LEGEND 1 MINMAX = 2
    PLOT WEIPDF(X,2) FOR X = 0.01 0.01 3
    PLOT WEIPDF(X,0.5) FOR X = 0.05 0.01 2
    END OF MULTIPLOT
 
-----MINOR TIC MARK NUMBER---------------------------------------------
 
MINOR TIC MARK NUMBER
 
Name:
    MINOR ...TIC MARK NUMBER
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the number of minor tic marks to appear between major tic
    marks on an axis.
 
Description:
    DATAPLOT can automatically scale the axis and select an appropriate
    number of major and minor tic marks.  However, it is sometimes
    desirable to override the default choice and to specify the number
    of minor tic marks directly.
 
Syntax:
    <prefix>MINOR TIC MARK NUMBER  <value>
    where
            no prefix     refers to all 4 sides;
            the prefix X  refers to both horizontal sides;
            the prefix Y  refers to both vertical sides;
            the prefix X1 refers to the lower horizontal side;
            the prefix X2 refers to the upper horizontal side;
            the prefix Y1 refers to the left  vertical   side;
            the prefix Y2 refers to the right vertical   side;
    and <value> is an integer number or parameter that specifies the
            desired number of minor tic marks.
 
Examples:
    MINOR TIC MARK NUMBER 5
    MINOR XTIC MARK NUMBER 6
    MINOR YTIC MARK NUMBER 4
    MINOR TIC MARK NUMBER
 
Note:
    A ...MINOR TIC MARK NUMBER command with no arguments reverts the
    setting to default; thus X1MINOR TIC MARK NUMBER with no arguments
    reverts the bottom horizontal tic labels to on.  A ...TIC
    MARK LABEL command with no prefix refers to all 4 sides; thus
    MINOR TIC MARK NUMBER OFF suppresses tic mark label for all 4 frame
    lines.  Note also that MINOR TIC MARK NUMBER with no prefix and no
    arguments reverts the tic label settings on all 4 sides to
    default.
 
Default:
    DATAPLOT selects an appropriate number of tic marks.
 
Synonyms:
    MINOR TIC NUMBER is a synonym for MAJOR TIC MARK NUMBER, as in
    MINOR TIC NUMBER 6.
 
Related Commands:
    MAJOR TIC MARK NUMB = Specifies the number of major tic mark
                          numbers to appear on an axis.
    LIMITS              = Specifies the axis minimum and maximum
                          values.
    TIC MARK            = Specifies whether or not tics are drawn.
    TIC MARK OFFSET     = Sets the offset for the first and last tic
                           marks.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    .
    TITLE DEMONSTRATE MINOR TICS COMMAND
    X1LABEL LEAD
    Y1LABEL POTASSIUM
    CHARACTER CIRCLE
    CHARACTER SIZE 1.5
    LINE BLANK ALL
    .
    XLIMITS 0 600; XTIC OFFSET 0 15
    MAJOR XTIC MARK NUMBER 7
    MINOR XTIC MARK NUMBER 4
    YLIMITS 100 400; YTIC OFFSET 50 50
    MAJOR YTIC MARK NUMBER 4
    MINOR YTIC MARK NUMBER 4
    .
    PLOT LEAD VS POTASSIUM
 
-----MKDIR---------------------------------------------------
 
MKDIR
 
Name:
    MKDIR
 
Type:
    Support Command
 
Purpose:
    This command creates a new directory.
 
Description:
    This command uses an operating system command to create
    a new directory.

    For Unix/Linux/MacOS systems, the MKDIR command issues a

        mkdir ....

    command to the operating system.

    For Windows systems, the MKDIR command issues an

        MKDIR ....

    command to the operating system.

    The string that follows the MKDIR on the command line
    is passed to the operating system as is.  Dataplot does no
    error checking of this string.

    This is a system dependent command.  It is currently supported
    for Unix/Linux/MacOS and Windows platforms.

Syntax:
    MKDIR <file-list>
    where <file-list> is a string containing a list of one or more
               directories to create.

Examples:
    MKDIR  macros
    MKDIR  tmp
    MKDIR  macros tmp
 
Note:
    The MKDIR capability can be implemented by direct use of the
    SYSTEM command.  For example, under Linux do something like

         system  mkdir  macros

    The motivation for adding this as a separate command is to
    allow the capability to be implemented in an operating
    system independent way.  This can be useful when writing
    general purpose macros that may be used on different
    operating systems.

Default:
    None
 
Synonyms:
    None
 
Note:
    Dataplot does no checking to ensure that a valid directory
    name was specified.  The entered string is passed to the
    operating system as entered.

Note:
    File names are case sensitive on Unix/Linux/MacOS file
    systems.  For this reason, case is preserved in passing the
    directory name to the operating system.
 
Related Commands:
    SYSTEM      = Enter an operating system command within a
                  Dataplot session.
    CD          = Change the current working directory.
    PWD         = Retrieve the current working directory.
    CAT         = List the contents of a file.
    RM          = Delete one or more files.
    DIR         = List the contents of a directory.
 
Applications:
    Interactive Usage
 
Implementation Date:
    2019/09
 
Program:
    SKIP 25
    READ BERGER1.DAT Y X
    .
    MKDIR PLOT_FILES
    SET POSTSCRIPT CONVERT PDF
    SET IPL1NA PLOT_FILES/PLOT.PS
    .
    CHARACTER X
    LINE BLANK
    PLOT Y X
 
-----MOD (LET)--------------------------------
 
MOD
 
Name:
    MOD (LET)
 
Type:
    Library Function
 
Purpose:
    Computes the mod function of a number.
 
Description:
    The mod function returns the remainder of the first number divided
    by the second number.  Mod functions are used with integer values.
 
Syntax:
    LET <y3> = MOD(<y1>,<y2>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter containing integer
               number(s);
          <y2> is a variable or a parameter containing integer
               number(s);
          <y3> is a variable or a parameter (depending on what <y1> and
               <y2> are) where the computed mod function values are
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MOD(14,10)
    LET A = MOD(A1,A2)
    LET X2 = MOD(X1,X4)
    LET X2 = MOD(X1-4,X2+6)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    OCTDEC = Perform an octal to decimal conversion of a number.
    MIN    = Compute the minimum of two numbers.
    INT    = Compute the integer portion of number.
    FRACT  = Compute the fractional portion of number.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET Y1 = DATA 10 12 34 54 23 12 5 4 6
    LET N = SIZE Y1
    LET Y2 = 2 FOR I = 1 1 N
    LET Y3 = MOD(Y1,Y2)
    PRINT Y1 Y2 Y3
 
-----MOOD SCORE (LET)-----------------------------------------------
 
MOOD SCORE
 
Name:
    MOOD SCORE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the Mood scores of a variable.
 
Description:
    The Mood scores are defined as

        s(R(j)) = (R(j) - (n+1)/2)**2

    where R(j) is the rank of the j-th observation and n is the number
    of observations.  That is, Mood scores are the square of the
    difference between the observation rank and the average rank.

Syntax:
    LET <s> = MOOD SCORE <y>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <s> is a variable where the computed Mood scores are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET MOODSCOR = MOOD SCORE Y
 
Note:
    Ties are assigned an average rank.  For example, if the 2nd and 3rd
    highest values are equal, each is assigned a rank of 2.5.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MEDIAN TEST             = Perform a median test.
    ANOVA                   = Perform a fixed effects analysis of variance.
    MEDIAN SCORES           = Generate median scores.
    VAN DER WAERDEN SCORES  = Generate Van Der Waerden scores.
    SAVAGE SCORES           = Generate Savage scores.
    KLOTZ SCORES            = Generate Klotz scores.
    CONOVER SCORES          = Generate Conover scores.
    ANSARI BRADLEY SCORES   = Generate Ansari Bradley scores.
    PLACEMENT SCORES        = Generate placement scores.
    RANK                    = Generate the ranks of a variable. 
 
Reference:
    Bradley (1968), "Distribution-Free Statistical Tests,"
    Prentice Hall, p. 122.

    Mood (1954), "On the Asymptotic Efficiency of Certain
    Nonparametric Two-Sample Tests," Annals of Mathematical
    Statistics, Vol. 25, pp. 514-522.

Applications:
    Nonparametric statistics
 
Implementation Date:
    2023/06
 
Program:
    . Step 1:   Define the data
    .
    let y1 = data 16.55 15.36 15.94 16.43 16.01
    let y2 = data 16.05 15.98 16.10 15.88 15.91
    let n1 = size y1
    let n2 = size y2
    let n = n1 + n2
    .
    . Step 2:   Combine into single array
    .
    let y tag = stack y1 y2
    if n1 <= n2
       let tag = tag - 1
       let n1t = n1
    else
       let tag = 0 subset tag = 2
       let n1t = n2
    end of if
    .
    . Step 3:   Compute the Mood scores
    .
    let ymood = mood scores y
    .
    . Step 4:   Two-Sample Linear Rank Test
    .
    let temp = tag*ymood
    let s = sum temp
    .
    let aval = sum ymood
    let smean = (n1t/n)*aval
    let meanrank = mean ymood
    let temp = (ymood - meanrank)**2
    let aval = sum temp
    let svar = ((n1*n2)/(n*(n-1)))*aval
    let statval = (s - smean)/sqrt(svar)
    let statval = round(statval,3)
    let cv = norppf(0.975)
    let upplim = round(cv,2)
    let lowlim = -upplim
    feedback off
    print "Two Sample Linear Rank Sum Test Based on Mood Scores"
    print "H0: Scales are Equal"
    print "Ha: Scales are Not Equal"
    print "alpha: 0.05"
    print "Test Statistic: ^statval"
    print "Lower Critical Value: ^lowlim"
    print "Upper Critical Value: ^upplim"
    if statval < cv
       print "Conclusion: Accept H0"
    else
       print "Conclusion: Reject H0"
    end of if
 
-----MOVE-------------------------------------------------------
 
MOVE
 
Name:
    MOVE
 
Type:
    Diagrammatics Command
 
Purpose:
    Moves to a position on the screen.
 
Description:
    The coordinates define the (x,y) value of the position to be moved
    to.  This command is usually used prior to a TEXT command to
    position the text string.
 
Syntax:
    MOVE   <x>   <y>
    where <x> is a number or parameter in the decimal range 0 to 100
              that specifies the desired horizontal coordinate;
    and   <y> is a number or parameter in the decimal range 0 to 100
              that specifies the desired vertical coordinate.
 
Examples:
    MOVE 50 50
    MOVE 20 80
    MOVE 70 65.3
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    TEXT             = Writes a text string.
    MOVEDATA         = Move in the units of the most recent plot.
    DRAW             = Draws a line.
    POINT            = Draws a point.
    ARROW            = Draws an arrow.
    TRIANGLE         = Draws a triangle.
    BOX              = Draws a box.
    HEXAGON          = Draws a hexagon.
    CIRCLE           = Draws a circle.
    SEMI-CIRCLE      = Draws a semi-circle.
    ARC              = Draws an arc.
    ELLIPSE          = Draws an ellipse.
    OVAL             = Draws an oval.
    DIAMOND          = Draws a diamond.
    DIAMOND          = Draws a diamond.
    AMPLIFIER        = Draws an amplifier.
    CAPACITOR        = Draws a capacitor.
    GROUND           = Draws a ground.
    INDUCTOR         = Draws an inductor.
    RESISTOR         = Draws a resistor.
    AND              = Draws an and gate.
    OR               = Draws an or gate.
    NAND             = Draws a nand gate.
    NOR              = Draws a nand gate.
    CROSS-HAIR       = Activates and reads the cross-hair.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    FONT DUPLEX
    .
    HEIGHT 4
    MOVE 5 95
    TEXT JAPAN's 6-POINT PROGRAM FOR
    MOVE 5 89
    TEXT QUALITY MANUFACTURING
    MOVE 10 80
    HEIGHT 2.2
    TEXT CIRC() QUALITY AUDITS
    MOVE 10 74
    TEXT CIRC() COMPANY-WIDE QUALITY CONTROL (CWQC)
    MOVE 10 68
    TEXT CIRC() QUALITY TRAINING AND EDUCATION
    MOVE 10 62
    TEXT CIRC() APPLICATION OF STATISTICAL METHODS
    MOVE 10 56
    TEXT CIRC() QUALITY CIRCLE ACTIVITIES
    MOVE 10 50
    TEXT CIRC() NATION-WIDE QUALITY CONTROL PROMOTIONAL ACTIVITIES
    HEIGHT 2
    MOVE 5 10
    TEXT SOURCE: Q.C. TRENDS WINTER 1985, PAGES 22-23.
 
-----MOVEDATA-------------------------------------------------------
 
MOVEDATA
 
Name:
    MOVEDATA
 
Type:
    Diagrammatics Command
 
Purpose:
    Moves to a position on the screen in units of the most recent plot.
 
Description:
   The coordinates define the (x,y) value of the position to be moved
   to.  These coordinates are in units of the most recent plot (as
   opposed to the 0 to 100 units of the standard MOVE command).  This
   command is usually used in conjunction with the TEXT command to
   label points or bars on a plot.
 
Syntax:
    MOVEDATA   <x>   <y>
    where <x> is a number or parameter in units of the most recent plot
              that specifies the desired horizontal coordinate;
    and   <y> is a number or parameter in units of the most recent plot
              that specifies the desired vertical coordinate.
 
Examples:
    MOVEDATA 123 56
    MOVEDATA 0.5 0.2
    MOVEDATA 6 2345
 
Note:
    The may occassionally be cases where you want one coordinate
    to be in data units and the other coordinate to be in
    screen (i.e., 0 to 100) units.  Use the syntax

      MOVESD  - x-coordinate is screen units, y-coordinate is
                data units
      MOVEDS  - y-coordinate is data units, x-coordinate is
                screen units.

    Although you can use MOVESS and MOVEDD as well, these
    simply correspond to using MOVE and MOVEDATA respectively.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MOVE             = Move to a point.
    TEXT             = Writes a text string.
    DRAW             = Draws a line.
    POINT            = Draws a point.
    ARROW            = Draws an arrow.
    TRIANGLE         = Draws a triangle.
    BOX              = Draws a box.
    HEXAGON          = Draws a hexagon.
    CIRCLE           = Draws a circle.
    SEMI-CIRCLE      = Draws a semi-circle.
    ARC              = Draws an arc.
    ELLIPSE          = Draws an ellipse.
    OVAL             = Draws an oval.
    DIAMOND          = Draws a diamond.
    DIAMOND          = Draws a diamond.
    AMPLIFIER        = Draws an amplifier.
    CAPACITOR        = Draws a capacitor.
    GROUND           = Draws a ground.
    INDUCTOR         = Draws an inductor.
    RESISTOR         = Draws a resistor.
    AND              = Draws an and gate.
    OR               = Draws an or gate.
    NAND             = Draws a nand gate.
    NOR              = Draws a nand gate.
    CROSS-HAIR       = Activates and reads the cross-hair.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    LET Y = DATA 392 341 307 203 115 59 38 32 29 28
    LET STRING S1 = APOLLO
    LET STRING S2 = SUN
    LET STRING S3 = HP
    LET STRING S4 = DEC
    LET STRING S5 = SYM
    LET STRING S6 = SG
    LET STRING S7 = IBM
    LET STRING S8 = DG
    LET STRING S9 = TI
    LET STRING S10 = XEROX
    .
    LET N = NUMBER Y
    LET X = SEQUENCE 1 1 N
    .
    LINES BLANK ALL
    BAR ON ALL
    BAR WIDTH .5 ALL
    YMAX 600
    XMAX 12
    TITLE DEMONSTRATE MOVEDATA COMMAND
    PLOT Y X
    .
    JUSTIFICATION CENTER
    HEIGHT 2.0
    LOOP FOR K = 1 1 N
        LET X1 = X(K)
        LET Y1 = Y(K); LET Y1 = Y1 + 1.5
        MOVEDATA X1 Y1
        TEXT ^S^K
    END OF LOOP
 
-----MOVING <STATISTIC> CONTROL CHART----------------------------
 
MOVING STATISTIC CONTROL CHART
 
Name:
    MOVING <STATISTIC> CONTROL CHART
 
Type:
    Graphics Command
 
Purpose:
    Generates a moving average, a moving range, or a moving standard
    deviation control chart.
 
Description:
    The xbar, range, and standard deviation control charts
    are applied for grouped data.  The moving average, moving range,
    and moving standard deviation control charts are an alternative
    that can be applied to ungrouped data.  Although these charts
    can also be applied to grouped data, they have less desirable
    statistical properties than the xbar, range, and standard
    deviation control charts for grouped data.

    For ungrouped data, the moving average control chart is formed
    by plotting the moving average.  The moving average depends
    on a filter width.  For example, if this width is 3, then the
    first point plotted is the average of points one through three,
    the second poing plotted is the average of points two through
    five, and so on.  The x coordinate is in the middle of the points
    (i.e., the x coordinate of the first point plotted is 2).  In
    Dataplot, you specify the filter width by entering the following
    command before generating the control chart:

         LET K = <value>

    The control limits are computed as

         XBAR +/- 3.09*RANGEM/(E2(K)*SQRT(K))

    where XBAR is the overall mean, K is the filter width, and
    RANGEM is an estimate of sigmahat based on a moving range.
    Specifically, we compute a moving range comparable to the
    moving average described above and then we take the average of
    these moving ranges.  Dataplot uses the same filter width for
    this moving range as it does for computing the moving average.
    E2 is a tabulated value.

    The technique for constucting moving range and moving standard
    deviation charts is similar.  However, the control limits
    are:

         FACT*RANGEM

    where FACT is a tabulated value (it is different for the
    moving range and moving standard deviation control charts).

    In some cases, there may be historical data or engineering
    considerations that determine the control limits.  You can set
    your own control limits by entering the commands:

        LET TARGET = <value>
        LET USL = <value>
        LET LSL = <value>

    where TARGET is the desired target value and USL and LSL are the
    desired upper and lower control limits.

    You can control the appearance of this chart by setting the
    switches for the LINE, CHARACTER, SPIKE, and BAR commands
    appropriately.  Specifically,

       Trace 1 = the CUSUM statistic for positive sums
       Trace 2 = the CUSUM statistic for negative sums
       Trace 3 = Target reference line (the overall mean)
       Trace 4 = Dataplot calculated upper control limit
       Trace 5 = Dataplot calculated lower control limit
       Trace 6 = User specified target value
       Trace 7 = User specified upper control limit
       Trace 8 = User specified lower control limit

    For example, to draw the EWMA values as a solid line and
    an X,  the reference line and the Dataplot calculated control
    limits as dotted lines, and no user specified control limit, 
    enter the commands:

        LINE SOLID DOTTED DOTTED DOTTED BLANK BLANK BLANK
        CHARACTER X BLANK BLANK BLANK BLANK BLANK BLANK

Syntax 1:
    MOVING <stat> CONTROL CHART <y> <group>
                                <SUBSET/EXCEPT/FOR qualification>
    where <stat> is AVERAGE, RANGE, or SD;
          <y> is a response variable;
          <group> is a sub-group identifier variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for grouped data.

Syntax 2:
    MOVING <stat> CONTROL CHART <y>    <SUBSET/EXCEPT/FOR qualification>
    where <stat> is AVERAGE, RANGE, or SD;
          <y> is a response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for ungrouped data.

Examples:
    MOVING AVERAGE CONTROL CHART Y
    MOVING RANGE CONTROL CHART Y
    MOVING SD CONTROL CHART Y
    MOVING AVERAGE CONTROL CHART Y X
    MOVING AVERAGE CONTROL CHART Y X SUBSET X > 1

Note:
    The data should be checked for normality before applying these
    charts.  This can be done with a normal probability plot or
    a Wilks-Shapiro test.

Note:
    The Dataplot control limits should not be applied if the data
    contain a know trend.  See chapter 6 of Ryan for determining
    acceptable control limits for this case.

Default:
    None
 
Synonyms:
    MOVING AVERAGE CHART is a synonym for MOVING AVERAGE CONTROL CHART.
    MOVING RANGE CHART is a synonym for MOVING RANGE CONTROL CHART.
    MOVING SD CHART is a synonym for MOVING SD CONTROL CHART.
 
Related Commands:
    XBAR CONTROL CHART      = Generates a mean control chart.
    RANGE CONTROL CHART     = Generates a mean control chart.
    S CONTROL CHART         = Generates a sd control chart.
    EWMA CONTROL CHART      = Generates a ewma control chart.
    CUSUM CONTROL CHART     = Generates a mean cusum control chart.
    HOTELLING CONTROL CHART = Generates a Hotelling control chart.
    C CHART                 = Generates a C control chart.
    U CHART                 = Generates a U control chart.
    P CHART                 = Generates a P control chart.
    NP CHART                = Generates an Np control chart.
    NORMAL PROBABILITY PLOT = Generates a normal probability plot.
    WILKS-SHAPIRO TEST      = Compute the Wilks-Shapiro test for
                              normality.
 
Reference:
    "Statistical Methods For Quality Improvement", Thomas Ryan,
    John Wiley and Sons, 1989, chapter 6.

Applications:
    Quality Control
 
Implementation Date:
    1997/9
 
Program:
    LABEL CASE ASIS
    CASE ASIS
    Y1LABEL Distance (Micrometers)
    LINE SOLID DOTT DOTT DOTT
    XLIMITS 0 100
    XTIC OFFSET 2 10
    X3LABEL AUTOMATIC
    .
    SKIP 25
    READ CROARK3.DAT Y
    .
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    MULTIPLOT 2 2
    MOVING AVERAGE CONTROL CHART Y
    MOVING RANGE CONTROL CHART Y
    MOVING SD CONTROL CHART Y
    END OF MULTIPLOT
    MOVE 50 95
    JUSTIFICATION CENTER
    TEXT Magnification Standard for SEMs
 
-----MOVING <STATISTIC> (LET)---------------------------------------
 
MOVING (LET)
 
Name:
    MOVING <STATISTIC> (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute a "moving" statistic for a variable.
 
Description:
    It is sometimes useful to a compute a statistic over a "local"
    region of a variable rather than the entire variable.  The most
    common example would be to compute a moving average for a variable.

    Although this command is most commonly used for a location
    statistic, it can in fact be used for any supported statistic (enter
    HELP STATISTIC for a list of supported statistics).
    
    The "local" area is defined by the FILTER WIDTH command.  For example,

         FILTER WIDTH  5

    says that 5 points will be used to compute the specified statistic.

    The command 

        SET MOVING DIRECTION <CENTER/LEFT/RIGHT>

    defines the direction of the local region:

          CENTER   = the current row plus an equal number of rows
                     above and below the current row.  For example,
                     if the FILTER WIDTH is set to 5, the local area
                     for row i will be rows i - 2  to  i + 2.

          LEFT     = the current row plus the specified number of rows
                     above the current row.  For example, if the
                     FILTER WIDTH is set to 5, the local area for row i
                     will be rows  i  to  i + 4.

          RIGHT    = the current row minus the specified number of rows
                     below the current row.  For example, if the
                     FILTER WIDTH is set to 5, the local area for row i
                     will be rows  i - 4  to  i.

    The other issue is how the "end points" will be handled.  This is
    specified with the command

        SET MOVING END POINT <SKIP/SYMMETRIC/PARTIAL>

    where

         SKIP      = if the local region extends beyond the start or
                     end point, no output value will be generated for
                     that row.
    
         PARTIAL   = if the local region extends beyond the start or
                     end point, the statistic will be computed for the
                     subset of rows that are within range.
    
         SYMMETRIC = if the local region extends beyond the start or
                     end point, the statistic will be computed for the
                     largest subset of rows that maintains an equal
                     number of rows above and below the current row.
                     This option is only supported if the MOVING DIRECTION
                     is CENTER.

    The default is a FILTER WIDTH of 3, MOVING DIRECTION of CENTER, and
    a MOVING END POINT of SKIP.

Syntax:
    LET <yout> = MOVING <stat> <y1> ... <yk>
                               <SUBSET/EXCEPT/FOR qualification>
    where <y1> ... <yk> is a list of one to three response variables
              (depending on what <stat> is);
          <stat> is one of the supported statistics (HELP STATISTICS
              for a list);
          <yout> is a variable where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y2 = MOVING MEAN Y
    LET Y2 = MOVING MEIDAN Y
    LET Y2 = MOVING MINIMUM Y
    LET Y2 = MOVING SD Y

Note:
    The SMOOTH command can generate smooths based on a number of
    different moving statistics.  Enter HELP SMOOTH for details.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SMOOTH           = Perform a smooth.
    CROSS TABULATE   = Compute group statistics for one to six group
                       variables.
    STATISTIC PLOT   = Generate a statistic versus subset plot.
 
Applications:
    Data Analysis
 
Implementation Date:
    2010/10
 
Program:
    skip 25
    read mavro.dat y
    .
    let n = size y
    let x = sequence 1 1 n
    set write decimals 6
    .
    set moving end point skip
    let yskip = moving average y
    .
    set moving end point symmetric
    let ysymm = moving average y
    .
    set moving end point partial
    let ypart = moving average y
    .
    print x y yskip ysymm ypart

-----MOVING STATISTIC PLOT---------------------------------------
 
MOVING STATISTIC PLOT
 
Name:
    ... MOVING STATISTIC PLOT
 
Type:
    Graphics Command
 
Purpose:
    Plots the moving value of a statistic for a response variable.
    Optionally, the moving statistic can be plotted against a group-id
    variable.
 
Description:
    It is sometimes useful to a compute a statistic over a "local"
    region of a variable rather than the entire variable.  The most
    common example would be to compute a moving average for a variable.

    Although this command is most commonly used for a location
    statistic, it can in fact be used for any supported statistic (enter
    HELP STATISTIC for a list of supported statistics).
    
    The local area is defined by the FILTER WIDTH command.  For example,

         FILTER WIDTH  5

    says that 5 points will be used to compute the specified statistic.

    The command 

        SET MOVING DIRECTION <CENTER/LEFT/RIGHT>

    defines the direction of the local region:

          CENTER   = the current row plus an equal number of rows
                     above and below the current row.  For example,
                     if the FILTER WIDTH is set to 5, the local area
                     for row i will be rows i - 2  to  i + 2.

          LEFT     = the current row plus the specified number of rows
                     above the current row.  For example, if the
                     FILTER WIDTH is set to 5, the local area for row i
                     will be rows  i  to  i + 4.

          RIGHT    = the current row minus the specified number of rows
                     below the current row.  For example, if the
                     FILTER WIDTH is set to 5, the local area for row i
                     will be rows  i - 4  to  i.

    The other issue is how the end points will be handled.  This is
    specified with the command

        SET MOVING END POINT <SKIP/SYMMETRIC/PARTIAL>

    where

         SKIP      = if the local region extends beyond the start or
                     end point, no output value will be generated for
                     that row.
    
         PARTIAL   = if the local region extends beyond the start or
                     end point, the statistic will be computed for the
                     subset of rows that are within range.
    
         SYMMETRIC = if the local region extends beyond the start or
                     end point, the statistic will be computed for the
                     largest subset of rows that maintains an equal
                     number of rows above and below the current row.
                     This option is only supported if the MOVING DIRECTION
                     is CENTER.

    The default is a FILTER WIDTH of 3, MOVING DIRECTION of CENTER, and
    a MOVING END POINT of SKIP.

    The <stat> STATISTIC PLOT can be used plot the value of a
    statistic versus the index of a group-id variable.  So if
    you have 10 groups in your data, there will be 10 values of
    the statistic computed.

    The <stat> MOVING STATISTIC PLOT is a variant of the
    <stat> STATISTIC PLOT.

    There are two cases.

       1. If there is a single group in the data, then the
          moving value of the statistic will be plotted
          versus the sequence number.  That is, plot

              S(Y(i)) versus i

          where

              S(Y(i)) = the value of the moving statistic at point i.

          A reference line will be drawn at the value of the statistic
          for the full data set.

          The appearance of these two traces is controlled by the first
          two settings of the LINES, CHARACTERS, SPIKES, BARS, and
          and associated attribute setting commands.
 
       2. If there are multiple groups in the data, then the process
          above is repeated for each group.  In this case, the
          x coordinates is the index of the full data set, not just
          the current group.  However, the moving statistic is
          only computed for points in the current group.  The group
          sizes do not need to be equal.

          The distinction between this command and the STATISTIC PLOT
          is that the STATISTIC PLOT only plots the value of the
          statistic for all points in the group while this command
          plots the value of the moving statistic for all points
          in the group.  For example, if there are ten groups with
          ten points each, the STATISTIC PLOT will plot ten points
          while the MOVING STATISTIC PLOT will plot 100 points.

          A reference line will be drawn for each group (the reference
          value is the value of the statistic for all points in the
          specific group).

          The traces for the plot are defined in pairs.  That is,
          trace one is the moving statistics for group one, trace
          two is the reference line for group one, trace three is
          the moving statistics for group two, trace four is the
          reference line for group two, and so on.

          If you enter the command

              SET MOVING STATISTIC PLOT GROUPS STACKED

          then the x coordinate will start at one for each group.
          In this case, no reference line is drawn.

Syntax 1:
    <stat> MOVING STATISTIC PLOT  <y1> ... <yk>
                                  <SUBSET/EXCEPT/FOR qualification>
    where <stat> is one of Dataplot's supported statistics;
          <y1> ... <yk> is a list of 1 to 3 response variables
              (<stat> determines how many response variables);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    For a list of supported statistics, enter

          HELP STATISTICS

    This syntax is for the case without groups in the data.

Syntax 2:
    <stat> MOVING STATISTIC PLOT  <y1> ... <yk> <x>
                                  <SUBSET/EXCEPT/FOR qualification>
    where <stat> is one of Dataplot's supported statistics;
          <y1> ... <yk> is a list of 1 to 3 response variables
              (<stat> determines how many response variables);
          <x> is a group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    For a list of supported statistics, enter

          HELP STATISTICS
 
    This syntax is used for the case where there is a group-id
    variable.

Examples:
    MEAN MOVING STATISTIC PLOT Y
    MEAN MOVING STATISTIC PLOT Y X
    MEAN MOVING STATISTIC PLOT Y X  SUBSET X > 2
    SD MOVING STATISTIC PLOT Y
    CORRELATION MOVING STATISTIC PLOT Y1 Y2
 
Note:
    If the command

        SET MOVING END POINT SKIP

    is given, then some points at the beginning or end of the
    data will not have the moving statistic computed.  So if
    i=3 is the first point at which the moving statistic is
    computed, the x-coordinate will be set to 3, not 1.
 
Note:
    The word STATISTIC is required in this command (i.e., MOVING PLOT
    is not a synonym for MOVING STATISTIC PLOT).  This is to avoid
    conflicts with other commands.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MOVING <STATISTIC>      = Compute the moving value of a statistic.
    CUMULATIVE STAT PLOT    = Generate a plot of the cumulative value of a
                              statistic.
    STATISTIC PLOT          = Generate a statistic versus index plot.
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    2015/5

    The list of supported statistics is frequently updated.  Enter HELP
    STATISTICS for a current list of supported statistics.
 
Program:
    . Step 1:   Read the data
    .
    dimension 40 columns
    skip 25
    read zarr13.dat y1
    read berger1.dat y2 x2
    read lew.dat y3
    read gear.dat y4 x4
    skip 0
    .
    . Step 2:   Set some default plot control options
    .
    case asis
    label case asis
    tic mark label case asis
    title case asis
    title offset 2
    y1label displacement 15
    x1label displacement 12
    multiplot scale factor 2
    multiplot corner coordinates 5 5 95 95
    .
    . Step 3:   Moving plots, no groups, single response variable
    .
    filter width 5
    x1label Sequence
    .
    multiplot 2 2
    .
    title Mean Moving Statistic Plot
    y1label Moving Mean
    mean moving statistic plot y1
    .
    title Median Moving Statistic Plot
    y1label Moving Median
    median moving statistic plot y1
    .
    title SD Moving Statistic Plot
    y1label Moving SD
    standard deviation moving statistic plot y1
    .
    title Skewness Moving Statistic Plot
    y1label Moving Skewness
    skewness moving statistic plot y1
    .
    end of multiplot
    .
    just center
    move 50 97
    text Moving Statistic Plots for ZARR13.DAT (filter width 5)
    .
    y1label displacement
    x1label displacement
    .
    . Step 4:   Moving plots, no groups, two response variable
    .
    xlimits 0 120
    .
    title Correlation Moving Statistic Plot for BERGER1.DAT
    y1label Moving Correlation
    correlation moving statistic plot y2 x2
    .
    xlimits
    .
    . Step 5:   Cumulative/moving plots, groups, one response variable
    .
    title Mean Moving Statistic Plot for GEAR.DAT
    y1label Moving Mean
    mean moving statistic plot y4 x4

-----MSD (LET)--------------------------------
 
MSD
 
Name:
    MSD (LET)
 
Type:
    Library Function
 
Purpose:
    Return the most significant digit of the number.
 
Description:
    This is the first non-zero leading digit.  For example, the most
    significant digit of 3.14 is 3 while the most significant digit of
    0.00234 is 2.
 
Syntax:
    LET <y2> = MSD(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter containing decimal
               number(s);
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed most significant digits are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = MSD(.00234)
    LET A = MSD(A1)
    LET X2 = MSD(X1)
    LET X2 = MSD(X1-4)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    OCTDEC = Perform an octal to decimal conversion of a number.
    MOD    = Compute the modulo of two numbers.
    INT    = Compute the integer portion of number.
    FRACT  = Compute the fractional portion of number.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y2 = MSD(Y1)
    PRINT Y1 Y2
 
-----MULTINOMIAL PDF-------------------------------
 
MULTINOMIAL PDF
 
Name:
    MULTINOMIAL PDF
 
Type:
    Let Subcommand
 
Purpose:
    Compute the probability density function for a multinomial
    distribution.
 
Description:
    The multinomial distribution is a multivariate generalization
    of the binomial distribution.  For a binomial distribution,
    we perform n trials where each trial has two mutually
    exclusive outcomes (labeled success and failure).  Each trial
    has the same probability of success, p.  The binomial
    distribution is the probability of x successes in the n trials.

    The multinomial distribution extends this by allowing k
    possible outcomes.  These outcomes are mutually exclusive
    with each outcome having probability p(i).  The p(i) must
    sum to 1 and are the same for each trial.  The multinomial
    distribution is the probability that each event occurs
    x(i) times (i = 1, 2, ..., k) in the n trials.

    The probability mass function for the multinomial
    distribution is defined as

       p(x(1), x(2), ..., x(k)) =
             X!*[p(1)**(x(1))*p(2)**(x(2))* ... *p(k)**(x(k))]/
             [x(1)!*x(2)!* ... *x(k)!]*

    where x(1), ..., x(k) are non-negative integers, X is the sum of
    the x(i) (equals the number of trials), and the p(i) denote the
    probabilities of outcome i.  The p(i) should all be in the interval
    (0,1) and sum to 1.

Syntax:
    LET <a> = MULTINOMIAL PDF <x> <p>
    where <x> is a non-negative variable specifying the number of
               times the corresponding outcome occurs;
          <p> is a variable (of the same length as <x>) containing
               the desired probabilities for each outcome;
    and where <a> is a parameter where the resulting multinomial
               pdf is stored.
 
Examples:
    LET P = DATA 0.2 0.1 0.3 0.2 0.2
    LET X = DATA 5 4 10 8 7
    LET A = MULTINOMIAL PDF X P
 
Note:
    Dataplot uses a Fortran translation of the
    "gsl_ran_multinomial_lnpdf" code (written by Gavin Crooks) from
    the GNU GSL library.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MULTINOMIAL RANDOM NUMBERS  = Generate multinomial random numbers.
    BINPDF                      = Compute the binomial pdf function.
    DIRICHELET PDF              = Compute the Dirichelet pdf function.
 
Reference:
    "Statistical Distributions: Third Edition", Evans, Hastings,
    and Peacock, Wiley, 2000.
 
Applications:
    Simulation, Bayesian Analysis
 
Implementation Date:
    2003/5
 
Program:
    let p = data 0.2 0.1 0.2 0.3 0.2
    let x = data 12 5 8 10 6
    .
    let a = multinomial pdf x p
    .
    print a
 
-----MULTINOMIAL RANDOM NUMBER-------------------------------
 
MULTINOMIAL RANDOM NUMBER
 
Name:
    MULTINOMIAL RANDOM NUMBER
 
Type:
    Let Subcommand
 
Purpose:
    Generate random numbers from a multinomial distribution.
 
Description:
    The multinomial distribution is a multivariate generalization
    of the binomial distribution.  For a binomial distribution,
    we perform n trials where each trial has two mutually
    exclusive outcomes (labeled success and failure).  Each trial
    has the same probability of success, p.  The binomial
    distribution is the probability of x successes in the n trials.

    The multinomial distribution extends this by allowing k
    possible outcomes.  These outcomes are mutually exclusive
    with each outcome having probability p(i).  The p(i) must
    sum to 1 and are the same for each trial.  The multinomial
    distribution is the probability that each event occurs
    x(i) times (i = 1, 2, ..., k) in the n trials.

    For univariate distributions, Dataplot generates random
    numbers using the common syntax

       LET <shape-parameter>  = <value>
       LET Y = <dist> RANDOM NUMBERS FOR I = 1 1 N
       LET Y = LOC + SCALE*Y

    Multivariate distributions, however, generally require matrix
    operations.  For this reason, random numbers for multivariate
    distributions each have their own unique syntax.

    To generate multinomial random numbers, you need to specify
    a variable containing the k probabilities for each outcome
    (these probabilities must sum to 1), a scalar value specifying
    the number of trials (n), and a scalar value specifying the
    number of multinomial events (nevents) to simulate.  The output
    is a matrix with nevent rows and k columns.  Each row of the
    matrix should sum to n.

Syntax:
    LET <mat> = MULTINOMIAL RANDOM NUMBERS <p> <n> <nevents>
    where <p> is a variable containing the desired probabilities for
               each outcome;
          <n> is a number or parameter specifying the desired number
               of trials;
          <nevents> is a number or parameter specifying the number
               of multinomial events being generated;
    and where <mat> is a matrix where the resulting multivariate
               multinomial random numbers are stored.
 
    Dataplot determines the number of possible outcomes from the
    number of rows in the <p> variable.  The returned matrix will
    have <nevents> rows and columns equal to the number of rows in
    <p>.

Examples:
    LET P = DATA 0.2 0.1 0.3 0.2 0.2
    LET N = 100
    LET NEVENTS = 10
    LET M = MULTINOMIAL RANDOM NUMBERS P N
 
Note:
    Dataplot uses code from the RANLIB library of Brown and
    Lavato.  This library was downloaded from the statlib
    library.  This code implements an algorithm suggested by
    Luc Devroye (see Reference).

Note:
    As with univariate random numbers, the multinomial random
    numbers are built on an underlying uniform random number
    generator.  Dataplot supports a number of different
    uniform random number generators.  For details, enter

       HELP SET RANDOM NUMBER GENERATOR

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RANDOM NUMBERS                = Generate random numbers for 60+
                                    univariate distributions.
    SET RANDOM NUMBER GENERATOR   = Specify which univariate generator
                                    to use.
    MULTIVARIATE NORM RAND NUMB   = Generate multivariate normal
                                    random numbers.
    MULTIVARIATE T RANDOM NUMBERS = Generate multivariate t random
                                    numbers.
    INDEPENDENT UNIFORM RAND NUMB = Generate random numbers for
                                    independent uniform distributions.
    WISHART RANDOM NUMBERS        = Generate random numbers for a
                                    Wishart distribution.
    DIRICHLET RANDOM NUMBERS      = Generate random numbers for a
                                    Dirichlet distribution.
 
Reference:
    "Statistical Distributions: Third Edition", Evans, Hastings,
    and Peacock, Wiley, 2000.
 
    "Non-Uniform Random Variate Generation", Luc Devroye,
    Springer-Verlang, 1986, p. 559.

Applications:
    Simulation, Bayesian Analysis
 
Implementation Date:
    2003/5
 
Program:
    dimension 100 columns
    .
    let p = data 0.2 0.1 0.2 0.3 0.2
    let n = 200
    let nevents = 10
    .
    let m = multinomial random numbers p n
    .
    print m
 
-----MULTIPLOT-------------------------------------------------------
 
MULTIPLOT
 
Name:
    MULTIPLOT
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the number of rows and columns in the "matrix of plots"
    that is to be formed by subsequent various plot commands.
 
Description:
    The MULTIPLOT command, though simple, is one of the most powerful
    and most commonly used recent (since 1988) enhancements to
    DATAPLOT.  Generating multiple plots per page is an extremely
    important exploratory data analysis tool.  The MULTIPLOT command
    does all the behind-the-scenes scaling of the plots, the erase for
    the first plot, the non-erase for subsequent plots, etc.  It is
    frequently used to examine 1 variable by many different plot
    techniques.  It is also used to examine many variables by a single
    plot technique.  The MULTIPLOT command should receive routine and
    daily usage.
 
    The MULTIPLOT command divides the plot area into equal size rows
    and columns.  As the next plot is generated, it is moved into the
    next row and column position.  The sub-area is given its own
    0 to 100 coordinate system and all commands until the next plot
    command are based on this scaled down plot area.  That is, sizes
    are automatically scaled relative to the sub-area and diagrammatic
    graphics are plotted in this sub-area.  Normally, plots move
    sequentially through the row and column positions.  However,
    syntax 2 or syntax 3 below can be used to move to a specific
    location.
 
Syntax 1:
    MULTIPLOT   <rows>  <columns>
    where <rows> is a number or parameter that specifies the desired
                 number of rows of plots to subsequently appear;
    and   <columns> is a number or parameterthat specifies the desired
                 number of columns of plots to subsequently appear.
 
    This syntax does a screen erase before the next plot.  This is the
    most common syntax for MULTIPLOT.
 
Syntax 2:
    MULTIPLOT   <rows> <columns> <start>
    where <rows> is a number or parameter that specifies the desired
                 number of rows of plots to subsequently appear;
          <columns> is a number or parameterthat specifies the desired
                 number of columns of plots to subsequently appear;
    and   <start> is a number or parameter that specifies the index
                 of the next plot to generate (i.e., the first <start>
                 - 1 plots are skipped).
 
    This syntax does not do a screen erase before the next plot.  It
    is typically used to skip 1 or more plots and is almost always
    preceded by a MULTIPLOT command using syntax 1.
 
Syntax 3:
    MULTIPLOT   <rows> <columns> <row 0> <column 0>
    where <rows> (a number or parameter) is the desired number
                 of rows of plots to subsequently appear, and
          <columns> is a number or parameterthat specifies the desired
                 number of columns of plots to subsequently appear;
          <row 0> is a number or parameterthat specifies the desired
                 row where the next plot should appear;
    and   <column 0> is a number or parameterthat specifies the desired
                 column where the next plot should appear.
 
    This syntax does not do a screen erase before the next plot.  It
    is typically used to skip 1 or more plots and is almost always
    preceded with a MULTIPLOT command using syntax 1.  It is similar
    to syntax 2.  The distinction is that the position of the next plot
    is specified by a specific row and column id rather than a count.
 
Examples:
    MULTIPLOT 2 2
    MULTIPLOT 4 5
    MULTIPLOT 10 10
 
Note:
    The END OF MULTIPLOT command is used to terminate a multiplot
    sequence of plots and revert the plot area back to the full screen.
 
Note:
    By default, the MULTIPLOT command divides the current plot area
    ((15,20), (85,90) by default).  The MULTIPLOT CORNER COORDINATES
    command can be used to specify the portion of the screen to use
    for MULTIPLOT.
 
Note:
    There is no restriction on the type of plot that can be used in
    conjunction with the MULTIPLOT command.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    All graphics commands
    MULTIPLOT CORNER COORDINATES   = Specify coordinates for the area
                                     to use for multi-plot.
    FRAME CORNER COORDINATES       = Specify the coordinates of the
                                     plot frame.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    88/9
 
Program:
    LET THETA = SEQUENCE 0 1 380
    LET X = SIN(THETA)
    MULTIPLOT 3 4
    FEEDBACK OFF
    FRAME OFF
    PRE-SORT OFF
    XLABEL SIZE 4
    LOOP FOR K = .1 .1 1.2
    LET Y=SIN(K*THETA)
    XLABEL ^K
    PLOT Y X
    END OF LOOP
 
-----MULTIPLOT COORDINATES--------------------------------------------
 
MULTIPLOT COORDINATES
 
Name:
    MULTIPLOT COORDINATES
 
Type:
    Plot Control Command
 
Purpose:
    Specify the area of the device to use for the MULTIPLOT command.
 
Description:
    The MULTIPLOT plot command divides the page into separate plot
    areas.  By default, it uses the current frame area.  That is, the
    frame is divided into equal sized rectangles with their own 0 to
    100 scale in the X and Y directions.  The default frame area is
    from (15,20) to (85,90) in DATAPLOT 0 to 100 units.  Each multiplot
    region has its own frame (still (15,20) and (85,90) but with respect
    to the multiplot region rather than the whole page).
 
    It is often desirable to use a larger portion of the screen before
    creating the multiplot subregions.  The MULTIPLOT COORDINATES
    command specifies the lower left corner and the upper right corner
    for doing the multiplot.  The FRAME COORDINATES command is used to
    specify the size of the frame area within a given multiplot
    subregion.
 
Syntax:
    MULTIPLOT COORDINATES  <x1>  <y1>  <x2>  <y2>
    where <x1> is a decimal number or parameter in the range 0 to 100
               that specifies the horizontal position of the lower left
               corner;
          <y1> is a decimal number or parameter in the range 0 to 100
               that specifies the vertical position of the lower left
               corner;
          <x2> is a decimal number or parameter in the range 0 to 100
               that specifies the horizontal position of the upper right
               corner;
          <y2> is a decimal number or parameter in the range 0 to 100
               that specifies the vertical position of the upper right
               corner.
 
Examples:
    MULTIPLOT COORDINATES 0 0 100 100
    MULTIPLOT COORDINATES 5 5 95 95
 
Default:
    In DATAPLOT 0 to 100 coordinates, the default left corner is (15,20)
    and the default right corner is (85,90).
 
Synonyms:
    MULTIPLOT CORNER COORDINATES
 
Related Commands:
    MULTIPLOT                 = Generate multiple plots per page.
    PLOT                      = Generates a data or function plot.
    FRAME                     = Sets the on/off switch for plot frame.
    FRAME CORNER COORDINATES  = Specify the frame coordinates.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    TITLE
    LET THETA = SEQUENCE 0 1 380
    LET X = SIN(THETA)
    MULTIPLOT 3 4
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    FEEDBACK OFF
    FRAME OFF
    PRE-SORT OFF
    LABEL SIZE 4
    LOOP FOR K = .1 .1 1.2
    LET Y=SIN(K*THETA)
    XLABEL ^K
    PLOT Y X
    END OF LOOP
    END OF MULTIPLOT
 
-----MULTIPLOT SCALE FACTOR--------------------------------------------
 
MULTIPLOT SCALE FACTOR
 
Name:
    MULTIPLOT SCALE FACTOR
 
Type:
    Plot Control Command
 
Purpose:
    Specify a multiplier factor for character sizes when
    generating multiplots.
 
Description:
    Dataplot sets character size in percentages of the vertical
    height of a device.  That is, CHARACTER SIZE 3 sets the 
    character size as 3% of the height of the graphics region.
    The MULTIPLOT command divides the plot into a matrix of
    subplots.  Each of these subplot areas defines its own
    0 to 100 region.  For multiplots, character sizes are
    relative to subplot region, not the full graphics area.

    At times, it is desirable to scale character sizes larger
    when generating multiplots in order to keep the text on 
    the plot more legible.  Although each of the components of
    the plot can explicitly set the character size larger
    (e.g., TITLE SIZE, LABEL SIZE, etc.), the MULTIPLOT SCALE
    FACTOR allows you to scale ALL character sizes larger
    by a constant factor.  This avoids having to reset a number
    of size commands before generating a MULTIPLOT (and resetting
    them after the plot is done).
 
    When multiplotting is in effect, Dataplot determines the
    appropriate size of the text character based on the specified
    size.  It then multiplies that size by the scale factor
    specified by this command.  If no MULTIPLOT SCALE FACTOR
    command has been entered, it defaults to 1 (i.e., no
    scaling).

Syntax:
    MULTIPLOT SCALE FACTOR  <height>  <width>
    where <height> is a decimal number or parameter that specifies
               the scale factor for text height;
    and where <width> is a decimal number or parameter that
               specifies the scale factor for text width.
 

    The <width> parameter is optional.  It is most commonly used
    when the number of rows and columns on the MULTIPLOT command
    significantly differ.

Examples:
    MULTIPLOT 2 2
    MULTIPLOT SCALE FACTOR
 
    MULTIPLOT 3 3
    MULTIPLOT SCALE FACTOR 1.5 1.5
 
    MULTIPLOT 5 1
    MULTIPLOT SCALE FACTOR 3 1
 
Default:
    The default scale factor is 1 (i.e., no scaling).
 
Synonyms:
    None
 
Related Commands:
    MULTIPLOT                 = Generate multiple plots per page.
    MULTIPLOT COORDINATES     = Specify the coordinates for the
                                multiplot region.
    PLOT                      = Generates a data or function plot.
    FRAME                     = Sets the on/off switch for plot frame.
    FRAME CORNER COORDINATES  = Specify the frame coordinates.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    1998/8
 
Program:
    TITLE
    LET THETA = SEQUENCE 0 1 380
    LET X = SIN(THETA)
    MULTIPLOT 3 4
    MULTIPLOT COORDINATES 0 0 100 100
    MULTIPLOT SCALE FACTOR 2.5
    FRAME OFF
    PRE-SORT OFF
    LABEL SIZE 4
    LOOP FOR K = .1 .1 1.2
       LET Y=SIN(K*THETA)
       XLABEL ^K
       PLOT Y X
    END OF LOOP
    END OF MULTIPLOT
 
-----MULTIVARIATE NORMAL CDF-------------------------------
 
MULTIVARIATE NORMAL CDF
 
Name:
    MULTIVARIATE NORMAL CDF
 
Type:
    Let Subcommand
 
Purpose:
    Compute the cumulative distribution function (CDF) from a
    multivariate normal distribution.
 
Description:
    The NORCDF function computes the CDF of a univariate
    normal distribution.  This command extends that capability
    to the multivariate case (for up to 20 variables).

    The CDF is the integral of the probability density function
    from negative infinity to the desired value.  In addition
    to the CDF case, this command can handle integration
    from the specified point to positive infinity and integration
    from negative infinity to positive infinity.

    For the multivariate case, you need to specify a
    varible containing the location estimates for each
    variable, the variance-covariance matrix of the the
    variables, and variables specifying the limits of integration.

    This command uses codes provided by Alan Genz (see the
    Reference seciton below).  In particular, this code
    supports four different methods:

       1) SADMVN - a subregion adaptive integration method
                   developed by Alan Genz.
       2) KROMVN - a lattice rule method using randomized
                   Korobov rules.
       3) RANMVN - Genz'a Monte-Carlo integration.
       4) SPHNRM - Deak's method.

    Alan Genz has written several papers comparing the
    speed and accuracy of these various methods.  His basic
    conclusion is that for moderate accuracy SADMVN and
    KROMVN are usually much faster (with SADMVN faster for
    fewer than 10 variables and KROMVN faster for more than
    10 variables).  By default, Dataplot uses the SADMVN
    method, but you specify one of the other methods (see
    the Note section below).

Syntax 1:
    LET <par> = MULTIVARIATE NORMAL CDF <sigma> <upplim>
    where <sigma> is a matrix containing the desired
               variance-covariance matrix;
          <upplim> is a variable containing the upper levels
               of integration;
    and where <par> is a parameter containing the computed
               multivariate normal cdf value.
 
    This syntax computes the cdf function. 

Syntax 2:
    LET <par> = MULTIVARIATE NORMAL CDF <sigma> <lowlim> <upplim>
    where <sigma> is a matrix containing the desired
               variance-covariance matrix;
          <lowlim> is a variable containing the lower levels
               of integration;
          <upplim> is a variable containing the upper levels
               of integration;
    and where <par> is a parameter containing the computed
               multivariate normal cdf value.
 
    This syntax can be used to compute arbitrary integrals of
    the multivariate normal function.

Examples:
    READ MATRIX SIGMA
    1   0.5  0.5
    0.5  1   0.5
    0.5 0.5   1
    END OF DATA
    LET LOWLIM = DATA 1.5 2 0.5
    LET A = MULTIVARIATE NORMAL CDF SIGMA LOWLIM
 
Note:
    You can specify which method to use with the following
    command:

        SET MULTIVARIATE NORMAL <method>

    where <method> is one of the following:

        SADMVN
        KROMVN
        RANMVN
        SPHMVN

Note:
    The accuracy of the routine can be specified by entering
    one of the following command (before entering the MULTIVARIATE
    NORMAL CDF command):

       LET ABSEPS = <value>
       LET RELEPS = <value>

    These define the desired absolute and relative errors,
    respectively.  The default absolute error is set to 0.00005 and
    the default relative error is set to 0 (i.e., the absolute
    error is used).  This should be a reasonable choice for most
    applications.

Note:
    The error estimate is returned in the internal parameter
    NCDFERRS.  You can use this parameter like any user
    created parameter.  For example, to see its value, enter
    PRINT NCDFERRS.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NORCDF                        = Compute the univariate normal
                                    cdf function.
    MULTIVARIATE T CDF            = Generate multivariate t cdf
                                    function.
    MULTIVARIATE NORM RAND NUMB   = Generate multivariate normal
                                    random numbers.
    MULTIVARIATE T RANDOM NUMBERS = Generate multivariate t random
                                    numbers.
 
Reference:
    "Comparison of Methods for the Computation ofMultivariate
    Normal Probabilities", Alan Genz, Computing Science and
    Statistics, 25, 1993, pp. 400-405.

    "Numerical Computation of Multivariate Normal Probabilities",
    Alan Genz, Journal of Computational and Graphical Statistics,
    1, 1992, pp. 141-149.

Applications:
    Bayesian Analysis
 
Implementation Date:
    2003/5
 
Program:
    read matrix sigma
     1.0        -0.707107  0.0  0.0 0.0
    -0.707107    1.0       0.5  0.5 0.5
     0.0         0.5       1.0  0.5 0.5
     0.0         0.5       0.5  1.0 0.5
     0.0         0.5       0.5  0.5 1.0
    end of data
    .
    let cpumin = -infinity
    let lowl = data 0.0      0.0   1.7817   1.4755   cpumin
    let uppl = data infinity 1.5198 infinity infinity 1.5949
    .
    let a = multivariate normal cdf sigma lowl uppl
    set multivariate normal kromvn
    let a = multivariate normal cdf sigma lowl uppl
    set multivariate normal ranmvn
    let a = multivariate normal cdf sigma lowl uppl
    set multivariate normal sphmvn
    let a = multivariate normal cdf sigma lowl uppl
 
-----MULTIVARIATE NORMAL RANDOM NUMBER-------------------------------
 
MULTIVARIATE NORMAL RANDOM NUMBER
 
Name:
    MULTIVARIATE NORMAL RANDOM NUMBER GENERATOR
 
Type:
    Let Subcommand
 
Purpose:
    Generate random numbers from a multivariate normal
    distribution.
 
Description:
    For univariate distributions, Dataplot generates random
    numbers using the common syntax

       LET <shape-parameter>  = <value>
       LET Y = <dist> RANDOM NUMBERS FOR I = 1 1 N
       LET Y = LOC + SCALE*Y

    Multivariate distributions, however, genrally require matrix
    operations.  For this reason, random numbers for multivariate
    distributions each have their own unique syntax.  Although
    you can generate P columns of normal random numbers, this does
    take into account any correlation between the variables (i.e.,
    they are independent).

    To generate an NxP matrix of normal random numbers in Dataplot,
    you must specify a Px1 mean vector and a PxP variance-covariance
    matrix.  The mean vector specifies the location parameters for
    each of the P columns.  The diagonal of the variance-covariance
    matrix specifies the scale parameters of the P columns.

Syntax:
    LET <mat> = MULTIVARIATE NORMAL RANDOM NUMBERS <mu> <sigma> <n>
    where <mu> is a variable containing the desired location
               parameters;
          <sigma> is a matrix containing the desired
               variance-covariance matrix;
          <n> is a number or parameter specifying the desired number
               of rows;
    and where <mat> is a matrix where the resulting multivariate
               normal random numbers are stored.
 
    Dataplot determines the number of columns to generate from
    the number of rows in the <mu> vector.  Note that the number
    of rows in <mu> must equal the number of rows (and columns)
    in <sigma> and <sigma> must be a symmetric positive-definite
    matrix (i.e., a value variance-covariance matrix).

Examples:
    LET MU = -5 0 5
    READ MATRIX SIGMA
    1   0.5  0.5
    0.5  1   0.5
    0.5 0.5   1
    END OF DATA
    LET N = 500
    LET M = MULTIVARIATE NORMAL RANDOM NUMBERS MU SIGMA N
 
Note:
    Dataplot generates multivariate normal random numbers
    with a mean vector AMU and a variance-covariance matrix
    SIGMA using the RDMNOR routine written by Charlie Reeves while
    he was a member of the NIST Statistical Engineering Division.

Note:
    As with univariate random numbers, the nultivariate normal
    random numbers are built on an underlying uniform random
    number generators.  Dataplot supports a number of different
    uniform random number generators.  For details, enter

       HELP SET RANDOM NUMBER GENERATOR

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RANDOM NUMBERS                = Generate random numbers for 60+
                                    univariate distributions.
    SET RANDOM NUMBER GENERATOR   = Specify which univariate generator
                                    to use.
    MULTIVARIATE T RANDOM NUMBERS = Generate multivariate t random
                                    numbers.
    INDEPENDENT UNIFORM RAND NUMB = Generate random numbers for
                                    independent uniform distributions.
    WISHART RANDOM NUMBERS        = Generate random numbers for a
                                    Wishart distribution.
    DIRICHLET RANDOM NUMBERS      = Generate random numbers for a
                                    Dirichlet distribution.
 
Reference:
    "Continuous Multivariate Distributions Volume 1: Models and
    Applications", Johnson, Kotz, and Balakrishnan, Wiley, 2000.
 
    "Introduction to Matrix Computations", G. W. Stewart,
    Academic Press, Algorithm 3.9, p. 142.

Applications:
    Simulation, Bayesian Analysis
 
Implementation Date:
    2003/3
 
Program:
    dimension 100 columns
    .
    read matrix sigma
     1.0        -0.707107  0.0  0.0 0.0
    -0.707107    1.0       0.5  0.5 0.5
     0.0         0.5       1.0  0.5 0.5
     0.0         0.5       0.5  1.0 0.5
     0.0         0.5       0.5  0.5 1.0
    end of data
    .
    let mu = data 0 0 0 0 0
    let n = 200
    .
    let m = multivariate normal random numbers mu sigma n
    .
    multiplot corner coordinates 0 0 100 100
    multiplot 2 3
    title automatic
    loop for k = 1 1 5
        relative histogram m^k
    end of loop
 
-----MULTIVARIATE T CDF-------------------------------
 
MULTIVARIATE T CDF
 
Name:
    MULTIVARIATE T CDF
 
Type:
    Let Subcommand
 
Purpose:
    Compute the cumulative distribution function (CDF) from a
    multivariate t distribution.
 
Description:
    The TCDF function computes the CDF of a univariate
    t distribution.  This command extends that capability
    to the multivariate case (for up to 20 variables).

    The CDF is the integral of the probability density function
    from negative infinity to the desired value.  In addition
    to the CDF case, this command can handle integration
    from the specified point to positive infinity and integration
    from negative infinity to positive infinity.

    For the multivariate case, you need to specify a
    varible containing the location estimates for each
    variable, the variance-covariance matrix of the the
    variables, a parameter defining the degrees of freedom,
    and variables specifying the limits of integration.

    This command uses codes provided by Alan Genz (see the
    Reference seciton below).  In particular, this code
    supports three different methods:

       1) SADMVT - a subregion adaptive integration method
                   developed by Alan Genz.
       2) KROMVT - a lattice rule method using randomized
                   Korobov rules.
       3) RANMVT - Genz'a Monte-Carlo integration.

    By default, Dataplot uses the SADMVN method, but you specify
    one of the other methods (see the Note section below).

Syntax 1:
    LET <par> = MULTIVARIATE T CDF <sigma> <nu> <upplim>
    where <sigma> is a matrix containing the desired
               variance-covariance matrix;
          <nu> is a number or parameter that specifies the
               desired degrees of freedom for the t distribution;
          <upplim> is a variable containing the upper levels
               of integration;
    and where <par> is a parameter containing the computed
               multivariate t cdf value.
 
    This syntax computes the cdf function. 

Syntax 2:
    LET <par> = MULTIVARIATE T CDF <sigma> <nu> <lowlim> <upplim>
    where <sigma> is a matrix containing the desired
               variance-covariance matrix;
          <nu> is a number or parameter that specifies the
               desired degrees of freedom for the t distribution;
          <lowlim> is a variable containing the lower levels
               of integration;
          <upplim> is a variable containing the upper levels
               of integration;
    and where <par> is a parameter containing the computed
               multivariate t cdf value.
 
    This syntax can be used to compute arbitrary integrals of
    the multivariate t function.

Examples:
    LET NU = 5
    READ MATRIX SIGMA
    1   0.5  0.5
    0.5  1   0.5
    0.5 0.5   1
    END OF DATA
    LET LOWLIM = DATA 1.5 2 0.5
    LET A = MULTIVARIATE T CDF SIGMA NU LOWLIM
 
Note:
    You can specify which method to use with the following
    command:

        SET MULTIVARIATE NORMAL <method>

    where <method> is one of the following:

        SADMVN
        KROMVN
        RANMVN

Note:
    The accuracy of the routine can be specified by entering
    one of the following command (before entering the MULTIVARIATE
    NORMAL CDF command):

       LET ABSEPS = <value>
       LET RELEPS = <value>

    These define the desired absolute and relative errors,
    respectively.  The default absolute error is set to 0.00005 and
    the default relative error is set to 0 (i.e., the absolute
    error is used).  This should be a reasonable choice for most
    applications.

Note:
    The error estimate is returned in the internal parameter
    NCDFERRS.  You can use this parameter like any user
    created parameter.  For example, to see its value, enter
    PRINT NCDFERRS.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    TCDF                          = Compute the univariate t
                                    cdf function.
    MULTIVARIATE NORMAL CDF       = Generate multivariate normal
                                    cdf function.
    MULTIVARIATE NORM RAND NUMB   = Generate multivariate normal
                                    random numbers.
    MULTIVARIATE T RANDOM NUMBERS = Generate multivariate t random
                                    numbers.
 
Reference:
    "Comparison of Methods for the Computation ofMultivariate
    Normal Probabilities", Alan Genz, Computing Science and
    Statistics, 25, 1993, pp. 400-405.

    "Numerical Computation of Multivariate Normal Probabilities",
    Alan Genz, Journal of Computational and Graphical Statistics,
    1, 1992, pp. 141-149.

Applications:
    Bayesian Analysis
 
Implementation Date:
    2003/5
 
Program:
    read matrix sigma
     1.0         0.75      0.75 0.75 0.75
     0.75        1.0       0.75 0.75 0.75
     0.75        0.75      1.0  0.75 0.75
     0.75        0.75      0.75 1.0  0.75
     0.75        0.75      0.75 0.75 1.0
    end of data
    .
    let cpumin = -infinity
    let lowl = data cpumin  cpumin  cpumin  cpumin cpumin
    let uppl = data   2       2       2        2     2
    .
    let nu = 10
    let a = multivariate t cdf sigma nu lowl uppl
    let nu = 20
    let a = multivariate t cdf sigma nu lowl uppl
    let nu = 30
    let a = multivariate t cdf sigma nu lowl uppl
    let nu = 40
    let a = multivariate t cdf sigma nu lowl uppl
    pause
    .
    set multivariate normal kromvt
    let nu=10
    let a = multivariate t cdf sigma nu lowl uppl
    let nu=20
    let a = multivariate t cdf sigma nu lowl uppl
    let nu=30
    let a = multivariate t cdf sigma nu lowl uppl
    let nu=40
    let a = multivariate t cdf sigma nu lowl uppl
    pause
    .
    set multivariate normal ranmvt
    let nu=10
    let a = multivariate t cdf sigma nu lowl uppl
    let nu=20
    let a = multivariate t cdf sigma nu lowl uppl
    let nu=30
    let a = multivariate t cdf sigma nu lowl uppl
    let nu=40
    let a = multivariate t cdf sigma nu lowl uppl
 
-----MULTIVARIATE T RANDOM NUMBER-------------------------------
 
MULTIVARIATE T RANDOM NUMBER
 
Name:
    MULTIVARIATE T RANDOM NUMBER GENERATOR
 
Type:
    Let Subcommand
 
Purpose:
    Generate random numbers from a multivariate t distribution.
 
Description:
    For univariate distributions, Dataplot generates random
    numbers using the common syntax

       LET <shape-parameter>  = <value>
       LET Y = <dist> RANDOM NUMBERS FOR I = 1 1 N
       LET Y = LOC + SCALE*Y

    Multivariate distributions, however, genrally require matrix
    operations.  For this reason, random numbers for multivariate
    distributions each have their own unique syntax.  Although
    you can generate P columns of t random numbers, this does
    take into account any correlation between the variables (i.e.,
    they are independent).

    To generate an NxP matrix of t random numbers in Dataplot,
    you must specify a Px1 mean vector, a PxP variance-covariance
    matrix, and the desired degress of freedom (i.e., the shape
    parameter for the t distribution).  The mean vector specifies
    the location parameters for each of the P columns.  The diagonal
    of the variance-covariance matrix specifies the scale parameters
    of the P columns.  A single value is specified for the degrees
    of freedom (i.e., all columns assume a common degrees of
    freedom).

Syntax:
    LET <mat> = MULTIVARIATE T RANDOM NUMBERS <mu> <sigma> <nu> <n>
    where <mu> is a variable containing the desired location
               parameters;
          <sigma> is a matrix containing the desired
               variance-covariance matrix;
          <nu> is a number or parameter specifying the desired
               degrees of freedom;
          <n> is a number or parameter specifying the desired number
               of rows;
    and where <mat> is a matrix where the resulting multivariate
               normal random numbers are stored.
 
    Dataplot determines the number of columns to generate from
    the number of rows in the <mu> vector.  Note that the number
    of rows in <mu> must equal the number of rows (and columns)
    in <sigma> and <sigma> must be a symmetric positive-definite
    matrix (i.e., a value variance-covariance matrix).

Examples:
    LET MU = -5 0 5
    READ MATRIX SIGMA
    1   0.5  0.5
    0.5  1   0.5
    0.5 0.5   1
    END OF DATA
    LET N = 500
    LET NU = 500
    LET M = MULTIVARIATE T RANDOM NUMBERS MU SIGMA NU N
 
Note:
    Dataplot first generates multivariate normal random numbers
    with a mean vector AMU and a variance-covariance matrix
    SIGMA using the RDMNOR routine.  The multivariate normal
    random numbers are then divded by the SQRT(CHSRAN(NU)/NU)
    where CHSRAN is an independent chi-square random number 
    with NU degrees of freedom.

    RDMNOR was written by Charlie Reeves while he was a member of
    the NIST Statistical Engineering Division.

Note:
    As with univariate random numbers, the nultivariate normal
    random numbers are built on an underlying uniform random
    number generators.  Dataplot supports a number of different
    uniform random number generators.  For details, enter

       HELP SET RANDOM NUMBER GENERATOR

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RANDOM NUMBERS                = Generate random numbers for 60+
                                    univariate distributions.
    SET RANDOM NUMBER GENERATOR   = Specify which univariate generator
                                    to use.
    MULTIVARIATE NORM RAND NUMB   = Generate multivariate normal
                                    random numbers.
    INDEPENDENT UNIFORM RAND NUMB = Generate random numbers for
                                    independent uniform distributions.
    WISHART RANDOM NUMBERS        = Generate random numbers for a
                                    Wishart distribution.
    DIRICHLET RANDOM NUMBERS      = Generate random numbers for a
                                    Dirichlet distribution.
 
Reference:
    "Continuous Multivariate Distributions Volume 1: Models and
    Applications", Johnson, Kotz, and Balakrishnan, Wiley, 2000.
 
    "Introduction to Matrix Computations", G. W. Stewart,
    Academic Press, Algorithm 3.9, p. 142.
 
Applications:
    Simulation, Bayesian Analysis
 
Implementation Date:
    2003/5
 
Program:
    dimension 100 columns
    .
    read matrix sigma
     1.0        -0.707107  0.0  0.0 0.0
    -0.707107    1.0       0.5  0.5 0.5
     0.0         0.5       1.0  0.5 0.5
     0.0         0.5       0.5  1.0 0.5
     0.0         0.5       0.5  0.5 1.0
    end of data
    .
    let mu = data 0 0 0 0 0
    let n = 500
    let nu = 3
    .
    let m = multivariate t random numbers mu sigma nu n
    .
    multiplot corner coordinates 0 0 100 100
    multiplot 2 3
    title automatic
    loop for k = 1 1 5
        relative histogram m^k
    end of loop
 
-----MULTIVARIATE UNIFORM RANDOM NUMBERS------------------------------
 
MULTIVARIATE UNIFORM RANDOM NUMBERS
 
Name:
    MULTIVARIATE UNIFORM RANDOM NUMBER 
 
Type:
    Let Subcommand
 
Purpose:
    Generate random numbers from correlated uniform distributions.
 
Description:
    For univariate distributions, Dataplot generates random
    numbers using the common syntax

       LET <shape-parameter>  = <value>
       LET Y = <dist> RANDOM NUMBERS FOR I = 1 1 N
       LET Y = LOC + SCALE*Y

    Multivariate distributions, however, generally require matrix
    operations.  For this reason, random numbers for multivariate
    distributions each have their own unique syntax.  Although
    you can generate P columns of uniform random numbers, this does
    take into account any correlation between the variables (i.e.,
    they are independent).

    To generate correlated uniform random numbers, Dataplot
    generates correlated multivariate normal random numbers and then
    takes the normal cumulative distribution function of these
    numbers.  This algorithm is from Gentle (2003) "Random
    Number Generation and Monte Carlo Methods".

    For details on how to generate uncorrelated multivariate
    uniform random numbers, enter HELP INDEPENDENT UNIFORM RANDOM
    NUMBERS.

Syntax:
    LET <mat> = MULTIVARIATE UNIFORM RANDOM NUMBERS  <sigma> <n>
    where <sigma> is a variance-covariance matrix from a
               multivariate normal distribution;
          <n> is a number or parameter specifying the desired number
               of rows;
    and where <mat> is a matrix where the resulting multivariate
               independent uniform random numbers are stored.
 
    Dataplot determines the number of columns to generate from
    the number of rows in the <sigma> matrix.

Examples:
    LET M = MULTIVARIATE UNIFORM RANDOM NUMBERS SIGMA N
 
Note:
    Dataplot supports a number of different uniform random number
    generators.  For details, enter

       HELP SET RANDOM NUMBER GENERATOR

Default:
    None
 
Synonyms:
    CORRELATED UNIFORM RANDOM NUMBERS
 
Related Commands:
    INDEPENDENT UNIFORM RAND NUMB = Generate uncorrelated uniform
                                    random numbers.
    RANDOM NUMBERS                = Generate random numbers for 60+
                                    univariate distributions.
    SET RANDOM NUMBER GENERATOR   = Specify which univariate generator
                                    to use.
    MULTIVARIATE NORM RAND NUMB   = Generate multivariate normal random
                                    numbers.
    MULTIVARIATE T RANDOM NUMBERS = Generate multivariate t random
                                    numbers.
    WISHART RANDOM NUMBERS        = Generate random numbers for a
                                    Wishart distribution.
    DIRICHLET RANDOM NUMBERS      = Generate random numbers for a
                                    Dirichlet distribution.
 
Reference:
    "Random Number Generation and Monte Carlo Methods",
    Second Edition, James Gentle, Springer-Verlang, 2003, p. 207.
 
Applications:
    Simulation, Bayesian Analysis
 
Implementation Date:
    2003/10
 
Program:
    dimension 100 columns
    .
    READ MATRIX SIGMA
    1.0   0.5
    0.5   1.0
    END OF DATA
    LET N = 1000
    .
    CHARACTER .
    CHARACTER JUSTIFICATION LEBO
    LINE BLANK
    .
    LET M = MULTIVARIATE UNIFORM RANDOM NUMBERS SIGMA N
    .
    PLOT M1 VS M2

-----MUTCDF (LET)--------------------------------
 
MUTCDF
 
Name:
    MUTCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Muth cumulative distribution function
    with shape parameter beta.
 
Description:
    The standard Muth distribution has the following
    cumulative distribution function:

       F(x;beta) = 1 - EXP[-(1/beta)*(EXP(beta*x) - 1) + beta*x]
                   0 <= beta <= 1; x > 0
 
    with beta denoting the shape parameter.

    This distribution can be generalized with location and
    scale parameters in the usual way using the relation

       F(x;beta,loc,scale) = F((x-loc)/scale;beta,0,1)

Syntax:
    LET <y> = MUTCDF(<x>,<beta>,<loc>,<scale>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed Muth cdf value
              is stored;
          <beta> is a number, parameter, or variable that
              specifies the shape parameter;
          <loc> is a number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable
              that specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = MUTCDF(0.3,0.2)
    LET Y = MUTCDF(X,0.5,0,5)
    PLOT MUTCDF(X,0.7,0,3) FOR X = 0  0.01  5
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MUTCHAZ = Compute the Muth cumulative hazard function.
    MUTHAZ  = Compute the Muth hazard function.
    MUTPDF  = Compute the Muth probability density function.
    MUTPPF  = Compute the Muth percent point function.
    RAYPDF  = Compute the Rayleigh probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    EXPPDF  = Compute the exponential probability density function.
    GAMPDF  = Compute the gamma probability density function.
    EWEPDF  = Compute the exponentiated Weibull probability density
              function.
    B10PDF  = Compute the Burr type 10 probability density function.
 
Reference:
    Leemis and McQuestion (2008), "Univariate Distribution
    Relationships", The Amertican Statistician Vol. 62, No. 1,
    pp. 45-53.

    Muth (1977), "Reliability Models with Positive Memory Derived
    from the Mean Residual Life Function", in "The Theory and
    Applications of Reliability", Eds. Tsokos and Shimi, New York:
    Academic Press Inc., pp. 401-435.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2008/2
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.2
    TITLE BETA = ^BETA
    PLOT MUTCDF(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 0.5
    TITLE BETA = ^BETA
    PLOT MUTCDF(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 0.7
    TITLE BETA = ^BETA
    PLOT MUTCDF(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 1
    TITLE BETA = ^BETA
    PLOT MUTCDF(X,BETA) FOR X = 0.01  0.01  5
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Muth Cumulative Distribution Functions
 
-----MUTCHAZ (LET)--------------------------------
 
MUTCHAZ
 
Name:
    MUTCHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Muth cumulative hazard function with shape
    parameter beta.
 
Description:
    The standard Muth distribution has the following
    cumulative hazard function:

       H(x;beta) = (1/beta)*(EXP(beta*x) - 1) - beta*x
                   0 <= beta <= 1; x > 0
 
    with beta denoting the shape parameter.

    This distribution can be generalized with location and
    scale parameters in the usual way using the relation

       H(x;beta,loc,scale) = H((x-loc)/scale;beta,0,1)

Syntax:
    LET <y> = MUTCHAZ(<x>,<beta>,<loc>,<scale>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed Muth cumulative hazard
              value is stored;
          <beta> is a number, parameter, or variable that
              specifies the shape parameter;
          <loc> is a number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable
              that specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = MUTCHAZ(0.3,0.2)
    LET Y = MUTCHAZ(X,0.5,0,5)
    PLOT MUTCHAZ(X,0.7,0,3) FOR X = 0  0.01  5
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MUTCDF  = Compute the Muth cumulative distribution function.
    MUTHAZ  = Compute the Muth hazard function.
    MUTPDF  = Compute the Muth probability density function.
    MUTPPF  = Compute the Muth percent point function.
    RAYPDF  = Compute the Rayleigh probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    EXPPDF  = Compute the exponential probability density function.
    GAMPDF  = Compute the gamma probability density function.
    EWEPDF  = Compute the exponentiated Weibull probability density
              function.
    B10PDF  = Compute the Burr type 10 probability density function.
 
Reference:
    Leemis and McQuestion (2008), "Univariate Distribution
    Relationships", The Amertican Statistician Vol. 62, No. 1,
    pp. 45-53.

    Muth (1977), "Reliability Models with Positive Memory Derived
    from the Mean Residual Life Function", in "The Theory and
    Applications of Reliability", Eds. Tsokos and Shimi, New York:
    Academic Press Inc., pp. 401-435.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2008/2
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.2
    TITLE BETA = ^BETA
    PLOT MUTCHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 0.5
    TITLE BETA = ^BETA
    PLOT MUTCHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 0.7
    TITLE BETA = ^BETA
    PLOT MUTCHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 1
    TITLE BETA = ^BETA
    PLOT MUTCHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Muth Cumulative Hazard Functions
 
-----MUTHAZ (LET)--------------------------------
 
MUTHAZ
 
Name:
    MUTHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Muth hazard function with shape parameter beta.
 
Description:
    The standard Muth distribution has the following
    hazard function:

       h(x;beta) = EXP(beta*x) - beta
                   0 <= beta <= 1; x > 0
 
    with beta denoting the shape parameter.

    This distribution can be generalized with location and
    scale parameters in the usual way using the relation

       h(x;beta,loc,scale) = (1/scale)*h((x-loc)/scale;beta,0,1)

Syntax:
    LET <y> = MUTHAZ(<x>,<beta>,<loc>,<scale>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed Muth pdf value
              is stored;
          <beta> is a number, parameter, or variable that
              specifies the shape parameter;
          <loc> is a number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable
              that specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = MUTHAZ(0.3,0.2)
    LET Y = MUTHAZ(X,0.5,0,5)
    PLOT MUTHAZ(X,0.7,0,3) FOR X = 0  0.01  5
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MUTCDF  = Compute the Muth cumulative distribution function.
    MUTCHAZ = Compute the Muth cumulative hazard function.
    MUTPDF  = Compute the Muth probability density function.
    MUTPPF  = Compute the Muth percent point function.
    RAYPDF  = Compute the Rayleigh probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    EXPPDF  = Compute the exponential probability density function.
    GAMPDF  = Compute the gamma probability density function.
    EWEPDF  = Compute the exponentiated Weibull probability density
              function.
    B10PDF  = Compute the Burr type 10 probability density function.
 
Reference:
    Leemis and McQuestion (2008), "Univariate Distribution
    Relationships", The Amertican Statistician Vol. 62, No. 1,
    pp. 45-53.

    Muth (1977), "Reliability Models with Positive Memory Derived
    from the Mean Residual Life Function", in "The Theory and
    Applications of Reliability", Eds. Tsokos and Shimi, New York:
    Academic Press Inc., pp. 401-435.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2008/2
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.2
    TITLE BETA = ^BETA
    PLOT MUTHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 0.5
    TITLE BETA = ^BETA
    PLOT MUTHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 0.7
    TITLE BETA = ^BETA
    PLOT MUTHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 1
    TITLE BETA = ^BETA
    PLOT MUTHAZ(X,BETA) FOR X = 0.01  0.01  5
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Muth Hazard Functions
 
-----MUTPDF (LET)--------------------------------
 
MUTPDF
 
Name:
    MUTPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Muth probability density function
    with shape parameter beta.
 
Description:
    The standard Muth distribution has the following
    probability density function:

       f(x;beta) = (EXP(beta*x) - beta)*
                   EXP[-(1/beta)*(EXP(beta*x) - 1) + beta*x]
                   0 <= beta <= 1; x > 0
 
    with beta denoting the shape parameter.

    This distribution can be generalized with location and
    scale parameters in the usual way using the relation

       f(x;beta,loc,scale) = (1/scale)*f((x-loc)/scale;beta,0,1)

Syntax:
    LET <y> = MUTPDF(<x>,<beta>,<loc>,<scale>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable;
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed Muth pdf value
              is stored;
          <beta> is a number, parameter, or variable that
              specifies the shape parameter;
          <loc> is a number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable
              that specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = MUTPDF(0.3,0.2)
    LET Y = MUTPDF(X,0.5,0,5)
    PLOT MUTPDF(X,0.7,0,3) FOR X = 0  0.01  5
 
Note:
    Muth random numbers, probability plots, and goodness
    of fit tests can be generated with the commands:

       LET BETA = <value>
       LET Y = MUTH RANDOM NUMBERS FOR I = 1 1 N
       MUTH PROBABILITY PLOT Y
       MUTH PROBABILITY PLOT Y2 X2
       MUTH PROBABILITY PLOT Y3 XLOW XHIGH
       MUTH KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       MUTH CHI-SQUARE GOODNESS OF FIT Y2 X2
       MUTH CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    The following commands can be used to estimate the beta
    shape parameter for the Muth distribution:

       LET BETA1 = <value>
       LET BETA2 = <value>
       MUTH PPCC PLOT Y
       MUTH PPCC PLOT Y2 X2
       MUTH PPCC PLOT Y3 XLOW XHIGH
       MUTH KS PLOT Y
       MUTH KS PLOT Y2 X2
       MUTH KS PLOT Y3 XLOW XHIGH

    The default values for BETA1 and BETA2 are 0 and 1.

    The probability plot can then be used to estimate the
    location and scale (location = PPA0, scale = PPA1).

    The BOOTSTRAP DISTRIBUTION command can be used to find
    uncertainty intervals for the ppcc and ks plots.
       
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MUTCDF  = Compute the Muth cumulative distribution function.
    MUTCHAZ = Compute the Muth cumulative hazard function.
    MUTHAZ  = Compute the Muth hazard function.
    MUTPPF  = Compute the Muth percent point function.
    RAYPDF  = Compute the Rayleigh probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    EXPPDF  = Compute the exponential probability density function.
    GAMPDF  = Compute the gamma probability density function.
    EWEPDF  = Compute the exponentiated Weibull probability density
              function.
    B10PDF  = Compute the Burr type 10 probability density function.
 
Reference:
    Leemis and McQuestion (2008), "Univariate Distribution
    Relationships", The Amertican Statistician Vol. 62, No. 1,
    pp. 45-53.

    Muth (1977), "Reliability Models with Positive Memory Derived
    from the Mean Residual Life Function", in "The Theory and
    Applications of Reliability", Eds. Tsokos and Shimi, New York:
    Academic Press Inc., pp. 401-435.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2008/2
 
Program 1:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.2
    TITLE BETA = ^BETA
    PLOT MUTPDF(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 0.5
    TITLE BETA = ^BETA
    PLOT MUTPDF(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 0.7
    TITLE BETA = ^BETA
    PLOT MUTPDF(X,BETA) FOR X = 0.01  0.01  5
    .
    LET BETA  = 1
    TITLE BETA = ^BETA
    PLOT MUTPDF(X,BETA) FOR X = 0.01  0.01  5
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Muth Probability Density Functions
 
Program 2:
    let beta = 0.65
    let betasav = beta
    .
    let y = muth random numbers for i = 1 1 200
    let y = 10*y
    let amax = maximum y
    .
    label case asis
    title case asis
    .
    y1label Correlation Coefficient
    x1label Beta
    muth ppcc plot y
    let beta = shape
    justification center
    move 50 6
    text Betahat = ^beta (BETA = ^betasav)
    move 50 2
    text Maximum PPCC = ^maxppcc
    .
    y1label Data
    x1label Theoretical
    char x
    line bl
    muth prob plot y
    move 50 6
    text Location = ^ppa0, Scale = ^ppa1
    char bl
    line so
    .
    y1label Relative Frequency
    x1label
    relative hist y
    limits freeze
    pre-erase off
    line color blue
    plot mutpdf(x,beta,ppa0,ppa1) for x = 0.01 .01 amax
    line color black
    limits 
    pre-erase on
    .
    let ksloc = ppa0
    let ksscale = ppa1
    muth kolmogorov smirnov goodness of fit y

-----MUTPPF (LET)--------------------------------
 
MUTPPF
 
Name:
    MUTPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Muth percent point function with shape
    parameter beta.
 
Description:
    The standard Muth distribution has the following
    cumulative distribution point function:

       F(x;beta) = 1 - EXP[-(1/beta)*(EXP(beta*x) - 1) + beta*x]
                   0 <= beta <= 1; x > 0
 
    with beta denoting the shape parameter.

    The percent point function is computed by numerically
    inverting the cumulative distribution function using a
    bisection method.

    This distribution can be generalized with location and
    scale parameters in the usual way using the relation

       G(p;beta,loc,scale) = loc + scale*G(p;beta,0,1)

Syntax:
    LET <y> = MUTPPF(<p>,<beta>,<loc>,<scale>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, parameter, or variable in the
              interval (0,1);
          <y> is a variable or a parameter (depending on what
              <p> is) where the computed Muth ppf value
              is stored;
          <beta> is a number, parameter, or variable that
              specifies the shape parameter;
          <loc> is a number, parameter, or variable that
              specifies the location parameter;
          <scale> is a positive number, parameter, or variable
              that specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = MUTPPF(0.95,0.2)
    LET Y = MUTPPF(P,0.5,0,5)
    PLOT MUTPPF(P,0.7,0,3) FOR P = 0.01  0.01  0.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MUTCDF  = Compute the Muth cumulative distribution function.
    MUTCHAZ = Compute the Muth cumulative hazard function.
    MUTHAZ  = Compute the Muth hazard function.
    MUTPDF  = Compute the Muth probability density function.
    RAYPDF  = Compute the Rayleigh probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    EXPPDF  = Compute the exponential probability density function.
    GAMPDF  = Compute the gamma probability density function.
    EWEPDF  = Compute the exponentiated Weibull probability density
              function.
    B10PDF  = Compute the Burr type 10 probability density function.
 
Reference:
    Leemis and McQuestion (2008), "Univariate Distribution
    Relationships", The Amertican Statistician Vol. 62, No. 1,
    pp. 45-53.

    Muth (1977), "Reliability Models with Positive Memory Derived
    from the Mean Residual Life Function", in "The Theory and
    Applications of Reliability", Eds. Tsokos and Shimi, New York:
    Academic Press Inc., pp. 401-435.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2008/2
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.2
    TITLE BETA = ^BETA
    PLOT MUTPPF(P,BETA) FOR P = 0.01  0.01  0.99
    .
    LET BETA  = 0.5
    TITLE BETA = ^BETA
    PLOT MUTPPF(P,BETA) FOR P = 0.01  0.01  0.99
    .
    LET BETA  = 0.7
    TITLE BETA = ^BETA
    PLOT MUTPPF(P,BETA) FOR P = 0.01  0.01  0.99
    .
    LET BETA  = 1
    TITLE BETA = ^BETA
    PLOT MUTPPF(P,BETA) FOR P = 0.01  0.01  0.99
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Muth Percent Point Functions
 
-------------------------------------------------------------



































































-------------------------  *N*  ZZZZZ--------------------
 
-----NAME-------------------------------------------------------
 
NAME
 
Name:
    NAME
 
Type:
    Support Command
 
Purpose:
    Specifies an additional name to be assigned to an already-existing
    variable.
 
Description:
    This is useful, for example, if the analyst has written a generic
    sub-program which makes reference to, say, X and Y, while the
    variable names in the main program are, say, PRESSURE and TEMP.
    The NAME command is efficient in that it does not duplicate the
    data.  Thus NAME X PRESSURE will not duplicate the data already
    existing in the variable PRESSURE (as would LET X = PRESSURE).  It
    merely adds the additional name X by which that same data in
    PRESSURE can be subsequently referred.
 
Syntax:
    NAME   <name 1>   <name 2>
    where <name 1> is the name of an already-existing variable;
    and   <name 2> is the desired additional name by which that
                   variable can be referred.
 
Examples:
    NAME PRESSURE Y
 
Note:
    The name list can be extended in pairs; thus
       NAME PRESSURE Y TEMP X CONC Z
    is equivalent to
       NAME PRESSURE Y
       NAME TEMP X
       NAME CONC Y
 
Default:
    None
 
Synonyms:
    RENAME
 
Related Commands:
    LET       = Copies variables (and many other operations).
    STATUS    = Displays dimension, variables, parameters, functions,
                etc.
    DELETE    = Deletes (all or part of) a variable.
    DIMENSION = Changes internal workspace size.
    CALL      = Executes the commands in a "macro" file.
 
Applications:
    Data Management
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----NAME TABLE (PROBE)--------------------------------------------
 
NAME TABLE
 
Name:
    NAME TABLE (PROBE)
 
Type:
    Set Subcommand
 
Purpose:
    Extract information about Dataplot's internal name table.
 
Description:
    This command is used to display the current status of the internal
    Dataplot name table.  The name table includes the names of all
    variables, parameters, strings, functions, and matrices.

    This command is primarily of interest to the Dataplot developers for
    debugging purposes.  However, it can be used by any Dataplot user.
    This command is not supported for the SET command (i.e., you cannot
    use it to modify the name table).

    Specifically, this command returns the following information

        I           - the index number
        IHNAME(I)   - characters 1 to 4 of the I-th name
        IHNAM2(I)   - characters 5 to 8 of the I-th name
        IN(I)       - for variable names, this contains the number
                      of observations for the variable.  For parameters
                      and strings, this value should be either 0 or 1.
        VALUE(I)    - for parameters, this is the value of the parameter.
                      For strings and user defined variables, this should
                      be 0.  For the internally defined variables (PRED,
                      RES, YPLOT, XPLOT, X2PLOT, and TAGPLOT), it defines
                      the column in the data workspace.

Syntax:
    PROBE NAME TABLE
 
Examples:
    PROBE NAME TABLE

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    FILE SWITCHES     = Probe the values for certain file names and the
                         associated unit numbers and file status.
    BUG SWITCHES      = Set debug switches.
    SYSTEM LIMITS     = Parameters defining certain Dataplot limits.
    MACHINE CONSTANTS = Return the values for certain machine constants.
 
Applications:
    Debugging
 
Implementation Date:
    Pre-1987
 
Program:
    SKIP 25
    READ BERGER1.DAT Y X BAT
    LET STRING F = BERGER1.DAT
    LET N = SIZE Y
    .
    PROBE NAME TABLE
 
-----NAND-------------------------------------------------------
 
NAND
 
Name:
    NAND
 
Note:
    ***** This command is not currently operational *****
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Draws a Nand Gate (a logical device used in electronic circuit
    diagrams).
 
Description:
    The 2 pairs of coordinates define the the (x,y) values for the
    middle back and the middle front (respectively) of the Nand Gate.
 
Syntax:
    NAND   <x1>   <y1>   <x2>   <y2>
    where <x1> is a number or parameter in the decimal range 0 to 100
               that specifies the x coordinate for the middle back of
               the Nand Gate;
          <y1> is a number or parameter in the decimal range 0 to 100
               that specifies the y coordinate for the middle back of
               the Nand Gate;
          <x2> is a number or parameter in the decimal range 0 to 100
               that specifies the x coordinate for the middle front
               of the Nand Gate;
    and   <y2> is a number or parameter in the decimal range 0 to 100
               that specifies the y coordinate for the middle front of
               the Nand Gate;
 
Examples:
    NAND 50 50 60 50
    NAND 50 50 60 60
    NAND 20 20 25 20
 
Note:
    The line style (i.e., SOLID, DASH), line color, and line thickness
    are controlled by the first entry of the LINE, LINE COLOR, and
    LINE THICKNESS commands respectively.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    AND              = Draws an and gate.
    OR               = Draws an or gate.
    NOR              = Draws a nor gate.
    MOVE             = Moves to a point.
    DRAW             = Draws a line.
    LINES            = Sets the line type for figures and plot lines.
    LINE THICKNESSES = Sets the line thickness for figures and plot
                       lines.
    LINE COLOR       = Sets the line colors for figures and plot lines.
    CROSS-HAIR       = Activates and reads the cross-hair.
    TEXT             = Writes a text string.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----NBCDF (LET)--------------------------------
 
NBCDF
 
Name:
    NBCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the negative binomial cumulative distribution function.
 
Description:
    The negative binomial distribution is used when there are exactly
    two mutually exclusive outcomes of a trial.  These outcomes are
    often called successes and failures.  The negative binomial
    probability distribution is the probability of obtaining the kth
    success on the xth trial (the binomial distribution is the
    probability of x successes in n trials).  It has the following
    probability density function:
       nb(x;p,k) = ((x-1) (k-1))*p**k*(1-p)**(x-k)
    where p is the probability of a success on a single trial and
    ((x-1) (k-1)) is the combinatorial function of x-1 things taken
    k-1 at a time.  It has the formula:
       ((x-1) (k-1)) = (x-1)!/((k-1)!*((x-1)-(k-1))!)
    The cumulative distribution is the probability of obtaining the
    kth success on trials 0 through x.  It is the sum of the negative
    binomial probabilities of 0 to x.
 
Syntax:
    LET <y2> = NBCDF(<y1>,<p>,<k>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a non-negative integer variable, number, or
               parameter specifying the number of trials;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed negative binomial cdf value is saved;
          <p> is a number or parameter between 0 and 1 that is the
               probability of success on a single trial;
          <k> is the number of successes;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NBCDF(3,0.5,10)
    LET X2 = NBCDF(X1,0.3,25))
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NBPDF  = Compute the negative binomial probability density
             function.
    NBPPF  = Compute the negative binomial percent point function.
    BINCDF = Compute the binomial cumulative distribution function.
    BINPDF = Compute the binomial probability density function.
    BINPPF = Compute the binomial percent point function.
    POIPDF = Compute the Poisson probability density function.
    POICDF = Compute the Poisson cumulative distribution function.
    POIPPF = Compute the Poisson percent point function.
    GEOCDF = Compute the geometric cumulative distribution function.
    GEOPDF = Compute the geometric probability density function.
    GEOPPF = Compute the geometric percent point function.
 
Reference:
    "Discrete Univariate Distributions", Johnson and Kotz,
    Houghton Mifflin, 1970 (chapter 5).
 
Applications:
    XX
 
Implementation Date:
    94/4
 
Program:
    YLIMITS 0 1
    MAJOR YTIC NUMBER 6
    MINOR YTIC NUMBER 1
    YTIC DECIMAL 1
    XLIMITS 0 50
    XTIC OFFSET 0.5 0.5
    LINE BLANK
    SPIKE ON
    SPIKE LINE DASH
    CHARACTER CIRCLE
    CHARACTER FILL ON
    CHARACTER SIZE 1.2
    TITLE AUTOMATIC
    X1LABEL NUMBER OF TRIALS TILL FIRST SUCCESS
    Y1LABEL PROBABILITY
    PLOT NBCDF(X,0.2,5) FOR X = 0 1 50
 
-----NBPDF (LET)--------------------------------
 
NBPDF
 
Name:
    NBPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the negative binomial probability density function.
 
Description:
    The negative binomial distribution is used when there are exactly
    two mutually exclusive outcomes of a trial.  These outcomes are
    often called successes and failures.  The negative binomial
    probability distribution is the probability of obtaining the kth
    success on the xth trial (the binomial distribution is the
    probability of x successes in n trials).  It has the following
    probability mass function:

       nb(x;p,k) = ((x-1) (k-1))*p**k*(1-p)**(x-k)

    where p is the probability of a success on a single trial and
    ((x-1) (k-1)) is the combinatorial function of x-1 things taken
    k-1 at a time.  It has the formula:

       ((x-1) (k-1)) = (x-1)!/((k-1)!*((x-1)-(k-1))!)
 
Syntax:
    LET <y2> = NBPDF(<y1>,<p>,<k>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a non-negative integer variable, number, or
               parameter specifying the number of trials;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed negative binomial pdf value is saved;
          <p> is a number or parameter between 0 and 1 that is the
               probability of success on a single trial;
          <k> is the number of successes;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NBPDF(3,0.5,10)
    LET X2 = NBPDF(X1,0.3,25))
 
Note:
    For a number of commands utilizing the negative binomial
    distribution, it is convenient to bin the data.  There are
    two basic ways of binning the data.

      1) For some commands (histograms, maximum likelihood
         estimation), bins with equal size widths are
         required.  This can be accomplished with the
         following commands:

            LET AMIN = MINIMUM Y
            LET AMAX = MAXIMUM Y
            LET AMIN2 = AMIN - 0.5
            LET AMAX2 = AMAX + 0.5
            CLASS MINIMUM AMIN2
            CLASS MAXIMUM AMAX2
            CLASS WIDTH 1
            LET Y2 X2 = BINNED

      2) For some commands, unequal width bins may be
         helpful.  In particular, for the chi-square goodness
         of fit, it is typically recommended that the minimum
         class frequency be at least 5.  In this case, it may
         be helpful to combine small frequencies in the tails.
         Unequal class width bins can be created with the
         commands

            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = INTEGER FREQUENCY TABLE Y

         If you already have equal width bins data, you can
         use the commands
         
            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = COMBINE FREQUENCY TABLE Y2 X2

         The MINSIZE parameter defines the minimum class
         frequency.  The default value is 5.

Note:
    You can generate negative binomial random numbers,
    probability plots, and chi-square goodness of fit tests
    with the following commands:

       LET P = <value>
       LET K = <value>
       LET Y = NEGATIVE BINOMIAL RANDOM NUMBERS FOR I = 1 1 N

       NEGATIVE BINOMIAL PROBABILITY PLOT Y
       NEGATIVE BINOMIAL PROBABILITY PLOT Y2 X2
       NEGATIVE BINOMIAL PROBABILITY PLOT Y3 XLOW XHIGH

       NEGATIVE BINOMIAL CHI-SQUARE GOODNESS OF FIT Y
       NEGATIVE BINOMIAL CHI-SQUARE GOODNESS OF FIT Y2 X2
       NEGATIVE BINOMIAL CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    There are two cases to consider when fitting the
    negative binomial distribution to a set of data.

       1) In the first case, we assume that k is known
          and fixed.  For example, in a designed study we
          may fix the value of k in advance.

       2) In the second case, we assume that k is unknown.

    For the k fixed and known case, the maximum likelihood
    estimate of p is:

       k/(xbar+k)

    with xbar denoting the sample mean.  A bias corrected
    maximum likelihood estimate of p is:

        (k-1)/(xbar+k-1)  k >= 2

    The variance of this estimate and a confidence interval
    for p are given on pp. 89-90 of Berry.

    You may enter the known value of k as shown below.  If
    you omit this value, the method of moments estimate of
    k will be used.

    For the k unknown case, the method of moment estimates are:

        khat = xbar^2/(s^2 - xbar)
        phat = (s^2/xbar) - 1

    For the maximum likelihood estimates, we first estimate
    k by solving the following equation (the moment
    estimator of k is used as the starting value):

       LOG(khat) - LOG(xbar + khat) - psi(khat) +
       (1/n)*SUM[i=1 to n][psi(x(i)+khat)] = 0

    The maximum likelihood estimate of p is then

       k/(xbar+k)

    As with the k known case, a bias corrected estimate of p is

        (k-1)/(xbar+k-1  k >= 2)

    To obtain the maximum likelihood estimates of p and k
    in Dataplot, enter the commands

        LET K = <value>
        NEGATIVE BINOMIAL MAXIMUM LIKELIHOOD Y

    You can generate estimates of p and k based on the
    maximum ppcc value or the minimum chi-square goodness of fit
    with the commands

        LET P1 = <value>
        LET P2 = <value>
        LET K1 = <value>
        LET K2 = <value>
        NEGATIVE BINOMIAL KS PLOT Y
        NEGATIVE BINOMIAL KS PLOT Y2 X2
        NEGATIVE BINOMIAL KS PLOT Y3 XLOW XHIGH
        NEGATIVE BINOMIAL PPCC PLOT Y
        NEGATIVE BINOMIAL PPCC PLOT Y2 X2
        NEGATIVE BINOMIAL PPCC PLOT Y3 XLOW XHIGH

    The default values of p1 and p2 are 0.05 and 0.95,
    respectively.  The default values for k1 and k2 are
    1 and 25, respectively.  For the k known case, simply
    set k1 and k2 equal (to the known value).

    Due to the discrete nature of the percent point function
    for discrete distributions, the ppcc plot will not be smooth.
    For that reason, if there is sufficient sample size the
    KS PLOT (i.e., the minimum chi-square value) is typically
    preferred.  However, it may sometimes be useful to perform
    one iteration of the PPCC PLOT to obtain a rough idea of an
    appropriate neighborhood for the shape parameters since the
    minimum chi-square statistic can generate extremely large
    values for non-optimal values of the shape parameters.
    Also, since the data is integer values, one of the binned
    forms is preferred for these commands.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NBCDF  = Compute the negative binomial cumulative distribution
             function.
    NBPPF  = Compute the negative binomial percent point function.
    BINCDF = Compute the binomial cumulative distribution function.
    BINPDF = Compute the binomial probability mass function.
    BINPPF = Compute the binomial percent point function.
    POIPDF = Compute the Poisson probability mass function.
    POICDF = Compute the Poisson cumulative distribution function.
    POIPPF = Compute the Poisson percent point function.
    GEOCDF = Compute the geometric cumulative distribution function.
    GEOPDF = Compute the geometric probability mass function.
    GEOPPF = Compute the geometric percent point function.
    GNBPDF = Compute the generalized negative binomial probability
             mass function.
 
Reference:
    Johnson, Kotz, and Kemp (1992), "Univariate Discrete
    Distributions", Second Edition, Wiley, chapter 5.

    Evans, Hastings, and Peacock (2000), "Statistical
    Distributions", Third Edition, Wiley, pp. 109-113.

    Karl Bury (1999), "Statistical Distributions in
    Engineering", Cambridge University Press, chapter xx.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/4
 
Program:
    XLIMITS 0 50
    XTIC OFFSET 0.5 0.5
    LINE BLANK
    SPIKE ON
    SPIKE LINE DASH
    CHARACTER CIRCLE
    CHARACTER FILL ON
    CHARACTER SIZE 1.2
    TITLE AUTOMATIC
    X1LABEL NUMBER OF TRIALS TILL FIRST SUCCESS
    Y1LABEL PROBABILITY
    PLOT NBPDF(X,0.2,5) FOR X = 0 1 50
 
-----NBPPF (LET)--------------------------------
 
NBPPF
 
Name:
    NBPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the negative binomial percent point function.
 
Description:
    The negative binomial distribution is used when there are exactly
    two mutually exclusive outcomes of a trial.  These outcomes are
    often called successes and failures.  The negative binomial
    probability distribution is the probability of obtaining the kth
    success on the xth trial (the binomial distribution is the
    probability of x successes in n trials).  It has the following
    probability density function:
       nb(x;p,k) = ((x-1) (k-1))*p**k*(1-p)**(x-k)
    where p is the probability of a success on a single trial and
    ((x-1) (k-1)) is the combinatorial function of x-1 things taken
    k-1 at a time.  It has the formula:
       ((x-1) (k-1)) = (x-1)!/((k-1)!*((x-1)-(k-1))!)
    The percent point function is the inverse of the cumulative
    distribution function.  The cumulative distribution sums the
    probability from 0 to the given x value.  The percent point
    function takes a cumulative probability value and computes the
    corresponding x value.
 
    The input value is a real number between 0 and 1 (since it
    corresponds to a probability).
 
Syntax:
    LET <y2> = NBPPF(<y1>,<p>,<n>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable, a number, or a parameter in the range 0
              to 1;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed negative binomial ppf value is saved;
          <p> is a number or parameter between 0 and 1 that is the
               probability of success on a single trial;
          <k> is the number of successes;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NBPPF(0.9,0.5,50)
    LET X2 = NBPPF(X1,0.7,100)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NBCDF  = Compute the negative binomial cumulative distribution
             function.
    NBPDF  = Compute the negative binomial probability density
             function.
    BINCDF = Compute the binomial cumulative distribution function.
    BINPDF = Compute the binomial probability density function.
    BINPPF = Compute the binomial percent point function.
    POIPDF = Compute the Poisson probability density function.
    POICDF = Compute the Poisson cumulative distribution function.
    POIPPF = Compute the Poisson percent point function.
    GEOCDF = Compute the geometric cumulative distribution function.
    GEOPDF = Compute the geometric probability density function.
    GEOPPF = Compute the geometric percent point function.
 
Reference:
    "Discrete Univariate Distributions", Johnson and Kotz, 1969.
 
Applications:
    XX
 
Implementation Date:
    94/4
 
Program:
    XLIMITS 0 1
    MAJOR XTIC NUMBER 6
    MINOR XTIC NUMBER 1
    XTIC DECIMAL 1
    TITLE AUTOMATIC
    X1LABEL PROBABILITY
    PLOT NBPPF(X,0.2,5) FOR X = 0.01 0.01 0.99
 
-----NCBCDF (LET)--------------------------------
 
NCBCDF
 
Name:
    NCBCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the non-central beta cumulative distribution function with
    shape parameters A and B and non-centrality parameter LAMBDA.
 
Description:
    The non-central beta distribution has the following cumulative
    distribution function:
      f(x,a,b,lambda) = INTEGRAL((EXP(-lambda/2)*(lambda/2)**j/j!)*
            Ix(a+j,b)      0 <= x <= 1, a > 0, b > 0, lambda >= 0
    where the integral is from j equals zero to infinity and Ix is the
    incomplete beta function (see the documentation for the BETAI
    command for details on this function).  Since this is a probability
    function, the returned value will be between 0 and 1.
 
Syntax:
    LET <y> = NCBCDF(<x>,<a>,<b>,<l>) <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing values
               between 0 and 1;
          <a> is a positive number, parameter, or variable that
               specifies the first shape parameter;
          <b> is a positive number, parameter, or variable that
               specifies the second shape parameter;
          <l> is a non-negative number, parameter, or variable that
               specifies the non-centrality parameter;
          <y> is a variable or a parameter (depending on what <x>,
               <a>, <b>, and <l> are) where the computed cdf value is
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NCBCDF(0.3,10,8,1)
    LET A = NCBCDF(A1,10,8,1.5)
    LET X2 = NCBCDF(X1,2,6,2)

Note:
    DATAPLOT uses algorithm AS 226 (see the REFERENCE section below)
    obtained from the statlib archive to compute the non-central beta
    cdf.  It uses the DBETAI and DLNGAM routines from the SLATEC
    library rather than the corresponding algorithms from the 
    Applied Statistics series to compute the log gamma and incomplete
    beta functions.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NCBPPF = Compute the non-central beta percent point function.
    NCBPDF = Compute the non-central beta probability density
             function.
    BETPDF = Compute the beta probability density function.
    NCFCDF = Compute the non-central F cumulative distribution
             function.
    NCTCDF = Compute the non-central t cumulative distribution
             function.
    NCCCDF = Compute the non-central chi-square cumulative distribution
             function.
    GAMPDF = Compute the gamma probability density function.
    NORPDF = Compute the normal probability density function.
 
Reference:
    "Computing Noncentral Beta Probabilities", Lenth, Applied 
    Statistics, Vol. 39, No. 2, 1987, pp. 241-244.

    "Continuous Univariate Distributions--Volume II", Second
    Edition, Johnson, Kotz, and Balakrishnan, Wiley, 1994,
    pp. 502-504.

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000 (chapter 5).
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/9
 
Program:
    TITLE AUTOMATIC
    PLOT NCBCDF(X,2,4,1) FOR X = 0 0.01 1
 
-----NCBPDF (LET)--------------------------------
 
NCBPDF
 
Name:
    NCBPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the non-central beta probability density function with
    shape parameters A and B and non-centrality parameter LAMBDA.
 
Description:
    IF CHSPDF(x;A) and CHSPDF(x;B) are mutually independent
    chi-square random variables, then

        CHSPDF(x;A)/*CHSPDF(x;A) + CHSPDF(X;B))

    has a beta distribution with shape parameters A/2 and B/2.

    If CHSPDF(x;A) is replaced with a non-central chi-square
    random variable, NCCPDF(x;A,LAMBDA), with non-centrality parameter
    LAMBDA, then

        NCCPDF(x;A,LAMBDA)/*NCCPDF(x;A,LAMBDA) + CHSPDF(X;B))

    has a non-central beta distribution with shape parameters
    A and B and non-centrality parameter LAMBDA.

    Dataplot computes the non-central beta probability density
    function by numerically integrating the non-central beta
    cumulative distribution function.

    The non-central beta probability density function can be
    generalized with location and scale parameters in the usual way.

Syntax:
    LET <y> = NCBPDF(<x>,<a>,<b>,<l>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing values
               between 0 and 1;
          <a> is a positive number, parameter, or variable that
               specifies the first shape parameter;
          <b> is a positive number, parameter, or variable that
               specifies the second shape parameter;
          <l> is a non-negative number, parameter, or variable that
               specifies the non-centrality parameter;
          <loc> is a number or parameter that specifies the location
               parameter;
          <scale> is a number or parameter that specifies the scale
               parameter;
          <y> is a variable or a parameter (depending on what <x>,
               <a>, <b>, and <l> are) where the computed pdf value is
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The location and scale parameters are optional.

Examples:
    LET A = NCBPDF(0.3,10,8,1)
    LET A = NCBPDF(A1,10,8,1.5)
    LET X2 = NCBPDF(X1,2,6,2)

Note:
    DATAPLOT uses algorithm AS 226 (see the REFERENCE section below)
    obtained from the statlib archive to compute the non-central beta
    cdf.  It uses the DBETAI and DLNGAM routines from the SLATEC
    library rather than the corresponding algorithms from the 
    Applied Statistics series to compute the log gamma and incomplete
    beta functions.

    Dataplot uses the DIFF routine from the Slatec library to compute
    the numerical derivative.

Note:
    To generate non-central beta random numbers, enter
    the commands

        LET ALPHA = <value>
        LET BETA = <value>
        LET LAMBDA = <value>
        LET Y = NON-CENTRAL BETA RANDOM NUMBERS ...
                FOR I = 1 1 N

    To generate an non-central beta probability plot
    or an non-central beta Kolmogorov-Smirnov or
    beta goodness of fit test, enter the following commands

        LET ALPHA = <value>
        LET BETA = <value>
        LET LAMBDA = <value>
        NON-CENTRAL BETA PROBABILITY PLOT Y
        NON-CENTRAL BETA KOLMOGOROV SMIRNOV ...
                   GOODNESS OF FIT Y
        NON-CENTRAL BETA CHI-SQUARE GOODNESS OF FIT Y

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NCBCDF = Compute the non-central beta cumulative distributiuon
             function.
    NCBPPF = Compute the non-central beta percent point function.
    BETPDF = Compute the beta probability density function.
    NCFPDF = Compute the non-central F probability density function.
    NCTPDF = Compute the non-central t probability density function.
    NCCPDF = Compute the non-central chi-square probability density
             function.
    GAMPDF = Compute the gamma probability density function.
    NORPDF = Compute the normal probability density function.
 
Reference:
    "Computing Noncentral Beta Probabilities", Lenth, Applied 
    Statistics, Vol. 39, No. 2, 1987, pp. 241-244.

    "Continuous Univariate Distributions--Volume II", Second
    Edition, Johnson, Kotz, and Balakrishnan, Wiley, 1994,
    pp. 502-504.

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, chapter 5.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2004/5
 
Program:
    LABEL CASE ASIS
    Y1LABEL Probability
    X1LABEL X
    X1LABEL DISPLACEMENT 12
    Y1LABEL DISPLACEMENT 12
    TITLE DISPLACEMENT 2
    Y1LIMITS 0 2
    Y1TIC OFFSET 0 0.2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    MULTIPLOT 2 2
    TITLE LAMBDA = 0
    PLOT NCBPDF(X,2,4,0) FOR X = 0.01  0.01  0.99
    TITLE LAMBDA = 1
    PLOT NCBPDF(X,2,4,1) FOR X = 0.01  0.01  0.99
    TITLE LAMBDA = 2
    PLOT NCBPDF(X,2,4,2) FOR X = 0.01  0.01  0.99
    TITLE LAMBDA = 5
    PLOT NCBPDF(X,2,4,5) FOR X = 0.01  0.01  0.99
    END OF MULTIPLOT
    CASE ASIS
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Non-Central Beta PDF (A = 2, B = 4)
 
-----NCBPPF (LET)--------------------------------
 
NCBPPF
 
Name:
    NCBPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the non-central beta percent point function with shape
    parameters A and B and non-centrality parameter lambda.
 
Description:
    The percent point function is the inverse of the cumulative
    distribution function.  The cumulative distribution sums the
    probability from 0 to the given x value.  The percent point
    function takes a cumulative probability value and computes the
    corresponding x value.  See the documentation for the NCBCDF
    command for a description of the non-central beta cumulative
    distribution function.
 
Syntax:
    LET <y> = NCBPPF(<p>,<a>,<b>,<l>) <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, parameter, or variable containing values
               between 0 and 1;
          <a> is a positive number, parameter, or variable that
               specifies the first shape parameter;
          <b> is a positive number, parameter, or variable that
               specifies the second shape parameter;
          <l> is a non-negative number, parameter, or variable that
               specifies the non-centrality parameter;
          <y> is a variable or a parameter (depending on what <p>,
               <a>, <b>, and <l> are) where the computed ppf value is
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NCBPPF(0.9,10,8,1)
    LET X2 = NCBPPF(X1,10,8,2)
 
Note:
    DATAPLOT uses a bisection method to compute the non-central beta
    ppf value.  The algorithm for the central beta distribution is 
    given in the Kennedy and Gentle book (see the REFERENCE section
    below).  The algorithm for the non-central beta distribution is
    similar.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NCBCDF = Compute the non-central beta cumulative distribution
             function.
    BETCDF = Compute the beta cumulative distribution function.
    BETPDF = Compute the beta probability density function.
    BETPPF = Compute the beta percent point function.
    NCFCDF = Compute the non-central F cumulative distribution
             function.
    NCFPPF = Compute the non-central F percent point function.
    NCTCDF = Compute the non-central t cumulative distribution
             function.
    NCTPPF = Compute the non-central t percent point function.
    NCCCDF = Compute the non-central chi-square cumulative distribution
             function.
    NCCPPF = Compute the non-central chi-square percent point function.
    GAMCDF = Compute the gamma cumulative distribution function.
    GAMPDF = Compute the gamma probability density function.
    GAMPPF = Compute the gamma percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
 
Reference:
    "Computing Noncentral Beta Probabilities", Lenth, Applied 
    Statistics, Vol. 39, No. 2, 1987, pp. 241-244.

    "Continuous Univariate Distributions--Volume II", Second
    Edition, Johnson, Kotz, and Balakrishnan, Wiley, 1994,
    pp. 502-504.

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000 (chapter 5).
 
    "Statistical Computing", Kennedy and Gentle, Marcel-Dekker, 
    1978 (chapter 5).

Applications:
    Distributional Modeling
 
Implementation Date:
    1994/9
 
Program:
    TITLE AUTOMATIC
    PLOT NCBPPF(X,4,2,1) FOR X = 0.01 .01 0.99
 
-----NCCCDF (LET)------------------------------------------
 
NCCCDF
 
Name:
    NCCCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the non-central chi-square cumulative distribution
    function with degrees of freedom parameters v and with
    non-centrality parameter delta.
 
Description:
    The non-central chi-square distribution with degrees of freedom
    v and non-centrality parameter delta is the sum of v independent
    normal distributions with mean delta and standard deviation 1.
    The functional forms of the density and distribution are given
    in the references given below (see REFERENCE).  This distribution
    is sometimes needed in the calculation of the power of a test.

    The cumulative distribution is the area from negative infinity to
    x.  Since this is a probability function, the returned value will
    be between 0 and 1.
 
Syntax:
    LET <y2> = NCCCDF(<y1>,<v>,<delta>) 
                        <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a positive number, variable or a parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed cdf value is stored;
          <v> is a positive number, parameter or variable that
               specifies the degrees of freedom parameter;
          <delta> is a non-negative number, parameter or variable that
               specifies the first non-centrality parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NCCCDF(0.7,1,1)
    LET A = NCCCDF(3,10,10)
 
Note:
    DATAPLOT uses algorithm AS 170 (see the REFERENCE section below)
    obtained from the statlib archive to compute the non-central
    chi-square cdf.  It uses the DGAMI and DLNGAM routines from the
    SLATEC library rather than the corresponding algorithms from the 
    Applied Statistics series to compute the log gamma and incomplete
    gamma functions.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NCCNCP = Compute the non-central chi-square non-centrality
             parameter function.
    NCCPPF = Compute the non-central chi-square percent point function.
    CHSPDF = Compute the chi-square probability density function.
    NCFCDF = Compute the non-central F cumulative distribution
             function.
    NCBCDF = Compute the non-central beta cumulative distribution
             function.
    NCTCDF = Compute the non-central t cumulative distribution
             function.
    NORPDF = Compute the normal probability density function.
 
Reference:
    "Computation of Probability and Non-centrality Parameter of a
    Non-central Chi-squared Distribution", Narula and Desu, Applied
    Statistics, Vol. 30, No. 3, 1981, pp. 349-352.

    "Continuous Univariate Distributions--Volume II", Second
    Edition, Johnson, Kotz, and Balakrishnan, Wiley, 1994,
    chapter 29.

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 58-61.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/9
 
Program:
    TITLE AUTOMATIC
    PLOT NCCCDF(X,10,1) FOR X = 0.1 0.2 20
 
-----NCCNCP (LET)------------------------------------------
 
NCCNCP
 
Name:
    NCCNCP (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the non-centrality parameter of a non-central chi-square
    distribution with degrees of freedom parameters v given the 
    cumulative distribution function value.
 
Description:
    The non-central chi-square distribution with degrees of freedom
    v and non-centrality parameter delta is the sum of v independent
    normal distributions with mean delta and standard deviation 1.
    The functional forms of the density and distribution are given
    in the references given below (see REFERENCE).  The DATAPLOT 
    function NCCCDF can be used to compute the cumulative distribution
    function value (given the degrees of freedom and non-centrality
    parameter).  The NCCNCP function computes the non-centrality
    parameter given the degrees of freedom and the cumulative
    distribution function value.  This is sometimes useful in sample
    size calculations.
 
Syntax:
    LET <y2> = NCCNCP(<y1>,<v>,<cdf>) 
                        <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a positive number, variable or a parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed non-centrality parameter value is
               stored;
          <v> is a positive number, parameter or variable that
               specifies the degrees of freedom parameter;
          <cdf> is a number, parameter or variable in the interval
               (0,1) that specifies the cdf value;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NCCNCP(0.7,1,0.95)
    LET A = NCCNCP(3,10,.90)
 
Note:
    DATAPLOT uses algorithm AS 170 (see the REFERENCE section below)
    obtained from the statlib archive to compute the non-central
    chi-square non-centrality parameter.  It uses the DGAMI and DLNGAM
    routines from the SLATEC library rather than the corresponding
    algorithms from the Applied Statistics series to compute the log
    gamma and incomplete gamma functions.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NCCCDF = Compute the non-central chi-square cumulative distribution
             function.
    NCCPPF = Compute the non-central chi-square percent point function.
    CHSPDF = Compute the chi-square probability density function.
    CHSPPF = Compute the chi-square percent point function.
    CHSCDF = Compute the chi-square cumulative distribution function.
    NCFCDF = Compute the non-central F cumulative distribution
             function.
    NCFPPF = Compute the non-central F percent point function.
    NCBCDF = Compute the non-central beta cumulative distribution
             function.
    NCBPPF = Compute the non-central beta percent point function.
    NCTCDF = Compute the non-central t cumulative distribution
             function.
    NCTPPF = Compute the non-central t percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
 
Reference:
    "Computation of Probability and Non-centrality Parameter of a
    Non-central Chi-squared Distribution", Narula and Desu, Applied
    Statistics, Vol. 30, No. 3, 1981, pp. 349-352.

    "Continuous Univariate Distributions--Volume II", Second
    Edition, Johnson, Kotz, and Balakrishnan, Wiley, 1994,
    chapter 29.

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 58-61.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/9
 
Program:
    TITLE AUTOMATIC
    PLOT NCCNCP(2,10,X) FOR X = 0.01 0.01 0.99
 
-----NCCPDF (LET)------------------------------------------
 
NCCPDF
 
Name:
    NCCPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the non-central chi-square cumulative distribution
    function with degrees of freedom parameters v and with
    non-centrality parameter delta.
 
Description:
    If U1, U2, ...., Uv are v independent standard normal random
    variables, then 

       SUM[i=1 to v][U(i)**2]

    follows a central chi-square distribution.

    This can be generalized with

       SUM[i=1 to v][(U(i) + delta(i))**2]

    That is, the normal random variable U(i) has a location parameter
    delta(i).  The above sum follows a non-central chi-square
    distribution with non-centrality parameter

       delta = SUM[i=1 to v][delta(i)]

    The probability density can be given as

       f(x;nu,delta) = EXP[-(delta+x)/2]*(1/2)*(x/delta)**((v-2)/4)*
                       I((v-2)/2)(SQRT(delta*x))
                       x, nu > 0; delta >= 0

    with nu and delta denoting the shape parameters and I(a)(x)
    denoting the modified Bessel function of the first kind of
    order a.

    The non-central chi-square probability density function can be
    generalized with location and scale parameters in the usual way.

    The non-central chi-square distribution is also referred to as
    the Rayleigh, Rayleigh-Rice, or Rice distribution in the
    literature.
 
Syntax:
    LET <y> = NCCPDF(<x>,<v>,<delta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a positive number, variable or a parameter;
          <v> is a positive number, parameter or variable that
              specifies the degrees of freedom parameter;
          <delta> is a non-negative number, parameter or variable that
              specifies the non-centrality parameter;
          <loc> is a number or parameter that specifies the location
               parameter;
          <scale> is a number or parameter that specifies the scale
               parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The location and scale parameters are optional.

Examples:
    LET A = NCCPDF(0.7,1,1)
    LET A = NCCPDF(3,10,10)
 
Note:
    DATAPLOT uses algorithm AS 170 (see the REFERENCE section below)
    obtained from the statlib archive to compute the non-central
    chi-square cdf.  It uses the DGAMI and DLNGAM routines from the
    SLATEC library rather than the corresponding algorithms from the 
    Applied Statistics series to compute the log gamma and incomplete
    gamma functions.

Note:
    To generate non-central chi-square random numbers, enter
    the commands

        LET NU = <value>
        LET LAMBDA = <value>
        LET Y = NON-CENTRAL CHI-SQUARE RANDOM NUMBERS ...
                FOR I = 1 1 N

    To generate an non-central chi-square probability plot
    or an non-central chi-square Kolmogorov-Smirnov or
    chi-square goodness of fit test, enter the following commands

        LET NU = <value>
        LET LAMBDA = <value>
        NON-CENTRAL CHI-SQUARE PROBABILITY PLOT Y
        NON-CENTRAL CHI-SQUARE KOLMOGOROV SMIRNOV ...
                   GOODNESS OF FIT Y
        NON-CENTRAL CHI-SQUARE CHI-SQUARE GOODNESS OF FIT Y
       
    To generate a PPCC or Kolmogorov-Smirnov plot, enter the
    following commands

        LET NU1 = <value>
        LET NU2 = <value>
        LET LAMBDA1 = <value>
        LET LAMBDA2 = <value>
        NON-CENTRAL CHI-SQUARE PPCC PLOT Y
        NON-CENTRAL CHI-SQUARE KS PLOT Y

    The default values for NU1 and NU2 are 5 and 15.  The default
    values for LAMBDA1 and LAMBDA2 are 0 and 10.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NCCCDF = Compute the non-central chi-square cumulative distribution
             function.
    NCCNCP = Compute the non-central chi-square non-centrality
             parameter function.
    NCCPPF = Compute the non-central chi-square percent point function.
    CHSPDF = Compute the chi-square probability density function.
    NCFPDF = Compute the non-central F probability density function.
    NCBPDF = Compute the non-central beta probability density function.
    NCTPDF = Compute the non-central t probability density function.
    NORPDF = Compute the normal probability density function.
 
Reference:
    "Computation of Probability and Non-centrality Parameter of a
    Non-central Chi-squared Distribution", Narula and Desu, Applied
    Statistics, Vol. 30, No. 3, 1981, pp. 349-352.

    "Continuous Univariate Distributions--Volume 2", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, chapter 29.

    "Statistical Distributions", Third Edition, Evans, Hastings, and
    Peacock, 2000, chapter 9.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2004/5
 
Program:
    LABEL CASE ASIS
    Y1LABEL Probability
    X1LABEL X
    X1LABEL DISPLACEMENT 12
    Y1LABEL DISPLACEMENT 12
    YLIMITS 0  0.2
    TITLE DISPLACEMENT 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    MULTIPLOT 2 2
    TITLE LAMBDA = 0
    PLOT NCCPDF(X,5,0) FOR X = 0.01  0.01  10
    TITLE LAMBDA = 0.5
    PLOT NCCPDF(X,5,0.5) FOR X = 0.01  0.01  10
    TITLE LAMBDA = 1
    PLOT NCCPDF(X,5,1) FOR X = 0.01  0.01  10
    TITLE LAMBDA = 2
    PLOT NCCPDF(X,5,2) FOR X = 0.01  0.01  10
    END OF MULTIPLOT
    CASE ASIS
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Non-Central Chi-Square PDF (NU = 5)
 
-----NCCPPF (LET)--------------------------------
 
NCCPPF
 
Name:
    NCCPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the non-central chi-square percent point function with
    degrees of freedom parameters v and non-centrality parameter delta.
 
Description:
    The non-central chi-square distribution with degrees of freedom
    v and non-centrality parameter delta is the sum of v independent
    normal distributions with mean delta and standard deviation 1.
    The functional forms of the density and distribution are given
    in the references given below (see REFERENCE).  This distribution
    is sometimes needed in the calculation of the power of a test.
 
    The percent point function is the inverse of the cumulative
    distribution function.  The cumulative distribution sums the
    probability from 0 to the given x value.  The percent point
    function takes a cumulative probability value and computes the
    corresponding x value.
 
Syntax:
    LET <y> = NCCPPF(<p>,<v>,<delta>) <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, variable or a parameter containing values
               in the interval (0,1);
          <y> is a variable or a parameter (depending on what <p> is)
               where the computed ppf value is stored;
          <v> is a non-negative number, parameter or variable that
               specifies the degrees of freedom parameter;
          <delta> is a non-negative number, parameter or variable that
               specifies the first non-centrality parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NCCPPF(0.90,3,3)
    LET A = NCCPPF(0.95,10,5)
    LET X2 = NCCPPF(0.99,100,10)
 
Note:
    DATAPLOT uses a bisection method to compute the non-central
    chi-square ppf value.  The algorithm for the central beta
    distribution is given in the Kennedy and Gentle book (see the
    REFERENCE section below).  The algorithm for the non-central 
    chi-square distribution is similar.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NCCCDF = Compute the non-central chi-square cumulative distribution
             function.
    NCCNCP = Compute the non-central chi-square non-centrality
             parameter function.
    CHSPDF = Compute the chi-square probability density function.
    CHSPPF = Compute the chi-square percent point function.
    CHSCDF = Compute the chi-square cumulative distribution function.
    NCFCDF = Compute the non-central F cumulative distribution
             function.
    NCFPPF = Compute the non-central F percent point function.
    NCBCDF = Compute the non-central beta cumulative distribution
             function.
    NCBPPF = Compute the non-central beta percent point function.
    NCTCDF = Compute the non-central t cumulative distribution
             function.
    NCTPPF = Compute the non-central t percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
 
Reference:
    "Computation of Probability and Non-centrality Parameter of a
    Non-central Chi-squared Distribution", Narula and Desu, Applied
    Statistics, Vol. 30, No. 3, 1981, pp. 349-352.

    "Continuous Univariate Distributions--Volume II", Second
    Edition, Johnson, Kotz, and Balakrishnan, Wiley, 1994,
    chapter 29.

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 58-61.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/9
 
Program:
    TITLE AUTOMATIC
    PLOT NCCPPF(P,10,5) FOR P = 0.01 0.01 0.99
 
-----NCFCDF (LET)------------------------------------------
 
NCFCDF
 
Name:
    NCFCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the non-central F cumulative distribution function with
    degrees of freedom parameters v1 and v2 and with non-centrality
    parameter lambda.
 
Description:
    The F distribution is the ratio of 2 central chi-square
    distributions:
          F = (U/v1)/(V/v2)
    where U and V are 2 independent chi-square distributions with v1
    and v2 degrees of freedom respectively.  The non-central F
    distribution is the ratio of a non-central chi-square distribution
    and a central chi-square distribution.  That is:
          f(x) = (X1/v1)/(X2/v2)
    where X1 is non-central chi-square distribution with degrees of
    freedom parameter v1 and non-centrality parameter lambda and
    X2 is a central chi-square distribution with v2 degrees of freedom.

    The cumulative distribution is the area from 0 to x.  Since this is
    a probability function, the returned value will be between 0 and 1.
 
    The input value should be greater than 0, the non-centrality
    parameter should be non-negative, and both degrees of freedom
    parameters should be positive.
 
Syntax:
    LET <y2> = NCFCDF(<y1>,<v1>,<v2>,<lambda>) 
                        <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a number, variable or a parameter containing 
               non-negative values;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed cdf value is stored;
          <v1> is a non-negative number, parameter or variable that
               specifies the first degrees of freedom parameter;
          <v2> is a non-negative number, parameter or variable that
               specifies the second degrees of freedom parameter;
          <lambda> is a non-negative number, parameter or variable
               that specifies the first non-centrality parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NCFCDF(2,3,3,5)
    LET A = NCFCDF(2,10,10,5)
    LET X2 = NCFCDF(1.1,14,15,10000)
 
Note:
    DATAPLOT converts the non-central F distribution to an equivalent
    non-central beta distribution.  It then uses algorithm AS 226 (see
    the REFERENCE section below) obtained from the statlib archive to
    compute the non-central beta cdf.  It uses the DBETAI and DLNGAM
    routines from the SLATEC library rather than the corresponding
    algorithms from the Applied Statistics series to compute the log
    gamma and incomplete beta functions.

Note:
    DATAPLOT also supports the central F and the doubly non-central F
    distributions (see the documentation for FCDF and DNFCDF).  The
    DNFCDF function can also be used to calculate the singly
    non-central F (although they use different algorithms).  The
    NCFCDF routine can be used to compute the central F distribution
    (set the non-centrality parameter to zero).  For example, this can
    be used for the non-integer degrees of freedom case.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NCFPDF = Compute the singly non-central F probability density
             function.
    NCFPPF = Compute the singly non-central F percent point function.
    DNFCDF = Compute the doubly non-central F cumulative distribution
             function.
    FPDF   = Compute the F probability density function.
    NCBCDF = Compute the non-central beta cumulative distribution
             function.
    NCCCDF = Compute the non-central chi-square cumulative distribution
             function.
    NCTCDF = Compute the non-central t cumulative distribution
             function.
    CHSPDF = Compute the chi-square probability density function.
    NORPDF = Compute the normal probability density function.
 
Reference:
    "Computing Noncentral Beta Probabilities", Lenth, Applied 
    Statistics, Vol. 39, No. 2, 1987, pp. 241-244.

    "Continuous Univariate Distributions--Volume II", Second
    Edition, Johnson, Kotz, and Balakrishnan, Wiley, 1994,
    chapter 30.

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 95-97.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/9
 
Program:
    TITLE A NON-CENTRAL F DISTRIBUTION
    PLOT NCFCDF(X,3,10,5) FOR X = 0 0.1 6
 
-----NCFPDF (LET)------------------------------------------
 
NCFPDF
 
Name:
    NCFPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the non-central F probability density function with
    degrees of freedom parameters v1 and v2 and with non-centrality
    parameter lambda.
 
Description:
    If U and V are mutually independent chi-square random variables
    with degrees of freedom parameter v1 and v2, respectively,
    then

          F = (U/v1)/(V/v2)

    follows a F distribution.  If U is replaced with a non-central
    chi-square distribution with non-centrality parameter lambda,
    then the above ratio follows a non-central F distribution with
    non-centrality parameter lambda.

    The probability density function of the non-central F distribution
    is rather complicated and not given here.  It is given on page 95
    of Evans, Hastings, and Peacock (see the Reference section below).
    The input value and both degrees of freedom parameters should be
    positive and the non-centrality parameter should be non-negative
    (lambda = 0 reduces to the standard F distribution).
 
    The non-central F probability density function can be
    generalized with location and scale parameters in the usual way.

Syntax:
    LET <y> = NCFPDF(<x>,<v1>,<v2>,<lambda>,<loc>,<scale>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, variable or a parameter containing 
               non-negative values;
          <v1> is a non-negative number, parameter or variable that
               specifies the first degrees of freedom parameter;
          <v2> is a non-negative number, parameter or variable that
               specifies the second degrees of freedom parameter;
          <lambda> is a non-negative number, parameter or variable
               that specifies the non-centrality parameter;
          <loc> is a number or parameter that specifies the location
               parameter;
          <scale> is a number or parameter that specifies the scale
               parameter;
          <y> is a variable or a parameter (depending on what <y1> is)
               where the computed pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The location and scale parameters are optional.

Examples:
    LET A = NCFPDF(2,3,3,5)
    LET A = NCFPDF(2,10,10,5)
    LET X2 = NCFPDF(1.1,14,15,10000)
 
Note:
    Dataplot computes the non-central F probability density by finding
    the numerical derivative of the non-central F cumulative distribution
    function.

    DATAPLOT computes the non-central F distribution by converting it to
    an equivalent non-central beta distribution.  It then uses algorithm
    AS 226 (see the REFERENCE section below) obtained from the statlib
    archive to compute the non-central beta cdf.  It uses the DBETAI and
    DLNGAM routines from the SLATEC library rather than the corresponding
    algorithms from the Applied Statistics series to compute the log
    gamma and incomplete beta functions.

Note:
    DATAPLOT also supports the central F and the doubly non-central F
    distributions (see the documentation for FPDF and DNFPDF).  The
    NCFPDF routine can be used to compute the central F distribution
    (set the non-centrality parameter to zero).  For example, this can
    be used for the non-integer degrees of freedom case.

Note:
    To generate non-central F random numbers, enter the commands

        LET NU1 = <value>
        LET NU2 = <value>
        LET LAMBDA = <value>
        LET Y = NON-CENTRAL F RANDOM NUMBERS ...
                FOR I = 1 1 N

    To generate a non-central F probability plot or an non-central F
    Kolmogorov-Smirnov or chi-square goodness of fit test, enter the
    following commands

        LET NU1 = <value>
        LET NU2 = <value>
        LET LAMBDA = <value>
        NON-CENTRAL F PROBABILITY PLOT Y
        NON-CENTRAL F KOLMOGOROV SMIRNOV ...
                   GOODNESS OF FIT Y
        NON-CENTRAL F CHI-SQUARE GOODNESS OF FIT Y

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NCFCDF = Compute the singly non-central F cumulative distribution
             function.
    NCFPPF = Compute the singly non-central F percent point function.
    DNFCDF = Compute the doubly non-central F cumulative distribution
             function.
    DNFPDF = Compute the doubly non-central F probability density
             function.
    FPDF   = Compute the F probability density function.
    NCBCDF = Compute the non-central beta cumulative distribution
             function.
    NCCCDF = Compute the non-central chi-square cumulative distribution
             function.
    NCTCDF = Compute the non-central t cumulative distribution
             function.
    CHSPDF = Compute the chi-square probability density function.
    NORPDF = Compute the normal probability density function.
 
Reference:
    "Computing Noncentral Beta Probabilities", Lenth, Applied 
    Statistics, Vol. 39, No. 2, 1987, pp. 241-244.

    "Continuous Univariate Distributions: Volume 2", Johnson, Kotz, and
    Balakrishnan, Wiley and Sons, 1994, chapter 30.

    "Statistical Distributions", Third Edition, Evans, Hastings, and
    Peacock, 2000 pp. 95-97.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2004/5
 
Program:
    LABEL CASE ASIS
    Y1LABEL Probability
    X1LABEL X
    Y1LABEL DISPLACEMENT 12
    X1LABEL DISPLACEMENT 12
    TITLE DISPLACEMENT 2
    Y1LIMITS 0 0.7
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    MULTIPLOT 2 2
    TITLE LAMBDA = 0
    PLOT NCFPDF(X,10,5,0) FOR X = 0.01 0.01 5
    TITLE LAMBDA = 0.5
    PLOT NCFPDF(X,10,5,0.5) FOR X = 0.01 0.01 5
    TITLE LAMBDA = 1
    PLOT NCFPDF(X,10,5,1) FOR X = 0.01 0.01 5
    TITLE LAMBDA = 2
    PLOT NCFPDF(X,10,5,2) FOR X = 0.01 0.01 5
    END OF MULTIPLOT
    CASE ASIS
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Non-Central F Distribution PDF (NU1 = 10, NU2 = 5)
 
-----NCFPPF (LET)--------------------------------
 
NCFPPF
 
Name:
    NCFPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the non-central F percent point function with degrees of
    freedom parameters v1 and v2 and non-centrality parameter lambda.
 
Description:
    The F distribution is the ratio of 2 central chi-square
    distributions:
          F = (U/v1)/(V/v2)
    where U and V are 2 independent chi-square distributions with v1
    and v2 degrees of freedom respectively.  The non-central F
    distribution is the ratio of a non-central chi-square distribution
    with v1 degrees of freedom and non-centrality parameter lambda and
    a central chi-square distribution with v2 degrees of freedom.
    That is:
          f(x) = (X1/v1)/(X2/v2)
    where X1 has a non-central chi-square distribution with v1 degrees
    of freedom and non-centrality parameter lambda and X2 has a central
    chi-square distribution with v2 degrees of freedom.
 
    The percent point function is the inverse of the cumulative
    distribution function.  The cumulative distribution sums the
    probability from 0 to the given x value.  The percent point
    function takes a cumulative probability value and computes the
    corresponding x value.
 
Syntax:
    LET <y> = NCFPPF(<p>,<v1>,<v2>,<lambda>) 
                        <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, variable or a parameter containing values in
               the interval (0,1);
          <y> is a variable or a parameter (depending on what <p> is)
               where the computed ppf value is stored;
          <v1> is a non-negative number, parameter or variable that
               specifies the first degrees of freedom parameter;
          <v2> is a non-negative number, parameter or variable that
               specifies the second degrees of freedom parameter;
          <lambda> is a non-negative number, parameter or variable that
               specifies the non-centrality parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NCFPPF(0.75,3,3,5)
    LET A = NCFPPF(0.95,10,10,5)
    LET X2 = NCFPPF(0.82,14,15,10000)
 
Note:
    DATAPLOT uses a bisection method to compute the non-central F
    ppf value.  The algorithm for the central beta distribution is 
    given in the Kennedy and Gentle book (see the REFERENCE section
    below).  The algorithm for the non-central F distribution is
    similar.

Note:
    Both the degrees of freedom parameters and the non-centrality
    parameters should be positive real numbers.  The non-centrality
    parameter should be a non-negative real number.

Note:
    DATAPLOT also supports the central F and the doubly non-central F
    distributions (see the documentation for FPPF and DNFPPF).  The
    DNFPPF function can be used for the singly non-central F as well
    (set the second non-centrality parameter to zero).  The NCFPPF
    function can be used for the central F distribution as well.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    DNFPPF = Compute the doubly non-central F percent point function.
    NCFCDF = Compute the singly non-central F cumulative distribution
             function.
    FCDF   = Compute the F cumulative distribution function.
    FPDF   = Compute the F probability density function.
    FPPF   = Compute the F percent point function.
    NCBCDF = Compute the non-central beta cumulative distribution
             function.
    NCBPPF = Compute the non-central beta percent point function.
    NCCCDF = Compute the non-central chi-square cumulative distribution
             function.
    NCCPPF = Compute the non-central chi-square percent point function.
    NCTCDF = Compute the non-central t cumulative distribution
             function.
    NCTPPF = Compute the non-central t percent point function.
    CHSPDF = Compute the chi-square probability density function.
    CHSPPF = Compute the chi-square percent point function.
    CHSCDF = Compute the chi-square cumulative distribution function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
 
Reference:
    "Computing Noncentral Beta Probabilities", Lenth, Applied 
    Statistics, Vol. 39, No. 2, 1987, pp. 241-244.

    "Continuous Univariate Distributions--Volume II", Second
    Edition, Johnson, Kotz, and Balakrishnan, Wiley, 1994,
    chapter 30.

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 95-97.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/9
 
Program:
    TITLE AUTOMATIC
    PLOT NCFPPF(P,10,10,5) FOR P = 0.01 0.01 0.99
 
-----NCTCDF (LET)------------------------------------------
 
NCTCDF
 
Name:
    NCTCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the non-central t cumulative distribution function with
    degrees of freedom parameters v and with non-centrality parameter
    delta.
 
Description:
    Given the random variable:
          Y = Z/SQRT(X/v)
    where Z is a normal distribution with mean delta and a standard
    deviation of 1 and X is a central chi-square distribution with
    v degrees of freedom, then Y has a non-central t distribution.

    The cumulative distribution is the area from negative infinity to
    x.  Since this is a probability function, the returned value will
    be between 0 and 1.
 
Syntax:
    LET <y2> = NCTCDF(<y1>,<v>,<delta>) 
                        <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a number, variable or a parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed cdf value is stored;
          <v> is a non-negative number, parameter or variable that
               specifies the degrees of freedom parameter;
          <delta> is a non-negative number, parameter or variable that
               specifies the first non-centrality parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NCTCDF(0.7,1,1)
    LET A = NCTCDF(3,10,10)
    LET X2 = NCTCDF(95,10,100)
 
Note:
    DATAPLOT uses algorithm AS 243 (see the REFERENCE section below)
    obtained from the statlib archive to compute the non-central t
    cdf.  It uses the DBETAI and DLNGAM routines from the SLATEC
    library rather than the corresponding algorithms from the 
    Applied Statistics series to compute the log gamma and incomplete
    beta functions.  It uses the DATAPLOT normal cdf function rather
    than AS 66.

Note:
    DATAPLOT also supports the central t and the doubly non-central t
    distributions (see the documentation for TCDF and DNTCDF).  The
    DNTCDF function can be used for the singly non-central t as well,
    altough it uses a different algorithm.  The NCTCDF can also be used
    for the central t cdf.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NCTPDF = Compute the singly non-central t probability density
             function.
    NCTPPF = Compute the singly non-central t percent point function.
    DNTCDF = Compute the doubly non-central t cumulative distribution
             function.
    TPDF   = Compute the t probability density function.
    NCFCDF = Compute the non-central F cumulative distribution
             function.
    NCBCDF = Compute the non-central beta cumulative distribution
             function.
    NCCCDF = Compute the non-central chi-square cumulative distribution
             function.
    CHSPDF = Compute the chi-square probability density function.
    NORPDF = Compute the normal probability density function.
    FPDF   = Compute the F probability density function.
 
Reference:
    "Cumulative Distribution Function for the Non-central t 
    Distribution", Lenth, Applied Statistics, Vol. 38, No. 1, 1988,
    pp. 185-188

    "Continuous Univariate Distributions: Volume 2", Second Edition,
    Johnson, Kotz, and Balakrshnan,  Wiley, 1994, chapter 31.

    "Statistical Distributions", Third Edition, Evans, Hastings, and
    Peacock, 2000, pp. 184-186.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/9
 
Program:
    TITLE AUTOMATIC
    PLOT NCTCDF(X,10,1) FOR X = -10 0.2 30
 
-----NCTPDF (LET)------------------------------------------
 
NCTPDF
 
Name:
    NCTPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the non-central t probability density function with
    degrees of freedom parameters v and with non-centrality parameter
    delta.
 
Description:
    Given the random variable:
          Y = Z/SQRT(X/v)
    where Z is a normal distribution with mean delta and a standard
    deviation of 1 and X is a central chi-square distribution with
    v degrees of freedom, then Y has a non-central t distribution.

    The probability density function is rather complicated, so it is
    not given here.  See the Evans, Hastings, and Peacock book for the
    formula (see the Reference section below).

    DATAPLOT actually uses the following formula to compute the
    non-central t density function (thanks to Mark Vangel of the NIST
    Statistical Engineering Division for pointing this formula out to
    us):
         NCTPDF(x,v,delta) = (v/x)*[NCTCDF(SQRT((v+2)/v)*x,v+2,delta)
                                - NCTCDF(x,v,delta)]
    where NCTCDF is the non-central t cumulative distribution
    function.  The case where x is zero is handled separately.
 
    The non-central t probability density function can be
    generalized with location and scale parameters in the usual way.

Syntax:
    LET <y2> = NCTPDF(<y1>,<v>,<delta>,<loc>,<scale>) 
                        <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a number, parameter, or variable;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed pdf value is stored;
          <v> is a non-negative number, parameter or variable that
               specifies the degrees of freedom parameter;
          <delta> is a non-negative number, parameter or variable that
               specifies the non-centrality parameter;
          <loc> is a number or parameter that specifies the location
               parameter;
          <scale> is a number or parameter that specifies the scale
               parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The location and scale parameters are optional.

Examples:
    LET A = NCTPDF(0.7,1,1)
    LET A = NCTPDF(3,10,10)
    LET X2 = NCTPDF(95,10,100)
 
Note:
    DATAPLOT uses algorithm AS 243 (see the REFERENCE section below)
    obtained from the statlib archive to compute the non-central t
    cdf.  It uses the DBETAI and DLNGAM routines from the SLATEC
    library rather than the corresponding algorithms from the 
    Applied Statistics series to compute the log gamma and incomplete
    beta functions.  It uses the DATAPLOT normal cdf function rather
    than AS 66.

Note:
    DATAPLOT also supports the central t and the doubly non-central t
    distributions (see the documentation for TPDF and DNTCDF).

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NCTCDF = Compute the singly non-central t cumulative distribution
             function.
    NCTPPF = Compute the singly non-central t percent point function.
    DNTCDF = Compute the doubly non-central t cumulative distribution
             function.
    TPDF   = Compute the t probability density function.
    NCFCDF = Compute the non-central F cumulative distribution
             function.
    NCBCDF = Compute the non-central beta cumulative distribution
             function.
    NCCCDF = Compute the non-central chi-square cumulative distribution
             function.
    NORPDF = Compute the normal probability density function.
 
Reference:
    "Tables of Normal Tolerance Limits, Sampling Plans and Screening",
    Odeh and Owen, Marcel Dekker, 1980 (page 272).

    "Continuous Univariate Distributions: Volume 2", Second Edition,
    Johnson, Kotz, and Balakrshnan,  Wiley, 1994, chapter 31.

    "Statistical Distributions", Third Edition, Evans, Hastings, and
    Peacock, 2000, pp. 184-186.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1995/5
 
Program:
    TITLE NON-CENTRAL T DISTRIBUTIONS (V = 5)
    X1LABEL X
    Y1LABEL PROBABILITY
    LINE SOLID DASH DOT
    PLOT NCTPDF(X,5,0) FOR X = -3 0.01 7 AND
    PLOT NCTPDF(X,5,2) FOR X = -3 0.01 7 AND
    PLOT NCTPDF(X,5,0.5) FOR X = -3 0.01 7
 
-----NCTPPF (LET)--------------------------------
 
NCTPPF
 
Name:
    NCTPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the non-central t percent point function with degrees of
    freedom parameters v and non-centrality parameter delta.
 
Description:
    Given the random variable:
          Y = Z/SQRT(X/v)
    where Z is a normal distribution with mean delta and a standard
    deviation of 1 and X is a central chi-square distribution with
    v degrees of freedom, then Y has a non-central t distribution.
 
    The percent point function is the inverse of the cumulative
    distribution function.  The cumulative distribution sums the
    probability from 0 to the given x value.  The percent point
    function takes a cumulative probability value and computes the
    corresponding x value.
 
Syntax:
    LET <y> = NCTPPF(<p>,<v>,<delta>) <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, variable or a parameter containing values
               in the interval (0,1);
          <y> is a variable or a parameter (depending on what <p> is)
               where the computed ppf value is stored;
          <v> is a non-negative number, parameter or variable that
               specifies the degrees of freedom parameter;
          <delta> is a non-negative number, parameter or variable that
               specifies the first non-centrality parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NCTPPF(0.90,3,3)
    LET A = NCTPPF(0.95,10,5)
    LET X2 = NCTPPF(0.99,14,100)
 
Note:
    DATAPLOT uses a bisection method to compute the non-central t
    ppf value.  The algorithm for the central beta distribution is 
    given in the Kennedy and Gentle book (see the REFERENCE section
    below).  The algorithm for the non-central t distribution is
    similar.

Note:
    DATAPLOT also supports the central t and the doubly non-central t
    distributions (see the documentation for TCDF and DNTCDF).  The
    DNTCDF function can be used for the singly non-central t as well,
    altough it uses a different algorithm.  The NCTCDF can also be used
    for the central t cdf.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NCTCDF = Compute the singly non-central t cumulative distribution
             function.
    NCTPDF = Compute the non-central t probability density function.
    DNTPPF = Compute the doubly non-central t percent point function.
    TPDF   = Compute the t probability density function.
    NCFCDF = Compute the non-central F cumulative distribution
             function.
    NCBCDF = Compute the non-central beta cumulative distribution
             function.
    NCCCDF = Compute the non-central chi-square cumulative distribution
             function.
    CHSPDF = Compute the chi-square probability density function.
    NORPDF = Compute the normal probability density function.
    FPDF   = Compute the F probability density function.
 
Reference:
    "Cumulative Distribution Function for the Non-central t 
    Distribution", Lenth, Applied Statistics, Vol. 38, No. 1, 1988,
    pp. 185-188

    "Continuous Univariate Distributions: Volume 2", Second Edition,
    Johnson, Kotz, and Balakrshnan,  Wiley, 1994, chapter 31.

    "Statistical Distributions", Third Edition, Evans, Hastings, and
    Peacock, 2000, pp. 184-186.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/9
 
Program:
    TITLE AUTOMATIC
    PLOT NCTPPF(P,10,5) FOR P = 0.01 0.01 0.99
 
-----NEAREST NEIGHBOR-------------------------------------------------------
 
NEAREST NEIGHBOR
 
Name:
    NEAREST NEIGHBOR
 
Type:
    LET Subcommand
 
Purpose:
    Compute 2-dimensional nearests neighbors.
 
Description:
    Given a set of points, it is often desirable to determine the
    nearest neighbor of each point.  It may also be desirable to
    compute the distances between the nearest neigbors.  In some
    cases, there may be two separate lists of points and we want
    the nearest neighbor in list one for each point in list two.

    Dataplot provides several different commands to accomodate
    these different cases.  Note that currently only the
    2-dimensional case is considered.

Syntax 1:
    LET <yindex>  = NEAREST NEIGHBOR  INDEX <y>  <x>
                    <SUBSET/EXPCEPT/FOR qualification>
    where <y> is a variable containing the y-coordinates of
               the data set;
          <x> is a variable containing the x-coordinates of
               the data set;
          <yindex> is a variable that will contain the index of
               the nearest neighor for each point;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Given a set of points, this syntax returns the index of the
    point that is nearest neighbor to each point in the list (i.e.,
    the output variable will have the same number of rows as the
    input variable.

Syntax 2:
    LET <ydist>  = NEAREST NEIGHBOR  DISTANCE <y>  <x>
                    <SUBSET/EXPCEPT/FOR qualification>
    where <y> is a variable containing the y-coordinates of
               the data set;
          <x> is a variable containing the x-coordinates of
               the data set;
          <ydist> is a variable that will contain the distance of
               the nearest neighor for each point;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Given a set of points, this syntax returns the distance between
    each point and its nearest neighbor.

Syntax 3:
    LET <yindex> <ydist> = NEAREST NEIGHBOR  <y>  <x>
                           <SUBSET/EXPCEPT/FOR qualification>
    where <y> is a variable containing the y-coordinates of
               the data set;
          <x> is a variable containing the x-coordinates of
               the data set;
          <yindex> is a variable that will contain the index of
               the nearest neighor for each point;
          <ydist> is a variable that will contain the distance of
               the nearest neighor for each point;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Given a set of points, this syntax returns both the index of the
    point that is nearest neighbor to each point in the list and the
    distance between the point and its nearest neighbor.

Syntax 4:
    LET <y2> <x2> <tag2> = NEAREST NEIGHBOR JOIN <y1>  <x1> <yindex>
                           <SUBSET/EXPCEPT/FOR qualification>
    where <y1> is a variable containing the y-coordinates of
               the data set;
          <x1> is a variable containing the x-coordinates of
               the data set;
          <yindex> is a variable containing the index of the nearest
               neighor for each point;
          <y2> is a variable that will contain the y-coordinates of
               nearest neighors;
          <x2> is a variable that will contain the x-coordinates of
               nearest neighors;
          <tag2> is a variable that will contain a tag identifying
               which points in <x2> and <y2> are connected;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This command is useful if you want to plot the nearest neighbors.
    It connects each point in (<x1>,<y1>) with its nearest neighbor where
    the Syntax 1 command is typically run first to obtain <yindex>.  This
    is demonstrated in the Program 1 example below.

Syntax 5:
    LET <y3> <x3> <dist> = FIRST NEAREST NEIGHBOR <y1>  <x1> <y2> <x2>
                           <SUBSET/EXPCEPT/FOR qualification>
    where <y1> is a variable containing the y-coordinates of
               the first data set;
          <x1> is a variable containing the x-coordinates of
               the first data set;
          <y2> is a variable containing the y-coordinates of
               the second data set;
          <x2> is a variable containing the x-coordinates of
               the second data set;
          <y3> is a variable that will contain the y-coordinate of
               the nearest neighor;
          <x3> is a variable that will contain the x-coordinate of
               the nearest neighor;
          <dist> is a variable that will contain the distance of
               the nearest neighor;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This command works on two sets of points.  For each point in
    (<x2>,<y2>), the points in (<x1>,<y1>) are searched to determine
    the nearest neighbor.  The coordinates of the nearest neighbor
    are save in (<x3>,<y3>).  In addition, the distance between the
    nearest neighbors are also saved.

Syntax 6:
    LET <y3> <x3> <dist> <tag1> <tag2> = ALL NEAREST NEIGHBORS
                                         <y1>  <x1> <y2> <x2>
                                         <SUBSET/EXPCEPT/FOR qualification>
    where <y1> is a variable containing the y-coordinates of
               the first data set;
          <x1> is a variable containing the x-coordinates of
               the first data set;
          <y2> is a variable containing the y-coordinates of
               the second data set;
          <x2> is a variable containing the x-coordinates of
               the second data set;
          <y3> is a variable that will contain the y-coordinate of
               the nearest neighor;
          <x3> is a variable that will contain the x-coordinate of
               the nearest neighor;
          <dist> is a variable that will contain the distance of
               the nearest neighor;
          <tag1> is a variable that identifies the row number of
               the second data set;
          <tag2> is a variable that identifies the nearest neighbor
               index;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This command works on two sets of points.  For each point in
    (<x2>,<y2>), the points in (<x1>,<y1>) are searched to determine a
    sorted list of nearest neighbors.  The coordinates of the nearest
    neighbors are saved in (<x3>,<y3>).  In addition, the distance between
    the nearest neighbors are also saved.

    The <tag1> variable identifies the row number in the second data
    set.  The <tag2> variable identifies the index in the sorted list
    of nearest neighbors (i.e., a value of 1 identifies the first
    nearest neighbor, a value of 2 identifies the second nearest
    neighbor, and so on).

    This syntax is useful if you want to determine not just the first
    nearest neighbor but the second or third (and so on) nearest
    neighbors.  If N1 is the number of rows in the first data set and
    N2 is the number of rows in the second data set, then the output
    variables will have N1*N2 rows.

Examples:
    LET YINDEX = NEAREST NEIGHBOR INDEX Y X
    LET YDIST  = NEAREST NEIGHBOR DISTANCE Y X
    LET Y3 X3 DIST = FIRST NEAREST NEIGHBOR Y1 X1 Y2 X2
    LET Y3 X3 DIST TAG1 TAG2 = ALL NEAREST NEIGHBORS Y1 X1 Y2 X2
 
Note:
    These nearest neighbor commands are currently implemented using
    brute force algorithms.  Although these algorithms are not
    particularly efficient, they should be adequate for small to
    moderate size 2d data sets.

Default:
    None
 
Synonyms:
    LET YINDEX = NEAREST NEIGBOR Y X is a synonym for LET YINDEX =
    NEAREST NEIGBOR INDEX Y X.
 
Related Commands:
    CONVEX HULL             = Compute the convex hull of a set of points.
    MINIMAL SPANNING TREE   = Determine the minimal spanning tree.
 
Applications:
    Computational Geometry, Spatial Statistics
 
Implementation Date:
    2013/9
 
Program 1:
    skip 25
    read convhull.dat x y
    .
    let yindex = nearest neighbor y x
    let y3 x3 tag3 = nearest neighbor join y x yindex
    .
    title case asis
    title offset 2
    title Nearest Neighbor Map
    y1label Y
    x1label X
    tic offset units screen
    tic offset 3 3
    .
    character circle all
    character hw 0.5 0.375 all
    character fill on all
    .
    plot y3 x3 tag3

Program 2:
    dimension 40 columns
    skip 25
    read convhull.dat x y
    .
    read x2 y2
     0  0
     1  1
     1 -1
    -1 -1
    -1  1
    end of data
    .
    let y4 x4 dist4 = first nearest neighbor y x y2 x2
    set write decimals 2
    write x2 y2 x4 y4 dist4

Program 3:
    dimension 40 columns
    skip 25
    read convhull.dat x y
    .
    read x2 y2
     0  0
     1  1
     1 -1
    -1 -1
    -1  1
    end of data
    .
    set isubro arn2
    let y4 x4 dist4 tag1 tag2 = all nearest neighbor y x y2 x2
    set write decimals 2
    write x2 y2
    write x4 y4 dist4 tag1 tag2

-----NEGATE-------------------------------------------------------
 
NEGATE
 
Name:
    NEGATE
 
Type:
    Support Command
 
Purpose:
    Vertical axis variables on a plot are negated (i.e., plot the
    negative of the variable).
 
Syntax:
    NEGATE    <ON/OFF>
    where ON specifies that vertical axis variables are to be negated
            while OFF specifies that vertical axis variables are not
            negated.
 
Examples:
    NEGATE ON
    NEGATE OFF
    NEGATE
 
Note:
    Entering NEGATE with no arguments sets the value to ON.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PLOT          = Generate a data or function plot.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----NEGATIVE PREDICTIVE VALUE (LET)--------------------------------
 
NEGATIVE PREDICTIVE VALUE
 
Name:
    NEGATIVE PREDICTIVE VALUE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the negative predictive value between two
    binary variables.
 
Description:
    Given two variables with n parired observations where each
    variable has exactly two possible outcomes, we can generate
    the following 2x2 table:

                      |       Variable 2        |
        Variable 1    |   Success      Failure  |  Row Total
        ====================================================
        Success       |   N11            N12    |  N11 + N12
        Failure       |   N21            N22    |  N21 + N22
        ====================================================
        Column Total  |   N11+N21      N12+N22  |  Total

    The parameters N11, N12, N21, and N22 denote the counts
    for each category.
 
    Success and failure can denote any binary response.
    Dataplot expects "success" to be coded as "1" and "failure"
    to be coded as "0".  Some typical examples would be:

       1) Variable 1 denotes whether or not a patient has a
          disease (1 denotes disease is present, 0 denotes
          disease not present).  Variable 2 denotes the result
          of a test to detect the disease (1 denotes a positive
          result and 0 denotes a negative result).

       2) Variable 1 denotes whether an object is present or
          not (1 denotes present, 0 denotes absent). Variable 2
          denotes a detection device (1 denotes object detected
          and 0 denotes object not detected).

    In these examples, the "ground truth" is typically given
    as variable 1 while some estimator of the ground truth is
    given as variable 2.
   
    The negative predictive value is then N12/(N12+N22).  This
    is the conditional probability of variable 1 being false
    given that variable 2 is false.  In the context of the first
    example above, this is the probability that the disease is
    not present when there is a negative test result.

    Fleiss and his co-authors recommend negative predictive value
    and positive predictive value as an alternative to false
    positive and false negative due to the fact that the
    definitions of false positive and false negative have
    been inconsistent in the literature.

Syntax:
    LET <par> = NEGATIVE PREDICTIVE VALUE <y1> <y2>
                              <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed negative
               predictive value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NEGATIVE PREDICTIVE VALUE Y1 Y2
    LET A = NEGATIVE PREDICTIVE VALUE Y1 Y2 SUBSET TAG > 2
 
Note:
    The two variables must have the same number of elements.
 
Note:
    There are two ways you can define the response variables:

       1) Raw data - in this case, the variables contain
          0's and 1's.

          If the data is not coded as 0's and 1's, Dataplot
          will check for the number of distinct values.  If
          there are two distinct values, the minimum value
          is converted to 0's and the maximum value is
          converted to 1's.  If there is a single distinct
          value, it is converted to 0's if it is less than
          0.5 and to 1's if it is greater than or equal to
          0.5.  If there are more than two distinct values,
          an error is returned.

       2) Summary data - if there are two observations, the
          data is assummed to be the 2x2 summary table.
          That is,

              Y1(1) = N11
              Y1(2) = N21
              Y2(1) = N12
              Y2(2) = N22
 
Note:
    The following additional commands are supported

        TABULATE NEGATIVE PREDICTIVE VALUE  Y1 Y2 X
        CROSS TABULATE NEGATIVE PREDICTIVE VALUE Y1 Y2 X1 X2

        NEGATIVE PREDICTIVE VALUES PLOT Y1 Y2 X
        CROSS TABULATE NEGATIVE PREDICTIVE VALUES PLOT Y1 Y2 X1 X2

        BOOTSTRAP NEGATIVE PREDICTIVE VALUES PLOT Y1 Y2
        JACKNIFE  NEGATIVE PREDICTIVE VALUES PLOT Y1 Y2

Default:
    None
 
Synonyms:
    NPV is a synonym for NEGATIVE PREDICTIVE VALUE.

Related Commands:
    POSITIVE PREDICTIVE VALUE  = Compute the positive predictive
                                 value between two binary variables.
    TRUE POSITIVES             = Compute the proportion of
                                 true positives.
    TRUE NEGATIVES             = Compute the proportion of
                                 true negatives.
    FALSE POSITIVES            = Compute the proportion of
                                 false positives.
    FALSE NEGATIVES            = Compute the proportion of
                                 false negatives.
    TEST SENSITIVITY           = Compute the test sensitivity.
    TEST SPECIFICITY           = Compute the test specificity.
    ODDS RATIO                 = Compute the bias corrected
                                 log(odds ratio).
    ODDS RATIO STANDARD ERROR  = Compute the standard error of the
                                 bias corrected log(odds ratio).
    RELATIVE RISK              = Compute the relative risk.
    TABULATE                   = Compute a statistic for data with
                                 a single grouping variable.
    CROSS TABULATE             = Compute a statistic for data with
                                 two grouping variables.
    STATISTIC PLOT             = Generate a plot of a statistic for
                                 data with a single grouping
                                 variable.
    CROSS TABULATE PLOT        = Generate a plot of a statistic for
                                 data with two grouping variables.
    BOOTSTRAP PLOT             = Generate a bootstrap plot for a
                                 given statistic.
 
Reference:
    Fleiss, Levin, and Paik (2003), "Statistical Methods for
    Rates and Proportions", Third Edition, Wiley, chapter 1.
 
Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/4
 
Program:
    let n = 1
    .
    let p = 0.2
    let y1 = binomial rand numb for i = 1 1 100
    let p = 0.1
    let y2 = binomial rand numb for i = 1 1 100
    .
    let p = 0.4
    let y1 = binomial rand numb for i = 101 1 200
    let p = 0.08
    let y2 = binomial rand numb for i = 101 1 200
    .
    let p = 0.15
    let y1 = binomial rand numb for i = 201 1 300
    let p = 0.18
    let y2 = binomial rand numb for i = 201 1 300
    .
    let p = 0.6
    let y1 = binomial rand numb for i = 301 1 400
    let p = 0.45
    let y2 = binomial rand numb for i = 301 1 400
    .
    let p = 0.3
    let y1 = binomial rand numb for i = 401 1 500
    let p = 0.1
    let y2 = binomial rand numb for i = 401 1 500
    .
    let x = sequence 1 100 1 5
    .
    let a = negative predictive value y1 y2 subset x = 1
    tabulate negative predictive value y1 y2 x
    .
    label case asis
    xlimits 1 5
    major xtic mark number 5
    minor xtic mark number 0
    xtic mark offset 0.5 0.5
    ytic mark offset 0.05 0.05
    y1label Negative Predictive Value
    x1label Group ID
    character x blank
    line blank solid
    .
    negative predictive value plot y1 y2 x
 
-----NEWS-------------------------------------------------------
 
NEWS
 
Name:
    NEWS
 
Type:
    Support Command
 
Purpose:
    Prints out the news, course announcements, new commands, etc. to
    the general user population.
 
Syntax:
    NEWS
 
Examples:
    NEWS
 
Note:
    The NEWS file documents new commands that may not be documented
    elsewhere.  The NEWS command typically only prints the most recent
    enhancements.  However, the complete NEWS file contains a
    historical record of additions.  Contact your local site installer
    for instructions on printing the entire news file.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MAIL = Lists the mail file.
    HELP = Lists portions of the help file.
    BUGS = Lists the bugs file.
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----NEXT COMPOSITION (LET)-----------------------------------------
 
NEXT COMPOSITION
 
Name:
    NEXT COMPOSITION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate the next composition of a positive integer.
 
Description:
    Given positive integers n and k, a composition of n into k
    parts is defined as

       n = r1 + r2 + ... + rk  (r(i) >= 0, i = 1,k)

    (the order of r1, ..., rk is significant).

    The number of compositions is given by

        (n+k-1   n)  = (n+k-1)!/[(n!*(k-1)!]

    This command can be used to generate all of these compositions
    for given values of n and k.  Each time this command is called
    for a given value of n and k, the next composition is returned.
    Note that the first call with a given value of n and k has a
    slightly different syntax than the subsequent calls since the
    subsequent calls need to specify the most recent composition
    generated.

    The output is an array of size k.

Syntax 1:
    LET <y> = NEXT COMPOSITION <k> <n>
    where <k> is a number or parameter that specifies the number
              of elements in the composition;
          <n> is a number or parameter that specifies the integer
              for which the composition is being generated;
    and   <y> is a variable where the composition is saved.
 
    This syntax is used to return the first composition in the
    sequence of compositions.

Syntax 2:
    LET <y> = NEXT COMPOSITION <k> <n> <yprev>
    where <k> is a number or parameter that specifies the number
              of elements in the composition;
          <n> is a number or parameter that specifies the integer
              for which the composition is being generated;
          <yprev> is a variable which contains the most recent
              composition;
    and   <y> is a variable where the composition is saved.
 
    This syntax is used to return all compositions in the sequence
    of compositions after the first composition has been generated.

Examples:
    LET N = 5
    LET K = 3
    LET Y = NEXT COMPOSITION K N
 
Note:
    Dataplot implements this command using the NEXCOM algorithm 
    described in Nijenhuis and Wilf (see Reference section
    below).
 
Note:
    Dataplot saves the internal parameter LASTSEQU when this
    command is entered.  If LASTSEQU = 1, this indicates that
    the current composition is the last composition in the
    sequence for the given values of n and k.  Otherwise, the
    value of LASTSEQU will be set to 0.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                          = Generate data transformations.
    RANDOM SUBSET                = Generate a random subset.
    RANDOM PERMUTATION           = Generate a random permutation.
    RANDOM K-SET OF N-SET        = Generate a random k-set of n-set.
    RANDOM COMPOSITION           = Generate a random composition.
    RANDOM PARTITION             = Generate a random partition.
    RANDOM EQUIVALENCE RELATION  = Generate a random partition.
    NEXT SUBSET                  = Generate the next subset of a set.
    NEXT PERMUTATION             = Generate the next permutation.
    NEXT K-SET OF N-SET          = Generate the next k-set of n-set.
    NEXT PARTITION               = Generate the next partition.
    NEXT EQUIVALENCE RELATION    = Generate the next composition.
 
 
References:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 5.

Applications:
    Combinatorial Analysis
 
Implementation Date:
    2009/1
 
Program:
    LET N = 6
    LET K = 3
    SET WRITE REWIND OFF
    SET WRITE DECIMALS 0
    WRITE COMPOSITION.OUT "COMPOSITIONS FOR N = 3"
    LET Y = NEXT COMPOSITION K N
    LET YPREV = Y
    WRITE COMPOSITION.OUT "COMPOSITION 1:"
    WRITE COMPOSITION.OUT Y
    WRITE COMPOSITION.OUT " "
    WRITE COMPOSITION.OUT " "
    LET NUMCOMP = 1
    LOOP FOR L = 2 1 30
        LET NUMCOMP = NUMCOMP + 1
        LET Y = NEXT COMPOSITION K N YPREV
        WRITE COMPOSITION.OUT "COMPOSITION ^L:"
        WRITE COMPOSITION.OUT Y
        WRITE COMPOSITION.OUT " "
        WRITE COMPOSITION.OUT " "
        LET YPREV    = Y
        IF LASTSEQU = 1
           BREAK LOOP
        END OF IF
    END OF LOOP
    WRITE COMPOSITION.OUT "NUMBER OF COMPOSITIONS: ^NUMCOMP"

-----NEXT EQUIVALENCE RELATION (LET)-------------------------------
 
NEXT EQUIVALENCE RELATION
 
Name:
    NEXT EQUIVALENCE RELATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate the next equivalence relation of a an n-element set.
 
Description:
    Given a set S = {1, 2, ..., n}, a partition of S is defined as
    a collection of sets T1, T2, ... , Tk satisfying

        1) The intersection of T(i) and T(j) is the empty
           set for i not equal j.

        2) The union of all k sets contains all the elements
           of S.

    For example, if n = 3, then there are 5 possible partitions:

        {1, 2, 3}
        {1,2} {3}
        {1, 3} {2}
        {2, 3} {1}
        {1} {2} {3}
      
    The output of this command is an array of size n where
    the ith element identifies the class which i belongs to.
    For example, the following array (for n = 5)

        3  3  1  2  2

    identifies the partition

       {3}  {4, 5}  {1, 2}
   
    A partition of a set is identical with an equivalence
    relation on the set with the T(i) as the equivalence classes.

Syntax 1:
    LET <y> <yp> = NEXT EQUIVALENCE RELATION  <n>
    where <n> is a number or parameter that specifies the size of
              the original set;
          <yp> is a variable that contains the number of elements
              in the ith classs of the output partition;
    and   <y> is a variable where the equivalence relation is saved.
 
    This syntax is used to return the first equivalence relation
    in the sequence of equivalence relation.
    
    The <yp> values are not of primary interest.  They are
    returned because the current values of this array are needed
    in computing the next equivalence relation in the sequence.

Syntax 2:
    LET <y> <yp> = NEXT EQUIVALENCE RELATION  <n>  <yprev>  <ypold>
    where <n> is a number or parameter that specifies the size of
              the original set;
          <yprev> is a variable that contains the most recently
              generated values for the given value of <n>;
          <ypold> is a variable that contains the most recently
              generated values for the <yp> variable;
          <yp> is a variable that contains the number of elements
              in the ith classs of the output partition;
    and   <y> is a variable where the equivalence relation is saved.
 
    This syntax is used to return the all equivalence relations in
    the sequence of equivalence relations after the first equivalence
    relation has been generated.
    
    The <yp> values are not of primary interest.  They are
    returned because the current values of this array are needed
    in computing the next equivalence relation in the sequence.

Examples:
    LET N = 5
    LET Y = NEXT EQUIVALENCE RELATION
 
Note:
    Dataplot implements this command using the NEXEQU algorithm 
    described in Nijenhuis and Wilf (see Reference section
    below).
 
Note:
    Dataplot saves the internal parameter LASTSEQU when this
    command is entered.  If LASTSEQU = 1, this indicates that
    the current equivalence relation is the last equivalence
    relation in the sequence for the given value of n.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                          = Generate data transformations.
    RANDOM SUBSET                = Generate a random subset.
    RANDOM PERMUTATION           = Generate a random permutation.
    RANDOM K-SET OF N-SET        = Generate a random k-set of n-set.
    RANDOM COMPOSITION           = Generate a random composition.
    RANDOM PARTITION             = Generate a random partition.
    RANDOM EQUIVALENCE RELATION  = Generate a random partition.
    NEXT SUBSET                  = Generate the next subset of a set.
    NEXT PERMUTATION             = Generate the next permutation.
    NEXT K-SET OF N-SET          = Generate the next k-set of n-set.
    NEXT COMPOSITION             = Generate the next composition.
    NEXT PARTITION               = Generate the next partition.
 
 
References:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 11.

Applications:
    Combinatorial Analysis
 
Implementation Date:
    2009/1
 
Program:
    LET N = 5
    SET WRITE REWIND OFF
    SET WRITE DECIMALS 0
    WRITE EQUIVALENCE.OUT "EQUIVALENCE RELATIONS FOR N = 5"
    LET Y YP = NEXT EQUIVALENCE RELATION N
    LET YPREV = Y
    LET YPOLD = YP
    WRITE EQUIVALENCE.OUT "EQUIVALENCE RELATION 1:"
    WRITE EQUIVALENCE.OUT Y
    WRITE EQUIVALENCE.OUT " "
    WRITE EQUIVALENCE.OUT " "
    LET NUMEQUIV = 1
    LOOP FOR K = 2 1 100
        LET NUMEQUIV = NUMEQUIV + 1
        . LET Y YP = NEXT EQUIVALENCE RELATION N YPREV YPOLD
        LET Y YP = NEXT EQUIVALENCE RELATION N YPREV YPOLD
        WRITE EQUIVALENCE.OUT "EQUIVALENCE RELATION ^K:"
        WRITE EQUIVALENCE.OUT Y
        WRITE EQUIVALENCE.OUT " "
        WRITE EQUIVALENCE.OUT " "
        DELETE YPREV YPOLD
        LET YPREV = Y
        LET YPOLD = YP
        DELETE Y YP
        IF LASTSEQU = 1
           BREAK LOOP
        END OF IF
    END OF LOOP
    WRITE EQUIVALENCE.OUT "NUMBER OF EQUIVALENCE RELATIONS: ^NUMEQUIV"

-----NEXT K-SET OF N-SET (LET)-------------------------------------
 
NEXT K-SET OF N-SET
 
Name:
    NEXT K-SET OF N-SET (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate the next k-set of a an n-set.
 
Description:
    Given a set of n elements {1, 2, ..., n}, a basic
    combinatorial problem is the combination of n things
    taken k at a time.  For a given n and k, there are 

        (n k)  = n!/[k!*(n-k)!]

    k-sets of the original n-set.

    This command can be used to generate all of these k-sets
    of an n-set for given values of n and k.  Each time this
    command is called for given values of n and k, the next
    k-set of an n-set is returned.  Note that the first call
    with given values of n and k has a slightly different
    syntax than the subsequent calls since the subsequent calls
    need to specify the most recent k-set of an n-set generated.

    The output is an array of size k that identifies the
    elements included in the k-set of an n-set.

Syntax 1:
    LET <y> = NEXT K-SET OF N-SET <k> <n>
    where <k> is a number or parameter that specifies the size of
              the k-set;
          <n> is a number or parameter that specifies the number
              of elements in the set;
    and   <y> is a variable where the k-set of an n-set is saved.
 
    This syntax is used to return the first k-set of an n-set in
    the sequence of k-sets of an n-set.

Syntax 2:
    LET <y> = NEXT K-SET OF N-SET <k> <n> <yprev>
    where <k> is a number or parameter that specifies the size of
              the k-set;
          <n> is a number or parameter that specifies the number
              of elements in the set;
          <yprev> is a variable which contains the most recent
              k-set of an n-set;
    and   <y> is a variable where the k-set of an n-set is saved.
 
    This syntax is used to return all k-sets of an n-set in the
    sequence of k-sets of an n-set after the first k-set of an n-set
    has been generated.

Examples:
    LET N = 5
    LET K = 3
    LET Y = NEXT K-SET OF N-SET K  N
 
Note:
    Dataplot implements this command using the algorithm 
    NEXKSB described in Nijenhuis and Wilf (see Reference section
    below).
 
Note:
    Dataplot saves the internal parameter LASTSEQU when this
    command is entered.  If LASTSEQU = 1, this indicates that
    the current k-set of an n-set is the last k-set of an n-set
    in the sequence for given values of n and k.  Otherwise, the
    value of LASTSEQU will be set to 0.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                          = Generate data transformations.
    RANDOM SUBSET                = Generate a random subset.
    RANDOM PERMUTATION           = Generate a random permutation.
    RANDOM K-SET OF N-SET        = Generate a random k-set of n-set.
    RANDOM COMPOSITION           = Generate a random composition.
    RANDOM PARTITION             = Generate a random partition.
    RANDOM EQUIVALENCE RELATION  = Generate a random partition.
    NEXT SUBSET                  = Generate the next subset of a set.
    NEXT PERMUTATION             = Generate the next permutation.
    NEXT COMPOSITION             = Generate the next composition.
    NEXT PARTITION               = Generate the next partition.
    NEXT EQUIVALENCE RELATION    = Generate the next composition.
 
References:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 3.

Applications:
    Combinatorial Analysis
 
Implementation Date:
    2009/1
 
Program:
    LET N = 5
    LET K = 3
    LET NTOT = BINOMIAL(N,K)
    SET WRITE REWIND OFF
    SET WRITE DECIMALS 0
    WRITE KSET.OUT "ALL K-SETS OF AN N-SET FOR N = ^N AND K = ^K"
    LET Y = NEXT K-SET OF N-SET K N
    LET YPREV = Y
    WRITE KSET.OUT "K-SET 1:"
    WRITE KSET.OUT Y
    WRITE KSET.OUT " "
    WRITE KSET.OUT " "
    LOOP FOR L = 2 1 NTOT
        LET Y = NEXT K-SET OF N-SET K N YPREV
        WRITE KSET.OUT "K-SET ^L:"
        WRITE KSET.OUT Y
        WRITE KSET.OUT " "
        WRITE KSET.OUT " "
        LET YPREV = Y
    END OF LOOP

-----NEXT PARTITION (LET)-----------------------------------------
 
NEXT PARTITION
 
Name:
    NEXT PARTITION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate the next partition of a positive integer.
 
Description:
    Given a positive integer n, a partition of n is defined as

        n = r1 + r2 + ... + rk  (r1 >= r2 >= ... >= rk)

    where r1, r2, ...., rk are positive integers.

    For example, if n = 6, then there are 3 partitions with 3
    elements:

        6 = 4 + 1 + 1
          = 3 + 2 + 1
          = 2 + 2 + 2
   
    This command can be used to generate all of these partitions
    for a given value of n.  Each time this command is called for
    a given value of n, the next partition is returned.  Note that
    the first call with a given value of n has a slightly different
    syntax than the subsequent calls since the subsequent calls
    need to specify the most recent partition generated.

    The output is a pair of vectors.  The first vector contains
    the integers in the partition while the second vector contains
    the number of times the corresponding integer in the first
    vector is contained in the partition.

Syntax 1:
    LET <yval> <yrepeat> = NEXT PARTITION <n>
    where <n> is a number or parameter that specifies the size of
              the set;
          <yval> is a variable containing the values for the current
              permutation;
    and   <yrepeat> is a variable containing the repeat values for
              the current permutation.
 
    This syntax is used to return the first partition in the
    sequence of partitions.

Syntax 2:
    LET <yval> <yrepeat> = NEXT PARTITION <n> <yvalold> <yrepold>
    where <n> is a number or parameter that specifies the size of
              the set;
          <yvalold> is a variable that contains the most recently
              generated values for the given value of <n>;
          <yrepold> is a variable that contains the most recently
              generated repeat values for the given value of <n>;
          <yval> is a variable containing the values for the current
              permutation;
    and   <yrepeat> is a variable containing the repeat values for
              the current permutation.
 
    This syntax is used to return the all partitions in the sequence
    of partitions after the first partition has been generated.

Examples:
    LET N = 6
    LET YVAL2 YREPEAT2 = NEXT PARTITION N
    LET YVAL1 YREPEAT1 = NEXT PARTITION N YVAL2 YREPEAT2
 
Note:
    Dataplot implements this command using the NEXPAR algorithm 
    described in Nijenhuis and Wilf (see Reference section
    below).
 
Note:
    Dataplot saves the internal parameter LASTSEQU when this
    command is entered.  If LASTSEQU = 1, this indicates that
    the current partition is the last partition in the sequence
    for the given value of n.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                          = Generate data transformations.
    RANDOM SUBSET                = Generate a random subset.
    RANDOM PERMUTATION           = Generate a random permutation.
    RANDOM K-SET OF N-SET        = Generate a random k-set of n-set.
    RANDOM COMPOSITION           = Generate a random composition.
    RANDOM PARTITION             = Generate a random partition.
    RANDOM EQUIVALENCE RELATION  = Generate a random partition.
    NEXT SUBSET                  = Generate the next subset of a set.
    NEXT PERMUTATION             = Generate the next permutation.
    NEXT K-SET OF N-SET          = Generate the next k-set of n-set.
    NEXT COMPOSITION             = Generate the next composition.
    NEXT EQUIVALENCE RELATION    = Generate the next composition.
 
References:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 9.

Applications:
    Combinatorial Analysis
 
Implementation Date:
    2009/1
 
Program:
    LET N = 3
    SET WRITE REWIND OFF
    SET WRITE DECIMALS 0
    WRITE PARTITION.OUT "PARTITIONS FOR N = 3"
    LET Y YREP = NEXT PARTITION N
    LET YPREV    = Y
    LET YREPPREV = YREP
    WRITE PARTITION.OUT "PARTITION 1:"
    WRITE PARTITION.OUT Y YREP
    WRITE PARTITION.OUT " "
    WRITE PARTITION.OUT " "
    LET NUMPAR = 1
    LOOP FOR K = 2 1 10
        LET NUMPAR = NUMPAR + 1
        LET Y YREP = NEXT PARTITION N YPREV YREPPREV
        WRITE PARTITION.OUT "PARTITION ^K:"
        WRITE PARTITION.OUT Y YREP
        WRITE PARTITION.OUT " "
        WRITE PARTITION.OUT " "
        DELETE YPREV YREPPREV
        LET YPREV    = Y
        LET YREPPREV = YREP
        DELETE Y YREP
        IF LASTSEQU = 1
           BREAK LOOP
        END OF IF
    END OF LOOP
    WRITE PARTITION.OUT "NUMBER OF PARTITIONS: ^NUMPAR"

-----NEXT PERMUTATION (LET)-----------------------------------------
 
NEXT PERMUTATION
 
Name:
    NEXT PERMUTATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate the next permutation of n letters.
 
Description:
    For a given value of n, there are n! permuations of the
    integers 1, 2, ..., n.  For example, for n = 3, there
    are 3*2*1 = 6 permutations:

       1  2  3
       1  3  2
       3  1  2
       3  2  1
       2  3  1
       2  1  3
   
    This command can be used to generate all of the permutations
    for a given value of n.  Each time this command is called for
    a given value of n, the next permutation is returned.  Note
    that the first call with a given value of n has a slightly
    different syntax than the subsequent calls since the subsequent
    calls need to specify the most recent permutation generated.

    The output is an array of size n that contains each of the
    integers from 1 to n exactly once.
 
Syntax 1:
    LET <y> = NEXT PERMUTATION <n>
    where <n> is a number or parameter that specifies the size of
              the set;
    and   <y> is a variable where the current permutation is saved.
 
    This syntax is used to return the first permutation in the
    sequence of permutations.

Syntax 2:
    LET <y> = NEXT PERMUTATION  <n>  <yprev>
    where <n> is a number or parameter that specifies the size of
              the set;
          <yprev> is a variable that contains the most recently
              generated permutation for the given value of <n>;
    and   <y> is a variable where the current permutation is saved.
 
    This syntax is used to return all permutations in the sequence
    of permutations after the first permutation has been generated.

 
Examples:
    LET Y = NEXT PERMUTATION N
    LET Y = NEXT PERMUTATION N YPREV
 
Note:
    Dataplot implements this command using the algorithm NEXPER
    described in Nijenhuis and Wilf (see Reference section
    below).
 
Note:
    Dataplot saves the internal parameter LASTSEQU when this
    command is entered.  If LASTSEQU = 1, this indicates that
    the current permutation is the last permutation in the sequence
    for the given value of n.  Otherwise, the value of LASTSEQU
    will be set to 0.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                          = Generate data transformations.
    RANDOM SUBSET                = Generate a random subset.
    RANDOM PERMUTATION           = Generate a random permutation.
    RANDOM K-SET OF N-SET        = Generate a random k-set of n-set.
    RANDOM COMPOSITION           = Generate a random composition.
    RANDOM PARTITION             = Generate a random partition.
    RANDOM EQUIVALENCE RELATION  = Generate a random partition.
    NEXT PERMUTATION             = Generate the next permutation.
    NEXT K-SET OF N-SET          = Generate the next k-set of n-set.
    NEXT COMPOSITION             = Generate the next composition.
    NEXT PARTITION               = Generate the next partition.
    NEXT EQUIVALENCE RELATION    = Generate the next composition.
 
References:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 7.

Applications:
    Combinatorial Analysis
 
Implementation Date:
    2009/1
 
Program:
    LET N = 4
    LET NTOT = GAMMA(N+1)
    SET WRITE REWIND OFF
    SET WRITE DECIMALS 0
    WRITE PERM.OUT "ALL PERMUTATIONS FOR N = ^N"
    LET Y = NEXT PERMUTATION N
    LET YPREV = Y
    WRITE PERM.OUT "PERMUTATION 1:"
    WRITE PERM.OUT Y
    WRITE PERM.OUT " "
    WRITE PERM.OUT " "
    LOOP FOR K = 2 1 NTOT
        LET Y = NEXT PERMUTATION N YPREV
        WRITE PERM.OUT "PERMUTATION ^K:"
        WRITE PERM.OUT Y
        WRITE PERM.OUT " "
        WRITE PERM.OUT " "
        LET YPREV = Y
    END OF LOOP

-----NEXT SUBSET (LET)-----------------------------------------
 
NEXT SUBSET
 
Name:
    NEXT SUBSET (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate the next subset of an n-set.
 
Description:
    A basic combinatorial problem is to generate the 2**n subsets
    of the set {1, 2, ..., n}.  For a given value of n there are
    2**n subsets.

    This command can be used to generate all of these subsets for
    a given value of n.  Each time this command is called for a
    given value of n, the next subset is returned.  Note that the
    first call with a given value of n has a slightly different
    syntax than the subsequent calls since the subsequent calls
    need to specify the most recent subset generated.

    The output is an array of zero and one values where zero
    for the ith element of the set indicates the element is not
    present and a value of one indicates the ith element is
    present.  For example, if n = 5 an output array of

        1 0 0 1 1

    specifies that elements 1, 4, and 5 are present while
    elements 2 and 3 are not.

Syntax 1:
    LET <y> = NEXT SUBSET <n>
    where <n> is a number or parameter that specifies the size of
              the set;
    and   <y> is a variable where the current subset is saved.
 
    This syntax is used to return the first subset in the sequence
    of subsets.

Syntax 2:
    LET <y> = NEXT SUBSET  <n>  <yprev>
    where <n> is a number or parameter that specifies the size of
              the set;
          <yprev> is a variable that contains the most recently
              generated subset for the given value of <n>;
    and   <y> is a variable where the current subset is saved.
 
    This syntax is used to return all subsets in the sequence
    of subsets after the first subset has been generated.

Examples:
    LET Y = NEXT SUBSET N
    LET Y = NEXT SUBSET N YPREV
 
Note:
    Dataplot implements this command using the algorithm NEXSUB
    described in Nijenhuis and Wilf (see Reference section
    below).
 
Note:
    Dataplot saves the internal parameter LASTSEQU when this
    command is entered.  If LASTSEQU = 1, this indicates that
    the current subset is the last subset in the sequence
    for the given value of n.  Otherwise, the value of LASTSEQU
    will be set to 0.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                          = Generate data transformations.
    RANDOM SUBSET                = Generate a random subset.
    RANDOM PERMUTATION           = Generate a random permutation.
    RANDOM K-SET OF N-SET        = Generate a random k-set of n-set.
    RANDOM COMPOSITION           = Generate a random composition.
    RANDOM PARTITION             = Generate a random partition.
    RANDOM EQUIVALENCE RELATION  = Generate a random partition.
    NEXT PERMUTATION             = Generate the next permutation.
    NEXT K-SET OF N-SET          = Generate the next k-set of n-set.
    NEXT COMPOSITION             = Generate the next composition.
    NEXT PARTITION               = Generate the next partition.
    NEXT EQUIVALENCE RELATION    = Generate the next composition.
 
References:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 1.

Applications:
    Combinatorial Analysis
 
Implementation Date:
    2009/1
 
Program:
    LET N = 3
    LET NTOT = 2**N
    SET WRITE REWIND OFF
    SET WRITE DECIMALS 0
    WRITE SUBSET.OUT "ALL SUBSETS FOR N = 3"
    LET Y = NEXT SUBSET N
    LET YPREV = Y
    PRINT Y
    WRITE SUBSET.OUT "SUBSAMPLE 1:"
    WRITE SUBSET.OUT Y
    WRITE SUBSET.OUT " "
    WRITE SUBSET.OUT " "
    LOOP FOR K = 2 1 NTOT
        LET Y = NEXT SUBSET N YPREV
        WRITE SUBSET.OUT "SUBSAMPLE ^K:"
        WRITE SUBSET.OUT Y
        WRITE SUBSET.OUT " "
        WRITE SUBSET.OUT " "
        LET YPREV = Y
    END OF LOOP

-----NLIST-------------------------------------------------------
 
NLIST
 
Name:
    NLIST
 
Type:
    Support Command
 
Purpose:
    Generate a list with line numbers.
 
Description:
    This command can be useful for things such as seeing how many
    header lines need to be skipped at the beginning of a data file.
 
Syntax 1:
    NLIST    <filename>
    where <file name> is the file to list.
 
Syntax 2:
    NLIST    <filename>  FOR I = <start> <inc> <stop>
    where <file name> is the file to list;
          <start> specifies the first line to list;
          <inc>   specifies the increment between lines (this is almost
                  always 1);
    and   <stop> specifies the last row to list.
 
Examples:
    NLIST PLOTCAL.DP
    NLIST PLOTCAL.DAT FOR I = 1 1 25
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LIST          = List the contents of a file.
    SKIP          = Specify the number of lines to skip at the
                    beginning of a data file.
    ROW LIMITS    = Specify which rows to read in a data file.
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----NOR-------------------------------------------------------
 
NOR
 
Name:
    NOR
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Draws a Nor Gate (a logical device used in electronic circuit
    diagrams).
 
Description:
    The 2 pairs of coordinates define the the (x,y) values for the
    middle back and the middle front (respectively) of the Nor Gate.
 
Syntax:
    NOR   <x1>   <y1>   <x2>   <y2>
    where <x1> is a number or parameter in the decimal range 0 to 100
               that specifies the x coordinate for the middle back of
               the Nor Gate;
          <y1> is a number or parameter in the decimal range 0 to 100
               that specifies the y coordinate for the middle back of
               the Nor Gate;
          <x2> is a number or parameter in the decimal range 0 to 100
               that specifies the x coordinate for the middle front
               of the Nor Gate;
    and   <y2> is a number or parameter in the decimal range 0 to 100
               that specifies the y coordinate for the middle front of
               the Or Gate;
 
Examples:
    NOR 50 50 60 50
    NOR 50 50 60 60
    NOR 20 20 25 20
 
Note:
    The line style (i.e., SOLID, DASH), line color, and line thickness
    are controlled by the first entry of the LINE, LINE COLOR, and
    LINE THICKNESS commands respectively.
 
Note:
    The keywords DATA and RELATIVE were added to the TRIANGLE
    command 7/1997.  These keywords are independent and can
    be used separately or together.  For example, 
    TRIANGLE DATA, TRIANGLE RELATIVE, or TRIANGLE DATA RELATIVE.
    The word DATA should come before the word RELATIVE if both
    appear.

    DATA means that the coordinates are specified in terms of
    the data units of the most recent plot rather than Dataplot
    0 to 100 screen units.

    RELATIVE means that the coordinates of the first point
    are drawn in absolute coordinates an all subsequent points
    in the figure are relative to that first point.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    AND              = Draws an and gate.
    NAND             = Draws a nand gate.
    OR               = Draws an or gate.
    MOVE             = Moves to a point.
    DRAW             = Draws a line.
    LINES            = Sets the line type for figures and plot lines.
    LINE THICKNESSES = Sets the line thickness for figures and plot
                       lines.
    LINE COLOR       = Sets the line colors for figures and plot lines.
    CROSS-HAIR       = Activates and reads the cross-hair.
    TEXT             = Writes a text string.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    LINE SOLID
    LINE COLOR BLACK
    LINE THICKNESS 0.2
    NOR 20 20 60 60
    MOVE 20 70
    TEXT NOR COORDINATES (20,20), (60,60)
 
-----NORCDF (LET)--------------------------------
 
NORCDF
 
Name:
    NORCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard normal (i.e, mean=0, sd=1) cumulative
    distribution function.
 
Description:
    The normal distribution has the following probability density
    function:
       f(x)=(1/sqrt(2*PI))*e**-(1/2)*x**2
    The cumulative distribution is the area from negative infinity to x
    (i.e., the integral of the above function).
 
    The input value can be any real number.  Since this is a
    probability function, the returned value will be between 0 and 1.
 
Syntax:
    LET <y2> = NORCDF(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed normal cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NORCDF(3)
    LET A = NORCDF(A1)
    LET X2 = NORCDF(X1)
 
Note:
    The cdf values for non-standard normal distributions can be
    computed by standardizing the input value.  For example, suppose
    Y contains a set of data and you want the cdf value corresponding
    to Y = 8:
        LET M = MEAN Y
        LET SD = STANDARD DEVIATION Y
        LET PT = 8
        LET NEWPT = (PT - M)/SD
        LET CDFPT = NORCDF(NEWPT)
        PRINT "CDF VALUE FOR ^PT = ^CDFPT"
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHSPDF = Compute the chi-square probability density function.
    CHSCDF = Compute the chi-square cumulative distribution function.
    CHSPPF = Compute the chi-square percent point function.
    FCDF   = Compute the F cumulative distribution function.
    FPDF   = Compute the F probability density function.
    FPPF   = Compute the F percent point function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
    TCDF   = Compute the T cumulative distribution function.
    TPDF   = Compute the T probability density function.
    TPPF   = Compute the T percent point function.
    WEICDF = Compute the Weibull cumulative distribution function.
    WEIPDF = Compute the Weibull probability density function.
    WEIPPF = Compute the Weibull percent point function.
 
Reference:
    "Continuous Univariate Distributions", Johnson and Kotz, 1970.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    YLIMITS 0 1
    MAJOR YTIC NUMBER 6
    MINOR YTIC NUMBER 1
    YTIC DECIMAL 1
    XLIMITS -3 3
    XTIC OFFSET 0.6 0.6
    PLOT NORCDF(X) FOR X = -3.5 0.01 3.5
 
-----NORCHAZ (LET)--------------------------------
 
NORCHAZ
 
Name:
    NORCHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the normal cumulative hazard function.
 
Description:
    The normal distribution has the following cumulative hazard
    function:

       H(x)=-LOG(1 - NORCDF(x))         -infinity <= x <= infinity

    where NORCDF is the normal cumulative distribution function.

Syntax:
    LET <y2> = NORCHAZ(<y1>,<loc>,<scale>)
                                 <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a number, parameter, or variable;
          <loc> is a number, parameter, or variable containing the
               location parameter;
          <scale> is a number, parameter, or variable containing the
               scale parameter;
          <y2> is a parameter or variable (depending on what <y1>
               is) where the computed normal cumulative hazard value
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The location and scale parameters are optional.

Examples:
    LET A = NORCHAZ(3)
    LET A = NORCHAZ(A1)
    LET X2 = NORCHAZ(X1,10,50)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NORHAZ  = Compute the normal hazard function.
    NORPDF  = Compute the normal probability density function.
    WEIHAZ  = Compute the Weibull hazard function.
    LGNHAZ  = Compute the lognormal hazard function.
    EXPHAZ  = Compute the exponential hazard function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", Johnson, Kotz,
    and Balakrishnan, John wiley and Sons, 1994.
 
Applications:
    Reliability
 
Implementation Date:
    1998/5
 
Program:
    TITLE AUTOMATIC
    PLOT NORCHAZ(X) FOR X = -5 0.1 5
 
-----NORHAZ (LET)--------------------------------
 
NORHAZ
 
Name:
    NORHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard normal (i.e, mean=0, sd=1) hazard function.
 
Description:
    The normal distribution has the following hazard function:

       h(x)=NORPDF(x)/(1 - NORCDF(x))      -infinity <= x <= infinity

    where NORPDF is the normal probability density function and
    NORCDF is the normal cumulative distribution function.

Syntax:
    LET <y2> = NORHAZ(<y1>,<loc>,<scale>)
                                 <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a number, parameter, or variable;
          <y2> is a parameter or variable (depending on what <y1>
               is) where the computed normal hazard value is stored;
          <loc> is a number, parameter, or variable containing the
               location parameter;
          <scale> is a number, parameter, or variable containing the
               scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The location and scale parameters are optional.

Examples:
    LET A = NORHAZ(3)
    LET A = NORHAZ(A1)
    LET X2 = NORHAZ(X1,10,50)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NORCHAZ = Compute the normal cumulative hazard function.
    NORPDF  = Compute the normal probability density function.
    WEIHAZ  = Compute the Weibull hazard function.
    LGNHAZ  = Compute the lognormal hazard function.
    EXPHAZ  = Compute the exponential hazard function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", Johnson, Kotz,
    and Balakrishnan, John wiley and Sons, 1994.
 
Applications:
    Reliability
 
Implementation Date:
    1998/5
 
Program:
    TITLE AUTOMATIC
    PLOT NORHAZ(X) FOR X = -5 0.1 5
 
-----NORMAL KERNEL DENSITY MIXTURE PLOT--------------------------------
 
NORMAL KERNEL DENSITY MIXTURE PLOT
 
Name:
    NORMAL KERNEL DENSITY MIXTURE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a normal kernel density mixture plot from means and
    standard deviations.
 
Description:
    Data for reference materials, interlaboratory studies, and key
    comparisons is often given as a mean and an associated standard
    deviation.  It is often assumed that the data for each laboratory
    is from a normal distribution.

    This command plots the following:

       1. The first curve is the laboratory means versus the laboratory
          number.

       2. The second curve is the mixture of normal probability
          densities of the individual laboratories.  This mixture
          is computed by

          a. For each individual laboratory, compute the ybar +/- 4*s
             points where ybar and s denote the mean and standard
             deviation of the laboratory.

          b. Find the minimum and maximum value of these points over all
             the laboratories.  Define a grid of 1,000 equally spaced
             points between the minimum and maximum point.

          c. At each grid point, compute the normal probability density
             function (PDF) for each laboratory (each laboratory will
             use its own mean and standard deviation for the parameters
             of the normal distribution).  The PDF values for all
             laboratories are summed and then the value at the grid point
             is normalized by dividing by the number of laboratories.

          d. If the maximum density value is < 2.8, the density values are
             scaled so that the maximum density is 3.  This is done for
             visual resolution of the plot.  If the density values
             themselves are of interest, you can use the
             NORMAL KERNEL DENSITY MIXTURE (LET) command to obtain them.

          e. The value NLAB + 1, with NLAB denoting the number of
             laboratories, is added to the density value to determine
             the plot position.

       3. The third curve is the normal probability densities for the
          indiviual laboratories.  That is, a normal PDF curve is drawn
          using the mean and standard deviation of the indiviual
          laboratory.  This curve is drawn using 100 points from
          ybar - 3*s to ybar + 3*s.  The value NLAB is added to the
          vertical value to obtain the plotting position.

       4. The fourth curve draws a solid line from ybar - 2*s to
          ybar + 2*s.  The vertical coordinate is set to NLAB.

Syntax:
    NORMAL KERNEL DENSITY MIXTURE PLOT <ymean> <ysd> 
                          <SUBSET/EXCEPT/FOR qualification>
    where <ymean> is a response variable containg the means;
          <ysd> is a response variable containng the standard deviations;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    NORMAL KERNEL DENSITY MIXTURE PLOT YMEAN YSD
    NORMAL KERNEL DENSITY MIXTURE PLOT YMEAN YSD SUBSET YSD > 0
 
Note:
    For small values of the standard deviation, the normal PDF for a
    given laboratory may be greater than 1 and therefore overlap the
    normal PDF for one or more succeeding laboratories.  You can
    use the following command to multiply the density value by a
    constant to minimize this overlap

        SET NORMAL KERNEL DENSITY MIXTURE PLOT EXPANSION FACTOR <value>

    where <value> has a default value of 1.  If <value> is less than
    0.01, it will be set to 1.

    This expansion factor will be applied to all of the normal PDF
    curves.  This is used for visual purposes only.  It is the shape and
    height of the normal PDF curves relative to the other laboratories
    that is relevant in this graph.  The expansion factor maintains this
    relative height.

Note:
    The appearance of the plot can be controlled with the various LINE
    and CHARACTER commands.  This is demonstrated in the program example
    below.

    The settings for trace 3 apply to all of the normal PDF curves for
    the individual laboratories.  Likewise, the settings for trace 4
    apply to all of the ybar +/- 2*s lines.

Note:
    The HORIZONTAL SWITCH command can be used to draw these graphs
    vertically rather than horizontally.  This is demonstrated in the
    program example below.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NORMAL KERNEL DENSITY MIXTURE  = Compute the normal kernel density
                                     mixture for a set of means and
                                     associated standard deviations.
    CONSENSUS MEANS                = Perform a consensus means analysis.
    E691                           = Perform an E-691 analysis.
 
Reference:
    Duewer (2008), "A Comparison of Location Estimators for
    Interlaboratory Data Contaminated with Value and Uncertainty
    Outliers", Accredited Quality Assurance, Vol. 13, pp. 193-216.

Applications:
    Interlaboratry Analysis
 
Implementation Date:
    2017/07
 
Program:
    . Step 1:   Read the data (from David Duewer paper)
    .
    skip 25
    read duewer1.dat ymean ysd
    .
    . Step 2:   Set some plot control features
    .
    label case asis
    title case asis
    title offset 2
    y1label Measurement Value
    x1label Lab
    title Normal Kernel Density Mixture Plot for Duewer Data
    .
    xlimits 1 10
    major x1tic mark number 10
    minor x1tic mark number 0
    tic mark offset units data
    x1tic mark offset 1 3.2
    ylimits 100 110
    major y1tic mark number 6
    minor y1tic mark number 1
    y1tic mark offset 1 1
    horizontal switch on
    .
    line blank
    line thickness 0.1 0.1 0.1 0.2
    line color black black red blue
    character circle
    character hw 1 0.75
    character fill on
    .
    normal kernel density mixture plot ymean ysd
    .
    line solid
    drawdsds 10 20 10 90

-----NORMAL KERNEL DENSITY MIXTURE (LET)---------------------------------
 
NORMAL KERNEL DENSITY MIXTURE
 
Name:
    NORMAL KERNEL DENSITY MIXTURE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Given a set of means and associated uncertainties, compute the
    mixture of their normal kernels.
 
Description:
    Data for reference materials, interlaboratory studies, and key
    comparisons is often given as a mean and an associated standard
    deviation.  It is often assumed that the data for each laboratory
    is from a normal distribution.

    This command does the following:

       1. For each individual laboratory, compute the ybar +/- 4*s points
          where ybar and s denote the mean and standard deviation of the
          laboratory.

       2. Find the minimum and maximum value of these points over all the
          laboratories.  Define a grid of 1,000 equally spaced points
          between the minimum and maximum point.

       3. At each grid point, compute the normal probability density
          function (PDF) for each laboratory (each laboratory will
          use its own mean and standard deviation for the parameters of
          the normal distribution).  The PDF values for all laboratories
          are summed and then the value at the grid point is normalized by
          dividing by the number of laboratories.

Syntax:
    LET <y> <x> = NORMAL KERNEL DENSITY MIXTURE <ymean> <ysd>
              <SUBSET/EXCEPT/FOR qualification>
    where <ymean> is a variable containing laboratory means;
          <ysd> is a variable containing the standard uncertainties
               associated with the <ymean> variable;
          <x> is a variable containing the values where the normal
               kernel density mixture values are computed;
          <y> is a variable containing the normal kernel density
               mixture values;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET YKERN XKERN = NORMAL KERNEL DENSITY MIXTURE YMEAN YSD
    LET YKERN XKERN = NORMAL KERNEL DENSITY MIXTURE YMEAN YSD SUBSET TAG = 1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CONSENSUS MEAN       = Compute the consensus mean and associated
                           uncertainty.
    KERNEL DENSITY PLOT  = Generate a kernel density plot.
 
Reference:
    Duewer (2008), "A Comparison of Location Estimators for
    Interlaboratory Data Contaminated with Value and Uncertainty
    Outliers", Accredited Quality Assurance, Vol. 13, pp. 193-216.
 
Applications:
    Consensus means, interlaboratory studies, key comparisons
 
Implementation Date:
    2017/02
 
Program:
    . Step 1:   Define the data
    .           (from David Duewer paper)
    .
    read ymean ysd
    102.02   0.16
    102.47   0.84
    102.98   0.90
    103.69   0.45
    104.08   1.16
    105.04   0.39
    105.36   0.32
    107.26   1.50
    108.26   0.77
    end of data
    .
    . Step 2:   Generate the normal kernel density mixture
    .
    let y x = normal kernel density mixture  ymean ysd
    .
    . Step 3:   Plot the result
    .
    label case asis
    title case asis
    title offset 2
    x1label Measurement Value
    y1label Density
    title Normal Kernel Density Mixture for Duewer Data
    xlimits 95 115
    .
    plot y x

-----NORMAL ORDER STATISTICS MEDIANS (LET)--------------------------
 
NORMAL ORDER STATISTICS MEDIANS

    Enter HELP ORDER STATISTICS MEDIANS.  The order statistics
    medians can be generated for the normal, uniform, half-normal,
    extreme value type I, extreme value type II, and Weibull 
    distributions.
 
-----NORMAL PLOT--------------------------------------
 
NORMAL PLOT
 
Name:
    NORMAL PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a normal plot.
 
Description:
    A normal plot is a normal probability plot, but with the data on
    the horizontal axis and neat probability values on the vertical
    axis.  The plot consists of the following 4 components:

       1) The raw data;
       2) A fitted line to the raw data;
       3) A horizontal 50% line;
       4) A vertical 50% line.

    The characteristics of these components are controlled through the
    LINE and CHARACTER commands.

    If you have groups in the data, you can specify a "highlight" option
    to draw the points in the different groups with different attributes.
    For example, this can be used to draw outliers in a different color.
 
Syntax 1:
    NORMAL PLOT <y>       <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    NORMAL PLOT <y> <tag> <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <tag> is a censoring variable (values equal to 0 are omitted
               from the plot);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 3:
    HIGHLIGHT NORMAL PLOT <y>  <x>     <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <x> is a group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 4:
    HIGHLIGHT NORMAL PLOT <y> <tag> <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <x> is a group-id variable;
          <tag> is a censoring variable (values equal to 0 are omitted
               from the plot);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    NORMAL PLOT Y1
    NORMAL PLOT Y1 CENSOR
    HIGHLIGHT NORMAL PLOT Y1 X
 
Note:
    The following internal parameters are saved after a NORMAL PLOT.
    These parameters can be used like any user created parameter by
    the analyst.

        SIGMA   - the slope of the fitted line
        MU      - the intercept of the fitted line
        SDSIGMA - the standard deviation of SIGMA
        SDETA   - the standard deviation of MU
        BPT1    - the 0.1% point of the best fit distribution
        BPT5    - the 0.5% point of the best fit distribution
        BP1     - the 1% point of the best fit distribution
        BP5     - the 5% point of the best fit distribution
        BP10    - the 10% point of the best fit distribution
        BP20    - the 20% point of the best fit distribution
        BP50    - the 50% point of the best fit distribution
        BP80    - the 80% point of the best fit distribution
        BP90    - the 90% point of the best fit distribution
        BP95    - the 95% point of the best fit distribution
        BP99    - the 99% point of the best fit distribution
        BP995   - the 99.5% point of the best fit distribution
        BP999   - the 99.9% point of the best fit distribution
 
Note:
    Some sources reverse the role of the x and y axes as used by Dataplot.
    You can reverse the axes in Dataplot with the command

        SET NORMAL PLOT AXES REVERSE

    To reset the default, enter

        SET NORMAL PLOT AXES DEFAULT

Default:
    None
 
Synonyms:
    SUBSET is a synonym for HIGHLIGHT
 
Related Commands:
    LINES                   = Sets the type for plot lines.
    NORMAL PROBABILITY PLOT = Generates a normal probability plot.
    HISTOGRAM               = Generates a histogram.
    QUAN-QUAN PLOT          = Generates a quantile-quantile plot
    BOX PLOT                = Generates a box plot
    PLOT                    = Generates a data or function plot.
    MULTIPLOT               = Allows multiple plots per page
 
Applications:
    Exploratory Data Analysis, Distributional Modeling
 
Implementation Date:
    1990/05
    2011/02: Added support for HIGHLIGHT option
    2014/07: Added the SET NORMAL PLOT AXES option
 
Program:
    SKIP 25
    READ ZARR13.DAT Y
    LINE SOLID DASH DOT DOT
    TITLE AUTOMATIC
    NORMAL PLOT Y
 
-----NORMAL PPCC------------------------------------------------
 
NORMAL PPCC
 
Name:
    NORMAL PPCC
 
Type:
    LET Subcommand
 
Purpose:
    Compute the normal probability plot correlation coefficient (also
    called the ppcc) value for a variable.
 
Description:
    The normal ppcc is the correlation coefficient of the straight line
    fitted to a normal probability plot (see the documentation for PPCC
    PLOT for details).
 
Syntax:
    LET <par> = NORMAL PPCC <y>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <par> is the parameter where the normal ppcc value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NORMAL PPCC Y
    LET A = NORMAL PPCC Y SUBSET Y > -3
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STAT PPCC           = Compute the ppcc value for a specified
                          distribution.
    NORMAL PPCC PLOT    = Generates a normal ppcc versus subset plot.
    PPCC PLOT           = Generates a probability plot correlation
                          coefficient plot.
    PROBABILITY PLOT    = Generates a probability plot.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    94/2
 
Program:
    LET Y = CAUCHY RANDOM NUMBERS FOR I = 1 1 100
    LET A = NORMAL PPCC Y
 
-----NORMAL PPCC PLOT------------------------------------------------
 
NORMAL PPCC PLOT
 
Name:
    NORMAL PPCC PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a normal ppcc plot.
 
Description:
    A normal ppcc plot consists of subsample normal probability plot
    correlation coefficient (ppcc) versus subsample index.  The
    subsample normal ppcc is the correlation coefficient of the straight
    line fitted to a normal probability plot (see the documentation for
    PPCC PLOT for details) in the subsample.  The normal ppcc plot is
    used to answer the question--"Does the subsample normality change
    over different subsamples?"  The plot consists of:
       Vertical   axis = subsample normal ppcc;
       Horizontal axis = subsample index.
    The normal ppcc plot yields 2 traces:
       1. a subsample normal ppcc trace; and
       2. a full-sample normal ppcc reference line.
    Like usual, the appearance of these 2 traces is controlled
    by the first 2 settings of the LINES, CHARACTERS, SPIKES,
    BARS, and similar attributes.
 
Syntax:
    NORMAL PPCC PLOT   <y>   <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    NORMAL PPCC PLOT Y X
    NORMAL PPCC PLOT Y X SUBSET X > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    STANDARD DEVIATION PLOT = Generates a stand deviation plot.
    MEAN PLOT               = Generates a mean plot.
    BOX PLOT                = Generates a box plot.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    94/2
 
Program:
    SKIP 50
    SET READ FORMAT 3F4.0,F5.0,F6.0,F3.0,2F9.0
    READ PBF11.DAT YEAR DAY BOT SD F11 FLAG WV CO2
    .
    RETAIN YEAR DAY BOT SD F11 WV CO2 FLAG SUBSET FLAG 0
    LET MONTH=INT(DAY/30.25)+1
    .
    LINE BLANK DASH
    CHARACTER X BLANK
    XLIMITS 0 15
    Y1LABEL NORMAL PPPCC
    X1LABEL GROUP ID
    TITLE AUTOMATIC
    NORMAL PPCC PLOT WV MONTH
 
-----NORMXCDF (LET)--------------------------------
 
NORMXCDF
 
Name:
    NORMXCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the mixture of two normal cumulative distribution
    functions.
 
Description:
    The normal mixture distribution has the following cumulative
    distribution function:

       F(x,u1,sd1,u2,sd2,p)=p*norcdf(u1,sd1) +
                                   (1-pmix)*norcdf(u2,sd2)

    where norcdf(u,s) is a normal probability density function
    with mean u and standard deviation s, pmix is a real number
    between 0 and 1 that defines the mixing proportions, and x
    is a real number.

Syntax:
    LET <y2> = NORMXCDF(<y1>,<u1>,<sd1>,<u2>,<sd2>,<pmix>)
                                  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a number, parameter, or variable;
          <u1> is a number, parameter, or variable;
          <sd1> is a number, parameter, or variable;
          <u2> is a number, parameter, or variable;
          <sd2> is a number, parameter, or variable;
          <pmix> is a number, parameter, or variable in the range
               0 to 1;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed normal mixture cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NORMXCDF(3,0,1,10,20,0.2)
    LET A = NORMXCDF(3,U1,SD1,U2,SD2,P)
    LET Y = NORMXCDF(X,U1,SD1,U2,SD2,P)
 
Note:
    You can generate a probability plot for a normal mixture
    distribution as follows:
   
         LET U1 = <value>
         LET SD1 = <value>
         LET U2 = <value>
         LET SD2 = <value>
         LET P = <value>
         NORMAL MIXTURE PROBABILITY PLOT Y
   
    You can generate random numbers from a normal mixture
    distribution as follows:
   
         LET U1 = <value>
         LET SD1 = <value>
         LET U2 = <value>
         LET SD2 = <value>
         LET P = <value>
         LET Y = NORMAL MIXTURE RANDOM NUMBERS FOR I = 1 1 1000

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NORMXPDF = Compute the normal mixture probability density
               function.
    NORMXPPF = Compute the normal mixture percent point function.
    NORCDF   = Compute the normal cumulative distribution function.
    NORPDF   = Compute the normal probability density function.
    NORPPF   = Compute the normal percent point function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", Johnson, Kotz,
    and Balakrishnan, John Wiley and Sons, 1994.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1998/5
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    LET U1 = 0
    LET SD1 = 1
    LET U2 = 5
    LET SD2 = 3
    TITLE P = 0.2
    PLOT NORMXCDF(X,U1,SD1,U2,SD2,0.2) FOR X = -5 0.1 15
    TITLE P = 0.4
    PLOT NORMXCDF(X,U1,SD1,U2,SD2,0.4) FOR X = -5 0.1 15
    TITLE P = 0.6
    PLOT NORMXCDF(X,U1,SD1,U2,SD2,0.6) FOR X = -5 0.1 15
    TITLE P = 0.8
    PLOT NORMXCDF(X,U1,SD1,U2,SD2,0.8) FOR X = -5 0.1 15
    END OF MULTIPLOT
 
-----NORMXPDF (LET)--------------------------------
 
NORMXPDF
 
Name:
    NORMXPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the mixture of two normal probability density functions.
 
Description:
    The normal mixture distribution has the following probability
    density function:

       f(x,u1,sd1,u2,sd2,pmix)=pmix*norpdf(u1,sd1) +
                                   (1-pmix)*norpdf(u2,sd2)

    where norpdf(u,s) is a normal probability density function
    with mean u and standard deviation s, pmix is a real number
    between 0 and 1 that defines the mixing proportions, and x
    is a real number.

Syntax:
    LET <y2> = NORMXPDF(<y1>,<u1>,<sd1>,<u2>,<sd2>,<pmix>)
                                  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a number, parameter, or variable;
          <u1> is a number, parameter, or variable;
          <sd1> is a number, parameter, or variable;
          <u2> is a number, parameter, or variable;
          <sd2> is a number, parameter, or variable;
          <pmix> is a number, parameter, or variable in the range
               0 to 1;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed normal mixture pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NORMXPDF(3,0,1,10,20,0.2)
    LET A = NORMXPDF(3,U1,SD1,U2,SD2,P)
    LET Y = NORMXPDF(X,U1,SD1,U2,SD2,P)
 
Note:
    You can generate a probability plot for a normal mixture
    distribution as follows:
   
         LET U1 = <value>
         LET SD1 = <value>
         LET U2 = <value>
         LET SD2 = <value>
         LET P = <value>
         NORMAL MIXTURE PROBABILITY PLOT Y
   
    You can generate random numbers from a normal mixture
    distribution as follows:
   
         LET U1 = <value>
         LET SD1 = <value>
         LET U2 = <value>
         LET SD2 = <value>
         LET P = <value>
         LET Y = NORMAL MIXTURE RANDOM NUMBERS FOR I = 1 1 1000

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NORMXCDF = Compute the normal mixture cumulative distribution
               function.
    NORMXPPF = Compute the normal mixture percent point function.
    NORCDF   = Compute the normal cumulative distribution function.
    NORPDF   = Compute the normal probability density function.
    NORPPF   = Compute the normal percent point function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", Johnson, Kotz,
    and Balakrishnan, John Wiley and Sons, 1994.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1998/5
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    LET U1 = 0
    LET SD1 = 1
    LET U2 = 5
    LET SD2 = 3
    TITLE P = 0.2
    PLOT NORMXPDF(X,U1,SD1,U2,SD2,0.2) FOR X = -5 0.1 15
    TITLE P = 0.4
    PLOT NORMXPDF(X,U1,SD1,U2,SD2,0.4) FOR X = -5 0.1 15
    TITLE P = 0.6
    PLOT NORMXPDF(X,U1,SD1,U2,SD2,0.6) FOR X = -5 0.1 15
    TITLE P = 0.8
    PLOT NORMXPDF(X,U1,SD1,U2,SD2,0.8) FOR X = -5 0.1 15
    END OF MULTIPLOT
 
-----NORMXPPF (LET)--------------------------------
 
NORMXPPF
 
Name:
    NORMXPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the percent point function of a mixture of two normal
    distributions.
 
Description:
    The normal mixture distribution has the following cumulative
    distribution function:

       F(x,u1,sd1,u2,sd2,p)=p*norcdf(u1,sd1) +
                                   (1-pmix)*norcdf(u2,sd2)

    where norcdf(u,s) is a normal probability density function
    with mean u and standard deviation s, pmix is a real number
    between 0 and 1 that defines the mixing proportions, and x
    is a real number.

    The percent point function is the inverse of the cumulative
    distribution function.  That is, given a probability value, it
    returns the corresponding x value.  The percent point function
    for the mixture of two normal distributions is computed
    numerically.

Syntax:
    LET <y2> = NORMXPPF(<p>,<u1>,<sd1>,<u2>,<sd2>,<pmix>)
                                  <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, parameter, or variable containing
              probability values between 0 and 1;
          <u1> is a number, parameter, or variable;
          <sd1> is a number, parameter, or variable;
          <u2> is a number, parameter, or variable;
          <sd2> is a number, parameter, or variable;
          <pmix> is a number, parameter, or variable in the range
               0 to 1;
          <y2> is a variable or a parameter (depending on what <p> is)
               where the computed normal mixture ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NORMXPPF(0.95,0,1,10,20,0.2)
    LET A = NORMXPPF(0.90,U1,SD1,U2,SD2,P)
    LET Y = NORMXPPF(P,U1,SD1,U2,SD2,PMIX)
 
Note:
    You can generate a probability plot for a normal mixture
    distribution as follows:
   
         LET U1 = <value>
         LET SD1 = <value>
         LET U2 = <value>
         LET SD2 = <value>
         LET P = <value>
         NORMAL MIXTURE PROBABILITY PLOT Y
   
    You can generate random numbers from a normal mixture
    distribution as follows:
   
         LET U1 = <value>
         LET SD1 = <value>
         LET U2 = <value>
         LET SD2 = <value>
         LET P = <value>
         LET Y = NORMAL MIXTURE RANDOM NUMBERS FOR I = 1 1 1000

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NORMXPDF = Compute the normal mixture probability density
               function.
    NORMXCDF = Compute the normal mixture cumulative distribution
               function.
    NORCDF   = Compute the normal cumulative distribution function.
    NORPDF   = Compute the normal probability density function.
    NORPPF   = Compute the normal percent point function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", Johnson, Kotz,
    and Balakrishnan, John Wiley and Sons, 1994.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1998/5
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    YLIMITS -5 15
    XLIMITS 0 1
    MAJOR XTIC MARK NUMBER 6
    MINOR XTIC MARK NUMBER 1
    LET U1 = 0
    LET SD1 = 1
    LET U2 = 5
    LET SD2 = 3
    TITLE P = 0.2
    PLOT NORMXPPF(P,U1,SD1,U2,SD2,0.2) FOR P = 0.01 0.01 0.99
    TITLE P = 0.4
    PLOT NORMXPPF(P,U1,SD1,U2,SD2,0.4) FOR P = 0.01 0.01 0.99
    TITLE P = 0.6
    PLOT NORMXPPF(P,U1,SD1,U2,SD2,0.6) FOR P = 0.01 0.01 0.99
    TITLE P = 0.8
    PLOT NORMXPPF(P,U1,SD1,U2,SD2,0.8) FOR P = 0.01 0.01 0.99
    END OF MULTIPLOT
 
-----NORPDF (LET)--------------------------------
 
NORPDF
 
Name:
    NORPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard normal (i.e, mean=0, sd=1) probability density
    function.
 
Description:
    The normal distribution has the following probability density
    function:
       f(x)=(1/sqrt(2*PI))*e**-(1/2)*x**2
    The NORPDF function evaluates this function for a given x value.
 
    The input value can be any real number.
 
Syntax:
    LET <y2> = NORPDF(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed normal pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NORPDF(3)
    LET A = NORPDF(A1)
    LET X2 = NORPDF(X1)
 
Note:
    The pdf values for non-standard normal distributions can be
    computed by standardizing the input value.  For example, suppose
    Y contains a set of data and you want the pdf value corresponding
    to Y = 8:
        LET M = MEAN Y
        LET SD = STANDARD DEVIATION Y
        LET PT = 8
        LET NEWPT = (PT - M)/SD
        LET PDFPT = NORPDF(NEWPT)
        PRINT "PDF VALUE FOR ^PT = ^PDFPT"
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHSCDF = Compute the chi-square cumulative distribution function.
    CHSPDF = Compute the chi-square probability density function.
    CHSPPF = Compute the chi-square percent point function.
    FCDF   = Compute the F cumulative distribution function.
    FPDF   = Compute the F probability density function.
    FPPF   = Compute the F percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPPF = Compute the normal percent point function.
    TCDF   = Compute the T cumulative distribution function.
    TPDF   = Compute the T probability density function.
    TPPF   = Compute the T percent point function.
    WEICDF = Compute the Weibull cumulative distribution function.
    WEIPDF = Compute the Weibull probability density function.
    WEIPPF = Compute the Weibull percent point function.
 
Reference:
    "Continuous Univariate Distributions", Johnson and Kotz, 1970.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    Pre-1987
 
Program:
    YLIMITS 0 0.4
    MAJOR YTIC NUMBER 5
    MINOR YTIC NUMBER 1
    YTIC DECIMAL 1
    XLIMITS -3 3
    XTIC OFFSET 0.6 0.6
    PLOT NORPDF(X) FOR X = -3.5 0.01 3.5
 
-----NORPPCV (LET)--------------------------------
 
NORPPCCV
 
Name:
    NORPPCV (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the critical value for the normal probability plot correlation
    coefficient (PPCC).

Description:
    The PPCC value is a measure of distributional goodness of fit based on

       1. The linearity of the probability plot is a good measure of
          goodness of fit for a distribution.

       2. The correlation coefficient of the points on the probability
          plot is a good measure of the linearity of the probability plot.
 
    For a normal distribution, critical values for this statistic have
    been determined by simulation.  The original tables were computed by
    Filliben and more extensive versions of the tables were computed by
    Devaney.

    The current tables are available for N = 3 to 1,000 and for
    significance levels of 0.01 or 0.05 (the PPCC provides a lower tailed
    test).  Significance levels of 0.99 and 0.95 are interpreted as 0.01
    and 0.05, respectively.

    PPCC values of less than the critical value reject the hypothesis of a
    normal distribution.

Syntax:
    LET <y> = NORPPCV(<n>,<alpha>)
    where <n> is a variable, parameter or number indicating the sample size;
    and   <k> is a variable, parameter or number indicating the significance
              level;
          <y> is a variable or a parameter (depending on what <n> and <k>
              are) where the computed critical value is stored.
 
Examples:
    LET A = NORPPCV(N,ALPHA)
    LET A = NORPPCV(N,0.01)
    LET A = NORPPCV(N,0.05)
    LET A = NORPPCV(105,0.05)
 
Note:
    Significance levels other than 0.01, 0.05, 0.95, and 0.99 will use
    0.05.  Values for the sample size outside the range 3 to 1,000 will
    return an error message.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NORMAL PROBABILITY PLOT  = Generate a normal probability plot.
    NORMAL PPCC              = Compute the PPCC statistic for a normal
                               distribution.
 
References:
    James J. Filliben (1975), "The Probability Plot Correlation Coefficient
    Test for Normality", Technometrics, Vol. 17, No. 1.

    Judy Devaney, Phd Thesis, George Mason University.

Applications:
    Distributional Goodness of Fit
 
Implementation Date:
    2014/07
 
Program:
    . Step 1:   Read the data
    .
    skip 25
    read zarr13.dat y
    .
    . Step 2:   Generate normal probability plot with PPCC
    .           value and associated critical values
    .
    let n = size y
    let alpha = 0.01
    let cv1 = norppcv(n,alpha)
    let cv1 = round(cv1,3)
    let alpha = 0.05
    let cv2 = norppcv(n,alpha)
    let cv2 = round(cv2,3)
    .
    char circle
    char fill on
    char hw 0.5 0.375
    line blank
    y1label Sorted Data
    x1label Percentiles of Normal Distribution
    title Normal Probability Plot for ZARR13.DAT
    title case asis
    title offset 2
    label case asis
    ylimits 9.1  9.4
    major y1tic mark number 4
    .
    normal probability plot y
    .
    let ppcc = round(ppcc,3)
    let ppa0 = round(ppa0,3)
    let ppa1 = round(ppa1,3)
    case asis
    justification left
    move 16 88
    text Location: ^ppa0
    move 16 85
    text Scale: ^ppa1
    move 16 82
    text PPCC: ^ppcc
    move 16 79
    text 0.01 CV: ^cv1
    move 16 76
    text 0.05 CV: ^cv2
 
-----NORPPF (LET)--------------------------------
 
NORPPF
 
Name:
    NORPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard normal (i.e, mean=0, sd=1) percent point
    function.
 
Description:
    The normal distribution has the following probability density
    function:
       f(x)=(1/sqrt(2*PI))*e**-(1/2)*x**2
    The percent point function is the inverse of the cumulative
    distribution function.  The cumulative distribution sums the
    probability from 0 to the given x value (i.e., the integral of the
    above function).  The percent point function takes a cumulative
    probability value and computes the corresponding x value.
 
    The input value is a real number between 0 and 1 (since it
    corresponds to a probability).  The output value can be any real
    number.
 
Syntax:
    LET <y2> = NORPPF(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter in the range 0 to 1;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed normal ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NORPPF(0.9)
    LET A = NORPPF(A1)
    LET X2 = NORPPF(X1)
 
Note:
    The ppf values for non-standard normal distributions can be
    computed from the mean and standard deviation.  For example,
    suppose Y contains a set of data and you want the 0.95% ppf value:
        LET M = MEAN Y
        LET SD = STANDARD DEVIATION Y
        LET ALPHA = 0.95
        LET PPF = NORCDF(ALPHA)
        LET NEWPPF = (PPF + M)*SD
        PRINT "THE 0.95 PPF VALUE = ^NEWPPF"
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHSCDF = Compute the chi-square cumulative distribution function.
    CHSPDF = Compute the chi-square probability density function.
    CHSPPF = Compute the chi-square percent point function.
    FCDF   = Compute the F cumulative distribution function.
    FPDF   = Compute the F probability density function.
    FPPF   = Compute the F percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    TCDF   = Compute the T cumulative distribution function.
    TPDF   = Compute the T probability density function.
    TPPF   = Compute the T percent point function.
    WEICDF = Compute the Weibull cumulative distribution function.
    WEIPDF = Compute the Weibull probability density function.
    WEIPPF = Compute the Weibull percent point function.
 
Reference:
    "Continuous Univariate Distributions", Johnson and Kotz, 1970.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XLIMITS 0 1
    MAJOR XTIC NUMBER 6
    MINOR XTIC NUMBER 1
    XTIC DECIMAL 1
    PLOT NORPPF(X) FOR X = 0.01 .01 0.99
 
-----NORSF (LET)--------------------------------
 
NORSF
 
Name:
    NORSF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard form of the normal sparsity function.
 
Description:
    The standard normal distribution has the following probability
    density function:
       f(x)=(1/sqrt(2*PI))*exp(-(1/2)*x**2)
    The sparsity function function is the derivative of the percent
    point function, which is the inverse of the cumulative distribution
    function.  The cumulative distribution sums the probability from 0
    to the given x value (i.e., the integral of the above function).
    The percent point function takes a cumulative probability value and
    computes the corresponding x value.
 
    The input value is a real number between 0 and 1 (since it
    corresponds to a probability).
 
Syntax:
    LET <y2> = NORSF(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable, a number, or a parameter in the range 0
               to 1;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed normal sf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = NORSF(0.9)
    LET X2 = NORSF(X1)
 
Note:
    The general form of the normal distribution is:
       f(x)=(1/(sqrt(2*PI)*sigma)*exp(-(1/2)*(x-u)/sigma)**2)
    where u is a location parameter and sigma is a scale parameter.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
    HFNCDF = Compute the half-normal cumulative distribution function.
    HFNPDF = Compute the half-normal probability density function.
    HFNPPF = Compute the half-normal percent point function.
    LGNCDF = Compute the lognormal cumulative distribution function.
    LGNPDF = Compute the lognormal probability density function.
    LGNPPF = Compute the lognormal percent point function.
    CHSCDF = Compute the chi-square cumulative distribution function.
    CHSPDF = Compute the chi-square probability density function.
    CHSPPF = Compute the chi-square percent point function.
    FCDF   = Compute the F cumulative distribution function.
    FPDF   = Compute the F probability density function.
    FPPF   = Compute the F percent point function.
    TCDF   = Compute the T cumulative distribution function.
    TPDF   = Compute the T probability density function.
    TPPF   = Compute the T percent point function.
    WEICDF = Compute the Weibull cumulative distribution function.
    WEIPDF = Compute the Weibull probability density function.
    WEIPPF = Compute the Weibull percent point function.
 
Reference:
    "Continuous Univariate Distributions", Johnson and Kotz, Houghton
    Mifflin, 1970 (chapter 13).
 
Applications:
    XX
 
Implementation Date:
    94/4
 
Program:
    XLIMITS 0 1
    MAJOR XTIC NUMBER 6
    MINOR XTIC NUMBER 1
    XTIC DECIMAL 1
    TITLE AUTOMATIC
    PLOT NORSF(X) FOR X = 0.01 .01 0.99
 
-----NOT EXIST------------------------------------------------
 
NOT EXIST
 
Name:
    NOT EXIST
 
Type:
    Keyword
 
Purpose:
    Check whether or not a parameter or variable in an IF clause has
    been previously defined.
 
Syntax:
    IF <param> NOT EXIST
    where <param> is a parameter or variable name.
 
Examples:
    IF A NOT EXIST
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    IF      = Conditionally execute commands.
 
Applications:
    XX
 
Implementation Date:
    92/8
 
Program:
    IF A NOT EXIST
      A = 3.0
    END OF IF
 
-----NP CHART----------------------------------------------------
 
NP CHART
 
Name:
    NP CHART
 
Type:
    Graphics Command
 
Purpose:
    Generates a (binomial) counts control chart.
 
Description:
    The NP chart is a data analysis technique for determining if a
    measurement process has gone out of statistical control.  It is
    sensitive to changes in the number of defective items in the
    measurement process.  The "NP" in NP charts stands for the np (the
    number of successes) of a binomial distribution.  The NP control
    chart consists of:
        Vertical   axis = the proportion of defectives (number of
                          defectives in sub-group/size of sub-group)
                          for each sub-group;
        Horizontal axis = the sub-group designation.
    A sub-group is typically a time sequence (e.g., the number of
    defectives in a daily production run where each day is considered a
    sub-group).  If the times are equally spaced, the horizontal axis
    variable can be generated as a sequence (e.g.,
    LET X = SEQUENCE 1 1 N where N is the number of sub-groups).
 
    In addition, horizontal lines are drawn at the mean number of
    defectives and at the upper and lower control limits.  The control
    limits are calculated as:
         UCL = pbar + 3*sqrt(pbar(1-pbar)/N)
         LCL = pbar - 3*sqrt(pbar(1-pbar)/N)
    where pbar is the total number of defectives divided by the total
    number of items and N is the number of items in a given sub-group.
    Also, zero serves as a lower bound on the LCL value.
 
Syntax:
    NP CHART   <y1>   <size>   <x>  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable containing the number of defective items
               in each sub-group;
          <size> is a variable containing the sample size for each
               sub-group;
          <x>  is a variable containing the sub-group identifier
               (usually 1, 2, 3, ...);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    NP CHART Y SIZE X
    NP CHART NUMDEF NUMTOT X
 
Note:
    The distribution of defective items is assumed to be Binomial.
    This assumption is the basis for calculating the upper and lower
    control limits.
 
Note:
    The P chart and NP chart are related to one another. The
    distinction is that the P chart is used when sub-groups have equal
    size (so the number of defectives is plotted) while the NP chart is
    used when the sub-groups have unequal sample sizes (so the
    percentage of defectives is plotted).
 
Note:
    The attributes of the 4 traces that make up the NP control chart
    are controlled by the standard LINES, CHARACTERS, SPIKES, and BAR
    commands.  Trace 1 is the response variable, trace 2 is the mean
    line, and traces 3 and 4 are the upper and lower control limits.
    Some analysts prefer to draw the response variable as a character
    or spike rather than a connected line.
 
Default:
    None
 
Synonyms:
    NP CHART for NP CONTROL CHART
 
Reference:
    "Guide to Quality Control", Karou Ishikawa, Asian Productivity
    Organization, 1982 (Chapter 8).
 
Related Commands:
    U CHART             = Generates a U control chart.
    P CHART             = Generates a P control chart.
    C CHART             = Generates an C control chart.
    XBAR CHART          = Generates an xbar control chart.
    R CHART             = Generates a range control chart.
    S CHART             = Generates a stanard deviation control chart.
 
    CHARACTERS          = Sets the types for plot characters.
    LINES               = Sets the types for plot lines.
    SPIKES              = Sets the on/off switches for plot spikes.
    BARS                = Sets the on/off switches for plot bars.
    PLOT                = Generates a data or function plot.
    LAG PLOT            = Generates a lag plot.
    4-PLOT              = Generates a 4-plot for univariate analysis.
    ANOP PLOT           = Generates an ANOP plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    . DEFECTIVE MIRRORS (CCPN.DAT IN DATAPLOT REFERENCE DIRECTORY)
    .  1. X = SUBGROUP ID (1 TO 25)
    .  2. NUMDEF = NUMBER OF DEFECTIVE ITEMS IN SUB-GROUP
    .  3. SIZE = TOTAL NUMBER OF ITEMS IN SUB-GROUP
    .
    SERIAL READ NUMDEF
    6 5 5 5 6 4 3 3 6 5 3 2 5 4 4 6 5 4 6 5 6 4 9 12 14
    END OF DATA
    LET SIZE = 150 FOR I = 1 1 25
    LET X = SEQUENCE 1 1 25
    .
    LINES SOLID SOLID DOT DOT
    XLIMITS 0 25
    XTIC OFFSET 0 1
    YLIMITS 0 15
    YTIC OFFSET 2 0
    .
    NP CONTROL CHART NUMDEF  SIZE X

-----NUMBER OF WORDS-------------------------------------------------

NUMBER OF WORDS

Name:
    NUMBER OF WORDS
 
Type:
    Let Subcommand
 
Purpose:
    Return the number of words in a string.
 
Description:
    There may be times when it is useful to extract the individual
    words in a string.  In order to automate this task, it is helpful
    to know the number of words in the string.

    Dataplot delineates words in a string by spaces.  It will treat
    non-printing characters in the string as spaces.  That is,
    any character in the string with an ASCII collating index less
    than or equal to 32 or greater than 127 will be treated as a space.
    In particular, tabs will be treated as spaces.  However, hyphens
    and other special characters such as "&" will not be treated as
    word boundaries.

Syntax:
    LET <nword> = NUMBER OF WORDS  <sorg>
    where <nword> is a parameter containing the returned number
                  of words in the string;
    and   <sorg> is the name of the string.
 
Examples:
    LET NWORD = NUMBER OF WORDS S1
 
Note:
    The string on the right hand side of the equal sign must be a
    previously existing string.  That is, expressions are not allowed.
    For example, instead of

        LET NWORD = NUMBER OF WORDS "a b c d"

    you need to do

        LET STRING SORG = a b c d
        LET NWORD = NUMBER OF WORDS SORG

    The name on the left hand side of the equal sign may be a
    previously existing parameter.  However, if it is a previously
    existing string/function, variable, or matrix name, an error will
    be reported and the requested parameter will not be created.

Note:
    The 2020/08 version of Dataplot added support for the

         SET WORD DELIMITER <char>

    command.  Previously, only the space character (non-printing
    characters are interpreted as spaces) was recognized.  With
    this command, you can specify a specific character as a delimiter.
    If a non-space character is specified, spaces and non-printing
    characters will be treated as part of the word and not as
    delimiters.

    The most common use for this is in parsing comma delimited files.
Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to the
    combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STRING WORD               = Extract a specified word from a string.
    UPPER CASE                = Convert a string to upper case.
    LOWER CASE                = Convert a string to lower case.
    LET FUNCTION              = Defines a function.
    LET STRING                = Defines a string.
    READ STRING               = Reads a string from a file.
    SUBSTITUTE CHARACTER (^)  = Substitute the value of a string or
                                parameter.
    CONCATENATE CHARACTER (&) = Concatenate two strings.
    SUBTRING                  = Extract a substring from an existing
                                string.
    STRING INDEX              = Extract the start/stop positions of a
                                substring within a string.
    STRING CONCATENATE        = Concatenate one or more previously defined
                                strings.
    STRING EDIT               = Edit a string.
    STRING MERGE              = Insert a string into another string without
                                overwrite.
    STRING LENGTH             = Return the length of a string.
    CHARACTER                 = Convert numeric values to strings based on
                                the ASCII collating sequence.
    ICHAR                     = Convert a string to numeric values based on
                                the ASCII collating sequence.
    GROUP LABEL               = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2010/10
    2020/08: Support for SET WORD DELIMITER
 
Program:
    let string s = funnel ramp cone square
    .
    feedback off
    print "String s = ^s"
    let nword = number of words s
    loop for k = 1 1 nword
        let s^k = string word s k
        print "String ^k = ^s^k"
    end of loop
    feedback on

-----NUMBER TO STRING-----------------------------------------
 
NUMBER TO STRING
 
Name:
    NUMBER TO STRING (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Convert a parameter to a string where the number of digits will
    be controlled by the SET WRITE DECIMALS command.
 
Description:
    In some cases, it is desired to insert a number into a string or
    TEXT command with a specified number of digits.  Typically, when
    the "^" operator is used to substitute the value of a parameter,
    trailing zeros will be truncated.  This command allows you to
    copy the parameter to a string with more control over how the
    number is printed.

    Specifically, given the number 23.84 and the command

       SET WRITE DECIMALS  <numdig>

    the parameter will be written in the following format to the string:

       <numdig> > 0           => Fy.x format (e.g., 23.840)
       <numdig> = 0           => Ix   format (e.g., 23)
       <numdig> = -1          => blank string
       <numdig> = -3 to -20   => Ey.x format (e.g., 0.23840E+02)
       <numdig> = -99         => **

Syntax:
    LET <sout> = NUMBER TO STRING  <a>
    where <a> is a parameter or number;
    and   <sout> is a string.
 
    Although you can enter an explicit number with this command, it
    is usually a parameter that is entered.

Examples:
    SET WRITE DECIMALS 2
    LET AVAL = 32.1
    LET SOUT = NUMBER TO STRING AVAL
 
Note:
    The SET PARAMETER EXPAND DIGITS command is an alternative method.
    This command controls how many digits are used for the
    substitution character ("^").

    Note that the SET PARAMETER EXPAND DIGITS command applies to
    all parameter substitions encountered.  If this value is set
    to 0 or a positive integer, it will act similar to the
    NUMBER TO STRING command (i.e., F or I formats).  However, it
    does not support exponential format.

    The SET PARAMETER EXPANSION command can be used to specify that
    parameter substitutions will be converted to exponential format.
    However, this is intended for the case when the parameters are
    being used in numerical computations.  It does not generate the
    numbers in a format that is attractive for printing.

    In general, the SET PARAMETER EXPAND DIGITS and SET PARAMETER
    EXPANSION were developed in the context of using parameter
    substitution in numerical computations while the NUMBER TO
    STRING is intended for printing or display on plots.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    ^                   = Substitute the value of a parameter or a string.
    &                   = Concatenate two strings.
    CHAR                = Convert a parameter or a variable to a string
                          based on the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    LET STRING          = Defines a string.
    SUBTRING            = Extract a substring from an existing string.
    STRING LENGTH       = Return the length of a string.
    STRING INDEX        = Return the start and stop positions of a 
                          substring within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING EDIT         = Edit a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2015/06
 
Program:
    let a = 32.1
    let b = 0.2345/10**8
    set write decimal 2
    let sout1 = number to string a
    set write decimal -7
    let sout2 = number to string a
    let sout4 = number to string b
    set write decimal 0
    let sout3 = number to string a
    .
    margin 40
    crlf on
    move 40 80
    text A = ^sout1
    text A = ^sout2
    text A = ^sout3
    text B = ^sout4
    .
    move 40 30
    text A = ^a (default)
    set parameter expand digits 2
    text A = ^a (digits = 2)
    set parameter expand digits 0
    text A = ^a (digits = 0)
    set parameter expansion exponential
    text A = ^a (digits = exponential)
    text B = ^b (digits = exponential)

-----NUMERICAL DERIVATIVE (LET)-------------------------------------
 
NUMERICAL DERIVATIVE
 
Name:
    NUMERICAL DERIVATIVE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the derivative for a univariate function numerically.
 
Description:
    The DERIVATIVE LET subcommand computes a derivative by first
    determining the analytic derivative function and then evaluating
    that function at the requested point (or points).  However, Dataplot
    only computes the analytic derivative for a limited number of basic
    functions (including combinations of these functions).

    If Dataplot cannot compute the analytic derivative of a function,
    you can use the NUMERICAL DERIVATIVE instead.

    This command is limited to univariate functions (i.e., it does
    not compute partial derivatives).
 
Syntax 1:
    LET <resp> = NUMERICAL DERIVATIVE <function> WRT <var>
                                        
    where <function> is the name of a previously defined function;
          <var> is the name of the variable with respect to which the
                derivative is taken;
    and   <resp> is a variable of the same length as <var> where the
                evaluated derivatives are stored.
 
    With this syntax, the derivative variable (<var>) must be defined
    for one or more points.  The derivative is calculated at each of
    these points and the resulting value is put in the corresponding
    element of <resp>.
 
Syntax 2:
    LET <resp> = NUMERICAL DERIVATIVE <function>
                 WRT <var>  FOR <var> = <value>
    where <function> is the name of a previously defined function;
          <var> is the name of the variable with respect to which the
                derivative is taken;
          <value> is a number or parameter at which the derivative is
                to be evaluated;
    and   <resp> is a parameter of length 1 where the evaluated
                derivative is stored.
 
    This syntax is similar to Syntax 1.  However, the FOR clause
    identifies a single point at which the derivative is to be
    evaluated and <var> does not need to be pre-specified.
 
Examples:
    LET X = SEQUENCE -5 0.1 5
    LET Y = NUMERICAL DERIVATIVE 3*X**2 -8*X + 4 WRT X

    LET X = SEQUENCE -5 0.1 5
    LET FUNCTION F = 3*X**2 -8*X + 4
    LET Y = DERIVATIVE F WRT X
    LET Y = DERIVATIVE F WRT X FOR X = 2.3
 
Note:
    DATAPLOT uses the DIFF routine of David Kahaner (formerly of
    NIST) to compute the numeric derivative.  This routine uses
    Neville's process to extrapolate from a sequence of simple
    polynomial approximations based on interpolating points
    distributed symmetrically about the point at which the derivative
    is to be computed.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    DERIVATIVE     = Compute the analytic derivative of a function.
    INTEGRAL       = Compute the integral of a function.
    ROOTS          = Compute the roots of a function.
    RUNGE KUTTA    = Runge Kutta differential equation solver.
    INTERPOLATE    = Interpolate a function.
 
Reference:
    Consult any standard Calculus textbook.
 
Applications:
    Mathematics
 
Implementation Date:
    2004/1
 
Program:
    .
    .  Compute the PDF of a G-and-H distribution by computing the
    .  derivative of the G-and-H CDF function.
    .
    LET G = 1.5
    LET H = 0.3
    LET FUNCTION F = GHCDF(X,G,H)
    LET X = SEQUENCE -5 0.1 5
    LET Y = NUMERICAL DERIVATIVE F WRT X
    Y1LABEL PROBABILITY
    X1LABEL X
    TITLE PLOT OF G-AND-H PDF (BASED ON DERIVATIVE OF CDF)
    PLOT Y VS X

---------------------------------------------------------













































































-------------------------  *O*  ZZZZZ--------------------
 
-----OCTDEC----------------------------------------------------

OCTDEC
 
Name:
    OCTDEC (LET)
 
Type:
    Library Function
 
Purpose:
    Perform an octal to decimal conversion of a number.
 
Syntax:
    LET <y2> = OCTDEC(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter containing octal number(s);
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed decimal values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = OCTDEC(14)
    LET A = OCTDEC(A1)
    LET X2 = OCTDEC(X1)
    LET X2 = OCTDEC(X1-4)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    DECOCT = Perform decimal to octal conversion.
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
 
Program:
    LET Y1 = SEQUENCE 0 1 100
    LET Y2 = OCTDEC(Y1)
    PRINT Y1 Y2
 
-----ODDS RATIO (LET)--------------------------------
 
ODDS RATIO
 
Name:
    ODDS RATIO (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the bias corrected odds ratio between two
    binary variables.
 
Description:
    Given two variables where each variable has exactly two
    possible outcomes (typically defined as success and failure),
    we define the odds ratio as:

        o = (N11/N12)/(N21/N22)
          = (N11*N22)/(N12*N21)

    where

        N11 = number of successes in sample 1 
        N21 = number of failures in sample 1 
        N12 = number of successes in sample 2 
        N22 = number of failures in sample 2

    The first definition shows the meaning of the odds ratio
    clearly, although it is more commonly given in the literature
    with the second definition.

    Alternatively, the odds ratio can be given in terms of
    the proportions

      o = (p11/p12)/(p21/p22)
        = (p11*p22)/(p12*p21)

    where

        p11 = N11/(N11 + N21) = proportion of successes in sample 1
        p21 = N21/(N11 + N21) = proportion of failures in sample 1
        p12 = N12/(N12 + N22) = proportion of successes in sample 2
        p22 = N22/(N12 + N22) = proportion of failures in sample 2

    Success and failure can denote any binary response.
    Dataplot expects "success" to be coded as "1" and "failure"
    to be coded as "0".

    Dataplot actually returns the bias corrected version of the
    statistic:

       o'  = {(N11+0.5)*(N22+0.5)}/{(N12+0.5)*(N21+0.5)}

    In addition to reducing bias, this statistic also has the
    advantage that the odds ratio is still defined even when
    N12 or N21 is zero (the uncorrected statistic will be
    undefined for these cases).

Syntax:
    LET <par> = ODDS RATIO <y1> <y2>
                              <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed odds ratio is
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = ODDS RATIO Y1 Y2
    LET A = ODDS RATIO Y1 Y2 SUBSET TAG > 2
 
Note:
    The two variables need not have the same number of elements.
 
Note:
    There are two ways you can define the response variables:

       1) Raw data - in this case, the variables contain
          0's and 1's.

          If the data is not coded as 0's and 1's, Dataplot
          will check for the number of distinct values.  If
          there are two distinct values, the minimum value
          is converted to 0's and the maximum value is
          converted to 1's.  If there is a single distinct
          value, it is converted to 0's if it is less than
          0.5 and to 1's if it is greater than or equal to
          0.5.  If there are more than two distinct values,
          an error is returned.

       2) Summary data - if there are two observations, the
          data is assummed to be the 2x2 summary table.
          That is,

              Y1(1) = N11
              Y1(2) = N21
              Y2(1) = N12
              Y2(2) = N22
 
Note:
    The following additional commands are supported

        TABULATE ODDS RATIO  Y1 Y2 X
        CROSS TABULATE ODDS RATIO Y1 Y2 X1 X2

        ODDS RATIO PLOT Y1 Y2 X
        CROSS TABULATE ODDS RATIO PLOT Y1 Y2 X1 X2

        BOOTSTRAP ODDS RATIO PLOT Y1 Y2
        JACKNIFE  ODDS RATIO PLOT Y1 Y2

    Note that the above commands expect the variables to have
    the same number of observations.  If the two samples are
    in fact of different sizes, there are two ways to address
    the issue:

       1) Y1 and Y2 can contain the summary data.  That is,

            Y1(1) = N11
            Y1(2) = N21
            Y2(1) = N12
            Y2(2) = N22

          This is a useful option in that the data is sometimes
          only available in summary form.  Note that this will
          not work for the BOOTSTRAP PLOT and JACKNIFE PLOT
          commands (these require raw data).

       2) You can specify a missing value for the smaller
          sample.  For example, if Y1 has 100 observations and
          Y2 has 200 observations, you can do something like

              SET STATISTIC MISSING VALUE -99
              LET Y1 = -99 FOR I = 101  1  200

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    ODDS RATIO STANDARD ERROR  = Compute the standard error of the
                                 bias corrected odds ratio.
    LOG ODDS RATIO             = Compute the bias corrected
                                 log(odds ratio).
    FALSE POSITIVES            = Compute the proportion of
                                 false positives.
    FALSE NEGATIVES            = Compute the proportion of
                                 false negatives.
    TRUE NEGATIVES             = Compute the proportion of
                                 true negatives.
    TRUE POSITIVES             = Compute the proportion of
                                 true positives.
    TEST SENSITIVITY           = Compute the test sensitivity.
    TEST SPECIFICITY           = Compute the test specificity.
    TABULATE                   = Compute a statistic for data with
                                 a single grouping variable.
    CROSS TABULATE             = Compute a statistic for data with
                                 two grouping variables.
    STATISTIC PLOT             = Generate a plot of a statistic for
                                 data with a single grouping
                                 variable.
    CROSS TABULATE PLOT        = Generate a plot of a statistic for
                                 data with two grouping variables.
    BOOTSTRAP PLOT             = Generate a bootstrap plot for a
                                 given statistic.
    STATISTIC MISSING VALUE    = Define a missing value for several
                                 plots and commands for unpaired
                                 samples that may be of different
                                 sizes.
 
Reference:
    Fleiss, Levin, and Paik (2003), "Statistical Methods for
    Rates and Proportions", Third Edition, Wiley, chapter 1.
 
Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/5
 
Program:
    let n = 1
    .
    let p = 0.2
    let y1 = binomial rand numb for i = 1 1 100
    let p = 0.1
    let y2 = binomial rand numb for i = 1 1 100
    .
    let p = 0.4
    let y1 = binomial rand numb for i = 101 1 200
    let p = 0.08
    let y2 = binomial rand numb for i = 101 1 200
    .
    let p = 0.15
    let y1 = binomial rand numb for i = 201 1 300
    let p = 0.18
    let y2 = binomial rand numb for i = 201 1 300
    .
    let p = 0.6
    let y1 = binomial rand numb for i = 301 1 400
    let p = 0.45
    let y2 = binomial rand numb for i = 301 1 400
    .
    let p = 0.3
    let y1 = binomial rand numb for i = 401 1 500
    let p = 0.1
    let y2 = binomial rand numb for i = 401 1 500
    .
    let x = sequence 1 100 1 5
    .
    let a = odds ratio y1 y2 subset x = 1
    tabulate odds ratio y1 y2 x
    .
    label case asis
    xlimits 1 5
    major xtic mark number 5
    minor xtic mark number 0
    xtic mark offset 0.5 0.5
    y1label Bias Corrected Odds Ratio
    x1label Group ID
    character x blank
    line blank solid
    .
    odds ratio plot y1 y2 x
 
-----ODDS RATIO CHI-SQUARE TEST (LET)--------------------------------
 
ODDS RATIO CHI-SQUARE TEST
 
Name:
    ODDS RATIO CHI-SQUARE TEST (LET)
 
Type:
    Analysis Command
 
Purpose:
    Perform an odds ratio chi-square test of a series of
    fourfold (2x2) tables.

Description:
    Given two variables where each variable has exactly two
    possible outcomes (typically defined as success and failure),
    we define the odds ratio as:

        o = (N11/N12)/(N21/N22)
          = (N11*N22)/(N12*N21)

    where

        N11 = number of successes in sample 1 
        N21 = number of failures in sample 1 
        N12 = number of successes in sample 2 
        N22 = number of failures in sample 2

    The log odds ratio is the logarithm of the odds ratio:

        l(o) = LOG{(N11/N12)/(N21/N22)}
             = LOG{(N11*N22)/(N12*N21)}

    Alternatively, the log odds ratio can be given in terms of
    the proportions

      l(o) = LOG{(p11/p12)/(p21/p22)}
           = LOG{(p11*p22)/(p12*p21)}

    where

        p11 = N11/(N11 + N21) = proportion of successes in sample 1
        p21 = N21/(N11 + N21) = proportion of failures in sample 1
        p12 = N12/(N12 + N22) = proportion of successes in sample 2
        p22 = N22/(N12 + N22) = proportion of failures in sample 2

    Success and failure can denote any binary response.
    Dataplot expects "success" to be coded as "1" and "failure"
    to be coded as "0".

    The bias corrected version of the log odds ratio is:

       l'(o) = LOG[{(N11+0.5)*(N22+0.5)}/{(N12+0.5)*(N21+0.5)}]

    In addition to reducing bias, this statistic also has the
    advantage that the log odds ratio is still defined even when
    N12 or N21 is zero (the uncorrected statistic will be
    undefined for these cases).

    Note that N11, N21, N12, and N22 defines a 2x2 contingency
    table.  These types of contingency tables are also referred
    to as fourfold tables.

    The odds ratio chi-square test is applied in the situation
    where we have a series of fourfold tables.  That is, the two
    variables for the fourfold tables are the same, but data is
    collected from different populations or groups with regards
    to these variables.  Fleiss, Levin, and Paik (p. 234) list
    the following questions that are typically asked about 
    these type of data:

        1) Is there evidence that the degree of association,
           whatever its magnitude, is consistent from one group
           to another?

        2) Assuming that the degree of association is found to
           be consistent, is the common degree of association
           statistically significant?

        3) Assuming that the common degree of association is
           significant, what is the best estimate of the common
           value for the measure of association?  What is its
           standard error?  How does one construct a confidence
           interval for the common measure?

    The following description for this test is summarized from
    Chapter 10 of Fleiss, Levin, and Paik.  Consult this reference
    for a more detailed discussion. 

    Suppose we have g fourfold tables.  Then

       y(i)      = measure of association for table i
       se(y(i))  = standard error of y(i)
       w(i)      = 1/[se(y(i))]**2 
       g         = number of groups (i.e., number of 2x2 tables)

    This test is based on decomposing the total chi-square
    in the following way:

        Chi-square(total) = SUM[i=1 to g][w(i)*y(i)**2]
                          = Chi-square(homogeneity) +
                            Chi-square(association)

    The Chi-square(homogeneity) assesses the degree of
    homogeneity (i.e., equality) among the g measures of
    association.  The chi-square(association) assesses the
    significance of the average degree of association.

    The overall measure of association (across all groups)
    is the weighted average of the g individual measures:

        ybar = SUM[i=1 to g][w(i)*y(i)]/SUM[i=1 to g][w(i)]

    Under the hypothesis of zero overall association, ybar
    has an average value of zero and a standard error of

        se(ybar) = 1/SQRT(SUM[i=1 to g][w(i)])

    From this

        ybar/se(ybar) = SUM[i=1 to g][w(i)*y(i)]/
                        SUM[i=1 to g][w(i)]

    follows an approximately a standard normal distribution
    under the null hypothesis and

        Chi-square(association) = {ybar/se(ybar)}**2
                                = ybar**2*SUM[i=1 to g][w(i)]
                                 = (SUM[i=1 to g][w(i)*y(i)])**2/
                                   SUM[i=1 to g][w(i)]

    follows an approximately chi-square distribution with
    one degree of freedom.

    In addition,

        Chi-square(homogeneity) = Chi-square(total) -
                                  Chi-square(association)
                                = SUM[i=1 to g][w(i)*y(i)**2 -
                                  ybar**2*SUM[i=1 to g][w(i)]
                                = SUM[i=1 to g][w(i)*(y(i)-ybar)**2

    follows an approximately chi-square distribution with
    g - 1 degrees of freedom.

    Note that chi-square(association) and chi-square(homogeneity)
    are uncorrelated.

    Based on the above formulas, we can answer the above
    questions as follows.

        1) Consistency of association can be tested using the
           chi-square(homogeneity) statistic.  If this statistic
           is significant, this indicates that groups are different
           with respect to the measure of association.

        2) If chi-square(homogeneity) is not signficant (i.e.,
           the groups can be considered equivalent), then
           the overall degree of association can be tested using
           the chi-square(association) statistic.

        3) The estimate of overall association is ybar and a
           large sample confidence interval is

               ybar +/- NORPPF(alpha/2)*se(ybar)

    The above discussion is based on a generic statistic for
    the measure of association.  For the odds ratio chi-square
    test, the specific measure of association is the bias
    corrected log odds ratio (given above).  Note that the
    standard error of the bias corrected log odds ratio is:

      SE(l'(o)) = SQRT{1/(N11+0.5) + 1/(N21+0.5) + 1/(N12+0.5) +
                  1/(N22+0.5)}

    The ODDS RATIO CHI-SQUARE TEST generates the following
    output:

       1) A summary table of various statistics (odds ratio,
          log(odds ratio), standard error of log(odds ratio),
          w(i), and w(i)*log(odds ratio)).

       2) A table summarizing the combined log(odds ratio) and
          its standard error and the chi-square test statistics
          (total, association, and homogeneity).

       3) A table for the chi-square test for homogeneity.

       4) A table for the chi-square test for overall degree of
          association.

       5) Estimates and large sample confidence intervals for the
          common log(odds ratio) and the common odds ratio.

Syntax 1:
    ODDS RATIO CHI-SQUARE TEST <y1> <y2>
                                 <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where <y1> and <y2> denote
    a series of 2x2 tables (i.e., rows 1 and 2 are group 1,
    rows 3 and 4 are group 2, and so on).

Syntax 2:
    ODDS RATIO CHI-SQUARE TEST <y1> <y2> <groupid>
                                 <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <groupid> is a group id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where you have raw data (i.e.,
    the data has not yet been cross tabulated into a two-way table).
    In this case, the two response variables have an equal
    number of cases for each group.

Syntax 3:
    ODDS RATIO CHI-SQUARE TEST <y1> <groupid1> <y2> <groupid2>
                                 <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <groupid1> is a group id variable corresponding to
              <y1>;
          <y2> is the second response variable;
          <groupid2> is a group id variable corresponding to
              <y2>;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where you have raw data (i.e.,
    the data has not yet been cross tabulated into a two-way table).
    In this case, the two response variables may have an unequal
    number of cases for each group, so <y1> and <y2> require
    different group id variables.

Examples:
    ODDS RATIO CHI-SQUARE TEST Y1 Y2
    ODDS RATIO CHI-SQUARE TEST Y1 Y2 X
    ODDS RATIO CHI-SQUARE TEST Y1 X1 Y2 X2

Note:
    This test is similar to the Mantel-Haenszel test.  Fleiss,
    Levin, and Paik make the following recommendations in
    regard to these two tests (they include other tests in
    their comparison).

       1) If the number of groups is small or moderate and
          the sample sizes within each group are large,
          the log(odds ratio) test performs well.

       2) If the number of groups is large, but the sample
          sizes within  the groups are small to moderate,
          then the Mantel-Haenszel test can be recommended.
          The log(odds ratio) test may performs poorly for
          this case.

       3) If the number of groups and the sample sizes
          within the groups are both small, exact methods
          may be required.  Dataplot does not currently
          support any exact methods for this problem.

Note:
    The following information is written to the file dpst1f.dat
    (in the current directory):

        Column 1   - significance level
        Column 2   - lower confidence limit for common
                     log(odds ratio)
        Column 3   - upper confidence limit for common
                     log(odds ratio)
        Column 4   - lower confidence limit for common
                     odds ratio
        Column 5   - upper confidence limit for common
                     odds ratio

     To read this information into Dataplot, enter

        SET READ FORMAT F10.5,1X,4E15.7
        READ DPST1F.DAT SIGLEV LOGLOWCL LOGUPPCL ODDLOWCL ODDUPPCL

     Dataplot saves the following internal parameters:

        STATTOT   = the "total" test statistic
        CDFTOTAL  = the cdf for the "total" test statistic
        STATASSO  = the "association" test statistic
        CDFASSOC  = the cdf for the "association" test statistic
        STATHOMO  = the "homogeneity" test statistic
        CDFHOMOG  = the cdf for the "homogeneity" test statistic

Default:
    None
 
Synonyms:
    None

Related Commands:
    MANTEL-HAENSZEL TEST          = Perform a Mantel-Haenszel test.
    ODDS RATIO INDEPENDENCE TEST  = Perform a log(odds ratio)
                                    independence test.
    CHI-SQUARE INDEPENDENCE TEST  = Perform a chi-square independence
                                    test.
    FISHER EXACT TEST             = Perform Fisher's exact test.
    ASSOCIATION PLOT              = Generate an association plot.
    SIEVE PLOT                    = Generate a sieve plot.
    ROSE PLOT                     = Generate a Rose plot.
    BINARY TABULATION PLOT        = Generate a binary tabulation plot.
    ROC CURVE                     = Generate a ROC curve.
    ODDS RATIO                    = Compute the bias corrected odds
                                    ratio.
    LOG ODDS RATIO                = Compute the bias corrected
                                    log(odds ratio).

Reference:
    Fleiss, Levin, and Paik (2003), "Statistical Methods for
    Rates and Proportions", Third Edition, pp. 234-238.

Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/5
 
Program:
    let n1 = 105
    let n2 = 192
    let n3 = 145
    let n = n1 + n2 + n3
    let x = 3 for i = 1 1 n
    let istop = n1 + n2
    let x = 2 for i = 1 1 istop
    let x = 1 for i = 1 1 n1
    .
    set statistic missing value -99
    .
    .  Group 1 values
    .
    let y1 = 0 for i = 1 1 n
    let y2 = 0 for i = 1 1 n
    let y1 = 1 for i = 1 1  81
    let y2 = 1 for i = 1 1  34
    .
    .  Group 2 values (have unequal samples here, so fill
    .          with missing values
    .
    let istrt = n1 + 1
    let istop1 = istrt + 118 - 1
    let istop2 = istrt + 69 - 1
    let y1 = 1 for i = istrt 1 istop1
    let y2 = 1 for i = istrt 1 istop2
    let istrt2 = n1 + 174 + 1
    let istop2 = n1 + n2
    let y2 = -99 for i = istrt2 1 istop2
    .
    .  Group 3 values
    .
    let istrt = n1 + n2 + 1
    let istop1 = istrt + 82 - 1
    let istop2 = istrt + 52 - 1
    let y1 = 1 for i = istrt 1 istop1
    let y2 = 1 for i = istrt 1 istop2
    .
    odds ratio chi-square test y1 y2 x

-----ODDS RATIO INDEPENDENCE TEST (LET)--------------------------------
 
ODDS RATIO INDEPENDENCE TEST
 
Name:
    ODDS RATIO INDEPENDENCE TEST (LET)
 
Type:
    Analysis Command
 
Purpose:
    Perform a log odds ratio test of independence for a two-way
    contingency table.

Description:
    Given two variables where each variable has exactly two
    possible outcomes (typically defined as success and failure),
    we define the odds ratio as:

        o = (N11/N12)/(N21/N22)
          = (N11*N22)/(N12*N21)

    where

        N11 = number of successes in sample 1 
        N21 = number of failures in sample 1 
        N12 = number of successes in sample 2 
        N22 = number of failures in sample 2

    The log odds ratio is the logarithm of the odds ratio:

        l(o) = LOG{(N11/N12)/(N21/N22)}
             = LOG{(N11*N22)/(N12*N21)}

    Alternatively, the log odds ratio can be given in terms of
    the proportions

      l(o) = LOG{(p11/p12)/(p21/p22)}
           = LOG{(p11*p22)/(p12*p21)}

    where

        p11 = N11/(N11 + N21) = proportion of successes in sample 1
        p21 = N21/(N11 + N21) = proportion of failures in sample 1
        p12 = N12/(N12 + N22) = proportion of successes in sample 2
        p22 = N22/(N12 + N22) = proportion of failures in sample 2

    Success and failure can denote any binary response.
    Dataplot expects "success" to be coded as "1" and "failure"
    to be coded as "0".

    The bias corrected version of the log odds ratio is:

       l'(o) = LOG[{(N11+0.5)*(N22+0.5)}/{(N12+0.5)*(N21+0.5)}]

    In addition to reducing bias, this statistic also has the
    advantage that the log odds ratio is still defined even when
    N12 or N21 is zero (the uncorrected statistic will be
    undefined for these cases).

    Note that N11, N21, N12, and N22 defines a 2x2 contingency
    table.  These types of contingency tables are also referred
    to as fourfold tables.

    A common question with regards to a two-way contingency
    table is whether we have independence.  By independence, we
    mean that the row and column variables are unassociated
    (i.e., knowing the value of the row variable will not
    help us predict the value of column variable and likewise
    knowing the value of the column variable will not help us
    predict the value of the row variable).

    A more technical definition for independence is that

        P(row i, column j) = P(row i)*P(column j)   for all i,j

    One such test for the special case described above (i.e.,
    we have success/failure data) is the log odds ratio test for
    independence.

       H0: The two-way table is independent
       Ha: The two-way table is not independent
       Test Statistic:
            The log odds ratio independence test statistic is:

               T = (N1 + N2)*(N11*N22 - N12*N21)**2/
                   {N1*N2*(N11+N12)*(N21+N22)}

            Some analysts prefer to use the Yates corrected
            version of the test statistic:


               T = (N1 + N2)*(|N11*N22 - N12*N21| - 0.5*(N1 + N2))**2/
                   {N1*N2*(N11+N12)*(N21+N22)}

       Significance Level:  alpha
       Critical Region: T > NORPPF(alpha)

             where NORPPF is the percent point function of the
             normal distribution
       Conclusion: Reject the independence hypothesis if the value
                   of the test statistic is greater than the
                   normal value.

Syntax 1:
    ODDS RATIO INDEPENDENCE TEST <y1> <y2>
                                 <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where you have raw data (i.e.,
    the data has not yet been cross tabulated into a two-way table).

Syntax 2:
    ODDS RATIO INDEPENDENCE TEST <m>
               <SUBSET/EXCEPT/FOR qualification>
    where <m> is a matrix containing the two-way table;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where we the data have already
    been cross-tabulated into a two-way contingency table.

Syntax 3:
    ODDS RATIO INDEPENDENCE TEST <n11> <n12> <n21> <n22>
    where <n11> is a parameter containing the value for row 1,
                column 1 of a 2x2 table;
          <n12> is a parameter containing the value for row 1,
                column 2 of a 2x2 table;
          <n21> is a parameter containing the value for row 2,
                column 1 of a 2x2 table;
          <n22> is a parameter containing the value for row 2,
                column 2 of a 2x2 table.

    This syntax is used for the special case where you have a
    2x2 table.  In this case, you can enter the 4 values directly,
    although you do need to be careful that the parameters are
    entered in the order expected above.

Examples:
    ODDS RATIO INDEPENDENCE TEST Y1 Y2
    ODDS RATIO INDEPENDENCE TEST M
    ODDS RATIO INDEPENDENCE TEST N11 N12 N21 N22

Note:
    Some authors recommend using a continuity correction for this
    test.  In this case, 0.5 is added to the observed frequency
    in each cell.  Dataplot performs this test both with the
    continuity correction and without the continuity correction.

Note:
    The following information is written to the file dpst1f.dat
    (in the current directory):

        Column 1   - significance level
        Column 2   - lower confidence limit (uncorrected case)
        Column 3   - upper confidence limit (uncorrected case)
        Column 4   - lower confidence limit (corrected case)
        Column 5   - upper confidence limit (corrected case)

     To read this information into Dataplot, enter

        SET READ FORMAT F10.5,1X,4E15.7
        READ DPST1F.DAT SIGLEV UNCLOWCL UNCUPPCL CORLOWCL CORUPPCL

     The following internal parameters are automatically
     saved after running this command:

        STATVAL  = test statistic (uncorrected)
        STATVALY = test statistic (with Yates correction)
        STATCDF  = cdf value for test statistic (uncorrected)
        STATCDFY = cdf value for test statistic (with Yates
                   correction)
        ODDSRATI = value of the log(odds ratio)
        ODDSRASE = value of the standard error of the
                   log(odds ratio)
        ODDSRABC = value of the bias corrected log(odds ratio)
        ODDSBCSE = value of the bias corrected standard error of
                   the log(odds ratio)

Note:
    The CHI-SQUARE INDEPENDENCE TEST performs an alternative
    test for independence.

    The chi-square independence test is more general in the
    sense that it applies to RxC contingency tables, not
    just 2x2 tables.

Default:
    None
 
Synonyms:
    None

Related Commands:
    CHI-SQUARE INDEPENDENCE TEST  = Perform a chi-square test for
                                    independence.
    FISHER EXACT TEST             = Perform Fisher's exact test.
    ODDS RATIO CHI-SQUARE TEST    = Perform a log(odds ratio)
                                    chi-square test.
    MANTEL-HAENSZEL TEST          = Perform a Mantel-Haenszel test.
    ASSOCIATION PLOT              = Generate an association plot.
    SIEVE PLOT                    = Generate a sieve plot.
    ROSE PLOT                     = Generate a Rose plot.
    BINARY TABULATION PLOT        = Generate a binary tabulation plot.
    ROC CURVE                     = Generate a ROC curve.
    ODDS RATIO                    = Compute the bias corrected odds
                                    ratio.
    LOG ODDS RATIO                = Compute the bias corrected
                                    log(odds ratio).

Reference:
    Andrew Rukhin, private communication.

    Fleiss, Levin, and Paik (2003), "Statistical Methods for
    Rates and Proportions", Third Edition, pp. 234-238.

Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/2
 
Program 1:
    let n11 = 53
    let n21 = 7
    let n12 = 48
    let n22 = 12
    .
    odds ratio independence test n11 n21 n12 n22

Program 2:
    let n = 1
    let p = 0.9
    let y1 = binomial rand numb for i = 1 1 200
    let p = 0.68
    let y2 = binomial rand numb for i = 1 1 130
    .
    odds ratio independence test y1 y2

-----ODDS RATIO STANDARD ERROR (LET)--------------------------------
 
ODDS RATIO STANDARD ERROR
 
Name:
    ODDS RATIO STANDARD ERROR (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the standard error of the bias corrected odds ratio
    between two binary variables.
 
Description:
    Given two variables where each variable has exactly two
    possible outcomes (typically defined as success and failure),
    we define the odds ratio as:

        o = (N11/N12)/(N21/N22)
          = (N11*N22)/(N12*N21)

    where

        N11 = number of successes in sample 1 
        N21 = number of failures in sample 1 
        N12 = number of successes in sample 2 
        N22 = number of failures in sample 2

    The first definition shows the meaning of the odds ratio
    clearly, although it is more commonly given in the literature
    with the second definition.

    Success and failure can denote any binary response.
    Dataplot expects "success" to be coded as "1" and "failure"
    to be coded as "0".

    Dataplot actually returns the bias corrected version of the
    statistic:

       o'  = {(N11+0.5)*(N22+0.5)}/{(N12+0.5)*(N21+0.5)}

    In addition to reducing bias, this statistic also has the
    advantage that the odds ratio is still defined even when
    N12 or N21 is zero (the uncorrected statistic will be
    undefined for these cases).

    The standard error of this bias corrected odds ratio is then

      SE(o') = o'*SQRT{1/(N11+0.5) + 1/(N21+0.5) + 1/(N12+0.5) +
              1/(N22+0.5)}

    where o' is the bias corrected odds ratio.

Syntax:
    LET <par> = ODDS RATIO STANDARD ERROR <y1> <y2>
                              <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed odds ratio is
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = ODDS RATIO STANDARD ERROR Y1 Y2
    LET A = ODDS RATIO STANDARD ERROR Y1 Y2 SUBSET TAG > 2
 
Note:
    The two variables need not have the same number of elements.
 
Note:
    There are two ways you can define the response variables:

       1) Raw data - in this case, the variables contain
          0's and 1's.

          If the data is not coded as 0's and 1's, Dataplot
          will check for the number of distinct values.  If
          there are two distinct values, the minimum value
          is converted to 0's and the maximum value is
          converted to 1's.  If there is a single distinct
          value, it is converted to 0's if it is less than
          0.5 and to 1's if it is greater than or equal to
          0.5.  If there are more than two distinct values,
          an error is returned.

       2) Summary data - if there are two observations, the
          data is assummed to be the 2x2 summary table.
          That is,

              Y1(1) = N11
              Y1(2) = N21
              Y2(1) = N12
              Y2(2) = N22
 
Note:
    The following additional commands are supported

        TABULATE ODDS RATIO STANDARD ERROR  Y1 Y2 X
        CROSS TABULATE ODDS RATIO STANDARD ERROR Y1 Y2 X1 X2

        ODDS RATIO STANDARD ERROR PLOT Y1 Y2 X
        CROSS TABULATE ODDS RATIO STANDARD ERROR PLOT Y1 Y2 X1 X2

        BOOTSTRAP ODDS RATIO STANDARD ERROR PLOT Y1 Y2
        JACKNIFE  ODDS RATIO STANDARD ERROR PLOT Y1 Y2

    Note that the above commands expect the variables to have
    the same number of observations.  If the two samples are
    in fact of different sizes, there are two ways to address
    the issue:

       1) Y1 and Y2 can contain the summary data.  That is,

            Y1(1) = N11
            Y1(2) = N21
            Y2(1) = N12
            Y2(2) = N22

          This is a useful option in that the data is sometimes
          only available in summary form.  Note that this will
          not work for the BOOTSTRAP PLOT and JACKNIFE PLOT
          commands (these require raw data).

       2) You can specify a missing value for the smaller
          sample.  For example, if Y1 has 100 observations and
          Y2 has 200 observations, you can do something like

              SET STATISTIC MISSING VALUE -99
              LET Y1 = -99 FOR I = 101  1  200

Default:
    None
 
Synonyms:
    STANDARD ERROR ODDS RATIO
 
Related Commands:
    ODDS RATIO                 = Compute the bias corrected
                                 odds ratio.
    LOG ODDS RATIO             = Compute the bias corrected
                                 log(odds ratio).
    FALSE POSITIVES            = Compute the proportion of
                                 false positives.
    FALSE NEGATIVES            = Compute the proportion of
                                 false negatives.
    TRUE NEGATIVES             = Compute the proportion of
                                 true negatives.
    TRUE POSITIVES             = Compute the proportion of
                                 true positives.
    TEST SENSITIVITY           = Compute the test sensitivity.
    TEST SPECIFICITY           = Compute the test specificity.
    TABULATE                   = Compute a statistic for data with
                                 a single grouping variable.
    CROSS TABULATE             = Compute a statistic for data with
                                 two grouping variables.
    STATISTIC PLOT             = Generate a plot of a statistic for
                                 data with a single grouping
                                 variable.
    CROSS TABULATE PLOT        = Generate a plot of a statistic for
                                 data with two grouping variables.
    BOOTSTRAP PLOT             = Generate a bootstrap plot for a
                                 given statistic.
    STATISTIC MISSING VALUE    = Define a missing value for several
                                 plots and commands for unpaired
                                 samples that may be of different
                                 sizes.
 
Reference:
    Fleiss, Levin, and Paik (2003), "Statistical Methods for
    Rates and Proportions", Third Edition, Wiley, chapter 1.
 
Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/5
 
Program:
    let n = 1
    .
    let p = 0.2
    let y1 = binomial rand numb for i = 1 1 100
    let p = 0.1
    let y2 = binomial rand numb for i = 1 1 100
    .
    let p = 0.4
    let y1 = binomial rand numb for i = 101 1 200
    let p = 0.08
    let y2 = binomial rand numb for i = 101 1 200
    .
    let p = 0.15
    let y1 = binomial rand numb for i = 201 1 300
    let p = 0.18
    let y2 = binomial rand numb for i = 201 1 300
    .
    let p = 0.6
    let y1 = binomial rand numb for i = 301 1 400
    let p = 0.45
    let y2 = binomial rand numb for i = 301 1 400
    .
    let p = 0.3
    let y1 = binomial rand numb for i = 401 1 500
    let p = 0.1
    let y2 = binomial rand numb for i = 401 1 500
    .
    let x = sequence 1 100 1 5
    .
    let a = odds ratio standard error y1 y2 subset x = 1
    tabulate odds ratio standard error y1 y2 x
    .
    label case asis
    xlimits 1 5
    major xtic mark number 5
    minor xtic mark number 0
    xtic mark offset 0.5 0.5
    y1label Bias Corrected Odds Ratio Standard Error
    x1label Group ID
    character x blank
    line blank solid
    .
    odds ratio standard error plot y1 y2 x
 
-----OFF-------------------------------------------------------
 
OFF
 
Name:
    OFF
 
Type:
    Keyword
 
Purpose:
    Sets the DATAPLOT switch in question to the "off" position.
 
Description:
 
Syntax:
    <Certain commands>   OFF
 
Examples:
    HARDCOPY OFF
    ECHO OFF
    FRAME OFF
    TICS OFF
    X2TICS OFF
    TIC LABELS OFF
    X2TIC LABELS OFF
    FEEDBACK OFF
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    ON        = Allows a switch to be "on".
    DEFAULT   = Allows a switch to be "default".
    AUTOMATIC = Allows a switch to be "automatic".
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----OGICDF (LET)--------------------------------
 
OGICDF
 
Name:
    OGICDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the ogive cumulative distribution function
    with shape parameter n.
 
Description:
    The standard ogive distribution has the following
    cumulative distribution function:

       F(x;n) = ((4*n-2)/(3*n-1))*x**n - ((n-1)/(3*n-1))*x**(2*n)
                0 <= x <= 1, n >= 0.5
 
    with n denoting the shape parameter.

    This distribution can be extended with lower and upper
    bound parameters.  If a and b denote the lower and upper
    bounds, respectively, then the location and scale 
    parameters are:

        location = a
        scale    = b - a

    The general form of the cumulative distribution function
    can then be found by using the relation

        F(x;n,a,b) = F((x-a)/(b-a);n,0,1)

Syntax:
    LET <y> = OGICDF(<x>,<n>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing
              values in the interval (a,b);
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed ogive cdf value
              is stored;
          <n> is a positive number, parameter, or variable that
              specifies the shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = OGICDF(0.3,2.2)
    LET Y = OGICDF(X,2.5,0,5)
    PLOT OGICDF(X,2,0,3) FOR X = 0  0.01  3
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    OGIPDF = Compute the ogive probability density function.
    OGPPFF = Compute the ogive percent point function.
    TSOPDF = Compute the two-sided ogive probability density
             function.
    SLOPDF = Compute the slope probability density function.
    TSSPDF = Compute the two-sided slope probability density
             function.
    TOPPDF = Compute the Topp and Leone probability density function.
    RGTPDF = Compute the generalized reflected Topp and Leone
             probability density function.
    GTLPDF = Compute the generalized Topp and Leone probability
             density function.
    TSPPDF = Compute the two-sided power probability density
             function.
    BETPDF = Compute the n probability density function.
    TRIPDF = Compute the triangular probability density function.
    TRAPDF = Compute the trapezoid probability density function.
    UNIPDF = Compute the uniform probability density function.
    POWPDF = Compute the power probability density function.
    JSBPDF = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond N:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, chapter 8.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/10
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET N  = 0.5
    TITLE N = ^n
    PLOT OGICDF(X,N) FOR X = 0  0.01  1
    .
    LET N  = 0.8
    TITLE N = ^n
    PLOT OGICDF(X,N) FOR X = 0  0.01  1
    .
    LET N  = 1.5
    TITLE N = ^n
    PLOT OGICDF(X,N) FOR X = 0  0.01  1
    .
    LET N  = 2
    TITLE N = ^n
    PLOT OGICDF(X,N) FOR X = 0  0.01  1
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Ogive Cumulative Distribution Functions
 
-----OGIPDF (LET)--------------------------------
 
OGIPDF
 
Name:
    OGIPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the ogive probability density function
    with shape parameter n.
 
Description:
    The standard ogive distribution has the following
    probability density function:

       f(x;n) = n*x**(n-1)*{(4*n-2)/(3*n-1) -
                ((2*n-2)/(3*n-1))*x**n}
                0 <= x <= 1, n >= 0.5
 
    with n denoting the shape parameter.

    This distribution can be extended with lower and upper
    bound parameters.  If a and b denote the lower and upper
    bounds, respectively, then the location and scale 
    parameters are:

        location = a
        scale    = b - a

    The general form of the distribution can then be found
    by using the relation

        f(x;n,a,b) = f((x-a)/(b-a);n,0,1)/(b-a)

Syntax:
    LET <y> = OGIPDF(<x>,<n>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing
              values in the interval (a,b);
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed ogive pdf value
              is stored;
          <n> is a positive number, parameter, or variable that
              specifies the shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = OGIPDF(0.3,2.2)
    LET Y = OGIPDF(X,2.5,0,5)
    PLOT OGIPDF(X,2,0,3) FOR X = 0  0.01  3
 
Note:
    Ogive random numbers, probability plots, and goodness of
    fit tests can be generated with the commands:

       LET N = <value>
       LET A = <value>
       LET B = <value>
       LET Y = OGIVE RANDOM NUMBERS FOR I = 1 1 N
       OGIVE PROBABILITY PLOT Y
       OGIVE PROBABILITY PLOT Y2 X2
       OGIVE PROBABILITY PLOT Y3 XLOW XHIGH
       OGIVE KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       OGIVE CHI-SQUARE GOODNESS OF FIT Y2 X2
       OGIVE CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    The following commands can be used to estimate the n
    shape parameter for the ogive distribution:

       LET N1 = <value>
       LET N2 = <value>
       OGIVE PPCC PLOT Y
       OGIVE PPCC PLOT Y2 X2
       OGIVE PPCC PLOT Y3 XLOW XHIGH
       OGIVE KS PLOT Y
       OGIVE KS PLOT Y2 X2
       OGIVE KS PLOT Y3 XLOW XHIGH

    The default values for N1 and N2 are 0.5 and 10.

    The probability plot can then be used to estimate the
    lower and upper limits (lower limit = PPA0,
    upper limit = PPA0 + PPA1).

    For the KS plot, we can fix the location and scale.
    This is equivalent to assuming that the lower and
    upper limits are known (e.g., we could use the
    data minimum and maximum as the lower and upper
    limit values).  Given that the lower and upper
    limits are LOWLIM and UPPLIM, enter the commands

         LET KSLOC   = LOWLIM
         LET KSSCALE = UPPLIM - LOWLIM

    The PPCC plot is invariant to location and scale,
    so we cannot fix the lower and upper limits.

    The BOOTSTRAP DISTRIBUTION command can be used to find
    uncertainty intervals for the PPCC plot and KS plot.
       
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    OGICDF = Compute the ogive cumulative distribution
             function.
    OGPPFF = Compute the ogive percent point function.
    TSOPDF = Compute the two-sided ogive probability density
             function.
    SLOPDF = Compute the slope probability density function.
    TSSPDF = Compute the two-sided slope probability density
             function.
    TOPPDF = Compute the Topp and Leone probability density function.
    RGTPDF = Compute the generalized reflected Topp and Leone
             probability density function.
    GTLPDF = Compute the generalized Topp and Leone probability
             density function.
    TSPPDF = Compute the two-sided power probability density
             function.
    BETPDF = Compute the beta probability density function.
    TRIPDF = Compute the triangular probability density function.
    TRAPDF = Compute the trapezoid probability density function.
    UNIPDF = Compute the uniform probability density function.
    POWPDF = Compute the power probability density function.
    JSBPDF = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond N:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, chapter 8.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/10
 
Program 1:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET N  = 0.5
    TITLE N = ^n
    PLOT OGIPDF(X,N) FOR X = 0  0.01  1
    .
    LET N  = 0.8
    TITLE N = ^n
    PLOT OGIPDF(X,N) FOR X = 0.01  0.01  1
    .
    LET N  = 1.5
    TITLE N = ^n
    PLOT OGIPDF(X,N) FOR X = 0  0.01  1
    .
    LET N  = 2
    TITLE N = ^n
    PLOT OGIPDF(X,N) FOR X = 0  0.01  1
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Ogive Probability Density Functions
 
Program 2:
    let n = 1.2
    let y = ogive rand numb for i = 1 1 200
    .
    let nsav = n
    ogive ppcc plot y
    just center
    move 50 5
    let n = shape
    text maxppcc = ^maxppcc, N = ^n
    move 50 2
    text Nsav = ^nsav
    .
    char x
    line blank
    ogive prob plot y
    move 50 5
    text PPA0 = ^ppa0, PPA1 = ^ppa1
    move 50 2
    let upplim = ppa0 + ppa1
    text Lower Limit = ^ppa0, Upper Limit = ^upplim
    char blank
    line solid
    .
    let ksloc = ppa0
    let ksscale = upplim
    ogive kolm smir goodness of fit y

-----OGIPPF (LET)--------------------------------
 
OGIPPF
 
Name:
    OGIPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the ogive percent point function with shape
    parameter n.
 
Description:
    The standard ogive distribution has the following
    cumulative distribution function:

       F(x;n) = ((4*n-2)/(3*n-1))*x**n - ((n-1)/(3*n-1))*x**(2*n)
                0 <= x <= 1, n >= 0.5
 
    with n denoting the shape parameter.

    The percent point function is computed by numerically
    inverting the cumulative distribution function.

    This distribution can be extended with lower and upper
    bound parameters.  If a and b denote the lower and upper
    bounds, respectively, then the location and scale 
    parameters are:

        location = a
        scale    = b - a

    The general form of the percent point function can then
    be found by using the relation

        G(p;n,a,b) = a + (b-a)*G(p;n,0,1)

Syntax:
    LET <y> = OGIPPF(<p>,<n>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, parameter, or variable containing
              values in the interval (0,1);
          <y> is a variable or a parameter (depending on what
              <p> is) where the computed ogive ppf value
              is stored;
          <n> is a positive number, parameter, or variable that
              specifies the shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = OGIPPF(0.05,2.2)
    LET Y = OGIPPF(P,2.5,0,5)
    PLOT OGIPPF(P,2,0,3) FOR P = 0  0.01  1
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    OGICDF = Compute the ogive cumulative distribution
             function.
    OGPPDF = Compute the ogive probability density function.
    TSOPDF = Compute the two-sided ogive probability density
             function.
    SLOPDF = Compute the slope probability density function.
    TSSPDF = Compute the two-sided slope probability density
             function.
    TOPPDF = Compute the Topp and Leone probability density function.
    RGTPDF = Compute the generalized reflected Topp and Leone
             probability density function.
    GTLPDF = Compute the generalized Topp and Leone probability
             density function.
    TSPPDF = Compute the two-sided power probability density
             function.
    BETPDF = Compute the n probability density function.
    TRIPDF = Compute the triangular probability density function.
    TRAPDF = Compute the trapezoid probability density function.
    UNIPDF = Compute the uniform probability density function.
    POWPDF = Compute the power probability density function.
    JSBPDF = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond N:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, chapter 8.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/10
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET N  = 0.5
    TITLE N = ^n
    PLOT OGIPPF(P,N) FOR P = 0  0.01  1
    .
    LET N  = 0.8
    TITLE N = ^n
    PLOT OGIPPF(P,N) FOR P = 0  0.01  1
    .
    LET N  = 1.5
    TITLE N = ^n
    PLOT OGIPPF(P,N) FOR P = 0  0.01  1
    .
    LET N  = 2
    TITLE N = ^n
    PLOT OGIPPF(P,N) FOR P = 0  0.01  1
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Ogive Cumulative Distribution Functions
 
-----OMIT (LET)---------------------------------------------------
 
OMIT
 
Name:
    OMIT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Given a group-id variable, create a tag variable based on a list
    of groups to omit.
 
Description:
    For some analyses, it may be necessary to omit some laboratories
    from the analysis.  Although you can create an appropriate tag
    variable manually, the OMIT command can simplify that process.

    For example, if you have labs 1 to 10 and you want to omit labs 3 and
    8 from the analysis, you can do something like the following

        LET XOMIT = DATA 3 8
        LET TAG = OMIT X XOMIT

    That is, this command will return a tag variable (TAG) based on
    the values of X.  Values of X that match any value in XOMIT will
    be set to 0 and values of X that do not match any values in XOMIT
    will be set to 1.

Syntax:
    LET <tag> = OMIT <x> <xomit>    <SUBSET/EXCEPT/FOR qualification>
    where <x> is the group-id variable;
          <xomit> is a list of values to match against <x>;
          <tag> is a variable of the same length as <x> that will contain
               0 where a match is found and 1 otherwise;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET TAG = OMIT X XOMIT
 
Note:
    The KEEP command is similar.  However, with the KEEP command you
    specify a list of lab id's to keep rather than to omit.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    KEEP       = Create a tag variable based on a list of labs to keep.
    CODE       = Generate a coded variable.
    COCODE     = Generate a coded variable based on another variable.
    COCOPY     = Generate a coded variable based on another variable.
 
Applications:
    Data Transformations
 
Implementation Date:
    2011/4
 
Program:
    skip 25
    read gear.dat y x
    set write decimals 4
    .
    let xomit = data 1 3 5 7 8 9
    let tag = omit x xomit
    print x tag y
 
-----ON-------------------------------------------------------
 
ON
 
Name:
    ON
 
Type:
    Keyword
 
Purpose:
    Sets the DATAPLOT switch in question to the "on" position.
 
Description:
 
Syntax:
    <Certain commands>   ON
 
Examples:
    HARDCOPY ON
    ECHO ON
    FRAME ON
    TICS ON
    X2TICS ON
    TIC LABELS ON
    X2TIC LABELS ON
    FEEDBACK ON
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    OFF       = Allows switches to be set to "off".
    DEFAULT   = Allows switches to be set to "default".
    AUTOMATIC = Allows switches to be set to "automatic".
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----ONE WAY ANOVA---------------------------------------------------
 
ONE WAY ANOVA
 
Name:
    ONE WAY ANOVA
 
Type:
    Analysis Command
 
Purpose:
    Perform a One Way Analysis of Variance (ANOVA)
 
Description:
    Analysis of Variance (ANOVA) is a data analysis technique for
    examining the significance of the factors (= independent variables)
    in a multi-factor model.  Each factor has a certain number of values
    it can have (these are referred to as the levels of a factor).  The
    number of levels can vary betweeen factors.  Each factor and level
    combination is a cell.  Balanced designs are those in which each
    cell has an equal number of observations and unbalanced designs are
    those in which the number of observations can vary among cells.
    A treatment is defined as a single combination of the levels
    of the factors.  For the one-factor case, a treatment is
    equivalent to a level.

    The basic ANOVA model for one factor is

        y(ij) = mu + tau(i) + e(ij)  i = 1, ..., k, j = 1, 2, ..., n(i)

    where

        y(ij)   = the j-th observation of the i-th treatment
        mu      = the population (grand) mean
        tau(i)  = the effect of the i-th treatment
        e(ij)   = the error for the j-th observation of the i-th
                  treatment
        n(i)    = the number of observations for treatment i
        k       = the number of treatments

    The errors are assumed to be independent and normally distributed
    with mean 0 and standard deviation sigma and mu is assumed to be a
    fixed parameter.

    In the fixed effects ANOVA model, the levels of the factor are
    assumed to be fixed and the tau(i) are also assumed to be fixed
    parameters.  In the random effects ANOVA model, the levels of a
    factor are assumed to be a random sample from a population of
    possible level values and the tau(i) are assumed to be random
    variables that are normally distributed with mean zero and standard
    deviation sigma(tau).  The tau(i) and e(ij) are assumed to be
    independent for all i and j.  Although the basic ANOVA calculations
    are the same for the fixed and random effects model, the hypothesis
    being tested is different.  In a fixed effects model, ANOVA is used to
    test the hypothesis that tau(1) = tau(2) = ... = tau(k).  In a random
    effects model, ANOVA is used to test the hypothesis that
    sigma(tau) = 0.  Note that testing for the equality of the tau(i)
    is not meaningful in the context of a random effects model.

    For example, suppose one factor is the operator of a machine.  In a
    fixed effects model, we would be testing whether the average
    performance varies between the specific operators tested.  For a
    random effects model, we assume that the specific operators tested
    were randomly selected from a larger pool of available operators.  In
    this case, we are not interested in the average performance of the
    specific operators tested.  Rather we are interested in the
    variability between operators.

    The basic computations for the one factor fixed effects ANOVA are
    given here (and in most introductory statistics text books)

        https://www.itl.nist.gov/div898/handbook/prc/section4/prc431.htm
        https://www.itl.nist.gov/div898/handbook/prc/section4/prc432.htm
        https://www.itl.nist.gov/div898/handbook/prc/section4/prc433.htm

    Basically, the sum of squares are decomposed into a "treatment"
    sum of squares and an "error" sum of squares.  Essentially we are
    comparing the ratio of the between treatment variability and the
    within treatment variability.  For a fixed effects case, if the
    between variability is small compared to the within variability
    we conclude the treatment means are essentially equal.  Similarly
    for the random effects model, if the between variability is small
    compared to the within variability we conclude the variance between
    treatments is essentially zero.

    The Dataplot ANOVA command performs an analysis of variance for
    up to 10 factors.  However, this command is intended for the
    fixed effects case with balanced data (i.e., all cells have the
    same sample size).

    The ONE WAY ANOVA command specifically handles the case of a
    single factor variable.  However, it handles a broader range
    cases than the regular ANOVA command and provides some additional
    output.  Specifically,

       1. The ONE WAY ANOVA command allows summary data (i.e., the mean,
          standard deviation and sample size for each level of the factor
          variable) in addition to raw data.

       2. The ONE WAY ANOVA command allows a random effects model to
          be specified.  This case will generate a variance components
          table (more will be said about this in the Notes section
          below).

       3. For the fixed effects case, the ONE WAY ANOVA command generates
          several additional tables.  Specifically

              a. A table containing confidence intervals for the
                 treatment means is generated.

              b. A table containg confidence intervals for the
                 difference of the treatment means is generated.

              c. A table containing Bonferroni adjusted confidence
                 intervals for the difference of treatment means is
                 generated.

              d. A table containing Tukey-Kramer adjusted confidence
                 intervals for the difference of treatment means is
                 generated.

          Details about these tables is given in the Notes section
          below.

          Since random effect models are not concerned with the mean
          values and difference of the mean values for the specific
          treatments, these tables will not be generated for that case.

       4. The ONE WAY ANOVA command supports unbalanced data.

          There are two warnings that should be noted when dealing
          with unbalanced data.  The balanced ANOVA case is known to be
          somewhat robust to the assumption of equal variances for the
          treatments.  A common rule of thumb is that if the ratio of
          the largest treatment variance to the smallest treatment
          variance is less than 2, then the ANOVA should be robust
          to unequal variances.  The unbalanced case is more sensitive
          to the equal variances assumption (and there is no
          corresponding rule of thumb in this case).  In addition,
          the unbalanced ANOVA is known to be less powerful than the
          balanced ANOVA case.  By less powerful, we mean that it takes
          larger differences in the treatment means to detect a
          statistically significant difference.
 
Syntax 1:
    ONE WAY ANOVA <y> <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the factor (= independent) variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax generates a fixed effects ANOVA based on raw data.

Syntax 2:
    ONE WAY SUMMARY ANOVA <ymean> <ysd> <yn>
                          <SUBSET/EXCEPT/FOR qualification>
    where <ymean> is a variable containing the treatment means;
          <ysd>   is a variable containing the treatment standard
                  deviations;
          <yn>    is a variable containing the treatment sample sizes;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax generates a fixed effects ANOVA based on summary data.

Syntax 3:
    ONE WAY RANDOM EFFECTS ANOVA <y> <x>
                                 <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the factor (= independent) variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax generates a random effects ANOVA based on raw data.

Syntax 4:
    ONE WAY SUMMARY RANDOM EFFECTS ANOVA <ymean> <ysd> <yn>
                                         <SUBSET/EXCEPT/FOR qualification>
    where <ymean> is a variable containing the treatment means;
          <ysd>   is a variable containing the treatment standard
                  deviations;
          <yn>    is a variable containing the treatment sample sizes;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax generates a random effects ANOVA based on summary data.

Examples:
    ONE WAY ANOVA Y X
    ONE WAY SUMMARY ANOVA YMEAN YSD YN
    ONE WAY RANDOM EFFECTS ANOVA Y X
    ONE WAY SUMMARY RANDOM EFFECTS ANOVA YMEAN YSD YN
    ONE WAY ANOVA Y X  SUBSET Y > 0
    ONE WAY ANOVA Y X  SUBSET X = 1 TO 6
 
Note:
    The ONE WAY ANOVA command saves the residuals in the variable RES
    and the predicted values in the variable PRED.  These can be used to
    generate various diagnostic plots.
 
    The predicted values are the estimated grand mean plus the estimated
    treatment effect.  The residuals are the response variable minus the
    predicted values.
 
    The PRED and RES variables will not be saved if summary data is used.

Note:
    For the random effects model, a variance component table will be
    printed.  An example table is shown here

                Variance Components Table: Random Effects

     ----------------------------------------------------------------------------------------------------------------
                                                  Lower          Upper       Intraclass          Lower          Upper
                                Variance     Confidence     Confidence      Correlation     Confidence     Confidence
                   Source      Component          Limit          Limit  Coefficient (%)          Limit          Limit
     ----------------------------------------------------------------------------------------------------------------
      Treatment (Between)      11.711111       3.456828     101.096603            86.68      54.490128      98.364796
        Residual (Within)       1.800000       0.878770       5.543625            13.32

    The variance component table is used to specify the percentage of
    the variance that can be attributed to the treatment (between) and
    how much to the error (within).

    The variance component for the treatment is computed as

         S(Treatment)**2 = MAX(0,(MSTR - MSE)/n0)

    where MSTR denotes the mean square of the treatment and MSE denotes
    the mean square error and

        n0 = (1/(k-1)) *
             (SUM[i=1 to k][n(i) - (SUM[i=1 to k][n(i)**2]/SUM[i=1 to k][n(i)])

    The MSTR and MSE values are obtained from the standard ANOVA table.
    In the balanced case, n0 is equal to the level sample size.  The
    variance component for the error is simply the MSE.

    The variance components are often given as a proportion of the total
    variance.  In this case, the variance component is divided by the
    sum of the treatment variance component and the error variance
    component.  This is also referred to as the intraclass correlation
    coefficient.  Dataplot prints this expressed as a percentage rather
    than a proportion.

    The confidence interval for the treatment variance component is
    computed as

          Lower CL = SSTR*(1 - (Fu/F0))/(n0*CHSPPF(alpha/2,k-1))
          Upper CL = SSTR*(1 - (Fl/F0))/(n0*CHSPPF(1-(alpha/2),k-1))

    where

          CHSPPF = the chi-square percent point function
          Fl     = FPPF(alpha/2,k-1,ntotal-k)
          Fu     = FPPF(1 - (alpha/2),k-1,ntotal-k)
          F0     = F statistic from the ANOVA
          FPPF   = the F percent point function
          ntotal = the total number of observations

    The confidence interval for the error variance component is
    computed as

          LCL = (ntotal - k)*MSE/CHSPPF(alpha/2,ntotal-k)
          UCL = (ntotal - k)*MSE/CHSPPF(1 - (alpha/2),ntotal-k)

    Approximate confidence intervals for the intraclass correlation
    coefficient are computed as

          LCL = L/(1+L)
          UCL = U/(1+U)

    where

          L = (1/n0)*((F0/Fu) - 1)
          U = (1/n0)*((F0/Fl) - 1)

    where F0, Fl and Fu are as defined above.

Note:
    For the fixed effects model, confidence intervals for the level
    means are computed as follows

         Ybar(i) +/- t(1-alpha/2,ntotal-k)*SQRT(MSE/n(i))

    with Ybar((i) denoting the mean of the i-th level and t denoting
    the t percent point function.

    If the ANOVA shows a statistically significant difference in the
    level means, a follow-up step is to compare the pairwise difference
    in treatment means to determine which differences are statistically
    significant.  This is a subset of possible multiple comparisons.
    There are a number of different ways to perform these pairwise
    comparisons.

    The first table generates confidence intervals based on Fisher's
    Least Protected Difference (LSD)

         |Ybar(i) - Ybar(j)| +/- t(1-(alpha/2),ntotal-k)*
                                 SQRT{MSE*((1/n(i)) + (1/n(j)))}

    This is just the standard confidence interval for the difference
    between means.  The protected part is based on the idea that these
    differences are only analyzed if the F test from the ANOVA is
    statistically significant.  The last column provides p-values
    (p-values less than alpha indicate statistical significance).

    The second table generates confidence intervals based on
    Bonferroni's adjustment to alpha.  The LSD method provides pairwise
    statistical signficance, but does not provide simultaneous
    statistical significance.  Bonferroni addresses this with the
    following correction to alpha

         alpha' = alpha/(k*(k-1)/2)

    The table header prints the adjusted alpha.  This can be compared
    to the p-values in the last column to determine statistical
    significance.

    The third table generates Tukey-Kramer honest significant difference
    (HSD) confidence intervals.  These confidence intervals are based on

         |Ybar(i) - Ybar(j)| +/- q(alpha,k,ntotal-k)*
                                 SQRT{MSE*((1/n(i)) + (1/n(j)))}

    where q denotes the studentized range percent point function.  Like
    the Bonferroni intervals, these intervals provide simultaneous
    statistical significance.

    The generated tables are based on pairwised differences between level
    means.  More general comparisons are based on contrasts and linear
    combnations.  A contrast is a linear combination of two or more factor
    level means with coefficients that sum to zero

         C = c1*mu1 + c2*mu2 + ... + cj*muj

    with c1, c2, ..., cj denoting the contrast coefficients and mu1,
    mu2, ..., muj denoting the factor level means and where

         SUM[i=1 to k][c(i)] = 0

    For example, the pairwise difference betweem two level means has
    coefficients c1 = 1 and c2 = -1.  To compare levels 1 and 2 with
    level 3, the coefficients are c1 = 1, c2 = 1, and c3 = -2.

    Two contrasts are orthogonal if the sum of the products of
    corresponding coefficients (i.e., coefficients for the same means)
    also sum to zero.  That is

        SUM[i=1 to r][c(i)*d(i)] = 0

    where c and d are coefficients for two contrasts.

    For the unbalanced case, this is

        SUM[i=1 to r][n(i)*c(i)*d(i)] = 0

    A linear combination is similar to a contrast, but it does not
    require that the coefficients sum to zero.

    A contrast is estimated by

        Chat = SUM[i=1 to r][c(i)*Ybar(i)]

    The variance of the contrast is

        Var(Chat) = sigma**2*SUM[i=1 to r][c(i)**2/n(i)]

    and a confidence interval is given by

        Chat +/- t(1-(alpha/2),ntotal-r)*SQRT(Var(Chat))

    Estimates and confidence intervals for linear combinations are
    generated using the same formulas as contrasts.

    Montgomery (pp. 60-62) shows how the treatment sum of squares can
    be partitioned into contrast sum of squares for orthogonal
    contrasts.  Note that constrasts should be chosen before the data
    is collected.

Note:
    By default, an alpha = 0.05 is used in the above formulas.  To use
    a different value of alpha, enter

        LET ALPHA = <value>

    Typical values for alpha are 0.01, 0.05 and 0.10.

Note:
    The following quantities are written to files

       1. dpst1f.dat - the level id, the level mean, the effect
                       estimate and the standard deviation of the
                       effect estimate

       2. dpst2f.dat - the level id, the level mean, the level standard
                       deviation, and the lower and upper confidence
                       limits for the level mean

       3. dpst3f.dat - the first level id, the second level id, the
                       Fisher LSD lower and upper confidence limits and
                       the p-value for the difference of means

       4. dpst4f.dat - the first level id, the second level id, the
                       Bonferroni lower and upper confidence limits and
                       the p-value for the difference of means

       5. dpst5f.dat - the first level id, the second level id, the
                       Tukey-Kramer standard error, the Tukey-Kramer
                       lower and upper confidence limits and the 90%,
                       95% and 99% critical values for Tukey-Kramer

Note:
    The following parameters are saved after the ONE WAY ANOVA command
    is performed.

         STATVAL   - value of the F test statistic
         STATCDF   - CDF of the F test statistic
         PVALUE    - p-value of the F test statistic
         MSTR      - treatment mean square
         MSE       - error mean square
         SSTR      - treatment sum of squares
         SSE       - error sum of squares
         SSTOT     - total sum of squares

Default:
    None
 
Synonyms:
    ANALYSIS OF VARIANCE is a synonym for ANOVA
    1 WAY is a synonym for ONE WAY
    RANDOM EFFECTS SUMMARY is a synonym for SUMMARY RANDOM EFFECTS
 
Related Commands:
    ANOVA                 = Perform a fixed effects ANOVA for balanced
                            data (up to 10 factors)
    KRUSKAL WALLIS        = Perform a Kruskal Wallis test.
    MEDIAN POLISH         = Carries out a robust ANOVA.
    YATES ANALYSIS        = Analyze a Yate's design.
    BLOCK PLOT            = Generate a block plot.
    DEX SCATTER PLOT      = Generates a dex scatter plot.
    DEX ... PLOT          = Generates a dex plot for a statistic.
    DEX ... EFFECTS PLOT  = Generates a dex effects plot for a
                            statistic.
    T TEST                = Carries out a t test.
    PLOT                  = Plots (e.g., residuals and GANOVA ).
 
References:
    One way analysis of variance is covered in most introductory
    statistics books and more advanced books covering linear models.

    Neter, Wasserman and Kunter (1990), "Applied Linear Statistical
    Models," 3rd ed., Irwin.
 
    Searle, Casella and McCulloch (1992), "Variance Components,"
    Wiley, Chapter 3.

    Montgomery (1976), "Design and Analysis of Experiments," Second
    Edition, Wiley, chapters 3 and 4.
 
Applications:
    Analysis of Variance
 
Implementation Date:
    2023/09
 
Program 1:
    . Fixed Effects Case
    .
    . Step 1:   Create the data
    .
    read x y
    1   6.9
    1   5.4
    1   5.8
    1   4.6
    1   4.0
    2   8.3
    2   6.8
    2   7.8
    2   9.2
    2   6.5
    3   8.0
    3  10.5
    3   8.1
    3   6.9
    3   9.3
    4   5.8
    4   3.8
    4   6.1
    4   5.6
    4   6.2
    end of data
    .
    set let cross tabulate collapse
    let ymean = cross tabulate mean y x
    let ysd   = cross tabulate sd   y x
    let yn    = cross tabulate size x
    .
    . Step 2:   Run standard anova command and summary anova command
    .
    echo on
    capture 1way.out
    anova y x
    one way summary anova ymean ysd yn
    one way         anova y x
    end of capture
    echo off

Program 2:
    . Random Effects Case
    .
    . Step 1:   Create the data
    .
    capture screen on
    .
    read x y
     1     74
     1     76
     1     75
     2     68
     2     71
     2     72
     3     75
     3     77
     3     77
     4     72
     4     74
     4     73
     5     79
     5     81
     5     79
    end of data
    .
    set let cross tabulate collapse
    let ymean = cross tabulate mean y x
    let ysd   = cross tabulate sd   y x
    let yn    = cross tabulate size x
    .
    . Step 2:   Run random effects ANOVA
    .
    echo on
    capture 1way_rand.out
    set write decimals 6
    one way random effects anova y x
    one way summary random effects anova ymean ysd yn
    end of capture
    echo off

-----OR-------------------------------------------------------
 
OR
 
Name:
    OR
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Draws an Or Gate (a logical device used in electronic circuit
    diagrams).
 
Description:
    The 2 pairs of coordinates define the the (x,y) values for the
    middle back and the middle front (respectively) of the Or Gate.
 
Syntax:
    OR   <x1>   <y1>   <x2>   <y2>
    where <x1> is a number or parameter in the decimal range 0 to 100
               that specifies the x coordinate for the middle back of
               the Or Gate;
          <y1> is a number or parameter in the decimal range 0 to 100
               that specifies the y coordinate for the middle back of
               the Or Gate;
          <x2> is a number or parameter in the decimal range 0 to 100
               that specifies the x coordinate for the middle front
               of the Or Gate;
    and   <y2> is a number or parameter in the decimal range 0 to 100
               that specifies the y coordinate for the middle front of
               the Or Gate;
 
Examples:
    OR 50 50 60 50
    OR 50 50 60 60
    OR 20 20 25 20
 
Note:
    The line style (i.e., SOLID, DASH), line color, and line thickness
    are controlled by the first entry of the LINE, LINE COLOR, and
    LINE THICKNESS commands respectively.
 
Note:
    The keywords DATA and RELATIVE were added to the TRIANGLE
    command 7/1997.  These keywords are independent and can
    be used separately or together.  For example, 
    TRIANGLE DATA, TRIANGLE RELATIVE, or TRIANGLE DATA RELATIVE.
    The word DATA should come before the word RELATIVE if both
    appear.

    DATA means that the coordinates are specified in terms of
    the data units of the most recent plot rather than Dataplot
    0 to 100 screen units.

    RELATIVE means that the coordinates of the first point
    are drawn in absolute coordinates an all subsequent points
    in the figure are relative to that first point.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    AND              = Draws an and gate.
    NAND             = Draws a nand gate.
    NOR              = Draws a nor gate.
    MOVE             = Moves to a point.
    DRAW             = Draws a line.
    LINES            = Sets the line type for figures and plot lines.
    LINE THICKNESSES = Sets the line thickness for figures and plot
                       lines.
    LINE COLOR       = Sets the line colors for figures and plot lines.
    CROSS-HAIR       = Activates and reads the cross-hair.
    TEXT             = Writes a text string.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    LINE SOLID
    LINE COLOR BLACK
    LINE THICKNESS 0.2
    OR 20 20 60 60
    MOVE 20 70
    TEXT OR COORDINATES (20,20), (60,60)
 
-----ORDER STATISTICS MEANS (LET)--------------------------
 
ORDER STATISTICS MEANS
 
Name:
    ORDER STATISTICS MEANS (LET)
    ORDER STATISTICS STANDARD DEVIATIONS (LET)
    SAVAGE SCORE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate the N order statistics means or order statistic standard
    deviations from one of the following distributions:

        UNIFORM
        NORMAL
        EXPONENTIAL
 
Description:
    Given a sample of size n from a distribution, the observations
    can be ordered from smallest to largest.  The smallest value is
    called the first order statistic and the largest value is called
    the n-th order statistic.  There is an order statistic corresponding
    to each observation (so there are n order statistics in all).  Each
    of these order statistics has its own sampling distribution with
    its own statistics (e.g., mean, standard deviation).

    For the uniform distribution, the order statistic mean and standard
    deviation are (u denotes the uniform distribution)

        E(u(r:n)) = r/(n+1)    1 <= r <= n
        SD(u(r:n)) = SQRT(r*(n-r+1)/((n+1)**2*(n+2))   1 <= r <= n

    For the exponential distribution, the order statistic mean and
    standard deviation are (u denotes the exponential distribution)

        E(e(r:n))  = SUM[j=1 to r][1/(n-j+1)]       1 <= r <= n
        SD(e(r:n)) = SUM[j=1 to r][1/(n-j+1)**2]    1 <= r <= n

    A slight variation of the exponential order statistic mean is the
    Savage score.  The Savage score is obtained by subtracting 1 from
    the exponential order statistic mean.  This centers the scores at
    zero (specifically, the scores sum to zero).

    For the normal distribution, the order statistic means are computed
    numerically using the exact algorithm of Royston for values of n
    between 2 and 1,999.  For n >= 2000, the following approximation
    given by Blom is used (n denotes the normal distribution)

        E(n(r:n))  = NORCDF((r-alpha)/(n-2*alpha+1))

    where NORCDF is the cumulative distribution function of the normal
    distribution and a value of 0.375 is used for alpha.

    The standard deviation uses the following approximation

        SD(n(r:n)) = C/(NORPDF(NORCDF(r/(n+1)))**2

    where NORCDF and NORPDF are the cumulative distribution function and
    probability density function of the normal distribution, respectively,
    and

        C = r*(n-r+1)/((n+1)**2*(n+2))

    Note that this is a first order approximation.  If a more accurate
    approximation is needed, then this can be computed by a simulation
    as shown in the Program example below.

Syntax 1:
    LET <resp> = <dist> ORDER STATISTICS MEANS
                 FOR I = <start> <inc> <stop>
    where <dist> identifies the distribution from which the order
              statistics are derived (NORMAL, UNIFORM, EXPONENTIAL);
          <start> is a number or parameter that identifies the first
              row of <resp> in which the order statistics means are
              saved (typically it has a value of 1);
          <inc> is a number or parameter that identifies the row
              increment of <resp> in which the order statistics means
              are saved (typically it has a value of 1);
          <stop> is a number or parameter that identifies the last row
              of <resp> in which the order statistics means are
              saved;
    and where <resp> is a variable where the order statistics means
              are saved.
 
Syntax 2:
    LET <resp> = SAVAGE SCORE FOR I = <start> <inc> <stop>
    where <start> is a number or parameter that identifies the first
              row of <resp> in which the order statistics means are
              saved (typically it has a value of 1);
          <inc> is a number or parameter that identifies the row
              increment of <resp> in which the Savage scores are saved
              (typically it has a value of 1);
          <stop> is a number or parameter that identifies the last row
              of <resp> in which the order statistics means are
              saved;
    and where <resp> is a variable where the order statistics means
              are saved.
 
Examples:
    LET Y1 = NORMAL ORDER STATISTICS MEANS FOR I = 1 1 100
    LET Y1 = NORMAL ORDER STATISTICS STANDARD DEVIATIONS FOR I = 1 1 100

    LET Y1 = UNIFORM ORDER STATISTICS MEANS FOR I = 1 1 100
    LET Y1 = UNIFORM ORDER STATISTICS STANDARD DEVIATIONS FOR I = 1 1 100

    LET Y1 = EXPONENTIAL ORDER STATISTICS MEANS FOR I = 1 1 100
    LET Y1 = EXPONENTIAL ORDER STATISTICS STANDARD DEVIATIONS FOR I = 1 1 100

Note:
    For other distributions you can generate order statistic means and
    standard deviations via simulation.  This is demonstrated in the
    program example below.  This simulation approach can also be applied to
    other statistics.

Default:
    None
 
Synonyms:
    SD is a synonym for STANDARD DEVIATION
 
Related Commands:
    ORDER STATISTIC MEDIANS = Compute order statistic medians for a few
                              select distributions.
    MEAN                    = Compute the mean of a variable.
    STANDARD DEVIATION      = Compute the standard deviation of a variable.
 
Applications:
    Extreme value analysis
 
References:
    Royston (1982), "Algorithm AS 177: Expected Normal Order Statistics
    (Exact and Approximate)," Applied Statistics, 31, pp. 161-165.

    Blom (1958), "Statistical Estimates and Transformed Beta Variables,"
    Wiley.

    Omondi (2014), "Order Statistics of Uniform, Logistic and Exponential
    Distributions," Masters Thesis for University Of Nairobi, College of
    Biological and Physical Sciences, School of Mathematics Chapters
    3 and 5.

    https://stats.stackexchange.com/questions/394960/
    variance-of-normal-order-statistics

    Jenny A. Baglivo (2005), "Mathematica laboratories for mathematical
    statistics: Emphasizing simulation and computer intensive methods."

    Higgins (2004), "Introduction to Modern Nonparametric Statisics,"
    Duxbury Press, pp. 50-51.

Implementation Date:
    2022/04
    2023/05: Add support for SAVAGE SCORES
 
Program:
    . Step 1:   Uniform
    .
    let n = 100
    .
    let ymed1  = uniform order statistic medians for i = 1 1 n
    let ymean1 = uniform order statistic means   for i = 1 1 n
    let ysd1   = uniform order statistic sd      for i = 1 1 n
    .
    . Step 2:   Exponential
    .
    let ymed3  = exponential order statistic medians for i = 1 1 n
    let ymean3 = exponential order statistic means   for i = 1 1 n
    let ysd3   = exponential order statistic sd      for i = 1 1 n
    .
    . Step 3:   Normal
    .
    let ymed2  = normal order statistic medians for i = 1 1 n
    let ymean2 = normal order statistic means   for i = 1 1 n
    let ysd2   = normal order statistic sd      for i = 1 1 n
    .
    .           Now do simulation
    .
    let nsamp = 10000
    let ynorm = normal rand numbers for i = 1 1 n
    let ynorm = sort ynorm
    let yunif = uniform rand numbers for i = 1 1 n
    let yunif = sort yunif
    let yexpo = exponential rand numbers for i = 1 1 n
    let yexpo = sort yexpo
    let xseq  = sequence 1 1 10
    .
    feedback off
    loop for k = 2 1 nsamp
        let ynormt = normal rand numbers for i = 1 1 n
        let ynormt = sort ynormt
        let yunift = uniform rand numbers for i = 1 1 n
        let yunift = sort yunift
        let yexpot = exponential rand numbers for i = 1 1 n
        let yexpot = sort yexpot
        let xseqt  = sequence 1 1 10
        let ynorm = combine ynorm ynormt
        let yunif = combine yunif yunift
        let yexpo = combine yexpo yexpot
        let xseq  = combine xseq  xseqt
    end of loop
    feedback on
    .
    set let cross tabulate collapse
    .
    let ymed1b   = cross tabulate median yunif xseq
    let ymean1b  = cross tabulate mean   yunif xseq
    let ysd1b    = cross tabulate sd     yunif xseq
    .
    let ymed3b   = cross tabulate median yexpo xseq
    let ymean3b  = cross tabulate median yexpo xseq
    let ysd3b    = cross tabulate sd     yexpo xseq
    .
    let ymed2b   = cross tabulate median ynorm xseq
    let ymean2b  = cross tabulate mean ynorm xseq
    let ysd2b = cross tabulate sd ynorm xseq
    .
    print "Uniform"
    print ymed1 ymean1 ysd1 ymed1b ymean1b ysd1b
    print " "
    print "Exponential"
    print ymed3 ymean3 ysd3 ymed3b ymean3b ysd3b
    print " "
    print "Normal"
    print ymed2 ymean2 ysd2 ymed2b ymean2b ysd2b
 
-----ORDER STATISTICS MEDIANS (LET)--------------------------
 
ORDER STATISTICS MEDIANS
 
Name:
    ORDER STATISTICS MEDIANS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate the N order statistics medians from one of the following
    distributions:

        NORMAL
        UNIFORM
        HALF NORMAL
        EV1 (or GUMBEL)
        EV2 (or FRECHET)
        WEIBULL
        EXPONENTIAL
 
Description:
    Given a sample of size N from a distribution, the observations
    can be ordered from smallest to largest.  The smallest value is
    called the first order statistic and the largest value is called
    the n-th order statistic.  There is an order statistic corresponding
    to each observation (so there are N order statistics in all).  Each
    of these order statistics has its own sampling distribution with
    its own statistics (e.g., mean, standard deviation).  The order
    statistics medians command generates the medians of each of the N
    order statistics.
 
    Order statistics are commonly used in extreme value analysis.  In
    particular, the first (i.e., minimum) and n-th (i.e., maximum)
    order statistics are of interest.

    The order statistic medians (Filliben 1975) can be approximated by:

        N(i) = G(U(i))

    where U(i) are the uniform order statistic medians (defined below) and
    G is the percent point function for the desired distribution.

    The uniform order statistic medians are defined as:

        m(i) = 1 - m(n)                  for i = 1
        m(i) = (i - 0.3175)/(n + 0.365)  for i = 2, 3, ..., n-1
        m(i) = 0.5**(1/n)                for i = n

    Dataplot uses order statistic medians in the generation of probability
    plots.  Specifically, the probability plot is formed by:

        Vertical axis:   Ordered response values
        Horizontal axis: Order statistic medians for the specified
                         distribution

Syntax:
    LET <resp> = <dist> ORDER STATISTICS MEDIANS
                 FOR I = <start> <inc> <stop>
    where <dist> identifies the distribution from which the order
              statistics are derived (NORMAL, HALF NORMAL, UNIFORM,
              EV1, EV2, WEIBULL, EXPONENTIAL);
          <start> is a number or parameter that identifies the first
              row of <resp> in which the order statistics medians are
              saved (typically it has a value of 1);
          <inc> is a number or parameter that identifies the row
              increment of <resp> in which the order statistics medians
              are saved (typically it has a value of 1);
          <stop> is a number or parameter that identifies the last row
              of <resp> in which the order statistics medians are
              saved;
    and where <resp> is a variable where the order statistics medians
              are saved.
 
Examples:
    LET Y1 = NORMAL ORDER STATISTICS MEDIANS FOR I = 1 1 100
    LET Y2 = NORMAL ORDER STATISTICS MEDIANS FOR I = 1 1 1000
    LET Y1 = HALF NORMAL ORDER STATISTICS MEDIANS FOR I = 1 1 100
    LET Y1 = UNIFORM ORDER STATISTICS MEDIANS FOR I = 1 1 100
    LET Y1 = EV1 ORDER STATISTICS MEDIANS FOR I = 1 1 100

    LET GAMMA = 3.2
    LET Y1 = WEIBULL ORDER STATISTICS MEDIANS FOR I = 1 1 100

    LET GAMMA = 2
    LET Y1 = EV2 ORDER STATISTICS MEDIANS FOR I = 1 1 100
 
Note:
    For the Weibull and Frechet distributions, you need to specify the
    value of the shape parameter.  To do this, enter the following
    command before ORDER STATISTIC MEDIAN command

        LET GAMMA = <value>
 
Note:
    You can use the percent point function to compute order statistic
    medians for distributions not supported by the ORDER STATISTIC MEDIANS
    command.  For example, to obtain the order statistic medians for the
    gamma distribution, enter

        LET GAMMA = 1.8
        LET YTEMP = UNIFORM ORDER STATISTIC MEDIANS FOR I = 1 1 100
        LET YOSMED = GAMMPPF(YTEMP,GAMMA)

Default:
    None
 
Synonyms:
    FRECHET for EV1
    GUMBEL for EV2
 
Related Commands:
    ORDER STATISTIC MEANS  = Compute order statistic means for a few
                             select distributions.
    MEDIAN                 = Compute the median of a variable.
    MEAN                   = Compute the mean of a variable.
    RANDOM NUMBERS         = Generate a sequence of random numbers.
    NORMAL PLOT            = Generate a normal plot.
    WEIBULL PLOT           = Generate a Weibull plot.
    PROBABILITY PLOT       = Generates a probability plot.
    PPCC PLOT              = Generates a probability plot correlation
                             coefficient plot.
 
Applications:
    Extreme value analysis
 
References:
    Filliben (1975), "The Probability Plot Correlation Coefficient Test
    for Normality," Technometrics, pp. 111-117.

Implementation Date:
    1991/10: Original implementation of uniform, normal and half-normal
             distributions
    1993/05: Added EV1 (Gumbel), EV2 (Frechet) and Weibull distributions
    2022/04: Added exponential distribution
 
Program:
    SKIP 25
    READ ZARR13.DAT Y
    LET N = SIZE Y
    LET Y = SORT Y
    LET X = ORDER STATISTIC MEDIANS FOR I = 1 1 N
    .
    TITLE CASE ASIS
    LABEL CASE ASIS
    TITLE Normal Probability Plot for ZARR13.DAT
    Y1LABEL Sorted Data
    X1LABEL Normal Order Statistic Medians
    .
    PLOT Y X
 
-----ORD PLOT--------------------------------------
 
ORD PLOT
 
Name:
    ORD PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates an Ord plot.

Description:
    An Ord plot can be used to distinguish whether a
    data set follows a Poisson, binomial, negative binomial,
    or logarithmic series distribution.
 
    If x and n(x) denote the class value and the corresponding
    class frequency, then the Ord plot is a plot of

       x*n(x)/n(x-1) versus x

    If this plot is approximately linear, then it can help
    distinguish between these four distributions based on
    the following table:

                       Slope         Intercept      Parameter
    Distribution         a              b           Estimate
    =========================================================
    Poisson              0              +           lambda = a
    Binomial             -              +           p = b/(b-1)
    Negative Binomial    +              +           p =1-b
    Logarithmic Series   +              -           theta = -a

    The slope and intercept can be determined by fitting
    a line to the plotted points.  We follow the suggestion
    of Friendly of using the weights

       w(x) = SQRT(n(x) - 1)

    This compensates for the fact that classes with small frequency
    have large variance.

    The primary disadvantage of this plot is that a discrepant
    frequency affects the points for both x and x+1.  For this
    reason, the Ord plot does not have good resistance properties.

Syntax 1:
    ORD PLOT <y>       <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where you have raw data.
    Dataplot will automatically create the frequency table.

Syntax 2:
    ORD PLOT <y> <x>     <SUBSET/EXCEPT/FOR qualification>
    where <y> is a variable containing frequencies;
          <x> is a variable containing the class value;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    ORD PLOT Y
    ORD PLOT Y X
 
Note:
    The appearance of the plot can be controlled with
    the LINE and CHARACTER commands.  The first setting
    is for the plot points and the second setting is for
    the fitted line.   This is demonstrated with the sample
    plot below.

Note:
    The following internal parameters are saved by this plot:

        PPA0      - the intercept of the fitted line
        PPA1      - the slope of the fitted line
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POSSION PLOT        = Generates a Poisson plot.
    PROBABILITY PLOT    = Generates a probability plot.
    PPCC PLOT           = Generates a ppcc plot.
    KS PLOT             = Generates a Kolmogorov-Smirnov (or
                          chi-square) plot.
    HISTOGRAM           = Generates a histogram.
    LINES               = Sets the type for plot lines.
    CHARACTER           = Sets the type for plot characters.
 
References:
    Friendly (2000), "Visualizing Categorical Data", SAS Publishing,
    Cary, NC, pp. 49-56.

Applications:
    Distributional Modeling
 
Implementation Date:
    2007/5
 
Program:
    . Data from p. 47 of Friendly
    read x y
    0  109
    1   65
    2   22
    3    3
    4    1
    end of data
    .
    title case asis
    title offset 2
    label case asis
    title Ord Plot
    y1label Frequency Ratio
    x1label x
    .
    tic offset units screen
    tic offset 3 3
    xlimits 0 4
    major xtic mark number 5
    minor xtic mark number 0
    .
    character x blank
    line blank dotted
    .
    ord plot y x

-----ORIENTATION-------------------------------------------------------
 
ORIENTATION
 
Name:
    ORIENTATION
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the page orientation for subsequent plots.
 
Description:
    Many laser printers and penplottters are able to produce plots in
    either a landscape or portrait orientation.  In addition, many
    plotters have a "large" size.  The ORIENTATION command will take
    advantage of these different page modes on devices that support
    them.  On devices that do not (e.g., most terminal screens), it
    tries to emulate it.  The POSTER mode is only supported on a few
    penplotters (it is the same as FULL on other devices).
 
Syntax:
    ORIENTATION <LANDSCAPE/FULL/PORTRAIT/POSTER>
    where LANDSCAPE specifies a landscape orientation (11 by 8.5),
          PORTRAIT specifies a portrait orientation (8.5 by 11), FULL
          specifies the full device area, and POSTER sets a poster size
          (30 by 30).
 
Examples:
    ORIENTATION LANDSCAPE
    ORIENTATION PORTRAIT
    ORIENTATION POSTER
 
Note:
    The Postscript, QMS, Zeta, Calcomp, and X11 devices support explicit
    landscape and portrait modes.  Other devices emulate them by
    maintaining the aspect ratio and using the full screen size in one
    direction and centering the plot in the other direction.  However,
    the plot is not rotated on the device.
 
Note:
    This command only applies to devices that are active when the
    command is entered.  That is, enter the commands in the following
    order:
       DEVICE 2 POSTSCRIPT
       ORIENTATION PORTRAIT
    If the ORIENTATION command is entered before the DEVICE command, it
    has no effect on that device.
 
    The one exception to this is the X11 driver.  It only honors the
    orientation if the ORIENTATION is entered before the X11 command.
    In order to activate both X11 and a Postscript device, enter the
    commands in the following order:
       DEVICE 2 POSTSCRIPT
       ORIENTATION PORTRAIT
       DEVICE 1 X11
 
Note:
    The orientation can be toggled as many times as desired in a given
    DATAPLOT session.
 
Note:
    Postscript output sent to DEVICE 3 (which only contains the most
    recent plot) does not honor the ORIENTATION command.  It always
    prints in landscape mode.
 
Default:
    Landscape
 
Synonyms:
    None
 
Related Commands:
    PLOT         = Generates a data or function plot.
    ERASE        = Start a new page on the device.
 
Applications:
    Presentation graphics
 
Implementation Date:
    89/2
 
Program:
    XX
 
-----ORTHOGNAL DISTANCE FIT---------------------------------------------
 
ORTHOGONAL DISTANCE FIT
 
Name:
    ORTHOGONAL DISTANCE FIT
 
Type:
    Analysis Command
 
Purpose:
    Estimate the parameters for an orthognal distance fit.  Note that
    the orthogonal distance fit is also commonly referred to as 
    errors in variables fitting.
 
Description:
    The ordinary least squares model is:

       y = f(x;beta)

    where y is a response variable, f is a linear or non-linear
    function, x is a list of one or more independent (or factor)
    variables, and beta is a list of parameters in the function
    to be estimated.  The least squares fit generates estimates for
    beta and predicted and residual values for y.  You can also
    specify weights for the response variable y.  Weighting is
    typically applied to give more weight to observations that
    are known to more precise.

    In ordinary least squares fitting, the independent variables are
    assumed to be fixed (i.e., there is no measurement error).  However,
    in many measurement processes, there can be significant error in
    the independent variables as well as the dependent variables.
    This is commonly referred to as the measurement error model or
    the errors in variables problem.

    Orthogonal distance fitting provides one method for fitting these
    error in variables model.  Dataplot supports orthogonal distance
    fitting using the ODRPACK library (see the References section
    below).
 
    A mathematical description of orthogonal distance fitting is
    beyond the scope of this help file.  We have placed a Postscript
    copy of the ODRPACK User's Guide on the Dataplot web site (see
    the References section below) for those who are interested in
    the mathematical details of orthogonal distance regression.
    This help file will concentrate on applying orthogonal distance
    fitting within Dataplot.

    As mentioned above, ordinary least squares allows you to specify
    weights for the response variable and starting values for the
    parameters.  It returns estimates for the model parameters (beta)
    and predicted and residual values for the response variable.

    For orthogonal distance fitting, you can additionally specify
    the following:

       1) You can specify which observations in the independent
          variables (also called the design matrix) are to be
          estimated and which are to remain fixed.

       2) You can specify weights for the design matrix.

       3) You can specify starting values for the estimated errors
          in the design matrix.

    In addition to the estimated (i.e., predicted) response variable,
    orthogonal distance fitting returns an estimate for the design
    matrix.  More specifically, it returns the residuals, DELTA,
    which are added to the original design matrix to obtain the
    estimated (i.e., predicted) design matrix.

    These topics are discussed in more detail in the various "Note:"
    sections below.

    Although errors in variables models were the primary motivation
    for incorporating ODRPACK into Dataplot, ODRPACK provides the
    following 2 additional capabilities:

      1) Implicit models can be fit.

      2) Multiple response variables can be fit for both linear
         and nonlinear models.

   These topics are discussed in "Note:" sections below.

Syntax 1:
    ORTHOGONAL DISTANCE FIT <y>  =  <f>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <f> is:
               1) any general FORTRAN-like expression; or
               2) any function name that the user has already created
                  via the LET FUNCTION command;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is appropriate for applying orthogonal distance
    fitting to linear, polynomial, multi-linear, and non-linear models.
 
Syntax 2:
    ORTHOGONAL DISTANCE FIT <f>  <SUBSET/EXCEPT/FOR qualification>
    where <f> is:
               1) any general FORTRAN-like expression; or
               2) any function name that the user has already created
                  via the LET FUNCTION command;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is appropriate for applying orthogonal distance
    fitting to implicit models.
 
Syntax 3:
    ORTHOGONAL DISTANCE FIT <y1>... <yk>  =  <f1> ... <fk> 
                                  <SUBSET/EXCEPT/FOR qualification>
    where <y1>... <yk> is a list of 2 to 5 response (= dependent)
              variables;
          <f1> ... <fk> is a list of 2 to 5 function names (must equal
              the number of response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used when there are multiple response variables.
    
    NOTE: This syntax is still being tested.
 
Examples:
    ORTHOGONAL DISTANCE FIT Y = A0 + A1*X1
    ORTHOGONAL DISTANCE FIT Y = A0 + A1*X1 + A2*X1**2
    ORTHOGONAL DISTANCE FIT Y = A0 + A1*X1 + A2*X2
    ORTHOGONAL DISTANCE FIT Y = A0 + A1*X1  SUBSET X1 > 1
    ORTHOGONAL DISTANCE FIT Y = A+B*EXP(-C*X)
 
Note:
    As with least squares nonlinear fitting, providing good
    starting values for the model parameters can be important.
    In Dataplot, the LET command is used to provide starting values.
    This is demonstrated in the example programs below.

    Starting values are often determined from previous fits to
    similar data.  If this is not available, you may need to do
    some preliminary analysis to determine starting values.  In
    Dataplot, the PRE-FIT command can often be useful for this
    purpose.

Note:
    If there is a single response variable, you can specify weights
    for the response variable using the command

        WEIGHTS  <varname>
    
    where <varname> is the name of the variable containing the
    weights.

    See the Note below regarding multi-response fits for a discussion
    of how weights are specified for multi-response fits.

Note:
    You can specify which observations in the design matrix are
    to treated as fixed (no measurement error) and which are to
    be estimated.

    A common case is to specify which columns of the design matrix
    are to be fixed or estimated.  For example, suppose there
    are three independent variables where the first and third are to
    be estimated while the second is fixed, then enter the commands

        LET YERR = DATA 1 0 1
        ORTHOGONAL DISTANCE ERROR YERR

    That is, a single variable (it does not have to be called YERR)
    is specified and the number of rows must be equal to the number
    of columns in the design matrix.  A zero indicates that the
    corresponding column is considered fixed and a non-zero (here,
    that means the abosolute value is greater than 0.5) means it
    it will be estimated.  Note that order is important in the above
    command.  That is, Dataplot creates a list of independent variables
    when it parses the function name in the ORTHOGONAL DISTANCE FIT
    command.  This parsing is left to right, so the order of the
    values in the YERR variable is relative to the variable names
    as they are first encountered (left to right) in the function.

    You can also specify which are fixed at the observation level.
    For example, suppose there are two independent variables with
    eight observations each.  For the first variable, we want the
    first two observatons to be fixed and for the second variable
    we want the first four observations to be fixed.  We would
    enter the commands

       LET YERR1 = DATA 0 0 1 1 1 1 1 1
       LET YERR2 = DATA 0 0 0 0 1 1 1 1
       ORTHOGONAL DISTANCE ERROR YERR1 YERR2

    As for the one variable case, order is important in the command.
    YERR1 applies to the first variable name encountered in the
    function (left to right), YERR2 corresponds to the second
    variable name encountered, and so on.

    The default is to assume all values in the design matrix are
    to be estimated.  In this case, the ORTHOGONAL DISTANCE ERROR
    command does not need to be entered.  If you entered a previous
    ORTHOGONAL DISTANCE ERROR command, you can reset the default
    by entering

       ORTHOGONAL DISTANCE ERROR

    The general idea is to "fix" values in the independent variable
    that are known to be precise and to estimate values that have
    significant measurement errors.  In most cases, sufficient
    precision will be determined at the variable level.  However,
    there may be cases where a measurement for a given independent
    variable is known to be precise within a given range, but
    it may be error prone outside of that range.

Note:
    You can specify weights for the observations in the design
    matrix.

    You can specify weights by columns of the design matrix.  For
    example, suppose there are two independent variables where the
    first independent variable will be assigned a weight of 3 and
    the second independent variable will be assigned a weight of 5.
    You can enter the commands

        LET RHO = DATA 3 5
        ORTHOGONAL DISTANCE DELTA WEIGHTS RHO

    That is, a single variable (it does not have to be called YERR)
    is specified and the number of rows must be equal to the number
    of columns in the design matrix.  A zero indicates that the
    corresponding column is considered fixed and a non-zero (here,
    that means the abosolute value is greater than 0.5) means it
    it will be estimated.  Note that order is important in the above
    command.  That is, Dataplot creates a list of independent variables
    when it parses the function name in the ORTHOGONAL DISTANCE FIT
    command.  This parsing is left to right, so the order of the
    values in the RHO variable is relative to the variable names
    as they are first encountered (left to right) in the function.

    You can also specify weights at the observation level.
    For example, suppose there are two independent variables with
    eight observations each.  The following shows an example of
    specifying individual weights.

       LET RHO1 = DATA 1 1 2 2 2 2 1 1
       LET RHO2 = DATA 1 1 1 1 2 2 2 2
       ORTHOGONAL DISTANCE DELTA WEIGHTS RHO1 RHO2

    As for the one variable case, order is important in the command.
    RHO1 applies to the first variable name encountered in the
    function (left to right), RHO2 corresponds to the second
    variable name encountered, and so on.

    The default is the unweighted case.  That is, all points in
    the design matrix will have a weight of 1.  Note that if
    an observation or column has been designated as fixed, the
    weight is ignored.  If you entered a previous
    ORTHOGONAL DISTANCE DELTA WEIGHT command, you can reset the
    default by entering

       ORTHOGONAL DISTANCE DELTA WEIGHTS

    The general idea is to provide greater weight to independent
    variables or observations that are known to be more precise.

Note:
    You can specify starting values for the deltas of the observations
    in the design matrix.  Remember that the deltas are essentially
    the residuals for the design matrix (i.e., they are added to the
    values in the design matrix to obtain the predicted value of the
    design matrix).  By default, the deltas are set to zero and in most
    cases this is adequate.

    You can specify starting values by columns of the design matrix.
    For example, suppose there are two independent variables where the
    first independent variable will be assigned a starting value of 2
    and the second independent variable will be assigned a starting
    value of 7.  You can enter the commands

        LET DEL = DATA 2 7
        ORTHOGONAL DISTANCE DELTA DEL

    That is, a single variable (it does not have to be called DEL)
    is specified and the number of rows must be equal to the number
    of columns in the design matrix.  A zero indicates that the
    corresponding column is considered fixed and a non-zero (here,
    that means the abosolute value is greater than 0.5) means it
    it will be estimated.  Note that order is important in the above
    command.  That is, Dataplot creates a list of independent variables
    when it parses the function name in the ORTHOGONAL DISTANCE FIT
    command.  This parsing is left to right, so the order of the
    values in the RHO variable is relative to the variable names
    as they are first encountered (left to right) in the function.

    You can also specify starting values at the observation level.
    For example, suppose there are two independent variables with
    eight observations each.  The following shows an example of
    specifying individual weights.

       LET DEL1 = DATA 0.5 0.5 0.5 0.5  2.0 2.0 2.0 2.0
       LET DEL2 = DATA 0 0 0 0 1 1 1 1
       ORTHOGONAL DISTANCE DELTA DEL1 DEL2

    As for the one variable case, order is important in the command.
    DEL1 applies to the first variable name encountered in the
    function (left to right), DEL2 corresponds to the second
    variable name encountered, and so on.

Note:
    You can define the maximum number of iterations for the fit
    with the following command (the default is 50).

       FIT ITERATIONS <value>

    You can define a number of convergence critierion.  By default,
    these are chosen automatically by ODRPACK and we recommend that
    these default values be used unless you have a good reason for
    changing them.  See the ODRPACK User's Guide for more information
    on these parameters.

       SET ORTHOGONAL DISTANCE TRUST REGION RADIUS <value> - defines
           the trust region radius

       SET ORTHOGONAL DISTANCE STOP TOLERANCE <value> - defines the
           stop tolerance for the sum of squares convergence

       SET ORTHOGONAL DISTANCE PARAMETER TOLERANCE <value> - defines
           the stopping tolerance for parameter convergence

Note:
    ODRPACK allows several levels of output.  Dataplot allows some
    control over this with the following command:

       SET ORTHOGONAL DISTANCE PRINT OPTION <SHORT/INTERMEDIATE/FULL>

    The default is INTERMEDIATE.

    In addition, Dataplot writes the following information to files
    after an orthogonal distance fit:

    1) dpst1f.dat - contains the final parameter estimates and their
       standard deviaitions.

    2) dpst2f.dat - contains the parameter variance-covariance matrix.
       Written using a 20(E15,7,1X) format.

    3) dpst3f.dat - the predicted values for the design matrix
       (i.e., "x + delta").  Written using a 20(E15.7,1X) format.

    4) dpst4f.dat - the deltas (i.e., the residuals for the design
       matrix).  Written using a 20(E15.7,1X) format.

    In addition, the internal parameters RESSD and RESDF will contain
    the residual standard deviation and the residual degrees of
    freedom for the fitted model.

Note:
    Dataplot currently imposes the following limits on the size of
    problem that can be handled with the ORTHOGONAL DISTANCE FIT
    command.

    1) The maximum number of observations is one half the maximum row
       size.  That is, the default version of Dataplot allows a
       maximum of 20,000 rows for your data.  The ORTHOGONAL DISTANCE
       FIT then allows a maximum number of observations of 10,000.

       You can redimension the Dataplot data space to have fewer rows
       and more columns.  The limit on the number of observations for
       the ORTHOGONAL DISTANCE FIT command is relative to the
       allowable maximum, not the number of rows you may have set
       using the DIMENSION command.

    2) The maximum number of independent variables in your function
       is 20.  The maximum number of parameters in the model is 100.
       The maximum number of characters in the function is 1,000.

    3) ODRPACK requires the following number of words of scratch
       space:

           18 + 11*NP + NP**2 + M + M**2 + 4*N*NQ + 6*N*M +
           2*N*NQ*M + 2*N*NQ*NP + NQ**2 5*NQ + NQ*(NP+M) + (N*1)*NQ

       where NP is the number of parameters in the model, M is the
       number of independent variables, NQ is the number of
       response variables, and N is the number of observations.

       Dataplot provides 23*MAXOBV words of scratch space.  An error
       message is printed if Dataplot does not have enough storage.

Note:
    Although Dataplot uses the double precision version of
    ODRPACK, Dataplot function evaluation returns single precision
    results.  For this reason, Dataplot uses the single precision
    convergence critierion.

    On most platforms, Dataplot can be compiled in a mode where
    single precision is treated as double precision (so Dataplot
    function evaluation returns double precision results).  If
    you desire higher precision results from the orthogonal distance
    regression, you should install a double precision version of
    Dataplot on your system.  Contact Alan Heckert for additional
    information.

    For NIST users, we maintain a double precision version on the
    Sun that can be cross-mounted from the /itl/apps directory.  If
    you have cross-mounted this directory, enter

        dataplot.dp

    to run the double precision version.

Note:
    An explicit function is defined as:

      y = f(xi;beta)

    An implicit function is defined as:

      f(xi,y) = 0

    The ODRPACK software can fit implicit models and Dataplot
    supports this capability.  See Syntax 2 above and the
    Program 2 example below.

    Basically, the response variable is omitted.  The other options
    described above work the same for the implicit model as for the
    explicit model.

Note:
    ODRPACK allows models that have multiple response variables.
    We are currently working to make this capability available
    within Dataplot.  This is still in the development/testing phase.

    Syntax 3 shows the basic syntax for the multi-response case.
    The primary point is that a function is specified for each
    response variable (you must give the name of a previously
    defined function, not a functional expression).

    The other difference is that you can specify a weight variable
    for each response variable.  Use the command

        ORTHOGONAL DISTANCE Y WEIGHTS <var-list>

    where <var-list> is a list of variables that define the weights
    for each of the response variables (i.e., if there are 3 response
    variables, there should be a list of 3 weight variables).

    Note that for the single response variable case, you can specify
    the weights either with this command or with the WEIGHTS command.
    If both are given, the ORTHOGONAL DISTANCE Y WEIGHTS command
    takes precedence.

Note:
    ODRPACK accepts the model parameters as an array of ordered
    values, not by parameter name.  Note that Dataplot passes the
    parameters in the order that they are encountered in the function
    (from left to right).  Keep this in mind when interpreting the
    ODRPACK output.

Note:
    The ODRPACK library provides for considerable flexibility in
    performing the orthogonal distance fit.  It was designed to
    support anything from the simplest fits to the most complex
    fits.  Although the above notes documented a significant number
    of options, there are additional options that Dataplot does not
    support.

    1) ODRPACK allows the user to specify both the function to be
       fit and analytic Jacobians (relative to the parameters and
       to the deltas).

       In Dataplot, you are limited to functions that can be
       computed using the LET FUNCTION command.  Although this
       provides a relatively rich set of functions, you may well
       have functions that cannot be stated using the Dataplot
       LET FUNCTION command.

       Dataplot does not currently support analytic Jacobians.
       It specifies that ODRPACK should compute the partial
       derivatives using a central finite difference method.  ODRPACK
       also allows the use of a forward finite difference method for
       computing the partial derivatives (the forward finite difference
       method is faster, but somewhat less accurate).  Dataplot
       always uses the central difference method.

    2) For the multi-response case, the weights for both the
       response variable and the independent variables allow
       a covariance structure to be implemented for the weight
       function.  This is not currently supported in Dataplot.
       See the ODRPACK User's Guide for details.

    3) ODRPACK allows the scaling to be specified for both the
       parameters and the deltas (i.e., the residuals of the
       independent variables).  Dataplot utilizes the default
       ODRPACK scaling algorithms.

    4) ODRPACK allows the user to specify the number of reliable
       decimal digits in the function evaluations.  Dataplot
       utilizes the default ODRPACK value.

    5) ODRPACK allows relative step sizes to be specified relative
       to both the parameters and the deltas when computing partial
       derivatives using the forward finite difference method.
       Dataplot utilizes the default ODRPACK values.

    6) ODRPACK allows constraints to be coded for the model
       parameters.  Basically, ODRPACK will try to take a step
       closer to the previous value if an out of range value is
       encountered.  Dataplot does not support the specification of
       constraints in the initial implementation, but this is
       being considered for future development.

    If you need to run an orthogonal distance fit that is beyond
    Dataplot's capabilities, we recommend you download the ODRPACK
    Fortran source and use ODRPACK directly.

Note:
    Dataplot uses version 2.01 of ODRPACK.  This is the current
    (and apparently final) version of ODRPACK.

Default:
    None
 
Synonyms:
    The following are synonyms for ORTHOGONAL DISTANCE FIT:

        ORTHOGONAL DISTANCE REGRESSION
        ERRORS IN VARIABLES FIT
        ERRORS IN VARIABLES REGRESSION
 
Related Commands:
    FIT ITERATIONS     = Sets the maximum number of iterations for the
                         fit and orthogonal distance fit commands.
    WEIGHTS            = Sets the weights for the dependent variable for
                         the fit and orthogonal distance fit commands.
    PRED               = A variable where predicted values are stored.
    RES                = A variable where residuals are stored.
    RESSD              = A parameter where the residual standard
                         deviation is stored.
    RESDF              = A parameter where the residual degrees of
                         freedom is stored.
    EXACT RATIONAL FIT = Carries out an exact rational fit.
    PRE-FIT            = Carries out a least squares pre-fit.
    SPLINE FIT         = Carries out a spline fit.
    PLOT               = Generates a data/function plot.
 
References:
    "Algorithm 676: ODRPACK: Software for Weighted Orthogonal Distance
    Regression", Paul Boggs, Janet Donaldson, Richard Byrd, and
    Robert Schnabel, ACM Transactions on Mathematical Software,
    December, 1989, Volume 15, Number 4, pp. 348-364.
 
    "User's Reference Guide for ODRPACK Version 2.01: Software for
    Weighted Orthogonal Distance Regression", Paul Boggs, Janet
    Donaldson, Richard Byrd, and Robert Schnabel, NIST-IR 89-4103,
    Revised).

    Note: for those interested in the mathematics of orhogonal
          distance regression, we have put a Postscript copy of the
          ODRPACK User's Guide on the Dataplot web site at:

    http://www.itl.nist.gov/div898/software/dataplot/refman1/odrpack_guide.ps

Applications:
    Fitting where there can be significiant error in the independent
    variables
 
Implementation Date:
    2001/4
 
Program 1:
    .  FILE: FULLODR1.DP
    .  Performs an orthogonal distance analysis of example from
    .  Wayne Fuller's book (see header of FULLODR1.DAT for reference).
    .  This is example 1 from version 2.01 of ODRPACK User's Guide.
    .
    skip 25
    read fullodr1.dat x y
    let n = size y
    .
    let b1 = 1500.0
    let b2 = -50.0
    let b3 = -0.1
    let function f = b1 + b2*(exp(b3*x) - 1)**2
    .
    let yerr = 0 for i = 1 1 n
    let yerr = 1 subset x = 1 to 99
    .
    orthogonal distance error yerr
    .
    orthogonal distance fit y = f
 
Program 2:
    .  FILE: FULLODR2.DP
    .  Performs an orthogonal distance analysis of example from
    .  Wayne Fuller's book (see header of FULLODR2.DAT for reference).
    .  This is example 2 from version 2.01 of ODRPACK User's Guide.
    .
    .  Note that this is an example of fitting an implicit function.
    .
    skip 25
    read fullodr2.dat v h
    let n = size v
    .
    let b1 = -1.0
    let b2 = -3.0
    let b3 = 0.09
    let b4 = 0.02
    let b4 = 0.08
    let function f1 = b3*(v-b1)**2
    let function f2 = 2*b4*(v-b1)*(h-b2)
    let function f3 = b5*(h-b2)**2
    let function f = f1 + f2 + f3 - 1.0
    .
    orthogonal distance fit f

Program 3:
    .  FILE: DRAPS521.DP
    .  Performs an orthogonal distance analysis of Draper/Smith
    .  data set (p. 521 of 2nd. ed.).  From version 1.3 of ODRPACK
    .  User's Guide.
    .
    skip 25
    read draps521.dat y x1 x2
    .
    let a1 = 0.01155
    let a2 = 5000.0
    let function f = exp(-a1*x1*exp(-a2*(1/x2  - 1/620)))
    .
    let rho = data 5.0 3.0
    let yerr = data 1 0
    .
    orthogonal distance error yerr
    orthogonal distance delta weights rho
    .
    orthogonal distance fit y = f

Program 4:
    .  FILE: DRAPS518.DP
    .  Performs an orthogonal distance analysis of Draper/Smith
    .  data set (p. 518 of 2nd. ed.).  From ODRPACK ACM article.
    .
    skip 25
    read draps518.dat y x
    .
    let b1 = 4
    let b2 = 5
    let b3 = 200
    let function f = B1*10**(b2*x/(b3+x))
    .
    let yerr = data 1
    .
    orthogonal distance error yerr
    .
    orthogonal distance fit y = f

-----OPERATOR-------------------------------------------------------
 
 
Note:
    ***** This command is not currently operational *****
OPERATOR
 
Name:
    OPERATOR
 
Type:
    Support Command
 
Purpose:
    Sends a message to the operator at the main console of the
    host computer.
 
Syntax:
    OPERATOR   <message>
    where <message> is the desired message.
 
Examples:
    OPERATOR WHEN WILL CALCOMP BE READY?
    OPERATOR PLEASE USE LARGE PAPER FOR VERSATEC
    OPERATOR PLEASE USE NYLON PEN FOR ZETA
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    HELP    = Lists portions of the help file.
    NEWS    = Lists the news file.
    BUGS    = Lists the bugs file.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----OPTIMIZE (LET)-------------------------------------------------
 
OPTIMIZE
 
Name:
    OPTIMIZE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Determine the minimum of a function.
 
Description:
    Function minimization/maximization has many applications
    in mathematics and statistics.

    Minimization can be either unconstrained or constrained.
    Constrained minimization limits the domain of the variables
    that define the function.  The OPTIMIZE command currently
    only supports unconstrained minimization.

    Finding the maximum of a function is equivalent to finding
    the minimum of the negative of a function.  Therefore, the
    OPTIMIZE command can be used to find the maximum of a 
    function as well (simply take the negative of the relevant
    function).

    Multivariate functions may have many local minimum and
    maximum.  Although the goal is typically to find the
    global minimum (or maximum), most numerical techniques
    may in fact find a local minimum (or maximum) point.
    If something is known about the function, specifying
    better starting values can sometimes alleviate this
    problem.  Specifying starting values is discussed below.
    There are optimization techniques, such as simulated 
    annealing, that attempt to avoid the problem of finding
    a local rather than a global minimum.  Dataplot does not
    currently support any of these global optimization
    techniques.

Syntax 1:
    LET <par> = OPTIMIZE <func>  WRT <var>
                FOR <var> = <lower> <upper>
    where <func> is the name of a previously defined function or a
              functional expression;
          <var> is the variable for which the optimization is being
              computed;
          <lower> is a number or parameter defining the lower limit
              for finding the minimum;
          <upper> is a number or parameter defining the upper limit
              for finding roots;
          <par> is a parameter where the value of <var> at the
              minimum is stored.
 
     This syntax minimizes a univariate function.

Syntax 2:
    LET <var> = OPTIMIZE <func>  WRT <var-list>
    where <func> is the name of a previously defined function or a
              functional expression;
          <var-list> is a list of variables for which the
              minimization is being computed;
          <var> is a variable where the values of <var-list> at
              the minimum are stored.
 
     This syntax minimizes a multivariate function.

Examples:
    LET A = OPTIMIZE X**2 + 2*X - 4 WRT X FOR X = -10 10

    LET A = OPTIMIZE X**2 +Y**2 - X*Y WRT X Y

    LET FUNCTION F1 = X**2 + Y**2 - X*Y
    LET A = OPTIMIZE F1 WRT X Y
 
Note:
    Univariate optimization is implemented using the FMIN routine
    from the "Numerical Methods and Software" book by Kahaner,
    Moler, and Nash.  Multivariate optimization is implemented
    using the UNCMIN package of Schnabel and Weiss.
 
    The FMIN routine was written by R. Brent and uses a
    combination of golden section search and successive
    parabolic interpolation.

    The UNCMIN package is designed to incorporate a number of
    different variations of quasi-Newton (also known as
    variable metric) approaches to unconstrained optimization.
    See the Dennis and Schnabel or chapter 10 of Numerical
    Recipes for a more detailed discussion of these
    issues.

    Specifically, the UNCMIN routines allow the following
    variations of the method.

    A. You can specify the global strategy to use at each
       iteration.
 
       1. Line search
       2. Hookstep trust region
       3. Dogleg trust region

       Although these methods can vary in efficiency and
       accuaracy for some problems, none of them is superior
       in general.

    B. You can specify the type of gradient (first derivative)
       to compute.

       1. Use an analytic gradient.
       2. Use a numerical approximation based on finite
          differences.

    C. You can specify the type of updating for the Hessian
       matrix at each step.

       1. Use analytic derivatives.
       2. Use a finite difference approximation.
       3. Use BFGS (Broyden-Fletcher-Goldfarb-Shanno) updating
          (a positive definite secant updating method).

       Generally, BFGS is considered superior to using
       finite difference approximation.

    This results in 18 (3*2*3) methods.  This effectively
    is 15, as using numerical first derivative with
    analytic updating of the Hessian matrix is unrealistic.

    Dataplot only supports numerical approximations for
    the first derivatives and the Hessian matrix, so this
    reduces to six methods (three types of global strategy and
    two types of approximation for the Hessian matrix).

    You can use the following command to specify which of
    the six methods to use in Dataplot:

        OPTIMIZATION METHOD <LINE/DOGLET/HOOK>  <FINITE/BFGS>

    The default is LINE and FINITE.

    Note that optimization of functions is an area of much
    mathematical research and there are a number of other
    approaches to optimization (e.g., Nelder-Meld simplex,
    conjugate gradient methods) as well (not currently supported
    in Dataplot).  Each of these methods have advantages and
    disadvantages.

    The UNCMIN procedures are intended for to small to
    moderate size problems.  Problems with a large number of
    variables typically require sparse matrix techniques which
    are not currently implemented in Dataplot.  In general,
    the UNCMIN routines provide good results for a broad
    class of problems.  However, there will be some problems
    for which they may not work well.

Note:
    By default, Dataplot finds the minimum of a function.  If you
    want to find the maximum of a function, you can do one of the
    following.

        1. You can take the negative of your function.  That is,
           if F is your original function, enter

                LET FUNCTION G = -F

           and then use G in the OPTIMIZE command.

        2. The following command was added in the September 2015 version

                SET OPTIMIZE <MINIMUM/MAXIMUM>

            where MINIMUM specificies that the function is being minimized
            and MAXIMUM specifies that the function is being maximized.
            The default is to find the minimum of the function.

Note:
    Minimization routines can sometimes settle on a local rather
    global minimum.  If you have some knowledge of the function,
    you can sometimes solve this problem by setting the values
    of the function parameters using the LET command.
  
    The followng example shows how to specify the starting
    values.
 
       LET FUNCTION F1 = X**2 + Y**2 - X*Y
       LET X = 0.1
       LET Y = 0.1
       LET A = OPTIMIZE F1 WRT X Y

Note:
    The primary limitation of the OPTIMIZE command for statistical
    applications is that Dataplot's function library does not
    currently support a summation function.  This prevents the
    OPTIMIZE command from being used for most maximum likelihood
    problems.  Maximum likelihood estimation is the primary
    application of function minimization in statistics.  This
    limitation is currently under investigation.

    The 2016/09 version of Dataplot introduced a new feature called
    "function blocks".  This feature allows you to use various LET
    subcommands in defining your function.  Specifically, this allows
    us to now define many of the functions that are needed in many
    statistical applications.  To see how function blocks are defined
    and used, enter HELP FUNCTION BLOCKS.  This gives several examples
    of using function blocks with the optimization command.

Note:
    Function minimization can be a numerically difficult
    problem.  For this reason, a number of options can be
    provided to help improve the performance of the minimization
    code.  Dataplot will provide defaults for each of these.
    However, if you have some knowledge of the function being
    minimized, specifying one or more of these parameters may
    help.

    The following parameters can be specified when minimizing a
    function:
    
       LET OPTSCALE = <value>   (default = 1.0)
       OPTSCALE is used to provide an estimate of the scale of
       the minimization function.  If know, Specifying the scalei
       may help provide better numerical results 

       LET OPTMSG   = <value>   (default = 8)
       OPTMSG can be used to control the output and certain
       checks.  Normally, this option is only used for
       debugging purposes.

       LET OPTITER  = <value>   (default = 150)
       OPTITER is used to specify the maximum number of
       iterations.

       LET OPTDLT   = <value>   (default = 0)
       OPTDLT specifies the trust region radius.

       LET OPTRDTL  = <value>   (default = R1MACH(4)**(1/3))
       OPTRDTL specifies the tolerance at which the gradient
       is considered close enough to zero to terminate the
       algorithm.

       LET OPTSPMX  = <value>   (default = 0)
       OPTSTPMX specifies the value of zero to trip default
       maximum.

       LET OPTSTPTL = <value>   (default = 0)
       OPTSTPTL specifies the tolerance at which successive
       iterations are considered close enough to terminate
       the algorithm.

    Note that default values of 0 imply that the UNCMIN will
    determine the default and this default may be dependent
    on the particular function being optimized.
 
Note:
    The optimized value of the function is saved in the internal
    parameter OPTVALUE.

    For multivariate optimization, the following information is
    written to files.

       DPST1F.DAT  - The gradients (derivatives) of each variable.
       DPST2F.DAT  - The Hessian matrix.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    3D-PLOT        = Generate a 3D plot.
    CONTOUR PLOT   = Generate a countor plot.
    SIMPLEX SOLU   = Solve linear programming problem using
                     simplex algorithm.
    ROOTS          = Find the roots of a univariate function.
    DERIVATIVE     = Compute the derivative of a function.
    INTEGRAL       = Compute the integral of a function.
    RUNGE KUTTA    = Runge Kutta differential equation solver.
    INTERPOLATE    = Interpolate a function.
 
Reference:
    Kahaner, Moler, and Nash (1989), "Numerical Methods and Software",
    Prentice-Hall.

    R. P. Brent (1973), "Algorithms for Minimization Without Derivatives",
    Prentice-Hall.

    J. E. Dennis, Jr. and Dennis B.  Schnabel (1996), "Numerical Methods
    for Unconstrained Optimization and Nonlinear Equations", SIAM.

    R. B. Schnabel, J. E. Koontz, and B. E. Weiss (1982), "A Modular
    System of Algorithms for Unconstrained Optimization", Report
    Cu-CS-240-82, Computer Science Department, University of Colorado.

    Press, Teukolsky, Vetterling, and Flannery (1992), "Numerical Recipes
    in Fortran: The Art of Scientific Programming", 2nd, ed., Cambridge
    University Press.

Applications:
    Maximum Likelihood Estimation
 
Implementation Date:
    1996/05
    2015/09: Added support for function blocks.
    2015/09: Added the SET OPTIMIZE <MINIMUM/MAXIMUM> command.
 
Program 1:
    LET FUNCTION F = X**2 + 2*X - 4
    PLOT F FOR X = -10 0.01 10
    LET A = OPTIMIZE F WRT X FOR X = -10 10
    LET X = DATA A
    LET Y = F
    LET OPTVALUE = Y(1)
    JUSTIFICATION CENTER
    MOVE 50 5
    TEXT MINIMUM OF ^OPTVALUE AT X = ^A

Program 2:
    LET FUNCTION F = X**2 + Y**2 -X*Y
    3D-PLOT F FOR X = -3 0.1 3 FOR Y = -3 0.1 3
    OPTIMIZATION METHOD LINE BFGS
    LET XPTS = OPTIMIZE F WRT X Y
    LET X1 = XPTS(1)
    LET Y1 = XPTS(2)
    JUSTIFICATION CENTER
    MOVE 50 5
    TEXT MINIMUM OF ^OPTVALUE AT X = ^X1 AND Y = ^Y1
 
-----ORIGIN COORDINATES--------------------------------------------
 
ORIGIN COORDINATES
 
Name:
    ORIGIN COORDINATES
 
Type:
    Support Command
 
Purpose:
    Specifies the origin coordinates (i.e., the position where the
    3-prong x-y-z frame intersects) for subsequent 3-dimensional
    plotting (via the 3D-PLOT command).
 
Syntax:
    ORIGIN COORDINATES   <x>   <y>   <z>
    where <x> is a decimal number or parameter in units of the data
              that specifies the desired x coordinate;
          <y> is a decimal number or parameter in units of the data
              that specifies the desired y coordinate;
    and   <z> is a decimal number or parameter in units of the data
              that specifies the desired z coordinate.
 
Examples:
    ORIGIN COORDINATES 20 20 3.5
    ORIGIN COORDINATES 0.5 200 4.5
    ORIGIN COORDINATES X0 Y0 Z0
 
Note:
    As the 3-D PLOT command does not currently draw the plot frame,
    this command does not have any effect.
 
Default:
    Default x = data x minimum
    Default y = data y minimum
    Default z = data z minimum
 
Synonyms:
    None
 
Related Commands:
    3D-PLOT            = Generates a 3-d data or function plot.
    EYE COORDINATES    = Sets the location of the eye for 3-d plots.
    PEDESTAL           = Allows or suppresses the pedestal for 3-d
                         plots.
    PEDESTAL COLOR     = Sets the pedestal color for 3-d plots.
    PEDESTAL SIZE      = Sets the pedestal height for 3-d plots.
    VISIBLE            = Allows or suppresses hidden lines in 3-d
                         plots.
 
Applications:
    3D Graphics
 
Implementation Date:
    XX
 
Program:
    XX
 
-----OUTPUT LINE NUMBERS (SET)---------------------------------------
 
OUTPUT LINE NUMBER (SET)
 
Name:
    SET OUTPUT LINE NUMBERS
 
Type:
    Support Command
 
Purpose:
    Specify whether alphanumeric output will have line numbers
    at the beginning of each line.
 
Description:
    By default, Dataplot does not insert a line number to the
    beginning of output lines.  However, there may be occassions
    where this is convenient (e.g., for debugging purposes).

Syntax:
    SET OUTPUT LINE NUMBERS <ON/OFF>
    where ON specifies that line numbers will be added to the output
               and OFF specifies that line numbers will not be added.
 
Examples:
    SET OUTPUT LINE NUMBERS ON
    SET OUTPUT LINE NUMBERS OFF
 
Default:
    OFF
 
Synonyms:
    None
 
Related Commands:
    CAPTURE       = Re-direct output to a file.
 
Applications:
    Debugging
 
Implementation Date:
    2019/12
 
Program:
    SKIP 25
    READ BERGER1.DAT Y X BATCH
    .
    SET OUTPUT LINE NUMBERS ON
    CAPTURE FIT.OUT
    FIT Y X
    QUADRATIC FIT Y X
    END OF CAPTURE
    .
    LIST FIT.OUT
 
-----OUTPUT-------------------------------------------------------
 
OUTPUT
 
Name:
    OUTPUT
 
Type:
    Output Device Command
 
Purpose:
    Specifies the name of the DEVICE 2 output file.

Description:
    Entering

         OUTPUT PLOT

    is equivalent to entering the commands

         DEVICE 2 CLOSE
         SET IPL1NA PLOT.PS
         DEVICE 2 POSTSCRIPT

    This is a convenience command to simplify renaming the DEVICE 2
    output file.

Syntax:
    OUTPUT <name>
    where <name> is the base name of the graphics output file.
 
    Dataplot will automatically add ".PS" to <name>.
 
Examples:
    OUTPUT PLOT1
    OUTPUT HISTOGRAM
 
Default:
    The default name for the DEVICe 2 output file is "dppl1f.dat".
 
Synonyms:
    None
 
Related Commands:
    DEVICE       = Specify a grahics device.
    SET IPL1NA   = Specify the name of the DEVICE 2 graphics output file.
 
Applications:
    Managing Graphics Output
 
Implementation Date:
    2020/05
 
Program:
    OUTPUT HISTOGRAM
    LET Y = NORMAL RANDOM NUMBERS FOR I = 1 1 500
    HISTOGRAM Y
 
-----OVAL-------------------------------------------------------
 
OVAL
 
Name:
    OVAL
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Draws an oval.
 
Description:
    The 3 pairs of coordinates define the (x,y) values for one major
    diameter endpoint, one minor diameter endpoint, and the other major
    diameter endpoint (respectively) of the oval.
 
Syntax:
    OVAL   <x1>   <y1>   <x2>   <y2>   <x3>   <y3>
    where <x1> is a number or parameter in the decimal range 0 to 100
               that specifies the x coordinate for one major diameter
               endpoint;
          <y1> is a number or parameter in the decimal range 0 to 100
               that specifies the y coordinate for one major diameter
               endpoint;
          <x2> is a number or parameter in the decimal range 0 to 100
               that specifies the x coordinate for the minor diameter
               endpoint;
          <y2> is a number or parameter in the decimal range 0 to 100
               that specifies the y coordinate for the minor diameter
               endpoint;
          <x3> is a number or parameter in the decimal range 0 to 100
               that specifies the x coordinate for the other major
               diameter endpoint;
    and   <y3> is a number or parameter in the decimal range 0 to 100
               that specifies the y coordinate for one major diameter
               endpoint.
 
Examples:
    OVAL 30 50 50 40 70 50
    OVAL 30 30 50 40 70 70
    OVAL 20 70 30 50 40 70
    OVAL X1 Y1 X2 Y2 X3 Y3
    OVAL 50 50 X2 Y2 70 50
    OVAL 40 50 50 30 60 50
 
Note:
    The line style (i.e., SOLID, DASH), line color, and line thickness
    are controlled by the first entry of the LINE, LINE COLOR, and
    LINE THICKNESS commands respectively.
 
    The keywords DATA and RELATIVE were added to the TRIANGLE
    command 7/1997.  These keywords are independent and can
    be used separately or together.  For example, 
    TRIANGLE DATA, TRIANGLE RELATIVE, or TRIANGLE DATA RELATIVE.
    The word DATA should come before the word RELATIVE if both
    appear.

    DATA means that the coordinates are specified in terms of
    the data units of the most recent plot rather than Dataplot
    0 to 100 screen units.

    RELATIVE means that the coordinates of the first point
    are drawn in absolute coordinates an all subsequent points
    in the figure are relative to that first point.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POINT            = Draws a point.
    ARROW            = Draws an arrow.
    TRIANGLE         = Draws a triangle.
    BOX              = Draws a box.
    HEXAGON          = Draws a hexagon.
    CIRCLE           = Draws a circle.
    SEMI-CIRCLE      = Draws a semi-circle.
    CUBE             = Draws a cube.
    ARC              = Draws an arc.
    ELLIPSE          = Draws an ellipse.
    DIAMOND          = Draws a diamond.
    DRAW             = Draws a line.
    MOVE             = Moves to a point.
    LINES            = Sets the line type for figures and plot lines.
    LINE THICKNESSES = Sets the line thickness for figures and  plot
                       lines.
    LINE COLOR       = Sets the line colors for figures and plot lines.
    CROSS-HAIR       = Activates and reads the cross-hair.
    TEXT             = Writes a text string.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    OVAL 10 10 13 15 20 20
    OVAL 60 10 70 18 80 30
    .
    THICKNESS 0.7
    OVAL 10 30 13 35 20 40
    THICKNESS 0.2
    .
    LINE DASH
    OVAL 10 50 13 55 20 60
    LINE SOLID
    .
    LINE COLOR G50
    THICKNESS 0.5
    OVAL 10 80 17 86 20 90
 
-------------------------------------------------------------
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 














































































-END -----*-----      ----------------ZZZZZ------
