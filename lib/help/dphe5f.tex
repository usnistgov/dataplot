68900.      (VERSION 2023.11)  total number of lines in file (including this line)
 4.                          number of     sections below
  100.    P                  first line number of P section
22600.    Q                  first line number of Q section
25700.    R                  first line number of R section
44500.    S                  first line number of S section
 
----------------------------------------------------------
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
-------------------------  *P*  ZZZZZ--------------------
 
-----PAGE TEST-----------------------------------------
 
PAGE TEST
 
Name:
    PAGE TEST
 
Type:
    Analysis Command
 
Purpose:
    Perform a Page test that k treatments have identical effects
    against the alternative of ordered treatment effects.
 
Description:
    The Page test is a non-parametric test for analyzing randomized
    complete block designs.  It is derived from a Spearman's rho
    rank correlation of the Friedman within block rankings and the
    specified ordering of the treatments.  The Page test statistic
    is actually a monotonic function of Spearman's rho when there is
    no ties in the data.

    The distinction between the Friedman test and the Page test
    is that the Page test is used when you want to test for ordered
    effects.   By ordered effects, we mean that treatment 1 is
    less than or equal to treatment 2 which is less than or equal to
    treatment 3 and so on (and at least one of these should be
    strictly less than).

    As with the Friedman test, assumes that there are k experimental
    treatments (k >= 2).  The observations are arranged in p blocks,
    that is

                     Treatment
    Block  1    2      ...      k
      1   X11  X12     ...     X1k
      2   X21  X22     ...     X2k
      3   X31  X32     ...     X3k
     ...  ...  ...     ...     ...
      b   Xb1  Xb2     ...     Xbk

    Let R(Xij) be the rank assigned to Xij within block i (i.e.,
    ranks within a given row).  Average ranks are used in the case
    of ties.  The ranks are summed to obtain

         R(j) = SUM[i=1 to b]R(X(ij))

    Then the Page test is 

        H0: The treatment effects have identical effects
        Ha: mu1 <= mu2 <= .... <= mu3  or
            mu1 >= mu2 >= .... >= mu3
        Test Statistic:
            The Page test statistic is

                T4 = SUM[j=1 to k][j*R(j)]

            In order to compare this to a standard normal distribution,
            this statistic is transformed to

                T5 = {T4 - b*k*(k+1)**2/4}/SQRT{b*(k**3 - k)**2/(144*(k-1))}
        Significance Level: ALPHA
        Critical Region:
            T5 > NORPPF(ALPHA) where NORPPF is the normal percent point
            function
        Conclusion: Reject the null hypothesis if the test
                    statistic is in the critical region.

Syntax:
    PAGE TEST  <y>  <block> <treat>
                        <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <block> is a variable that identifies the block;
          <treat> is a variable that identifies the treatment;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    PAGE TEST Y BLOCK TREATMENT
    PAGE TEST Y X1 X2
    PAGE TEST Y BLOCK TREATMENT  SUBSET BLOCK > 2
 
Note:
    Dataplot formulates the test as a "less than or equal to"
    test.  That is, the treatment that is hypothesized to be
    the smallest should be coded as 1, the treatment that is
    hypothesized to be the second smallest should be coded as 2,
    and so on.  If your treatments are coded in the opposite order,
    you can reverse them with the command

        LET TREAT2 = FLIP TREAT

Note:
    In Dataplot, the variables should be given as:
 
        Y   BLOCK   TREAT
       X11    1      1
       X12    1      2
       ...    1     ...
       X1k    1      k 
       X21    2      1
       X22    2      2
       ...    2     ...
       X2k    2      k 
 
       ...   ...    ...
 
 
       Xb1    b      1
       Xb2    b      2
       ...    b     ...
       Xb3    b      k 
 
    If your data are in a format similar to that given in the
    DESCRIPTION section (i.e., you have colums Y1 to Yk, each
    with b rows), you can convert it to the format required by
    Dataplot with the commands:

       LET NBLOCK = SIZE Y1
       LET BLOCKID = SEQUENCE 1 1 NBLOCK
       LET Y BLOCK TREAT = REPLICATED STACK Y1 Y2 Y3 Y4 Y5 BLOCKID
       PAGE TEST Y BLOCK TREAT

Note:
    The response, ranked response, block, and treatment are
    written to the file dpst1f.dat in the current directory.

Note:
    The Page test is based on the following assumptions:

       1) The b rows are mutually independent.  That means that
          the results within one block (row) do not affect
          the results within other blocks.

       2) The data can be meaningfully ranked.

Note:
    The following statistics are also supported:

        LET A = PAGE TEST            Y X1 X2
        LET A = PAGE TEST NORMALIZED Y X1 X2
        LET A = PAGE TEST CDF        Y X1 X2
        LET A = PAGE TEST PVALUE     Y X1 X2

    The PAGE TEST returns the T4 value described above and the
    PAGE TEST NORMALIZED returns the T5 value described above.

    Enter HELP STATISTICS to see what commands can use these
    statistics.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    FRIEDMAN TEST         = Perform a Friedman test.
    QUADE TEST            = Perform a Quade test.
    ANOVA                 = Perform an analysis of variance.
    DURBIN TEST           = Perform a Durbin test for two-way
                            incomplete balanced block designs.
    COCHRAN TEST          = Perform a Cochran test for two-way
                            complete block designs (binary data).
    KRUSKAL WALLIS        = Perform a Kruskall Wallis test.
    BLOCK PLOT            = Generate a block plot.
    DEX SCATTER PLOT      = Generates a dex scatter plot.
    DEX ... PLOT          = Generates a dex plot for a statistic.
 
Reference:
    Conover, "Practical Nonparametric Statistics", Third Edition, Wiley,
    1999, pp. 380-383.
    
 
Applications:
    Analysis of Variance
 
Implementation Date:
    2013/2
 
Program:
    .  Test Page test as given in
    .  Conover (1999), "Practical Non-Parametric Statistics"
    .  Third Edition, pp. 380-381.
    .
    read y treat block
    79   1    1
    78   1    2
    72   1    3
    66   1    4
    75   1    5
    64   1    6
    68   1    7
    70   1    8
    76   2    1
    76   2    2
    74   2    3
    65   2    4
    75   2    5
    66   2    6
    70   2    7
    72   2    8
    77   3    1
    76   3    2
    77   3    3
    68   3    4
    72   3    5
    65   3    6
    68   3    7
    78   3    8
    84   4    1
    80   4    2
    78   4    3
    72   4    4
    74   4    5
    69   4    6
    74   4    7
    76   4    8
    82   5    1
    80   5    2
    75   5    3
    65   5    4
    77   5    5
    68   5    6
    70   5    7
    77   5    8
    end of data
    .
    let statval = page test             y block treat
    let statva2 = page test normalized  y block treat
    let cdf     = page test cdf         y block treat
    let pval    = page test pvalue      y block treat
    .
    set write decimals 4
    page test y block treat
 
-----P CHART-----------------------------------------------------
 
P CHART
 
Name:
    P CHART
 
Type:
    Graphics Command
 
Purpose:
    Generates a (binomial) proportion control chart.
 
Description:
    A P chart is a data analysis analysis technique for determining if
    a measurement process has gone out of statistical control.  The p
    chart is sensitive to changes in the proportion of defective items
    in the measurement process.  The "p" in P CHART stands for the p
    (the proportion of successes) of a binomial distribution.  The p
    control chart consists of:
       Vertical   axis = the proportion defectives for each sub-group;
       Horizontal axis = the sub-group designation.
    A sub-group is typically a time sequence (e.g., the number of
    defectives in a daily production run where each day is considered a
    sub-group).  If the times are equally spaced, the horizontal axis
    variable can be generated as a sequence (e.g.,
    LET X = SEQUENCE 1 1 N where N is the number of sub-groups).
 
    In addition, horizontal lines are drawn at the mean number of
    defectives and at the upper and lower control limits.  The control
    limits are calculated as:
         UCL = pbar + 3*sqrt(pbar(1-pbar)/N)
         LCL = pbar - 3*sqrt(pbar(1-pbar)/N)
    where pbar is the total number of defectives divided by the total
    number of items and N is the number of items in a given sub-group.
    Also, zero serves as a lower bound on the LCL value.
 
Syntax:
    P CHART   <y1>   <y2>   <x>  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable containing the number of defective
               items in each sub-group;
          <y2> is a variable containing the total number of items
               in each sub-group; and
          <x>  is a variable containing the sub-group identifier
               (usually 1, 2, 3, ...);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    P CHART Y1 Y2 X
    P CHART D T X
 
Note:
    The distribution of defective items is assumed to be Binomial.
    This assumption is the basis for calculating the upper and lower
    control limits.
 
Note:
    The P chart and NP chart are related to one another. The
    distinction is that the P chart is used when sub-groups have equal
    size (so the number of defectives is plotted) while the NP chart is
    used when the sub-groups have unequal sample sizes (so the
    percentage of defectives is plotted).
 
Note:
    The attributes of the 4 traces that make up the NP control chart
    are controlled by the standard LINES, CHARACTERS, SPIKES, and BAR
    commands.  Trace 1 is the response variable, trace 2 is the mean
    line, and traces 3 and 4 are the upper and lower control limits.
    Some analysts prefer to draw the response variable as a character
    or spike rather than a connected line.
 
Default:
    None
 
Synonyms:
    PROPORTION CHART for P CHART
 
Related Commands:
    NP CHART            = Generates a Np control chart.
    U CHART             = Generates a U control chart.
    C CHART             = Generates an C control chart.
    XBAR CHART          = Generates an xbar control chart.
    R CHART             = Generates a range control chart.
    S CHART             = Generates a standard deviation control chart.
 
    CHARACTERS          = Sets the types for plot characters.
    LINES               = Sets the types for plot lines.
    SPIKES              = Sets the on/off switches for plot spikes.
    BARS                = Sets the on/off switches for plot bars.
    PLOT                = Generates a data or function plot.
    LAG PLOT            = Generates a lag plot.
    4-PLOT              = Generates a 4-plot for univariate analysis.
    ANOP PLOT           = Generates an ANOP plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    . DEFECTIVE MOTORS
    .  1. X = SUBGROUP ID (1 TO 25)
    .  2. NUMDEF = NUMBER OF DEFECTIVE ITEMS IN SUB-GROUP
    .  3. SIZE = TOTAL NUMBER OF ITEMS IN SUB-GROUP
    .
    SERIAL READ NUMDEF
    14 19 19 24 15 16 38 40 21 32 40 25 39 36 17 19 4 9 12 26
    END OF DATA
    SERIAL READ SIZE
    125 200 188 200 200 250 390 360 250 250 395 300 310 200 300 185 55
    90 130 300
    END OF DATA
    LET X = SEQUENCE 1 1 20
    .
    LINES SOLID SOLID DOT DOT
    XLIMITS 0 20
    XTIC OFFSET 0 1
    . YLIMITS 0 15
    . YTIC OFFSET 2 0
    .
    P CONTROL CHART NUMDEF  SIZE X
 
-----PAPCDF (LET)--------------------------------
 
PAPCDF
 
Name:
    PAPCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Polya-Aeppli cumulative distribution function.
 
Description:
    The formula for the Polya-Aeppli probability mass function is

    p(x;theta,p) = EXP(-theta)        x = 0
                 = EXP(-theta)*p**x*SUM[j=1 to x]
                   [(x-1  j-1)*(theta*(1-p)/p)**j/j!]
                   x = 1, ...;
                   0 < p < 1; theta > 0

    with theta and <i>p</i> denoting the shape parameters.

    The cumulative distribution function is computed using the
    following recurrence relation (from page 379 of Johnson,
    Kemp, and Kotz)

        p(X+1) = (THETA*(1-P)/(X+1))*SUM[J=0 TO X]
                 [(X+1-J)*P**(X-J)*p(X)]

Syntax:
    LET <y> = PAPCDF(<x>,<theta>,<p>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative integer variable, number, or
               parameter;
          <theta> is a positive number or parameter that specifies
               the first shape parameter;
          <p> is a positive number or parameter that specifies
               the second shape parameter;
          <y> is a variable or a parameter where the computed
               Polya-Aeppli cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PAPCDF(3,3,0.5)
    LET Y = PAPCDF(X1,2,0.3)
    PLOT PAPCDF(X,2,0.3) FOR X = 0  1  20
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PAPCDF                   = Compute the Polya-Aeppli cumulative
                               distribution function.
    PAPPDF                   = Compute the Polya-Aeppli probability
                               mass function.
    LPOPDF                   = Compute the Lagrange-Poisson
                               percent point function.
    BTAPDF                   = Compute the Borel-Tanner probability
                               mass function.
    LOSPDF                   = Compute the lost games probability
                               mass function.
    POIPDF                   = Compute the Poisson probability
                               density function.
    HERPDF                   = Compute the Hermite probability
                               density function.
    BINPDF                   = Compute the binomial probability
                               density function.
    NBPDF                    = Compute the negative binomial
                               probability density function.
    GEOPDF                   = Compute the geometric probability
                               density function.

References:
    Douglas (1980), "Analysis with Standard Contagious
    Distributions", International Co-operative Publishing House,
    Fairland, MD.

    Evans (1953), "Experimental Evidence Concerning Contagious
    Distributions in Ecology", Biometrika, 40, pp. 186-211.

    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 378-382.

Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    title size 3
    tic label size 3
    label size 3
    legend size 3
    height 3
    multiplot scale factor 1.5
    x1label displacement 12
    y1label displacement 17
    .
    multiplot corner coordinates 0 0 100 95
    multiplot scale factor 2
    label case asis
    title case asis
    case asis
    tic offset units screen
    tic offset 3 3
    title displacement 2
    y1label Probability
    x1label X
    .
    ylimits 0 1
    major ytic mark number 6
    minor ytic mark number 3
    xlimits 0 20
    line blank
    spike on
    .
    multiplot 2 2
    .
    title Theta = 0.5, P = 0.5
    plot papcdf(x,0.5,0.5) for x = 1 1 20
    .
    title Theta = 1, P = 0.5
    plot papcdf(x,1,0.5) for x = 1 1 20
    .
    title Theta = 2.5, P = 0.5
    plot papcdf(x,2.5,0.5) for x = 1 1 20
    .
    title Theta = 5, P = 0.5
    plot papcdf(x,5,0.5) for x = 1 1 20
    .
    end of multiplot
    .
    justification center
    move 50 97
    text Cumulative Distribution for Polya-Aeppli
 
-----PAPPDF (LET)--------------------------------
 
PAPPDF
 
Name:
    PAPPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Polya-Aeppli probability mass function.
 
Description:
    The formula for the Polya-Aeppli probability mass function is

    p(x;theta,p) = EXP(-theta)        x = 0
                 = EXP(-theta)*p**x*SUM[j=1 to x]
                   [(x-1  j-1)*(theta*(1-p)/p)**j/j!]
                   x = 1, ...;
                   0 < p < 1; theta > 0

    with theta and <i>p</i> denoting the shape parameters.

    The Polya-Aeppli distribution can be derived as a model for
    the number of objects where the objects occur in clusters,
    the clusters follow a Poisson distribution with shape
    parameter theta, and the number of objects within a cluster
    follows a geometric distribution with shape parameter p.
    For this reason, this distribution is sometimes referred to
    as a geometric Poisson distribution

    Note that there are a number of alternative parameterizations
    of this distribution in the literature.  The parameterization
    used above is the one given in Johnson, Kotz, and Kemp.
             
    The moments of this distribution are:

        mean      = theta/(1-p)
        variance  = theta*(1+p)/(1-p)**2
        skewess   = (1+4*p+p**2)**2/((1+p)**3*theta)">
        kurtosis  = 3 + (1+11*p+11*p**2+p**3)/((1+p)**2*theta)

Syntax:
    LET <y> = PAPPDF(<x>,<theta>,<p>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative integer variable, number, or
               parameter;
          <theta> is a positive number or parameter that specifies
               the first shape parameter;
          <p> is a positive number or parameter that specifies
               the second shape parameter;
          <y> is a variable or a parameter where the computed
               Polya-Aeppli pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PAPPDF(3,3,0.5)
    LET Y = PAPPDF(X1,2,0.3)
    PLOT PAPPDF(X,2,0.3) FOR X = 0  1  20
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Note:
    For a number of commands utilizing the Polya-Aeppli
    distribution, it is convenient to bin the data.  There
    are two basic ways of binning the data.

      1) For some commands (histograms, maximum likelihood
         estimation), bins with equal size widths are
         required.  This can be accomplished with the
         following commands:

            LET AMIN = MINIMUM Y
            LET AMAX = MAXIMUM Y
            LET AMIN2 = AMIN - 0.5
            LET AMAX2 = AMAX + 0.5
            CLASS MINIMUM AMIN2
            CLASS MAXIMUM AMAX2
            CLASS WIDTH 1
            LET Y2 X2 = BINNED

      2) For some commands, unequal width bins may be
         helpful.  In particular, for the chi-square goodness
         of fit, it is typically recommended that the minimum
         class frequency be at least 5.  In this case, it may
         be helpful to combine small frequencies in the tails.
         Unequal class width bins can be created with the
         commands

            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = INTEGER FREQUENCY TABLE Y

         If you already have equal width bins data, you can
         use the commands
         
            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = COMBINE FREQUENCY TABLE Y2 X2

         The MINSIZE parameter defines the minimum class
         frequency.  The default value is 5.

Note:
    You can generate Polya-Aeppli random numbers, probability
    plots, and chi-square goodness of fit tests with the
    following commands:

       LET N = VALUE
       LET THETA = <value>
       LET LAMBDA = <value>
       LET Y = POLYA AEPPLI RANDOM NUMBERS FOR I = 1 1 N

       POLYA AEPPLI PROBABILITY PLOT Y
       POLYA AEPPLI PROBABILITY PLOT Y2 X2
       POLYA AEPPLI PROBABILITY PLOT Y3 XLOW XHIGH

       POLYA AEPPLI CHI-SQUARE GOODNESS OF FIT Y2 X2
       POLYA AEPPLI CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    To obtain the method of moments, the method of zero frequency
    and the mean, and the weighted discrepancies estimates of
    lambda and theta, enter the command

        POLYA AEPPLI MAXIMUM LIKELIHOOD Y
        POLYA AEPPLI MAXIMUM LIKELIHOOD Y2 X2

    The method of moments estimates are

        thetahat  = 2*xbar**2/(s**2 + xbar)
        phat = (s**2 - xbar)/(s^2 + xbar)

    with xbar and s**2 denoting the sample mean and sample
    variance, respectively.

    The mean and zero frequency estimates are

        thetahat = -LOG(f0/N))
        phat = 1 - thetahat/xbar

    with f0 denoting the sample frequency at x = 0.

    The method of the first two sample frequencies estimates
    are

        thetahat = -LOG(f0/N))
        phat = -f1/(f0LOG(f0/N))

    with f0 and f1 denoting the sample frequencies at
    x = 0 and x = 1, respectively.

    The maximum likelihood estimates are the solution to the
    following equations

        xbar - thetahat/(1-phat) = 0

        xbar - SUM[i=1 to N][(f(j)*(j-1)*Phat(j-1)/(N*Phat(j)) = 0

    with f(x) and Phat(x) denoting the frequency at x and the
    Polya-Aeppli probaility mass function value at x, respectively.

    You can generate estimates of theta and p based on the
    maximum ppcc value or the minimum chi-square goodness of fit
    with the commands

        LET THETA1 = <value>
        LET THETA2 = <value>
        LET P1 = <value>
        LET P2 = <value>
        POLYA AEPPLI KS PLOT Y
        POLYA AEPPLI KS PLOT Y2 X2
        POLYA AEPPLI KS PLOT Y3 XLOW XHIGH
        POLYA AEPPLI PPCC PLOT Y
        POLYA AEPPLI PPCC PLOT Y2 X2
        POLYA AEPPLI PPCC PLOT Y3 XLOW XHIGH

    The default values of p1 and p2 are 0.05 and 0.95,
    respectively.  The default values of theta1 and theta2
    are 1 and 25, respectively.  Due to the discrete nature of
    the percent point function for discrete distributions, the
    ppcc plot will not be smooth.  For that reason, if there is
    sufficient sample size the KS PLOT (i.e., the minimum
    chi-square value) is typically preferred.  However, it may
    sometimes be useful to perform one iteration of the PPCC PLOT
    to obtain a rough idea of an appropriate neighborhood for the
    shape parameters since the minimum chi-square statistic can
    generate extremely large values for non-optimal values of the
    shape parameter.  Also, since the data is integer values, one
    of the binned forms is preferred for these commands.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PAPCDF                   = Compute the Polya-Aeppli cumulative
                               distribution function.
    PAPPPF                   = Compute the Polya-Aeppli percent point
                               function.
    LPOPDF                   = Compute the Lagrange-Poisson
                               probability mass function.
    BTAPDF                   = Compute the Borel-Tanner probability
                               mass function.
    LOSPDF                   = Compute the lost games probability
                               mass function.
    POIPDF                   = Compute the Poisson probability
                               mass function.
    HERPDF                   = Compute the Hermite probability
                               mass function.
    BINPDF                   = Compute the binomial probability
                               mass function.
    NBPDF                    = Compute the negative binomial
                               probability mass function.
    GEOPDF                   = Compute the geometric probability
                               mass function.
    INTEGER FREQUENCY TABLE  = Generate a frequency table at
                               integer values with unequal bins.
    COMBINE FREQUENCY TABLE  = Convert an equal width frequency
                               table to an unequal width frequency
                               table.
    KS PLOT                  = Generate a minimum chi-square plot.
    MAXIMUM LIKELIHOOD       = Perform maximum likelihood
                               estimation for a distribution.

References:
    Douglas (1980), "Analysis with Standard Contagious
    Distributions", International Co-operative Publishing House,
    Fairland, MD.

    Evans (1953), "Experimental Evidence Concerning Contagious
    Distributions in Ecology", Biometrika, 40, pp. 186-211.

    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 378-382.

Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    let theta = 1.7
    let p = 0.7
    let y = polya aeppli random numbers for i = 1 1 500
    .
    let y3 xlow xhigh = integer frequency table y
    class lower 0.5
    class width 1
    let amax = maximum y
    let amax2 = amax + 0.5
    class upper amax2
    let y2 x2 = binned y
    .
    set write decimals 5
    polya aeppli mle y
    relative histogram y2 x2
    limits freeze
    pre-erase off
    line color blue
    plot pappdf(x,thetaml,pml) for x = 0 1 amax
    limits
    pre-erase on
    line color black
    let p = pml
    let theta = thetaml
    polya aeppli chi-square goodness of fit y3 xlow xhigh
    case asis
    justification center
    move 50 97
    text Theta = ^thetaml, P = ^pml
    move 50 93
    text Minimum Chi-Square = ^minks, 95% CV = ^cutupp95
    .
    label case asis
    x1label P
    x2label Curves Represent Values of Theta
    y1label Minimum Chi-Square
    let theta1 = 0.5
    let theta2 = 5
    let p1 = 0.3
    let p2 = 0.9
    polya aeppli chi-square plot y3 xlow xhigh
    let theta = shape1
    let p = shape2
    polya aeppli chi-square goodness of fit y3 xlow xhigh
    case asis
    justification center
    move 50 97
    text Theta = ^theta, P = ^p
    move 50 93
    text Minimum Chi-Square = ^minks, 95% CV = ^cutupp95
 
-----PAPPPF (LET)--------------------------------
 
PAPPPF
 
Name:
    PAPPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Polya-Aeppli percent point function.
 
Description:
    The formula for the Polya-Aeppli probability mass function is

    p(x;theta,p) = EXP(-theta)        x = 0
                 = EXP(-theta)*p**x*SUM[j=1 to x]
                   [(x-1  j-1)*(theta*(1-p)/p)**j/j!]
                   x = 1, ...;
                   0 < p < 1; theta > 0

    with theta and <i>p</i> denoting the shape parameters.

    The cumulative distribution function is computed using the
    following recurrence relation (from page 379 of Johnson,
    Kemp, and Kotz)

        p(X+1) = (THETA*(1-P)/(X+1))*SUM[J=1 TO X]
                 [(X+1-J)*P**(X-J)*p(X)]

    The percent point function is computed by computing the
    cumulative distribution function until the appropriate
    probability is obtained.

Syntax:
    LET <y> = PAPPPF(<x>,<theta>,<p>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is a integer variable, number, or parameter in the
               interval (0,1);
          <theta> is a positive number or parameter that specifies
               the first shape parameter;
          <p> is a positive number or parameter that specifies
               the second shape parameter;
          <y> is a variable or a parameter where the computed
               Polya-Aeppli ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PAPPPF(0.95,3,0.5)
    LET Y = PAPPPF(P,2,0.3)
    PLOT PAPPPF(P,2,0.3) FOR P = 0  0.01  0.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PAPCDF                   = Compute the Polya-Aeppli cumulative
                               distribution function.
    PAPPDF                   = Compute the Polya-Aeppli probability
                               mass function.
    LPOPDF                   = Compute the Lagrange-Poisson
                               percent point function.
    BTAPDF                   = Compute the Borel-Tanner probability
                               mass function.
    LOSPDF                   = Compute the lost games probability
                               mass function.
    POIPDF                   = Compute the Poisson probability
                               density function.
    HERPDF                   = Compute the Hermite probability
                               density function.
    BINPDF                   = Compute the binomial probability
                               density function.
    NBPDF                    = Compute the negative binomial
                               probability density function.
    GEOPDF                   = Compute the geometric probability
                               density function.

References:
    Douglas (1980), "Analysis with Standard Contagious
    Distributions", International Co-operative Publishing House,
    Fairland, MD.

    Evans (1953), "Experimental Evidence Concerning Contagious
    Distributions in Ecology", Biometrika, 40, pp. 186-211.

    Johnson, Kotz, and Kemp (1992),  "Univariate Discrete
    Distributions", Second Edition, Wiley, pp. 378-382.

Applications:
    Distributional Modeling
 
Implementation Date:
    2006/6
 
Program:
    title size 3
    tic label size 3
    label size 3
    legend size 3
    height 3
    multiplot scale factor 1.5
    x1label displacement 12
    y1label displacement 17
    .
    multiplot corner coordinates 0 0 100 95
    multiplot scale factor 2
    label case asis
    title case asis
    case asis
    tic offset units screen
    tic offset 3 3
    title displacement 2
    x1label Probability
    y1label X
    .
    xlimits 0 1
    major xtic mark number 6
    minor xtic mark number 3
    .
    multiplot 2 2
    .
    title Theta = 0.5, P = 0.5
    plot papppf(x,0.5,0.5) for x = 0  0.01  0.99
    .
    title Theta = 1, P = 0.5
    plot papppf(x,1,0.5) for x = 0  0.01  0.99
    .
    title Theta = 2.5, P = 0.5
    plot papppf(x,2.5,0.5) for x = 0  0.01  0.99
    .
    title Theta = 5, P = 0.5
    plot papppf(x,5,0.5) for x = 0  0.01  0.99
    .
    end of multiplot
    .
    justification center
    move 50 97
    text Percent Point for Polya-Aeppli
 
-----PARALLEL LINES--------------------------------------------------
 
PARALLEL LINES
 
Name:
    PARALLEL LINES
 
Type:
    LET Subcommand
 
Purpose:
    Given a line defined by two points and a third point, find the line
    parallel to the first line and containing the third point.

Syntax:
    LET <yout> <xout>= PARALLEL LINES <x1> <y1> <x2> <y2> <x3> <y3>
                       <SUBSET/EXPCEPT/FOR qualification>
    where <x1> is a variable or parameter containing the x-coordinates for the
               first point of line one;
          <y1> is a variable or parameter containing the y-coordinates for the
               first point of line one;
          <x2> is a variable or parameter containing the x-coordinates for the
               second point of line one;
          <y2> is a variable or parameter containing the y-coordinates for the
               second point of line one;
          <x3> is a variable or parameter containing the x-coordinates for the
               third point;
          <y3> is a variable or parameter containing the y-coordinates for the
               third point;
          <yout> is a variable containing the y-coordinates of the
               second point of the parallel line;
          <xout> is a variable containing the x-coordinates of the
               second point of the parallel line;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET YOUT XOUT = PARALLEL LINES X1 Y1 X2 Y2 X3 Y3 X4 Y4

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POINTS IN POLYGON  = Determine whether points are in the interior
                         of a convex polygon.
    CONVEX HULL        = Determine the convex hull of a set of points.
    TRANSFORM POINTS   = Perform location, scale, and rotation
                         transformation for a set of points.
    EXTREME POINTS     = Determine the extreme points of a set of points.
    LINE INTERSECTIONS = Determine the intersection points for a set of
                         lines.
    PERPINDICULAR LINE = Determine the coordinates for a point that defines
                         a perpindicular line determined by a point and a line
                         defined by two points.

Applications:
    Computational Geometry
 
Implementation Date:
    2012/10
 
Program:
    dimension 40 columns
    skip 25
    read convhull.dat x y
    .
    let y2 x2 = 2d convex hull y x
    let xtemp = x2(1)
    let ytemp = y2(1)
    let y2 = combine y2 ytemp
    let x2 = combine x2 xtemp
    let x3 = x2
    let y3 = y2
    let n = size y2
    let nm1 = n - 1
    retain x2 y2 for i = 1 1 nm1
    retain x3 y3 for i = 2 1 n
    let slope = slope(x2,y2,x3,y3)
    let pdist = dpntline(xtemp,ytemp,x3,y3,slope)
    let xtempv = xtemp for i = 1 1 nm1
    let ytempv = ytemp for i = 1 1 nm1
    let y5 x5 = parallel line x2 y2 x3 y3 xtempv ytempv
    .
    set write decimals 4
    print "Anchor Point: (^xtemp,^ytemp)"
    print " "
    print " "
    print x2 y2 x3 y3 x5 y5
 
-----PARALLEL COORDINATES PLOT--------------------------------------
 
PARALLEL COORDINATES PLOT
 
Name:
    PARALLEL COORDINATES PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates an parallel coordinates plot.
 
Description:
    A parallel coordinates plot is a graphical data analysis
    technique for plotting multivariate data.

    In the parallel coordinates plot, a set of parallel axes
    are drawn for each variable.  Then a given row of data
    is represented by drawing a line that connects the value
    of that row on each corresponding axis.  For example,
    given the row of data (0, 1, 0) for variables X1, X2, and
    X3:

      X3  +----------------------

      X2  ----------------------+

      X1  +----------------------

          0                     1

    The "+" positions identify plot coordinates (these would be
    connected on a graphics device).

    Paralled coordinate plots were first recoginized as a
    data analysis tool by Ed Wegman (see the Reference section
    below).

    There have been a number of variants of the parallel
    coordinate plots recommended in the literature.

Syntax 1:
    PARALLEL COORDINATES PLOT  <y1> <y2> ... <yk>
                               <SUBSET/EXCEPT/FOR qualification>
    where <y1> through <yk> are the response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    GROUP PARALLEL COORDINATES PLOT  <y1> <y2> ... <yk> <tag>
                               <SUBSET/EXCEPT/FOR qualification>
    where <y1> through <yk> are the response variables;
          <tag> is a group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    With this syntax, the last variable listed is interpreted as
    a group-id variable.  All rows of the response variable
    with the same group-id are plotted with the same line and
    character attributes.  See the Note section below for
    additional clarification.

Examples:
    PARALLEL COORDINATES PLOT Y1 Y2 Y3 Y4 Y5
    PARALLEL COORDINATES PLOT Y1 TO Y5
    PARALLEL COORDINATES PLOT Y1 Y2 Y3 Y4 Y5 SUBSET TAG > 2
 
Note:
    For the GROUP PARALLEL COORDINATES PLOT case, you can use
    whatever numerical grouping scheme you find convenient.
    For example, you can use a categorical response variable
    that already provides grouping or you can define your own
    groups based on whatever criterion you find relevant.

    However you define the original grouping, Dataplot automatically
    recodes the group id's as the integers from 1 to NG where NG is
    the number of groups.  The coding is from smallest value of
    the original group id's to the largest value of the original
    group id's.

    When the parallel coordinates plot is generated, observations
    with a group value of 1 use the first settings of the
    line and character settings, observations with a group value
    of 2 use the second settings of the line and character settings,
    and so on.

Note:
    The data are typically scaled for a parallel coordinates
    plot.  In Dataplot, you can use the following command:

        SET PARALLEL COORDINATES PLOT STANDARDIZE <NONE/USCORE/ZSCORE>

    where

        NONE    - means no scaling is applied
        USCORE  - scales the data between 0 and 1 (specifically
                  xscale = (x - xmin)/(xmax - xmin)
        ZSCORE  - scales the data by subtracting the mean and
                  dividing by the standard deviation

    The default is USCORE.  The NONE option is useful if you
    want to apply your own scaling.  For example, you may
    want to scale the data based on the full data set, but only
    generate the parallel coordinates plot for a subset of the
    data.
 
Note:
    By default, Dataplot draws the parallel axes on the
    vertical axis and the data scale on the horizontal axis.
    To reverse this, enter the command

        HORIZONTAL SWITCH ON

Note:
    The order of the variables on the plot can affect the
    appearance of the parallel coordinates plot.  At the
    current time, Dataplot simply draws the axes
    in the order they are given on PARALLEL COORDINATES PLOT
    command.
 
Note:
    Dataplot currently allows up to 30 variables to be plotted.
 
Note:
    The TO syntax is allowed on this command.  For example

          PARALLEL COORDINATES PLOT Y1 TO Y10
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINES              = Sets the types for plot lines.
    PLOT               = Generates a data or function plot.
    ANDREWS PLOT       = generate an Andrews plot.
    STAR PLOT          = Generate a star plot.
    PROFILE PLOT       = Generate a profile plot.
 
Reference:
    "Hyperdimensional Data Analysis Using Parallel Coordinates",
    Edward Wegman, Journal of the American Statistical Association,
    85, 664-675.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    2003/3
    2003/5: Added the GROUP PARALLEL COORDINATE PLOT case.
 
Program:
    ROW LIMITS 26 50
    COLUMN LIMITS 20 132
    READ AUTO79.DAT Y1 TO Y9
    .
    YLIMITS 0 8
    MAJOR YTIC MARK NUMBER 9
    MINOR YTIC MARK NUMBER 0
    Y1TIC MARK LABEL FORMAT ALPHA
    Y1TIC MARK LABEL CONTENT PRICE MPG 1978SP()REPAIR 1977SP()REPAIR ...
    HEADSP()ROOM REARSP()SEATCR()ROOM TRUNKSP()SPACE WEIGHT LENGTH
    YGRID ON
    TIC OFFSET UNITS SCREEN
    TIC OFFSET 3 3
    .
    PRE-SORT OFF
    FRAME CORNER COORDINATES 20 20 90 90
    PARALLEL COORDINATES PLOT Y1 TO Y9

-----PARAMETER EXPANSION (SET)---------------------------------------
 
PARAMETER EXPANSION
 
Name:
    PARAMETER EXPANSION (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify whether parameters substituted for by the "^"
    character are expanded into a numeric or exponential format.
 
Description:
    The "^" is normally used to substitute parameters into text
    strings for various types of labels.  For this reason, a
    limited amount of precision is maintained.

    The "^" can also be used to define a constant in a fit.  In
    this case, more precision may be necessary.  Setting 
    PARAMETER EXPANSION to EXPONENTIAL will substitute the 
    number as 
         (0.number*10**(exp))
    where number and exp are the values for the number in
    scientific notation.

    In brief, setting this parameter to EXPONENTIAL is
    sometimes needed for fits.  For all other purposes, you
    typically want this parameter set to NUMERIC.
 
Syntax:
    SET PARAMETER EXPANSION <value>
    where <value> is NUMERIC or EXPONENTIAL.
 
Examples:
    SET PARAMETER EXPANSION EXPONENTIAL
    SET PARAMETER EXPANSION NUMERIC
 
Default:
    The default is NUMERIC.
 
Synonyms:
    None
 
Related Commands:
    ^        = Substitution character.
    FIT      = Perform linear and non-linear fits.
 
Applications:
    Fitting
 
Implementation Date:
    2000/1
 
Program:
    read richter.nice1 x y
    .
    set parameter expansion exponential
    let pii = 3.141592654
    let ee = 1.602177*(10**(-19))
    let h = 6.6260755*(10**(-34))
    let hb = h/(2*pii)
    let sn = (ee*ee)/(pii*h)
    .
    .
    let me = 9.10939*(10**(-31))
    let mstar = 0.067*me
    .
    let minsig = 0.0028308966
    let ns = 3.342*(10**(15))
    let mobility = minsig/(ee*ns)
    let taue = mstar*mobility/ee
    let kfermi = sqrt(2*pii*ns)
    let vfermi = kfermi*(hb/mstar)
    let d = (vfermi*vfermi*taue)/2.0
    .
    .
    let taup = 5
    let x0 = 9.36*(10**(-6))
    .
    let function arg1 = (^hb)/(4*(^d)*(^ee)*(taup*(10**(-11)))*abs(x-x0))
    let function arg2 = (^hb)/(4*(^d)*(^ee)*(^taue)*abs(x-x0))
    let function arg3 = (taup*(10**(-11)))/(^taue)
    .
    let function f0 = (digamma(0.5+arg1)-digamma(0.5+arg2)+log(arg3))
    let function f = (^sn)*(f0)+(^minsig)
    .
    fit y=f
 
-----PARAMETER EXPAND DIGITS (SET)---------------------------------------
 
PARAMETER EXPAND DIGITS
 
Name:
    PARAMETER EXPAND DIGITS (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify the number of digits to the right of the decimal point
    when parameters are substituted by the "^" keyword.
 
Description:
    The "^" is normally used to substitute parameters into text strings
    for various types of labels.  For this reason, a limited amount of
    precision is maintained.  The "^" can also be used to define a
    constant in a fit.  In this case, more precision may be necessary.

    The SET PARAMETER EXPAND DIGITS command can be used to specify
    exactly how many digits to use after the decimal point.  Note that
    trailing digits will be included.

Syntax:
    SET PARAMETER EXPAND DIGITS <value>
    where <value> is a numeric value.

    If <value> is -1, then Dataplot will automatically determine the
    number of digits to use.  If <value> is 0, the parameter will be
    expanded to an integer value.  If <value> is a positive integer
    value, then the parameter will be expanded with <value> digits to
    the right of the decimal point.
 
Examples:
    SET PARAMETER EXPAND DIGITS 8
    SET PARAMETER EXPAND DIGITS -1
 
Note:
    The command SET PARAMETER EXPANSION EXPONENTIAL can be used to expand
    the parameter in exponential format.  This can be useful when
    expanding the parameter in numerical computations (e.g., fitting).

Note:
    The 2016/05 version of Dataplot expanded the default parameter
    expansion to handle up to 9 digits (prior to this, the limit was
    6 digits).

    The 2016/05 version also increased the number of digits that can be
    used by the SET PARAMETER EXPAND DIGITS command from 9 to 15.

    One distinction is that the default expansion does not include
    trailing zeros.  If the SET PARAMETER EXPAND DIGITS command is used,
    trailing zeros will be included.

Default:
    The default is -1 (i.e., Dataplot automatically determines the
    number of digits to use).
 
Synonyms:
    None
 
Related Commands:
    ^                            = Substitution character.
    PARAMETER EXPANDSION (SET)   = Specify whether parameter expansions
                                   are generated in real format or
                                   exponential format.
 
Applications:
    Plot Labeling
 
Implementation Date:
    2005/02<BR>
    2016/05: Increase maximum number of digits from 9 to 15.<BR>

 
Program:
    let a = .0001
    print "a = ^a"
    .
    let a = .00001
    print "a = ^a"
    .
    let a = .000001
    print "a = ^a"
    .
    let a = .0000001
    print "a = ^a"
    .
    let a = .00000001
    print "a = ^a"
    .
    let a = .000000001
    print "a = ^a"
    .
    let a = .0000000001
    print "a = ^a"
    .
    set parameter expand digits 9
    let a = .000000001
    print "a = ^a"
    .
    set parameter expand digits 10
    let a = .0000000001
    print "a = ^a"
    .
    set parameter expand digits 12
    let a = .000000000001
    print "a = ^a"
 
-----PARCDF (LET)--------------------------------
 
PARCDF
 
Name:
    PARCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Pareto cumulative distribution function with
    shape parameters gamma and a.
 
Description:
    The standard form of the Pareto cumulative distrubution
    function is:

       F(x;gamma,a) = 1 - (a/x)**gamma     x >= a;   a, gamma > 0

    with gamma and a denoting the tail length shape parameter
    and the lower bound parameter, respectively.

    Note that although the a parameter is typically called a
    location parameter (and it is in the sense that it defines
    the lower bound), it is not a location parameter in the
    technical sense that the following relation does not hold:
    
       f(x;gamma,a) = f((x-a);gamma,0)

    with f denoting the probability density function.

    For this reason, Dataplot treats a as a shape parameter.
    In Dataplot, the a shape parameter is optional with a
    default value of 1.
 
Syntax:
    LET <y> = PARCDF(<x>,<gamma>,<a>,<loc>,<scale>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <gamma> is a number or parameter that specifies the
               tail length shape parameter;
          <a> is a number or parameter that specifies the
               optional lower bound shape parameter;
          <loc> is a number or parameter that specifies the
               optional location parameter;
          <scale> is a number or parameter that specifies the
               optional scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Pareto cdf value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The a, loc, and scale parameters are all optional.

Examples:
    LET A = PARCDF(3,1.5)
    LET A = PARCDF(3,1.5,2)
    LET Y = PARCDF(X,GAMMA,A,LOC,SCALE)
 
Note:
    The Pareto cumulative distribution can be extended with
    location and scale parameters by using the relationship

       F(x;gamma,a,loc,scale) = F((x-loc)/scale;gamma,a,0,1)

    Since a defines the lower bound, the location parameter is
    typically set to zero.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PARPDF = Compute the Pareto probability density function.
    PARPPF = Compute the Pareto percent point function.
    GEPPDF = Compute the generalized Pareto probability density
             function.
    EV1PDF = Compute the extreme value type I probability density
             function.
    WEIPDF = Compute the Weibull probability density function.
    EXPPDF = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, chapter 19.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/4
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    CASE ASIS
    TITLE CASE ASIS
    LABEL CASE ASIS
    TITLE DISPLACEMENT 2
    Y1LABEL DISPLACEMENT 15
    X1LABEL DISPLACEMENT 12
    Y1LABEL Probability
    X1LABEL X
    .
    TITLE Gamma = 1
    PLOT PARCDF(X,1) FOR X = 1 0.1 10
    TITLE Gamma = 2
    PLOT PARCDF(X,2) FOR X = 1 0.1 10
    TITLE Gamma = 5
    PLOT PARCDF(X,5) FOR X = 1 0.1 10
    TITLE Gamma = 0.5
    PLOT PARCDF(X,0.5) FOR X = 1 0.1 10
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT Pareto CDF Functions
 
-----PARCHAZ (LET)--------------------------------
 
PARCHAZ
 
Name:
    PARCHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Pareto cumulative hazard function with shape
    parameters gamma and a.
 
Description:
    The standard form of the Pareto cumulative hazard function
    is:

       H(x;gamma,a) = gamma*LOG(x/a)     x >= a;   a, gamma > 0

    with gamma and a denoting the tail length shape parameter
    and the lower bound parameter, respectively.

    Note that although the a parameter is typically called a
    location parameter (and it is in the sense that it defines
    the lower bound), it is not a location parameter in the
    technical sense that the following relation does not hold:

       H(x;gamma,a) = H((x-a);gamma,0)

    with H denoting the cumulative hazard function.

    For this reason, Dataplot treats a as a shape parameter.
    In Dataplot, the a shape parameter is optional with a
    default value of 1.
 
Syntax:
    LET <y> = PARCHAZ(<x>,<gamma>,<a>,<loc>,<scale>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <gamma> is a number or parameter that specifies the
               tail length shape parameter;
          <a> is a number or parameter that specifies the
               optional lower bound shape parameter;
          <loc> is a number or parameter that specifies the
               optional location parameter;
          <scale> is a number or parameter that specifies the
               optional scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Pareto cumulative hazard value
               is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
   The a, loc, and scale parameters are all optional.

Examples:
    LET A = PARCHAZ(3,1.5)
    LET A = PARCHAZ(3,1.5,2)
    LET Y = PARCHAZ,GAMMA,A,LOC,SCALE)
    PLOT PARCHAZ(X,GAMMA,A,LOC,SCALE) FOR X = XSTART  0.01  XSTOP
 
Note:
    The Pareto cumulative hazard function can be extended with
    location and scale parameters by using the relationship

        H(x;gamma,a,loc,scale) = H((x-loc)/scale;gamma,a,0,1)

    Since a defines the lower bound, the location parameter is
    typically set to zero.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PARCDF = Compute the Pareto cumulative distribution function.
    PARHAZ = Compute the Pareto hazard function.
    PARPDF = Compute the Pareto probability density function.
    PARPPF = Compute the Pareto percent point function.
    GEPPDF = Compute the generalized Pareto probability density
             function.
    EV1PDF = Compute the extreme value type I probability density
             function.
    WEIPDF = Compute the Weibull probability density function.
    EXPPDF = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, chapter 19.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1998/4
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    CASE ASIS
    TITLE CASE ASIS
    LABEL CASE ASIS
    TITLE DISPLACEMENT 2
    Y1LABEL DISPLACEMENT 15
    X1LABEL DISPLACEMENT 12
    Y1LABEL Cumulative Hazard
    X1LABEL X
    .
    TITLE Gamma = 1
    PLOT PARCHAZ(X,1) FOR X = 1 0.1 10
    TITLE Gamma = 2
    PLOT PARCHAZ(X,2) FOR X = 1 0.1 10
    TITLE Gamma = 5
    PLOT PARCHAZ(X,5) FOR X = 1 0.1 10
    TITLE Gamma = 0.5
    PLOT PARCHAZ(X,0.5) FOR X = 1 0.1 10
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT Pareto Cumulative Hazard Functions
 
-----PARETO PLOT---------------------------------------------------
 
PARETO PLOT
 
Name:
    PARETO PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a Pareto plot.
 
Description:
    A Pareto plot is an ordered (largest to smallest) histogram with
    carry-along tags.  The Pareto plot is used to answer the question--
    "Which data values are most important, and which are least
    important?".  The Pareto plot consists of:
       Vertical   axis = ordered response value;
       Horizontal axis = dummy index (1 to n) where n is the number of
                         response values.
    Like usual, the appearance of the trace is controlled by the first
    setting of the LINES, CHARACTERS, SPIKES, BARS, and similar
    attributes.
 
Syntax:
    PARETO PLOT   <y>    <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    PARETO PLOT Y
    PARETO PLOT Y1
    PARETO PLOT Y SUBSET LAB 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS         = Sets the type for plot characters.
    CHARACTER FILL     = Sets the fill switch (on/off) for characters.
    CHARACTER OFFSET   = Sets the horizontal and vertical offset for
                         characters.
    CHARACTER ANGLE    = Sets the angle for characters
    LINES              = Sets the type for plot lines.
    SPIKES             = Sets the on/off switches for plot spikes.
    BARS               = Sets the on/off switches for plot bars.
    BAR FILL           = Sets the on/off switches for plot bar fills.
    BAR DIMENSION      = Sets the dimension (2 or 3) for bars.
    BAR WIDTH          = Sets the widths for plot bars.
    FONT               = Sets the font.
 
Applications:
    Quality Management
 
Implementation Date:
    88/9
 
Program:
    LET Y = DATA 9 4 13 11 19 8 11 10
    CHARACTERS CA FL IL MA NE NY OR TX
    CHARACTERS OFFSET 2 2 ALL
    CHARACTER ANGLE 45 ALL
    SPIKE ON ALL
    TITLE 1986 AUTO GAS TAX
    PARETO PLOT Y
 
-----PARHAZ (LET)--------------------------------
 
PARHAZ
 
Name:
    PARHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Pareto hazard function with shape parameters
    gamma and a.
 
Description:
    The standard form of the Pareto hazard function is:

       h(x;gamma,a) = gamma/x          x >= a;   a, gamma > 0

    with gamma and a denoting the tail length shape parameter
    and the lower bound parameter, respectively.

    Note that although the a parameter is typically called a
    location parameter (and it is in the sense that it defines
    the lower bound), it is not a location parameter in the
    technical sense that the following relation does not hold:
    
       h(x;gamma,a) = h((x-a);gamma,0)

    with h denoting the hazard function.

    For this reason, Dataplot treats a as a shape parameter.
    In Dataplot, the a shape parameter is optional with a
    default value of 1.
 
Syntax:
    LET <y> = PARHAZ(<x>,<gamma>,<a>,<loc>,<scale>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <gamma> is a number or parameter that specifies the
               tail length shape parameter;
          <a> is a number or parameter that specifies the
               optional lower bound shape parameter;
          <loc> is a number or parameter that specifies the
               optional location parameter;
          <scale> is a number or parameter that specifies the
               optional scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Pareto hazard value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The a, loc, and scale parameters are all optional.

Examples:
    LET A = PARHAZ(3,1.5)
    LET A = PARHAZ(3,1.5,2)
    LET Y = PARHAZ,GAMMA,A,LOC,SCALE)
    PLOT PARHAZ(X,GAMMA,A,LOC,SCALE) FOR X = XSTART  0.01  XSTOP
 
Note:
    The Pareto hazard function can be extended with location and
    scale parameters by using the relationship

       h(x;gamma,a,loc,scale) = (1/scale)*
                                h((x-loc)/scale;gamma,a,0,1)

    Since a defines the lower bound, the location parameter is
    typically set to zero.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PARCDF = Compute the Pareto cumulative distribution function.
    PARPDF = Compute the Pareto probability density function.
    PARPPF = Compute the Pareto percent point function.
    GEPPDF = Compute the generalized Pareto probability density
             function.
    EV1PDF = Compute the extreme value type I probability density
             function.
    WEIPDF = Compute the Weibull probability density function.
    EXPPDF = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, chapter 19.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1998/4
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    CASE ASIS
    TITLE CASE ASIS
    LABEL CASE ASIS
    TITLE DISPLACEMENT 2
    Y1LABEL DISPLACEMENT 15
    X1LABEL DISPLACEMENT 12
    Y1LABEL Hazard
    X1LABEL X
    .
    TITLE Gamma = 1
    PLOT PARHAZ(X,1) FOR X = 1 0.1 10
    TITLE Gamma = 2
    PLOT PARHAZ(X,2) FOR X = 1 0.1 10
    TITLE Gamma = 5
    PLOT PARHAZ(X,5) FOR X = 1 0.1 10
    TITLE Gamma = 0.5
    PLOT PARHAZ(X,0.5) FOR X = 1 0.1 10
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT Pareto Hazard Functions
 
-----PARPDF (LET)--------------------------------
 
PARPDF
 
Name:
    PARPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Pareto probability density function with
    shape parameters gamma and a.
 
Description:
    The standard form of the Pareto probability density
    function is:

       f(x;gamma,a) = gammaa*a**gamma/(x**(gamma+1))
                      x >= a, a, gamma > 0

    with gamma and a denoting the tail length shape parameter
    and the lower bound parameter, respectively.  The default
    value of a is 1.

    Note that although the a parameter is typically called a
    location parameter (and it is in the sense that it defines
    the lower bound), it is not a location parameter in the
    technical sense that the following relation does not hold:
    
       f(x;gamma,a) = f((x-a);gamma,0)

    For this reason, Dataplot treats a as a shape parameter.
    In Dataplot, the a shape parameter is optional with a
    default value of 1.
 
Syntax:
    LET <y> = PARPDF(<x>,<gamma>,<a>,<loc>,<scale>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <gamma> is a number or parameter that specifies the
               tail length shape parameter;
          <a> is a number or parameter that specifies the
               optional lower bound shape parameter;
          <loc> is a number or parameter that specifies the
               optional location parameter;
          <scale> is a number or parameter that specifies the
               optional scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Pareto pdf value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The a, loc, and scale parameters are all optional.

Examples:
    LET A = PARPDF(3,1.5)
    LET A = PARPDF(3,1.5,2)
    LET Y = PARPDF(X,GAMMA,A,LOC,SCALE)
    PLOT PARPDF(X,GAMMA,A,LOC,SCALE) FOR X = XSTART  0.01  XSTOP
 
Note:
    The Pareto distribution can be extended with location and
    scale parameters by using the relationship

       f(x;gamma,a,loc,scale) = (1/scale)*f(x;gamma,a,0,1)

    Since a defines the lower bound, the location parameter is
    typically set to zero.

Note:
    Pareto random numbers, probability plots, and goodness
    of fit tests can be generated with the commands:

       LET GAMMA = <value>
       LET A = <value>
       LET Y = PARETO RANDOM NUMBERS FOR I = 1 1 N
       PARETO PROBABILITY PLOT Y
       PARETO PROBABILITY PLOT Y X
       PARETO PROBABILITY PLOT Y XLOW XHIGH
       PARETO KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       PARETO CHI-SQUARE GOODNESS OF FIT Y X
       PARETO CHI-SQUARE GOODNESS OF FIT Y XLOW XHIGH

    The following commands can be used to estimate the shape
    parameters for the Pareto distribution:

       LET GAMMA1 = <value>
       LET GAMMA2 = <value>
       LET A = <value>
       PARETO PPCC PLOT Y
       PARETO PPCC PLOT Y X
       PARETO PPCC PLOT Y XLOW XHIGH
       PARETO KS PLOT Y
       PARETO KS PLOT Y X
       PARETO KS PLOT Y XLOW XHIGH

    The default values for gamma1 and gamma2 are 0.2 and 10,
    respectively.  Note that only the gamma parameter is
    estimated for these plots.  The default value of A is 1.
    If the value of A is greater than the data minimum, then
    it is automatically set to the data minimum.

    You can generate maximum likelihood estimates for the Pareto
    distribution with the command

        PARETO MAXIMUM LIKELIHOOD Y

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PARCDF = Compute the Pareto cumulative distribution function.
    PARPPF = Compute the Pareto percent point function.
    GEPPDF = Compute the generalized Pareto probability density
             function.
    EV1PDF = Compute the extreme value type I probability density
             function.
    WEIPDF = Compute the Weibull probability density function.
    EXPPDF = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, chapter 19.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/4
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    CASE ASIS
    TITLE CASE ASIS
    LABEL CASE ASIS
    TITLE DISPLACEMENT 2
    Y1LABEL DISPLACEMENT 15
    X1LABEL DISPLACEMENT 12
    Y1LABEL Probability Density
    X1LABEL X
    .
    TITLE Gamma = 1
    PLOT PARPDF(X,1) FOR X = 1 0.1 10
    TITLE Gamma = 2
    PLOT PARPDF(X,2) FOR X = 1 0.1 10
    TITLE Gamma = 5
    PLOT PARPDF(X,5) FOR X = 1 0.1 10
    TITLE Gamma = 0.5
    PLOT PARPDF(X,0.5) FOR X = 1 0.1 10
    END OF MULTIPLOT
    .
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT Pareto PDF Functions
 
-----PARPPF (LET)--------------------------------
 
PARPPF
 
Name:
    PARPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Pareto percent point function with shape
    parameters gamma and a.
 
Description:
    The standard form of the Pareto percent point function is:

       G(p;gamma,a) = a*(1-p)**(-1/gamma)    0 <= p < 1;
                                             a, gamma > 0

    with gamma and a denoting the tail length shape parameter
    and the lower bound parameter, respectively.  The default
    value of a is 1.

    Note that although the a parameter is typically called a
    location parameter (and it is in the sense that it defines
    the lower bound), it is not a location parameter in the
    technical sense that the following relation does not hold:
    
       G(p;gamma,a) = a + G(p;gamma,0)

    For this reason, Dataplot treats a as a shape parameter.
    In Dataplot, the a shape parameter is optional with a
    default value of 1.
 
Syntax:
    LET <y> = PARPPF(<p>,<gamma>,<a>,<loc>,<scale>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, a number, or a parameter in the
               interval (0,1);
          <gamma> is a number or parameter that specifies the
               tail length shape parameter;
          <a> is a number or parameter that specifies the
               optional lower bound shape parameter;
          <loc> is a number or parameter that specifies the
               optional location parameter;
          <scale> is a number or parameter that specifies the
               optional scale parameter;
          <y> is a variable or a parameter (depending on what <p>
               is) where the computed Pareto ppf value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PARPPF(0.95,1.5)
    LET A = PARPPF(0.95,1.5,2)
    LET Y = PARPPF(P,GAMMA,A,LOC,SCALE)
    PLOT PARPPF(P,GAMMA,A,LOC,SCALE) FOR P = 0  0.01  0.99
 
Note:
    The Pareto percent point function can be extended with
    location and scale parameters by using the relationship

       G(p;gamma,a,loc,scale) = loc + scale*G(p;gamma,a,0,1)

    Since a defines the lower bound, the location parameter is
    typically set to zero.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PARCDF = Compute the Pareto cumulative distribution function.
    PARPDF = Compute the Pareto probability density function.
    GEPPDF = Compute the generalized Pareto probability density
             function.
    EV1PDF = Compute the extreme value type I probability density
             function.
    WEIPDF = Compute the Weibull probability density function.
    EXPPDF = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, chapter 19.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/4
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    CASE ASIS
    TITLE CASE ASIS
    LABEL CASE ASIS
    TITLE DISPLACEMENT 2
    Y1LABEL DISPLACEMENT 15
    X1LABEL DISPLACEMENT 12
    X1LABEL Probability
    Y1LABEL X
    .
    TITLE Gamma = 1
    PLOT PARPPF(P,1) FOR P = 0  0.01  0.99
    TITLE Gamma = 2
    PLOT PARPPF(P,2) FOR P = 0  0.01  0.99
    TITLE Gamma = 5
    PLOT PARPPF(P,5) FOR P = 0  0.01  0.99
    TITLE Gamma = 0.5
    PLOT PARPPF(P,0.5) FOR P = 0  0.01  0.99
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT Pareto PPF Functions
 
-----PA2CDF (LET)--------------------------------
 
PA2CDF
 
Name:
    PA2CDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Pareto cumulative distribution of the second
    kind with shape parameters gamma and a.
 
Description:
    The standard form of the Pareto cumulative distribution
    function of the second kind is:

       F(x;gamma,a) = 1 - a**gamma/(x+a)**gamma
                      x, gamma, a > 0
 
    with gamma and a denoting the shape parameters.  The a
    parameter is optional and has a default value of 1.

    The Pareto distribution of the second kind is sometimes
    referred to as the Lomax distribution.

Syntax:
    LET <y> = PA2CDF(<x>,<gamma>,<a>,<loc>,<scale>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <gamma> is a number or parameter that specifies the
               tail length shape parameter;
          <a> is a number or parameter that specifies the
               optional lower bound shape parameter;
          <loc> is a number or parameter that specifies the
               optional location parameter;
          <scale> is a number or parameter that specifies the
               optional scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Pareto cdf value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The a, loc, and scale parameters are all optional.
 
Examples:
    LET A = PA2CDF(3,1.5)
    LET X2 = PA2CDF(X1,GAMMA)
 
Note:
    The Pareto cumulative distribution of the second kind can
    be extended with location and scale parameters by using the
    relationship

       F(x;gamma,a,loc,scale) = F((x-loc)/scale;gamma,a,0,1)
 
Note:
    Johnson, Kotz, and Balakrishnan (see Reference section below)
    define Pareto distributions of the first, second, third, and
    fourth kinds.  Dataplot supports Pareto distributions of the
    first and second kinds.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PA2PDF = Compute the Pareto second kind probability density
             function.
    PA2PPF = Compute the Pareto second kind percent point function.
    PARPDF = Compute the Pareto probability density function.
    GEPPDF = Compute the generalized Pareto probability density
             function.
    EV1PDF = Compute the extreme value type I probability density
             function.
    WEIPDF = Compute the Weibull probability density function.
    NORPDF = Compute the normal probability density function.
    LGNPDF = Compute the lognormal probability density function.
    EXPPDF = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", 2nd. Ed.,
    Johnson, Kotz, and Balakrishnan, John Wiley, 1994, (chapter 20).
 
Applications:
    Distributional Modeling, Income Distributions
 
Implementation Date:
    1995/10
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    CASE ASIS
    TITLE CASE ASIS
    LABEL CASE ASIS
    TITLE DISPLACEMENT 2
    Y1LABEL DISPLACEMENT 15
    X1LABEL DISPLACEMENT 12
    Y1LABEL Probability
    X1LABEL X
    .
    LET A = 1
    TITLE Gamma = 0.1
    PLOT PA2CDF(X,0.1,A) FOR X = 0.01  0.01  5
    TITLE Gamma = 1
    PLOT PA2CDF(X,1,A) FOR X = 0.01  0.01  5
    TITLE Gamma = 2
    PLOT PA2CDF(X,2,A) FOR X = 0.01  0.01  5
    TITLE Gamma = 5
    PLOT PA2CDF(X,5,A) FOR X = 0.01  0.01  5
    END OF MULTIPLOT
    .
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT Pareto Second Kind CDF Functions
 
-----PA2PDF (LET)--------------------------------
 
PA2PDF
 
Name:
    PA2PDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Pareto probability density function of the second
    kind with shape parameters gamma and a.
 
Description:
    The standard form of the Pareto probability density function
    of the second kind is:

       f(x;gamma,a) = gamma*a**gamma/((a+x)**(gamma+1))
                      x, gamma > 0
 
    with gamma and a denoting the shape parameters.  The a
    parameter is optional and has a default value of 1.

    The Pareto distribution of the second kind is sometimes
    referred to as the Lomax distribution.

Syntax:
    LET <y> = PA2PDF(<x>,<gamma>,<a>,<loc>,<scale>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <gamma> is a number or parameter that specifies the
               tail length shape parameter;
          <a> is a number or parameter that specifies the
               optional second shape parameter;
          <loc> is a number or parameter that specifies the
               optional location parameter;
          <scale> is a number or parameter that specifies the
               optional scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Pareto pdf value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The a, loc, and scale parameters are all optional.
 
Examples:
    LET A = PA2PDF(3,1.5)
    LET A = PA2PDF(3,1.5,0.5)
    LET X2 = PA2PDF(X1,GAMMA,A)
    PLOT PA2PDF(X,GAMMA,A) FOR X = 0  0.01  10
 
Note:
    The Pareto distribution of the second kind can be extended with
    location and scale parameters by using the relationship

       f(x;gamma,a,loc,scale) = (1/scale)*f(x;gamma,a,0,1)

Note:
    Pareto second kind random numbers, probability plots, and
    goodness of fit tests can be generated with the commands:

       LET GAMMA = <value>
       LET A = <value>
       LET Y = PARETO SECOND KIND RANDOM NUMBERS FOR I = 1 1 N
       PARETO SECOND KIND PROBABILITY PLOT Y
       PARETO SECOND KIND PROBABILITY PLOT Y X
       PARETO SECOND KIND PROBABILITY PLOT Y XLOW XHIGH
       PARETO SECOND KIND KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       PARETO SECOND KIND CHI-SQUARE GOODNESS OF FIT Y X
       PARETO SECOND KIND CHI-SQUARE GOODNESS OF FIT Y XLOW XHIGH

    The following commands can be used to estimate the shape
    parameters for the Pareto distribution of the second kind:

       LET GAMMA1 = <value>
       LET GAMMA2 = <value>
       LET A = <value>
       PARETO SECOND KIND PPCC PLOT Y
       PARETO SECOND KIND PPCC PLOT Y X
       PARETO SECOND KIND PPCC PLOT Y XLOW XHIGH
       PARETO SECOND KIND KS PLOT Y
       PARETO SECOND KIND KS PLOT Y X
       PARETO SECOND KIND KS PLOT Y XLOW XHIGH

    The default values for gamma1 and gamma2 are 0.2 and 10,
    respectively.  Note that only the gamma parameter is
    estimated for these plots.  The default value of A is 1.

Note:
    Johnson, Kotz, and Balakrishnan (see Reference section below)
    define Pareto distributions of the first, second, third, and
    fourth kinds.  Dataplot supports Pareto distributions of the
    first and second kinds.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PA2CDF = Compute the Pareto second kind cumulative
             distribution function.
    PA2PPF = Compute the Pareto second kind percent point function.
    PARPDF = Compute the Pareto probability density function.
    GEPPDF = Compute the generalized Pareto probability density
             function.
    EV1PDF = Compute the extreme value type I probability density
             function.
    WEIPDF = Compute the Weibull probability density function.
    NORPDF = Compute the normal probability density function.
    LGNPDF = Compute the lognormal probability density function.
    EXPPDF = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", 2nd. Ed.,
    Johnson, Kotz, and Balakrishnan, John Wiley, 1994, (chapter 20).
 
Applications:
    Distributional Modeling, Income Distributions
 
Implementation Date:
    1995/10
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    CASE ASIS
    TITLE CASE ASIS
    LABEL CASE ASIS
    TITLE DISPLACEMENT 2
    Y1LABEL DISPLACEMENT 15
    X1LABEL DISPLACEMENT 12
    Y1LABEL Probability Density
    X1LABEL X
    .
    LET A = 1
    TITLE Gamma = 0.1
    PLOT PA2PDF(X,0.1,A) FOR X = 0.01  0.01  5
    TITLE Gamma = 1
    PLOT PA2PDF(X,1,A) FOR X = 0.01  0.01  5
    TITLE Gamma = 2
    PLOT PA2PDF(X,2,A) FOR X = 0.01  0.01  5
    TITLE Gamma = 5
    PLOT PA2PDF(X,5,A) FOR X = 0.01  0.01  5
    END OF MULTIPLOT
    .
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT Pareto Second Kind PDF Functions
 
-----PA2PPF (LET)--------------------------------
 
PA2PPF
 
Name:
    PA2PPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Pareto percent point function of the second
    kind with shape parameters gamma and a.
 
Description:
    The standard form of the Pareto percent point function of
    the second kind is:

       G(p;gamma,a) = (a**gamma/(1-p))**(1/gamma) - a
                      0 < p < 1; gamma, a > 0
 
    with gamma and a denoting the shape parameters.  The a
    parameter is optional and has a default value of 1.

    The Pareto distribution of the second kind is sometimes
    referred to as the Lomax distribution.

Syntax:
    LET <y> = PA2PPF(<p>,<gamma>,<a>,<loc>,<scale>)
                         <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, a number, or a parameter in the
               interval (0,1);
          <gamma> is a number or parameter that specifies the
               tail length shape parameter;
          <a> is a number or parameter that specifies the
               optional lower bound shape parameter;
          <loc> is a number or parameter that specifies the
               optional location parameter;
          <scale> is a number or parameter that specifies the
               optional scale parameter;
          <y> is a variable or a parameter (depending on what <p> is)
               where the computed Pareto ppf value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The a, loc, and scale parameters are all optional.
 
Examples:
    LET A = PA2PPF(0.95,1.5)
    LET X2 = PA2PPF(X1,GAMMA)
    LET X2 = PA2PPF(X1,GAMMA,A)
    PLOT PA2PPF(X,GAMMA,A) FOR P = 0.01  0.01  0.99
 
Note:
    The Pareto percent point of the second kind can be extended
    with location and scale parameters by using the relationship

       G(p;gamma,a,loc,scale) = loc + scale*G(p;gamma,a,0,1)
 
Note:
    Johnson, Kotz, and Balakrishnan (see Reference section below)
    define Pareto distributions of the first, second, third, and
    fourth kinds.  Dataplot supports Pareto distributions of the
    first and second kinds.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PA2CDF = Compute the Pareto second kind cumulative
             distribution function.
    PA2PDF = Compute the Pareto second kind probability density
             function.
    PARPDF = Compute the Pareto probability density function.
    GEPPDF = Compute the generalized Pareto probability density
             function.
    EV1PDF = Compute the extreme value type I probability density
             function.
    WEIPDF = Compute the Weibull probability density function.
    NORPDF = Compute the normal probability density function.
    LGNPDF = Compute the lognormal probability density function.
    EXPPDF = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", 2nd. Ed.,
    Johnson, Kotz, and Balakrishnan, John Wiley, 1994, (chapter 20).
 
Applications:
    Distributional Modeling, Income Distributions
 
Implementation Date:
    1995/10
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    CASE ASIS
    TITLE CASE ASIS
    LABEL CASE ASIS
    TITLE DISPLACEMENT 2
    Y1LABEL DISPLACEMENT 15
    X1LABEL DISPLACEMENT 12
    X1LABEL Probability
    Y1LABEL X
    .
    LET A = 1
    TITLE Gamma = 0.1
    PLOT PA2PPF(P,0.1,A) FOR P = 0.01  0.01  0.99
    TITLE Gamma = 1
    PLOT PA2PPF(P,1,A) FOR P = 0.01  0.01  0.99
    TITLE Gamma = 2
    PLOT PA2PPF(P,2,A) FOR P = 0.01  0.01  0.99
    TITLE Gamma = 5
    PLOT PA2PPF(P,5,A) FOR P = 0.01  0.01  0.99
    END OF MULTIPLOT
    .
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT Pareto Second Kind PPF Functions
 
-----PARTIAL CORRELATION (LET)--------------------------------
 
PARTIAL CORRELATION
 
Name:
    PARTIAL CORRELATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the partial correlation coefficient between two variables
    given the effect of a third variable.
 
Description:
    The standard correlation coefficient is a measure of the linear
    relationship between two variables.  It is computed as:

         r = Sxy/SQRT(Sxx*Syy)

    where

         Sxx = SUM[i=1 to N][(X(i)-XMEAN)**2]
         Syy = SUM[i=1 to N][(Y(i)-YMEAN)**2]
         Sxy = SUM[i=1 to N][(X(i)-XMEAN)*(Y(i)-YMEAN)]

    A perfect linear relationship yields a correlation coefficient of
    +1 (or -1 for a negative relationship) and no linear relationship
    yields a correlation coefficient of 0.
 
    Partial correlation is the correlation between two variables
    after removing the effect of one or more additional variables.  This
    command is specifcally for the the case of one additional variable.
    In this case, the partial correlation can be computed based on
    standard correlations between the three variables as follows:

        r12.3 = (r12 - r13*r23)/SQRT((1 - r13**2)*(1 - r23**2))

    with rxy denoting the correlation between x and y.

    As with the standard correlation coefficient, a value of +1 indicates
    a perfect positive linear relationship, a value of -1 indicates a
    perfect negative linear relationship, and a value of 0 indicates no
    linear relationship.

    It may be of interest to determine if the partial correlation
    is significantly different than 0.  The CDF value for this
    test is

         CDF = FCDF(VAL,1,N-3)

    where FCDF is the F cumulative distribution function with
    1 and N - 3 degrees of freedom (N is the number of observations)
    and VAL = ABS((N-3)*R**2/(1 - R**2)) with R denoting the
    computed partial correlation.  The pvalue is 1 - CDF.

Syntax 1:
    LET <par> = PARTIAL CORRELATION <y1> <y2> <y3>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <y3> is the third response variable;
          <par> is a parameter where the computed partial correlation is
               saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <par> = PARTIAL CORRELATION ABSOLUTE VALUE <y1> <y2> <y3>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <y3> is the third response variable;
          <par> is a parameter where the absolute value of the computed
               partial correlation is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the absolute value of the partial correlation
    coefficient.  This is typically used in screening applications where
    there is an interest in identifying high magnitude correlations
    regardless of the direction of the correlation.

Syntax 3:
    LET <par> = PARTIAL CORRELATION PVALUE <y1> <y2> <y3>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <y3> is the third response variable;
          <par> is a parameter where the computed partial correlation
               pvalue is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the pvalue (described above) of the partial
    correlation.

Syntax 4:
    LET <par> = PARTIAL CORRELATION CDF <y1> <y2> <y3>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <y3> is the third response variable;
          <par> is a parameter where the computed partial correlation
               cdf is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the cdf (described above) of the partial
    correlation.

Examples:
    LET A = PARTIAL CORRELATION Y1 Y2 Z
    LET A = PARTIAL CORRELATION Y1 Y2 Z  SUBSET TAG > 2
    LET A = PARTIAL CORRELATION ABSOLUTE VALUE Y1 Y2 Z
    LET A = PARTIAL CORRELATION PVALUE Y1 Y2 Z
    LET A = PARTIAL CORRELATION CDF Y1 Y2 Z
 
Note:
    The three variables must have the same number of elements.
 
Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PARTIAL CORRELATION MATRIX       = Compute the matrix of partial
                                       correlations.
    PARTIAL RANK CORRELATION         = Compute the partial rank
                                       correlation.
    PARTIAL KENDALL TAU CORRELATION  = Compute the partial Kendall tau
                                       correlation.
    CORRELATION MATRIX               = Compute the matrix of correlations.
    CORRELATION                      = Compute the correlation.
    RANK CORRELATION                 = Compute the rank correlation.
    KENDALL TAU CORRELATION          = Compute the Kendall tau correlation.
 
Reference:
    Conover (1999), "Practical Nonparametric Statistics", Third Edition,
    Wiley, p. 327.
 
    Peavy, Bremer, Varner, Hogben (1986), "OMNITAB 80:
    An Interpretive System for Statistical and Numerical
    Data Analysis," NBS Special Publication 701.

Applications:
    Linear Regression
 
Implementation Date:
    2012/06
 
Program:
    .  This data is from page 202 of
    .
    .  Peavy, Bremer, Varner, Hogben (1986), "OMNITAB 80:
    .  An Interpretive System for Statistical and Numerical
    .  Data Analysis," NBS Special Publication 701.
    .
    .  Original source of the data is from
    .  Draper and Smith (1981), "Applied Regression Analysis",
    .  Wiley, p. 373.
    .
    dimension 40 columns
    .
    read matrix m
    42.2  11.2  31.9  167.1
    48.6  10.6  13.2  174.4
    42.6  10.6  28.7  160.8
    39.0  10.4  26.1  162.0
    34.7   9.3  30.1  140.8
    44.5  10.8   8.5  174.6
    39.1  10.7  24.3  163.7
    40.1  10.0  18.6  174.5
    45.9  12.0  20.4  185.7
    end of data
    .
    set write decimals 4
    let c1 = partial correlation m1 m2 m3
    let c2 = partial correlation absolute value m1 m2 m3
    let c3 = partial correlation cdf m1 m2 m3
    let c4 = partial correlation pvalue m1 m2 m3
    print c1 c2 c3 c4

-----PARTIAL CORRELATION MATRIX (LET)--------------------------------
 
PARTIAL CORRELATION MATRIX
 
Name:
    PARTIAL CORRELATION MATRIX (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the partial correlation matrix of a matrix.
 
Description:
    The partial correlation matrix computes the partial correlation
    coefficients of the columns of a matrix.  That is, row i and column j
    of the partial correlation matrix is the partial correlation between
    column i and column j of the original matrix.  This partial
    correlation between column i and column j is the correlation
    between these two columns after removing the effects of the
    remaining columns.  Note that the diagonal elements of the
    partial correlation matrix will be 1 (since they are the partial
    correlation of a column with itself).  The partial correlation matrix
    is also symmetric (since the partial correlation of column i with
    column j is the same as the partial correlation of column j with
    column i).

    The algorithm for computing the partial correlations is:

        1) Compute the standard correlation matrix.

        2) Invert this correlation matrix.

        3) Compute

              r(ij.) = -r(ij)/SQRT(r(ii)*r(jj))

           where r(ij) is the (i,j)-th element of the inverted
           correlation matrix.

    Alternatively, you can compute the CDF or the p-value for the
    partial correlation coefficients (i.e., to see if the partial
    correlation coefficient is significantly different than zero).
    The CDF value is

        CDF = FCDF(VAL,1,N-NC)

    where FCDF is the F cumulative distribution function with
    1 and N - NC degrees of freedom (N is the number of observations
    and NC is the number of columns in the input matrix), and

        VAL = ABS((N-NC)*R**2/(1 - R**2))

    with R denoting the computed partial correlation.  The pvalue is
    1 - CDF.

Syntax 1:
    LET <mat2> = PARTIAL CORRELATION MATRIX <mat1>
                 <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the partial correlations are to be
                 computed;
          <mat2> is a matrix where the resulting partial correlations are
                 saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
    rarely used in this context.
 
Syntax 2:
    LET <mat2> = PARTIAL CORRELATION CDF MATRIX <mat1>
                 <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the partial correlation CDF's are
                 to be computed;
          <mat2> is a matrix where the resulting partial correlation CDF's
                 are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
    rarely used in this context.
 
    This syntax computes the CDF's of the partial correlation
    coefficients.

Syntax 3:
    LET <mat2> = PARTIAL CORRELATION PVALUE MATRIX <mat1>
                 <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the partial correlation p-value's
                 are to be computed;
          <mat2> is a matrix where the resulting partial correlation
                 p-values's are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
    rarely used in this context.
 
    This syntax computes the p-values of the partial correlation
    coefficients.

Examples:
    LET C = PARTIAL CORRELATION MATRIX A
 
Note:
    By default, the partial correlation matrices are computed on the
    columns.  That is, element (i,j) of the partial correlation matrix
    is the partial correlation between column i and column j of the
    input matrix.

    To specify a partial correlation matrix based on rows rather than
    columns, enter the command 

         SET MATRIX CORRELATION DIRECTION ROW

    To reset column based partial correlations, enter

         SET MATRIX CORRELATION DIRECTION COLUMN

Note:
    By default the Pearson correlation coefficient is computed.
    To specify a different type of correlation, enter the command

        SET CORRELATION TYPE <DEFAULT/RANK/WINSORIZED/
            BIWEIGHT MIDCORRELATION/PERCENTAGE BEND/KENDALL TAU>

    To see the definitions for these, enter

        HELP RANK CORRELATION
        HELP KENDALLS TAU
        HELP BIWEIGHT MIDCORRELATION
        HELP PERCENTAGE BEND

Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 100 rows.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PARTIAL CORRELATION         = Compute the partial correlation of three
                                  variables.
    CORRELATION MATRIX          = Generate the correlation matrix.
    CORRELATION                 = Compute the correlation of two variables.
    RANK CORRELATION            = Compute the rank correlation of two
                                  variables.
    KENDALLS TAU                = Compute the Kendall tau correlation of two
                                  variables.
    WINSORIZED CORRELATION      = Compute the Winsorized correlation of two
                                  variables.
    BIWEIGHT MIDCORRELATION     = Compute the biweight mid-correlation of
                                  two variables.
    PERCENTAGE BEND CORRELATION = Compute the percentage bend correlation of
                                  two variables.
    COVARIANCE                  = Compute the covariance of two variables.
 
Applications:
    Linear Fitting
 
Implementation Date:
    2012/06
 
Program:
    .  This data is from page 202 of
    .
    .  Peavy, Bremer, Varner, Hogben (1986), "OMNITAB 80:
    .  An Interpretive System for Statistical and Numerical
    .  Data Analysis," NBS Special Publication 701.
    .
    .  Original source of the data is from
    .  Draper and Smith (1981), "Applied Regression Analysis",
    .  Wiley, p. 373.
    .
    dimension 40 columns
    .
    read matrix m
    42.2  11.2  31.9  167.1
    48.6  10.6  13.2  174.4
    42.6  10.6  28.7  160.8
    39.0  10.4  26.1  162.0
    34.7   9.3  30.1  140.8
    44.5  10.8   8.5  174.6
    39.1  10.7  24.3  163.7
    40.1  10.0  18.6  174.5
    45.9  12.0  20.4  185.7
    end of data
    .
    set write decimals 4
    let pcorr = partial correlation matrix m
    print pcorr
 
-----PARTIAL KENDALLS TAU CORRELATION (LET)------------------------------
 
PARTIAL KENDALLS TAU CORRELATION
 
Name:
    PARTIAL KENDALLS TAU (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the partial Kendall's tau correlation coefficient between
    two variables given the effect of a third variable.
 
Description:
    Kendall's tau coefficient is a measure of concordance
    between two paired variables.  Given the pairs (X(i),Y(i)) and
    (X(j),Y(j)), then

       (Y(j) - Y(i))/(X(j) - X(i)) > 0   - pair is concordant
       (Y(j) - Y(i))/(X(j) - X(i)) < 0   - pair is discordant
       (Y(j) - Y(i))/(X(j) - X(i)) = 0   - pair is considered a tie
       X(i) = X(j)                       - pair is not compared

    Kendall's tau is computed as

        tau = (Nc - Nd)/(Nc + Nd)

    with Nc and Nd denoting the number of concordant pairs and
    the number of discordant pairs, respectively, in the sample.
    Ties add 0.5 to both the concordant and discordant counts.
    There are (n 2) possible pairs in the bivariate sample.

    A perfect linear relationship between the ranks yields a
    Kendall's tau correlation coefficient of +1 (or -1 for a negative
    relationship) and no linear relationship between the ranks
    yields a rank correlation coefficient of 0.
 
    Partial Kendall's tau correlation is the Kendall's tau correlation
    between two variables after removing the effect of one or more
    additional variables.  This command is specifcally for the the case
    of one additional variable.  In this case, the partial Kendall's tau
    correlation can be computed based on standard Kendall's tau
    correlations between the three variables as follows:

        r12.3 = (r12 - r13*r23)/SQRT((1 - r13**2)*(1 - r23**2))

    with rxy denoting the Kendall's tau correlation between x and y.

    As with the standard Kendall's tau correlation coefficient, a value
    of +1 indicates a perfect positive linear relationship, a value of -1
    indicates a perfect negative linear relationship, and a value of 0
    indicates no linear relationship.

Syntax 1:
    LET <par> = PARTIAL KENDALLS TAU CORRELATION <y1> <y2> <y3>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <y3> is the third response variable;
          <par> is a parameter where the computed partial Kendall's
               tau correlation is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <par> = PARTIAL KENDALLS TAU CORRELATION ABSOLUTE VALUE
                <y1> <y2> <y3>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <y3> is the third response variable;
          <par> is a parameter where the absolute value of the computed
               partial Kendall's tau correlation absolute value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the absolute value of the partial Kendall's
    tau correlation coefficient.  This is typically used in screening
    applications where there is an interest in identifying high magnitude
    correlations regardless of the direction of the correlation.

Examples:
    LET A = PARTIAL KENDALLS TAU CORRELATION Y1 Y2 Z
    LET A = PARTIAL KENDALLS TAU CORRELATION Y1 Y2 Z  SUBSET TAG > 2
    LET A = PARTIAL KENDALLS TAU CORRELATION ABSOLUTE VALUE Y1 Y2 Z
 
Note:
    The three variables must have the same number of elements.
 
Note:
    The command PARTIAL CORRELATION MATRIX can be used to compute
    the matrix of partial correlations.  This command has options
    to compute several robust forms of the partial correlation
    including the Kendall's tau correlation discussed here.

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    KENDALL TAU CORRELATION          = Compute the Kendall tau correlation.
    RANK CORRELATION                 = Compute the rank correlation.
    PARTIAL CORRELATION              = Compute the partial correlation.
    PARTIAL RANK CORRELATION         = Compute the partial rank
                                       correlation.
    PARTIAL CORRELATION MATRIX       = Compute the matrix of partial
                                       correlations.
    CORRELATION MATRIX               = Compute the matrix of correlations.
    CORRELATION                      = Compute the correlation.
 
Reference:
    Conover (1999), "Practical Nonparametric Statistics", Third Edition,
    Wiley, p. 327.
 
    Peavy, Bremer, Varner, Hogben (1986), "OMNITAB 80:
    An Interpretive System for Statistical and Numerical
    Data Analysis," NBS Special Publication 701.

Applications:
    Linear Regression
 
Implementation Date:
    2012/06
 
Program:
    .  This data is from page 202 of
    .
    .  Peavy, Bremer, Varner, Hogben (1986), "OMNITAB 80:
    .  An Interpretive System for Statistical and Numerical
    .  Data Analysis," NBS Special Publication 701.
    .
    .  Original source of the data is from
    .  Draper and Smith (1981), "Applied Regression Analysis",
    .  Wiley, p. 373.
    .
    dimension 40 columns
    .
    read matrix m
    42.2  11.2  31.9  167.1
    48.6  10.6  13.2  174.4
    42.6  10.6  28.7  160.8
    39.0  10.4  26.1  162.0
    34.7   9.3  30.1  140.8
    44.5  10.8   8.5  174.6
    39.1  10.7  24.3  163.7
    40.1  10.0  18.6  174.5
    45.9  12.0  20.4  185.7
    end of data
    .
    set write decimals 4
    let c1 = partial kendall tau correlation m1 m2 m3
    let c2 = partial kendall tau correlation absolute value m1 m2 m3
    print c1 c2

-----PARTIAL RANK CORRELATION (LET)--------------------------------
 
PARTIAL RANK CORRELATION
 
Name:
    PARTIAL RANK CORRELATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the partial rank correlation coefficient between two
    variables given the effect of a third variable.
 
Description:
    The Spearman rank correlation coefficient is computed as

        R = 1 - 6*SUM[i=1 to N][D(i)]/(N*(N**2-1))

    where D(i) is the difference between the ranks assigned to the
    corresponding pairs and N is the sample size.  Ties are assigned
    average ranks.

    A perfect linear relationship between the ranks yields a
    rank correlation coefficient of +1 (or -1 for a negative
    relationship) and no linear relationship between the ranks
    yields a rank correlation coefficient of 0.
 
    Partial rank correlation is the correlation between two variables
    after removing the effect of one or more additional variables.  This
    command is specifcally for the the case of one additional variable.
    In this case, the partial rank correlation can be computed based on
    standard rank correlations between the three variables as follows:

        r12.3 = (r12 - r13*r23)/SQRT((1 - r13**2)*(1 - r23**2))

    with rxy denoting the correlation between x and y.

    As with the standard rank correlation coefficient, a value of +1
    indicates a perfect positive linear relationship, a value of -1
    indicates a perfect negative linear relationship, and a value of 0
    indicates no linear relationship.

Syntax 1:
    LET <par> = PARTIAL RANK CORRELATION <y1> <y2> <y3>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <y3> is the third response variable;
          <par> is a parameter where the computed partial rank
               correlation is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <par> = PARTIAL RANK CORRELATION ABSOLUTE VALUE <y1> <y2> <y3>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <y3> is the third response variable;
          <par> is a parameter where the absolute value of the computed
               partial rank correlation absolute value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the absolute value of the partial rank
    correlation coefficient.  This is typically used in screening
    applications where there is an interest in identifying high magnitude
    correlations regardless of the direction of the correlation.

Examples:
    LET A = PARTIAL RANK CORRELATION Y1 Y2 Z
    LET A = PARTIAL RANK CORRELATION Y1 Y2 Z  SUBSET TAG > 2
    LET A = PARTIAL RANK CORRELATION ABSOLUTE VALUE Y1 Y2 Z
 
Note:
    The three variables must have the same number of elements.
 
Note:
    The command PARTIAL CORRELATION MATRIX can be used to compute
    the matrix of partial correlations.  This command has options
    to compute several robust forms of the partial correlation
    including the Spearman rank correlation discussed here.

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RANK CORRELATION                 = Compute the rank correlation.
    PARTIAL CORRELATION              = Compute the partial correlation.
    PARTIAL KENDALL TAU CORRELATION  = Compute the Kendall tau partial
                                       correlation.
    PARTIAL CORRELATION MATRIX       = Compute the matrix of partial
                                       correlations.
    CORRELATION MATRIX               = Compute the matrix of correlations.
    CORRELATION                      = Compute the correlation.
    KENDALL TAU CORRELATION          = Compute the Kendall tau correlation.
 
Reference:
    Conover (1999), "Practical Nonparametric Statistics", Third Edition,
    Wiley, p. 327.
 
    Peavy, Bremer, Varner, Hogben (1986), "OMNITAB 80:
    An Interpretive System for Statistical and Numerical
    Data Analysis," NBS Special Publication 701.

Applications:
    Linear Regression
 
Implementation Date:
    2012/06
 
Program:
    .  This data is from page 202 of
    .
    .  Peavy, Bremer, Varner, Hogben (1986), "OMNITAB 80:
    .  An Interpretive System for Statistical and Numerical
    .  Data Analysis," NBS Special Publication 701.
    .
    .  Original source of the data is from
    .  Draper and Smith (1981), "Applied Regression Analysis",
    .  Wiley, p. 373.
    .
    dimension 40 columns
    .
    read matrix m
    42.2  11.2  31.9  167.1
    48.6  10.6  13.2  174.4
    42.6  10.6  28.7  160.8
    39.0  10.4  26.1  162.0
    34.7   9.3  30.1  140.8
    44.5  10.8   8.5  174.6
    39.1  10.7  24.3  163.7
    40.1  10.0  18.6  174.5
    45.9  12.0  20.4  185.7
    end of data
    .
    set write decimals 4
    let c1 = partial rank correlation m1 m2 m3
    let c2 = partial rank correlation absolute value m1 m2 m3
    print c1 c2

-----PARTIAL LEVERAGE PLOT--------------------------------------

PARTIAL LEVERAGE PLOT

Name:
    PARTIAL LEVERAGE PLOT

Type:
    Graphics Command

Purpose:
    Generate a partial leverage plot.

Description:
    In multi-linear regression, high leverage points are those
    that are outliers with respect to the independent variables.
    Influential points are those that cause large changes in the
    parameter estimates when they are deleted.  Although an
    influential point will typically have high leverage, a
    high leverage point is not necessarily an influential
    point.  The leverage is typically defined as the diagonal of the
    hat matrix (hat matrix = H = X(X'X)**(-1)X').  Dataplot
    currently writes a number of measure of influence and leverage
    to the file DPST3F.DAT (e.g., the diagonal of the hat matrix,
    Cook's distance, DFFITS).

    Partial leverage is used to measure the contribution of the
    individual independent variables to the leverage of each
    observation.  That is, if h(i) is the ith row of the
    diagonal of the hat matrix, how does h(i) change as we add
    a variable to the regression model.

    The partial leverage is computed as:

       PL(j)(i) = (X(j.[j])(i))**2/[SUM[k=1 to n][(X(j.[j])k)**2]

    where

       j       = jth independent variable
       i       = the ith observation
       X(j.[j]) = residuals from regressing X(j) against the
                  remaining indpependent variables.

    Note that the partial leverage is the leverage of the ith
    point in the partial regression plot for the jth variable
    (enter HELP PARTIAL REGRESSION PLOT for details on the
    partial regression plot).

    The interpretation of the partial leverage plot is that
    data points with large partial leverage for an independent
    variable can exert undue influence on the selection of that
    variable in automatic regression model building procedures
    (e.g., the BEST CP command in Dataplot).

    Dataplot provides two forms for the partial leverage
    plot.  You can generate either a single partial leverage
    plot or you can generate a matrix of partial leverage plots
    (one plot for each independent variable in the model).

    For the matrix form of the command, a number of SET FACTOR PLOT
    options can be used to control the appearance of the plot
    (not all of the SET FACTOR PLOT options apply).  These are
    discussed in the Notes section below.

Syntax 1:
    PARTIAL LEVERAGE PLOT  <y> <x1> ... <xk>  <xi>
                           <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> ... <xk> are the independent variables;
          <xi> is the independent variable for which the
              partial leverage plot is being generated (note that
              <xi> must be one of the variables listed in
              <x1> ... <xk>;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This is the syntax for generating a single partial leverage
    plot.

Syntax 2:
    MATRIX PARTIAL LEVERAGE PLOT  <y> <x1> ... <xk>
                           <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> ... <xk> are the independent variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used to generate a matrix of partial leverage
    plots.

Examples:
    PARTIAL LEVERAGE PLOT Y X1 X2 X3 X4 X2

    MATRIX PARTIAL LEVERAGE PLOT Y X1 X2 X3 X4

    PARTIAL LEVERAGE PLOT Y X1 X2 X3 X4 X2 SUBSET TAG > 2
    MATRIX PARTIAL LEVERAGE PLOT Y X1 X2 X3 X4 SUBSET TAG > 2

Note:
    The following option controls which axis tic marks, tic mark
    labels, and axis labels are plotted.
 
        SET FACTOR PLOT LABELS <ON/OFF/XON/YON/BOX>

    OFF means that all axis labels are suppressed (this can be
    useful if a large number of variables are being plotted).  ON
    means that both X and Y axis labels are printed.  XON only
    plots the x axis labels and YON only plots the y axis labels.

    BOX is a special option that creates an extra column on the
    left and an extra row on the bottom.  The axis label is
    printed in this box.  BOX is typically reserved for the plot
    types that plot the variable names in the axes labels.

    The default is ON (both x and y axis labels are printed).

Note:
    The following option controls where the x axis tic marks,
    tic mark labels, and axis label are printed.
 
        SET FACTOR PLOT X AXIS <BOTTOM/TOP/ALTERNATE>

    BOTTOM specifies that the x axis labels are printed on the
    bottom axis (on the last row only).  TOP specifies that
    the x axis labels are printed on the top axis (first row
    only).  ALTERNATE specifies that the x axis labels alternate
    between the top (first row) and bottom axis (last row).
    We recommend using the TIC OFFSET command to avoid overlap
    of axis labels and tic marks.

    The default is ALTERNATE.

Note:
    The following option controls where the y axis tic marks,
    tic mark labels, and axis label are printed.

        SET FACTOR PLOT Y AXIS <LEFT/RIGHT/ALTERNATE>

    LEFT specifies that the y axis labels are printed on the
    left axis (on the first column only).  RIGHT specifies that
    the y axis labels are printed on the right axis (last column
    only).  ALTERNATE specifies that the y axis labels alternate
    between the left (first column) and right axis (last column).
    We recommend using the TIC OFFSET command to avoid overlap
    of axis labels and tic marks.

    The default is ALTERNATE.

Note:
    Users have different preferences in terms of whether the
    plot frames for neighboring plots are connected or not.
    This is controlled with the following option.
 
        SET FACTOR PLOT FRAME <DEFAULT/CONNECTED/USER>

    DEFAULT connects neighboring frames (i.e., the FRAME CORNER
    COORDINATES are set to 0 0 100 100).  USER uses whatever
    frame coordinates are currently set (15 20 85 90 by default)
    and makes no special provisions for axis labels and tic marks
    (i.e., you set them as you normally would, each plot uses 
    whatever you have set).  CONNECTED uses whatever frame
    coordinates have been set by the user, but it draws the axis
    labels and tic marks as if DEFAULT were being used (that is, as
    determined by the SET FACTOR PLOT <LABELS/X AXIS/Y AXIS>
    commands described above).  Typically, CONNECTED is used to
    put a small bit of space between plots.  For example, you
    might use FRAME CORNER COORDINATES  3 3 97 97 before the
    PARTIAL RESIDUAL PLOT command.
 
    Since the plots can often have different limits for the axes,
    the default is USER.

Note:
    When the tic marks and tic mark labels are all plotted on the
    same side (i.e., SET FACTOR PLOT Y AXIS is
    set to LEFT or RIGHT or SET PARTIAL RESIDUAL PLOT X AXIS is
    set to BOTTOM or TOP), then overlap between plots is possible.
    The TIC OFFSET command can be used to avoid this.  In addition,
    you can stagger the tic labels with the following command:
 
        SET FACTOR PLOT LABEL DISPLACEMENT <NORMAL/STAGGERED/VALUE>
 
    NORMAL means that all tic labels are plotted at a distance
    determined by the TIC LABEL DISPLACEMENT command.  STAGGERED
    means that alternating plots will be staggered.  That is, one
    will use the standard displacement while the next uses a
    staggered value.  Entering this command with a numeric value
    specifies the amount of the displacement for the staggered
    tic labels.  For example,

        TIC MARK LABEL DISPLACEMENT 10
        SET FACTOR PLOT LABEL DISPLACEMENT STAGGERED
        SET FACTOR PLOT LABEL DISPLACEMENT 25

    These commands specify that the default tic label displacement
    is 10 and the staggered tic mark label displacement is 25.

Note:
    It is often helpful on scatter plot matrices to overlay a
    fitted line on the plots.  The following command is used
    to specify the type of fit.

        SET FACTOR PLOT FIT <NONE/LOWESS/LINE/QUAD/SMOOTH>

    NONE means that no fitted line is plotted.  LOWESS means
    that a locally weighted least squares line will be overlaid.
    LINE means that a linear fit (Y = A0 + A1*X) will be overlaid.
    QUAD means that a quadratic fit (Y = A0 + A1*X + A2*X**2) will
    be overlaid.  SMOOTH means that a least squares smoothing will
    be overlaid.

    For LOWESS, it is recommended that the lowess fraction be set
    fairly high (e.g., LOWESS FRACTION 0.6).

    The fitted line is currently only generated if the factor plot
    type is PLOT.

    The default is for no fitted line to be overlaid on the plot.
    If a overlaid fit is desired, the most common choice is to use
    LOWESS.

Note:
    Dataplot allows you to set axis limits with the LIMITS command.
    For the factor plot, it is often desirable to set
    the axis limits for each plot.  This can be done with the
    command
 
        SET FACTOR PLOT YLIMITS <LOW1> <UPP1> <LOW2> <UPP2> ...
        SET FACTOR PLOT XLIMITS <LOW1> <UPP1> <LOW2> <UPP2> ...

    The default is to allow the axis limits to float with the data.

Note:
    You can use standard plot control commands to control the
    appearance of the factor plot.

    For example,

       MULTIPLOT CORNER COORDINATES 5 5 95 95
       MULTIPLOT SCALE FACTOR 3
       TIC OFFSET UNITS SCREEN
       TIC OFFSET 5 5

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    FIT                      = Perform a multi-linear fit.
    CCPR PLOT                = Generates a component and component
                               plus residual plot.
    PARTIAL RESIDUAL PLOT    = Generates a partial residual plot.
    PARTIAL REGRESSION PLOT   = Generates a partial regression plot.
    VIF                      = Compute variance inflation factors
                               for a multi-linear fit.
    CONDITION INDICES        = Compute condition indices for a design
                               matrix.
    SCATTER PLOT MATIRX      = Generate a factor plot.
    FACTOR PLOT              = Generate a plot for a response
                               against a number of different
                               independent variables.
    CONDITIONAL PLOT         = Generate a conditional (subset) plot.
 
Reference:
    "Modern Regression Methods", Tom Ryan, John Wiley, 1997.
 
    "Applied Linear Statistical Models", 3rd ed., Neter, Wasserman,
    and Kunter, 1990, Irwin.
 
    "Applied Regression Analysis", 3rd. ed., Draper and Smith, John
    Wiley, 1998.
 
    "Residuals and Influence in Regression", Cook and Weisberg,
    Chapman and Hall, 1982.
 
    "Regression Diagnostics", Belsley, Kuh, and Welsch, John Wiley,
    1980.
 
    "Efficient Computing of Regression Diagnostiocs",
    Paul Velleman and Roy Welsch, The American Statistician,
    November, 1981, Vol. 35, No. 4, pp. 234-242.
 
Applications:
    Multi-linear Regression
 
Implementation Date:
    2002/6
 
Program:
    SKIP 25
    READ HALD647.DAT Y X1 X2 X3 X4
    .
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    MULTIPLOT SCALE FACTOR 2
    LINE BLANK
    CHARACTER X
    .
    MATRIX PARTIAL LEVERAGE PLOT Y X1 X2 X3 X4

-----PARTIAL REGRESSION PLOT--------------------------------------

PARTIAL REGRESSION PLOT

Name:
    PARTIAL REGRESSION PLOT

Type:
    Graphics Command

Purpose:
    Generate a partial regression plot.  Note that partial
    regression plots are also referred to as added variable
    plots, adjusted variable plots, and individual coefficient
    plots.

Description:
    When performing a linear regression with a single independent
    variable, a scatter plot of the response variable against
    the independent variable provides a good indication of
    the nature of the relationship.  If there is more than one
    independent variable, things become more complicated.
    Although it can still be useful to generate scatter plots
    of the response variable against each of the independent
    variables, this does not take into account the effect of the
    other independent variables in the model.

    Partial regression plots attempt to show the effect of
    adding an additional variable to the model (given that
    one or more indpendent variables are already in the model).

    Partial regression plots are formed by:

       1) Compute the residuals of regressing the response
          variable against the indpendent variables but omitting
          X(i).

       2) Compute the residuals from regressing X(i) against
          the remaining indpendent variables.

       3) Plot the residuals from (1) against the residuals
          from (2).

    Velleman and Welsch (see References below) express this
    mathematically as:

       Y(.[i]) versus X(i.[i])

    where

       Y(.[i])  = residuals from regressing Y (the response
                  variable) against all the indpendent variables
                  except X(i).
       X(i.[i]) = residuals from regressing X(i) against the
                  remaining indpependent variables.

    Velleman and Welsch list the following useful properties
    for this plot:

       1) The least squares linear fit to this plot has the
          slope Beta(i) and intercept zero.

       2) The residuals from the least squares linear fit to
          this plot are identical to the residuals from the
          least squares fit of the original model (Y against
          all the independent variables including X(i)).

       3) The influences of individual data values on the
          estimation of a coefficient are easy to see in this
          plot.

       4) It is easy to see many kinds of failures of the
          model or violations of the underlying assumptions
          (nonlinearity, heteroscedasticity, unusual patterns).

    Partial regression plots are widely discussed in the regression
    diagnostics literature (e.g., see the References section below).
    Since the strengths and weaknesses of partial regression
    plots are widely discussed in the literature, we will not
    discuss that in any detail here.

    Partial regression plots are related to, but distinct from,
    partial residual plots.  Partial regression plots are most
    commonly used to identify leverage points and influential
    data points that might not be leverage points.  Partial residual
    plots are most commonly used to identify the nature of the
    relationship between Y and X(i) (given the effect of the
    other indpendent variables in the model).  Note that since
    the simple correlation betweeen the two sets of residuals
    plotted is equal to the partial correlation between the
    response variable and X(i), partial regression plots will show
    the correct strength of the linear relationship between the
    response variable and X(i).  This is not true for partial
    residual plots.  On the other hand, for the partial
    regression plot, the x axis is not X(i).  This limits its
    usefulness in determining the need for a transformation
    (which is the primary purpose of the partial residual plot).

    Dataplot provides two forms for the partial regression
    plot.  You can generate either a single partial regression
    plot or you can generate a matrix of partial regression plots
    (one plot for each independent variable in the model).

    For the matrix form of the command, a number of SET FACTOR PLOT
    options can be used to control the appearance of the plot
    (not all of the SET FACTOR PLOT options apply).  These are
    discussed in the Notes section below.

Syntax 1:
    PARTIAL REGRESSION PLOT  <y> <x1> ... <xk>  <xi>
                           <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> ... <xk> are the independent variables;
          <xi> is the independent variable for which the
              partial regression plot is being generated (note that
              <xi> must be one of the variables listed in
              <x1> ... <xk>;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This is the syntax for generating a single partial regression
    plot.

Syntax 2:
    MATRIX PARTIAL REGRESSION PLOT  <y> <x1> ... <xk>
                           <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> ... <xk> are the independent variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used to generate a matrix of partial regression
    plots.

Examples:
    PARTIAL REGRESSION PLOT Y X1 X2 X3 X4 X2

    MATRIX PARTIAL REGRESSION PLOT Y X1 X2 X3 X4

    PARTIAL REGRESSION PLOT Y X1 X2 X3 X4 X2 SUBSET TAG > 2
    MATRIX PARTIAL REGRESSION PLOT Y X1 X2 X3 X4 SUBSET TAG > 2

Note:
    The following option controls which axis tic marks, tic mark
    labels, and axis labels are plotted.
 
        SET FACTOR PLOT LABELS <ON/OFF/XON/YON/BOX>

    OFF means that all axis labels are suppressed (this can be
    useful if a large number of variables are being plotted).  ON
    means that both X and Y axis labels are printed.  XON only
    plots the x axis labels and YON only plots the y axis labels.

    BOX is a special option that creates an extra column on the
    left and an extra row on the bottom.  The axis label is
    printed in this box.  BOX is typically reserved for the plot
    types that plot the variable names in the axes labels.

    The default is ON (both x and y axis labels are printed).

Note:
    The following option controls where the x axis tic marks,
    tic mark labels, and axis label are printed.
 
        SET FACTOR PLOT X AXIS <BOTTOM/TOP/ALTERNATE>

    BOTTOM specifies that the x axis labels are printed on the
    bottom axis (on the last row only).  TOP specifies that
    the x axis labels are printed on the top axis (first row
    only).  ALTERNATE specifies that the x axis labels alternate
    between the top (first row) and bottom axis (last row).
    We recommend using the TIC OFFSET command to avoid overlap
    of axis labels and tic marks.

    The default is ALTERNATE.

Note:
    The following option controls where the y axis tic marks,
    tic mark labels, and axis label are printed.

        SET FACTOR PLOT Y AXIS <LEFT/RIGHT/ALTERNATE>

    LEFT specifies that the y axis labels are printed on the
    left axis (on the first column only).  RIGHT specifies that
    the y axis labels are printed on the right axis (last column
    only).  ALTERNATE specifies that the y axis labels alternate
    between the left (first column) and right axis (last column).
    We recommend using the TIC OFFSET command to avoid overlap
    of axis labels and tic marks.

    The default is ALTERNATE.

Note:
    Users have different preferences in terms of whether the
    plot frames for neighboring plots are connected or not.
    This is controlled with the following option.
 
        SET FACTOR PLOT FRAME <DEFAULT/CONNECTED/USER>

    DEFAULT connects neighboring frames (i.e., the FRAME CORNER
    COORDINATES are set to 0 0 100 100).  USER uses whatever
    frame coordinates are currently set (15 20 85 90 by default)
    and makes no special provisions for axis labels and tic marks
    (i.e., you set them as you normally would, each plot uses 
    whatever you have set).  CONNECTED uses whatever frame
    coordinates have been set by the user, but it draws the axis
    labels and tic marks as if DEFAULT were being used (that is, as
    determined by the SET FACTOR PLOT <LABELS/X AXIS/Y AXIS>
    commands described above).  Typically, CONNECTED is used to
    put a small bit of space between plots.  For example, you
    might use FRAME CORNER COORDINATES  3 3 97 97 before the
    PARTIAL RESIDUAL PLOT command.
 
    Since the plots can often have different limits for the axes,
    the default is USER.

Note:
    When the tic marks and tic mark labels are all plotted on the
    same side (i.e., SET FACTOR PLOT Y AXIS is
    set to LEFT or RIGHT or SET PARTIAL RESIDUAL PLOT X AXIS is
    set to BOTTOM or TOP), then overlap between plots is possible.
    The TIC OFFSET command can be used to avoid this.  In addition,
    you can stagger the tic labels with the following command:
 
        SET FACTOR PLOT LABEL DISPLACEMENT <NORMAL/STAGGERED/VALUE>
 
    NORMAL means that all tic labels are plotted at a distance
    determined by the TIC LABEL DISPLACEMENT command.  STAGGERED
    means that alternating plots will be staggered.  That is, one
    will use the standard displacement while the next uses a
    staggered value.  Entering this command with a numeric value
    specifies the amount of the displacement for the staggered
    tic labels.  For example,

        TIC MARK LABEL DISPLACEMENT 10
        SET FACTOR PLOT LABEL DISPLACEMENT STAGGERED
        SET FACTOR PLOT LABEL DISPLACEMENT 25

    These commands specify that the default tic label displacement
    is 10 and the staggered tic mark label displacement is 25.

Note:
    It is often helpful on scatter plot matrices to overlay a
    fitted line on the plots.  The following command is used
    to specify the type of fit.

        SET FACTOR PLOT FIT <NONE/LOWESS/LINE/QUAD/SMOOTH>

    NONE means that no fitted line is plotted.  LOWESS means
    that a locally weighted least squares line will be overlaid.
    LINE means that a linear fit (Y = A0 + A1*X) will be overlaid.
    QUAD means that a quadratic fit (Y = A0 + A1*X + A2*X**2) will
    be overlaid.  SMOOTH means that a least squares smoothing will
    be overlaid.

    For LOWESS, it is recommended that the lowess fraction be set
    fairly high (e.g., LOWESS FRACTION 0.6).

    The fitted line is currently only generated if the factor plot
    type is PLOT.

    The default is for no fitted line to be overlaid on the plot.
    If a overlaid fit is desired, the most common choice is to use
    LOWESS.

Note:
    Dataplot allows you to set axis limits with the LIMITS command.
    For the factor plot, it is often desirable to set
    the axis limits for each plot.  This can be done with the
    command
 
        SET FACTOR PLOT YLIMITS <LOW1> <UPP1> <LOW2> <UPP2> ...
        SET FACTOR PLOT XLIMITS <LOW1> <UPP1> <LOW2> <UPP2> ...

    The default is to allow the axis limits to float with the data.

Note:
    You can use standard plot control commands to control the
    appearance of the factor plot.

    For example,

       MULTIPLOT CORNER COORDINATES 5 5 95 95
       MULTIPLOT SCALE FACTOR 3
       TIC OFFSET UNITS SCREEN
       TIC OFFSET 5 5

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    FIT                      = Perform a multi-linear fit.
    CCPR PLOT                = Generates a component and component
                               plus residual plot.
    PARTIAL RESIDUAL PLOT    = Generates a partial residual plot.
    PARTIAL LEVERAGE PLOT    = Generates a partial leverage plot.
    VIF                      = Compute variance inflation factors
                               for a multi-linear fit.
    CONDITION INDICES        = Compute condition indices for a design
                               matrix.
    SCATTER PLOT MATIRX      = Generate a factor plot.
    FACTOR PLOT              = Generate a plot for a response
                               against a number of different
                               independent variables.
    CONDITIONAL PLOT         = Generate a conditional (subset) plot.
 
Reference:
    "Modern Regression Methods", Tom Ryan, John Wiley, 1997.
 
    "Applied Linear Statistical Models", 3rd ed., Neter, Wasserman,
    and Kunter, 1990, Irwin.
 
    "Applied Regression Analysis", 3rd. ed., Draper and Smith, John
    Wiley, 1998.
 
    "Residuals and Influence in Regression", Cook and Weisberg,
    Chapman and Hall, 1982.
 
    "Regression Diagnostics", Belsley, Kuh, and Welsch, John Wiley,
    1980.
 
    "Efficient Computing of Regression Diagnostiocs",
    Paul Velleman and Roy Welsch, The American Statistician,
    November, 1981, Vol. 35, No. 4, pp. 234-242.
 
Applications:
    Multi-linear Regression
 
Implementation Date:
    2002/6
 
Program:
    SKIP 25
    READ HALD647.DAT Y X1 X2 X3 X4
    .
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    MULTIPLOT SCALE FACTOR 2
    LINE BLANK
    CHARACTER X
    .
    MATRIX PARTIAL REGRESSION PLOT Y X1 X2 X3 X4

-----PARTIAL RESIDUAL PLOT--------------------------------------

PARTIAL RESIDUAL PLOT

Name:
    PARTIAL RESIDUAL PLOT

Type:
    Graphics Command

Purpose:
    Generate a partial residual plot.

Description:
    When performing a linear regression with a single independent
    variable, a scatter plot of the response variable against
    the independent variable provides a good indication of
    the nature of the relationship.  If there is more than one
    independent variable, things become more complicated.
    Although it can still be useful to generate scatter plots
    of the response variable against each of the independent
    variables, this does not take into account the effect of the
    other independent variables in the model.

    Partial residual plots attempt to show the relationship between
    a given independent variable and the response variable given
    that other independent variables are also in the model.

    Partial residual plots are formed as:

       Res + Betahat(i)*X(i) versus X(i)

    where

       Res = residuals from the full model
       Betahat(i) = regression coefficient from the ith
                    independent variable in the full model
       X(i) = the ith independent variable

    Partial residual plots are widely discussed in the regression
    diagnostics literature (e.g., see the References section below).
    Although they can often be useful, be aware that they can
    also fail to indicate the proper relationship.  In
    particular, if X(i) is highly correlated with any of the
    other independent variables, the variance indicated by the
    partial residual plot can be much less than the actual
    variance.  These issues are discussed in more detail in the
    references given below.

    Dataplot provides two forms for the partial residual
    plot.  You can generate either a single partial residual
    plot or you can generate a matrix of partial residual plots
    (one plot for each independent variable in the model).

    For the matrix form of the command, a number of SET FACTOR PLOT
    options can be used to control the appearance of the plot
    (not all of the SET FACTOR PLOT options apply).  These are
    discussed in the Notes section below.

    The CCPR plot is a variation of the PARTIAL RESIDUAL PLOT.
    Enter HELP CCPR PLOT for details.

Syntax 1:
    PARTIAL RESIDUAL PLOT  <y> <x1> ... <xk>  <xi>
                           <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> ... <xk> are the independent variables;
          <xi> is the independent variable for which the
              partial residual plot is being generated (note that
              <xi> must be one of the variables listed in
              <x1> ... <xk>;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This is the syntax for generating a single partial residual
    plot.

Syntax 2:
    MATRIX PARTIAL RESIDUAL PLOT  <y> <x1> ... <xk>
                           <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> ... <xk> are the independent variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used to generate a matrix of partial residual
    plots.

Examples:
    PARTIAL RESIDUAL PLOT Y X1 X2 X3 X4 X2

    MATRIX PARTIAL RESIDUAL PLOT Y X1 X2 X3 X4

    PARTIAL RESIDUAL PLOT Y X1 X2 X3 X4 X2 SUBSET TAG > 2
    MATRIX PARTIAL RESIDUAL PLOT Y X1 X2 X3 X4 SUBSET TAG > 2

Note:
    The following option controls which axis tic marks, tic mark
    labels, and axis labels are plotted.
 
        SET FACTOR PLOT LABELS <ON/OFF/XON/YON/BOX>

    OFF means that all axis labels are suppressed (this can be
    useful if a large number of variables are being plotted).  ON
    means that both X and Y axis labels are printed.  XON only
    plots the x axis labels and YON only plots the y axis labels.

    BOX is a special option that creates an extra column on the
    left and an extra row on the bottom.  The axis label is
    printed in this box.  BOX is typically reserved for the plot
    types that plot the variable names in the axes labels.

    The default is ON (both x and y axis labels are printed).

Note:
    The following option controls where the x axis tic marks,
    tic mark labels, and axis label are printed.
 
        SET FACTOR PLOT X AXIS <BOTTOM/TOP/ALTERNATE>

    BOTTOM specifies that the x axis labels are printed on the
    bottom axis (on the last row only).  TOP specifies that
    the x axis labels are printed on the top axis (first row
    only).  ALTERNATE specifies that the x axis labels alternate
    between the top (first row) and bottom axis (last row).
    We recommend using the TIC OFFSET command to avoid overlap
    of axis labels and tic marks.

    The default is ALTERNATE.

Note:
    The following option controls where the y axis tic marks,
    tic mark labels, and axis label are printed.

        SET FACTOR PLOT Y AXIS <LEFT/RIGHT/ALTERNATE>

    LEFT specifies that the y axis labels are printed on the
    left axis (on the first column only).  RIGHT specifies that
    the y axis labels are printed on the right axis (last column
    only).  ALTERNATE specifies that the y axis labels alternate
    between the left (first column) and right axis (last column).
    We recommend using the TIC OFFSET command to avoid overlap
    of axis labels and tic marks.

    The default is ALTERNATE.

Note:
    Users have different preferences in terms of whether the
    plot frames for neighboring plots are connected or not.
    This is controlled with the following option.
 
        SET FACTOR PLOT FRAME <DEFAULT/CONNECTED/USER>

    DEFAULT connects neighboring frames (i.e., the FRAME CORNER
    COORDINATES are set to 0 0 100 100).  USER uses whatever
    frame coordinates are currently set (15 20 85 90 by default)
    and makes no special provisions for axis labels and tic marks
    (i.e., you set them as you normally would, each plot uses 
    whatever you have set).  CONNECTED uses whatever frame
    coordinates have been set by the user, but it draws the axis
    labels and tic marks as if DEFAULT were being used (that is, as
    determined by the SET FACTOR PLOT <LABELS/X AXIS/Y AXIS>
    commands described above).  Typically, CONNECTED is used to
    put a small bit of space between plots.  For example, you
    might use FRAME CORNER COORDINATES  3 3 97 97 before the
    PARTIAL RESIDUAL PLOT command.
 
    Since the plots can often have different limits for the axes,
    the default is USER.

Note:
    When the tic marks and tic mark labels are all plotted on the
    same side (i.e., SET FACTOR PLOT Y AXIS is
    set to LEFT or RIGHT or SET PARTIAL RESIDUAL PLOT X AXIS is
    set to BOTTOM or TOP), then overlap between plots is possible.
    The TIC OFFSET command can be used to avoid this.  In addition,
    you can stagger the tic labels with the following command:
 
        SET FACTOR PLOT LABEL DISPLACEMENT <NORMAL/STAGGERED/VALUE>
 
    NORMAL means that all tic labels are plotted at a distance
    determined by the TIC LABEL DISPLACEMENT command.  STAGGERED
    means that alternating plots will be staggered.  That is, one
    will use the standard displacement while the next uses a
    staggered value.  Entering this command with a numeric value
    specifies the amount of the displacement for the staggered
    tic labels.  For example,

        TIC MARK LABEL DISPLACEMENT 10
        SET FACTOR PLOT LABEL DISPLACEMENT STAGGERED
        SET FACTOR PLOT LABEL DISPLACEMENT 25

    These commands specify that the default tic label displacement
    is 10 and the staggered tic mark label displacement is 25.

Note:
    It is often helpful on scatter plot matrices to overlay a
    fitted line on the plots.  The following command is used
    to specify the type of fit.

        SET FACTOR PLOT FIT <NONE/LOWESS/LINE/QUAD/SMOOTH>

    NONE means that no fitted line is plotted.  LOWESS means
    that a locally weighted least squares line will be overlaid.
    LINE means that a linear fit (Y = A0 + A1*X) will be overlaid.
    QUAD means that a quadratic fit (Y = A0 + A1*X + A2*X**2) will
    be overlaid.  SMOOTH means that a least squares smoothing will
    be overlaid.

    For LOWESS, it is recommended that the lowess fraction be set
    fairly high (e.g., LOWESS FRACTION 0.6).

    The fitted line is currently only generated if the factor plot
    type is PLOT.

    The default is for no fitted line to be overlaid on the plot.
    If a overlaid fit is desired, the most common choice is to use
    LOWESS.

Note:
    Dataplot allows you to set axis limits with the LIMITS command.
    For the factor plot, it is often desirable to set
    the axis limits for each plot.  This can be done with the
    command
 
        SET FACTOR PLOT YLIMITS <LOW1> <UPP1> <LOW2> <UPP2> ...
        SET FACTOR PLOT XLIMITS <LOW1> <UPP1> <LOW2> <UPP2> ...

    The default is to allow the axis limits to float with the data.

Note:
    You can use standard plot control commands to control the
    appearance of the factor plot.

    For example,

       MULTIPLOT CORNER COORDINATES 5 5 95 95
       MULTIPLOT SCALE FACTOR 3
       TIC OFFSET UNITS SCREEN
       TIC OFFSET 5 5

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    FIT                      = Perform a multi-linear fit.
    CCPR PLOT                = Generates a component and component
                               plus residual plot.
    PARTIAL REGRESSION PLOT  = Generates a partial regression plot.
    PARTIAL LEVERAGE PLOT    = Generates a partial leverage plot.
    VIF                      = Compute variance inflation factors
                               for a multi-linear fit.
    CONDITION INDICES        = Compute condition indices for a design
                               matrix.
    SCATTER PLOT MATIRX      = Generate a factor plot.
    FACTOR PLOT              = Generate a plot for a response
                               against a number of different
                               independent variables.
    CONDITIONAL PLOT         = Generate a conditional (subset) plot.
 
Reference:
    "Modern Regression Methods", Tom Ryan, John Wiley, 1997.
 
    "Applied Linear Statistical Models", 3rd ed., Neter, Wasserman,
    and Kunter, 1990, Irwin.
 
    "Applied Regression Analysis", 3rd. ed., Draper and Smith, John
    Wiley, 1998.
 
    "Residuals and Influence in Regression", Cook and Weisberg,
    Chapman and Hall, 1982.
 
    "Regression Diagnostics", Belsley, Kuh, and Welsch, John Wiley,
    1980.
 
    "Efficient Computing of Regression Diagnostiocs",
    Paul Velleman and Roy Welsch, The American Statistician,
    November, 1981, Vol. 35, No. 4, pp. 234-242.
 
Applications:
    Multi-linear Regression
 
Implementation Date:
    2002/6
 
Program:
    SKIP 25
    READ HALD647.DAT Y X1 X2 X3 X4
    .
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    MULTIPLOT SCALE FACTOR 2
    LINE BLANK
    CHARACTER X
    .
    MATRIX PARTIAL RESIDUAL PLOT Y X1 X2 X3 X4

-----PATH (SET)--------------------------------------------
 
PATH
 
Name:
    PATH (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify the name of the directory where Dataplot's auxiliary files
    are stored.
 
Description:
    The Dataplot distribution comes with a large number of sample data
    files, macro and program files, and experiment design files.
    Typically, these files can be accessed in the READ, CALL, and LIST
    commands without specifying a path name.  However, if the local
    implementor has not specified this path correctly in the Dataplot
    source code, the SET PATH command can be used to tell Dataplot where
    to locate them.  Check with your local implementor for the correct
    path.

    On Microsoft Windows platforms, the Install Shield installation sets
    the DATAPLO$ environment variable in the Windows registry that defines
    the default location.

    For Unix/Linux and Mac OS X installations, you will typically add a
    line in your .cshrc file (for c-shell or t-shell users) or your
    .bashrc (for Bourne-shell users) that defines the DATAPLOT_FILES
    environment variable.

    So for those systems where an appropriate environment variable has
    been properly defined, there is no need to enter a SET PATH command.

    The SET PATH command is most typically used by developers who would
    like to set the default Dataplot directory to a test directory
    rather than the default installation directory.
 
Syntax:
    SET PATH <string>
    where <string> specifies the desired path name.
 
    This string is currently limited to a maxium of 80 characters.

Examples:
    SET PATH D:\DATAPLOT
    SET PATH /usr/local/lib/dataplot
    PROBE PATH

Note:
    Starting with the 2019/04 version, Linux and MacOS systems allow
    the default path to be set in the Makefile.  So it is no longer
    neccessary to create a DATAPLOT_FILES environment variable on
    these systems.

    The order of determining the default path for Linux/MacOS
    platforms is:

        1. First check for the DATAPLOT_FILES environment variable.

        2. If DATAPLOT_FILES has not been defined, use the path
           specified in the Makefile (this will be called DPLIBDIR).

        3. If DATAPLOT_FILES has not been defined and DPLIBDIR has
           not been defined in the Makefile, then default to
           /usr/local/lib/dataplot.

Note:
    When Dataplot attempts to open a file, it will first do so in the
    current directory.  If Dataplot is unable to locate the file in the
    current directory, it will look in the directory containing the
    Dataplot auxillary files.

    You can use the SET SEARCH DIRECTORY command to define an additional
    directory where Dataplot will look for the file.

Default:
    On Microsoft Windows platforms, the default path is determined by the
    Install Shield installation and the DATAPLO$ environment variable is
    set to this directory.  For English-based platforms, this is either
    "C:\Program Files\NIST\DATAPLOT" (for 32-bit systems) or 
    "C:\Program Files (x86)\NIST\DATAPLOT".  Non-English platforms will
    typically have a different name for "Program Files".

    On Linux/Unix and MacOS systems, the default path is determined by
    the DATAPLOT_FILES environment variable.  If the this environment
    variable is not defined, then check to see if DPLIBDIR was defined
    in the Makefile.  If neither of these has been set, the default path is
    "/usr/local/lib/dataplot".
 
Synonyms:
    None
 
Related Commands:
    LIST              = List the contents of a file.
    READ              = Read data from a file.
    CALL              = Execute commands stored in a file.
    SEARCH DIRECTORY  = Define an additional directory that will be
                        searched.
 
Applications:
    File Usage
 
Implementation Date:
    1994/01
    2019/08: Use of DPLIBDIR in Makefile for Linux/MacOS systems
 
Program:
    SET PATH /home/heckert/lib/dataplot/
    LIST BERGER1.DAT
 
-----PATTERN (LET)---------------------------------------------------
 
PATTERN
 
Name:
    PATTERN (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate numbers with a specific pattern.
 
Description:
    The SEQUENCE command is used to generate sequences with a constant
    increment.  The PATTERN command can be used for those cases where
    there is a non-constant increment.
 
Syntax 1:
    LET <resp> = PATTERN <list>
    where <list> is a list of numbers or parameters;
    and   <resp> is a variable where the given numbers are saved.
 
    With this syntax, only one iteration of the pattern is saved.
 
Syntax 2:
    LET <resp> = PATTERN <list>  FOR I = <start>  <inc>  <stop>
    where <list> is a list of numbers or parameters;
          <resp> is a variable where the given numbers are saved;
          <start> is the first row in <resp> where the pattern is saved
              (typically has a value of 1);
          <inc> is the row increment for saving values in <resp>
              (typically has a value of 1);
    and   <stop> is the last row in <resp> for saving values.
 
    With this syntax, the pattern is repeated in <resp> until all the
    rows specified by the FOR are filled.
 
Examples:
    LET X = PATTERN 1 3 4 1 1 1 0 0 2
    LET X = PATTERN 1 3 4 1 1 1 0 0 2 FOR I = 1 1 100
 
Default:
    None
 
Synonyms:
    The DATA command is equivalent to SYNTAX 1.
 
Related Commands:
    SEQUENCE            = Generate a sequence of numbers.
    FIBONNACCI NUMBERS  = Generate Fibonnacci numbers.
    PRIME NUMBERS       = Generate prime numbers.
    DATA                = Place numbers in a variable.
    LOGISTIC NUMBERS    = Generate numbers from a logistic sequence.
    CANTOR NUMBERS      = Generate numbers from a Cantor set.
 
Applications:
    Data Input
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----PAUSE LINES (SET)-------------------------------------------
 
PAUSE LINES (SET)
 
Name:
    SET PAUSE LINES
 
Type:
    Support Command
 
Purpose:
    Specify the number of lines that will be printed to the screen
    before pausing and prompting for a carriage return.
 
Description:
    For some implementations (e.g., Windows) with a limited number
    of scroll lines or for cases where a large amount of output is
    printed to the screen, it can be useful to pause after a given
    number of lines have been printed in order to view the output.

    This command allows  you to specify a given number of lines.
    When this number of lines has been printed to the terminal
    screen, a "?" is printed and execution is halted until a carriage
    return is entered.

    This is similar to a PAUSE command.  However, a PAUSE command
    only pauses the output when a PAUSE is explicitly entered.
    In contrast, a SET PAUSE LINES needs to be entered only once
    and the pause will be activated automatically when the specified
    number of lines has been printed.
 
    If the number of pause lines is set to zero or a negative value,
    no pause will be generated.

    If you have activated the pause and wish to de-activate it later
    in the session, you can do this by entering a "0" at the "?"
    prompt.  You can also enter a SET PAUSE LINES 0 command.

Syntax:
    SET PAUSE LINES <value>
    where <value> specifies the number of lines to output to the
              screen before pausing and prompting for a carriage return.
 
Examples:
    PAUSE
 
Note:
    This command will not be active if you are running the
    graphical user interface (GUI).

Default:
    No pauses are generated
 
Synonyms:
    None
 
Related Commands:
    PAUSE         = Initiate an explicit pause.
 
Applications:
    Interactive Usage
 
Implementation Date:
    2010/09
 
Program:
    XX
 
-----PAUSE-------------------------------------------------------
 
PAUSE
 
Name:
    PAUSE
 
Type:
    Support Command
 
Purpose:
    A "?" is printed to the screen and execution is halted until
    a carriage return is entered.
 
Description:
    This command is typically used in macros to allow the analyst to
    look at the current plot (or terminal output) before the next plot
    is generated.
 
Syntax:
    PAUSE
 
Examples:
    PAUSE
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PLOT          = Generate a data or function plot.
 
Applications:
    Interactive Usage
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----PB (LET)--------------------------------
 
PB
 
Name:
    PB (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the parabolic cylinder functions or the derivatives
   of the parabolic cylinder functions.
 
Description:
    The parabolic cylinder functions are defined as:

       1) D(x,v) = COS(PI*v/2)*w1(x) + SIN(PI*v/2)*w2(x)

          where
        
          w1(x) = (1/SQRT(PI))*GAMMA(0.5 + 0.5*v)*y1(x)/(2**(-v/2))
          w2(x) = (1/SQRT(PI))*GAMMA(1 + 0.5*v)*y2(x)/(2**(-v/2 - 0.5))

          where

          y1(x) = SUM(a(2*m))*x**(2*m)/(2*m)!
          y2(x) = SUM(a(2*m+1))*x**(2*m+1)/(2*m+1)!

          where the summation is from m = 0 to infinity and
  
          a(0) = a(1) = 1
          a(2) = a(3) = a = -v - 0.5
          a(n) = a*a(n-2) + (1/4)*(n-2)(n-3)*a(n-4)   (n >= 4)

       2) V(x,v) =[1/(GAMMA(1+v)]*[-SIN(PI*v/2)w1(x) + COS(PI*v/2)w2(x)]

          where w1 and w2 are defined as for the D(x,v) function
          and GAMMA is the gamma function.
        
       3) W(+/-x,a) =[(COSH(PI*a)**(1/4)]*[G1y1(x) -/+ SQRT(2)*G2y2(x)]

          where y1 and y2 are defined as for the D(x,v) function,
          COSH is the hyperbolic cosine function, and

          G1 = ABS(GAMMA(0.25 + 0.5ia))
          G2 = ABS(GAMMA(0.75 + 0.5ia))
 
    Note that there are alternative formulations for the above
    functions.  More details are provided in the sources listed
    in the References section.

    In addition, Dataplot provides functions for computing the
    derivatives of each of these functions.

    Dataplot computes these function using the PDBV, PBVV, and
    PBWA routines from "Computation of Special Functions" (see
    the References section below).
 
Syntax 1:
    LET <y> = PBDV(<x>,<v>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, number, or parameter containing
              positive values;
          <v> is a variable, number, or parameter that defines
              the order of the parabolic function;
          <y> is a variable or a parameter (depending on what
              <x> and <v> are) where the computed parabolic
              cylinder  values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the first form of the parabolic
    cylinder functions (D(x,v)).

Syntax 2:
    LET <y> = PBDV1(<x>,<v>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, number, or parameter containing
              positive values;
          <v> is a variable, number, or parameter that defines
              the order of the parabolic cylinder function;
          <y> is a variable or a parameter (depending on what
              <x> and <v> are) where the computed parabolic
              cylinder  values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the derivative of the first form of the
    parabolic cylinder functions (D(x,v)).

Syntax 3:
    LET <y> = PBVV(<x>,<v>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, number, or parameter containing
              positive values;
          <v> is a variable, number, or parameter that defines
              the order of the parabolic function;
          <y> is a variable or a parameter (depending on what
              <x> and <v> are) where the computed parabolic
              cylinder  values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the second form of the parabolic
    cylinder functions (V(x,v)).

Syntax 4:
    LET <y> = PBVV1(<x>,<v>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, number, or parameter containing
              positive values;
          <v> is a variable, number, or parameter that defines
              the order of the parabolic function;
          <y> is a variable or a parameter (depending on what
              <x> and <v> are) where the computed parabolic
              cylinder  values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the derivative of the second form of
    the parabolic cylinder functions (V(x,v)).

Syntax 5:
    LET <y> = PBWA(<x>,<a>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, number, or parameter containing
              positive values;
          <a> is a variable, number, or parameter that defines
              the order of the parabolic function;
          <y> is a variable or a parameter (depending on what
              <x> and <v> are) where the computed parabolic
              cylinder  values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the third form of the parabolic
    cylinder functions (W(x,a)).

    This function is limited to the case when the absolute 
    value of <x> is less than 5.

Syntax 6:
    LET <y> = PBWA1(<x>,<a>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, number, or parameter containing
              positive values;
          <a> is a variable, number, or parameter that defines
              the order of the parabolic function;
          <y> is a variable or a parameter (depending on what
              <x> and <v> are) where the computed parabolic
              cylinder  values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the derivative of the third form of
    the parabolic cylinder functions (W(x,a)).

    This function is limited to the case when the absolute 
    value of <x> is less than 5.

Examples:
    LET A = PBDV(1.5,2)
    LET A = PBDV1(1.5,2)

    LET Y = PBVV(X,2)
    LET YPRIME = PBVV1(X,2)
 
    LET Y = PBWA(X,1)  FOR X = -3 0.1 3
    LET YPRIME = PBWA1(X,1)  FOR X = -3 0.1 3

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CLNGAM     = Compute the complex log gamma function.
    CBETA      = Compute the complex beta function.
    CLNBETA    = Compute the complex log beta function.
    GAMMA      = Compute the Gamma function.
    GAMMAI     = Compute the incomplete Gamma function.
    DIGAMMA    = Compute the digamma function.
 
Reference:
    "Computation of Special Functions", Shanjie Zhang and Jianming
    Jin, John Wiley and Sons, 1996, chapter 13.
 
    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964, pp. 685-720.
 
Applications:
    Special Functions
 
Implementation Date:
    1997/12
 
Program 1:
    LINE SOLID DASH
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    TITLE V = 1
    PLOT PBDV(X,1) FOR X = 0.1 0.1 5 AND
    PLOT PBDV1(X,1) FOR X = 0.1 0.1 5
    TITLE V = 2
    PLOT PBDV(X,2) FOR X = 0.1 0.1 5 AND
    PLOT PBDV1(X,2) FOR X = 0.1 0.1 5
    TITLE V = 3
    PLOT PBDV(X,3) FOR X = 0.1 0.1 5 AND
    PLOT PBDV1(X,3) FOR X = 0.1 0.1 5
    TITLE V = 4
    PLOT PBDV(X,4) FOR X = 0.1 0.1 5 AND
    PLOT PBDV1(X,4) FOR X = 0.1 0.1 5
    END OF MULTIPLOT
    MOVE 50 95
    JUSTIFICATION CENTER
    TEXT PBDV (AND DERIVATIVE) FUNCTIONS
 
Program 2:
    LINE SOLID DASH
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    TITLE V = 1
    PLOT PBVV(X,1) FOR X = 0.1 0.1 5 AND
    PLOT PBVV1(X,1) FOR X = 0.1 0.1 5
    TITLE V = 2
    PLOT PBVV(X,2) FOR X = 0.1 0.1 5 AND
    PLOT PBVV1(X,2) FOR X = 0.1 0.1 5
    TITLE V = 3
    PLOT PBVV(X,3) FOR X = 0.1 0.1 5 AND
    PLOT PBVV1(X,3) FOR X = 0.1 0.1 5
    TITLE V = 4
    PLOT PBVV(X,4) FOR X = 0.1 0.1 5 AND
    PLOT PBVV1(X,4) FOR X = 0.1 0.1 5
    END OF MULTIPLOT
    MOVE 50 95
    JUSTIFICATION CENTER
    TEXT PBVV (AND DERIVATIVE) FUNCTIONS
 
Program 3:
    LINE SOLID DASH
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    TITLE V = 1
    PLOT PBWA(X,1) FOR X = 0.1 0.1 5 AND
    PLOT PBWA1(X,1) FOR X = 0.1 0.1 5
    TITLE V = 2
    PLOT PBWA(X,2) FOR X = 0.1 0.1 5 AND
    PLOT PBWA1(X,2) FOR X = 0.1 0.1 5
    TITLE V = 3
    PLOT PBWA(X,3) FOR X = 0.1 0.1 5 AND
    PLOT PBWA1(X,3) FOR X = 0.1 0.1 5
    TITLE V = 4
    PLOT PBWA(X,4) FOR X = 0.1 0.1 5 AND
    PLOT PBWA1(X,4) FOR X = 0.1 0.1 5
    END OF MULTIPLOT
    MOVE 50 95
    JUSTIFICATION CENTER
    TEXT PBWA (AND DERIVATIVE) FUNCTIONS
 
-----PEAKS OF FREQUENCY TABLE (LET)----------------------------------
 
PEAKS OF FREQUENCY TABLE
 
Name:
    PEAKS OF FREQUENCY TABLE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Bin (i.e., create a frequency table) a response variable and
    then thin the frequency table by extracting the peaks.  
 
Description:
    Binning a data variable means to divide it into classes
    and compute the frequency for each class.  This is the
    numerical equivalent of a histogram.

    Peaks are determined as follows:

       1) Compute the difference of the frequency counts.

       2) Where the differences change sign indicates a peak.
 
    Also, you can specify that relative frequencies rather than
    counts be computed.   The command

        SET RELATIVE HISTOGRAM <AREA/PERCENT>

    can be used to specify whether relative frequencies are
    computed so that the area sums to 1 or so that frequencies
    sum to 1.  The first option, which is the default, is useful
    for when using the relative binning as an estimate of a
    probability distribution.  The second option is useful when
    you want to see what percentage of the data falls in a given
    class. 

Syntax 1:
    LET <y2> <x2> = PEAKS OF FREQUENCY TABLE <y>
                    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <y2> is a variable where the computed counts (or
              frequencies) are stored;
          <x2> is a variable where the computed bin mid-points
              are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where the frequencies are
    expressed as raw counts.

Syntax 2:
    LET <y2> <x2> = RELATIVE PEAKS OF FREQUENCY TABLE <y>
                    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <y2> is a variable where the computed counts (or
              frequencies) are stored;
          <x2> is a variable where the computed bin mid-points
              are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where the frequencies are
    expressed as relative frequencies.

Examples:
    LET Y2 X2 = PEAKS OF FREQUENCY TABLE Y
    LET Y2 X2 = PEAKS OF FREQUENCY TABLE Y SUBSET TAG > 2
    LET Y2 X2 = RELATIVE PEAKS OF FREQUENCY TABLE Y
 
Note:
    As with the histogram, you can use the CLASS WIDTH, CLASS
    LOWER, and CLASS UPPER commands to override these defaults.

    By default, DATAPLOT uses a class width of 0.3 times the standard
    deviation of the variable.  A number of alternative choices for
    class width can be set with the command

        SET HISTOGRAM CLASS WIDTH

    Enter HELP HISTOGRAM CLASS WIDTH for details.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    BINNED                   = Compute a frequency table.
    COMBINE FREQUENCY TABLE  = Combine low frequency classes in a
                               frequency table.
    HISTOGRAM                = Generate a histogram.
    CLASS WIDTH              = Set class widths for histograms and
                               other related commands.
    HISTOGRAM CLASS WIDTH    = Specify the algorithm used to
                               determine the class width.
 
Applications:
    Data Analysis
 
Implementation Date:
    2008/4
 
Program:
    let u1 = 0
    let sd1 = 1
    let u2 = 5
    let sd2 = 3
    let p = 0.6
    let y = normal mixture rand numb for i = 1 1 500
    .
    set write decimals 4
    let y2 x2 = binned y
    print x2 y2
    .
    let y3 x3 = peaks of frequency table y
    print x3 y3
    .
    xlimits -5 15
    histogram y
    .
    line color blue
    line dash
    line thickness 0.2
    let ycoor1 = 0
    let npeak = size x3
    .
    loop for k = 1 1 npeak
        let xtemp = x3(k)
        let ytemp = y3(k)
        drawdata xtemp ycoor1 xtemp ytemp
    end of loop

-----PEAKS OVER THRESHOLD PLOT--------------------------------------
 
PEAKS OVER THRESHOLD PLOT
 
Name:
    PEAKS OVER THRESHOLD PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a peaks over threshold plot.
 
Description:
    In univariate extreme value analysis, there are two basic
    approaches for extracting the extreme data.

       1) We find the maximum (or minimum) value in equal
          length intervals.  For example, we could extract the
          maximum wind speed for each year and then develop a
          distributional model for these yearly maximums.

          This is commonly referred to as the "epochal"  method.

       2) An alternative is to define an overall threshold.
          We then extract all points above that threshold and
          develop a distributional model for these points.  Note
          that in this case, the number of points extracted in
          each interval is not necessarily equal.

    The generalized Pareto distribution provides a useful
    distributional model for univariate extreme value data since
    it indicates what type of extreme value model is appropriate:

       1) gamma = 0   - this is equivalent to an extreme value
                        type I (Gumbel) distribution.
       2) gamma > 0   - this is equivalent to an extreme value
                        type II (Frechet) distribution.
       3) gamma < 0   - this is equivalent to a reverse Weibull
                        distribution (in Dataplot, this is a
                        Weibull with SET MINMAX MAXIMUM).  The
                        shape parameter for the reverse Weibull
                        is -1/gamma.

    The purpose of the PEAKS OVER THRESHOLD PLOT is to see
    how the estimated value of gamma changes as the threshold
    is changed.  Specifically, the plot is generated as follows:

       1) Define an initial threshold.  In Dataplot, you can
          specify either the starting number of points above the
          threshold or a particular value for the threshold.

          To specify the intial number of points above the
          threshold, enter the command

              SET PEAKS OVER THRESHOLD INITIAL POINTS <value>

          To specify a starting value for the threshold, enter
          the command

              SET PEAKS OVER THRESHOLD INITIAL THRESHOLD <value>

          If neither command is given, Dataplot will start
          with a threshold that gives 2.5% of the data set.
          If both are specified, the INITIAL THRESHOLD takes
          precedence over the INITIAL POINTS.

       2) For the points above the threshold, estimate the
          parameters for the generalized Pareto distribution
          (see the Note section below for details on how this
          is done).

          In addition, calculate a confidence interval for
          the shape parameter.  For the de Haan and CME methods
          (see the Note section below), we compute the standard
          deviation of the estimate of gamma.  We then use
          gamma +/- 2*sd(gamma) as an estimate of the confidence
          interval.  For the PPCC plot method, the confidence
          interval is computed using bootstrapping.

       3) Decrement the threshold.  To specify how much to
          decrement the threshold at each interval, enter the
          command

              SET PEAKS OVER THRESHOLD INCREMENT <value>

          The default increment is -1.

       4) This is repeated for a pre-specified number of
          iterations.  The default number of iterations is 30.
          To change the number of iterations, enter the command

              SET PEAKS OVER THRESHOLDS ITERATIONS <value>

    The plot then consists of three curves:

       1) The point estimates of gamma.
       2) The lower confidence limit for gamma.
       3) The upper confidence limit for gamma.

    Each of these is plotted against the number of points above
    the threshold.  To have the actual threshold plotted on the
    horizontal axis, enter the command

       SET PEAKS OVER THRESHOLD X AXIS THRESHOLD

    To restore the default of the number of points above the
    threshold, enter the command

       SET PEAKS OVER THRESHOLD X AXIS POINTS

    The basic interpretation of this plot is:

        When the threshold is high, few points are included so
        the variance of gamma is also high (and so the resulting
        confidence intervals are wide).  As the threshold
        decreases (and more points are included), the variance
        of gamma decreases with resulting narrower confidence
        intervals.  However, as the number of points increases,
        the bias of the estimate of gamma increases.  This will
        often be indicated by a downward slope of the graph.
        Over intervals where the bias error is small, the
        graph will be nearly horizontal.  When choosing a
        reasonable value of gamma from the graph, it should
        be noted that larger estimates of gamma imply a
        longer tail and are therefore conservative from a
        structural engineering point of view.

    In addition to the plot, this command will also generate
    the following tables at each iteration.

        1) The first table contains the threshold, the number
           of points above the threshold, and the parameter
           estimates.

        2) In engineering applications, the mean recurrence
           interval (this is also referred to as the return
           interval or recurrence interval) is of interest.

           The return interval of a given wind speed, in years, is
           defined as the inverse of the probability that the wind
           speed will be exceeded in any one year.  It is defined as

              1/(1 - F(x))

           with F(x) denoting the cumulative distribution function.
           Mean recurrence intervals are discussed in more detail
           in Simiu and Scanlon (see References section below).

           More often, we would like to compute the wind speed
           that corresponds to a given return interval.  The
           solution to this is given by solving the above
           equation for x.

              X(R) = G(1 - (1/R))

           with G and R denoting the percent point function and
           the desired mean recurrence interval, respectively.

           The above formula is for the case of a single yearly
           maximum.  If lambda is the mean number of threshold
           crossings per year, the formula is

              X(R) = G(1 - (1/(lambda*R)))

           In the Dataplot PEAKS OVER THRESHOLD PLOT command, you
           can optionally give a second variable that specifies the
           desired mean recurrence intervals.  If you specify mean
           return intervals, Dataplot will print a table showing
           the mean return interval along with the corresponding
           wind speed (called XR).

        3) In wind engineering applications, the load factor is
           also of interest.  This is commonly computed as
 
               (XMAX/XR(50))**2
 
           with XMAX denoting the maximum value of the fitted
           generalized Pareto distribution (the generalized
           Pareto is bounded above if the shape parameter is
           negative) and XR(50) denoting the wind speed 
           corresponding to a mean recurrence interval of 50
           years.
 
           To print the value of the maximum wind speed and the
           load factor, enter the command
 
               SET PEAKS OVER THRESHOLD LOAD FACTOR OFF
 
           Since this is specific to extreme wind applications,
           it is OFF by default.
         
Syntax 1:
    PEAKS OVER THRESHOLD PLOT <y>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    PEAKS OVER THRESHOLD PLOT <y> <r>
                              <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <r> is a variable containing mean recurrence intervals;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    PEAKS OVER THRESHOLD PLOT Y
    PEAKS OVER THRESHOLD PLOT Y R
    PEAKS OVER THRESHOLD PLOT Y SUBSET TAG > 1
 
Note:
    There are a number of methods for estimating the parameters
    for the generalized Pareto distribution.  To specify the
    method, enter the command

         SET PEAKS OVER THRESHOLD METHOD <value>

    where <value> is one of the following:

         DEHAAN  - use the de Haan method (enter HELP DEHAAN
                   for the details of this method)
         CME     - use the conditional mean exceedance method
                   (enter HELP CME for the details of this method)
         PPCC    - use the PPCC (probability plot correlation
                   coefficient plot) to estimate gamma and a
                   probability plot to estimate the location and
                   scale parameters.  A 95% confidence interval
                   for the gamma parameter is obtained via the
                   bootstrap.  For details of these methods, enter
                   HELP PPCC PLOT, HELP PROBABILITY PLOT, and
                   HELP DISTRIBUTIONAL BOOTSTRAP).

                   You can obtain more accurate estimates for
                   gamma by restricting the range for the PPCC
                   plot.  Enter the commands

                      LET GAMMA1 = <lower limit>
                      LET GAMMA2 = <upper limit>

                   One recommendation is to run the plot with the
                   default limits and then rerun it with tighter
                   limits based on the first plot (be sure to keep
                   them wide enough to accomodate the bootstrap
                   estimates).

    Additional methods will be added in future releases of
    Dataplot.  The default is DEHAAN.

Note:
    Since this command generates a large number of tables, it
    is typically desired to save them to file.  To do this,
    enter the commands

       CAPTURE  POT.OUT
       PEAKS OVER THRESHOLD PLOT Y R
       END OF CAPTURE

    You can alternatively choose to save the output in HTML,
    Latek, or RTF (Rich Text Format) formats.  For example,

       CAPTURE  HTML POT.HTM
       PEAKS OVER THRESHOLD PLOT Y R
       END OF CAPTURE

       CAPTURE  LATEX POT.TEK
       PEAKS OVER THRESHOLD PLOT Y R
       END OF CAPTURE

       CAPTURE  RTF POT.RTF
       PEAKS OVER THRESHOLD PLOT Y R
       END OF CAPTURE

    The HTML and Latex formats can incorporate the plot as
    well. For details, enter

        HELP CAPTURE HTML
        HELP CAPTURE LATEX

Note:
    Dataplot automatically writes the following values to the
    file dpst1f.dat (there is one row for each distinct value
    of the threshold, the following correspond to the columns
    in dpst1f.dat):

        1. Number of points above the threshold
        2. The threshold
        3. The estimate of the shape parameter, gamma
        4. The estimate of the location parameter
        5. The estimate of the scale parameter

    If mean recurrence intervals have been specified (see
    Syntax 2), Dataplot additionally writes the following values
    to the
    file dpst2f.dat:

        1. Iteration
        2. Number of points above the threshold
        3. The threshold
        4. The requested mean recurrence interval
        5. The XR corresponding to the requested mean
           recurrence interval
        6. The load factor corresponding to the mean recurrence
           interval

     Note that the last column, the load factor, is only printed
     if the SET LOAD FACTOR ON command is entered.  This load
     factor is

           (XR/XR50)**2

     A -99.0 is printed for mean recurrence intervals less than
     or equal to 50.

     The purpose of writing these values to files is to allow
     you to perform additional analyses.  For example, you may
     want to plot the XR corresponding to the various return
     intervals.  This is demonstrated in the program example
     below.

Note:
     Some sources reverse the sign in the definition of the
     generalized Pareto distribution.  For details, enter
     the command

          HELP GEPPDF

     If you use the reversed sign definition, then adjust the
     role of positive and negative values of gamma in the 
     discussion above.

Default:
    None
 
Synonyms:
    POT is a synonym for PEAKS OVER THRESHOLD
 
Related Commands:
    DEHAAN            = Compute the estimates for the parameters
                        of the generalized Pareto distribution
                        using the de Haan method.
    CME               = Compute the estimates for the parameters
                        of the generalized Pareto distribution
                        using the CME method.
    GEPPPF            = Computes the percent point function of
                        the generalized Pareto distribution.
    PPCC PLOT         = Generates a ppcc plot.
    PROBABILITY PLOT  = Generates a probability plot.
    DISTRIBUTIONAL    = Perform a bootstrap analysis for a
        BOOTSTRAP       univariate distribution.
    CME PLOT          = Generates a conditional mean exceedance plot.
 
Reference:
    E. Simiu, N. A. Heckert, and T. Whalen (April, 1996). "Estimates
    of Hurricane Wind Speeds by the 'Peaks Over Threshold' Method",
    NIST Technical Note 1416.
 
    E. Simiu and N. A. Heckert (March 1995). "Extreme Wind
    Distribution Tails: A 'Peak Over Threshold' Approach",
    NIST Building Science Series 174.

    Alan Heckert, Emil Simiu, and Tim Whalen (April,1998).
    "Estimates of Hurricane Wind Speeds by the 'Peaks Over
    Threshold' Approach", Journal of Structural Engineering,
    pp. 445-449.

    J. A. Lechner, E. Simiu, N. A. Heckert (1993). "Assessment of
    'peak over threshold' Methods for Estimating Extreme Value
    Distribution Tails", Structural Safety, 12, pp. 305-314.

    E. Simiu and N. A. Heckert (1996). "Extreme Wind Distribution
    Tails: A 'Peaks Over Threshold' Approach", Journal of Structural
    Engineering, Vol. 122, No. 5, 1996.

Applications:
    Extreme Value Analysis
 
Implementation Date:
    2005/5
 
Program:
    DIMENSION 40 COLUMNS
    SKIP 2
    READ PARAMETER MPOST550.DAT URATE
    SKIP 3
    READ MPOST550.DAT Y1 TO Y17
    .
    TITLE Peaks Over Threshold Plot (Milepost 550)CR()de Haan Method
    TITLE DISPLACEMENT 5
    Y1LABEL Gamma
    X1LABEL Number of Points Above Threshold
    TITLE CASE ASIS
    LABEL CASE ASIS
    LINE SOLID DOT DOT
    LINE THICKNESS 0.2 0.1 0.1
    .
    SET PEAKS OVER THRESHOLD ITERATIONS 50
    SET PEAKS OVER THRESHOLD PERIOD URATE
    SET PEAKS OVER THRESHOLD METHOD DEHAAN
    .
    LET R = DATA 25 50 100 200 500 1000
    .
    CAPTURE POT.OUT
    PEAKS OVER THRESHOLD PLOT Y17 R
    END OF CAPTURE
    .
    SKIP 0
    READ DPST2F.DAT ITER NPOINTS THRESH R2 XR
    .
    TITLE Mean Recurrence Intervals (Milepost 550)
    TITLE DISPLACEMENT 2
    Y1LABEL XR
    LINE SOLID ALL
    LINE THICKNESS 0.1 ALL
    .
    PLOT XR NPOINTS R2
    .
    CRLF ON
    MARGIN 87
    MOVE 87 88
    TEXT 1,000 - yr
    TEXT 500
    TEXT 200
    TEXT 100
    TEXT 50
    TEXT 25
 
-----PEARSON CONTINGENCY COEFICIENT (LET)--------------------------------
 
PEARSON CONTINGENCY COEFICIENT
 
Name:
    PEARSON CONTINGENCY COEFICIENT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute Pearson's contingency coefficient for an RxC contingency
    table.
 
Description:
    If we have N observations with two variables where each
    observation can be classified into one of R mutually exclusive
    categories for variable one and one of C mutually exclusive
    categories for variable two, then a cross-tabulation of the
    data results in a two-way contingency table (also referred to
    as an RxC contingency table).  The resulting contingency table
    has R rows and C columns.

    A common question with regards to a two-way contingency
    table is whether we have independence.  By independence, we
    mean that the row and column variables are unassociated
    (i.e., knowing the value of the row variable will not
    help us predict the value of column variable and likewise
    knowing the value of the column variable will not help us
    predict the value of the row variable).

    A more technical definition for independence is that

        P(row i, column j) = P(row i)*P(column j)   for all i,j

    The standard test statistic for determing independence is
    the chi-square test statistic:

        T = SUM[i=1 to r][j=1 to c][(O(ij) - E(ij)**2/E(ij)]

    where
 
       r     = the number of rows in the contingency table
       c     = the number of columns in the contingency table
       O(ij) = the observed frequency of the ith row and
               jth column
       E(ij) = the expected frequency of the ith row and
               jth column
             = R(i)*C(j)/N
       R(i)  = the sum of the observed frequencies for row i
       C(j)  = the sum of the observed frequencies for column j
       N     = the total sample size

    One criticism of this statistic is that it does not give a
    meaningful description of the degree of dependence (or strength of
    association).   That is, it is useful for determining whether there
    is dependence. However, since the strength of that association also
    depends on the degrees of freedom as well as the value of the test
    statistic, it is not easy to interpert the strength of association.

    The Pearson's contingency coefficient is one method to provide an
    easier to interpret measure of strength of association.  Specifically,
    it is:

       Pearson's Coefficient = SQRT(T/(N+T))

    where

       T   = the chi-square test statistic given above
       N   = the total sample size

    So this statistic basically scales the chi-square statistic to
    a value between 0 (no association) and 1 (maximum association).
    It has the desirable property of scale invariance.  That is,
    if the sample size increases, the value of Pearson's contingency
    coefficient does not change as long as values in the table change
    the same relative to each other.

    The data for the contingency table can be specified in either of
    the following two ways:

        1) raw data

           In this case, you will have two variables.  The first
           will contain r distinct values and the second will contain
           c distinct values.  Dataplot will automatically perform the
           cross-tabulation to obtain the counts for each cell.  Although
           the distinct values will typically be integers, this is not
           strictly required.

        2) table data

           If you only have the resulting contingency table (i.e., the
           counts for each cell), then you can use the READ MATRIX (or
           CREATE MATRIX) command to create a matrix with the data.  This
           is demonstrated in the example program below.

           In this case, your data should contain non-negative integers
           since they represent the counts for each cell.

Syntax 1:
    LET <par> = PEARSON CONTINGENCY COEFICIENT <y1> <y2>
                              <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed Pearson contingency
               coefficient is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Use this syntax for raw data.

Syntax 2:
    LET <par> = MATRIX GRAND PEARSON CONTINGENCY COEFICIENT <y1> <y2>
                              <SUBSET/EXCEPT/FOR qualification>
    where <m> is a matrix containing the contingency table;
          <par> is a parameter where the computed Pearson contingency
               coefficient is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Use this syntax if your data is a contingency table.

Examples:
    LET A = PEARSON CONTINGENCY COEFICIENT Y1 Y2
    LET A = MATRIX GRAND PEARSON CONTINGENCY COEFICIENT M
 
Note:
    The Cramer contingency coefficient is more commonly used
    than the Pearson contingency coefficient.

Note:
    For the raw data case, the two variables should have the same
    number of elements.
 
Note:
    The following additional commands are supported

        TABULATE PEARSON CONTINGENCY COEFICIENT  Y1 Y2 X
        CROSS TABULATE PEARSON CONTINGENCY COEFICIENT Y1 Y2 X1 X2

        PEARSON CONTINGENCY COEFICIENT PLOT Y1 Y2 X
        CROSS TABULATE PEARSON CONTINGENCY COEFICIENT PLOT Y1 Y2 X1 X2

        BOOTSTRAP PEARSON CONTINGENCY COEFICIENT PLOT Y1 Y2
        JACKNIFE  PEARSON CONTINGENCY COEFICIENT PLOT Y1 Y2

    Note that the above commands expect the variables to have
    the same number of observations.

    Note that the above commands are only available if you have
    raw data.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHI-SQUARE INDEPENDENCE TEST     = Perform a chi-square test for
                                       independence.
    CRAMER CONTINGENCY COEFFICIENT   = Compute Cramer's contingency 
                                       coefficient.
    ASSOCIATION PLOT                 = Generate an association plot.
    SIEVE PLOT                       = Generate a sieve plot.
    ODDS RATIO INDEPENDENCE TEST     = Perform a log(odds ratio) test for
                                       independence.
    FISHER EXACT TEST                = Perform Fisher's exact test.
    ROSE PLOT                        = Generate a Rose plot.
    BINARY TABULATION PLOT           = Generate a binary tabulation plot.
    ROC CURVE                        = Generate a ROC curve.
    ODDS RATIO                       = Compute the bias corrected odds
                                       ratio.
    LOG ODDS RATIO                   = Compute the bias corrected
                                       log(odds ratio).
 
Reference:
    Conover (1999), "Practical Nonparametric Statistics",
    Third Edition, Wiley, pp. 229-230.

    Friendly (2000), "Visualizing Categorical Data", SAS Institute
    Inc., p. 61.

Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/5
 
Program:
    . Sample data from page 61 of Friendly
    read matrix m
     5  29 14 16
    15  54 14 10
    20  84 17 94
    68 119 26 7
    end of data
    .
    let a = matrix pearson contingency coefficient m
 
-----PEARSON DISSIMILARITY (LET)--------------------------------
 
PEARSON DISSIMILARITY
 
Name:
    PEARSON DISSIMILARITY (LET)
    PEARSON SIMILARITY (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the Pearson correlation coefficient transformed to a
    dissimilarity measure between two variables.
 
Description:
    The correlation coefficient is a measure of the linear relationship
    between two variables.  It is computed as:

         Sxx = SUM[i=1 to N][(X(i)-XMEAN)**2]
         Syy = SUM[i=1 to N]([Y(i)-YMEAN)**2]
         Sxy = SUM[i=1 to N][(X(i)-XMEAN)*(Y(i)-YMEAN)]
         r = Sxy/SQRT(Sxx*Syy)

    A perfect linear relationship yields a correlation coefficient of
    +1 (or -1 for a negative relationship) and no linear relationship
    yields a correlation coefficient of 0.
 
    In some applications, such as clustering, it can be useful to
    transform the correlation coefficient to a dissimilarity measure.
    The transformation used here is

        d = (1 - r)/2

    This converts the correlation coefficient with values between -1 and
    1 to a score between 0 and 1.  High positive correlation (i.e., very
    similar) results in a dissimilarity near 0 and high negative
    correlation (i.e., very dissimilar) results in a dissimilarity near 1.

    If a similarity score is preferred, you can use

        s = 1 - d

    where d is defined as above.

Syntax 1:
    LET <par> = PEARSON DISSIMILARITY <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed Pearson dissimilarity
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Syntax 2:
    LET <par> = PEARSON SIMILARITY <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed Pearson similarity
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET A = PEARSON DISSIMILARITY Y1 Y2
    LET A = PEARSON DISSIMILARITY Y1 Y2 SUBSET TAG > 2
    LET A = PEARSON SIMILARITY Y1 Y2
 
Note:
    The two variables must have the same number of elements.
 
Default:
    None
 
Synonyms:
    PEARSON DISTANCE is a synonym for PEARSON DISSIMILARITY
 
Related Commands:
    CORRELATION               = Compute the Pearson correlation of two
                                variables.
    SPEARMAN DISSIMILARITY    = Compute the dissimilarity of two variables
                                based on Spearman's rank correlation.
    KENDALL TAU DISSIMILARITY = Compute the dissimilarity of two variables
                                based on Kendall's tau correlation.
    COSINE DISTANCE           = Compute the cosine distance.
    MANHATTAN DISTANCE        = Compute the Euclidean distance.
    EUCLIDEAN DISTANCE        = Compute the Euclidean distance.
    MATRIX DISTANCE           = Compute various distance metrics for a
                                matrix.
    GENERATE MATRIX <stat>    = Compute a matrix of pairwise statistic
                                values.
    CLUSTER                   = Perform a cluster analysis.
 
Reference:
    Kaufman and Rousseeuw (1990), "Finding Groups in Data: An
    Introduction To Cluster Analysis", Wiley.

Applications:
    Clustering
 
Implementation Date:
    2017/08:
    2018/10: Added PEARSON SIMILARITY
 
Program 1:
    SKIP 25
    READ BERGER1.DAT Y X
    LET CORR = CORRELATION Y X
    LET D    = PEARSON DISSIMILARITY Y X
    SET WRITE DECIMALS 3
    PRINT CORR D
 
Program 2:
    SKIP 25
    READ IRIS.DAT Y1 Y2 Y3 Y4
    SET WRITE DECIMALS 3
    .
    LET M = GENERATE MATRIX PEARSON DISSIMILARITY Y1 Y2 Y3 Y4
    PRINT M
 
Program 3:
    SKIP 25
    READ IRIS.DAT Y1 Y2 Y3 Y4 TAG
    .
    CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    LABEL CASE ASIS
    TIC MARK OFFSET UNITS DATA
    YLIMITS 0 1
    MAJOR YTIC MARK NUMBER 6
    MINOR YTIC MARK NUMBER 1
    Y1TIC MARK LABEL DECIMAL 1
    Y1LABEL DISPLACEMENT 20
    X1LABEL Species
    XLIMITS 1 3
    MAJOR XTIC MARK NUMBER 3
    MINOR XTIC MARK NUMBER 0
    XTIC MARK OFFSET 0.3 0.3
    X1LABEL DISPLACEMENT 14
    CHARACTER X BLANK
    LINES BLANK SOLID
    .
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    MULTIPLOT SCALE FACTOR 2
    MULTIPLOT 2 3
    .
    TITLE Sepal Length vs Sepal Width
    CORRELATION PLOT Y1 Y2 TAG
    .
    TITLE Sepal Length vs Petal Length
    CORRELATION PLOT Y1 Y3 TAG
    .
    TITLE Sepal Length vs Petal Width
    CORRELATION PLOT Y1 Y4 TAG
    .
    TITLE Sepal Width vs Petal Length
    CORRELATION PLOT Y2 Y3 TAG
    .
    TITLE Sepal Width vs Petal Width
    CORRELATION PLOT Y2 Y4 TAG
    .
    TITLE Petal Length vs Petal Width
    CORRELATION PLOT Y3 Y4 TAG
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Pearson Dissimilarity Coefficient
 
-----PEDESTAL-------------------------------------------------------
 
PEDESTAL
 
Note:
    THIS COMMAND IS NOT CURRENTLY OPERATIONAL!!!!
 
Name:
    PEDESTAL
 
Type:
    Plot Control Command
 
Purpose:
    Specifies whether or not a pedestal will appear on subsequent
    3-d plots (as generated via the 3D-PLOT command).
 
Description:
    A pedestal is a base upon which 3-dimensional surfaces may rest.
    It is the preferred representation of 3-d surfaces by some
    analysts.
 
Syntax:
    PEDESTAL   <ON or OFF>
    where ON specifies that the pedestal will be generated while OFF
             specifies that it will not.
 
Examples:
    PEDESTAL ON
    PEDESTAL OFF
    PEDESTAL
 
Default:
    Off
 
Synonyms:
    None
 
Related Commands:
    3D-PLOT            = Generates a 3-d data or function plot.
    EYE COORDINATES    = Sets the location of the eye for 3-d plots.
    PEDESTAL COLOR     = Sets the pedestal color for 3-d plots.
    PEDESTAL SIZE      = Sets the pedestal height for 3-d plots.
    VISIBLE            = Allows/suppress hidden lines in 3-d plots.
 
Applications:
    3D plots
 
Implementation Date:
    XX
 
Program:
    XX
 
-----PEDESTAL COLOR----------------------------------------------------
 
PEDESTAL COLOR
 
Note:
    The PEDESTAL command is not currently operational, so this command
    has no effect.
 
Name:
    PEDESTAL COLOR
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the color of the lines which constitute the pedestal in
    subsequent 3-d plots.
 
Syntax:
    PEDESTAL COLOR  <color>
    where <color> specifies the desired color.
 
Examples:
    PEDESTAL COLOR GREEN
    PEDESTAL COLOR YELLOW
    PEDESTAL COLOR
 
Note:
    The PEDESTAL COLOR command with no arguments reverts the pedestal
    color to default.
 
Default:
    The default is black (but the default is for the pedestal lines
    themselves to be off.)
 
Synonyms:
    None
 
Related Commands:
    PEDESTAL           = Allows/suppresses the pedestal for 3-d plots.
    PEDESTAL SIZE      = Sets the pedestal height for 3-d plots.
    3D-PLOT            = Generates a 3-d data or function plot.
    EYE COORDINATES    = Sets the location of eye for 3-d plots.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----PEDESTAL SIZE----------------------------------------------------
 
PEDESTAL SIZE
 
Note:
    The PEDESTAL command is not currently operational, so this command
    has no effect.
 
Name:
    PEDESTAL SIZE
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the vertical height of the pedestal in subsequent 3-d
    plots.
 
Description:
    The size is in units of the vertical axis variable on the 3-d plot.
 
Syntax:
    PEDESTAL SIZE   <size>
    where <size> is a number or parameter in units of the 3-d vertical
             axis variable that specifies the size.
 
Examples:
    PEDESTAL SIZE 2000
    PEDESTAL SIZE 4500
    PEDESTAL SIZE 0.0025
 
Default:
    The default size is (zmax - zmin) where
       zmax = the data maximum for the vertical axis variable;
       zmin = the data minimum for the vertical axis variable.
 
Synonyms:
    None
 
Related Commands:
    PEDESTAL           = Allows/suppresses the pedestal for 3-d plots.
    PEDESTAL COLOR     = Sets the pedestal color for 3-d plots.
    3D-PLOT            = Generates a 3-d data or function plot.
    EYE COORDINATES    = Sets the location of the eye for 3-d plots.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----PEN MAP-------------------------------------------------------
 
PEN MAP
 
Name:
    PEN MAP
 
Type:
    Output Devices Command
 
Purpose:
    Allows the mapping of colors to pen slots to be defined by
    the user for selected pen plotters.
 
Description:
    Pen plotters allow different color pens to be loaded into each pen
    slot.  Previously, the color to pen slot mapping was hard coded in
    DATAPLOT.  The PEN MAP allows the user to re-define the default
    mapping for the HP-GL, ZETA, and CALCOMP devices.
 
    For each of the supported devices, up to 16 pens can be defined.
    Also, specifying "LIST/SHOW/PRINT" for the color will print the
    current mapping and "DEFAULT" will reset the default mapping.
 
    DATAPLOT also supports the Tektronix 4662 and HP 7221 plotters.
    However, these are now essentially obsolete, so they are not
    supported with this command.
 
Syntax 1:
    <device> PEN MAP <color> <index>
    where <device> is one of the following:
             HPGL     - for HPGL plotters
             CALCOMP  - for CALCOMP plotters
             ZETA     - for Zeta plotters;
         <color> is a character string that specifies one of the
             colors available on the plotter;
    and  <index> is an integer number or parameter between 1 and 16.
 
Syntax 2:
    <device> PEN MAP <keyword>
    where <device> is one of the following:
             HPGL     - for HPGL plotters
             CALCOMP  - for CALCOMP plotters
             ZETA     - for Zeta plotters;
    and  <keyword> is one of the following:
             LIST     - print the current mapping
             SHOW     - print the current mapping
             PRINT    - print the current mapping
             DEFAULT  - reset the default mapping.
 
Examples:
    HPGL PEN MAP DEFAULT
    HPGL PEN MAP SHOW
    HPGL PEN MAP RED 4
    CALCOMP PEN MAP BLUE 2
    ZETA PEN MAP GREEN 4
 
Note:
    If a color is defined more than once, it is mapped to lowest pen
    slot.
 
Note:
    In earlier versions of DATAPLOT, specifying a color by index
    would cause penplotters to use the slot corresponding to the index
    number (i.e., color 1 would go to slot 1).  However, to make the
    use of color names and color indices consistent across devices,
    an index now maps to a specific color (e.g., color 1 maps to
    black).  This color is then mapped to a particular slot number
    (which is not necessarily the same as the index number).  To see
    the default color to slot mapping, enter one of the following
    DATAPLOT commands:
        SHOW COLORS CALCOMP
        SHOW COLORS ZETA
        SHOW COLORS HPGL
    The PEN MAP command can be used to override the default color to
    slot mapping.
 
Note:
    If your plotter always has the same color pens in the same slots
    with an order different than the default DATAPLOT order, then a
    series of PEN MAP commands can be placed in the start-up file
    DPLOGF.DAT.
 
Default:
    The following is the default color to slot mapping for an eight
    slot penplotter:
        BLACK       1
        RED         2
        BLUE        3
        GREEN       4
        MAGENTA     5
        ORANGE      6
        CYAN        7
        YELLOW      8
 
Synonyms:
    None
 
Related Commands:
    SHOW COLORS    = Print the available colors.
 
Applications:
    XX
 
Implementation Date:
    90/6
 
Program:
    HPGL PEN MAP BLACK 1
    HPGL PEN MAP BLUE   2
    HPGL PEN MAP GREEN  3
    HPGL PEN MAP RED 4
 
-----PEQ (LET)----------------------------------------------
 
PEQ
 
Name:
    PEQ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the real component of the Weierstrass P elliptic function
    of a complex number (equianharmonic case with unit period
    parallelogram).
 
Description:
    The Weierstrass elliptic function is described in detail in the
    Handbook of Mathematical Functions (see REFERENCE section below).

Syntax:
    LET <a> = PEQ(<xr>,<xc>)  <SUBSET/EXCEPT/FOR qualification>
    where <xr> is a number, parameter, or variable that specifies the
              the real component of the input;
          <xc> is a number, parameter, or variable that specifies the
              the complex component of the input;
          <a> is a variable or a parameter (depending on what <xr> and
               <xc> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PEQ(2,1)
    LET A = PEQ(X,4)
    LET X2 = PEQ(1,Y)
 
Note:
    The Weierstrass elliptic functions are computed using algorithm
    549 from the ACM Transactions on Mathematical Software (see the
    REFERENCE section below).

Note:
    If the input value corresponds to a lattice point, an error
    message is printed and the output value is set to the largest
    real number on the machine.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PEQI    = Compute the complex component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQ1    = Compute the real component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PEQ1I   = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PLEM    = Compute the real component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEMI   = Compute the complex component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEM1   = Compute the real component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    PLEM1I  = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    SN      = Compute the Jacobi elliptic function sn.
    CN      = Compute the Jacobi elliptic function cn.
    DN      = Compute the Jacobi elliptic function dn.
    RF      = Compute the Carlson elliptic integral of the first kind.
    RD      = Compute the Carlson elliptic integral of the second kind.
    RJ      = Compute the Carlson elliptic integral of the third kind.
    ELLIPC1 = Compute the Legendre complete elliptic integral of the
              first kind.
    ELLIPC2 = Compute the Legendre complete elliptic integral of the
              second kind.
    ELLIP1  = Compute the Legendre elliptic integral of the first
              kind.
    ELLIP2  = Compute the Legendre elliptic integral of the second
              kind.
    ELLIP3  = Compute the Legendre's elliptic integral of the third
              kind.
 
Reference:
    "Algorithm 549: Weierstrass' Elliptic Functions", Eckhardt, ACM
    Transactions on Mathematical Software, vol. 6 (pp. 112-120).

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 18).

Applications:
    Special Functions
 
Implementation Date:
    94/11
 
Program:
    TITLE WEIERSTRASS ELLIPTIC FUNCTIONS
    LINE SOLID DASH
    PLOT PEQ(X,0.5) FOR X = 0 0.01 5 AND
    PLOT PEQI(X,0.5) FOR X = 0 0.01 5
 
-----PEQI (LET)----------------------------------------------
 
PEQI
 
Name:
    PEQI (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the complex component of the Weierstrass P elliptic
    function of a complex number (equianharmonic case with unit period
    parallelogram).
 
Description:
    The Weierstrass elliptic function is described in detail in the
    Handbook of Mathematical Functions (see REFERENCE section below).

Syntax:
    LET <a> = PEQI(<xr>,<xc>)  <SUBSET/EXCEPT/FOR qualification>
    where <xr> is a number, parameter, or variable that specifies the
              the real component of the input;
          <xc> is a number, parameter, or variable that specifies the
              the complex component of the input;
          <a> is a variable or a parameter (depending on what <xr> and
               <xc> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PEQI(2,1)
    LET A = PEQI(X,4)
    LET X2 = PEQI(1,Y)
 
Note:
    The Weierstrass elliptic functions are computed using algorithm
    549 from the ACM Transactions on Mathematical Software (see the
    REFERENCE section below).

Note:
    If the input value corresponds to a lattice point, an error
    message is printed and the output value is set to the largest
    real number on the machine.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PEQ     = Compute the real component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQ1    = Compute the real component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PEQ1I   = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PLEM    = Compute the real component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEMI   = Compute the complex component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEM1   = Compute the real component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    PLEM1I  = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    SN      = Compute the Jacobi elliptic function sn.
    CN      = Compute the Jacobi elliptic function cn.
    DN      = Compute the Jacobi elliptic function dn.
    RF      = Compute the Carlson elliptic integral of the first kind.
    RD      = Compute the Carlson elliptic integral of the second kind.
    RJ      = Compute the Carlson elliptic integral of the third kind.
    ELLIPC1 = Compute the Legendre complete elliptic integral of the
              first kind.
    ELLIPC2 = Compute the Legendre complete elliptic integral of the
              second kind.
    ELLIP1  = Compute the Legendre elliptic integral of the first
              kind.
    ELLIP2  = Compute the Legendre elliptic integral of the second
              kind.
    ELLIP3  = Compute the Legendre's elliptic integral of the third
              kind.
 
Reference:
    "Algorithm 549: Weierstrass' Elliptic Functions", Eckhardt, ACM
    Transactions on Mathematical Software, vol. 6 (pp. 112-120).

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 18).

Applications:
    Special Functions
 
Implementation Date:
    94/11
 
Program:
    TITLE WEIERSTRASS ELLIPTIC FUNCTIONS
    LINE SOLID DASH
    PLOT PEQI(X,0.5) FOR X = 0 0.01 5 AND
    PLOT PEQ(X,0.5) FOR X = 0 0.01 5
 
-----PEQ1 (LET)----------------------------------------------
 
PEQ1
 
Name:
    PEQ1 (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the real component of the first derivative of the 
    Weierstrass P elliptic function of a complex number (equianharmonic
    case with unit period parallelogram).
 
Description:
    The Weierstrass elliptic function is described in detail in the
    Handbook of Mathematical Functions (see REFERENCE section below).

Syntax:
    LET <a> = PEQ1(<xr>,<xc>)  <SUBSET/EXCEPT/FOR qualification>
    where <xr> is a number, parameter, or variable that specifies the
              the real component of the input;
          <xc> is a number, parameter, or variable that specifies the
              the complex component of the input;
          <a> is a variable or a parameter (depending on what <xr> and
               <xc> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PEQ1(2,1)
    LET A = PEQ1(X,4)
    LET X2 = PEQ1(1,Y)
 
Note:
    The Weierstrass elliptic functions are computed using algorithm
    549 from the ACM Transactions on Mathematical Software (see the
    REFERENCE section below).

Note:
    If the input value corresponds to a lattice point, an error
    message is printed and the output value is set to the largest
    real number on the machine.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PEQ     = Compute the real component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQI    = Compute the complex component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQ1I   = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PLEM    = Compute the real component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEMI   = Compute the complex component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEM1   = Compute the real component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    PLEM1I  = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    SN      = Compute the Jacobi elliptic function sn.
    CN      = Compute the Jacobi elliptic function cn.
    DN      = Compute the Jacobi elliptic function dn.
    RF      = Compute the Carlson elliptic integral of the first kind.
    RD      = Compute the Carlson elliptic integral of the second kind.
    RJ      = Compute the Carlson elliptic integral of the third kind.
    ELLIPC1 = Compute the Legendre complete elliptic integral of the
              first kind.
    ELLIPC2 = Compute the Legendre complete elliptic integral of the
              second kind.
    ELLIP1  = Compute the Legendre elliptic integral of the first
              kind.
    ELLIP2  = Compute the Legendre elliptic integral of the second
              kind.
    ELLIP3  = Compute the Legendre's elliptic integral of the third
              kind.
 
Reference:
    "Algorithm 549: Weierstrass' Elliptic Functions", Eckhardt, ACM
    Transactions on Mathematical Software, vol. 6 (pp. 112-120).

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 18).

Applications:
    Special Functions
 
Implementation Date:
    94/11
 
Program:
    TITLE WEIERSTRASS ELLIPTIC FUNCTIONS
    LINE SOLID DASH
    PLOT PEQ1(X,0.5) FOR X = 0 0.01 5 AND
    PLOT PEQ1I(X,0.5) FOR X = 0 0.01 5
 
-----PEQ1I (LET)----------------------------------------------
 
PEQ1I
 
Name:
    PEQ1I (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the complex component of the first derivative of the 
    Weierstrass P elliptic function of a complex number (equianharmonic
    case with unit period parallelogram).
 
Description:
    The Weierstrass elliptic function is described in detail in the
    Handbook of Mathematical Functions (see REFERENCE section below).

Syntax:
    LET <a> = PEQ1I(<xr>,<xc>)  <SUBSET/EXCEPT/FOR qualification>
    where <xr> is a number, parameter, or variable that specifies the
              the real component of the input;
          <xc> is a number, parameter, or variable that specifies the
              the complex component of the input;
          <a> is a variable or a parameter (depending on what <xr> and
               <xc> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PEQ1I(2,1)
    LET A = PEQ1I(X,4)
    LET X2 = PEQ1I(1,Y)
 
Note:
    The Weierstrass elliptic functions are computed using algorithm
    549 from the ACM Transactions on Mathematical Software (see the
    REFERENCE section below).

Note:
    If the input value corresponds to a lattice point, an error
    message is printed and the output value is set to the largest
    real number on the machine.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PEQ     = Compute the real component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQI    = Compute the complex component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQ1    = Compute the real component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PLEM    = Compute the real component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEMI   = Compute the complex component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEM1   = Compute the real component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    PLEM1I  = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    SN      = Compute the Jacobi elliptic function sn.
    CN      = Compute the Jacobi elliptic function cn.
    DN      = Compute the Jacobi elliptic function dn.
    RF      = Compute the Carlson elliptic integral of the first kind.
    RD      = Compute the Carlson elliptic integral of the second kind.
    RJ      = Compute the Carlson elliptic integral of the third kind.
    ELLIPC1 = Compute the Legendre complete elliptic integral of the
              first kind.
    ELLIPC2 = Compute the Legendre complete elliptic integral of the
              second kind.
    ELLIP1  = Compute the Legendre elliptic integral of the first
              kind.
    ELLIP2  = Compute the Legendre elliptic integral of the second
              kind.
    ELLIP3  = Compute the Legendre's elliptic integral of the third
              kind.
 
Reference:
    "Algorithm 549: Weierstrass' Elliptic Functions", Eckhardt, ACM
    Transactions on Mathematical Software, vol. 6 (pp. 112-120).

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 18).

Applications:
    Special Functions
 
Implementation Date:
    94/11
 
Program:
    TITLE WEIERSTRASS ELLIPTIC FUNCTIONS
    LINE SOLID DASH
    PLOT PEQ1(X,0.5) FOR X = 0 0.01 5 AND
    PLOT PEQ1I(X,0.5) FOR X = 0 0.01 5
 
-----PERCDIF (LET)--------------------------------
 
PERCDIF
 
Name:
    PERCDIF (LET)
 
Type:
    Library Function
 
Purpose:
    Return the percent difference of two numbers.

Description:
    The definition of the percent difference between X1 and X2 used
    by Dataplot is:

         Percent Difference = 100*ABS(X1 - X2)/MAX(ABS(X1),ABS(X2))
 
    Dataplot also supports the alternative formula

         Percent Difference = 100*ABS((X1 - X2)/((X1 + X2)/2))
 
Syntax 1:
    LET <y> = PERCDIF(<y1>,<y2>)      <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter;
          <y>  is a variable or a parameter (depending on what <y1> and
               <y2> are) where the computed percent difference values
               are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax implements the first formula given above (the
    denominator is the maximum of the two values).

Syntax 2:
    LET <y> = PERCDIF2(<y1>,<y2>)      <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter;
          <y>  is a variable or a parameter (depending on what <y1> and
               <y2> are) where the computed percent difference values
               are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax implements the second formula given above (the
    denominator is the average of the two values).

Examples:
    LET A = PERCDIF(14,10)
    LET A = PERCDIF(A1,A2)
    LET X2 = PERCDIF(X1,X4)
    LET X2 = PERCDIF(X1-4,X2+6)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PERCERR  = Compute the percent error of two numbers.
    RELDIF   = Compute the relative difference of two numbers.
    RELERR   = Compute the relative error of two numbers.
    MIN      = Compute the minimum of two numbers.
    MAX      = Compute the maximum of two numbers.
    ABS      = Compute the absolute value of a number.
 
Applications:
    Data Management
 
Implementation Date:
    2010/12
 
Program:
    LET X = SEQUENCE 0.1  0.1  3
    LET Y1 = X**2
    LET Y2 = X**(1/2)
    LET Y3 = PERCDIF(Y1,Y2)
    SET WRITE DECIMALS 5
    PRINT Y1 Y2 Y3
 
-----PERCENT AGREE (LET)------------------------------------------------
 
PERCENT AGREE
 
Name:
    PERCENT AGREE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the percentage of values that agree in two response
    variables.  This is pairwise agreement (i.e., how often does
    Y1(I) = Y2(I) for I = 1, ..., N).
 
Description:
    Given two methods (or two labortories), it may sometimes be useful
    to know how often they reach the same conclusion.

    For example, if we have two sensors that either detect or do not
    detect the presence of some quantity of interest, how often do
    the two detectors agree?

    This command is typically used when there a discrete number of
    values for the variable.  Often this will be two (e.g., Yes/No
    type data), but it is not restricted to two.

    If you want to compare values for two response variables when
    the data is continuous, the YOUDEN PLOT is recommended.

Syntax:
    LET <par> = PERCENT AGREE <y1> <y2>  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the percent agree is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PERCENT AGREE Y1 Y2
    LET A = PERCENT AGREE Y1 Y2  SUBSET TAG > 1
 
Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PERCENT DISAGREE   = Compute the percentage of values that disagree
                         in two response variables.
    FALSE NEGATIVES    = Compute the proportion of false negatives.
    FALSE POSITIVES    = Compute the proportion of false positives.
    TRUE NEGATIVES     = Compute the proportion of true negatives.
    TRUE POSITIVES     = Compute the proportion of true positives.
    TEST SENSITIVITY   = Compute the test sensitivity.
    TEST SPECIFICITY   = Compute the test specificity.
    ODDS RATIO         = Compute the bias corrected log(odds ratio).
    YOUDEN PLOT        = Generate a Youden plot.
 
Applications:
    Categorical Data Analysis
 
Implementation Date:
    2011/7
 
Program:
    .  Step 1: Read the Data
    .
    .          Column 1: Method 1 (low  => live cell, high => dead cell)
    .          Column 2: Method 2 (high => live cell, low  => dead cell)
    .
    dimension 40 columns
    read percmat  intensity
      7.1             39.8
      8.5             29.6
     72.7              4.2
     32.3             12.3
      5.4             21.5
     71.1              4.4
    100.0             13.5
     55.0             22.4
     15.0             25.9
      8.7             38.5
      0.9             16.6
     19.0             48.5
    100.0              4.3
    100.0              7.9
      5.2             42.6
     21.8             47.2
     90.0              1.0
      2.0             23.5
     98.0              2.2
    100.0              6.2
    100.0              2.0
    100.0              5.6
    100.0              3.0
     30.0             14.3
    100.0              1.0
    end of data
    .
    .  Step 3: Generate fluctuation plot based on different levels of
    .          the 2 methods
    .
    .          Use intensity levels of 5%, 10%, 15%, 20%, 25%
    .          Use percent matching levels of 80%, 90%, 95%, 99.5%
    .
    let n = size intensity
    let intcut = data 5 10 15 20 25
    let nint = size intcut
    let matcut = data 80 90 95 99.5
    let nmat = size matcut
    .
    let int2 = intensity
    let mat2 = percmat
    let xgroup = 1 for i = 1 1 n
    let ygroup = 1 for i = 1 1 n
    let icnt = 0
    .
    loop for k = 1 1 nint
        let acut = intcut(k)
        loop for l = 1 1 nmat
            let bcut = matcut(l)
            let icnt = icnt + 1
            if icnt = 1
               let xgroupal = xgroup
               let ygroupal = ygroup
               let intcor = 0 for i = 1 1 n
               let intcor = 1 subset int2 >  acut
               let intall = intcor
               let matcor = 0 for i = 1 1 n
               let matcor = 1 subset mat2 < bcut
               let matall = matcor
            else
               let xgroup2 = k for i = 1 1 n
               extend xgroupal xgroup2
               let ygroup2 = l for i = 1 1 n
               extend ygroupal ygroup2
               let intcor = 0 for i = 1 1 n
               let intcor = 1 subset int2 >  acut
               extend intall intcor
               let matcor = 0 for i = 1 1 n
               let matcor = 1 subset mat2 < bcut
               extend matall matcor
            end of if
        end of loop
    end of loop
    .
    label case asis
    tic mark label case asis
    title case asis
    title offset 2
    .
    title Percent Agreement Between Method 1 and Method 2
    y1label Method 1
    x1label Method 2
    tic offset units data
    xlimits 1 nmat
    major xtic mark number nmat
    minor xtic mark number 0
    xtic mark offset 0.7 0.7
    x1tic mark label format alpha
    x1tic mark label content 80% 90% 95% 99.5%
    ylimits 1 nint
    major ytic mark number nint
    minor ytic mark number 0
    ytic mark offset 0.7 0.7
    y1tic mark label format alpha
    y1tic mark label content 5% 10% 15% 20% 25%
    .
    let ylevel = data 60 70 80 85 90 101
    .
    let string color = g90 g20 green cyan blue orange red
    line color ^color
    region fill color ^color
    region border color ^color
    .
    set fluctuation plot floor 0
    set fluctuation plot ceiling  100
    fluctuation percent agreement contour plot ...
                intall matall xgroupal ygroupal ylevel
    .
    box fill pattern solid
    box shadow hw 0 0
    .
    box fill color g20
    box 86 90 90 86 
    move 91 87; text <= 60
    .
    box fill color green
    box 86 86 90 82 
    move 91 83; text 60 - 70
    .
    box fill color cyan
    box 86 82 90 78 
    move 91 79; text 70 - 80
    .
    box fill color blue
    box 86 78 90 74 
    move 91 75; text 80 - 85
    .
    box fill color orange
    box 86 74 90 70 
    move 91 71; text 85 - 90
    .
    box fill color red
    box 86 70 90 66 
    move 91 67; text > 90
 
-----PERCENTAGE BEND CORRELATION (LET)-------------------------------
 
PERCENTAGE BEND CORRELATION
 
Name:
    PERCENTAGE BEND CORRELATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the percentage bend correlation for a variable.
 
Description:
    Mosteller and Tukey (see Reference section below) define
    two types of robustness:

      1) resistance means that changing a small part, even by a
         large amount, of the data does not cause a large change
         in the estimate

      2) robustness of efficiency means that the statistic has
         high efficiency in a variety of situations rather than
         in any one situation.  Efficiency means that the estimate
         is close to optimal estimate given that we know what
         distribution that the data comes from.  A useful measure
         of efficiency is:

              Efficiency = (lowest variance feasible)/
                           (actual variance)
   
    Many statistics have one of these properties.  However,
    it can be difficult to find statistics that are both
    resistant and have robustness of efficiency.

    The Pearson correlation coefficient is an optimal estimator for
    Gaussian data.  However, it is not resistant and it does not
    have robustness of efficiency.

    The percentage bend correlation estimator, discussed in
    Shoemaker and Hettmansperger and also by Wilcox, is both
    resistant and robust of efficiency.  The rationale and
    derivation for this estimate is given in these references.

    The percentage bend correlation between two variables X and
    Y is computed as follows:

       1. Set m = [(1-beta)*n + 0.5].  This is the value of
          (1-beta)*m + 0.5 rounded down to the nearest integer.

       2. Let W(i) = |X(i) - M(x)| for i = 1, ..., n where M(x)
          is the median of X.

       3. Sort the W(i) in ascending order.

       4. what(x) = W(m) (i. e., the mth order statistic).
           W(m) is the estimate of the (1-beta) quantile of W.

       5. Sort the X values.  Compute the number of values
          of (X(i) - M(x))/whatx(beta) that are less than -1
          and the number that are greater than +1 and store in
          i1 and i2 respectively.  Then compute

             S(x) = SUM[i=i1+1 to n-i2][X(i)]
             phihat(x) = (what(x)*(i2-i1) + S(x))/(n - i1 - i2)
             U(i) = (X(i) - phihat(x)/what(x)

       6. Repeat the above calculations on the Y variable.
          Store corresponding quantities in what(y), phihat(y),
          and V(i).

       7. Define the function

              PSI(x) = MAX[-1, MIN(1,x)]

       8. Compute

              A(i) = PSI(U(i))
              B(i) = PSI(V(i))

       8. rho(pb) = SUM[i=1 to n][A(i)*B(i)]/
                    SQRT(SUM[i=1 to n][A(i)**2]*SUM[i=1 o n][B(i)**2])

    The value of beta is selected between 0 and 0.5.  Higher
    values of beta result in a higher breakdown point at the
    expense of lower efficiency.
         
Syntax:
    LET <par> = PERCENTAGE BEND CORRELATION <y1> <y2>
                      <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed percentage bend
               correlation is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PERCENTAGE BEND CORRELATION Y1 Y2
    LET A = PERCENTAGE BEND CORRELATION Y1 Y2 SUBSET TAG > 2
 
Note:
    To set the value of beta, enter the command

       LET BETA = <value>

    where <value> is greater than 0 and less than or equal to
    0.5.  The default value for beta is 0.1.

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PERCENTAGE BEND MIDVARI    = Compute the percentage bend
                                 midvariance of a variable.
    BIWEIGHT CORRELATION       = Compute a biweight correlation
                                 estimate of a variable.
    WINSORIZED CORRELATION     = Compute a Winsorized correlation
                                 estimate of a variable.
    CORRELATION                = Compute the correlation between
                                 two variables.
    RANK CORRELATION           = Compute the rank correlation between
                                 two variables.
    VARIANCE                   = Compute the variance of a variable.
    STATISTIC PLOT             = Generate a statistic versus group
                                 plot for a given statistic.
    CROSS TABULATE PLOT        = Generate a statistic versus group
                                 plot for a given statistic and two
                                 group variables.
    BOOTSTRAP PLOT             = Generate a bootstrap plot for a
                                 given statistic.
    DEX PLOT                   = Generate various types of design
                                 of experiment plots.
    INFLUENCE CURVE            = Generate an influence curve for a
                                 given statistic.
    INTERACTION STATISTIC PLOT = Generate an interaction plot for a
                                 given statistic.
 
Reference:
    "Robust Estimates of and Tests for the One- and Two-Sample
    Scale Models", Shoemaker and Hettmansperger, Biometrika 69,
    1982, pp. 47-54.

    "Introduction to Robust Estimation and Hypothesis Testing",
    Rand Wilcox, Academic Press, 1997.

    "Data Analysis and Regression: A Second Course in Statistics",
    Mosteller and Tukey, Addison-Wesley, 1977, pp. 203-209.

Applications:
    Robust Data Analysis
 
Implementation Date:
    2002/7
 
Program 1:
    SKIP 25
    READ MATRIX IRIS.DAT Y1 Y2 Y3 Y4 X
    LET M = CREATE MATRIX Y1 Y2 Y3 Y4
    SET CORRELATION TYPE PERCENTAGE BEND
    LET B = CORRELATION MATRIX Y1 Y2 Y3 Y4
 
Program 2:
    SKIP 25
    READ IRIS.DAT Y1 Y2 Y3 Y4 X
    .
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT 2 1
    BOOTSTRAP SAMPLES 500
    BOOTSTRAP PERCENTAGE BEND CORRELATION PLOT Y1 Y2
    X1LABEL B025 = ^B025, B975=^B975
    HISTOGRAM YPLOT
    END OF MULTIPLOT
    MOVE 50 96
    JUSTIFICATION CENTER
    TEXT PERCENTAGE BEND CORRELATION BOOTSTRAP: IRIS DATA
 
-----PERCENTAGE BEND MIDVARIANCE (LET)-------------------------------
 
PERCENTAGE BEND MIDVARIANCE
 
Name:
    PERCENTAGE BEND MIDVARIANCE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the percentage bend midvariance for a variable.
 
Description:
    Mosteller and Tukey (see Reference section below) define
    two types of robustness:

      1) resistance means that changing a small part, even by a
         large amount, of the data does not cause a large change
         in the estimate

      2) robustness of efficiency means that the statistic has
         high efficiency in a variety of situations rather than
         in any one situation.  Efficiency means that the estimate
         is close to optimal estimate given that we know what
         distribution that the data comes from.  A useful measure
         of efficiency is:

              Efficiency = (lowest variance feasible)/
                           (actual variance)
   
    Many statistics have one of these properties.  However,
    it can be difficult to find statistics that are both
    resistant and have robustness of efficiency.

    For scale estimators, the variance is an optimal estimator for
    Gaussian data.  However, it is not resistant and it does not
    have robustness of efficiency.

    The percentage bend midvariance estimator, discussed in
    Shoemaker and Hettmansperger and also by Wilcox, is both
    resistant and robust of efficiency.  The rationale and
    derivation for this estimate is given in these references.

    The percentage bend midvariance of a a variable X is computed
    as follows:

       1. Set m = [(1-beta)*n + 0.5].  This is the value of
          (1-beta)*m + 0.5 rounded down to the nearest integer.

       2. Let W(i) = |X(i) - M| for i = 1, ..., n where M is
          the median of X.

       3. Sort the W(i) in ascending order.

       4. what(beta) = W(m) (i. e., the mth order statistic).
           W(m) is the estimate of the (1-beta) quantile of W.


       5. Y(i) = (X(i) - M)/what(beta)

       6. a(i) = 1    if |Y(i)| < 1
               = 0    if |Y(i)| >= 1

       7. phi(x) = max[-1, min(1,x)]

       8. PBV = n*what(beta)**2*SUM[{phi(Y(i))}**2]/
                (SUM[a(i)])**2

    The value of beta is selected between 0 and 0.5.  Higher
    values of beta result in a higher breakdown point at the
    expense of lower efficiency.
         
Syntax:
    LET <par> = PERCENTAGE BEND MIDVARIANCE <y>
                      <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed percentage bend
               midvariance is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PERCENTAGE BEND MIDVARIANCE Y1
    LET A = PERCENTAGE BEND MIDVARIANCE Y1 SUBSET TAG > 2
 
Note:
    To set the value of beta, enter the command

       LET BETA = <value>

    where <value> is greater than 0 and less than or equal to
    0.5.  The default value for beta is 0.1.

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    BIWEIGHT MIDVARIANCE       = Compute a biweight midvariance
                                 estimate of a variable.
    BIWEIGHT SCALE             = Compute a biweight scale estimate
                                 of a variable.
    BIWEIGHT LOCATION          = Compute a biweight location estimate
                                 of a variable.
    BIWEIGHT CONFIDENCE LIMITS = Compute a biweight based confidence
                                 interval.
    WINSORIZED VARIANCE        = Compute the Winsorized variance of a
                                 variable.
    MEDIAN ABSOLUTE DEVIATION  = Compute the median absolute
                                 deviation of a variable.
    VARIANCE                   = Compute the variance of a variable.
    STATISTIC PLOT             = Generate a statistic versus group
                                 plot for a given statistic.
    CROSS TABULATE PLOT        = Generate a statistic versus group
                                 plot for a given statistic and two
                                 group variables.
    BOOTSTRAP PLOT             = Generate a bootstrap plot for a
                                 given statistic.
    DEX PLOT                   = Generate various types of design
                                 of experiment plots.
    INFLUENCE CURVE            = Generate an influence curve for a
                                 given statistic.
    INTERACTION STATISTIC PLOT = Generate an interaction plot for a
                                 given statistic.
 
Reference:
    "Robust Estimates of and Tests for the One- and Two-Sample
    Scale Models", Shoemaker and Hettmansperger, Biometrika 69,
    1982, pp. 47-54.

    "Introduction to Robust Estimation and Hypothesis Testing",
    Rand Wilcox, Academic Press, 1997.

    "Data Analysis and Regression: A Second Course in Statistics",
    Mosteller and Tukey, Addison-Wesley, 1977, pp. 203-209.

Applications:
    Robust Data Analysis
 
Implementation Date:
    2002/7
 
Program 1:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y2 = LOGISTIC RANDOM NUMBERS FOR I = 1 1 100
    LET Y3 = CAUCHY RANDOM NUMBERS FOR I = 1 1 100
    LET Y4 = DOUBLE EXPONENTIAL RANDOM NUMBERS FOR I = 1 1 100
    LET A1 = PERCENTAGE BEND MIDVARIANCE Y1
    LET A2 = PERCENTAGE BEND MIDVARIANCE Y2
    LET A3 = PERCENTAGE BEND MIDVARIANCE Y3
    LET A4 = PERCENTAGE BEND MIDVARIANCE Y4
 
Program 2:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    MULTIPLOT SCALE FACTOR 2
    X1LABEL DISPLACEMENT 12
    .
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 200
    LET Y2 = CAUCHY RANDOM NUMBERS FOR I = 1 1 200
    .
    BOOTSTRAP SAMPLES 500
    BOOTSTRAP PERCENTAGE BEND MIDVARIANCE PLOT Y1
    X1LABEL B025 = ^B025, B975=^B975
    HISTOGRAM YPLOT
    X1LABEL
    .
    BOOTSTRAP PERCENTAGE BEND MIDVARIANCE PLOT Y1
    X1LABEL B025 = ^B025, B975=^B975
    HISTOGRAM YPLOT
    .
    END OF MULTIPLOT
    JUSTIFICATION CENTER
    MOVE 50 96
    TEXT PERCENTAGE BEND MIDVARIANCE BOOTSTRAP: NORMAL
    MOVE 50 46
    TEXT PERCENTAGE BEND MIDVARIANCE BOOTSTRAP: CAUCHY
 
-----PERCENT DEFECTIVE (LET)------------------------------------------
 
PERCENT DEFECTIVE
 
Name:
    PERCENT DEFECTIVE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the percentage of defectives for a variable.
 
Description:
    The percent defective is the number of values of a variable
    (expressed as a percentage) that fall outside some user specified
    tolerance limits.
 
Syntax:
    LET <par> = PERCENT DEFECTIVE <x> <SUBSET/EXCEPT/FOR qualification>
    where <x> is the variable for which the percent defectives is
              computed;
          <par> is a parameter where the computed percentage of
              defectives is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PERCENT DEFECTIVE Y1
    LET A = PERCENT DEFECTIVE Y1  SUBSET TAG > 2
 
Note:
    The upper and lower specification limits must be specified by the
    user as follows:
        LET LSL = <value>
        LET USL = <value>
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CONTROL CHART        = Generate a control chart.
    CP (LET)             = Compute the CP index.
    CPK (LET)            = Compute the CPK index.
    EXPECTED LOSS (LET)  = Compute the expected loss of a sample.
 
Applications:
    Quality Control
 
Implementation Date:
    XX
 
Program:
    LET Y = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET LSL = -2
    LET USL = 2
    LET A = PERCENT DEFECTIVE Y
 
-----PERCENT DEFECTIVE PLOT-----------------------------------------
 
PERCENT DEFECTIVE PLOT
 
Name:
    PERCENT DEFECTIVE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a percent defective plot.
 
Description:
    A percent defective plot consists of subsample percent defective
    versus subsample index.  The subsample percent defective index is
    the percent defective of the data in the subsample.  The percent
    defective plot is used to answer the question--"Does the subsample
    percent defective index change over different subsamples?"  The
    plot consists of:
       Vertical   axis = subsample percent defective index;
       Horizontal axis = subsample index.
    The percent defective plot yields 2 traces:
       1. a subsample percent defective trace; and
       2. a full-sample percent defective reference line.
    Like usual, the appearance of these 2 traces is controlled by
    the first 2 settings of the LINES, CHARACTERS, SPIKES, BARS,
    and similar attributes.
 
Syntax:
    PERCENT DEFECTIVE PLOT <y> <x>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    PERCENT DEFECTIVE PLOT Y X
    PERCENT DEFECTIVE PLOT Y X SUBSET X > 6
 
Note:
    The percent defective computes the number of defectives for a
    variable (i.e., the number of values that fall outside of some user
    specified tolerance limits) and expresses it as a percentage.
    specified cost.
 
Note:
    The upper and lower specification limits must be specified by the
    user as follows:
        LET USL = <value>
        LET LSL = <value>
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    CP PLOT                 = Generates a Cp plot.
    CPK PLOT                = Generates a Cpk plot.
    EXPECTED LOSS PLOT      = Generates an expected loss plot.
    BOX PLOT                = Generates a box plot.
    XBAR CHART              = Generates an xbar control chart.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Quality Control
 
Implementation Date:
    93/10
 
Program:
    SKIP 25
    READ GEAR.DAT DIAMETER BATCH
    .
    TITLE CASE ASIS; LABEL CASE ASIS
    TITLE  Gear Diameter Analysis
    Y1LABEL PERCENT DEFECTIVE
    X1LABEL Batch
    LEGEND 1 Process Capability
    LEGEND 2 PERCENT DEFECTIVE Plot
    XTIC OFFSET 0.5 0.5
    YTIC OFFSET 2.0 2.0
    CHARACTER CIRCLE BLANK
    CHARACTER FILL ON
    CHARACTER SIZE 1.2
    SPIKE ON
    SPIKE DOTTED
    LINE BLANK SOLID
    .
    LET LSL = 0.99
    LET USL = 1.01
    .
    PERCENT DEFECTIVE PLOT DIAMETER BATCH
 
-----PERCENT DISAGREE (LET)--------------------------------------------
 
PERCENT DISAGREE
 
Name:
    PERCENT DISAGREE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the percentage of values that disagree in two response
    variables.  This is pairwise disagreement (i.e., how often does
    Y1(I) not equal Y2(I) for I = 1, ..., N).
 
Description:
    Given two methods (or two labortories), it may sometimes be useful
    to know how often they reach a different conclusion.

    For example, if we have two sensors that either detect or do not
    detect the presence of some quantity of interest, how often do
    the two detectors disagree?

    This command is typically used when there a discrete number of
    values for the variable.  Often this will be two (e.g., Yes/No
    type data), but it is not restricted to two.

    If you want to compare values for two response variables when
    the data is continuous, the YOUDEN PLOT is recommended.

Syntax:
    LET <par> = PERCENT DISAGREE <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the percent agree is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PERCENT DISAGREE Y1 Y2
    LET A = PERCENT DISAGREE Y1 Y2  SUBSET TAG > 1
 
Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PERCENT AGREE      = Compute the percentage of values that agree
                         in two response variables.
    FALSE NEGATIVES    = Compute the proportion of false negatives.
    FALSE POSITIVES    = Compute the proportion of false positives.
    TRUE NEGATIVES     = Compute the proportion of true negatives.
    TRUE POSITIVES     = Compute the proportion of true positives.
    TEST SENSITIVITY   = Compute the test sensitivity.
    TEST SPECIFICITY   = Compute the test specificity.
    ODDS RATIO         = Compute the bias corrected log(odds ratio).
    YOUDEN PLOT        = Generate a Youden plot.
 
Applications:
    Categorical Data Analysis
 
Implementation Date:
    2011/7
 
Program:
    .  Step 1: Read the Data
    .
    .          Column 1: Method 1 (low  => live cell, high => dead cell)
    .          Column 2: Method 2 (high => live cell, low  => dead cell)
    dimension 40 columns
    read percmat  intensity
      7.1             39.8
      8.5             29.6
     72.7              4.2
     32.3             12.3
      5.4             21.5
     71.1              4.4
    100.0             13.5
     55.0             22.4
     15.0             25.9
      8.7             38.5
      0.9             16.6
     19.0             48.5
    100.0              4.3
    100.0              7.9
      5.2             42.6
     21.8             47.2
     90.0              1.0
      2.0             23.5
     98.0              2.2
    100.0              6.2
    100.0              2.0
    100.0              5.6
    100.0              3.0
     30.0             14.3
    100.0              1.0
    end of data
    .
    .  Step 3: Generate fluctuation plot based on different levels of
    .          the 2 methods
    .
    .          Use intensity levels of 5%, 10%, 15%, 20%, 25%
    .          Use percent matching levels of 80%, 90%, 95%, 99.5%
    .
    let n = size intensity
    let intcut = data 5 10 15 20 25
    let nint = size intcut
    let matcut = data 80 90 95 99.5
    let nmat = size matcut
    .
    let int2 = intensity
    let mat2 = percmat
    let xgroup = 1 for i = 1 1 n
    let ygroup = 1 for i = 1 1 n
    let icnt = 0
    .
    loop for k = 1 1 nint
        let acut = intcut(k)
        loop for l = 1 1 nmat
            let bcut = matcut(l)
            let icnt = icnt + 1
            if icnt = 1
               let xgroupal = xgroup
               let ygroupal = ygroup
               let intcor = 0 for i = 1 1 n
               let intcor = 1 subset int2 >  acut
               let intall = intcor
               let matcor = 0 for i = 1 1 n
               let matcor = 1 subset mat2 < bcut
               let matall = matcor
            else
               let xgroup2 = k for i = 1 1 n
               extend xgroupal xgroup2
               let ygroup2 = l for i = 1 1 n
               extend ygroupal ygroup2
               let intcor = 0 for i = 1 1 n
               let intcor = 1 subset int2 >  acut
               extend intall intcor
               let matcor = 0 for i = 1 1 n
               let matcor = 1 subset mat2 < bcut
               extend matall matcor
            end of if
        end of loop
    end of loop
    .
    label case asis
    tic mark label case asis
    title case asis
    title offset 2
    .
    title Percent Disagreement Between Method 1 and Method 2
    y1label Method 1
    x1label Method 2
    tic offset units data
    xlimits 1 nmat
    major xtic mark number nmat
    minor xtic mark number 0
    xtic mark offset 0.7 0.7
    x1tic mark label format alpha
    x1tic mark label content 80% 90% 95% 99.5%
    ylimits 1 nint
    major ytic mark number nint
    minor ytic mark number 0
    ytic mark offset 0.7 0.7
    y1tic mark label format alpha
    y1tic mark label content 5% 10% 15% 20% 25%
    .
    let ylevel = data 60 70 80 85 90 101
    let ylevel = data 10 15 20 30 41
    .
    let string color = g90 green cyan blue orange red
    line color ^color
    region fill color ^color
    region border color ^color
    .
    set fluctuation plot floor 0
    set fluctuation plot ceiling  40
    fluctuation percent disagreement contour plot ...
                intall matall xgroupal ygroupal ylevel
    .
    box fill pattern solid
    box shadow hw 0 0
    .
    box fill color green
    box 86 90 90 86 
    move 91 87; text <= 10
    .
    box fill color cyan
    box 86 86 90 82 
    move 91 83; text 10 - 15
    .
    box fill color blue
    box 86 82 90 78 
    move 91 79; text 15 - 20
    .
    box fill color orange
    box 86 78 90 74 
    move 91 75; text 20 - 30
    .
    box fill color red
    box 86 74 90 70 
    move 91 71; text > 30
 
-----PERCENTAGE RANK (LET)---------------------------------------------------
 
PERCENTAGE RANK
 
Name:
    PERCENTAGE RANK (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the percentage ranks of a variable.
 
Description:
    The percentage rank is computed as

       PR(i) = 100*(RANK(i) - 0.5)/N

    with RANK(i) and N denoting the rank of the i-th element and the
    number of observations, respectively.

    Ranks are frequently used in nonparametric statistical analysis.  Some
    analysts like to the think of the ranks in terms of percentages.

Syntax:
    LET <y2> = PERCENTAGE RANK <y1>   <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a response variable;
          <y2> is a variable where the percentage ranks are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET PERCRANK = PERCENTAGE RANK Y1

Note:
    Ties are assigned an average rank.  For example, if the 2nd and 3rd
    highest values are equal, each is assigned a rank of 2.5.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RANK         = Rank the elements in a variable.
    RANK2        = Rank the elements in a variable when there are one,
                   two, or three group-id variables.
    RANK INDEX   = Rank the elements in a variable where each rank will
                   be assigned a unique integer value.
    SORT         = Sort the elements in a variable.
    SORTC        = Sort the elements in a variable and carry one or
                   more variables along.
 
Reference:
    ISO 13528, First Edition, Statistical Methods for Use
    in Proficiency Testing by Interlaboratory Comparisons,
    2005, p. 24.

Applications:
    Nonparametric statistics
 
Implementation Date:
    2012/1
 
Program:
    let y1 = norm rand numb for i = 1 1 20
    let y2 = rank y1
    let y3 = percentage rank y1
    .
    set write decimals 3
    print y1 y2 y3

-----PERCENTILE (LET)-----------------------------------------
 
PERCENTILE
 
Name:
    PERCENTILE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute a user specified percentile for a variable.
 
Description:
    The p-th percentile of a data set is defined as that value
    where p percent of the data is below that value and (1-p)
    percent of the data is above that value.  For example, the
    50th percentile is the median.
 
    The default method for computing percentiles in Dataplot is
    based on the order statistic.  The formula is:

       X(p) = (1 - r)*X(NI1) + r*X(NI2)

   where

       X are the observations sorted in ascending order
       NI1 = INT(p*(N+1))
       NI2 = NI1 + 1
       r = p*(N+1) - INT(p*(N+1))

   If p is < 1/(N+1), then X(1) is returned.  If p > N/(N+1), then X(N)
   is returned.

Syntax 1:
    LET <par> = <value> PERCENTILE <y> 
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed percentile
              is stored;
          <value> is a parameter in the range 0 to 100 that specifies
              which percentile to compute;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <par> = PERCENTILE <y> 
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed percentile is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    With this syntax, the desired percentile is specified by entering the
    command

        LET P100 = <value>

    before entering the PERCENTILE command.
 
Examples:
    LET A = 20 PERCENTILE Y
    LET A = 50 PERCENTILE Y SUBSET TAG > 2

    LET P100 = 90
    LET A = PERCENTILE Y

Note:
    The QUANTILE command is equivalent to the PERCENTILE command.  The
    only difference is that the requested percentile is given as a
    percentage between 0 and 100% while the requested quantile is
    specified as a fraction between 0 and 1.

Note:
    Note that there are a number of other ways of calculating percentiles
    in common use.  Hyndman and Fan (1996) in an American Statistician
    article evaluated nine different methods (we will refer to these as R1
    through R9) for computing percentiles relative to six desirable
    properties. Their goal was to advocate a "standard" definition for
    percentiles that would be implemented in statistical software. Although
    this has not in fact happened, the article does provide a useful
    summary and evaluation of various methods for computing percentiles.
    Most statistical and spreadsheet software use one of the methods
    described in Hyndman and Fan.

    The default method used by Dataplot described above corresponds to
    method R6 of Hyndman and Fan.  The description of the methods
    here will be in terms of the quantile q = p/100 (where p is
    the desired percentile).

    The method advocated by Hyndman and Fan is R8. For the R8 method,

       X(q) = X(NI1) + r*(X(NI2) - X(NI1))

    where

       X are the observations sorted in ascending order
       NI1 = INT(q*(N+(1/3)) + (1/3))
       NI2 = NI1 + 1
       r = q*(N+1) - INT(q*(N+1))

    If q <= (2/3)/(N+(1/3)) the minimum value will be returned and
    if q >= (N-(1/3))/(N+(1/3)) the maximum value will be returned.

    Method R7 (this is the default method in R and Excel) is calculated by

       X(q) = X(NI1) + r*(X(NI2) - X(NI1))

    where

       X are the observations sorted in ascending order
       NI1 = INT(q*(N-1) + 1)
       NI2 = NI1 + 1
       r = q*(N+1) - INT(q*(N+1))

    If q = 1, then X(N) is returned.

    The R6, R7, and R8 methods give fairly similar, but not exactly the
    same (particularly for small samples), results.  For most purposes,
    any of these three methods should be acceptable.

Note:
    The following command is used to determine which method
    is used to compute the percentile:

         SET QUANTILE METHOD <ORDER/R6/R7/R8>

    R6 is equivalent to ORDER.

Note:
    Dataplot statistics can be used in 20+ commands.  For details, enter

         HELP STATISTICS

    When using these commands, the specific quantile to compute is
    specified by entering the following command (before the statistic
    command):

       LET P100 = <value>

    where <value> is a number in the interval (0,100) that specifies
    the desired quantile.


Default:
    The ORDER STATISTIC (R6) method is the default method for calculating
    percentiles.
 
Synonyms:
    None
 
Related Commands:
    QUANTILE            = Compute a specified quantile.
    MEDIAN              = Compute the median.
    LOWER QUARTILE      = Compute the lower quartile.
    UPPER QUARTILE      = Compute the upper quartile.
    FIRST DECILE        = Compute the first decile (the 10th percentile).
    ... STATISTIC PLOT  = Generate a statistic versus subset plot for
                          numerous statistics.
 
Reference:
    Hyndman and Fan (November 1996), "Sample Quantiles in Statistical
    Packages", The American Statistician, Vol. 50, No. 4, pp. 361-365.

Applications:
    Data Analysis
 
Implementation Date:
    1998/12
    2015/2: Support for R7 and R8 methods
 
Program 1:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET A1 = 30 PERCENTILE Y1
 
Program 2:
    . Step 1:   Read the data
    .
    read y
    95.1772
    95.1567
    95.1937
    95.1959
    95.1442
    95.0610
    95.1591
    95.1195
    95.1065
    95.0925
    95.1990
    95.1682 
    end of data
    .
    . Step 2:   Compute the percentiles using various methods
    .
    let p100 = xq
    .
    let xpr6 = percentile y
    let xpr6 = round(xpr6,4)
    .
    set quantile method r7
    let xpr7 = percentile y
    let xpr7 = round(xpr7,4)
    .
    set quantile method r8
    let xpr8 = percentile y
    let xpr8 = round(xpr8,4)
    .
    . Step 3:   Print the results
    .
    print "Percentile with R6 method:  ^xpr6"
    print "Percentile with R7 method:  ^xpr7"
    print "Percentile with R8 method:  ^xpr8"

-----PERCENT POINT PLOT------------------------------------------------
 
PERCENT POINT PLOT
 
Name:
    PERCENT POINT PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a percent point plot.
 
Description:
    A percent point plot is a graphical data analysis technique for
    summarizing the distributional information of a variable.  It
    consists of:

       Vertical   axis = percent point;
       Horizontal axis = percent (0 to 100).

    Thus, for example, if the value of 50 is chosen on the horizontal
    axis, then the corresponding value on the vertical axis is the
    estimated 50% point (that is, the median) from the data.

    The percent point plot can be generated for either raw data or for
    binned data.

    For raw data, the percentile plot is constructed by plotting the
    sorted data on the vertical axis.  The corresponding horizontal axis
    value for the i-th point is 100*Y(i)/N with Y(i) and N denoting the
    i-th observation of the sorted data and the sample size, respectively.
    The multiplication by 100 is to covert the horizontal axis to a
    percentage value.

    For binned data, the vertical axis value is the mid-point of the
    bin.  The corresponding horizontal axis values are the cumulative
    sums of the frequencies of the bins divided by the sum of the
    frequencies for all bins.  This value is multiplied by 100 to convert
    the horizontal axis to a percentage value.

    By default, raw data is first binned into frequency data.  To
    suppress this binning (i.e., generate the raw data version of
    the plot), enter the command

        SET PERCENT POINT PLOT UNBINNED

    To restore the default of binning raw data, enter

        SET PERCENT POINT PLOT BINNED

    Typically no binning is preferred for small to moderate size data
    sets.  Binning can be helpful for large data sets in that it
    reduces the number of points that are plotted.

Syntax 1:
    PERCENT POINT PLOT  <x>  <SUBSET/EXCEPT/FOR qualification>
    where <x> is the variable of raw data;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where you have raw data.
 
Syntax 2:
    PERCENT POINT PLOT <y> <x>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the variable of pre-computed frequencies;
          <x> is the variable of distinct values;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where you have pre-computed
    frequencies at each data level.  This syntax is used when you
    have equal width bins.
 
Syntax 3:
    PERCENT POINT PLOT <y> <xlow> <xhigh>
                       <SUBSET/EXCEPT/FOR qualification>
    where <y> is the variable of pre-computed frequencies;
          <xlow> is the variable containing the lower limits of the bins;
          <xhigh> is the variable containing the upper limits of the bins;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where you have pre-computed
    frequencies at each data level.  This syntax is used when you have
    unequal width bins.
 
Syntax 4:
    MULTIPLE PERCENT POINT PLOT <y1> ... <yk>
                                <SUBSET/EXCEPT/FOR qualification>
    where <y1> ... <yk> is a list of 1 to 30 response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax will generate percent point plots of each of the
    listed response variables on the same plot.  You can specify
    different plot attributes for each response variable.

    This syntax is only supported for raw data (i.e., no binned data).
 
Syntax 5:
    REPLICATED PERCENT POINT PLOT <y> <x1> ... <xk>
                                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> ... <xk> is a list of 1 to 6 group-id variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    From one to six group-id variables can be specified (most
    commonly there is a single group-id variable).

    Note that with this syntax, the plot points corresponding to each
    group are drawn with different attributes (i.e., the first group
    uses the first setting for the CHARACTER and LINE and related
    attribute setting commands, the second group uses the second
    setting, and so on).  For example, this syntax can be used to label
    the plot points with the group-id.

    If there is more than one group-id variable, the attribute settings
    work from right to left.  That is, if X1 has 2 levels and X2 has
    2 levels, then

      trace 1  = Level 1 of X1 and Level 1 of X2
      trace 2  = Level 1 of X1 and Level 2 of X2
      trace 3  = Level 2 of X1 and Level 1 of X2
      trace 4  = Level 2 of X1 and Level 1 of X2

Syntax 6:
    HIGHLIGHTED PERCENT POINT PLOT <y> <x>
                                   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x> is a group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    Although this syntax is similar to the REPLICATION case, it
    is generally used in a different way.  The REPLICATION case is
    used when we have distinct groups of data and we want to generate
    separate percent point plots for each group.  Highlighting is
    used when we have a single group of data, but we want to draw
    some of the points with different attributes.  For example, we
    may want to emphasize the extreme points in the plot.

Example:
    PERCENT POINT PLOT Y
    PERCENT POINT Y X
    PERCENT POINT Y XLOW XHIGH
    HIGHTLIGHTED PERCENT POINT Y TAG
    MULTIPLE PERCENT POINT Y1 Y2 Y3
    PERCENT POINT Y X SUBSET X > 2
 
Note:
    When raw data is binned, Dataplot divides the raw data into classes
    in the same manner as it does for a histogram or frequency polygon.
    The percent points are calculated at the mid-points of these histogram
    classes.  The defaults are the same as for histograms (the class
    width is 0.3*standard deviation, 6 classes above and 6 classes
    below the mean).  You can specify your own binning with the
    CLASS LOWER, CLASS UPPER, and CLASS WIDTH commands.  This is
    demonstrated in the sample program below.

    The SET HISTOGRAM CLASS WIDTH can be used to define several other
    algorithms for binning the data (HELP HISTOGRAM CLASS WIDTH for
    details).  The SET HISTOGRAM OUTLIERS command also applies to
    the PERCENT POINT PLOT if raw data is being binned.
 
Note:
    Percent point plots are also referred to as quantile plots in
    the statistical literature.
 
Note:
    The attributes of the plot can be set by the first setting of the
    LINE, CHARACTER, SPIKE, and BAR commands (and there corresponding
    attribute setting commands).  This is demonstrated in the sample
    program below.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    QUAN-QUAN PLOT     = Generates a quantile-quantile plot.
    HISTOGRAM          = Generates a histogram.
    FREQUENCY PLOT     = Generates a frequency plot.
    PIE CHART          = Generates a pie chart.
    PROBABILITY PLOT   = Generates a probability plot.
    PPCC PLOT          = Generates probability plot correlation
                         coefficient plot.
    PLOT               = Generates a plot (including bar plots).
    CLASS LOWER        = Sets the lower class minimum for histograms,
                         frequency plots, and pie charts.
    CLASS UPPER        = Sets the upper class maximum for histograms,
                         frequency plots, and pie charts.
    CLASS WIDTH        = Sets the class width for histograms, frequency
                         plots, and pie charts.
 
Applications:
    Distributional Analysis
 
Reference:
    Chambers, Cleveland, Kleiner, and Tukey (1983), "Graphical Methods
    for Data Analysis", Wadsworth.
 
Implementation Date:
    Pre-1987
    1998/09: Support for SET PERCENT POINT PLOT command.
    2011/02: Support for REPLICATION and MULTIPLE options.
    2011/02: Support for HIGHLIGHT option.
 
Program 1:
    SKIP 25
    READ SUNSPOT2.DAT Y
    .
    LET ALOW = MINIMUM Y
    LET AHIGH = MAXIMUM Y
    CLASS LOWER ALOW
    CLASS UPPER AHIGH
    CLASS WIDTH 1.0
    CHARACTER CIRCLE
    CHARACTER FILL ON
    CHARACTER SIZE 1.2
    X1LABEL PERCENT POINT
    Y1LABEL DATA VALUE
    TITLE AUTOMATIC
    .
    PERCENT POINT PLOT Y
 
Program 2:
    let y1 = norm rand numb for i = 1 1 100
    .
    title case asis
    title offset 2
    title automatic
    label case asis
    tic mark offset units screen
    tic mark offset 3 3
    .
    char circle
    char fill on
    char hw 0.5 0.375
    line blank
    .
    multiplot corner coordinates 5 5 95 95
    multiplot scale factor 2
    multiplot 2 2
    .
    set percent point plot unbinned
    set histogram outliers on
    set histogram empty bins off
    title Unbinned Data
    percent point plot y1
    .
    set percent point plot binned
    title Data Binned by Command
    percent point plot y1
    .
    title User Created Bins: Equi-Spaced Bins
    let z2 x2 = binned y1
    percent point plot z2 x2
    .
    let minsize = 5
    let z3 xlow xhigh = combine frequency table z2 x2
    title User Created Bins: Unequal-Spaced Bins
    percent point plot z3 xlow xhigh
    .
    end of multiplot
    justification center
    move 50 97
    text Percent Point Plots for 100 Normal Random Numbers
    move 50 5
    text Percentile
    direction vertical
    move 3 50
    text Response Value

Program 3:
    dimension 500 rows
    skip 25
    read iris.dat y1 y2 y3 y4
    let m = create matrix y1 y2 y3 y4
    .
    title case asis
    title offset 2
    label case asis
    .
    char circle all
    char color black
    char fill on all
    char hw 0.5 0.375 all
    line blank all
    .
    y1label Response Value
    x1label Percentile
    title IRIS Data (all species combined)
    .
    set percent point plot unbinned
    set histogram outliers on
    set histogram empty bins off
    percent point plot m
    .
    char color red blue cyan green
    title IRIS Data (species plotted separately)
    multiple percent point plot y1 to y4

Program 4:
    skip 25
    read gear.dat y x
    .
    title case asis
    title offset 2
    label case asis
    tic mark offset units screen
    tic mark offset 5 5
    .
    char circle all
    char color black red blue green cyan grey brown magenta dgreen orange
    char fill on all
    char hw 0.5 0.375 all
    line blank all
    .
    title Percent Point Plots for GEAR.DAT
    y1label Response Value
    x1label Percentile
    .
    set percent point plot unbinned
    set histogram outliers on
    set histogram empty bins off
    replicated percent point plot y x

-----PERCERR (LET)--------------------------------
 
PERCERR
 
Name:
    PERCERR (LET)
 
Type:
    Library Function
 
Purpose:
    Return the percent error of two numbers.

Description:
    The definition of the percent error between a "true" value
    X(t) and an observed value X(o) used by Dataplot is:

         Percent Error = 100*(X(t) - X(o))/X(t)

    There may be some slight differences for this formula in other
    sources.  Specifically,

    1) Some sources take the absolute value of the above
       quantity.  In Dataplot, you can use the ABS function
       to obtain this form.

    2) Some sources may reverse the order of the X(t) and X(o) values.
       This changes the sign of the result, but not the magnitude.

Syntax:
    LET <y> = PERCERR(<y1>,<y2>)      <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter;
          <y>  is a variable or a parameter (depending on what <y1> and
               <y2> are) where the computed percent error values
               are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PERCERR(14,10)
    LET A = PERCERR(A1,A2)
    LET X2 = PERCERR(X1,X4)
    LET X2 = PERCERR(X1-4,X2+6)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PERCDIF  = Compute the percent difference of two numbers.
    RELDIF   = Compute the relative difference of two numbers.
    MIN      = Compute the minimum of two numbers.
    MAX      = Compute the maximum of two numbers.
    ABS      = Compute the absolute value of a number.
 
Applications:
    Data Management
 
Implementation Date:
    2010/12
 
Program:
    LET X = SEQUENCE 0.1  0.1  3
    LET Y1 = X**2
    LET Y2 = X**(1/2)
    LET Y3 = PERCERR(Y1,Y2)
    SET WRITE DECIMALS 5
    PRINT Y1 Y2 Y3
 
-----PERIODOGRAM-------------------------------------------------------
 
PERIODOGRAM
 
Name:
    PERIODOGRAM
 
Type:
    Graphics Command
 
Purpose:
    Generates an auto-periodogram.
 
Description:
    A periodogram is a time series technique which carries out a
    Fourier decomposition of the time series.  It consists of:
      Vertical   axis = sum of squared Fourier coefficients
                        (a(i)**2 + b(i)**2);
      Horizontal axis = Fourier frequencies (1/n, 2/n, 3/n, ..., 1/2)
                        where n is the number of observations in the
                        time series.
 
Syntax 1: (one time series, produces an auto-periodogram)
    PERIODOGRAM   <y>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    PERIODOGRAM Y
    PERIODOGRAM Y2  SUBSET Y2 > 2
 
Note:
    The periodogram assumes equi-spaced data.  Equi-spaced time series
    are inherently limited to detecting frequencies between 0 and 0.5.
 
Note:
    The spectral plot is an improved form of the periodogram and is
    generally recommended in its place.  See the SPECTRUM command for
    details.
 
Note:
    The CROSS-PERIODOGRAM, CO-PERIODOGRAM, and QUADRATURE PERIODOGRAM
    commands are recognized.  However, these variations are not
    implemented at this time.  These commands will generate a page
    erase, but no plot is generated.  These options are recognized for
    the SPECTRUM command.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SPECTRUM            = Generates a spectral plot.
    CORRELATION PLOT    = Generates a correlation plot.
    COMPLEX DEMOD  PLOT = Generates a complex demodulation plot.
    LAG PLOT            = Generates a lag plot.
    PLOT                = Generates a data or function plot.
    4-PLOT              = Generates 4-plot univariate analysis.
    CHARACTERS          = Sets the types for plot characters.
    LINES               = Sets the types for plot lines.
    SPIKES              = Sets the on/off switches for plot spikes.
    SUMMARY             = Generates a table of summary statistics.
    LET                 = Generates  sin/cos transformations (plus
                          much more).
    FIT                 = Carries out a least squares fit.
 
Reference:
    "Spectral Analysis of Time Series", Jenkins and Watts, ...
 
Applications:
    Frequency Time Series Analysis
 
Implementation Date:
    Pre-1987
 
Program:
    .  THIS SAMPLE PROGRAM READS THE FILE LEW.DAT IN THE
    .  DATAPLOT REFERENCE DIRECTORY.  SINCE IT CONTAINS 200
    .  DATA POINTS, IT IS NOT REPRODUCED HERE.  THESE DATA ARE
    .  BEAM DEFLECTION DATA.
    .
    SKIP 25
    READ LEW.DAT DEFLECT
    .
    SPIKE ON
    LINE BLANK
    YLIMITS 0 40000
    YTIC OFFSET 0 2000
    .
    PERIODOGRAM DEFLECT

-----PERPINDICULAR LINES--------------------------------------------------
 
PERPINDICULAR LINES
 
Name:
    PERPINDICULAR LINES
 
Type:
    LET Subcommand
 
Purpose:
    Given a line defined by two points and a third point, find the line
    perpindicular to the first line and containing the third point.

Syntax:
    LET <yout> <xout>= PERPINDICULAR LINES <x1> <y1> <x2> <y2> <x3> <y3>
                       <SUBSET/EXPCEPT/FOR qualification>
    where <x1> is a variable or parameter containing the x-coordinates for the
               first point of line one;
          <y1> is a variable or parameter containing the y-coordinates for the
               first point of line one;
          <x2> is a variable or parameter containing the x-coordinates for the
               second point of line one;
          <y2> is a variable or parameter containing the y-coordinates for the
               second point of line one;
          <x3> is a variable or parameter containing the x-coordinates for the
               third point;
          <y3> is a variable or parameter containing the y-coordinates for the
               third point;
          <yout> is a variable containing the y-coordinates of the
               second point of the perpindicular line;
          <xout> is a variable containing the x-coordinates of the
               second point of the perpindicular line;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET YOUT XOUT = PERPINDICULAR LINES X1 Y1 X2 Y2 X3 Y3 X4 Y4

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PARALLEL LINE      = Determine the coordinates for a point that defines
                         a parallel line determined by a point and a line
                         defined by two points.
    POINTS IN POLYGON  = Determine whether points are in the interior
                         of a convex polygon.
    CONVEX HULL        = Determine the convex hull of a set of points.
    TRANSFORM POINTS   = Perform location, scale, and rotation
                         transformation for a set of points.
    EXTREME POINTS     = Determine the extreme points of a set of points.
    LINE INTERSECTIONS = Determine the intersection points for a set of
                         lines.

Applications:
    Computational Geometry
 
Implementation Date:
    2012/10
 
Program:
    dimension 40 columns
    skip 25
    read convhull.dat x y
    .
    let y2 x2 = 2d convex hull y x
    let xtemp = x2(1)
    let ytemp = y2(1)
    let y2 = combine y2 ytemp
    let x2 = combine x2 xtemp
    let x3 = x2
    let y3 = y2
    let n = size y2
    let nm1 = n - 1
    retain x2 y2 for i = 1 1 nm1
    retain x3 y3 for i = 2 1 n
    let slope = slope(x2,y2,x3,y3)
    let pdist = dpntline(xtemp,ytemp,x3,y3,slope)
    let xtempv = xtemp for i = 1 1 nm1
    let ytempv = ytemp for i = 1 1 nm1
    let y5 x5 = perpindicular line x2 y2 x3 y3 xtempv ytempv
    .
    set write decimals 4
    print "Anchor Point: (^xtemp,^ytemp)"
    print " "
    print " "
    print x2 y2 x3 y3 x5 y5

-----PEXCDF (LET)--------------------------------
 
PEXCDF
 
Name:
    PEXCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the exponential power cumulative distribution function
    with shape parameter beta.
 
Description:
    The exponential power distribution has the following cumulative
    distribution function:

        F(x;beta) = 1 - EXP(1 - EXP(X**BETA))
                    x > 0; beta > 0

    with beta denoting the shape parameter.

    This distribution can be generalized with location and
    scale parameters using the relation

         F(x;beta,loc,scale) = F((x-loc)/scale;beta,0,1)

    This distribution was proposed by Dhillon as useful
    distribution for reliability applications since it can
    have increasing, decreasing, or bathtub shaped hazard
    functions.
 
Syntax:
    LET <y> = PEXCDF(<x>,<beta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing positive
               values;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed exponential power cdf value is
               stored;
          <beta> is a positive number, parameter, or variable that
               specifies the shape parameter;
          <loc> is a number, parameter, or variable that specifies
               the location parameter;
          <scale> is a positive number, parameter, or variable that
               specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = PEXCDF(0.3,2.5)
    LET A = PEXCDF(X1,2.5,0,10)
    PLOT PEXCDF(X,2.5,0,3) FOR X = 0.1  0.1  10
 
Note:
    The 11/2007 version changed the syntax for this function
    from

        LET A = PEXCDF(X,ALPHA,BETA,LOC,SCALE)

    to

        LET A = PEXCDF(X,BETA,LOC,SCALE)

    This was done since ALPHA is in fact a scale parameter
    (in the articles listed in the References section, ALPHA
    is actually the reciprocal of the scale parameter).

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PEXPDF  = Compute the exponential power probability density
              function.
    PEXPPF  = Compute the exponential power percent point function.
    PEXHAZ  = Compute the exponential power hazard function.
    PEXCHAZ = Compute the exponential power cumulative hazard
              function.
    ALPPDF  = Compute the alpha probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the log-normal probability density function.
    NORCDF  = Compute the normal cumulative distribution function.
    NORPDF  = Compute the normal probability density function.
 
References:
    Johnson, Kotz, and Balakrishnan (1994), "Continuous Univariate
    Distributions--Volume 2", Second Edition, John Wiley and Sons,
    pp. 643-644.

    Dhillon (1981), "Life Distributions", IEEE Transactions on
    Reliability, Vol. R-30, No. 5, pp. 457-459.

Applications:
    Reliability, accelerated life testing
 
Implementation Date:
    1998/4
    2007/11: Corrected the second shape parameter to be the
             scale parameter

Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.5
    TITLE BETA = ^beta
    PLOT PEXCDF(X,BETA) FOR X = 0.01  0.01  2
    .
    LET BETA  = 1
    TITLE BETA = ^beta
    PLOT PEXCDF(X,BETA) FOR X = 0.01  0.01  2
    .
    LET BETA  = 2
    TITLE BETA = ^beta
    PLOT PEXCDF(X,BETA) FOR X = 0.01  0.01  2
    .
    LET BETA  = 5
    TITLE BETA = ^beta
    PLOT PEXCDF(X,BETA) FOR X = 0.01  0.01  2
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Exponential Power Cumulative Distribution Functions
 
-----PEXCHAZ (LET)--------------------------------
 
PEXCHAZ
 
Name:
    PEXCHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the exponential power cumulative hazard function
    with shape parameter beta.
 
Description:
    The exponential power distribution has the following cumulative
    hazard function:

        H(x;beta) = EXP(x**beta) - 1
                    x > 0; beta > 0

    with beta denoting the shape parameter.

    This distribution can be generalized with location and
    scale parameters using the relation

         H(x;beta,loc,scale) = H((x-loc)/scale;beta,0,1)

    This distribution was proposed by Dhillon as useful
    distribution for reliability applications since it can
    have increasing, decreasing, or bathtub shaped hazard
    functions.
 
Syntax:
    LET <y> = PEXCHAZ(<x>,<beta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing positive
               values;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed exponential power cumulative
               hazard value is stored;
          <beta> is a positive number, parameter, or variable that
               specifies the shape parameter;
          <loc> is a number, parameter, or variable that specifies
               the location parameter;
          <scale> is a positive number, parameter, or variable that
               specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = PEXCHAZ(0.3,2.5)
    LET A = PEXCHAZ(X1,2.5,0,10)
    PLOT PEXCHAZ(X,2.5,0,3) FOR X = 0.1  0.1  10
 
Note:
    The 11/2007 version changed the syntax for this function
    from

        LET A = PEXCHAZ(X,ALPHA,BETA,LOC,SCALE)

    to

        LET A = PEXCHAZ(X,BETA,LOC,SCALE)

    This was done since ALPHA is in fact a scale parameter
    (in the articles listed in the References section, ALPHA
    is actually the reciprocal of the scale parameter).

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PEXCDF  = Compute the exponential power cumulative distribution
              function.
    PEXPDF  = Compute the exponential power probability density
              function.
    PEXPPF  = Compute the exponential power percent point function.
    PEXHAZ  = Compute the exponential power hazard function.
    ALPPDF  = Compute the alpha probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the log-normal probability density function.
    NORCDF  = Compute the normal cumulative distribution function.
    NORPDF  = Compute the normal probability density function.
 
References:
    Johnson, Kotz, and Balakrishnan (1994), "Continuous Univariate
    Distributions--Volume 2", Second Edition, John Wiley and Sons,
    pp. 643-644.

    Dhillon (1981), "Life Distributions", IEEE Transactions on
    Reliability, Vol. R-30, No. 5, pp. 457-459.

Applications:
    Reliability, accelerated life testing
 
Implementation Date:
    1998/4
    2007/11: Corrected the second shape parameter to be the
             scale parameter

Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.5
    TITLE BETA = ^beta
    PLOT PEXCHAZ(X,BETA) FOR X = 0.01  0.01  2
    .
    LET BETA  = 1
    TITLE BETA = ^beta
    PLOT PEXCHAZ(X,BETA) FOR X = 0.01  0.01  2
    .
    LET BETA  = 2
    TITLE BETA = ^beta
    PLOT PEXCHAZ(X,BETA) FOR X = 0.01  0.01  2
    .
    LET BETA  = 5
    TITLE BETA = ^beta
    PLOT PEXCHAZ(X,BETA) FOR X = 0.01  0.01  2
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Exponential Power Cumulative Hazard Functions
 
-----PEXHAZ (LET)--------------------------------
 
PEXHAZ
 
Name:
    PEXHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the exponential power hazard function with shape
    parameter beta.
 
Description:
    The exponential power distribution has the following hazard
    function:

        h(x;beta) = beta*x**(beta-1)*EXP(x**beta)
                    x > 0; beta > 0

    with beta denoting the shape parameter.

    This distribution can be generalized with location and
    scale parameters using the relation

         h(x;beta,loc,scale) = (1/scale)*h((x-loc)/scale;beta,0,1)

    This distribution was proposed by Dhillon as useful
    distribution for reliability applications since it can
    have increasing, decreasing, or bathtub shaped hazard
    functions.
 
Syntax:
    LET <y> = PEXHAZ(<x>,<beta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing positive
               values;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed exponential power hazard value is
               stored;
          <beta> is a positive number, parameter, or variable that
               specifies the shape parameter;
          <loc> is a number, parameter, or variable that specifies
               the location parameter;
          <scale> is a positive number, parameter, or variable that
               specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = PEXHAZ(0.3,2.5)
    LET A = PEXHAZ(X1,2.5,0,10)
    PLOT PEXHAZ(X,2.5,0,3) FOR X = 0.1  0.1  10
 
Note:
    The 11/2007 version changed the syntax for this function
    from

        LET A = PEXHAZ(X,ALPHA,BETA,LOC,SCALE)

    to

        LET A = PEXHAZ(X,BETA,LOC,SCALE)

    This was done since ALPHA is in fact a scale parameter
    (in the articles listed in the References section, ALPHA
    is actually the reciprocal of the scale parameter).

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PEXCDF  = Compute the exponential power cumulative distribution
              function.
    PEXCHAZ = Compute the exponential power cumulative hazard
              function.
    PEXPDF  = Compute the exponential power probability density
              function.
    PEXPPF  = Compute the exponential power percent point function.
    ALPPDF  = Compute the alpha probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the log-normal probability density function.
    NORCDF  = Compute the normal cumulative distribution function.
    NORPDF  = Compute the normal probability density function.
 
References:
    Johnson, Kotz, and Balakrishnan (1994), "Continuous Univariate
    Distributions--Volume 2", Second Edition, John Wiley and Sons,
    pp. 643-644.

    Dhillon (1981), "Life Distributions", IEEE Transactions on
    Reliability, Vol. R-30, No. 5, pp. 457-459.

Applications:
    Reliability, accelerated life testing
 
Implementation Date:
    1998/4
    2007/11: Corrected the second shape parameter to be the
             scale parameter

Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.5
    TITLE BETA = ^beta
    PLOT PEXHAZ(X,BETA) FOR X = 0.01  0.01  2
    .
    LET BETA  = 1
    TITLE BETA = ^beta
    PLOT PEXHAZ(X,BETA) FOR X = 0.01  0.01  2
    .
    LET BETA  = 2
    TITLE BETA = ^beta
    PLOT PEXHAZ(X,BETA) FOR X = 0.01  0.01  2
    .
    LET BETA  = 5
    TITLE BETA = ^beta
    PLOT PEXHAZ(X,BETA) FOR X = 0.01  0.01  2
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Exponential Power Hazard Functions
 
-----PEXPDF (LET)--------------------------------
 
PEXPDF
 
Name:
    PEXPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the exponential power probability density function with
    shape parameter beta.
 
Description:
    The exponential power distribution has the following probability
    density function:

        f(x;beta) = beta*x**(beta-1)*EXP(x**beta)*
                    EXP(1 - EXP(x**beta))
                    x > 0; beta > 0

    with beta denoting the shape parameter.

    This distribution can be generalized with location and
    scale parameters using the relation

         f(x;beta,loc,scale) = (1/scale)*f((x-loc)/scale;beta,0,1)

    This distribution was proposed by Dhillon as useful
    distribution for reliability applications since it can
    have increasing, decreasing, or bathtub shaped hazard
    functions.
 
Syntax:
    LET <y> = PEXPDF(<x>,<beta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing positive
               values;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed exponential power pdf value is
               stored;
          <beta> is a positive number, parameter, or variable that
               specifies the shape parameter;
          <loc> is a number, parameter, or variable that specifies
               the location parameter;
          <scale> is a positive number, parameter, or variable that
               specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = PEXPDF(0.3,2.5)
    LET A = PEXPDF(X1,2.5,0,10)
    PLOT PEXPDF(X,2.5,0,3) FOR X = 0.1  0.1  10
 
Note:
    The 11/2007 version changed the syntax for this function
    from

        LET A = PEXPDF(X,ALPHA,BETA,LOC,SCALE)

    to

        LET A = PEXPDF(X,BETA,LOC,SCALE)

    This was done since ALPHA is in fact a scale parameter
    (in the articles listed in the References section, ALPHA
    is actually the reciprocal of the scale parameter).

Note:
    Exponential power random numbers, probability plots, and
    goodness of fit tests can be generated with the commands:

       LET BETA = <value>
       LET Y = EXPONENTIAL POWER RANDOM NUMBERS FOR I = 1 1 N
       EXPONENTIAL POWER PROBABILITY PLOT Y
       EXPONENTIAL POWER PROBABILITY PLOT Y2 X2
       EXPONENTIAL POWER PROBABILITY PLOT Y3 XLOW XHIGH
       EXPONENTIAL POWER KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       EXPONENTIAL POWER CHI-SQUARE GOODNESS OF FIT Y2 X2
       EXPONENTIAL POWER CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    The following commands can be used to estimate the beta
    shape parameter for the exponential power distribution:

       LET BETA1 = <value>
       LET BETA2 = <value>
       EXPONENTIAL POWER PPCC PLOT Y
       EXPONENTIAL POWER PPCC PLOT Y2 X2
       EXPONENTIAL POWER PPCC PLOT Y3 XLOW XHIGH
       EXPONENTIAL POWER KS PLOT Y
       EXPONENTIAL POWER KS PLOT Y2 X2
       EXPONENTIAL POWER KS PLOT Y3 XLOW XHIGH

    The default values for BETA1 and BETA2 are 0.5 and 10.

    The probability plot can then be used to estimate the
    location and scale (location = PPA0, scale = PPA1).

    The 2-parameter exponential power maximum likelihood
    estimates can be obtained using the command

       EXPONENTIAL POWER MAXIMUM LIKELIHOOD Y

    
    solution of the following simultaneous equations:

       (n/beta) + n*LOG(alpha) + SUM[i=1 to n][A(i)] - 
       SUM[i=1 to n][B(i)*C(i)*EXP(B(i))] + 
       SUM[i=1 to n][B(i)*C(i)] = 0

       (beta*n/alpha) - 
       (beta/alpha)*SUM[i=1 to n][B(i)*EXP(B(i))] +
       SUM[i=1 to n][B(i)] = 0

    where

       alpha = 1/scale
       A(i)  = LOG(X(i))
       B(i)  = (alpha*X(i))**beta
       C(i)  = LOG(alpha*X(i))

    Our experience indicates that the maximum likelihood
    can fail, particularly when the scale parameter is > 1.
    Specifying improved starting values can sometimes help
    (for example, use the estimates obtained from the ppcc/
    probability plot method as starting values).  These can
    be specified with the commands

       LET ALPHASV = <value>
       LET BETASV  = <value>

    In this context, ALPHASV is the starting value for the
    scale parameter, not the reciprocal of the scale parameter.

    The BOOTSTRAP DISTRIBUTION command can be used to find
    uncertainty intervals for the ppcc plot and the ks plot
    methods.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PEXCDF  = Compute the exponential power cumulative distribution
              function.
    PEXPPF  = Compute the exponential power percent point function.
    PEXHAZ  = Compute the exponential power hazard function.
    PEXCHAZ = Compute the exponential power cumulative hazard
              function.
    ALPPDF  = Compute the alpha probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the log-normal probability density function.
    NORCDF  = Compute the normal cumulative distribution function.
    NORPDF  = Compute the normal probability density function.
 
References:
    Johnson, Kotz, and Balakrishnan (1994), "Continuous Univariate
    Distributions--Volume 2", Second Edition, John Wiley and Sons,
    pp. 643-644.

    Dhillon (1981), "Life Distributions", IEEE Transactions on
    Reliability, Vol. R-30, No. 5, pp. 457-459.

Applications:
    Reliability, accelerated life testing
 
Implementation Date:
    1998/4
    2007/11: Corrected the second shape parameter to be the
             scale parameter

Program 1:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.5
    TITLE BETA = ^beta
    PLOT PEXPDF(X,BETA) FOR X = 0.01  0.01  2
    .
    LET BETA  = 1
    TITLE BETA = ^beta
    PLOT PEXPDF(X,BETA) FOR X = 0.01  0.01  2
    .
    LET BETA  = 2
    TITLE BETA = ^beta
    PLOT PEXPDF(X,BETA) FOR X = 0.01  0.01  2
    .
    LET BETA  = 5
    TITLE BETA = ^beta
    PLOT PEXPDF(X,BETA) FOR X = 0.01  0.01  2
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Exponential Power Probability Density Functions
 
Program 2:
    let beta = 2.4
    let y = exponential power random numbers for i = 1 1 200
    let y = 0.6*y
    let betasav = beta
    let amax = maximum y
    .
    exponential power ppcc plot y
    let beta1 = beta - 1
    let beta1 = max(beta1,0.1)
    let beta2 = beta + 1
    y1label Correlation Coefficient
    x1label Beta
    exponential power ppcc plot y
    justification center
    move 50 6
    let beta = shape
    text Betahat = ^beta (True Value: ^betasav)
    .
    char x
    line bl
    y1label Data
    x1label Theoretical
    exponential power prob plot y
    move 50 6
    text Location = ^ppa0, Scale = ^ppa1
    move 50 2
    text PPCC = ^ppcc
    char bl
    line so
    label
    .
    relative histogram y
    limits freeze
    pre-erase off
    plot pexpdf(x,beta,ppa0,ppa1) for x = 0.01 .01 amax
    limits 
    pre-erase on
    .
    let ksloc = ppa0
    let ksscale = ppa1
    exponential power kolm smir goodness of fit y
    .
    exponential power mle y
    .
    let beta = betaml
    let ksloc = ppa0
    let ksscale = alphaml
    exponential power kolm smir goodness of fit y

-----PEXPPF (LET)--------------------------------
 
PEXPPF
 
Name:
    PEXPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the exponential power percent point function
    with shape parameter beta.
 
Description:
    The exponential power distribution has the following percent
    point function:

        G(p;beta) = -{LOG[1 - LOG(1-p)]}**(1/beta)
                    0 < p < 1; beta > 0

    with beta denoting the shape parameter.

    This distribution can be generalized with location and
    scale parameters using the relation

         G(p;beta,loc,scale) = loc + scale*G(p;beta,0,1)

    This distribution was proposed by Dhillon as useful
    distribution for reliability applications since it can
    have increasing, decreasing, or bathtub shaped hazard
    functions.
 
Syntax:
    LET <y> = PEXPPF(<x>,<beta>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing positive
               values;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed exponential power ppf value is
               stored;
          <beta> is a positive number, parameter, or variable that
               specifies the shape parameter;
          <loc> is a number, parameter, or variable that specifies
               the location parameter;
          <scale> is a positive number, parameter, or variable that
               specifies the scale parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <loc> and <scale> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = PEXPPF(0.95,2.5)
    LET A = PEXPPF(P1,2.5,0,10)
    PLOT PEXPPF(P,2.5,0,3) FOR P = 0.01  0.01  0.99
 
Note:
    The 11/2007 version changed the syntax for this function
    from

        LET A = PEXPPF(P,ALPHA,BETA,LOC,SCALE)

    to

        LET A = PEXPPF(P,BETA,LOC,SCALE)

    This was done since ALPHA is in fact a scale parameter
    (in the articles listed in the References section, ALPHA
    is actually the reciprocal of the scale parameter).

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PEXCDF  = Compute the exponential power cumulative distribution
              function.
    PEXPDF  = Compute the exponential power probability density
              function.
    PEXHAZ  = Compute the exponential power hazard function.
    PEXCHAZ = Compute the exponential power cumulative hazard
              function.
    ALPPDF  = Compute the alpha probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    LGNPDF  = Compute the log-normal probability density function.
    NORCDF  = Compute the normal cumulative distribution function.
    NORPDF  = Compute the normal probability density function.
 
References:
    Johnson, Kotz, and Balakrishnan (1994), "Continuous Univariate
    Distributions--Volume 2", Second Edition, John Wiley and Sons,
    pp. 643-644.

    Dhillon (1981), "Life Distributions", IEEE Transactions on
    Reliability, Vol. R-30, No. 5, pp. 457-459.

Applications:
    Reliability, accelerated life testing
 
Implementation Date:
    1998/4
    2007/11: Corrected the second shape parameter to be the
             scale parameter

Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET BETA  = 0.5
    TITLE BETA = ^beta
    PLOT PEXPPF(P,BETA) FOR P = 0.01  0.01  0.99
    .
    LET BETA  = 1
    TITLE BETA = ^beta
    PLOT PEXPPF(P,BETA) FOR P = 0.01  0.01  0.99
    .
    LET BETA  = 2
    TITLE BETA = ^beta
    PLOT PEXPPF(P,BETA) FOR P = 0.01  0.01  0.99
    .
    LET BETA  = 5
    TITLE BETA = ^beta
    PLOT PEXPPF(P,BETA) FOR P = 0.01  0.01  0.99
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Exponential Power Percent Point Functions
 
-----PHASE PLANE DIAGRAM--------------------------------------
 
PHASE PLANE DIAGRAM
 
Name:
    PHASE PLANE DIAGRAM
 
Type:
    Graphics Command
 
Purpose:
    Generates a phase plane diagram.
 
Description:
    A first order differential equation is one of the form:
        y'=F(t,y)
    where t is an independent variable (often it is time) and y is a
    dependent variable.  A second order differential equation is one
    of the form:
        y''=F(t,y,y')
    Second (and higher order) differential equations are commonly
    reordered as a system of first order differential equations.  For
    the second order equation, this is done as:
        y1=y
        y2=y1'   = y'
        y3=y2'   = y''
    and the system of equations is:
        y1'=y2
        y2'=y3
    For example, the differential equation
        y''+y'=x**2 + y**2
    can be transformed into the two equations
        y1'=y2
        y2'=x**2+y**2-y2
 
    The phase space is the coordinate system determined by the
    dependent variables (y for first order equation, y1 and y2 for the
    second order case).  For the second order differential equation,
    the phase diagram (or phase portrait) plots the points:
          (y1(ti),y2(ti))
    where ti is the time at i = 0, 1, 2, ..., n.  In the original
    equations these points are:
          (y(ti),y'(ti))
    This idea extends to higher dimensions as well.
 
    If the functional forms are known, then the RUNGE KUTTA command
    can be used to find y and y', and the phase diagram can be plotted
    from those variables.
 
    The PHASE PLANE DIAGRAM is used for the case where the functional
    form of the differential equation is unknown.  It works on a set of
    data points (i.e., values for y and optionally for time) to give
    a graphical estimate of the phase diagram. It uses the fact that
    y'=dy/dx (i.e., the change in y divided by the change in x).  The
    one variable case (i.e., y only) plots the following:
       Vertical   axis = Y(i+1) - Y(i);
       Horizontal axis = Y(i).
    The two variable case plots the following:
       Vertical   axis = (Y(i+1) - Y(i))/(X(i+1)-X(i));
       Horizontal axis = Y(i).
    For the one variable case, the X values are assumed to be equally
    spaced and equal to 1 (that is, dx=1) and Y(i+1) - Y(i) is an
    estimate of dy.  For the two variable case, X(i+1) - X(i) is an
    estimate of dx and Y(i+1) - Y(i) is an estimate of dy.  In either
    case, the vertical axis is an estimate of the derivative of Y.
 
Syntax 1:
    PHASE PLANE DIAGRAM  <y>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    PHASE PLANE DIAGRAM <y> <x> <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <x> is the independent variable (usually time);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    PHASE PLANE DIAGRAM Y1 X
    PHASE PLANE DIAGRAM Y1
    PHASE PLANE DIAGRAM Y1 Y2 SUBSET TAG > 3
 
Note:
    A related technique is to plot y(t+1) vs. y(t).  This can be done
    in DATAPLOT with the LAG PLOT command.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINES          = Sets type for plot lines.
    CHARACTER      = Sets type for plot characters.
    LAG PLOT       = Generates a lag plot.
    PLOT           = Generates a data/function plot.
    MULTIPLOT      = Allows multiple plots per page
    RUNGE KUTTA    = Numerically solve a first or second order
                     differential equation.
 
Reference:
    "Differential Equations, Dynamical Systems, and Linear Algebra",
    Hirsch and Smale, Academic Press, 1974 (pp. 2-4).
 
    "Chaos", James Gleick, Penguin Press, 1987 (pp. 264-266).
 
Applications:
    Differential Equations
 
Implementation Date:
    88/9
 
Program:
    . SOURCE--DORN, WILLIAM S. AND MCCRACKEN, DANIEL D., NUMERICAL METHODS
    .         WITH FORTRAN IV CASE STUDIES, JOHN WILEY AND SONS, INC.,
    .         NEW YORK, 1972, PAGES 391-401.
    . TO FIND--DEFLECTION VALUE FOR VARIOUS DISTANCES OUT ONTO THE BEAM
    . NOTE--THE ELASTIC DEFLECTION SATISFIES THE DIFFERENTIAL EQUATION--
    .       Y'' / (1 + (Y')**2 )**(3/2)   =   P*(L-X) / (E*I)
    .       Y'' = P*(L-X) / (E*I)     *    (1 + (Y')**2 )**(3/2)
    .       WITH Y(0) = 0 AND Y'(0) = 0
    .       WHERE
    .          Y = DEFLECTION FROM HORIZONTAL (IN INCHES)
    .          X = DISTANCE OUT ONTO BEAM (X = 0, 2, 4, 6, ..., 100 INCHES)
    .          P = LOAD (IN POUNDS) AT FREE END (HERE = 64)
    .          L = LENGTH (IN INCHES) OF BEAM (HERE = 100)
    .          E = YOUNG'S MODULUS (= 6 * 10**6)
    .          I = MOMENT OF INERTIA OF CROSS SECTION (HERE = 0.128 INCHES**4)
    . -----START POINT-----------------------------------
    .
    .      STEP 1--DEFINE THE PHYSICAL PARAMETERS OF THE BEAM
    LET P = 64
    LET L = 100
    LET E = 6*10**6
    LET I = 0.128
    .      STEP 2--DEFINE THE RIGHT-SIDE FUNCTION OF Y''(X) = F
    LET FUNCTION F1 = P*(L-X)/(E*I)
    LET FUNCTION F2 = (1+YP**2)**(3/2)
    LET FUNCTION F = F1*F2
    .      STEP 3--DEFINE INITIAL CONDITIONS AND DEFINE THE DESIRED SEQUENCE
    .              OF POINTS AT WHICH TO COMPUTE THE SOLUTION CURVE.
    LET Y(1) = 0
    LET YP(1) = 0
    LET X = SEQUENCE 0 2 100
    .      STEP 4--SOLVE THE DIFFERENTIAL EQUATION
    LET Y YP = RUNGA-KUTTA F X
    .
    X1LABEL Y
    Y1LABEL Y' DERIVED FROM DATA
    PHASE PLANE DIAGRAM Y X
 
-----PI-------------------------------------------------------
 
PI
 
Name:
    PI
 
Type:
    Keyword
 
Purpose:
    An internal DATAPLOT parameter which has the value 3.1415926.
 
Description:
    This parameter is automatically-provided and can be used like
    any other parameter.
 
Syntax:
    None
 
Examples:
    PLOT SIN(PI*X) FOR X = 0 .1 2
    LET Y2 = (1/SQRT(2*PI))*EXP(0.5*X**2)
    FIT Y = A+B*SIN(OMEGA*PI*T)
 
Note:
    When PI is used in a FIT, as in
       FIT Y = A+B*SIN(OMEGA*PI*T)
    then DATAPLOT recognizes this parameter as a built-in constant (as
    one would hope) and so the FIT code will not attempt to produce
    least squares estimates of this parameter as it will for all the
    other parameters in the model being fitted.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    INFINITY    = Built-in parameter with the value machine infinity.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----PICTURE POINTS-------------------------------------------------
 
PICTURE POINTS
 
Name:
    PICTURE POINTS
 
Type:
    Output Device Command
 
Purpose:
    This command specifies the number of pixels (horizontal and
    vertical) on a device.
 
Description:
    Normally, specifying the device sets this value correctly.
    However, this command can sometimes be useful when using a
    different model number of a supported device.
 
Syntax 1:
    PICTURE POINTS  <hor>  <vert>
    where <hor> is a number or parameter that specifies the number of
              horizontal pixels;
    and   <vert> is a number or parameter that specifies the number of
              vertical pixels.
 
    This syntax sets the picture points on device 1 (i.e., the
    terminal).
 
Syntax 2:
    DEVICE <1/2/3>  PICTURE POINTS  <hor>  <vert>
    where 1 specifies device 1, 2 specifies device 2, and 3 specifies
              device 3;
          <hor> is a number or parameter that specifies the number of
              horizontal pixels;
    and   <vert> is a number or parameter that specifies the number of
              vertical pixels.
 
    This syntax sets the picture points on the specified device (1, 2,
    or 3).
 
Examples:
    PICTURE POINTS 1000 500
    DEVICE 2 PICTURE POINTS 1000 500
 
Default:
    None
 
Synonyms:
    DEVICE PICTURE POINTS
 
Related Commands:
    DEVICE           = Specify the graphics device.
    DEVICE COLOR     = Specify if the graphics device is color.
    DEVICE POWER     = Specify if the device is on or not.
 
Applications:
    Graphics Output
 
Implementation Date:
    Pre-1987
 
Program:
    DEVICE 2 GD JPEG
    DEVICE 2 PICTURE POINTS 700 450
    SKIP 25
    READ ZARR15.DAT Y
    4-PLOT Y
 
-----PIE CHART-------------------------------------------------------
 
PIE CHART
 
Name:
    PIE CHART
 
Type:
    Graphics Command
 
Purpose:
    Generates a pie chart.
 
Description:
    A pie chart is a graphical data analysis technique for summarizing
    the distributional information of a variable.  It is a circular
    plot consisting of wedges where the size of each wedge is
    proportional to the frequency (= number of observations) in that
    wedge.  The plot is to be read clockwise (where the first wedge is
    at "9 o'clock).
 
    If a single variable is specified, Dataplot divides the values
    into frequency classes in the same manner as for a histogram.  The
    histogram and the pie chart have the same information except the
    histogram has bars at the data values (where the height of the bar
    is proportional to the number of observations in the class),
    whereas the pie chart has wedges (where the area of the wedge is
    proportional to the number of observations in the class).
 
    If two variables are specified, the first variable contains
    pre-computed frequencies and the second variable is a group
    identifier.  This second form is more commonly used.
 
    As mentioned above, by default raw data is first binned into
    frequency data.  However, in many if not most cases, the response
    variable is intended to be interpreted as a frequency (i.e., the
    proportion for Y(i) is Y(i)/SUM[Y(i)]).  That is, we have an implicit
    group-id variable that is simply 1, 2, ..., N where N is the number
    of points in the response variable.

    To suppress this binning for the single variable case, enter

        SET PIE CHART UNBINNED

    To restore the default of binning raw data, enter

        SET PIE CHART BINNED

    Typically no binning is preferred for small size data sets.  Binning
    can be helpful for larger data sets in that it reduces the number of
    pie wedges that are plotted (in this case, we are really treating a
    pie chart as an alternative way to graph a histogram).

Syntax 1:
    PIE CHART   <x>    <SUBSET/EXCEPT/FOR qualification>
    where <x> is the variable of raw data values;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where you have raw data.
 
Syntax 2:
    PIE CHART   <y>   <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the variable of pre-computed frequencies;
          <x> is the variable of group identifiers;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where you have pre-computed
    frequencies at each data level.  This assumes that you have
    equal width bins.

Syntax 3:
    PIE CHART  <y>  <xlow>  <xhigh>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the variable of pre-computed frequencies;
          <xlow> is the variable containing the lower limits of the bins;
          <xhigh> is the variable containing the upper limits of the bins;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where you have pre-computed
    frequencies at each data level.  This syntax is used when you have
    unequal width bins.
 
Examples:
    PIE CHART X
    PIE CHART TEMP  SUBSET TEMP > 0
    PIE CHART F X   SUBSET X > 2
    PIE CHART COUNTS STATE
 
Note:
    Each wedge is drawn with a common set of attributes.  The
    attributes of the wedge borders are set with the LINE, LINE COLOR,
    and LINE THICKNESS commands (typically they are all set the same).
    The attributes of the interior are set with the various REGION
    commands.  Any labels for the wedges must be set with the LEGEND or
    TEXT commands.  The CROSS HAIR command can help in positioning
    labels.  The program example below shows how to set the attributes.
    Dataplot does not support features such as 3d pie charts or
    exploding slices that are common in many business graphics
    programs.
 
Note:
    Although pie charts are popular in business graphics, they are
    generally a poor graphics technique.  See the book listed in the
    Reference section below for more information.
 
Note:
    For the one variable form of the command, Dataplot uses a class
    width of 0.3 X the standard deviation of the variable.  Use the
    CLASS WIDTH to override this default.  Dataplot also tends to
    generate a large number of zero frequency classes at the lower and
    upper tails.  The CLASS LOWER and CLASS UPPER commands can be used
    to set lower and upper limits for the classes.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    HISTOGRAM          = Generates a histogram.
    FREQUENCY PLOT     = Generates a frequency plot.
    PERCENT POINT PLOT = Generates a percent point plot.
    PLOT               = Generates a plot (including bar plots).
    CLASS LOWER        = Sets the lower class minimum for histograms,
                         frequency plots, and pie charts.
    CLASS UPPER        = Sets the upper class maximum for histograms,
                         frequency plots, and pie charts.
    CLASS WIDTH        = Sets the class width for histogram, frequency
                         plots, and pie charts.
    LINE               = Sets the types for plot lines.
    LINE COLOR         = Sets the colors for plot lines.
    LINE THICKNESS     = Sets the thicknesses for plot lines.
    REGION FILL        = Sets on/off switches for region fills.
 
Reference:
    William Cleveland (1985), "The Elements of Graphing Data", Wadsworth,
    p. 264.
 
Applications:
    Business Graphics
 
Implementation Date:
    Pre-1987
    1993/11: Added the ability to set the attributes of the pie wedges.
 
Program:
    LET X = DATA 81 82 83 84 85
    LET Y = DATA 2 5 9 15 28
    .
    TITLE SALES IN MILLIONS OF DOLLARS
    LINE THICKNESS .3 ALL
    REGION FILL ON ALL
    REGION PATTERN COLOR G10 G30 G50 G70 G90
    REGION FILL COLOR G10 G30 G50 G70 G90
    LET N = SIZE X
    LOOP FOR K = 1 1 N
        LET A = X(K)
        LEGEND ^K 19^A
    END OF LOOP
    LEGEND 1 COORDINATES 8 58
    LEGEND 2 COORDINATES 10 71
    LEGEND 3 COORDINATES 28 92
    LEGEND 4 COORDINATES 68 77
    LEGEND 5 COORDINATES 67 30
    PIE CHART Y X

-----PIXMAP TITLE--------------------------------------------------
 
PIXMAP TITLE
 
Name:
    PIXMAP TITLE
 
Type:
    Support Command
 
Purpose:
    Specify a title for a plot saved with the SAVE PLOT command.
    This is a temporary title used for identification purposes
    only and is not saved with the plot.
 
Description:
    The SAVE PLOT and REPEAT PLOT commands allow you to save and
    recall graphs.  The primary use of this is to compare the current
    graph to previously created graphs.
 
    The PIXMAP TITLE command applies to the current plot when 
    the SAVE PLOT command is entered.  The order of the plot
    command and PIXMAP TITLE command does not matter.

    Dataplot maintains a list of saved graphs for the current
    session.  The "current list" consists of all plots saved in
    the current session and any plots from previous Dataplot
    sessions explicitly recalled with the REPEAT PLOT command.

    These commands are host dependent.  They are currently
    supported for the following platforms:
   
       1) Unix platforms via the X11 device driver;
       2) Windows 95/98/NT command line version built with the
          Microsoft Fortran compiler;
       3) Dataplot GUI (both Unix and Windows 95/98/NT).

Syntax:
    PIXMAP TITLE <string>
    where <string> specifies the title for the saved plot.
 
Examples:
    HISTOGRAM Y1
    PIXMAP TITLE HISTOGRAM: Y1
    SAVE PLOT HIST.1
 
Default:
    None
 
Synonyms:
    None

Note:
    Be aware that for SAVE PLOT AUTOMATIC, the saving for a given
    plot is not executed until the next screen erase (typically the
    next plot) is encountered to allow for multi-plotting and the
    addition of diagrammatic graphics to a plot.  The order of
    the commands would typically be something like:

       SAVE GRAPH AUTOMATIC
       4-PLOT Y
       PIXMAP TITLE 4-PLOT
       PLOT Y
       PIXMAP TITLE PLOT Y
       HISTOGRAM Y
       PIXMAP TITLE HISTOGRAM

    The main point here is that the PIXMAP TITLE comes AFTER the
    plot command.

Note:
    Unlike the regular TITLE command, the PIXMAP TITLE command does
    not persist.  That is, it applies only to the next saved plot and
    then reverts to the default of using the file name.

Note:
    The REPEAT PLOT command is used to display a plot saved
    with SAVE PLOT.  The LIST PLOT command lists the currently
    saved plots (by sequence number, file name, and title).
    The CYCLE PLOT command allows you to cycle through the
    pixmaps in the current list by clicking mouse buttons.
    The PIXMAP TITLE command allows you to specify the title
    for a saved plot.  This title is simply for ease of
    identification in listing the saved plots and is not
    saved as part of the plot.
 
Related Commands:
    LIST PLOT    = List saved plots.
    REPEAT PLOT  = Redraw a previously saved plot.
    SAVE PLOT    = Save a plot.
    CYCLE PLOT   = Cycle through previously saved graphs using 
                   mouse buttons.
 
Applications:
    Interactive Usage
 
Implementation Date:
    7/1997
 
Program:
    READ BERGER1.DAT Y X
    FIT Y X
    4-PLOT RES
    PIXMAP TITLE RESIDUALS FROM LINEAR FIT
    SAVE PLOT RES.1
    QUADRATIC FIT Y X
    4-PLOT RES
    PIXMAP TITLE RESIDUALS FROM QUADRATIC FIT
    SAVE PLOT RES.2
    LIST PLOT
 
-----PLACEMENT SCORE (LET)-----------------------------------------------
 
PLACEMENT SCORE
 
Name:
    PLACEMENT SCORE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the placement scores of two variables.
 
Description:
    Given two respoonse variables, say Y1 and Y2, the placement score
    for Y1(i) is defined as the number of observations in Y2 that
    are less than Y1(i).  Likewise, the placement score for Y2(i) is
    the number of observations in Y1 that are less than Y2(i).  Values
    in Y2 that are equal to Y1(i) (or values in Y1 that are equal to
    Y2(i)) add 0.5 rather than 1.

    Placement scores are used to compute the Fligner-Policello two
    sample location test.  This is demonstrated in the Program example
    below.

Syntax:
    LET <y1p> <y2p> = PLACEMENT SCORES <y1> <y2>
                      <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <y1p> is a variable where the computed placement scores for
              <y1> are saved;
          <y2p> is a variable where the computed placement scores for
              <y2> are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y1P Y2P = PLACEMENT SCORES Y1 Y2
    LET Y1P Y2P = PLACEMENT SCORES Y1 Y2  SUBSET Y1 > 0 SUBSET Y2 > 0
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RANK SUM TEST           = Perform a rank sum test.
    MEDIAN TEST             = Perform a median test.
    KRUSKAL WALLIS TEST     = Perform a Kruskal Wallis test.
    T TEST                  = Perform a t test.
    ANOVA                   = Perform a fixed effects analysis of variance.
    MEDIAN SCORES           = Generate median scores.
    MOOD SCORES             = Generate Mood scores.
    VAN DER WAERDEN SCORES  = Generate Van Der Waerden scores.
    SAVAGE SCORES           = Generate Savage scores.
    KLOTZ SCORES            = Generate Klotz scores.
    CONOVER SCORES          = Generate Conover scores.
    ANSARI BRADLEY SCORES   = Generate Ansari Bradley scores.
 
Reference:
    Fligner and Policello (1981), "Robust Rank Procedures for the
    Behrens-Fisher Problem," Journal of the American Statistical
    Association, Vol. 76, pp. 162-168.

Applications:
    Nonparametric statistics
 
Implementation Date:
    2023/06
 
Program:
    . Step 1:   Define the data
    .
    skip 25
    read natr323.dat y1 y2
    retain y2 subset y2 > -90
    .
    . Step 2: Compute Fligner-Policello Test
    .
    let y1p y2p = placement scores y1 y2
    let pmean1 = mean y1p
    let pmean2 = mean y2p
    let psum1 = sum y1p
    let psum2 = sum y2p
    let temp1 = (y1p - pmean1)**2
    let v1 = sum temp1
    let temp2 = (y2p - pmean2)**2
    let v2 = sum temp2
    let num = psum1 - psum2
    let den = 2*sqrt(v1 + v2 + pmean1*pmean2)
    let z = num/den
    let zabs = abs(z)
    .
    . Step 3: Print Fligner-Policello Test Results
    .
    feedback off
    print "Fligner-Policello Test"
    print "H0: Medians are Equal"
    print "Ha: Medians are Not Equal"
    print "alpha: 0.05"
    print "Test Statistic: ^z"
    print "Lower Critical Value: -1.96"
    print "Upper Critical Value:  1.96"
    if zabs <= 1.96
       print "Conclusion: Accept H0"
    else
       print "Conclusion: Reject H0"
    end of if

-----PLEM (LET)----------------------------------------------
 
PLEM
 
Name:
    PLEM (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the real component of the Weierstrass P elliptic function
    of a complex number (lemniscatic case with unit period
    parallelogram).
 
Description:
    The Weierstrass elliptic function is described in detail in the
    Handbook of Mathematical Functions (see REFERENCE section below).

Syntax:
    LET <a> = PLEM(<xr>,<xc>)  <SUBSET/EXCEPT/FOR qualification>
    where <xr> is a number, parameter, or variable that specifies the
              the real component of the input;
          <xc> is a number, parameter, or variable that specifies the
              the complex component of the input;
          <a> is a variable or a parameter (depending on what <xr> and
               <xc> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PLEM(2,1)
    LET A = PLEM(X,4)
    LET X2 = PLEM(1,Y)
 
Note:
    The Weierstrass elliptic functions are computed using algorithm
    549 from the ACM Transactions on Mathematical Software (see the
    REFERENCE section below).

Note:
    If the input value corresponds to a lattice point, an error
    message is printed and the output value is set to the largest
    real number on the machine.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PEQ     = Compute the real component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQI    = Compute the complex component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQ1    = Compute the real component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PEQ1I   = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PLEMI   = Compute the complex component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEM1   = Compute the real component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    PLEM1I  = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    SN      = Compute the Jacobi elliptic function sn.
    CN      = Compute the Jacobi elliptic function cn.
    DN      = Compute the Jacobi elliptic function dn.
    RF      = Compute the Carlson elliptic integral of the first kind.
    RD      = Compute the Carlson elliptic integral of the second kind.
    RJ      = Compute the Carlson elliptic integral of the third kind.
    ELLIPC1 = Compute the Legendre complete elliptic integral of the
              first kind.
    ELLIPC2 = Compute the Legendre complete elliptic integral of the
              second kind.
    ELLIP1  = Compute the Legendre elliptic integral of the first
              kind.
    ELLIP2  = Compute the Legendre elliptic integral of the second
              kind.
    ELLIP3  = Compute the Legendre's elliptic integral of the third
              kind.
 
Reference:
    "Algorithm 549: Weierstrass' Elliptic Functions", Eckhardt, ACM
    Transactions on Mathematical Software, vol. 6 (pp. 112-120).

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 18).

Applications:
    Special Functions
 
Implementation Date:
    94/11
 
Program:
    TITLE WEIERSTRASS ELLIPTIC FUNCTIONS
    LINE SOLID DASH
    PLOT PLEM(X,0.5) FOR X = 0 0.01 5 AND
    PLOT PLEMI(X,0.5) FOR X = 0 0.01 5
 
-----PLEMI (LET)----------------------------------------------
 
PLEMI
 
Name:
    PLEMI (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the complex component of the Weierstrass P elliptic
    function of a complex number (lemniscatic case with unit period
    parallelogram).
 
Description:
    The Weierstrass elliptic function is described in detail in the
    Handbook of Mathematical Functions (see REFERENCE section below).

Syntax:
    LET <a> = PLEMI(<xr>,<xc>)  <SUBSET/EXCEPT/FOR qualification>
    where <xr> is a number, parameter, or variable that specifies the
              the real component of the input;
          <xc> is a number, parameter, or variable that specifies the
              the complex component of the input;
          <a> is a variable or a parameter (depending on what <xr> and
               <xc> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PLEMI(2,1)
    LET A = PLEMI(X,4)
    LET X2 = PLEMI(1,Y)
 
Note:
    The Weierstrass elliptic functions are computed using algorithm
    549 from the ACM Transactions on Mathematical Software (see the
    REFERENCE section below).

Note:
    If the input value corresponds to a lattice point, an error
    message is printed and the output value is set to the largest
    real number on the machine.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PEQ     = Compute the real component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQI    = Compute the complex component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQ1    = Compute the real component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PEQ1I   = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PLEM    = Compute the real component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEM1   = Compute the real component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    PLEM1I  = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    SN      = Compute the Jacobi elliptic function sn.
    CN      = Compute the Jacobi elliptic function cn.
    DN      = Compute the Jacobi elliptic function dn.
    RF      = Compute the Carlson elliptic integral of the first kind.
    RD      = Compute the Carlson elliptic integral of the second kind.
    RJ      = Compute the Carlson elliptic integral of the third kind.
    ELLIPC1 = Compute the Legendre complete elliptic integral of the
              first kind.
    ELLIPC2 = Compute the Legendre complete elliptic integral of the
              second kind.
    ELLIP1  = Compute the Legendre elliptic integral of the first
              kind.
    ELLIP2  = Compute the Legendre elliptic integral of the second
              kind.
    ELLIP3  = Compute the Legendre's elliptic integral of the third
              kind.
 
Reference:
    "Algorithm 549: Weierstrass' Elliptic Functions", Eckhardt, ACM
    Transactions on Mathematical Software, vol. 6 (pp. 112-120).

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 18).

Applications:
    Special Functions
 
Implementation Date:
    94/11
 
Program:
    TITLE WEIERSTRASS ELLIPTIC FUNCTIONS
    LINE SOLID DASH
    PLOT PLEMI(X,0.5) FOR X = 0 0.01 5 AND
    PLOT PLEM(X,0.5) FOR X = 0 0.01 5
 
-----PLEM1 (LET)----------------------------------------------
 
PLEM1
 
Name:
    PLEM1 (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the real component of the first derivative of the 
    Weierstrass P elliptic function of a complex number (lemniscatic
    case with unit period parallelogram).
 
Description:
    The Weierstrass elliptic function is described in detail in the
    Handbook of Mathematical Functions (see REFERENCE section below).

Syntax:
    LET <a> = PLEM1(<xr>,<xc>)  <SUBSET/EXCEPT/FOR qualification>
    where <xr> is a number, parameter, or variable that specifies the
              the real component of the input;
          <xc> is a number, parameter, or variable that specifies the
              the complex component of the input;
          <a> is a variable or a parameter (depending on what <xr> and
               <xc> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PLEM1(2,1)
    LET A = PLEM1(X,4)
    LET X2 = PLEM1(1,Y)
 
Note:
    The Weierstrass elliptic functions are computed using algorithm
    549 from the ACM Transactions on Mathematical Software (see the
    REFERENCE section below).

Note:
    If the input value corresponds to a lattice point, an error
    message is printed and the output value is set to the largest
    real number on the machine.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PEQ     = Compute the real component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQI    = Compute the complex component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQ1    = Compute the real component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PEQ1I   = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PLEM    = Compute the real component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEMI   = Compute the complex component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEM1I  = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    SN      = Compute the Jacobi elliptic function sn.
    CN      = Compute the Jacobi elliptic function cn.
    DN      = Compute the Jacobi elliptic function dn.
    RF      = Compute the Carlson elliptic integral of the first kind.
    RD      = Compute the Carlson elliptic integral of the second kind.
    RJ      = Compute the Carlson elliptic integral of the third kind.
    ELLIPC1 = Compute the Legendre complete elliptic integral of the
              first kind.
    ELLIPC2 = Compute the Legendre complete elliptic integral of the
              second kind.
    ELLIP1  = Compute the Legendre elliptic integral of the first
              kind.
    ELLIP2  = Compute the Legendre elliptic integral of the second
              kind.
    ELLIP3  = Compute the Legendre's elliptic integral of the third
              kind.
 
Reference:
    "Algorithm 549: Weierstrass' Elliptic Functions", Eckhardt, ACM
    Transactions on Mathematical Software, vol. 6 (pp. 112-120).

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 18).

Applications:
    Special Functions
 
Implementation Date:
    94/11
 
Program:
    TITLE WEIERSTRASS ELLIPTIC FUNCTIONS
    LINE SOLID DASH
    PLOT PLEM1(X,0.5) FOR X = 0 0.01 5 AND
    PLOT PLEM1I(X,0.5) FOR X = 0 0.01 5
 
-----PLEM1I (LET)----------------------------------------------
 
PLEM1I
 
Name:
    PLEM1I (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the complex component of the first derivative of the 
    Weierstrass P elliptic function of a complex number (lemniscatic
    case with unit period parallelogram).
 
Description:
    The Weierstrass elliptic function is described in detail in the
    Handbook of Mathematical Functions (see REFERENCE section below).

Syntax:
    LET <a> = PLEM1I(<xr>,<xc>)  <SUBSET/EXCEPT/FOR qualification>
    where <xr> is a number, parameter, or variable that specifies the
              the real component of the input;
          <xc> is a number, parameter, or variable that specifies the
              the complex component of the input;
          <a> is a variable or a parameter (depending on what <xr> and
               <xc> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PLEM1I(2,1)
    LET A = PLEM1I(X,4)
    LET X2 = PLEM1I(1,Y)
 
Note:
    The Weierstrass elliptic functions are computed using algorithm
    549 from the ACM Transactions on Mathematical Software (see the
    REFERENCE section below).

Note:
    If the input value corresponds to a lattice point, an error
    message is printed and the output value is set to the largest
    real number on the machine.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PEQ     = Compute the real component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQI    = Compute the complex component of the Weierstrass elliptic
              function (equianharmonic case).
    PEQ1    = Compute the real component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PEQ1I   = Compute the complex component of the first derivative of
              the Weierstrass elliptic function (equianharmonic case).
    PLEM    = Compute the real component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEMI   = Compute the complex component of the Weierstrass elliptic
              function (lemniscatic case).
    PLEM1   = Compute the real component of the first derivative of
              the Weierstrass elliptic function (lemniscatic case).
    SN      = Compute the Jacobi elliptic function sn.
    CN      = Compute the Jacobi elliptic function cn.
    DN      = Compute the Jacobi elliptic function dn.
    RF      = Compute the Carlson elliptic integral of the first kind.
    RD      = Compute the Carlson elliptic integral of the second kind.
    RJ      = Compute the Carlson elliptic integral of the third kind.
    ELLIPC1 = Compute the Legendre complete elliptic integral of the
              first kind.
    ELLIPC2 = Compute the Legendre complete elliptic integral of the
              second kind.
    ELLIP1  = Compute the Legendre elliptic integral of the first
              kind.
    ELLIP2  = Compute the Legendre elliptic integral of the second
              kind.
    ELLIP3  = Compute the Legendre's elliptic integral of the third
              kind.
 
Reference:
    "Algorithm 549: Weierstrass' Elliptic Functions", Eckhardt, ACM
    Transactions on Mathematical Software, vol. 6 (pp. 112-120).

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 18).

Applications:
    Special Functions
 
Implementation Date:
    94/11
 
Program:
    TITLE WEIERSTRASS ELLIPTIC FUNCTIONS
    LINE SOLID DASH
    PLOT PLEM1I(X,0.5) FOR X = 0 0.01 5 AND
    PLOT PLEM1(X,0.5) FOR X = 0 0.01 5
 
-----PLNCDF (LET)--------------------------------
 
PLNCDF
 
Name:
    PLNCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard power-lognormal cumulative distribution
    function.
 
Description:
    The standard power-lognormal distribution has the following
    cumulative distribution function:
       F(x,sigma,p) = 1 - {NORCDF(-ln(x)/sigma)}**p
                      for x, sigma, p > 0
    where sigma is a shape parameter, p is a shape (power) parameter,
    and NORCDF and NORPDF are the cumulative distribution function
    and the probability density function for the standard normal
    distribution, respectively.

    If p is 1, this distribution reduces to the lognormal
    distribution.

Syntax:
    LET <y> = PLNCDF(<x>,<p>,<s>)   <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, parameter, or variable;
          <p> is a positive number, parameter, or variable
              that specifies the power parameter;
          <s> is an optional positive number, parameter, or variable
              that specifies the shape parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed power-lognormal cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If the <s> parameter is omitted, it defaults to 1.

Examples:
    LET A = PLNCDF(3,2,1)
    LET X2 = PLNCDF(X1,POW,SD)
    LET X2 = PLNCDF(X1,1,0.5)
 
Note:
    The general power-lognormal cumulative distribution function
    can be expressed in terms of the standard power-lognormal
    cumulative distribution function as follows:
       F(x,sigma,p,loc,scale)=F((x-loc)/scale,sigma,p)
                          for x > loc,  sigma, p, scale > 0
    where loc and scale are the location and scales parameters,
    respectively.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PLNPDF  = Compute the power-lognormal probability density
              function.
    PLNPPF  = Compute the power-lognormal percent point function.
    PLNHAZ  = Compute the power-lognormal hazard function.
    PLNCHAZ = Compute the power-lognormal cumulative hazard function.
    PNRPDF  = Compute the power-normal probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    HFNPDF  = Compute the half-normal probability density function.
    NORPDF  = Compute the normal probability density function.
 
Reference:
    "A Computer Program POWNOR for Fitting the Power-Normal and
    -Lognormal Models to Life or Strength Data from Specimens of
    Various Sizes", Nelson and Doganaksoy, NIST-IR 4760, March 1992.
 
Applications:
    Reliability
 
Implementation Date:
    1995/5

Program:
    LABEL CASE ASIS
    X1LABEL X
    Y1LABEL Probability
    Y1LABEL DISPLACEMENT 12
    TITLE CASE ASIS
    . 
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    .
    TITLE P = 0.5, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNCDF(X,0.5,0.2) FOR X = 0.01 .01 3 AND
    PLOT PLNCDF(X,0.5,0.4) FOR X = 0.01 .01 3 AND
    PLOT PLNCDF(X,0.5,0.7) FOR X = 0.01 .01 3 AND
    PLOT PLNCDF(X,0.5,1.0) FOR X = 0.01 .01 3
    TITLE P = 1.0, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNCDF(X,1.0,0.2) FOR X = 0.01 .01 3 AND
    PLOT PLNCDF(X,1.0,0.4) FOR X = 0.01 .01 3 AND
    PLOT PLNCDF(X,1.0,0.7) FOR X = 0.01 .01 3 AND
    PLOT PLNCDF(X,1.0,1.0) FOR X = 0.01 .01 3
    TITLE P = 5.0, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNCDF(X,5.0,0.2) FOR X = 0.01 .01 2 AND
    PLOT PLNCDF(X,5.0,0.4) FOR X = 0.01 .01 2 AND
    PLOT PLNCDF(X,5.0,0.7) FOR X = 0.01 .01 2 AND
    PLOT PLNCDF(X,5.0,1.0) FOR X = 0.01 .01 2
    TITLE P = 20, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNCDF(X,20,0.2) FOR X = 0.01 .01 1 AND
    PLOT PLNCDF(X,20,0.4) FOR X = 0.01 .01 1 AND
    PLOT PLNCDF(X,20,0.7) FOR X = 0.01 .01 1 AND
    PLOT PLNCDF(X,20,1.0) FOR X = 0.01 .01 1
    .
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT Power Lognormal CDF's
 
-----PLNCHAZ (LET)--------------------------------
 
PLNCHAZ
 
Name:
    PLNCHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard power-lognormal hazard function.
 
Description:
    The standard power-lognormal distribution has the following
    cumulative hazard function:
       H(x,sigma,p)=-LOG[(NORCDF(-LOG(x)/sigma))**p)
                     for x, p, sigma > 0
    where sigma is a shape parameter, p is a shape (power) parameter,
    and NORCDF is the cumulative distribution function for the
    standard normal distribution.
 
    If p is 1, this distribution reduces to the lognormal
    distribution.

Syntax:
    LET <y> = PLNCHAZ(<x>,<p>,<s>)   <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, parameter, or variable;
          <p> is a positive number, parameter, or variable
              that specifies the power parameter;
          <s> is an optional positive number, parameter, or variable
              that specifies the shape parameter;
          <y> is a variable or a parameter (depending on what <y1>
              is) where the computed power-lognormal cumulative
              hazard value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If the <s> parameter is omitted, it defaults to 1.

Examples:
    LET A = PLNCHAZ(3,2,1)
    LET X2 = PLNCHAZ(X1,POW,SD)
    LET X2 = PLNCHAZ(X1,0.5,0.5)
 
Note:
    The general power-lognormal cumulative hazard function can be
    expressed in terms of the standard power-lognormal cumulative
    hazard function as follows:
       H(x,sigma,p,loc,scale)=H((x-loc)/scale,sigma,p)
                          for x > loc,  sigma, p,scale > 0
    where loc and scale are the location and scales parameters,
    respectively.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PLNCDF  = Compute the power-lognormal cumulative distribution
              function.
    PLNPDF  = Compute the power-lognormal probability density
              function.
    PLNPPF  = Compute the power-lognormal percent point function.
    PLNHAZ  = Compute the power-lognormal hazard function.
    PNRPDF  = Compute the power-normal probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    HFNPDF  = Compute the half-normal probability density function.
    NORPDF  = Compute the normal probability density function.
 
Reference:
    "A Computer Program POWNOR for Fitting the Power-Normal and
    -Lognormal Models to Life or Strength Data from Specimens of
    Various Sizes", Nelson and Doganaksoy, NIST-IR 4760, March 1992.
 
Applications:
    Reliability
 
Implementation Date:
    1998/4
 
Program:
    LABEL CASE ASIS
    X1LABEL X
    Y1LABEL Cumulative Hazard
    TITLE CASE ASIS
    . 
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    .
    TITLE P = 0.5, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNCHAZ(X,0.5,0.2) FOR X = 0.01 .01 3 AND
    PLOT PLNCHAZ(X,0.5,0.4) FOR X = 0.01 .01 3 AND
    PLOT PLNCHAZ(X,0.5,0.7) FOR X = 0.01 .01 3 AND
    PLOT PLNCHAZ(X,0.5,1.0) FOR X = 0.01 .01 3
    TITLE P = 1.0, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNCHAZ(X,1.0,0.2) FOR X = 0.01 .01 3 AND
    PLOT PLNCHAZ(X,1.0,0.4) FOR X = 0.01 .01 3 AND
    PLOT PLNCHAZ(X,1.0,0.7) FOR X = 0.01 .01 3 AND
    PLOT PLNCHAZ(X,1.0,1.0) FOR X = 0.01 .01 3
    TITLE P = 5.0, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNCHAZ(X,5.0,0.2) FOR X = 0.01 .01 2 AND
    PLOT PLNCHAZ(X,5.0,0.4) FOR X = 0.01 .01 2 AND
    PLOT PLNCHAZ(X,5.0,0.7) FOR X = 0.01 .01 2 AND
    PLOT PLNCHAZ(X,5.0,1.0) FOR X = 0.01 .01 2
    TITLE P = 20, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNCHAZ(X,20,0.2) FOR X = 0.01 .01 1 AND
    PLOT PLNCHAZ(X,20,0.4) FOR X = 0.01 .01 1 AND
    PLOT PLNCHAZ(X,20,0.7) FOR X = 0.01 .01 1 AND
    PLOT PLNCHAZ(X,20,1.0) FOR X = 0.01 .01 1
    .
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT Power Lognormal Cumulative Hazard Functions
 
-----PLNHAZ (LET)--------------------------------
 
PLNHAZ
 
Name:
    PLNHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard power-lognormal hazard function.
 
Description:
    The standard power-lognormal distribution has the following
    hazard function:
       h(x,sigma,p)=p*(1/(x*sigma))*NORPDF(ln(x)/sigma)/
                    NORCDF(-ln(x)/sigma)     for x, p, sigma > 0
    where sigma is a shape parameter, p is a shape (power) parameter,
    and NORCDF and NORPDF are the cumulative distribution function
    and the probability density function for the standard normal
    distribution respectively.
 
    The hazard function for the power-lognormal distribution is
    a multiple (p) of the hazard function of the lognormal
    distribution.

    If p is 1, this distribution reduces to the lognormal
    distribution.

Syntax:
    LET <y> = PLNHAZ(<x>,<p>,<s>)   <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, parameter, or variable;
          <p> is a positive number, parameter, or variable
              that specifies the power parameter;
          <s> is an optional positive number, parameter, or variable
              that specifies the shape parameter;
          <y> is a variable or a parameter (depending on what <y1>
              is) where the computed power-lognormal hazard value is
              stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If the <s> parameter is omitted, it defaults to 1.

Examples:
    LET A = PLNHAZ(3,2,1)
    LET X2 = PLNHAZ(X1,POW,SD)
    LET X2 = PLNHAZ(X1,0.5,0.5)
 
Note:
    The general power-lognormal hazard function can be expressed
    in terms of the standard power-lognormal hazard function as
    follows:
       h(x,sigma,p,loc,scale)=h((x-loc)/scale,sigma,p)/scale
                          for x > loc,  sigma, p, scale > 0
    where loc and scale are the location and scales parameters,
    respectively.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PLNCDF  = Compute the power-lognormal cumulative distribution
              function.
    PLNPDF  = Compute the power-lognormal probability density
              function.
    PLNPPF  = Compute the power-lognormal percent point function.
    PLNCHAZ = Compute the power-lognormal cumulative hazard function.
    PNRPDF  = Compute the power-normal probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    HFNPDF  = Compute the half-normal probability density function.
    NORPDF  = Compute the normal probability density function.
 
Reference:
    "A Computer Program POWNOR for Fitting the Power-Normal and
    -Lognormal Models to Life or Strength Data from Specimens of
    Various Sizes", Nelson and Doganaksoy, NIST-IR 4760, March 1992.
 
Applications:
    Reliability
 
Implementation Date:
    1998/4
 
Program:
    LABEL CASE ASIS
    X1LABEL X
    Y1LABEL Hazard
    TITLE CASE ASIS
    . 
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    .
    TITLE P = 0.5, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNHAZ(X,0.5,0.2) FOR X = 0.01 .01 3 AND
    PLOT PLNHAZ(X,0.5,0.4) FOR X = 0.01 .01 3 AND
    PLOT PLNHAZ(X,0.5,0.7) FOR X = 0.01 .01 3 AND
    PLOT PLNHAZ(X,0.5,1.0) FOR X = 0.01 .01 3
    TITLE P = 1.0, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNHAZ(X,1.0,0.2) FOR X = 0.01 .01 3 AND
    PLOT PLNHAZ(X,1.0,0.4) FOR X = 0.01 .01 3 AND
    PLOT PLNHAZ(X,1.0,0.7) FOR X = 0.01 .01 3 AND
    PLOT PLNHAZ(X,1.0,1.0) FOR X = 0.01 .01 3
    TITLE P = 5.0, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNHAZ(X,5.0,0.2) FOR X = 0.01 .01 2 AND
    PLOT PLNHAZ(X,5.0,0.4) FOR X = 0.01 .01 2 AND
    PLOT PLNHAZ(X,5.0,0.7) FOR X = 0.01 .01 2 AND
    PLOT PLNHAZ(X,5.0,1.0) FOR X = 0.01 .01 2
    TITLE P = 20, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNHAZ(X,20,0.2) FOR X = 0.01 .01 1 AND
    PLOT PLNHAZ(X,20,0.4) FOR X = 0.01 .01 1 AND
    PLOT PLNHAZ(X,20,0.7) FOR X = 0.01 .01 1 AND
    PLOT PLNHAZ(X,20,1.0) FOR X = 0.01 .01 1
    .
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT Power Lognormal Hazard Functions
 
-----PLNPDF (LET)--------------------------------
 
PLNPDF
 
Name:
    PLNPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard power-lognormal probability density
    function.
 
Description:
    The standard power-lognormal distribution has the following
    probability density function:
       f(x,sigma,p)=(p/(x*sigma))*NORPDF(ln(x)/sigma)*
                    NORCDF(-ln(x)/sigma)**(p-1)
                    for x, p, sigma > 0
    where sigma is a shape parameter, p is a shape (power) parameter,
    and NORCDF and NORPDF are the cumulative distribution function
    and the probability density function for the standard normal
    distribution respectively.
 
    If p is 1, this distribution reduces to the lognormal
    distribution.

Syntax:
    LET <y> = PLNPDF(<x>,<p>,<s>)   <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, parameter, or variable;
          <p> is a positive number, parameter, or variable
              that specifies the power parameter;
          <s> is an optional positive number, parameter, or variable
              that specifies the shape parameter;
          <y> is a variable or a parameter (depending on what <y1>
              is) where the computed power-lognormal pdf value is
              stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If the <s> parameter is omitted, it defaults to 1.

Examples:
    LET A = PLNPDF(3,2,1)
    LET X2 = PLNPDF(X1,POW,SD)
    LET X2 = PLNPDF(X1,0.5,0.5)
 
Note:
    The general power-lognormal probability density function can
    be expressed in terms of the standard power-lognormal
    probability density function as follows:
       f(x,sigma,p,loc,scale)=f((x-loc)/scale,sigma,p)/scale
                          for x > loc,  sigma, p, scale > 0
    where loc and scale are the location and scales parameters,
    respectively.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PLNCDF  = Compute the power-lognormal cumulative distribution
              function.
    PLNPPF  = Compute the power-lognormal percent point function.
    PLNHAZ  = Compute the power-lognormal hazard function.
    PLNCHAZ = Compute the power-lognormal cumulative hazard function.
    PNRPDF  = Compute the power-normal probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    HFNPDF  = Compute the half-normal probability density function.
    NORPDF  = Compute the normal probability density function.
 
Reference:
    "A Computer Program POWNOR for Fitting the Power-Normal and
    -Lognormal Models to Life or Strength Data from Specimens of
    Various Sizes", Nelson and Doganaksoy, NIST-IR 4760, March 1992.
 
Applications:
    Reliability
 
Implementation Date:
    1995/5
 
Program:
    LABEL CASE ASIS
    X1LABEL X
    Y1LABEL Probability
    TITLE CASE ASIS
    . 
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    .
    TITLE P = 0.5, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNPDF(X,0.5,0.2) FOR X = 0.01 .01 3 AND
    PLOT PLNPDF(X,0.5,0.4) FOR X = 0.01 .01 3 AND
    PLOT PLNPDF(X,0.5,0.7) FOR X = 0.01 .01 3 AND
    PLOT PLNPDF(X,0.5,1.0) FOR X = 0.01 .01 3
    TITLE P = 1.0, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNPDF(X,1.0,0.2) FOR X = 0.01 .01 3 AND
    PLOT PLNPDF(X,1.0,0.4) FOR X = 0.01 .01 3 AND
    PLOT PLNPDF(X,1.0,0.7) FOR X = 0.01 .01 3 AND
    PLOT PLNPDF(X,1.0,1.0) FOR X = 0.01 .01 3
    TITLE P = 5.0, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNPDF(X,5.0,0.2) FOR X = 0.01 .01 2 AND
    PLOT PLNPDF(X,5.0,0.4) FOR X = 0.01 .01 2 AND
    PLOT PLNPDF(X,5.0,0.7) FOR X = 0.01 .01 2 AND
    PLOT PLNPDF(X,5.0,1.0) FOR X = 0.01 .01 2
    TITLE P = 20, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNPDF(X,20,0.2) FOR X = 0.01 .01 1 AND
    PLOT PLNPDF(X,20,0.4) FOR X = 0.01 .01 1 AND
    PLOT PLNPDF(X,20,0.7) FOR X = 0.01 .01 1 AND
    PLOT PLNPDF(X,20,1.0) FOR X = 0.01 .01 1
    .
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT Power Lognormal PDF's
 
-----PLNPPF (LET)--------------------------------
 
PLNPPF
 
Name:
    PLNPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the power-lognormal percent point function.
 
Description:
    The standard lognormal distribution has the following percent
    point function:
       G(f,sigma,p) = EXP(NORPPF(1-(1-f)**(1/p))/sigma)
                  for 0 < f < 1,  sigma, p > 0
    where sigma is a shape parameter, p is a shape (power) parameter,
    and NORPPF is the percent point function of the standard normal
    distribution.  The input value is a real number between 0 and 1
    (since it corresponds to a probability).

    If p is 1, this distribution reduces to the lognormal
    distribution.

Syntax:
    LET <y> = PLNPPF(<x>,<p>,<s>)   <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the range 0 to 1;
          <p> is a positive number, parameter, or variable
              that specifies the power parameter;
          <s> is an optional positive number, parameter, or variable
              that specifies the shape parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed power-lognormal ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If the <s> parameter is omitted, it defaults to 1.

Examples:
    LET A = PLNPPF(0.9,2,1)
    LET X2 = PLNPPF(X1,P,SD)
    LET X2 = PLNPPF(X1,0.5,3)
 
Note:
    The general power-lognormal percent point function can be
    expressed in terms of the standard power-lognormal percent point
    function as follows:
       G(f,sigma,p,loc,scale) = loc + scale*G(f,sigma,p)
                            for 0 < f < 1,  sigma, p, scale > 0
    where loc and scale are the location and scales parameters,
    respectively.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PLNCDF  = Compute the power-lognormal cumulative distribution
              function.
    PLNPDF  = Compute the power-lognormal probability density
              function.
    PLNHAZ  = Compute the power-lognormal hazard function.
    PLNCHAZ = Compute the power-lognormal cumulative hazard function.
    PNRPDF  = Compute the power-normal probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    HFNPDF  = Compute the half-normal probability density function.
    NORPDF  = Compute the normal probability density function.
 
Reference:
    "A Computer Program POWNOR for Fitting the Power-Normal and
    -Lognormal Models to Life or Strength Data from Specimens of
    Various Sizes", Nelson and Doganaksoy, NIST-IR 4760, March 1992.
 
Applications:
    Reliability
 
Implementation Date:
    1995/5
 
Program:
    LABEL CASE ASIS
    Y1LABEL X
    X1LABEL Probability
    TITLE CASE ASIS
    . 
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    .
    TITLE P = 0.5, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNPPF(F,0.5,0.2) FOR F = 0.01 .01 0.99 AND
    PLOT PLNPPF(F,0.5,0.4) FOR F = 0.01 .01 0.99 AND
    PLOT PLNPPF(F,0.5,0.7) FOR F = 0.01 .01 0.99 AND
    PLOT PLNPPF(F,0.5,1.0) FOR F = 0.01 .01 0.99
    TITLE P = 1.0, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNPPF(F,1.0,0.2) FOR F = 0.01 .01 0.99 AND
    PLOT PLNPPF(F,1.0,0.4) FOR F = 0.01 .01 0.99 AND
    PLOT PLNPPF(F,1.0,0.7) FOR F = 0.01 .01 0.99 AND
    PLOT PLNPPF(F,1.0,1.0) FOR F = 0.01 .01 0.99
    TITLE P = 5.0, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNPPF(F,5.0,0.2) FOR F = 0.01 .01 0.99 AND
    PLOT PLNPPF(F,5.0,0.4) FOR F = 0.01 .01 0.99 AND
    PLOT PLNPPF(F,5.0,0.7) FOR F = 0.01 .01 0.99 AND
    PLOT PLNPPF(F,5.0,1.0) FOR F = 0.01 .01 0.99
    TITLE P = 20, SIGMA = 0.2, 0.4, 0.7, 1.0
    PLOT PLNPPF(F,20,0.2) FOR F = 0.01 .01 0.99 AND
    PLOT PLNPPF(F,20,0.4) FOR F = 0.01 .01 0.99 AND
    PLOT PLNPPF(F,20,0.7) FOR F = 0.01 .01 0.99 AND
    PLOT PLNPPF(F,20,1.0) FOR F = 0.01 .01 0.99
    .
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT Power Lognormal PPF's
 
-----PLOT-------------------------------------------------------
 
PLOT
 
Name:
    PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a plot.
 
Description:
    The PLOT command allows the analyst to generate single or
    multi-trace plots of data, functions, or both.  It is DATAPLOT's
    most powerful, most important, and most heavily used graphics
    command.  There are 7 general plot syntaxes:
          1) 1-variable form
          2) 2-variable form
          3) 3-variable multi-trace form
          4) VERSUS form
          5) multi-VERSUS form
          6) function form
          7) AND form
 
    DATAPLOT uses the concept of traces.  A trace is a connected set of
    points.  Points in the same trace are plotted with the same
    attributes.  In most cases, a single variable is one trace.
    However, a single variable can be split into multiple traces if
    desired (see SYNTAX 3).
 
Syntax 1: (1-variable form)
    PLOT   <y>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is a variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This form for the PLOT command is used for plotting <y> versus its
    dummy index.  The resulting plot will have <y> on the vertical
    axis and the dummy index 1, 2, 3, ..., n (where n = the number of
    elements in <y>) on the horizontal axis.
 
Syntax 2: (2-variable form)
    PLOT   <y>   <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is an independent (i.e., the vertical axis) variable;
          <x> is an independent (i.e., the horizontal axis) variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This is the 2-argument form for the PLOT command.  It is used for
    plotting <y> versus <x>.  The resulting plot will have <y> on the
    vertical axis and <x> on the horizontal axis.
 
Syntax 3: (the 3-variable multi-trace form)
    PLOT   <y>   <x>   <tag>  <SUBSET/EXPECT/FOR qualification>
    where <y> is an independent (i.e., the vertical axis) variable;
          <x> is an independent (i.e., the horizontal axis) variable;
          <tag> is a variable that identifies groups in <y> and <x>
              that are plotted with common attributes;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This is the 3-argument form for the PLOT command.  It is used for
    multi-trace plotting of <y> versus <x>.  The resulting plot will
    have <y> on the vertical axis, <x> on the horizontal axis, and will
    have one trace for each distinct value in the <tag> variable.
 
    If the <x> variable and the <tag> variable are identical, all
    points with a common <x> value are treated as a common trace (i.e.,
    they are plotted with common attributes).
 
    Although DATAPLOT supports a large number of built-in plot formats,
    there will be cases where you may want a specialized chart format
    that is not available.  This syntax for the PLOT command can often
    be used for this purpose by defining the <tag> variable in the
    right way.  Points with a common <tag> value are treated as a
    trace, and attributes can be set for each individual trace.
 
Syntax 4: (VERSUS form)
    PLOT   <y1>   <y2>   <y3>  ... <yk>   VERSUS   <x>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1>, <y2>, <y3>, ..., <yk> are dependent (i.e., vertical
              axis) variables;
          <x> is an independent (i.e., the horizontal axis) variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This is the single-VERSUS argument form for the PLOT command.   It
    is used for multi-trace plotting where the dependent variables are
    plotted against a common <x> variable.  The resulting plot will
    have one trace for each <yi> variable:
       <y1> (vertically) versus <x> (horizontally)
       <y2> (vertically) versus <x> (horizontally)
       <y3> (vertically) versus <x> (horizontally)
       ...
       <yk> (vertically) versus <x> (horizontally)
 
    VS and VS. can also be used for VERSUS.
 
Syntax: 5 (multi-VERSUS form)
    PLOT   <syntax 4>   <syntax 4>   ...   <syntax 4>
 
    This is the multi-VERSUS argument form for the PLOT command.  It
    is used for multi-trace plotting where the dependent variables are
    plotted against different <x> variables.
 
Syntax: 6 (function form)
    PLOT  <f>  FOR  <x>  =  <start>  <increment>  <stop>
    where <f> is a function (either pre-defined via the LET
              FUNCTION command, or explicitly defined herein);
          <x> is the dummy variable in the function;
          <start> is the desired minimum value for <x> at which the
              function is to be evaluated;
          <increment> is the desired increment value for <x> at which
              the function is to be evaluated;
    and   <stop> is the desired maximum value for <x> at which the
              function is to be evaluated.
 
    This is the function form for the PLOT command.   It is used for
    plotting a function of one variable.
 
Syntax: 7 (AND form)
    <any valid syntax 1 to 6>  AND
    <any valid syntax 1 to 6>  AND
    <any valid syntax 1 to 6>  AND
    ...
    <any valid syntax 1 to 6>  AND
    <any valid syntax 1 to 6>
 
    This is the most general syntax for PLOT.  It is used for
    generating multi-trace plots of variables, of functions, or of
    mixtures of both.
 
Examples:
    PLOT Y
    PLOT TEMP  SUBSET TAG > 4
 
    PLOT Y X
    PLOT RES X  SUBSET X > -9999
 
    PLOT Y X LAB
    PLOT PRES TEMP DAY
    PLOT PRES TEMP DAY  DAY <> 4
 
    PLOT Y1 Y2 Y3 VERSUS X
    PLOT Y PRED VERSUS X
    PLOT Y PRED VERSUS X  SUBSET X = 10.6 TO 19.7
 
    PLOT Y1 Y2 Y3 VERSUS X1 Y4 Y5 VERSUS X2
    PLOT P1 VERSUS T1 P2 VERSUS T2 P3 VERUS T3
 
    PLOT SIN(X)*EXP(-X) FOR X = 0 .1 5
 
    LET FUNCTION F = EXP(-X*SIN(X**2))
    PLOT F FOR X = 0 .1 3
 
    PLOT Y X AND
    PLOT A+B*X FOR X = 1 1 10
 
    PLOT Y1 Y2 VS X AND
    PLOT Y X AND
    PLOT A*SIN(B*X) FOR X = 1 .1 3 AND
    PLOT Y3 X3 LAB
 
Note:
    Plot points can be plotted as characters, connected lines, spikes,
    or bars.  These are set independently of each other.  The default
    is to plot each trace as a connected line with no symbol, no bar,
    and no spike.  The LINE, CHARACTER, SPIKE, and BAR commands are
    used to set the switches for plotting a given trace as a connected
    line, a character, a spike, or a bar respectively.
 
    There are attribute setting commands for lines, characters, spikes,
    and bars.  See the documentation for LINE, CHARACTER, SPIKE, and
    BAR for a complete list of these commands.  Attributes are set
    giving a list of values.  The first trace uses the first setting,
    the second trace uses the second setting, and so on.  For example,
    CHARACTER SIZE 2.0 3.0 1.5 sets the character size for trace 1 to
    2.0, the character size for trace 2 to 3.0, and the character size
    for trace 3 to 1.5.  Attributes can be set for up to 100 traces.
 
    As a more complex example, suppose you want to plot a variable Y
    as a connected line and every fifth point as a filled circle.  You
    can do something like the following:
        LET N = SIZE Y
        LET X = SEQUENCE 1 1 N
        LET TAG = PATTERN 1 2 2 2 2 FOR I = 1 1 N
        CHARACTER CIRCLE BLANK
        CHARACTER FILL ON OFF
        CHARACTER SIZE 1.5
        PLOT Y X TAG
 
Note:
    DATAPLOT provides a large range of plot control features for the
    plot.  This includes titles, axis labels, legends, and so on.
    DATAPLOT sets these with separate commands (as opposed to
    arguments on the PLOT command itself).  Each of these features
    typically has its own attribute setting commands as well.  DATAPLOT
    simply uses whatever the current setting is for each of these
    attributes when it generates a plot.  For example, a TITLE command
    is entered to define the plot title (nothing is actually generated
    until the next PLOT is performed).  This title remains in effect
    for all subsequent plots until it is changed (another TITLE
    command) or deleted (TITLE with no arguments).
 
    Most of the commonly used plot features are listed below.  The
    attribute setting commands are not listed (e.g., TITLE is listed,
    but TITLE COLOR and TITLE SIZE are not).  See the documentation
    for the plot feature for its attribute setting commands.
 
Note:
    Dataplot allows subregions to be added to plots.  Enter
    HELP SUBREGION for details.

    This capability was implemented 2000/1.

Note:
    DATAPLOT saves the following internal parameters after a plot:

    PLOTCORR - correlation of the X and Y coordinates on the plot
    PLOTCOR1 - correlation of the X and Y coordinates on the plot
               with a tag value of 1.  This can be useful for
               plots that generate reference lines (which you
               do not want included in the correlation computation
    PLOTYMAX - maximum Y coordinate
    YMAXINDE - index of the maximum Y coordinate
    PLOTYMIN - minimum Y coordinate
    YMININDE - index of the minimum Y coordinate
    PLOTXMAX - maximum X coordinate
    XMAXINDE - index of the maximum X coordinate
    PLOTXMIN - minimum X coordinate
    XMININDE - index of the minimum X coordinate
    NACCEPT  - number of plot points inside the first subregion
               (0 if no subregions defined)
    NREJECT  - number of plot points outside the first subregion
               (0 if no subregions defined)
    NTOTAL   - number of plot points (NACCEPT + NREJECT)
               (0 if no subregions defined)

    These internal parameters are actually computed for all plot
    types, not just the PLOT command.

    This capability was implemented 2000/1.

Default:
    None
 
Synonyms:
    VS and VS. are synonyms for VERSUS.
 
Related Commands:
    CHARACTERS          = Sets the types for plot characters.
    LINES               = Sets the types for plot lines.
    SPIKES              = Sets the on/off switches for plot spikes.
    BARS                = Sets the on/off switches for plot bars.
    TITLE               = Sets the plot title.
    LABEL               = Sets the plot axis labels.
    LEGEND              = Sets the plot legends.
    BOX COORDINATES     = Sets the locations for plot boxes.
    ARROW COORDINATES   = Sets the locations for plot arrows.
    SEGMENT COORDINATES = Sets the locations for plot segments.
    FRAME               = Sets the on/off switch for the plot frame.
    FRAME COORDINATES   = Sets the location for the plot frame.
    GRID                = Sets the on/off switch for the plot grid.
    LOG                 = Sets the on/off switch for log scale.
    TIC                 = Sets the on/off switch for the plot tics.
    TIC LABEL           = Sets the on/off switch for the plot tic
                          labels.
    MARGIN COLOR        = Sets the color for the plot margin.
    BACKGROUND COLOR    = Sets the color for the plot background.
    PRE-ERASE           = Sets the automatic pre-erase switch for
                          plots.
    SEQUENCE            = Sets the automatic sequence switch for plots.
    MULTIPLOT           = Generate multiple plots per page.
 
Applications:
    Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    LET LEAD = DATA 164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    LET POT = DATA 106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    .
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE SCATTER PLOT; X1LABEL LEAD; Y1LABEL POTASSIUM
    LINE BLANK ALL; CHARACTER CIRCLE; CHARACTER FILL ON
    PLOT POT LEAD
    .
    CHARACTER CIRCLE SQUARE; CHARACTER FILL OFF ALL
    TITLE SCATTER PLOT WITH GROUPS
    LEGEND 1 CIRC() - GROUP 1; LEGEND 2 SQUA() - GROUP 2
    LEGEND FILL ON; LEGEND FONT DUPLEX
    PLOT POT LEAD ID2
    .
    CHARACTER CIRCLE CIRCLE SQUARE SQUARE; CHARACTER FILL OFF ON OFF ON
    LET X = SEQUENCE 1 1 17
    LEGEND 1 CIRC() - POTASSIUM; LEGEND 2 SQUA() - LEAD
    X1LABEL SEQUENCE; Y1LABEL; TITLE CHARACTER FILL REPRESENTS GROUP ID
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
    .
    CHARACTER BLANK ALL; LINE SOLID DASH
    SEGMENT 1 COORDINATES 16 85 19 85
    SEGMENT 2 COORDINATES 16 81 19 81
    SEGMENT 2 PATTERN DASH
    TITLE MULTIPLE TRACES AS LINES
    PLOT POT LEAD VS X
    END OF MULTIPLOT
 
-----PNRCDF (LET)--------------------------------
 
PNRCDF
 
Name:
    PNRCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard power-normal cumulative distribution
    function.
 
Description:
    The standard power-normal distribution has the following
    probability density function:
       f(x,p)=p*NORPDF(x)*NORCDF(-x)**(p-1)    for x > 0,  p > 0
    where p is the shape (power) parameter, and NORCDF and NORPDF are
    the cumulative distribution function and the probability density
    function for the standard normal distribution respectively.

    The cumulative distribution is the area under the curve from
    negative infinity to x (i.e., the integral of the above function).
    It has the formula:
       F(x,p) = 1 - (NORCDF(-x))**p       for x > 0, p > 0
 
    If p is 1, this distribution reduces to the normal distribution.

Syntax:
    LET <y2> = PNRCDF(<y1>,<p>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a non-negative number, parameter, or variable;
          <p> is a positive number, parameter, or variable
               that specifies the power parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed power-normal cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET A = PNRCDF(3,2)
    LET X2 = PNRCDF(X1,POW)
    LET X2 = PNRCDF(X1,0.5)
 
Note:
    The general power-normal distribution has the following
    probability density function:
       f(x,u,s,p)=(p/s)*NORPDF((x-u)/s)*NORCDF(-(x-u)/s)**(p-1)
                                     for x > 0,  s > 0, p > 0
    where u is the location parameter, s is the scale parameter, and p
    is the power parameter.  The cumulative distribution function has
    the formula:
       F(x,u,s,p) = 1 - (NORCDF(-(x-u)/s))**p   for x > 0, s > 0, p > 0

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PNRPDF = Compute the power-normal probability density function.
    PNRPPF = Compute the power-normal percent point function.
    PLNCDF = Compute the power-lognormal cumulative distribution
             function.
    PLNPDF = Compute the power-lognormal probability density function.
    PLNPPF = Compute the power-lognormal percent point function.
    LGNCDF = Compute the lognormal cumulative distribution function.
    LGNPDF = Compute the lognormal probability density function.
    LGNPPF = Compute the lognormal percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
 
Reference:
    "A Computer Program POWNOR for Fitting the Power-Normal and
    -Lognormal Models to Life or Strength Data from Specimens of
    Various Sizes", Nelson and Doganaksoy, NIST-IR 4760, March 1992.
 
Applications:
    Reliability
 
Implementation Date:
    1995/5
 
Program:
    LABEL CASE ASIS
    X1LABEL X
    YLIMITS 0  1
    Y1LABEL Probability
    MAJOR YTIC MARK NUMBER 6 
    TITLE CASE ASIS
    TITLE Power Normal PDF Plot CR() ...
     SD=1, P=10000, 3000, 1000, 300, 100, 50, 20, 5, 1, 0.5, 0.2 0.1 
    . 
    PLOT PNRCDF(X,10000) FOR X = -5 .05 5 AND 
    PLOT PNRCDF(X,3000) FOR X = -5 .05 5 AND 
    PLOT PNRCDF(X,1000) FOR X = -5 .05 5 AND 
    PLOT PNRCDF(X,300) FOR X = -5 .05 5 AND 
    PLOT PNRCDF(X,100) FOR X = -5 .05 5 AND 
    PLOT PNRCDF(X,50) FOR X = -5 .05 5 AND 
    PLOT PNRCDF(X,20) FOR X = -5 .05 5 AND 
    PLOT PNRCDF(X,5) FOR X = -5 .05 5 AND 
    PLOT PNRCDF(X,1) FOR X = -5 .05 5 AND 
    PLOT PNRCDF(X,0.5) FOR X = -5 .05 5 AND 
    PLOT PNRCDF(X,0.2) FOR X = -5 .05 5 AND 
    PLOT PNRCDF(X,0.1) FOR X = -5 .05 5 
 
-----PNRCHAZ (LET)--------------------------------
 
PNRCHAZ
 
Name:
    PNRCHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard power-normal cumulative hazard function.
 
Description:
    The standard power-normal distribution has the following
    cumulative hazard function:
       H(x,p)=-LOG[(NORCDF(-x))**p]       for x, p > 0
    where p is the shape (power) parameter and NORCDF is the
    cumulative distribution function for the standard normal
    distribution.

    If p is 1, this distribution reduces to the normal distribution.

Syntax:
    LET <y> = PNRCHAZ(<x>,<p>)    <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, parameter, or variable;
          <p> is a positive number, parameter, or variable
               that specifies the power parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed power-normal cumulative hazard
               value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET A = PNRCHAZ(3,2)
    LET X2 = PNRCHAZ(X1,POW)
    LET X2 = PNRCHAZ(X1,0.5)
 
Note:
    The general form of the power-normal cumulative hazard function is:
       H(x,p,mu,sigma)=-LOG[(NORCDF(-(x-mu)/sigma))**p]
                        for x, p, sigma > 0
    where mu and sigma are the location and scale parameters,
    respectively.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PNRCDF  = Compute the power-normal cumulative distribution
              function.
    PNRPDF  = Compute the power-normal probability density function.
    PNRPPF  = Compute the power-normal percent point function.
    PNRHAZ  = Compute the power-normal hazard function.
    PLNPDF  = Compute the power-lognormal probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    NORPDF  = Compute the normal probability density function.
 
Reference:
    "A Computer Program POWNOR for Fitting the Power-Normal and
    -Lognormal Models to Life or Strength Data from Specimens of
    Various Sizes", Nelson and Doganaksoy, NIST-IR 4760, March 1992.
 
Applications:
    Reliability
 
Implementation Date:
    1998/4
 
Program:
    LABEL CASE ASIS
    X1LABEL X
    Y1LABEL Cumulative Hazard
    YLIMITS 0 1 
    MAJOR YTIC MARK NUMBER 6 
    TITLE CASE ASIS
    TITLE Power Normal Cumulative Hazard Plot CR() ...
     SD=1, P=10000, 3000, 1000, 300, 100, 50, 20, 5, 1, 0.5, 0.2 0.1 
    . 
    PLOT PNRCHAZ(X,10000) FOR X = -5 .05 5 AND 
    PLOT PNRCHAZ(X,3000) FOR X = -5 .05 5 AND 
    PLOT PNRCHAZ(X,1000) FOR X = -5 .05 5 AND 
    PLOT PNRCHAZ(X,300) FOR X = -5 .05 5 AND 
    PLOT PNRCHAZ(X,100) FOR X = -5 .05 5 AND 
    PLOT PNRCHAZ(X,50) FOR X = -5 .05 5 AND 
    PLOT PNRCHAZ(X,20) FOR X = -5 .05 5 AND 
    PLOT PNRCHAZ(X,5) FOR X = -5 .05 5 AND 
    PLOT PNRCHAZ(X,1) FOR X = -5 .05 5 AND 
    PLOT PNRCHAZ(X,0.5) FOR X = -5 .05 5 AND 
    PLOT PNRCHAZ(X,0.2) FOR X = -5 .05 5 AND 
    PLOT PNRCHAZ(X,0.1) FOR X = -5 .05 5 
 
-----PNRHAZ (LET)--------------------------------
 
PNRHAZ
 
Name:
    PNRHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard power-normal hazard function.
 
Description:
    The standard power-normal distribution has the following
    hazard function:
       h(x,p)=p*NORPDF(x)/NORCDF(-x)       for x > 0,   p > 0
    where p is the power parameter, and NORCDF and NORPDF are the
    cumulative distribution function and the probability density
    function for the standard normal distribution respectively.

    If p is 1, this distribution reduces to the normal distribution.

Syntax:
    LET <y> = PNRHAZ(<x>,<p>)    <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, parameter, or variable;
          <p> is a positive number, parameter, or variable
               that specifies the power parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed power-normal hazard value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET A = PNRHAZ(3,2)
    LET X2 = PNRHAZ(X1,POW)
    LET X2 = PNRHAZ(X1,0.5)
 
Note:
    The general form of the power-normal hazard function is:
        h(x,p,mu,sigma)=p*NORPDF((x-mu)/sigma)/
                 [sigma*NORCDF(-(x-mu)/sigma)   for x, p, sigma > 0
    where mu and sigma are the location and scale parameters,
    respectively.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PNRCDF  = Compute the power-normal cumulative distribution
              function.
    PNRPDF  = Compute the power-normal probability density function.
    PNRPPF  = Compute the power-normal percent point function.
    PNRCHAZ = Compute the power-normal cumulative hazard function.
    PLNPDF  = Compute the power-lognormal probability density function.
    LGNPDF  = Compute the lognormal probability density function.
    NORPDF  = Compute the normal probability density function.
 
Reference:
    "A Computer Program POWNOR for Fitting the Power-Normal and
    -Lognormal Models to Life or Strength Data from Specimens of
    Various Sizes", Nelson and Doganaksoy, NIST-IR 4760, March 1992.
 
Applications:
    Reliability
 
Implementation Date:
    1998/4
 
Program:
    LABEL CASE ASIS
    X1LABEL X
    Y1LABEL Hazard
    YLIMITS 0 1 
    MAJOR YTIC MARK NUMBER 6 
    TITLE CASE ASIS
    TITLE Power Normal Hazard Plot CR() ...
     SD=1, P=10000, 3000, 1000, 300, 100, 50, 20, 5, 1, 0.5, 0.2 0.1 
    . 
    PLOT PNRHAZ(X,10000) FOR X = -5 .05 5 AND 
    PLOT PNRHAZ(X,3000) FOR X = -5 .05 5 AND 
    PLOT PNRHAZ(X,1000) FOR X = -5 .05 5 AND 
    PLOT PNRHAZ(X,300) FOR X = -5 .05 5 AND 
    PLOT PNRHAZ(X,100) FOR X = -5 .05 5 AND 
    PLOT PNRHAZ(X,50) FOR X = -5 .05 5 AND 
    PLOT PNRHAZ(X,20) FOR X = -5 .05 5 AND 
    PLOT PNRHAZ(X,5) FOR X = -5 .05 5 AND 
    PLOT PNRHAZ(X,1) FOR X = -5 .05 5 AND 
    PLOT PNRHAZ(X,0.5) FOR X = -5 .05 5 AND 
    PLOT PNRHAZ(X,0.2) FOR X = -5 .05 5 AND 
    PLOT PNRHAZ(X,0.1) FOR X = -5 .05 5 
 
-----PNRPDF (LET)--------------------------------
 
PNRPDF
 
Name:
    PNRPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the standard power-normal probability density function.
 
Description:
    The standard power-normal distribution has the following
    probability density function:
       f(x,p)=p*NORPDF(x)*NORCDF(-x)**(p-1) for x > 0,  p > 0
    where p is the power parameter, and NORCDF and NORPDF are the
    cumulative distribution function and the probability density
    function for the standard normal distribution respectively.

    If p is 1, this distribution reduces to the normal distribution.

Syntax:
    LET <y2> = PNRPDF(<y1>,<p>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a non-negative number, parameter, or variable;
          <p> is a positive number, parameter, or variable
               that specifies the power parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed power-normal pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET A = PNRPDF(3,2)
    LET X2 = PNRPDF(X1,POW)
    LET X2 = PNRPDF(X1,0.5)
 
Note:
    The general power-normal distribution has the following
    probability density function:
       f(x,u,s,p)=(p/s)*NORPDF((x-u)/s)*NORCDF(-(x-u)/s)**(p-1)
                                     for x > 0,  s > 0, p > 0
    where u is the location parameter, s is the shape parameter, and p
    is the power parameter.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PNRCDF = Compute the power-normal cumulative distribution
             function.
    PNRPPF = Compute the power-normal percent point function.
    PLNCDF = Compute the power-lognormal cumulative distribution
             function.
    PLNPDF = Compute the power-lognormal probability density function.
    PLNPPF = Compute the power-lognormal percent point function.
    LGNCDF = Compute the lognormal cumulative distribution function.
    LGNPDF = Compute the lognormal probability density function.
    LGNPPF = Compute the lognormal percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
 
Reference:
    "A Computer Program POWNOR for Fitting the Power-Normal and
    -Lognormal Models to Life or Strength Data from Specimens of
    Various Sizes", Nelson and Doganaksoy, NIST-IR 4760, March 1992.
 
Applications:
    Reliability
 
Implementation Date:
    1995/5
 
Program:
    LABEL CASE ASIS
    X1LABEL X
    YLIMITS 0 1.5
    Y1LABEL Probability
    MAJOR YTIC MARK NUMBER 6 
    TITLE CASE ASIS
    TITLE Power Normal PDF Plot CR() ...
     SD=1, P=10000, 3000, 1000, 300, 100, 50, 20, 5, 1, 0.5, 0.2 0.1 
    . 
    PLOT PNRPDF(X,10000) FOR X = -5 .05 5 AND 
    PLOT PNRPDF(X,3000) FOR X = -5 .05 5 AND 
    PLOT PNRPDF(X,1000) FOR X = -5 .05 5 AND 
    PLOT PNRPDF(X,300) FOR X = -5 .05 5 AND 
    PLOT PNRPDF(X,100) FOR X = -5 .05 5 AND 
    PLOT PNRPDF(X,50) FOR X = -5 .05 5 AND 
    PLOT PNRPDF(X,20) FOR X = -5 .05 5 AND 
    PLOT PNRPDF(X,5) FOR X = -5 .05 5 AND 
    PLOT PNRPDF(X,1) FOR X = -5 .05 5 AND 
    PLOT PNRPDF(X,0.5) FOR X = -5 .05 5 AND 
    PLOT PNRPDF(X,0.2) FOR X = -5 .05 5 AND 
    PLOT PNRPDF(X,0.1) FOR X = -5 .05 5 
 
-----PNRPPF (LET)--------------------------------
 
PNRPPF
 
Name:
    PNRPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the power-normal percent point function.
 
Description:
    The standard power-normal distribution has the following
    percent point function:
       G(f,p) = NORPPF(1-(1-f)**(1/p))    0 < f < 1; p > 0
    where p is the shape (power) parameter and NORPPF is the percent
    point function of the standard normal distribution.  The input
    value is a real number between 0 and 1 (since it corresponds to a
    probability).
 
    If p is 1, this distribution reduces to the normal distribution.

Syntax:
    LET <y2> = PNRPPF(<y1>,<p>)    <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a number, parameter, or variable in the range 0 to 1;
          <p> is a positive number, parameter, or variable
               that specifies the power parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed power-normal ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET A = PNRPPF(0.9,2)
    LET X2 = PNRPPF(X1,P)
    LET X2 = PNRPPF(X1,0.5)
 
Note:
    The general power-normal distribution has the following
    percent point function:
       G(f,p,mu,sigma) = mu + sigma*NORPPF(1-(1-f)**(1/p))
                         for 0 < f < 1; p, sigma > 0
    where mu and sigma are the location and scale parameters,
    respectively.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PNRCDF  = Compute the power-normal cumulative density function.
    PNRPDF  = Compute the power-normal probability density function.
    PNRHAZ  = Compute the power-normal hazard function.
    PNRCHAZ = Compute the power-normal cumulative hazard function.
    PLNPDF  = Compute the power-lognormal probability density
              function.
    LGNPDF  = Compute the lognormal probability density function.
    HFNPDF  = Compute the half-normal probability density function.
    NORPDF  = Compute the normal probability density function.
 
Reference:
    "A Computer Program POWNOR for Fitting the Power-Normal and
    -Lognormal Models to Life or Strength Data from Specimens of
    Various Sizes", Nelson and Doganaksoy, NIST-IR 4760, March 1992.
 
Applications:
    Reliability
 
Implementation Date:
    1995/5
 
Program:
    LABEL CASE ASIS
    X1LABEL Probabiulity
    Y1LABEL X
    YLIMITS -5 10
    TITLE CASE ASIS
    TITLE Power Normal PPF Plot CR() ...
     SD=1, P=10000, 3000, 1000, 300, 100, 50, 20, 5, 1, 0.5, 0.2 0.1 
    . 
    PLOT PNRPPF(F,10000) FOR F = 0.01 0.01 0.99 AND 
    PLOT PNRPPF(F,3000) FOR F = 0.01 0.01 0.99 AND 
    PLOT PNRPPF(F,1000) FOR F = 0.01 0.01 0.99 AND 
    PLOT PNRPPF(F,300) FOR F = 0.01 0.01 0.99 AND 
    PLOT PNRPPF(F,100) FOR F = 0.01 0.01 0.99 AND 
    PLOT PNRPPF(F,50) FOR F = 0.01 0.01 0.99 AND 
    PLOT PNRPPF(F,20) FOR F = 0.01 0.01 0.99 AND 
    PLOT PNRPPF(F,5) FOR F = 0.01 0.01 0.99 AND 
    PLOT PNRPPF(F,1) FOR F = 0.01 0.01 0.99 AND 
    PLOT PNRPPF(F,0.5) FOR F = 0.01 0.01 0.99 AND 
    PLOT PNRPPF(F,0.2) FOR F = 0.01 0.01 0.99 AND 
    PLOT PNRPPF(F,0.1) FOR F = 0.01 0.01 0.99 
 
-----POCH (LET)--------------------------------
 
POCH
 
Name:
    POCH (LET)
 
Type:
    Library Function
 
Purpose:
    Compute a generalization of Pochhammer's symbol.
 
Description:
    Pochhammer's generalized symbol is defined to be:
        POCH(X,A) = GAMMA(A+X)/GAMMA(A)
    where GAMMA is the gamma function.  See the documentation for the
    GAMMA command for a description of the gamma function.
 
Syntax:
    LET <y> = POCH(<x>,<a>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter or variable;
          <a> is a number, parameter, or variable; 
          <y> is a variable or a parameter (depending on what <x> 
               and <a> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET P = POCH(2.3,1)
    LET A = POCH(X,A1)
    LET X2 = POCH(X1,4.2)
 
Note:
    DATAPLOT uses the routine DPOCH from the SLATEC Common Mathematical
    Library to compute this function.  SLATEC is a large set of high
    quality, portable, public domain Fortran routines for various
    mathematical capabilities maintained by seven federal laboratories.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POCH1      = Compute a generalization of Pochhammer's symbol
                 starting from the first order.
    GAMMA      = Compute the gamma function.
    LOGGAMMA   = Compute the log (to base e) gamma function.
    GAMMAIP    = Compute an alternate form of the incomplete gamma
                 function.
    GAMMAIC    = Compute the complementary incomplete Gamma function.
    GAMMAR     = Compute the reciprocal gamma function.
    TRICOMI    = Compute Tricomi's incomplete gamma function.
    DIGAMMA    = Compute the digamma function.
 
Reference:
    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 6).
 
Applications:
    Special Functions
 
Implementation Date:
    94/9
 
Program:
    TITLE AUTOMATIC
    PLOT POCH(X,2.5) FOR X = 1 0.1 10
 
-----POCH1 (LET)--------------------------------
 
POCH1
 
Name:
    POCH1 (LET)
 
Type:
    Library Function
 
Purpose:
    Compute a generalization of Pochhammer's symbol starting from the
    first order.
 
Description:
    Pochhammer's generalized symbol starting from the first order is
    defined to be:
        POCH1(X,A) = [GAMMA(A+X)/(GAMMA(A)-1)]/X
    where GAMMA is the gamma function.  See the documentation for the
    GAMMA command for a description of the gamma function.
 
Syntax:
    LET <y> = POCH1(<x>,<a>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter or variable;
          <a> is a number, parameter, or variable; 
          <y> is a variable or a parameter (depending on what <x> 
               and <a> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET P = POCH1(2.3,1)
    LET A = POCH1(X,A1)
    LET X2 = POCH1(X1,4.2)
 
Note:
    DATAPLOT uses the routine DPOCH1 from the SLATEC Common
    Mathematical Library to compute this function.  SLATEC is a large
    set of high quality, portable, public domain Fortran routines for
    various mathematical capabilities maintained by seven federal
    laboratories.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POCH       = Compute a generalization of Pochhammer's symbol.
    GAMMA      = Compute the gamma function.
    LOGGAMMA   = Compute the log (to base e) gamma function.
    GAMMAIP    = Compute an alternate form of the incomplete gamma
                 function.
    GAMMAIC    = Compute the complementary incomplete Gamma function.
    GAMMAR     = Compute the reciprocal gamma function.
    TRICOMI    = Compute Tricomi's incomplete gamma function.
    DIGAMMA    = Compute the digamma function.
 
Reference:
    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 6).
 
    "The Special Functions and their Approximations, Volume 1", Luke,
    Academic Press, 34, (1969).

Applications:
    Special Functions
 
Implementation Date:
    94/9
 
Program:
    TITLE AUTOMATIC
    PLOT POCH1(X,2.5) FOR X = 1 0.1 10
 
-----POICDF (LET)--------------------------------
 
POICDF
 
Name:
    POICDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Poisson cumulative distribution function.
 
Description:
    The Poisson distribution is the distribution of the number of
    events in the interval (0,lambda) when the waiting time between
    events is exponentially distributed with mean 1 and standard
    deviation 1 (there are alternate interpretations as well).  The
    Poisson distribution has the following probability density
    function:
       p(x,lambda) = exp(-lambda)*lambda**x/lambda!
    where x is a non-negative integer.  The cumulative distribution is
    the probability of obtaining x or fewer events.  It is the sum of
    the Poisson probabilities of 0 to x.  The cumulative distribution
    is computed via a chi-square approximation.
 
Syntax:
    LET <y2> = POICDF(<y1>,<lambda>) <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a non-negative integer variable, number, or
               parameter (a warning message is printed if it is not);
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed Poisson cdf value is stored;
          <lambda> is a number or parameter that specifies the shape
               parameter of the Poisson distribution;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = POICDF(3,0.5)
    LET X2 = POICDF(X1,0.3)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POIPDF = Compute the Poisson probability density function.
    POIPPF = Compute the Poisson percent point function.
    BINCDF = Compute the binomial cumulative distribution function.
    BINPDF = Compute the binomial probability density function.
    BINPPF = Compute the binomial percent point function.
    NBCDF  = Compute the negative binomial cumulative distribution
             function.
    NBPDF  = Compute the negative binomial probability density
             function.
    NBPPF  = Compute the negative binomial percent point function.
    GEOCDF = Compute the geometric cumulative distribution function.
    GEOPDF = Compute the geometric probability density function.
    GEOPPF = Compute the geometric percent point function.
 
Reference:
    "Discrete Univariate Distributions", Johnson and Kotz, Houghton
    Mifflin, 1970 (chapter 4).
 
Applications:
    XX
 
Implementation Date:
    94/4
 
Program:
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    YLIMITS 0 1
    MAJOR YTIC NUMBER 6
    MINOR YTIC NUMBER 1
    YTIC DECIMAL 1
    XLIMITS 0 50
    XTIC OFFSET 0.5 0.5
    LINE BLANK
    SPIKE ON
    SPIKE LINE DASH
    CHARACTER CIRCLE
    CHARACTER FILL ON
    CHARACTER SIZE 1.2
    TITLE AUTOMATIC
    X1LABEL NUMBER OF SUCCESSES
    Y1LABEL PROBABILITY
    TITLE AUTOMATIC; TITLE SIZE 3
    PLOT POICDF(X,5) FOR X = 0 1 50
    PLOT POICDF(X,15) FOR X = 0 1 50
    PLOT POICDF(X,25) FOR X = 0 1 50
    PLOT POICDF(X,35) FOR X = 0 1 50
    END OF MULTIPLOT
 
-----POINTS IN POLYGON--------------------------------------------------
 
POINTS IN POLYGON
 
Name:
    POINTS IN POLYGON
 
Type:
    LET Subcommand
 
Purpose:
    Given a polygon and a set of points, determine if each of these
    points are interior points, exterior points, edge points, or
    equal to a vertex.
 
Description:
    A basic problem in computational geometry is to determine if a
    point is inside or outside of a polygon.  In a Dataplot context,
    the most common application for this basic problem is to determine
    whether a point should be plotted or not plotted.

    Given a set of one or more points, this command returns a tag
    value (where each row of the tag variable corresponds to the
    row of the variables containing the x and y coordinates of the
    points being tested).  Each value of the tag variable will contain
    either a 1, 2, 3, or 4 where

           1 = interior point
           2 = exterior point
           3 = edge point
           4 = vertex point

Syntax:
    LET <tag> = POINTS IN POLYGON  <xval>  <yval>  <xpoly> <ypoly>
                <SUBSET/EXPCEPT/FOR qualification>
    where <xval> is a variable containing the x-coordinates of
               the data points being checked;
          <yval> is a variable containing the y-coordinates of
               the data points being checked;
          <xpoly> is a variable that will contain the x-coordinats
               of the polygon;
          <ypoly> is a variable that will contain the y-coordinats
               of the polygon;
          <tag> is a variable (of the same size as <xval> and <yval>)
               that specifies whether each point is an interior,
               exterior, edge, or vertex point;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET TAG = POINTS IN POLYGON XVAL YVAL XPOLY YPOLY
 
Note:
    Dataplot uses a Fortran translation of the C routine "InPoly1"
    algorithm given on page 244 of O'Rourke (see Reference section
    below).

    This algorithm is based on counting the number of ray tracings.
    A complete description of the algorithm is given on pages
    239-245 of O'Rourke's book.

    This algorithm works for both convex and non-convex polygons.

Note:
    The points in the polygon are assumed to be sorted (i.e.,
    contiguous rows define an edge).  No check is made that these
    points in fact define a valid polygon.

    The <xval> and <yval> points do not need to be in any specific
    order since they are tested independently of each other.

Note:
    In deterining if a point is equal to a vertex point, Dataplot
    checks that the x-coordinate and the y-coordinate are within
    epsilon of each vertex where epsilon is set equal to 0.0000001.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CONVEX HULL             = Compute the convex hull of a set of
                              points.
    MINIMAL SPANNING TREE   = Determine the minimal spanning tree.
    SPAINNING FOREST        = Determine the spanning forest.
 
References:
    O'Rourke (1998), "Computational Geometry in C", Second Edition,
    Cambridge Unversity Press, Chapter 7.

Applications:
    Computational Geometry
 
Implementation Date:
    2011/9
 
Program:
    . Name:     poly.dp
    . Purpose:  Demonstrate "points in polygon" routine
    . Source:   Data from O'Rourke (1998), "Computational Geometry in
    .           C", Second Edition.
    .
    . Step 1: Read data
    .
    read xpoly ypoly
    0 0
    2 0
    2 2
    3 1
    4 2
    5 2
    3 3
    3 2
    2 4
    6 3
    7 4
    7 2
    8 5
    8 7
    7 7
    8 8
    5 9
    6 6
    5 7
    4 6
    4 8
    3 7
    2 7
    3 6
    4 4
    0 7
    2 3
    0 2
    end of data
    .
    read xval yval
    0 0
    1 0
    2 1
    1 2
    0 2
    6 2
    2 4
    5 4
    1 5
    3 5
    6 5
    7 6
    8 6
    1 7
    2 7
    3 7
    4 7
    4 8
    5 9
    end of data
    .
    . Step 2: Plot data
    .
    tic mark offset units screen
    tic mark offset 5 5
    pre-sort off
    line blank solid
    character circ blank
    character hw 0.5 0.375
    character fill on
    plot yval xval and
    plot ypoly xpoly
    set isubro popl
    cpu time
    let t1 = cputime
    let tag = point in polygon xval yval xpoly ypoly
    pause
    .
    line bl bl bl bl solid
    character circ circ circ circ blank
    character hw 0.5 0.375 all
    character fill on all
    char color blue red green cyan black
    plot yval xval subset tag = 1 and
    plot yval xval subset tag = 2 and
    plot yval xval subset tag = 3 and
    plot yval xval subset tag = 4 and
    plot ypoly xpoly
  
-----POINT-------------------------------------------------------
 
POINT
 
Name:
    POINT
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Draws a point at a position.
 
Description:
    The coordinates define the (x,y) value of the position.
 
Syntax:
    POINT   <x>   <y>
    where <x> is a decimal number or parameter in the range 0 to 100
              that specifies the horizontal coordinate;
    and   <y> is a decimal number or parameter in the range 0 to 100
              that specifies the vertical coordinate.
 
Examples:
    POINT 50 50
    POINT 20 80
    POINT 70 65.3
 
Note:
    The keywords DATA and RELATIVE were added to the TRIANGLE
    command 7/1997.  These keywords are independent and can
    be used separately or together.  For example, 
    TRIANGLE DATA, TRIANGLE RELATIVE, or TRIANGLE DATA RELATIVE.
    The word DATA should come before the word RELATIVE if both
    appear.

    DATA means that the coordinates are specified in terms of
    the data units of the most recent plot rather than Dataplot
    0 to 100 screen units.

    RELATIVE means that the coordinates of the first point
    are drawn in absolute coordinates an all subsequent points
    in the figure are relative to that first point.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CIRCLE           = Draws a circle.
    ARROW            = Draws an arrow.
    TRIANGLE         = Draws a triangle.
    BOX              = Draws a box.
    HEXAGON          = Draws a hexagon.
    SEMI-CIRCLE      = Draws a semi-circle.
    ARC              = Draws an arc.
    ELLIPSE          = Draws an ellipse.
    OVAL             = Draws an oval.
    DIAMOND          = Draws a diamond.
    DRAW             = Draws a line.
    MOVE             = Moves to a point.
    LINES            = Sets the line type for figures and plot lines.
    LINE THICKNESSES = Sets the line thickness for figures and  plot
                       lines.
    LINE COLOR       = Sets the line colors for figures and plot lines.
    CROSS-HAIR       = Activates and reads the cross-hair.
    TEXT             = Writes a text string.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----POIPDF (LET)--------------------------------
 
POIPDF
 
Name:
    POIPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Poisson probability density function.
 
Description:
    The Poisson distribution is the distribution of the number of
    events in the interval (0,lambda) when the waiting time between
    events is exponentially distributed with mean 1 and standard
    deviation 1 (there are alternate interpretations as well).  The
    Poisson distribution has the following probability mass
    function:

       p(x,lambda) = exp(-lambda)*lambda**x/lambda!
                     x = 0, 1, 2, ...

    with lambda denoting the shape parameter.
 
Syntax:
    LET <y> = POIPDF(<x>,<lambda>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative integer variable, number, or
              parameter;
          <lambda> is a number or parameter that specifies the shape
               parameter of the Poisson distribution;
          <y> is a variable or a parameter (depending on what <x>
              is) where the computed Poisson pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = POIPDF(3,0.5)
    LET X2 = POIPDF(X1,0.3)
 
Note:
    For a number of commands utilizing the Poisson distribution,
    it is convenient to bin the data.  There are two basic ways
    of binning the data.

      1) For some commands (histograms, maximum likelihood
         estimation), bins with equal size widths are
         required.  This can be accomplished with the
         following commands:

            LET AMIN = MINIMUM Y
            LET AMAX = MAXIMUM Y
            LET AMIN2 = AMIN - 0.5
            LET AMAX2 = AMAX + 0.5
            CLASS MINIMUM AMIN2
            CLASS MAXIMUM AMAX2
            CLASS WIDTH 1
            LET Y2 X2 = BINNED

      2) For some commands, unequal width bins may be
         helpful.  In particular, for the chi-square goodness
         of fit, it is typically recommended that the minimum
         class frequency be at least 5.  In this case, it may
         be helpful to combine small frequencies in the tails.
         Unequal class width bins can be created with the
         commands

            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = INTEGER FREQUENCY TABLE Y

         If you already have equal width bins data, you can
         use the commands
         
            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = COMBINE FREQUENCY TABLE Y2 X2

         The MINSIZE parameter defines the minimum class
         frequency.  The default value is 5.

Note:
    You can generate Poisson random numbers, probability
    plots, and chi-square goodness of fit tests with the
    following commands:

       LET LAMBDA = <value>
       LET Y = POISSON RANDOM NUMBERS FOR I = 1 1 N

       POISSON PROBABILITY PLOT Y
       POISSON PROBABILITY PLOT Y2 X2
       POISSON PROBABILITY PLOT Y3 XLOW XHIGH

       POISSON CHI-SQUARE GOODNESS OF FIT Y
       POISSON CHI-SQUARE GOODNESS OF FIT Y2 X2
       POISSON CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    To obtain the maximum likelihood estimates of lambda,
    enter the command

        POISSON MAXIMUM LIKELIHOOD Y

    The formula for the maximum likelihood estimate of
    lambda is:

        lambdahat = xbar

    with  xbar denoting the sample mean.

    You can generate the estimate of lambda based on the
    maximum ppcc value or the minimum chi-square goodness of
    fit with the commands

        LET LAMBDA1 = <value>
        LET LAMBDA2 = <value>
        POISSON KS PLOT Y
        POISSON KS PLOT Y2 X2
        POISSON KS PLOT Y3 XLOW XHIGH
        POISSON PPCC PLOT Y
        POISSON PPCC PLOT Y2 X2
        POISSON PPCC PLOT Y3 XLOW XHIGH

    The default values of lambda1 and lambda2 are 1 and 50,
    respectively.  Due to the discrete nature of the percent
    point function for discrete distributions, the ppcc plot
    will not be smooth.  For that reason, if there is sufficient
    sample size the KS PLOT (i.e., the minimum chi-square value)
    is typically preferred.  However, it may sometimes be useful
    to perform one iteration of the PPCC PLOT to obtain a rough
    idea of an appropriate neighborhood for the shape parameter
    since the minimum chi-square statistic can generate extremely
    large values for non-optimal values of the shape parameters.
    Also, since the data is integer values, one of the binned
    forms is preferred for these commands.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POICDF = Compute the Poisson cumulative distribution function.
    POIPPF = Compute the Poisson percent point function.
    BINCDF = Compute the binomial cumulative distribution function.
    BINPDF = Compute the binomial probability mass function.
    BINPPF = Compute the binomial percent point function.
    NBCDF  = Compute the negative binomial cumulative distribution
             function.
    NBPDF  = Compute the negative binomial probability mass
             function.
    NBPPF  = Compute the negative binomial percent point function.
    GEOCDF = Compute the geometric cumulative distribution function.
    GEOPDF = Compute the geometric probability mass function.
    GEOPPF = Compute the geometric percent point function.
 
Reference:
    Johnson, Kotz, and Kemp (1992), "Univariate Discrete
    Distributions", Second Edition, Wiley, chapter 4.

    Evans, Hastings, and Peacock (2000), "Statistical
    Distributions", Third Edition, Wiley, pp. 155-160.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/4
 
Program:
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    YLIMITS 0 0.2
    XLIMITS 0 50
    XTIC OFFSET 0.5 0.5
    LINE BLANK
    SPIKE ON
    SPIKE LINE DASH
    CHARACTER CIRCLE
    CHARACTER FILL ON
    CHARACTER SIZE 1.2
    TITLE AUTOMATIC
    X1LABEL NUMBER OF SUCCESSES
    Y1LABEL PROBABILITY
    TITLE AUTOMATIC; TITLE SIZE 3
    PLOT POIPDF(X,5) FOR X = 0 1 50
    PLOT POIPDF(X,15) FOR X = 0 1 50
    PLOT POIPDF(X,25) FOR X = 0 1 50
    PLOT POIPDF(X,35) FOR X = 0 1 50
    END OF MULTIPLOT
 
-----POIPPF (LET)--------------------------------
 
POIPPF
 
Name:
    POIPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Poisson percent point function.
 
Description:
    The Poisson distribution is the distribution of the number of
    events in the interval (0,lambda) when the waiting time between
    events is exponentially distributed with mean 1 and standard
    deviation 1 (there are alternate interpretations as well).  The
    Poisson distribution has the following probability density
    function:
       p(x,lambda) = exp(-lambda)*lambda**x/lambda!
    where x is a non-negative integer.
 
    The percent point function is the inverse of the cumulative
    distribution function.  The cumulative distribution sums the
    probability from 0 to the given x value.  The percent point
    function takes a cumulative probability value and computes the
    corresponding x value.  The Poisson percent point function is
    computed using a normal approximation.
 
    The input value is a real number between 0 and 1 (since it
    corresponds to a probability).
 
Syntax:
    LET <y2> = POIPPF(<y1>,<lambda>) <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable, a number, or a parameter in the range 0
              to 1;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed Poisson ppf value is stored;
          <lambda> is a number or parameter that specifies the shape
               parameter of the Poisson distribution;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = POIPPF(0.9,5)
    LET X2 = POIPPF(X1,0.7)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POICDF = Compute the Poisson cumulative distribution function.
    POIPDF = Compute the Poisson probability density function.
    BINCDF = Compute the binomial cumulative distribution function.
    BINPDF = Compute the binomial probability density function.
    BINPPF = Compute the binomial percent point function.
    NBCDF  = Compute the negative binomial cumulative distribution
             function.
    NBPDF  = Compute the negative binomial probability density
             function.
    NBPPF  = Compute the negative binomial percent point function.
    GEOCDF = Compute the geometric cumulative distribution function.
    GEOPDF = Compute the geometric probability density function.
    GEOPPF = Compute the geometric percent point function.
 
Reference:
    "Discrete Univariate Distributions", Johnson and Kotz, Houghton
    Mifflin, 1970 (chapter 4).
 
Applications:
    Pre-1987
 
Implementation Date:
    1994/4
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    YLIMITS 0 50
    XLIMITS 0 1
    MAJOR XTIC NUMBER 6
    MINOR XTIC NUMBER 1
    XTIC DECIMAL 1
    TITLE AUTOMATIC
    X1LABEL PROBABILITY
    Y1LABEL NUMBER OF SUCCESSES
    PLOT POIPPF(X,5) FOR X = 0.01 0.01 0.99
    PLOT POIPPF(X,15) FOR X = 0.01 0.01 0.99
    PLOT POIPPF(X,25) FOR X = 0.01 0.01 0.99
    PLOT POIPPF(X,35) FOR X = 0.01 0.01 0.99
    END OF MULTIPLOT
 
-----POISSON DISPERSION TEST------------------------------------
 
POISSON DISPERSION TEST
 
Name:
    POISSON DISPERSION TEST
 
Type:
    Analysis Command
 
Purpose:
    Perform a Poisson dispersion test for Poissonality.
 
Description:
    The Poisson dispersion test is one of the most common tests to
    determine if a univariate data set follows a Poisson distribution.

    The Poisson dispersion test statistic is defined as:

        D = SUM[i=1 to N][(X(i) - XBAR)**2/XBAR]

    with XBAR and N denoting the sample mean and the sample size,
    respectively.

    Note that this test can be applied to either raw (ungrouped) data
    or to frequency (grouped) data.

    This test follows an approximately chi-square distribution with
    N - 1 degrees of freedom.  This is a two-tailed test.

Syntax 1:
    POISSON DISPERSION TEST   <y>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the raw (ungrouped) data case.

Syntax 2:
    POISSON DISPERSION TEST  <y>  <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the variable containing the frequencies;
          <x> is the variable containing the class mid-points;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the grouped data case.

Syntax 3:
    MULTIPLE POISSON DISPERSION TEST  <y1>  ...  <yk>
                         <SUBSET/EXCEPT/FOR qualification>
    where <y1> ... <yk> is a list of 1 to 30 response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs a Poisson dispersion test on <y1>, then
    on <y2>, and so on.  Up to 30 response variables may be specified.

    Note that the syntax

         MULTIPLE POISSON DISPERSION TEST Y1 TO Y4

    is supported.  This is equivalent to

         MULTIPLE POISSON DISPERSION TEST Y1 Y2 Y3 Y4

Syntax 4:
    REPLICATED POISSON DISPERSION TEST  <y>  <x1> ...  <xk>
                         <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> ... <xk> is a list of 1 to 6 group-id variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax peforms a cross-tabulation of <x1> ... <xk> and performs a
    Poisson dispersion test for each unique combination of cross-tabulated
    values.  For example, if X1 has 3 levels and X2 has 2 levels, there
    will be a total of 6 Poisson dispersion tests performed.

    Up to six group-id variables can be specified.

    Note that the syntax

         REPLICATED POISSON DISPERSION TEST Y X1 TO X4

    is supported.  This is equivalent to

         REPLICATED POISSON DISPERSION TEST Y X1 X2 X3 X4

Examples:
    POISSON DISPERSION TEST Y1
    POISSON DISPERSION TEST Y1   SUBSET TAG > 2
    MULTIPLE POISSON DISPERSION TEST Y1 TO Y10
    REPLICATED POISSON DISPERSION TEST Y X
 
Note:
    Syntax 1 and Syntax 3 support matrix arguments.  Syntax 3 and
    Syntax 4 support the TO syntax.

    For Syntax 4 (the REPLICATED form), the variables must all have the
    same number of observations.

Note:
    The following statistics are also supported:

        LET A = POISSON DISPERSION TEST          Y
        LET A = POISSON DISPERSION TEST CDF      Y
        LET A = POISSON DISPERSION TEST PVALUE   Y

        LET A = GROUPED POISSON DISPERSION TEST          Y X
        LET A = GROUPED POISSON DISPERSION TEST CDF      Y X
        LET A = GROUPED POISSON DISPERSION TEST PVALUE   Y X

    In addition to the above LET command, built-in statistics are
    supported for about 17 different commands (enter HELP STATISTICS
    for details).

Note:
    The POISSON DISPERSION TEST command automatically saves the following
    internal parameters:

        STATVAL   = the value of the test statistic
        STATCDF   = the CDF of the test statistic
        PVALUE    = the p-value for the two-sided test
        CUTLOW50  = the 50% lower tailed critical value
        CUTUPP50  = the 50% upper tailed critical value
        CUTLOW80  = the 80% lower tailed critical value
        CUTUPP80  = the 80% upper tailed critical value
        CUTLOW90  = the 90% lower tailed critical value
        CUTUPP90  = the 90% upper tailed critical value
        CUTLOW95  = the 95% lower tailed critical value
        CUTUPP95  = the 95% upper tailed critical value
        CUTLOW99  = the 99% lower tailed critical value
        CUTUPP99  = the 99% upper tailed critical value
        CUTLO999  = the 99.9% lower tailed critical value
        CUTUP999  = the 99.9% upper tailed critical value

    If the MULTIPLE or REPLICATED option is used, these values will
    be written to the file "dpst1f.dat" instead.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POISSON PLOT     = Generate a Poisson plot.
    GOODNESS OF FIT  = Perform Anderson-Darling, Kolmogorov-Smirnov,
                       Chi-Square, and PPCC goodness of fit tests.
    POIPDF           = Compute the Poisson probability mass function.
 
Reference:
    Spinelli and Stephens (1997), "Cramer-Von Mises Tests of Fit for the
    Poisson Distribution", Canadian Journal of Statistics, Vol. 25(2),
    pp. 257-267.

    Kendell and Stuart (1979), "The Advanced Theory of Statistics: Volume 2",
    Fourth Edition, Griffin, London.
 
Applications:
    Distributional Fitting
 
Implementation Date:
    2013/11
 
Program 1:
    LET LAMBDA = 25
    LET Y = POISSON RANDOM NUMBERS FOR I = 1 1 1000
    SET WRITE DECIMALS 4
    POISSON DISPERSION TEST Y

Program 2:
    . Step 1: Read the data
    .
    .         This data set is from:
    .
    .         Spinelli and Stephens (1997), "Cramer-Von Mises Tests of Fit
    .         for the Poisson Distribution", Canadian Journal of Statistics,
    .         Vol. 25(2).
    .
    .         Hoaglin (1980), "A Poissonness Plot", The American Statistician,
    .         34, pp. 146-149.
    .
    .         Note that there is an error in one of the entries in the Spinelli
    .         and Stephens (for cell 2, they give a value of 283 rather than the
    .         value of 383, their computed statistics are consistent with using
    .         the value 383).
    .
    read x2 y2
     0   57
     1  203
     2  383
     3  525
     4  532
     5  408
     6  273
     7  139
     8   45
     9   27
    10   10
    11    4
    12    0
    13    1
    14    1
    end of data
    .
    . Step 2: Perform the Poisson Dispersion test.
    .
    set write decimals 4
    poisson dispersion test y2 x2

-----POISSON PLOT--------------------------------------
 
POISSON PLOT
 
Name:
    POISSON PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates one of the following types of plots:

       1) a Poisson plot
       2) a geometric plot
       3) a negative binomial plot
       4) a binomial plot
       5) a logarithmic series plot
 
Description:
    These plots are used to determine if the specified
    distribution provides an appropriate distributiuonal
    model to a set of data.  These are similar in concept
    to probability plots in that we generate a plot that
    should appear linear if the data are in fact fit well
    by the distribution.
 
    The following table shows how these plots are constructed
    where x and n(x) denote the class value and the corresponding
    frequency.  In all cases, the x-coordinate is x.

                       phi(n*(x))
                       Y-Axis           Theoretical   Theoretical
    Distribution       Coordinate       Slope         Intercept
    ==============================================================
    Poisson            LOG(x!*n*(x)/N)  LOG(lambda)   -lambda
    Geometric          LOG(n*(x)/N)     LOG(1-p)      LOG(p)
    Negative Binomial  LOG(n*(x)/       LOG(1-p)      n*LOG(p)
                       {N*(n+x-1  x)}
    Binomial           LOG(n*(x)/       LOG(p/(1-p))  n*LOG(1-p)
                       {N*(n+x   x)}
    Logarithmic Series LOG(x*n*(x)/N)   LOG(theta)    -LOG(-LOG(1-theta))

    where
       p      = probability of success parameter for the
                geometric, binomial, and negative binomial
                distributions.
       theta  = the shape parameter for the logarithmic series
                distribution.
       n      = the number of trials parameter for the binomial
                distribution.
       x      = class value
       n*(x)  = adjusted class frequency (defined below)

    The theoretical slope parameter can be used to estimate
    the shape parameter of the distribution.

    Hoaglin and Tukey (see References below) provides the
    derivations of why these plots should be linear if the specified
    distribution is appropriate.  They also make the following
    suggestions for enhancing these plots:

       1) A 95% confidence interval for each point on the plot
          is given as

            phi(n*(x)) +/- h(x)

          where

              n*(x)    = n(x) - 0.8*n(x)/N - 0.67    n(x) >= 2
                       = 1/e                         n(x) = 1
                       = undefined                   n(x) = 0
             
              h(x)     = 1.96*SQRT(1 - phat(x))/
                         SQRT{n(x) - (0.25*phat(x) +0.47)*SQRT(n(x))}

              N        = total sample size

              phat(x)  = n(k)/N

          The rationale for this confidence interval is given in
          the Hoaglin and Tukey reference.

          The n*(x) values are referred to as the adjusted
          frequencies.

       2) These plots can be "leveled".  By leveling, we convert
          the plot from interpretation of departures from a
          diagonal line to departures from a horizontal line.
          This may be an easier visual task.

          To level the plot, we plot

             phi'(n(x)) =  phi(n(x)) - (intercept + slope*x)

          where intercept and slope are taken from the columns
          "theoretical intercept" and "theoretical slope" in the
          table above.
   
          Note that a preliminary estimate of the shape parameter
          for the distribution is required to compute the
          theoretical intercept and the theoretical slope.
          This is discussed further in a Note section below.

Syntax 1:
    <dist> PLOT <y>       <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <dist> is one of the following:
              POISSON
              GEOMETRIC
              NEGATIVE BINOMIAL
              BINOMIAL
              LOGARITHMIC SERIES;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where you have raw data.
    Dataplot will automatically create the frequency table.

Syntax 2:
    <dist> PLOT <y> <x>     <SUBSET/EXCEPT/FOR qualification>
    where <y> is a variable containing frequencies;
          <x> is a variable containing the class value;
          <dist> is one of the distributions listed above:
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    POISSON PLOT Y
    POISSON PLOT Y X
    GEOMETRIC PLOT Y
    GEOMETRIC PLOT Y X
 
Note:
    For the leveled version of the plot, a preliminary estimate
    of the shape parameter(s) is required.

       1) For the Poisson distribution, the maximum likelihood
          estimate of lambda is the sample mean.  This is used
          as the prelimanary estimate of lambda in the leveled
          version of the plot.

       2) For the binomial distribution, you need to specify
          the n parameter (the number of trials) by entering
          the following command before the BINOMIAL PLOT
          command:

              LET N = <value>

          The sample mean is then used as the estimate of the
          p (probability of success) parameter. This is the
          maximum likelihood estimate.

       3) For the geometric distribution, the maximum likelihood
          estimate of the p (probability of success) parameter is

              1/(xbar + 1)

          where xbar is the sample mean.

       4) For the negative binomial distribution, there are two
          parameters: p and k.  For this plot, k is restricted to
          integer values.

          You can either specify a value for k by entering
          the command

              LET K = <value>
  
          or you can let Dataplot estimate the value.

          If k is not specified, the moment estimate of k is
          used:

              kmom = xbar**2/(s**2 - xbar)

          This estimate will be rounded to the nearest integer.
     
          The maximum likelihood estimate of p is then

              phat = k/(xbar + k)

          If k >= 2, then the bias corrected estimate is used

              phat = (k - 1)/(xbar + k - 1)
             
       5) For the logarithmic series distribution, you can
          specify the desired value of theta by entering the
          command

              LET THETA = <value>

          You can obtain this estimate either by using 
          maximum likelihood, the PPCC plot, or the KS plot.

Note:
    The appearance of the plot can be controlled with
    the LINE and CHARACTER commands.  Specifically,

        trace 1           = phi(n(x)) versus x
        trace 2           = fitted line for phi(n(x)) versus x
        trace 3           = phi(n*(x)) versus x
        trace 4           = fitted line for phi(n*(x)) versus x
        trace 5           = lower confidence point
        trace 6           = upper confidence point
        trace 7 and above = line connecting the lower and upper
                            confidence points

    If you want to suppress any of these components, you can
    set both the CHARACTER and LINE settings to BLANK.  The
    example programs below demonstrate the use of the LINE
    and CHARACTER commands to control the appearance of the plot.

Note:
    By default, the unleveled plot is generated.  To generate
    the leveled plot, enter the command

        SET POISSON PLOT LEVEL ON

    To reset the default, enter the command

        SET POISSON PLOT LEVEL OFF

    This command applies to all five of the plots described here,
    not just the Poisson plot.

Note:
    The following internal parameters are saved by this plot:

    All plots:
        PPA0      - the intercept of the fitted line (unadjusted
                    frequencies)
        PPA1      - the slope of the fitted line (unadjusted
                    frequencies)
        PPA0ADJU  - the intercept of the fitted line (adjusted
                    frequencies)
        PPA1      - the slope of the fitted line (adjusted
                    frequencies)

     Poisson plot:
        LAMBDAPP  - the estimate of lambda based on the
                    unadjusted frequencies
        LAMBDAPA  - the estimate of lambda based on the
                    adjusted frequencies

     Binomial, negative binomial, geometric plot:
        PPP       - the estimate of p based on the unadjusted
                    frequencies
        PPPADJ    - the estimate of p based on the adjusted
                    frequencies

     Logarithmic series plot:
        THETAPP   - the estimate of theta based on the
                    unadjusted frequencies
        THETAPPA  - the estimate of theta based on the
                    adjusted frequencies
 
Default:
    The unleveled version of the plot is generated by default.
 
Synonyms:
    None
 
Related Commands:
    PROBABILITY PLOT    = Generates a probability plot.
    PPCC PLOT           = Generates a ppcc plot.
    KS PLOT             = Generates a Kolmogorov-Smirnov (or
                          chi-square) plot.
    ORD PLOT            = Generate an Ord plot.
    HISTOGRAM           = Generates a histogram.
    LINES               = Sets the type for plot lines.
    CHARACTER           = Sets the type for plot characters.
 
References:
    Hoaglin (1980), "A Poissonness Plot", The American Statistician,
    34, pp. 146-149.

    Hoaglin and Tukey (1985), "Checking The Shape of Discrete
    Distributions". In Hoaglin, Mosteller, and Tukey, editors,
    "Exploring Data Tables, Trends, and Shapes", chapter 9,
    John Wiley and Sons, New York.

    Friendly (2000), "Visualizing Categorical Data", SAS Publishing,
    Cary, NC, pp. 49-56.

Applications:
    Distributional Modeling
 
Implementation Date:
    2007/5
 
Program:
    .  Following data from p. 51 of Friendly
    read x y
    0  109
    1   65
    2   22
    3    3
    4    1
    end of data
    .
    title case asis
    title offset 2
    label case asis
    x1label displacement 6
    title Poisson Plot
    x1label X
    y1label LOG(x!*n(x)/N)
    x3label
    .
    char blank all
    char fill off all
    char hw 1.5 1.2 all
    char color black all
    char circle blank circle blank circle circle
    char fill on off on
    char color blue black green
    line dotted all
    line blank solid blank solid blank blank
    line color black blue black green
    tic offset units screen
    tic offset 3 3
    .
    poisson plot y x
    .
    let lambml = weighted mean x y
    justification center
    move 50 8
    text Unadjusted: Intercept = ^ppa0, Slope = ^ppa1
    move 50 5
    text Adjusted: Intercept = ^ppa0adju, Slope = ^ppa1adju
    move 50 2
    text Lambda: ML = ^lambml, PP = ^lambdapp, PPadj = ^lambdapa

-----POLYGON-------------------------------------------------------
 
POLYGON
 
Name:
    POLYGON
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Draws a polygon.
 
Description:
    The POLYGON command takes an array of x-coordinates and an
    array of y-coordinates and draws the polygon defined by these
    points.
 
    Although Dataplot provides many specific geometric figures, the
    POLYGON command provides the most flexible option.  That is,
    you can create an arbitrarily complex geometric figure to
    append to a plot.

Syntax 1:
    POLYGON   <x>   <y>      <SUBSET/EXCEPT/FOR qualification>
    where <x> is an array of x coordinates;
          <y> is an array of y coordinates;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
               rarely used in this context.

    In this syntax, the coordinates are specified in absolute
    0 to 100 Dataplot screen units.
 
Syntax 2:
    POLYGON DATA  <x>   <y>      <SUBSET/EXCEPT/FOR qualification>
    where <x> is an array of x coordinates;
          <y> is an array of y coordinates;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
               rarely used in this context.

    In this syntax, the coordinates are specified in absolute
    units of the most recent plot.

Syntax 3:
    POLYGON RELATIVE <x>  <y>     <SUBSET/EXCEPT/FOR qualification>
    where <x> is an array of x coordinates;
          <y> is an array of y coordinates;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
               rarely used in this context.

    In this syntax, the first coordinate is specified in absolute
    0 to 100 Dataplot screen units.  Subsequent points are
    relative to the prior point (i.e., point 2 is relatvie to
    point 1, point 3 is relative to point 2, etc.) in Dataplot
    0 to 100 screen units.

Syntax 4:
    POLYGON RELATIVE DATA <x>  <y>  <SUBSET/EXCEPT/FOR qualification>
    where <x> is an array of x coordinates;
          <y> is an array of y coordinates;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
               rarely used in this context.

    In this syntax, the first coordinate is specified in absolute
    units of the most recent plot.  Subsequent points are
    relative to the prior point (i.e., point 2 is relatvie to
    point 1, point 3 is relative to point 2, etc.) in units of
    the most recent plot.

Examples:
    LET X = DATA 0.5 1.5 1.5 0.5 0.5
    LET Y = DATA 0   0   10  10  0
    POLYGON DATA X Y
 
Note:
    The line style (i.e., SOLID, DASH), line color, and line thickness
    for drawing the border of the polygon are dictated by the first
    entry of the LINE, LINE COLOR, and LINE THICKNESS commands
    respectively.  The attributes of the interior of the polygon
    are controlled by the various REGION attribute commands
    (e.g., REGION FILL, REGION FILL COLOR).
 
Note:
    Dataplot will automatically check if the first point is equal
    to the last point.  If not, Dataplot adds a point to close the
    polygon.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    BOX              = Draws a box.
    CIRCLE           = Draws a circle.
    ARC              = Draws an arc.
    DRAW             = Draws a line.
    MOVE             = Moves to a point.
    LINES            = Sets the line type for figures and plot lines.
    LINE THICKNESSES = Sets the line thickness for figures and  plot
                       lines.
    LINE COLOR       = Sets the line colors for figures and plot lines.
    CROSS-HAIR       = Activates and reads the cross-hair.
    TEXT             = Writes a text string.
    REGION FILL      = Specifies the fill attribute of a region.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    7/1997
 
Program:
    SKIP 25
    READ TEXAS.DAT X Y
    .
    PLOT Y X
    .
    REGION FILL ON
    REGION FILL COLOR G90
    POLYGON DATA X Y
 
-----POLYNOMIAL (LET)-----------------------------------
 
POLYNOMIAL

The following are DATAPLOT polynomial commands:
    POLYNOMIAL ADDITION       = Carries out a polynomial addition.
    POLYNOMIAL SUBTRACTION    = Carries out a polynomial subtraction.
    POLYNOMIAL MULTIPLICATION = Carries out a polynomial multiplication.
    POLYNOMIAL DIVISION       = Carries out a polynomial division.
    POLYNOMIAL SQUARE         = Carries out a polynomial square.
    POLYNOMIAL EVALUATION     = Carries out a polynomial evaluation.
 
-----POLYNOMIAL ADDITION (LET)-----------------------------------
 
POLYNOMIAL ADDITION (LET)
 
Name:
    POLYNOMIAL ADDITION (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the addition of 2 polynomials (with real coefficients).
 
Syntax:
    LET <v3> = POLYNOMIAL ADDITION <v1> <v2>
              <SUBSET/EXCEPT/FOR/qualification>
    where <v1> is the variable whose elements are the ordered (real)
               coefficients of the first polynomial;
          <v2> is the variable whose elements are the ordered (real)
               coefficients of the second polynomial;
          <v3> is the variable whose elements are the ordered (real)
               coefficients of the resultant polynomial;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
               rarely used in this context.
 
Examples:
    LET Y3  = POLYNOMIAL ADDITION Y1 Y2
    LET Y3  = POLYNOMIAL ADDITION Y1 Y2 SUBSET Y1 > 10
    LET Y3  = POLYNOMIAL ADDITION Y1 Y2 FOR I = 1 1 3
 
Note:
    The ordering of the coefficients within a variable is as follows:
          element 1 is the coefficient of the constant term;
          element 2 is the coefficient of the linear term;
          element 3 is the coefficient of the quadratic term;
          element 4 is the coefficient of the cubic term;
          etc.
    Thus the polynomial
       4 + 11*x + 37*x**2 + 8*x**3 + 19*x**4
    can be stored in the variable Y with 5 elements (4 11 37 8 19) via:
          SERIAL READ Y
          4 11 37 8 19
          END OF DATA
    or
          LET Y = DATA 4 11 37 8 19
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                       = Evaluates general functions.
    POLYNOMIAL SUBTRACTION    = Carries out a polynomial subtraction.
    POLYNOMIAL MULTIPLICATION = Carries out a polynomial multiplication.
    POLYNOMIAL DIVISION       = Carries out a polynomial division.
    POLYNOMIAL SQUARE         = Carries out a polynomial square.
    POLYNOMIAL EVALUATION     = Carries out a polynomial evaluation.
    COMPLEX ROOTS             = Computes the roots of complex
                                polynomial.
    PLOT                      = Plots data or functions
    COMPLEX ADDITION          = Carries out a complex addition.
    VECTOR ADDITION           = Carries out a vector addition.
    SET UNION                 = Carries out a set union.
    LOGICAL AND               = Carries out a logical and.
    MATRIX ADDITION           = Carries out a matrix addition.
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 4 11 37 8 19
    LET Y2 = DATA 1 2 1
    LET Y3 = POLYNOMIAL ADDITION Y1 Y2
    SET WRITE DECIMALS 0
    WRITE Y1 Y2 Y3
 
-----POLYNOMIAL DEGREE-------------------------------------------------
 
POLYNOMIAL DEGREE
 
Name:
    POLYNOMIAL DEGREE
 
Type:
    Support Command
 
Purpose:
    Specifies the polynomial degree for certain variations of the
    SMOOTH, SPLINE FIT, and FIT commands.
 
Description:
    The syntax for the SMOOTH, SPINE FIT, and FIT commands allows the
    analyst to embed the desired degree directly in the command, as a
    pre-word, as in
       CUBIC SMOOTH Y
       QUINTIC SPLINE FIT Y X K
       QUARTIC FIT Y X
    If the analyst chooses not to use such a pre-word, the degree
    information can be conveyed via the POLYNOMIAL DEGREE command, as
    in
       POLYNOMIAL DEGREE 3
       SMOOTH Y
       POLYNOMIAL DEGREE 5
       SPLINE FIT Y X K
       POLYNOMIAL DEGREE 4
       FIT Y X
    In practice, embedding degree information directly in the command
    is much more popular than using the POLYNOMIAL DEGREE command.
 
Syntax:
    POLYNOMIAL DEGREE   <n>
    where <n> is an integer number or parameter that is the desired
              degree of the polynomial in certain forms of the FIT,
              SPLINE FIT, and SMOOTH commands.
 
Examples:
    POLYNOMIAL DEGREE 3
    POLYNOMIAL DEGREE 1
 
Note:
    The POLYNOMIAL DEGREE command with no arguments reverts the
    polynomial degree to default.
 
Default:
    For smoothing     --1 (= linear);
    for spline fitting--3 (= cubic);
    for fitting       --1 (= linear).
 
Synonyms:
    None
 
Related Commands:
    FIT                = Carries out least squares fit.
    PRE-FIT            = Carries out least squares pre-fit.
    SPLINE FIT         = Carries out spline fit.
    SMOOTH             = Carries out smoothing.
    FIT STANDARD DEVI  = Set the minimum standard deviation for the
                         fit command.
    WEIGHTS            = Set weights for the fit command.
    FILTER WIDTH       = Set the filter width for the SMOOTH command.
    KNOTS              = Set the knots variable for the SPLINE FIT
                         command.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----POLYNOMIAL DIVISION (LET)-----------------------------------
 
POLYNOMIAL DIVISION (LET)
 
Name:
    POLYNOMIAL DIVISION (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the division of 2 polynomials (with real coefficients).
 
Syntax:
    LET <v3> <v4> = POLYNOMIAL DIVISION <v1> <v2>
              <SUBSET/EXCEPT/FOR/qualification>
    where <v1> is the variable whose elements are the ordered (real)
               coefficients of the first polynomial;
          <v2> is the variable whose elements are the ordered (real)
               coefficients of the second polynomial;
          <v3> is the variable whose elements are the ordered (real)
               coefficients of the resultant quotient polynomial;
          <v4> is the variable whose elements are the ordered (real)
               coefficients of the resultant remainder polynomial;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
               rarely used in this context.
 
Examples:
    LET Y3 Y4 = POLYNOMIAL DIVISION Y1 Y2
 
Note:
    The ordering of the coefficients within a variable is as follows:
          element 1 is the coefficient of the constant term;
          element 2 is the coefficient of the linear term;
          element 3 is the coefficient of the quadratic term;
          element 4 is the coefficient of the cubic term;
          etc.
    Thus the polynomial
       4 + 11*x + 37*x**2 + 8*x**3 + 19*x**4
    can be stored in the variable Y with 5 elements (4 11 37 8 19) via:
          SERIAL READ Y
          4 11 37 8 19
          END OF DATA
    or
          LET Y = DATA 4 11 37 8 19
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                       = Evaluates general functions.
    POLYNOMIAL ADDITION       = Carries out a polynomial addition.
    POLYNOMIAL SUBTRACTION    = Carries out a polynomial subtraction.
    POLYNOMIAL MULTIPLICATION = Carries out a polynomial multiplication.
    POLYNOMIAL SQUARE         = Carries out a polynomial square.
    POLYNOMIAL EVALUATION     = Carries out a polynomial evaluation.
    COMPLEX DIVISION          = Carries out complex division.
    COMPLEX ROOTS             = Computes the roots of a complex
                                polynomial.
    PLOT                      = Plots data or functions
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 1 -5 6
    LET Y2 = DATA 1 -2
    LET Y3 Y4 = POLYNOMIAL DIVISION Y1 Y2
    WRITE Y1 Y2
    WRITE Y3
    WRITE Y4
 
-----POLYNOMIAL EVALUATION (LET)---------------------------------
 
POLYNOMIAL EVALUATION (LET)
 
Name:
    POLYNOMIAL EVALUATION (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the evaluation of a polynomial (with real coefficients)
    for each point in a variable.
 
Syntax:
    LET <v3> = POLYNOMIAL EVALUATION <v1> <v2>
                      <SUBSET/EXCEPT/FOR/qualification>
    where <v1> is the variable whose elements are the ordered (real)
               coefficients of the polynomial;
          <v2> is the variable whose elements are the values at which
               the polynomial is to be evaluated;
          <v3> is the variable whose elements are the computed values of
               the polynomial;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
               rarely used in this context.
 
Examples:
    LET Y  = POLYNOMIAL EVALUATION C X
    LET Y  = POLYNOMIAL EVALUATION C X SUBSET X > 10
    LET Y  = POLYNOMIAL EVALUATION C X FOR I = 1 1 3
 
Note:
    The ordering of the coefficients within a variable is as follows:
          element 1 is the coefficient of the constant term;
          element 2 is the coefficient of the linear term;
          element 3 is the coefficient of the quadratic term;
          element 4 is the coefficient of the cubic term;
          etc.
    Thus the polynomial
       4 + 11*x + 37*x**2 + 8*x**3 + 19*x**4
    can be stored in the variable Y with 5 elements (4 11 37 8 19) via:
          SERIAL READ Y
          4 11 37 8 19
          END OF DATA
    or
          LET Y = DATA 4 11 37 8 19
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                       = Evaluates general functions.
    POLYNOMIAL ADDITION       = Carries out a polynomial addition.
    POLYNOMIAL SUBTRACTION    = Carries out a polynomial subtraction.
    POLYNOMIAL MULTIPLICATION = Carries out a polynomial multiplication.
    POLYNOMIAL DIVISION       = Carries out a polynomial division.
    POLYNOMIAL SQUARE         = Carries out a polynomial square.
    COMPLEX ROOTS             = Computes the roots of a complex
                                polynomial.
    PLOT                      = Plots data or functions
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    . PURPOSE--DETERMINE THE COMPLEX ROOTS OF THE POLYNOMIAL
    .          1.2 + 3.55*X + 12.25*X**2 + 7.33*X**3
    .          + 14.2377*X**4 -10.752*X**5 + 5.42*X**6
    . NOTE--FOR TESTING PURPOSES, THE ROOTS ARE
    .          -0.1977768    -0.6085631
    .          -0.1977768     0.6085631
    .          -0.1802901    -0.3198090
    .          -0.1802901     0.3198091
    .           1.369949      1.461156
    .           1.369949     -1.461156
    .
    .      STEP 1--DEFINE THE COEFFICIENTS OF THE POLYNOMIAL
    LET P = DATA 1.2 3.55 12.25 7.33 14.2377 -10.752 5.42
    .      STEP 2--DEFINE A SEQUENCE OF POINTS, EVALUATE THE POLYNOMIAL
    .              AT THOSE POINTS, PLOT THE EVALUATED POLYNOMIAL.
    LET X = SEQUENCE -1 .1 1
    LET Y = POLYNOMIAL EVALUATION P X
    MULTIPLOT 2 1; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE ORIGINAL FUNCTION
    PLOT Y X
    .      STEP 3--FIND THE COMPLEX ROOTS
    LET X2 Y2 = COMPLEX ROOTS P
    PRINT X2 Y2
    .      STEP 4--PLOT THE COMPLEX ROOTS
    CHAR X
    LINES
    X1LABEL REAL COMPONENT
    Y1LABEL COMPLEX COMPONENT
    GRID ON
    TITLE ROOTS OF FUNCTION
    PLOT Y2 X2
    END OF MULTIPLOT
 
-----POLYNOMIAL MULTIPLICATION (LET)-----------------------------
 
POLYNOMIAL MULTIPLICATION (LET)
 
Name:
    POLYNOMIAL MULTIPLICATION (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the multiplication of 2 polynomials (with real
    coefficients).
 
Syntax:
    LET <v3> = POLYNOMIAL MULTIPLICATION <v1> <v2>
                      <SUBSET/EXCEPT/FOR/qualification>
    where <v1> is the variable whose elements are the ordered (real)
               coefficients of the first polynomial;
          <v2> is the variable whose elements are the ordered (real)
               coefficients of the second polynomial;
          <v3> is the variable whose elements are the ordered (real)
               coefficients of the resultant polynomial;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
               rarely used in this context.
 
Examples:
    LET Y3  = POLYNOMIAL MULTIPLICATION Y1 Y2
    LET Y3  = POLYNOMIAL MULTIPLICATION Y1 Y2 SUBSET Y1 > 7
    LET Y3  = POLYNOMIAL MULTIPLICATION Y1 Y2 FOR I = 1 1 3
 
Note:
    The ordering of the coefficients within a variable is as follows:
          element 1 is the coefficient of the constant term;
          element 2 is the coefficient of the linear term;
          element 3 is the coefficient of the quadratic term;
          element 4 is the coefficient of the cubic term;
          etc.
    Thus the polynomial
       4 + 11*x + 37*x**2 + 8*x**3 + 19*x**4
    can be stored in the variable Y with 5 elements (4 11 37 8 19) via:
          SERIAL READ Y
          4 11 37 8 19
          END OF DATA
    or
          LET Y = DATA 4 11 37 8 19
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                       = Evaluates general functions.
    POLYNOMIAL ADDITION       = Carries out a polynomial addition.
    POLYNOMIAL SUBTRACTION    = Carries out a polynomial subtraction.
    POLYNOMIAL DIVISION       = Carries out a polynomial division.
    POLYNOMIAL SQUARE         = Carries out a polynomial square.
    POLYNOMIAL EVALUATION     = Carries out a polynomial evaluation.
    COMPLEX ROOTS             = Computes the roots of a complex
                                polynomial.
    PLOT                      = Plots data or functions
    COMPLEX MULTIPLICATION    = Carries out a complex multiplication.
    VECTOR DOT PRODUCT        = Computes the vector dot product.
    MATRIX MULTIPLICATION     = Carries out a matrix multiplication.
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    . PURPOSE--DETERMINE THE COMPLEX ROOTS OF A SUM OF 20 QUINTICS
    .          WHERE THE K-TH QUINTIC IS OF THE FORM (1 + (1/K)*X)**5
    . NOTE--FOR TESTING PURPOSES--
    .       THE RESULTING POLYNOMIAL HAS COEFFICIENTS--
    .             0.2000000E+02
    .             0.1798870E+02
    .             0.1596163E+02
    .             0.1200868E+02
    .             0.5411423E+01
    .             0.1036926E+01
    .       WITH COMPLEX ROOTS--
    .            -0.2387324E+01  0.0000000E+00 (DOUBLE ROOT)
    .            -0.1639799E+01 -0.1343364E+01
    .            -0.1639799E+01  0.1343364E+01
    .             0.2241036E+00 -0.1322019E+01
    .             0.2241036E+00  0.1322019E+01
    .
    FEEDBACK OFF; DIMENSION 100 VARIABLES
    LET N = 20
    .      STEP 1--DEFINE THE 20 MONOMIALS
    LOOP FOR K = 1 1 N
        LET M^K (1) = 1
        LET M^K (2) = 1/K
    END OF LOOP
    .      STEP 2--DEFINE THE 20 POLYNOMIALS
    LOOP FOR K = 1 1 N
        LET P^K = POLYNOMIAL MULTIPLICATION M^K M^K
        LET P^K = POLYNOMIAL MULTIPLICATION P^K M^K
        LET P^K = POLYNOMIAL MULTIPLICATION P^K M^K
        LET P^K = POLYNOMIAL MULTIPLICATION P^K M^K
    END OF LOOP
    .      STEP 3--COMPUTE THE SUM OF THE 20 POLYNOMIALS
    LET PSUM = DATA 0 0 0 0
    LOOP FOR K = 1 1 N
        LET PSUM = POLYNOMIAL ADDITION PSUM P^K
    END OF LOOP
    .      STEP 4--PLOT THE FUNCTION
    .
    MULTIPLOT 2 1; MULTIPLOT CORNER COORDINATES 0 0 100 100
    LET X = SEQUENCE -5 .1 5
    LET Y = POLYNOMIAL EVALUATION PSUM X
    TITLE SUM OF POLYNOMIALS
    PLOT Y X
    .      STEP 5--FIND THE COMPLEX ROOTS
    LET X2 Y2 = COMPLEX ROOTS PSUM
    .      STEP 6--PLOT THE COMPLEX ROOTS
    CHAR X; LINES; GRID ON
    X1LABEL REAL COMPONENT; Y1LABEL COMPLEX COMPONENT; TITLE PLOT ROOTS
    PLOT Y2 X2
    END OF MULTIPLOT
 
-----POLYNOMIAL SQUARE (LET)-------------------------------------
 
POLYNOMIAL SQUARE (LET)
 
Name:
    POLYNOMIAL SQUARE (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the squaring of a polynomial (with real coefficients).
 
Syntax:
    LET <v2> = POLYNOMIAL SQUARE <v1> <SUBSET/EXCEPT/FOR/qualification>
    where <v1> is the variable whose elements are the ordered (real)
               coefficients of the polynomial to be squared;
          <v2> is the variable whose elements are the ordered (real)
               coefficients of the resultant polynomial;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
               rarely used in this context.
 
Examples:
    LET Y2  = POLYNOMIAL SQUARE Y1
    LET Y2  = POLYNOMIAL SQUARE Y1 SUBSET Y1 > 10
    LET Y2  = POLYNOMIAL SQUARE Y1 FOR I = 1 1 3
 
Note:
    The ordering of the coefficients within a variable is as follows:
          element 1 is the coefficient of the constant term;
          element 2 is the coefficient of the linear term;
          element 3 is the coefficient of the quadratic term;
          element 4 is the coefficient of the cubic term;
          etc.
    Thus the polynomial
       4 + 11*x + 37*x**2 + 8*x**3 + 19*x**4
    can be stored in the variable Y with 5 elements (4 11 37 8 19) via:
          SERIAL READ Y
          4 11 37 8 19
          END OF DATA
    or
          LET Y = DATA 4 11 37 8 19
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                       = Evaluates general functions.
    POLYNOMIAL ADDITION       = Carries out a polynomial addition.
    POLYNOMIAL SUBTRACTION    = Carries out a polynomial subtraction.
    POLYNOMIAL MULTIPLICATION = Carries out a polynomial multiplication.
    POLYNOMIAL DIVISION       = Carries out a polynomial division.
    POLYNOMIAL EVALUATION     = Carries out a polynomial evaluation.
    COMPLEX ROOTS             = Computes the roots of a complex
                                polynomial.
    COMPLEX EXPONENTIATION    = Carries out a complex exponentiation.
    PLOT                      = Plots data or functions
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 4 11 37 8 19
    LET Y2 = POLYNOMIAL SQUARE Y1
    SET WRITE DECIMALS 0
    WRITE Y1 Y2
 
-----POLYNOMIAL SUBTRACTION (LET)--------------------------------
 
POLYNOMIAL SUBTRACTION (LET)
 
Name:
    POLYNOMIAL SUBTRACTION (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the subtraction of 2 polynomials (with real coefficients).
 
Syntax:
    LET <v3> = POLYNOMIAL SUBTRACTION <v1> <v2>
                      <SUBSET/EXCEPT/FOR/qualification>
    where <v1> is the variable whose elements are the ordered (real)
               coefficients of the first polynomial;
          <v2> is the variable whose elements are the ordered (real)
               coefficients of the second polynomial;
          <v3> is the variable whose elements are the ordered (real)
               coefficients of the resultant polynomial;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
               rarely used in this context.
 
Examples:
    LET Y3  = POLYNOMIAL SUBTRACTION Y1 Y2
    LET Y3  = POLYNOMIAL SUBTRACTION Y1 Y2 SUBSET Y1 > 10
    LET Y3  = POLYNOMIAL SUBTRACTION Y1 Y2 FOR I = 1 1 3
 
Note:
    The ordering of the coefficients within a variable is as follows:
          element 1 is the coefficient of the constant term;
          element 2 is the coefficient of the linear term;
          element 3 is the coefficient of the quadratic term;
          element 4 is the coefficient of the cubic term;
          etc.
    Thus the polynomial
       4 + 11*x + 37*x**2 + 8*x**3 + 19*x**4
    can be stored in the variable Y with 5 elements (4 11 37 8 19) via:
          SERIAL READ Y
          4 11 37 8 19
          END OF DATA
    or
          LET Y = DATA 4 11 37 8 19
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                       = Evaluates general functions.
    POLYNOMIAL ADDITION       = Carries out a polynomial addition.
    POLYNOMIAL MULTIPLICATION = Carries out a polynomial multiplication.
    POLYNOMIAL DIVISION       = Carries out a polynomial division.
    POLYNOMIAL SQUARE         = Carries out a polynomial square.
    POLYNOMIAL EVALUATION     = Carries out a polynomial evaluation.
    COMPLEX SUBTRACTION       = Carries out a complex subtraction.
    VECTOR SUBTRACTION        = Carries out a vector subtraction.
    SET INTERSECTION          = Carries out a set intersection.
    LOGICAL OR                = Carries out a logical or.
    MATRIX SUBTRACTION        = Carries out a matrix subtraction.
    COMPLEX ROOTS             = Computes the roots of a complex
                                polynomial.
    PLOT                      = Plots data or functions
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 4 11 37 8 19
    LET Y2 = DATA 1 2 1
    LET Y3 = POLYNOMIAL SUBTRACTION Y1 Y2
    SET WRITE DECIMALS 0
    WRITE Y1 Y2 Y3
 
-----POOLED VARIANCE-COVARIANCE MATRIX (LET)-------------------------
 
POOLED VARIANCE-COVARIANCE MATRIX
 
Name:
    POOLED VARIANCE-COVARIANCE MATRIX (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the pooled variance-covariance matrix of a matrix.
 
Description:
    This command operates on a matrix (M) and a group id variable
    (TAG).  The TAG variable has the same number of rows as the
    matrix M.  The values of TAG are typically integers that
    identify the group to which the corresponding row of the
    matrix belongs.

    The POOLED VARIANCE-COVARIANCE MATRIX command returns a matrix
    that contains a pooled variance-covariance matrix, which is
    defined as:

        SPOOL = (1/SUM(N(i)-1)) * SUM((1/N(i)-1)*C(i)))

    where N(i) is the number of elements in group i and C(i)
    is the variance-covariance matrix of the rows belonging to
    group i.

Syntax 1:
    LET <mat2> = POOLED VARIANCE-COVARIANCE MATRIX <mat1>  <tag>
    where <mat1> is a matrix for which the pooled covariance matrix
              is to be computed;
          <tag> is the group-id variable;
    and where <mat2> is a matrix where the resulting pooled
              covariance matrix is saved.
 
Syntax 2:
    LET <mat3> = POOLED VARIANCE-COVARIANCE MATRIX <mat1>  <mat2>
    where <mat1> is a matrix containing the data for group 1;
          <mat2> is a matrix containing the data for group 2;
    and where <mat3> is a matrix where the resulting pooled
             variance-covariance matrix is saved.
 
    This syntax can be used for the case where there are 
    exactly two groups.  In this case, the data for each group
    is stored in a separate matrix and no group id variable
    is required.

Examples:
    LET COV = POOLED VARIANCE-COVARIANCE MATRIX M TAG
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    VARIANCE-COVARIANCE MATRIX = Compute the variance-covariance
                                 matrix of a matrix.
    CORRELATION MATRIX         = Compute the correlation matrix of
                                 a matrix.
    MATRIX GROUP SD            = Compute the group means for a matrix.
    MATRIX GROUP SD            = Compute the group standard deviations
                                 for a matrix.
 
Reference:
    "Applied Multivariate Statistical Analysis", Third Edition,
    Johnson and Wichern, Prentice-Hall, 1992.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    1998/8
 
Program:
    DIMENSION 50 COLUMNS
    SKIP 25
    READ IRIS.DAT Y1 Y2 Y3 Y4 TAG
    LET N = SIZE Y1
    LET M = MATRIX DEFINITION Y1 N 4
    LET Z = POOLED VARIANCE-COVARIANCE MATRIX M TAG
 
-----POSITIONAL TABULATION--------------------------------------
 
POSITIONAL TABULATION
 
Name:
    POSITIONAL TABULATION
 
Type:
    Analysis Command
 
Purpose:
    Generate a position tabulation for one of Dataplot's supported
    univariate statistics for either a list of variables or a list
    of matrices.
 
Description:
    Dataplot typically computes statistic for the rows of a variable.
    However, there may be times where it is desirable to compute a
    statistic for each row of a list of variables.  For example, given
    the variables A, B, C, and D where each variable has 5 rows, 
    the POSITIONAL TABULATION MEAN command will print the means for

        row 1: mean of A(1), B(1), C(1), D(1)
        row 2: mean of A(2), B(2), C(2), D(2)
        row 3: mean of A(3), B(3), C(3), D(3)
        row 4: mean of A(4), B(4), C(4), D(4)
        row 5: mean of A(5), B(5), C(5), D(5)

    If you specify a list of matrices, then the statistic will be
    computed for each (i,j) position of the matrices.

Syntax:
    POSITIONAL TABULATION  <stat>  <y1> ... <yk>
                           <SUBSET/EXCEPT/FOR qualification>
    where <stat> is one of Dataplot's supported statistics;
          <y1> ... <yk> is a list of 1 to 30 response variables or
               matrices (with the same dimensions); 
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    The list of response variables must all be of the same type (i.e.,
    either all variables or all matrices).  They must also have the
    same dimension (if variables, all must have the same number of
    rows and if matrices, all must have the same number of rows and
    the same number of columns).

Examples:
    POSITIONAL TABULATION MEAN Y1 TO Y5
    POSITIONAL TABULATION MEAN Y1 TO Y5  FOR I = 1 1 25
 
Note:
    For a list of supported statistics, enter the command

        HELP STATISTICS

    Only statistics that operate on a single response are supported.

Note:
    The output is also written to the file DPST1F.DAT.  For example,
    you can do something like the following

       POSITIONAL TABULATION MEAN A B C D
       SKIP 0
       READ DPST1F.DAT ROW COL YMEAN
 
Note:
    To specify the number of digits to print to the right of the
    decimal point, enter the command (the default is exponential
    format)

       SET WRITE DECIMALS <value>

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CROSS TABULATE        = Generates a cross tabulation for a specified
                            statistic.
    MATRIX ROW STATISTIC  = Generate row statistics for a matrix.
    STATISTIC PLOT        = Generate a statistic versus subset plot.
    FLUCTUATION PLOT      = Generate a fluctuation plot.
    TABULATION PLOT       = Generate a tabulation plot.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    2011/9

Program 1:
    let y1 = data 1 2 3
    let y2 = data 4 5 6
    let y3 = data 7 8 9
    .
    set write decimals 3
    positional tabulation mean y1 y2 y3
    .
    read dpst1f.dat row col ymean

 Program 2:
     read matrix a
     1 2 3
     4 5 6
     7 8 9
     end of data
     .
     read matrix b
     11 21 31
     41 51 61
     71 81 91
     end of data
     .
     read matrix c
     101  102  103
     111  121  131
     141  151  161
     end of data
     .
     SET WRITE DECIMALS 1
     POSITIONAL TABULATION SUM A B C
 
-----POSITIVE PREDICTIVE VALUE (LET)--------------------------------
 
POSITIVE PREDICTIVE VALUE
 
Name:
    POSITIVE PREDICTIVE VALUE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the positive predictive value between two
    binary variables.
 
Description:
    Given two variables with n parired observations where each
    variable has exactly two possible outcomes, we can generate
    the following 2x2 table:

                      |       Variable 2        |
        Variable 1    |   Success      Failure  |  Row Total
        ====================================================
        Success       |   N11            N12    |  N11 + N12
        Failure       |   N21            N22    |  N21 + N22
        ====================================================
        Column Total  |   N11+N21      N12+N22  |  Total

    The parameters N11, N12, N21, and N22 denote the counts
    for each category.
 
    Success and failure can denote any binary response.
    Dataplot expects "success" to be coded as "1" and "failure"
    to be coded as "0".  Some typical examples would be:

       1) Variable 1 denotes whether or not a patient has a
          disease (1 denotes disease is present, 0 denotes
          disease not present).  Variable 2 denotes the result
          of a test to detect the disease (1 denotes a positive
          result and 0 denotes a negative result).

       2) Variable 1 denotes whether an object is present or
          not (1 denotes present, 0 denotes absent). Variable 2
          denotes a detection device (1 denotes object detected
          and 0 denotes object not detected).

    In these examples, the "ground truth" is typically given
    as variable 1 while some estimator of the ground truth is
    given as variable 2.
   
    The positive predictive value is then N11/(N11+N21).  This
    is the conditional probability of variable 1 being true
    given that variable 2 is true.  In the context of the first
    example above, this is the probability that the disease is
    present when there is a positive test result.

    Fleiss and his co-authors recommend positive predictive value
    and negative predictive value as an alternative to false
    positive and false negative due to the fact that the
    definitions of false positive and false negative have
    been inconsistent in the literature.

Syntax:
    LET <par> = POSITIVE PREDICTIVE VALUE <y1> <y2>
                              <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed positive
               predictive value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = POSITIVE PREDICTIVE VALUE Y1 Y2
    LET A = POSITIVE PREDICTIVE VALUE Y1 Y2 SUBSET TAG > 2
 
Note:
    The two variables must have the same number of elements.
 
Note:
    There are two ways you can define the response variables:

       1) Raw data - in this case, the variables contain
          0's and 1's.

          If the data is not coded as 0's and 1's, Dataplot
          will check for the number of distinct values.  If
          there are two distinct values, the minimum value
          is converted to 0's and the maximum value is
          converted to 1's.  If there is a single distinct
          value, it is converted to 0's if it is less than
          0.5 and to 1's if it is greater than or equal to
          0.5.  If there are more than two distinct values,
          an error is returned.

       2) Summary data - if there are two observations, the
          data is assummed to be the 2x2 summary table.
          That is,

              Y1(1) = N11
              Y1(2) = N21
              Y2(1) = N12
              Y2(2) = N22
 
Note:
    The following additional commands are supported

        TABULATE POSITIVE PREDICTIVE VALUE  Y1 Y2 X
        CROSS TABULATE POSITIVE PREDICTIVE VALUE Y1 Y2 X1 X2

        POSITIVE PREDICTIVE VALUE PLOT Y1 Y2 X
        CROSS TABULATE POSITIVE PREDICTIVE VALUE PLOT Y1 Y2 X1 X2

        BOOTSTRAP POSITIVE PREDICTIVE VALUE PLOT Y1 Y2
        JACKNIFE  POSITIVE PREDICTIVE VALUE PLOT Y1 Y2

Default:
    None
 
Synonyms:
    PPV is a synonym for POSITIVE PREDICTIVE VALUE.
 
Related Commands:
    NEGATIVE PREDICTIVE VALUE  = Compute the negative predictive
                                 value between two binary variables.
    TRUE POSITIVES             = Compute the proportion of
                                 true positives.
    TRUE NEGATIVES             = Compute the proportion of
                                 true negatives.
    FALSE POSITIVES            = Compute the proportion of
                                 false positives.
    FALSE NEGATIVES            = Compute the proportion of
                                 false negatives.
    TEST SENSITIVITY           = Compute the test sensitivity.
    TEST SPECIFICITY           = Compute the test specificity.
    ODDS RATIO                 = Compute the bias corrected
                                 log(odds ratio).
    ODDS RATIO STANDARD ERROR  = Compute the standard error of the
                                 bias corrected log(odds ratio).
    RELATIVE RISK              = Compute the relative risk.
    TABULATE                   = Compute a statistic for data with
                                 a single grouping variable.
    CROSS TABULATE             = Compute a statistic for data with
                                 two grouping variables.
    STATISTIC PLOT             = Generate a plot of a statistic for
                                 data with a single grouping
                                 variable.
    CROSS TABULATE PLOT        = Generate a plot of a statistic for
                                 data with two grouping variables.
    BOOTSTRAP PLOT             = Generate a bootstrap plot for a
                                 given statistic.
 
Reference:
    Fleiss, Levin, and Paik (2003), "Statistical Methods for
    Rates and Proportions", Third Edition, Wiley, chapter 1.
 
Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/4
 
Program:
    let n = 1
    .
    let p = 0.2
    let y1 = binomial rand numb for i = 1 1 100
    let p = 0.1
    let y2 = binomial rand numb for i = 1 1 100
    .
    let p = 0.4
    let y1 = binomial rand numb for i = 101 1 200
    let p = 0.08
    let y2 = binomial rand numb for i = 101 1 200
    .
    let p = 0.15
    let y1 = binomial rand numb for i = 201 1 300
    let p = 0.18
    let y2 = binomial rand numb for i = 201 1 300
    .
    let p = 0.6
    let y1 = binomial rand numb for i = 301 1 400
    let p = 0.45
    let y2 = binomial rand numb for i = 301 1 400
    .
    let p = 0.3
    let y1 = binomial rand numb for i = 401 1 500
    let p = 0.1
    let y2 = binomial rand numb for i = 401 1 500
    .
    let x = sequence 1 100 1 5
    .
    let a = positive predictive value y1 y2 subset x = 1
    tabulate positive predictive value y1 y2 x
    .
    label case asis
    xlimits 1 5
    major xtic mark number 5
    minor xtic mark number 0
    xtic mark offset 0.5 0.5
    ytic mark offset 0.05 0.05
    y1label Positive Predictive Value
    x1label Group ID
    character x blank
    line blank solid
    .
    positive predictive value plot y1 y2 x
 
-----POSTSCRIPT-------------------------------------------------------
 
POSTSCRIPT
 
Name:
    POSTSCRIPT
 
Type:
    Output Device Command
 
Purpose:
    Direct graphical output to a POSTSCRIPT device.
 
Description:
    Postscript is a device independent page description language
    supported by various vendors.  Although Postscript is primarily
    used by printers, it can be used by other types of devices (e.g.,
    film recorders) as well.  Note that Postscript is a complete
    language as opposed to a simple device protocol.  The Postscript
    file is an ASCII file containing Postscript commands.  To render a
    Postscript file on a specific device, one of the following
    methods is used

       1. A specific device may have built-in support for Postscript
          files.  Typically, this is provided by a vendor written
          driver.  In this case, the Postscript file can be sent
          directly to the device.

       2. If the device does not support Postscript directly,
          a Postscript translator may be available that allows
          you to view or print the Postscript file on a non-Postscript
          device.  One example of this is the ghostview/ghostscript
          software.  Ghostscript is the underlying Postscript
          translator while Ghostview is a GUI program that
          allows you to view the Postscript file on the screeen
          and to print the Postscript file on a non-Postscript
          printer.  Other translators/viewers are available.

    Postscript is routinely supported in the Linux environment for
    printers.  In the Windows environment, it is more common to use
    Ghostview (or some other Postscript translator) to send Postscript
    files to a printer.

    Postscript is the most commonly used format in Dataplot for
    printing graphics.

    Many word processing and page publishing programs import Postscript
    files thereby allowing graphics generated by other programs to be
    to be embedded with text.  However, they normally require that the
    Postscript file be in a special format called encapsulated
    Postscript.  The primary difference between encapsulated Postscript
    and standard Postscript is that encapsulated Postscript assumes that
    each graph is in a separate file while standard Postscript can
    contain multiple pages in the same file.  In order to generate
    encapsulated Postscript in Dataplot, you would typically do something
    like the following

        SET IPL1NA PLOT1.EPS
        DEVICE 2 POSTSCRIPT ENCAPSULATED
             ...  Generate first plot ..
        DEVICE 2 CLOSE
        .
        SET IPL1NA PLOT2.EPS
        DEVICE 2 POSTSCRIPT ENCAPSULATED
             ...  Generate second plot ..
        DEVICE 2 CLOSE
 
    The SET IPL1NA command is used to give the plot file a unique name.
    This basic sequence can be repeated as often as needed.

    Postscript is closely related to the Portable Document Format (PDF).
    PDF is essentially a binary form of Postscript.
 
Syntax 1:
    POSTSCRIPT
 
    This form designates device 1 (the terminal) as a Postscript
    device.
 
Syntax 2:
    POSTSCRIPT ENCAPSULATED
 
    This form designates device 1 (the terminal) as an encapsulated
    Postscript device.
 
Syntax 3:
    DEVICE <1/2/3> POSTSCRIPT
 
    This form designates one of DATAPLOT's 3 devices (it will typically
    be device 2) as a Postscript device.
 
Syntax 4:
    DEVICE <1/2/3> POSTSCRIPT ENCAPSULATED
 
    This form designates one of DATAPLOT's 3 devices (it will typically
    be device 2) as an encapsulated Postscript device.
 
Examples:
    POSTSCRIPT
    DEVICE 2 POSTSCRIPT
    DEVICE 3 POSTSCRIPT
    DEVICE 2 POSTSCRIPT ENCAPSULATED
 
Note:
    The Postscript driver can support either color or monochrome
    Postscript devices.  The default is monochrome.  Enter a DEVICE
    <num> COLOR ON command after the POSTSCRIPT command to get color.
    Postscript supports the full range of color and gray scale provided
    for in DATAPLOT.  Enter HELP COLOR for a list of available colors
    and gray scales.  Colors can have a different appearance on
    different Postscript devices.  Specifically, Postscript color
    printers can come with 1 bit, 4 bits. or 8 bits for each of 3
    colors.  The output quality will vary significantly depending on
    the number of bits used.
 
    Monochrome Postscript devices do support gray scale.  Be aware
    that they do it by "dithering" since each pixel is either on or
    off.  Dithering means that gray scale is emulated by turning some
    proportion of neighboring pixels on or off to get the desired
    effect.
 
    If you want to make color on the default, enter the command
    (you may want to put this in your DPLOGF.TEX startup file)

        SET POSTSCRIPT COLOR DEFAULT

Note:
    One of Postscript's strengths is the availability of scalable and
    rotatable typeset quality fonts.  Postscript fonts (for hardware
    generated characters) can be specified with the following command:

        SET POSTSCRIPT FONT <font id>

    The available fonts (34 are currently supported) can be shown with
    the following command:

        <a href="../ch7/postshow.pdf">POSTSCRIPT SHOW FONTS</a>

    The default font is Helvetica Bold.

Note:
    Postscript fonts are only used when hardware characters are
    generated.  This means that Greek characters and other special
    symbols are not available with the Postscript fonts.  The
    exception is that the SP(), CR(), LC(), and UC() options are
    supported for hardware fonts.
 
    Greek characters (and a few other special symbols) can be generated
    by using the symbol font (SET POSTSCRIPT FONT SYMBOL).  In this
    case, a Greek alpha is obtained by entering TEXT LC()A rather than
    TEXT LC()ALPH().  The limitation is that only one Postscript font
    can be active for a plot, so text strings that require a mixture of
    standard and Greek characters are not practical with this method.
    DATAPLOT does not support automatically switching to the symbol
    font when a Greek character (e.g., ALPH(), BETA()) is encountered
    in the text string.
 
    At this time, if you have text strings which consist only of Greek
    characters you can use the symbol font.  However, if your string is
    a mixture of standard and Greek characters, you need to use one of
    the software fonts.
 
    NOTE 5/2009: 

    The Postscript device was upgraded to handle most of Dataplot's
    supported special characters.  These special characters are
    mapped to the Postscript symbol font.  There is not a 1-to-1
    correspondence between Dataplot's special characters and
    the symbols available in the Postscript symbol font.  The
    supported symbols below are ones that are available in
    both the Dataplot special symbol set and the Postscript
    symbol font.  Note that this means that you can mix these
    Greek characters and special symbols with regular text
    without setting the SYMBOL font.

    Specifically, the following are supported:

      i) subscripts and superscripts

     ii) Greek characters

    iii) A subset of the mathematical symbols and other special
         characters.  The following is the list of Dataplot
         special characters that will be translated to
         equivalent characters in the Postscript symbol font:

             INTE(), SUMM(), PROD(), INFI(), DOTP(),
             DEL(), DIVI(), LT(), GT(), LTEQ(), GTEQ(),
             NOT(), +-(), APPR(), TILD(), EQUI(), VARI(),
             CARA(), TIME(), PART(), RADI(), SUBS(),
             SUPE(), UNIO(), INTR(), ELEM(), THEX(),
             THFO(), RAPO(), LBRA(), RBRA(), LCBR(),
             RCBR(), LELB(), RELB(), RARR(), UARR(),
             DARR(), VBAR(), HBAR(), DEGR() 

         The full set of special symbols supported by Dataplot
         is documented in chapter 13 of Volume I of the
         Reference Manual

            http://www.itl.nist.gov/div898/software/dataplot/
            refman1/ch13/homepage.pdf

Note:
    Postscript printers on most systems require that the first line
    start with a "%!".  However, a few require that it start with
    " %!".  The default in DATAPLOT is no leading space.  If your
    system requires this (i.e, if the Postscript output is printed as
    text rather than a graph), enter the following command:

         SET POSTSCRIPT SPACE ON
 
    Note that while this was an issue with some early Postscript devices,
    with current Postscript devices this should no longer be an issue.

Note:
    Landscape or portrait orientation can be set via the ORIENTATION
    command.  It can be toggled as many times as desired in a
    DATAPLOT session.  The default is landscape orientation.
 
Note:
    The following SET commands can be used to specify the margins and
    resolution of the particular Postscript printer (these should
    normally not be required):
 
        SET POSTSCRIPT PPI <number> sets the resolution (in points per
           inch).  The default is 300.
        SET POSTSCRIPT [LANDSCAPE/PORTRAIT] LEFT    MARGIN sets the
           left margin (in dots).  The default is 50.
        SET POSTSCRIPT [LANDSCAPE/PORTRAIT] RIGHT   MARGIN sets the
           right margin (in dots).  The default is 50.
        SET POSTSCRIPT [LANDSCAPE/PORTRAIT] BOTTOM  MARGIN sets the
           bottom margin (in dots).  The default is 50.
        SET POSTSCRIPT [LANDSCAPE/PORTRAIT] TOP     MARGIN sets the
           top margin (in dots).  The default is 50.
    You can also use the WINDOW CORNER COORDINATES command to set the
    margin, but this affects all the active devices.
 
Note:
    Display Postscript is a special version of Postscript for terminals
    and workstations.  The standard Postscript driver does not work
    for these devices.  Display Postscript does not currently seem
    to be of much interest.
 
Note:
    Some tweaks were made to the Postscript device 1/2003.

    1) Previously, Dataplot started a new page when the device
       was intialized.  It also started a new page when the first
       plot was generated.  This was to ensure that a fresh
       page was started if you were generating diagrammatic
       graphics before the first plot.  However, it caused
       a blank page to be printed for most applications.
       Dataplot now automatically keeps track so that the first
       plot will not generate the unneeded page erase.

    2) Previously, the LANDSCAPE WORDPERFECT orientation (this
       results in a landscape orientation on a portrait page)
       was supported for encapsulated Postscript, but not for
       regular Postscript.  This orientation is now supported
       for regular Postscript.

    3) Dataplot allows you to switch between the various
       orientations (LANDSCAPE, PORTRAIT, LANDSCAPE WORDPERFECT,
       SQUARE) when using Postscript.  For this reason, it sets
       the bounding box for an 11x11 inch page.

       The following command

           SET POSTSCRIPT BOUNDING BOX <FIXED/FLOAT>

       can be used to modify this behavior.  If the value is
       FLOAT (the default), the bounding box is set for an
       11x11 inch page.  If the value is set to FIXED, the
       bounding box will be set according to whatever the current
       orientation is when the device is initialized.  However,
       you should not change the orientation if FIXED is used.

       If you are simply using the Postscript output for printing,
       then you do not need to worry about this command.  However,
       it may occasionally be useful if are importing the Postscript
       output into an external program.

Note:
    In addition to Dataplot's native Postscript driver, you
    can also generate Postscript output using

        DEVICE 2 LIBPLOT POSTSCRIPT
        DEVICE 2 CAIRO POSTSCRIPT

     Libplot and Cairo are graphics libraries that support
     a number of different graphics devices.

Note:
    The 2023/11 version of Dataplot was updated to allow you to
    control the appearance of dashed and dotted lines.  Dash patterns
    are given by a series of pairs of integer values.  The first
    gives the number of units drawn as a solid line and the second
    gives the number of units drawn as a blank line.  These units
    are specified in Postscript 72 points per inch units (e.g., 2
    means 2 points or 2/72 of an inch).

    The defaults are:

        dotted line:   2 4
        dashed line:   4 4
        da1    line:   4 2
        da2    line:   6 4 2 4
        da3    line:   6 4 6 4
        da4    line:   6 4 4 4 2 4
        da5    line:   6 4 2 4 2 4

    To change the defaults, you can enter the commands

        SET POSTSCRIPT DOTTED LINE <list of values>
        SET POSTSCRIPT DASHED LINE <list of values>
        SET POSTSCRIPT DA1    LINE <list of values>
        SET POSTSCRIPT DA2    LINE <list of values>
        SET POSTSCRIPT DA3    LINE <list of values>
        SET POSTSCRIPT DA4    LINE <list of values>
        SET POSTSCRIPT DA5    LINE <list of values>

    Up to 10 pairs of points can be specified.  To reset the
    default, enter the command with no arguments (or use
    DEFAULT as the only argument).

    There are corresponding PROBE commands that display the
    current values.

Note:
    The ghostscript program can be used to convert Postscript to
    Portable Document Format (PDF) or to other formats such as JPEG.
    The SET POSTSCRIPT CONVERT command can be used to allow this to
    be done automatically (i.e., when a Postscript file is closed,
    a PDF version will automatically be created).  Independently
    of Dataplot, you can enter the command

        ps2pdf <postscript file name>

    This creates a file with same base name but an extension of
    "pdf" in PDF format.

    The open source GIMP program can be used to convert Dataplot
    postscript/PDF files to various popular image formats such as
    JPEG or PNG.  This can be useful if you want to import the
    Postscript file into a word processing program such as Word.
    Note that there a number of other programs (both open source and
    commercial) that can convert Postscript files to image formats.
    We do not endorse any specific program for this purpose, but
    it should be noted that better results are usually obtained if
    the program performs anti-aliasing when converting the Postscript
    file to a bit-map format.

Default:
    Postscript is the default for the DEVICE 3 output.
 
Synonyms:
    DEVICE 2 EPS is a synonym for DEVICE 2 POSTSCRIPT ENCAPSULATED
    SET POSTSCRIPT DEFAULT COLOR is a synonym for SET POSTSCRIPT
        COLOR DEFAULT

DEVICE NOTES
    1) HARDWARE TEXT - Postscript hardware characters can be scaled to
       any size.  Vertical strings are rotated 90 degrees.  There are
       34 typeset fonts that can be selected.  Postscript fonts are
       of publication quality.

    2) COLOR - Postscript devices are treated as black and white by
       default (although they do support gray scale).  To activate
       color, enter DEVICE 2 COLOR ON after the DEVICE 2 POSTSCRIPT
       command>  Postscript supports the full range of DATAPLOT colors.
       The appearance of a specific color can vary depending on the
       device.

    3) HARDWARE FILL - Area fills are generated in hardware.

    4) DASH PATTERNS - The Postscript driver supports unique dash
       patterns for DASH, DOT, DASH2, DASH3, and DASH4.  DASH5 is the
       same as DASH4.

    5) LINE WIDTH - Thick lines are generated in hardware.

    6) GRAPHICS INPUT - The CROSS-HAIR command is ignored for this
       device.
 
Related Commands:
    CALCOMP                = Direct graphical output to a Calcomp
                             device.
    HPGL                   = Direct graphical output to an HPGL device.
    TEKTRONIX              = Direct graphical output to a Tektronix
                             device.
    X11                    = Direct graphical output to an X11 device.
    DEVICE                 = Specify certain actions for the graphics
                             output.
    SHOW COLOR             = Show the available colors on the Postscript
                             device.
    SET POSTSCRIPT CONVERT = Automatically convert Postscript output to
                             a specified format when Postscript device
                             is closed.
    PSVIEW                 = View the most recent plot in a Postscript
                             viewer.
 
Applications:
    Graphics Output
 
Implementation Date:
    1989/02
    1989/06: Support for SET POSTSCRIPT FONT
    2003/01: Better handling of first page so a blank page will
             not be generated
    2003/01: Support for SET POSTSCRIPT BOUNDING BOX
    2003/01: LANDSCAPE WORDPERFECT orientation supported for
             regular Postscript
    2004/06: Support for SET POSTSCRIPT COLOR DEFAULT
    2009/05: Automatic support (i.e.,  SYMBOL font does not need to be
             set) for Greek characters and certain special symbols
    2023/11: Support for controlling the appearance of dashed/dotted
             lines
 
Program:
    DEVICE 2 POSTSCRIPT
    PLOT X**2 FOR X = 1 1 9
    DEVICE 2 CLOSE
 
-----POSTSCRIPT BOUNDING BOX (SET)---------------------------------------
 
POSTSCRIPT BOUNDING BOX
 
Name:
    POSTSCRIPT BOUNDING BOX (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify whether the bounding box generated by Dataplot Postscript
    output will be "fixed" or "floating".
 
Description:
    For Postscript output, Dataplot allows the orientation to be
    switched between landscape and portrait mode.  For this reason,
    Dataplot sets the bounding box equivalent to an 11 inch x 11 inch
    page to accomodate either mode.

    When importing Dataplot Postscript files into other programs,
    it may be prefferable to have the bounding box reflect either
    the landscape (i.e., 11 inch x 8.5 inch) or portrait (i.e.,
    8.5 inch x 11 inch) orientation.

    Setting this switch to FIXED will set the bounding box according
    to whatever orientation is in effect when the DEVICE 2 POSTSCRIPT
    command is entered.  In this case, you should not change the
    orientation until a DEVICE 2 CLOSE command is entered.  Setting
    this swith to FLOAT will use the default 11 inch x 11 inch
    bounding box (and you can change the orientation as often as you
    like).

    If you are only interested in printing the Postscript file, you
    can ignore this command.  If you intend to import the Postscript
    file into another program, it may be helpful to set the FIXED
    option.

    This command does not apply to encapsulated Postscript files.
    Since encapsulated assumes that each graph will be in a separate
    file, it already sets the bounding box according to the orientation.

Syntax:
    SET POSTSCRIPT BOUNDING BOX <FIXED/FLOAT>
    where FIXED specifies that the bounding box will be set using the
          current orientation and FLOAT sets the bounding box assuming
          that either landscape or portait orientation may be used.
 
Examples:
    SET POSTRSCRIPT BOUNDING BOX FIXED
    SET POSTRSCRIPT BOUNDING BOX FLOAT

Default:
    The default is FLOAT.
 
Synonyms:
    None
 
Related Commands:
    DEVICE xx POSTSCRIPT  = Set the device to Postscript.
    ORIENTATION           = Set the orientation of the plot.
 
Applications:
    Graphics Output
 
Implementation Date:
    2003/1
 
Program:
    SET POSTSCRIPT BOUNDING BOX FIXED
    ORIENTATION LANDSCAPE
    DEVICE 2 POSTSCRIPT
    PLOT SIN(X) FOR X = -6 0.1 6
    DEVICE 2 CLOSE
 
-----POSTSCRIPT CONVERT (SET)---------------------------------------
 
POSTSCRIPT CONVERT
 
Name:
    POSTSCRIPT CONVERT (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify that when a Postscript device is closed it will
    automatically be converted to the specified device.
 
Description:
    It is often desirable to import Dataplot generated graphs
    into external programs.  This includes word processors
    (e.g., Word, Word Perfect), presentation software (e.g.,
    Power Point), image manipulation programs (e.g., gimp,
    pbm image conversion programs), image viewers (xv), web browsers,
    graphics editors (e.g., Photoshop, Corel Draw), and so on.

    Most of these programs will accept Postscript or encapsulated
    Postscript as input.  However, in some cases, non-Postscript
    formats are needed or preferred.  For example, web browsers
    typically expect GIF, PNG, or JPEG images.  Also, Dataplot
    does not generate the optional bit-map preview for encapsulated
    Postscript (although you can add one using Ghostview on Windows).
    Most programs do not actually convert Postscript files.  Instead,
    they use the bit-map preview when displaying on non-Postscript
    devices and the original Postscript when displaying on Postscript
    devices.  In these cases, it may be more convenient to import a
    JPEG version of the graph.

    The SET POSTSCRIPT CONVERT command is used to specify one of the
    following devices:

       1) JPEG
       2) PDF (Portable Document Format)
       3) TIFF (Ghostscript supports a number of tiff devices, Dataplot
          currently uses the "tifflzw" device)
       4) PBM (Portable Bit Map, supports black and white only)
       5) PGM (Portable Grey Map, supports greyscale, but not color)
       6) PPM (Portable Pix Map, supports color)
       7) PNM (Portable Any Map, covers PBM, PGM, PPM)

    If one of these devices is set and a Postscript device is closed,
    then Dataplot invokes Ghostscript to convert the Postscript output
    to the specified device.  The original Postscript file is preserved.
    The new file has the same name with the file extension replaced with
    "jpg", "pdf", "tif", "pbm", "pgm", "ppm", or "pnm" (depending on
    the selected device).

    Note that Ghostscript supports conversion to a wide variety of
    output devices.  The devices selected above were the ones that
    are the most useful in exporting Dataplot graphs to other software
    programs.  Since our purpose for this command was to provide graphics
    formats suitable for input into other programs, we did not add support
    for the printer devices.  If your main interest is simply in printing
    to a non-Postscript device, then run Ghostview after exiting Dataplot
    to print the Postscript file.

    Between the original Postscript and the devices supported using the
    SET POSTSCRIPT CONVERT, it should be possible to import Dataplot
    graphics into most external programs.  In particular, the JPEG and
    PBM formats (PBM, PGM, PPM, and PNM) are supported by most image
    conversion programs.

    Alternatively, you can also use the "convert" program from the
    Image Magick software or the PS2PDF program (part of the Ghostscript
    installation).  See the Note section below for details.

Syntax 1:
    SET POSTSCRIPT CONVERT <device>
    where <device> is one of JPEG, PDF, TIFF, PBM, PGM, PPM, or PNM
          (any other choice is converted to NULL).
 
Syntax 2:
    SET POSTSCRIPT CONVERT <program>
    where <program> is one of GHOSTSCRIPT, CONVERT, or PS2PDF.

Syntax 3:
    SET POSTSCRIPT CONVERT <program> <device>
    where <program> is one of GHOSTSCRIPT, CONVERT, or PS2PDF;
    and   <device> is one of JPEG, PDF, TIFF, PBM, PGM, PPM, or PNM
          (any other choice is converted to NULL).
 
Examples:
    SET POSTRSCRIPT CONVERT PDF
    SET POSTRSCRIPT CONVERT JPEG
    SET POSTRSCRIPT CONVERT PPM
 
Note:
    This command assumes that Ghostscript is installed on your local
    system.  Currently, it is implemented on Unix (this includes Linux,
    Mac OSX, and FreeBSD) and Windows platforms.  It can easily be
    extended to any platform (e.g., VAX VMS) to which Ghostscript has
    been ported.  Contact Alan Heckert (alan.heckert@nist.gov) if
    you have a platform that you would like supported.

    For Unix platforms, Ghostscript is launched with the command

         gs

    If gs is not in your default path, you can enter something like

         set ghostscript path /usr/local/bin

    On Windows platforms, Ghostscript is launched with

         <ghostscript path>\GSWIN32C.EXE

    where <ghostscript path> is the directory defined by the
    SET GHOSTSCRIPT PATH command.  As of the 08/2019 version of
    Dataplot, the default path is

        C:\Program Files\GS\GS9.27\BIN

    If Ghostscript is installed in a different directory (typically the
    "GS9.27" will be different if you have installed a different version
    of Ghostscript), you can specify the correct directory with the command

        SET GHOSTSCRIPT PATH  <path-name>

    Enter HELP GHOSTSCRIPT PATH for details.

    If you have installed the 64-bit version of Ghostscript, enter the
    command

         SET GHOSTSCRIPT VERSION 64

    This will run the command GSWIN64C.EXE instead of GSWIN32C.EXE.

    To reset the 32-bit version, enter

         SET GHOSTSCRIPT VERSION 32

    If you select the CONVERT option, you must have the Image Magick
    software installed on your local platform and the convert program
    should be in your default path.

Note:
    If you use the GHOSTSCRIPT or PS2PDF option on Windows platforms,
    there are two addtional issues to consider.

       1. Dataplot will typically try to run the underlying SYSTEM
          command in "hidden" mode.  In "hidden" mode, the command
          prompt window will not pop up.

          However, if either the program name or the file name
          contains spaces, the hidden mode cannot currently be
          used.  In particular, the path name for the Ghostscript
          directory contains a space (i.e., the "Program Files")

          One solution is to add the following directory to
          your default path

             C:\Program Files\gs\gs9.27\bin

          Change 9.27 to match the version of Ghostscript you have
          installed.  Also, non-English systems will typically have a
          slightly different name for "Program Files".

       2. For the PS2PDF option, the PS2PDF.BAT script is actually
          in the "lib" directory.  In addition, the script calls
          the Ghostscript executable without a path name.  So if
          you want to use PS2PDF, then the following directories
          need to be added to your default path

             C:\Program Files\gs\gs9.27\bin
             C:\Program Files\gs\gs9.27\lib

    To add directories to your default path, do the following

       1. Bring up the Control Panel.
       2. Select "System and Security".
       3. Select "System".
       4. Select "Advanced System Settings".
       5. Select "Environment Variables".

    Then use the "Enviroment Variables" menu to add the needed
    directories.

Note:
    By default, the conversion is performed by Ghostscript.  You can also
    specify the "convert" program that is part of the Image Magick software
    by entering the command

        SET POSTSCRIPT CONVERT CONVERT

    To reset the use of Ghostscript, enter

        SET POSTSCRIPT CONVERT GHOSTSCRIPT

    You can also specify the use of the ps2pdf program to perform the
    conversion.  The ps2pdf program is a batch script file that is
    typically installed as part of the Ghostscript installation.  Linux
    installations will typically have Ghostcript and ps2pdf installed.

    The GHOSTSCRIPT option generates a Ghostscript command to perform the
    conversion, so the GHOSTSCRIPT and PS2PDF options perform essentially
    the same conversion.  The advantage of the PS2PDF option is that it
    has a simpler syntax.  The advantage of the GHOSTSCRIPT option is
    that it is not limited to converting the Postscript to PDF format
    (it also supports JPEG, TIFF, PBM, PBM, PGM, PPM, and PNM).

    The SET GHOSTSCRIPT PATH applies to the PS2PDF option as well.

Note:
    The converted image is created with a density of 72 dots per inch
    in both the horizontal and vertical directions.  You can specify a
    different resolution with the commands

         SET CONVERT DENSITY HORIZONTAL <value>
         SET CONVERT DENSITY VERTICAL   <value>

Note:
    When converting to an image format, you will typically want each
    graph in a separate file.  You can do this as follows:

       SET POSTSCRIPT CONVERT JPEG
       ORIENTATION LANDSCAPE WORDPERFECT
       SET IPL1NA PLOT1.PS
       DEVICE 2 POSTSCRIPT
           ... generate first plot ...
       DEVICE 2 CLOSE
       SET IPL1NA PLOT2.PS
       DEVICE 2 POSTSCRIPT
           ... generate second plot ...
       DEVICE 2 CLOSE

    After these commands are run, you will have the Postscript files
    PLOT1.PS and PLOT2.PS.  In addition, you will have the JPEG
    files PLOT1.jpg and PLOT2.jpg.

    PDF may sometimes be the exception.  Acroread (and other PDF
    viewers) can read PDF files with multiple graphs in them.

Note:
    The CAPTURE HTML <file> command is used to generate Dataplot
    output to a web page.

    If the PDF format is specified and the CAPTURE HTML command
    is activated, Dataplot will generate a link to the PDF file
    in the generated HTML code.  Enter HELP CAPTURE for more
    information about the CAPTURE HTML option

Note:
    On some platforms, Dataplot can generate PNG and JPEG image
    files directly.  Enter HELP GD for details.

Default:
    The default is device is NULL (i.e., no conversion is performed).
 
Synonyms:
    SET OUTPUT DEVICE
 
Related Commands:
    DEVICE xx POSTSCRIPT      = Set the device to Postscript.
    POSTSCRIPT CONVERT        = Specify the device that Postscript
                                output will be converted to.
    PP                        = Print the current plot.
    SET GHOSTSCRIPT PATH      = Set the directory where Ghostscript is
                                installed.
    SET GHOSTVIEW PATH        = Set the directory where Ghostview (and
                                GSPRINT) is installed.
    SET GHOSTSCRIPT PRINTER   = Use Ghostview as the default printer
                                under Windows.
    GD                        = Specify the GD device for generating
                                PNG and JPEG graphics.
 
Applications:
    Graphics Output
 
Implementation Date:
    2003/01
    2007/10: Added support for the "convert" program from ImageMagick
    2009/03: Added support for user specified density
    2019/08: Added support for the "ps2pdf" program
 
Program:
    SET GHOSTSCRIPT PATH /usr/local/src/bin/
    SET POSTSCRIPT CONVERT JPEG
    DEVICE 2 POSTSCRIPT
    PLOT SIN(X) FOR X = -6 0.1 6
    DEVICE 2 CLOSE
    SYSTEM xv dppl1f.jpg
 
-----POSTSCRIPT DEFAULT COLOR (SET)----------------------------------
 
POSTSCRIPT DEFAULT COLOR
 
Name:
    POSTSCRIPT DEFAULT COLOR (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify whether Postscript devices default to black and white
    or to color.
 
Description:
    Postscript devices can be either black and white or color.  
    Since many Postscript printers are black and white, Dataplot
    initializes Postscript devices as black and white when the

       DEVICE <1/2/3> POSTSCRIPT

    command is entered.  After entering this command, you can
    then specify that the Postscript device command is color by
    entering the command

       DEVICE <1/2/3> COLOR ON

    Although this works well enough for DEVICE 2 output, it is
    problematic for DEVICE 3 output.  The DEVICE 3 output contains
    the most recent graph only (by default, in Postscript format).
    The PP command is used within Dataplot to print this DEVICE 3
    output on the default printer.   Dataplot automatically
    opens and closes DEVICE 3 as needed without any explicit
    commands entered by the user.  This makes it difficult to
    know the appropriate time to enter the DEVICE 3 COLOR ON
    command and cumbersome even if you can figure out when to
    enter the command.

    For this reason, we have added the SET POSTSCRIPT DEFAULT COLOR
    command to specify whether the default for Postscript devices
    should be black and white or color.  Although this command
    was motivated by the DEVICE 3 command, it applies to
    DEVICE 1 POSTSCRIPT and DEVICE 2 POSTSCRIPT commands as well.
 
Syntax:
    SET POSTSCRIPT DEFAULT COLOR <ON/OFF>
    where <ON> specifies that Postscript devices will default
          to color and <OFF> specifies that they will default
          to black and white.
 
Examples:
    SET POSTRSCRIPT DEFAULT COLOR ON
    SET POSTRSCRIPT DEFAULT COLOR OFF
 
Default:
    The default is OFF (i.e., Postscript devices default to black
    and white).
 
Synonyms:
    None
 
Related Commands:
    DEVICE xx POSTSCRIPT      = Set the device to Postscript.
    POSTSCRIPT CONVERT        = Specify the device that Postscript
                                output will be converted to.
    PP                        = Print the current plot.
    SET GHOSTSCRIPT PRINTER   = Use Ghostview as the default printer
                                under Windows.
 
Applications:
    Graphics Output
 
Implementation Date:
    2004/6
 
Program:
    SET POSTSCRIPT DEFAULT COLOR ON
    DEVICE 2 POSTSCRIPT
    LINE COLOR BLUE
    PLOT SIN(X) FOR X = -6  0.1  6
    PP
 
-----POSTSCRIPT SHOW FONTS-----------------------------------------
 
POSTSCRIPT SHOW FONTS
 
Name:
    POSTSCRIPT SHOW FONTS
 
Type:
    Output Devices Command
 
Purpose:
    List the available Postscript fonts and the commands to set the
    fonts.
 
Description:
    DATAPLOT supports 34 Postscript fonts.  The Postscript font is
    used whenever hardware characters are generated on a Postscript
    device.  Postscript fonts are publication quality typeset fonts.
    This command is provided as a convenience to easily list the
    available fonts (and the command for setting it).
 
    The sample output is as follows:
 
       POSTSCRIPT FONT: Times-Roman
          SET POSTSCRIPT FONT TROM
          SET POSTSCRIPT TIMES ROMAN
 
    The first line is the name of the font while the next two lines
    give the command for setting the font.
 
Syntax:
    POSTSCRIPT SHOW FONTS
 
Examples:
    POSTSCRIPT SHOW FONTS
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SET POSTSCRIPT FONT   = Specify the Postscript font to use.
    POSTSCRIPT            = Direct graphical output to a Postscript
                            device.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    POSTSCRIPT SHOW FONTS
    SET POSTSCRIPT FONT TROM
 
-----POWCDF (LET)--------------------------------
 
POWCDF
 
Name:
    POWCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the power function cumulative distribution function.
 
Description:
    The cumulative distribution function of the standard
    power distribution is

       F(x,c) = x**c            0 <= x <= 1; c > 0

    The standard power distribution can be generalized with
    lower and upper bound parameters.  If a and be denote the
    lower and upper bounds, then the location and scale
    parameters are:

        location = a
        scale    = b - a

    The general form of the power distribution can then be
    found using the relation

        F(x;c,a,b) = F((x-a)/(b-a);c,0,1)

    If X has a Pareto distribution, then 1/X has a power
    distribution.  The power distribution is also a special
    case of the beta distribution where the second shape
    parameter is equal to 1.

Syntax:
    LET <y> = POWCDF(<x>,<c>,<a>,<b>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the
              interval a to b;
          <c> is a number, parameter, or variable that specifies the
              shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed power function cdf value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If the <a> and <b> parameters are omitted, the default to
    0 and 1, respectively.

Examples:
    LET A = POWCDF(3,1.5)
    LET X2 = POWCDF(X1,C)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POWPDF = Compute the power function probability density function.
    POWPPF = Compute the power function percent point function.
    PARPDF = Compute the Pareto probability density function.
    BETPDF = Compute the beta probability density function.
    GEPPDF = Compute the generalized Pareto probability density
             function.
    EXPPDF = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions", 2nd ed., Johnson, Kotz, and
    Balakrishnan, John Wiley and Sons, 1994 (page 607).

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, John Wiley & Sons, 2000.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    95/4
 
Program:
    TITLE POWER FUNCTION CDF'S (0.1,  0.5, 1, 3, 10)
    PLOT POWCDF(X,0.1) FOR X = 0.01 0.01 1 AND
    PLOT POWCDF(X,0.5) FOR X = 0.01 0.01 1 AND
    PLOT POWCDF(X,1) FOR X = 0.01 0.01 1 AND
    PLOT POWCDF(X,3) FOR X = 0.01 0.01 1 AND
    PLOT POWCDF(X,10) FOR X = 0.01 0.01 1
 
-----POWCHAZ (LET)--------------------------------
 
POWCHAZ
 
Name:
    POWCHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the power function cumulative hazard function.
 
Description:
    The standard form of the cumulative hazard function is:

       H(x,c) = -LOG(1-x**c)      0 <= x <= 1; c > 0

    with c denoting the shape parameter.
 
    The standard power distribution can be generalized with
    lower and upper bound parameters.  If a and be denote the
    lower and upper bounds, then the location and scale
    parameters are:

        location = a
        scale    = b - a

    The general form of the power distribution can then be
    found using the relation

        H(x;c,a,b) = H((x-a)/(b-a);c,0,1)

    If X has a Pareto distribution, then 1/X has a power
    distribution.  The power distribution is also a special
    case of the beta distribution where the second shape
    parameter is equal to 1.

Syntax:
    LET <y> = POWCHAZ(<x>,<c>,<a>,<b>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the
              interval a to b;
          <c> is a number, parameter, or variable that specifies the
              shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed power function cumulative hazard
              value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If the <a> and <b> parameters are omitted, the default to
    0 and 1, respectively.

Examples:
    LET A = POWCHAZ(3,1.5)
    LET X2 = POWCHAZ(X1,C)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POWCDF  = Compute the power function cumulative distribution
              function.
    POWHAZ  = Compute the power function hazard function.
    POWPDF  = Compute the power function probability density
              function.
    POWPPF  = Compute the power function percent point function.
    PARPDF  = Compute the Pareto probability density function.
    BETPDF  = Compute the beta probability density function.
    GEPPDF  = Compute the generalized Pareto probability density
              function.
    EXPPDF  = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions", 2nd ed., Johnson, Kotz, and
    Balakrishnan, John Wiley and Sons, 1994 (page 607).

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, John Wiley & Sons, 2000.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/12
 
Program:
    TITLE POWER FUNCTION CUMULATIVE HAZARD FUNCTIONS (0.1,  0.5, 1, 3, 10)
    PLOT POWCHAZ(X,0.1) FOR X = 0.01 0.01 0.99 AND
    PLOT POWCHAZ(X,0.5) FOR X = 0.01 0.01 0.99 AND
    PLOT POWCHAZ(X,1) FOR X = 0.01 0.01 0.99 AND
    PLOT POWCHAZ(X,2) FOR X = 0.01 0.01 0.99 AND
    PLOT POWCHAZ(X,5) FOR X = 0.01 0.01 0.99
 
-----POWHAZ (LET)--------------------------------
 
POWHAZ
 
Name:
    POWHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the power function hazard function.
 
Description:
    The standard form of the hazard function is:

       h(x,c) = c*x**(c-1)/(1-x**c)      0 <= x < 1; c > 0

    with c denoting the shape parameter.
 
    The standard power distribution can be generalized with
    lower and upper bound parameters.  If a and be denote the
    lower and upper bounds, then the location and scale
    parameters are:

        location = a
        scale    = b - a

    The general form of the power distribution can then be
    found using the relation

        h(x;c,a,b) = (1/(b-a))*h((x-a)/(b-a);c,0,1)

    If X has a Pareto distribution, then 1/X has a power
    distribution.  The power distribution is also a special
    case of the beta distribution where the second shape
    parameter is equal to 1.

Syntax:
    LET <y> = POWHAZ(<x>,<c>,<a>,<b>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the
              interval a to b;
          <c> is a number, parameter, or variable that specifies the
              shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed power function hazard value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If the <a> and <b> parameters are omitted, the default to
    0 and 1, respectively.

 
Examples:
    LET A = POWHAZ(3,1.5)
    LET X2 = POWHAZ(X1,C)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POWCDF  = Compute the power function cumulative distribution
              function.
    POWCHAZ = Compute the power function cumulative hazard
              function.
    POWPDF  = Compute the power function probability density
              function.
    POWPPF  = Compute the power function percent point function.
    PARPDF  = Compute the Pareto probability density function.
    BETPDF  = Compute the beta probability density function.
    GEPPDF  = Compute the generalized Pareto probability density
              function.
    EXPPDF  = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions", 2nd ed., Johnson, Kotz, and
    Balakrishnan, John Wiley and Sons, 1994 (page 607).

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, John Wiley & Sons, 2000.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/12
 
Program:
    TITLE POWER FUNCTION HAZARD FUNCTIONS (0.1,  0.5, 1, 3, 10)
    PLOT POWHAZ(X,0.1) FOR X = 0.01 0.01 0.99 AND
    PLOT POWHAZ(X,0.5) FOR X = 0.01 0.01 0.99 AND
    PLOT POWHAZ(X,1) FOR X = 0.01 0.01 0.99 AND
    PLOT POWHAZ(X,2) FOR X = 0.01 0.01 0.99 AND
    PLOT POWHAZ(X,5) FOR X = 0.01 0.01 0.99
 
-----POWER LAW RANDOM NUMBERS (LET)----------------------------------
 
POWER LAW RANDOM NUMBERS
 
Name:
    POWER LAW RANDOM NUMBERS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate random failure times from a non-homogeneous 
    Poisson process (NHPP) following a power law model.
 
Description:
    If you have internet access, you can see a discussion of the
    NHPP Power Law model by entering the command:

        WEB HANDBOOK NHPP POWER LAW

    The non-homogeneous Poisson process power law model is:

        M(t) = alpha*t**beta     alpha, beta > 0

    where M(t) is the expected number of failures at time
    t.  The random failure times are generated from the
    formula for the interarrival times (i.e., the CDF for
    the waiting time for the next failure given a failure at
    time T):

        F (t) = 1 - EXP(-ALPHA*[(T+t)**BETA-T**BETA]
         T

Syntax:
    LET <y> = POWER LAW RANDUM NUMBERS FOR I = <start> <inc>  <stop> 
    where <start> is the starting row for the random numbers;
          <inc> is the increment for the random numbers;
          <stop> is the stopping row for the random numbers;
          <y> is a variable where the power law random numbers
              are saved.
 
    Typically <start> and <inc> are 1 and <stop> is set to the
    number of random numbers to generate.  If <start> and <inc>
    are not 1, then <y> will still contain <stop> elements, but
    the empty rows will be set to 0.

    The alpha and beta parameters are specified with LET commands
    before entering the POWER LAW RANDOM NUMBERS command as 
    demonstrated in the examples below.

Examples:
    LET ALPHA = 2
    LET BETA = 3
    LET Y = POWER LAW RANDOM NUMBERS FOR I = 1 1 100
 
    LET ALPHA = 1
    LET BETA = 2
    LET Y = POWER LAW RANDOM NUMBERS FOR I = 1 1 1000

    LET ALPHA = 1
    LET BETA = 2
    LET Y = POWER LAW RANDOM NUMBERS FOR I = 2 5 100

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RANDOM NUMBERS     = Generate random numbers from various
                         probability distributions.
    INTERARRIVAL TIME  = Compute the interarrival times of a
                         variable.
    DUANE PLOT         = Generate a Duane plot.
 
Applications:
    Reliability
 
Implementation Date:
    1998/5
 
Program:
    LET ALPHA = 2
    LET BETA = 3
    LET Y = POWER LAW RANDOM NUMBERS FOR I = 1 1 100
    X1LABEL ALPHA = ^ALPHA, BETA = ^BETA
    TITLE AUTOMATIC
    DUANE PLOT Y
 
-----POWPDF (LET)--------------------------------
 
POWPDF
 
Name:
    POWPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the power function probability density function.
 
Description:
    The standard form of the probability density function is:

       f(x,c) = c*x**(c-1)               0 <= x <= 1; c > 0

    where c is a shape parameter.
 
    The standard power distribution can be generalized with
    lower and upper bound parameters.  If a and be denote the
    lower and upper bounds, then the location and scale
    parameters are:

        location = a
        scale    = b - a

    The general form of the power distribution can then be
    found using the relation

        f(x;c,a,b) = (1/(b-a))*f((x-a)/(b-a);c,0,1)

    If X has a Pareto distribution, then 1/X has a power
    distribution.  The power distribution is also a special
    case of the beta distribution where the second shape
    parameter is equal to 1.


Syntax:
    LET <y> = POWPDF(<x>,<c>,<a>,<b>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable in the
              interval a to b;
          <c> is a number, parameter, or variable that specifies the
              shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed power function pdf value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If the <a> and <b> parameters are omitted, the default to
    0 and 1, respectively.

 
Examples:
    LET A = POWPDF(3,1.5)
    LET X2 = POWPDF(X1,C)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POWCDF = Compute the power function cumulative distribution
             function.
    POWPPF = Compute the power function percent point function.
    PARPDF = Compute the Pareto probability density function.
    BETPDF = Compute the beta probability density function.
    GEPPDF = Compute the generalized Pareto probability density
             function.
    EXPPDF = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions", 2nd ed., Johnson, Kotz, and
    Balakrishnan, John Wiley and Sons, 1994 (page 607).

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, John Wiley & Sons, 2000.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    95/4
 
Program:
    TITLE POWER FUNCTION PDF'S (0.1,  0.5, 1, 3, 10)
    PLOT POWPDF(X,0.1) FOR X = 0.01 0.01 1 AND
    PLOT POWPDF(X,0.5) FOR X = 0.01 0.01 1 AND
    PLOT POWPDF(X,1) FOR X = 0.01 0.01 1 AND
    PLOT POWPDF(X,3) FOR X = 0.01 0.01 1 AND
    PLOT POWPDF(X,10) FOR X = 0.01 0.01 1
 
-----POWPPF (LET)--------------------------------
 
POWPPF
 
Name:
    POWPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the power function percent point function.
 
Description:
    The standard form of the power function percent point
    function is

       G(p;c) = p**(1/c)      0 <= p <= 1; c > 0
 
    The standard power distribution can be generalized with
    lower and upper bound parameters.  If a and be denote the
    lower and upper bounds, then the location and scale
    parameters are:

        location = a
        scale    = b - a

    The general form of the power distribution can then be
    found using the relation

        G(p;c,a,b) = loc + scale*G(p;c,0,1)

    If X has a Pareto distribution, then 1/X has a power
    distribution.  The power distribution is also a special
    case of the beta distribution where the second shape
    parameter is equal to 1.

 
Syntax:
    LET <y> = POWPPF(<p>,<c>,<a>,<b>)
              <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, parameter, or variable in the
              interval 0 to 1;
          <c> is a number, parameter, or variable that specifies the
              shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
          <y> is a variable or a parameter (depending on what <p> is)
              where the computed power function ppf value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If the <a> and <b> parameters are omitted, the default to
    0 and 1, respectively.

 
Examples:
    LET A = POWPPF(0.9,3)
    LET X2 = POWPPF(X1,C)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POWCDF = Compute the power function cumulative distribution
             function.
    POWPDF = Compute the power function probability density function.
    PARPDF = Compute the Pareto probability density function.
    BETPDF = Compute the beta probability density function.
    GEPPDF = Compute the generalized Pareto probability density
             function.
    EXPPDF = Compute the exponential probability density function.
 
Reference:
    "Continuous Univariate Distributions", 2nd ed., Johnson, Kotz, and
    Balakrishnan, John Wiley and Sons, 1994 (page 607).

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, John Wiley & Sons, 2000.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    95/5
 
Program:
    TITLE POWER FUNCTION PPF'S (0.5, 1, 3)
    LINE DASH SOLID DOT
    PLOT POWPPF(P,0.5) FOR P = 0 .01 1 AND
    PLOT POWPPF(P,1) FOR P = 0 .01 1 AND
    PLOT POWPPF(P,3) FOR P = 0 .01 1
 
-----PP-------------------------------------------------------
 
PP
 
Name:
    PP
 
Type:
    Support Command
 
Purpose:
    Send the most recent plot to the printer.
 
Description:
    DEVICE 3 (in file DPPL2F.DAT, name may vary on some systems)
    output is closed and re-opened at the beginning of a plot command,
    so only the most recent plot is in the graphics file.
 
Syntax:
    PP
 
Examples:
    PP
 
Note:
    This command is operating system dependent.  It is currently
    supported on the IBM PC and Unix (except Cray UNICOS).  It has
    been coded (but not tested) for VAX/VMS.  The primary requirement
    for supporting it on other systems is the ability to send a
    command to the operating system from a Fortran program.  Contact
    your local site installer to see about adding this capability to
    your version if it does not currently work.
 
Note:
    This command sends the file to the default printer.  On the IBM PC,
    this is LPT1 (i.e., the printer connected to your PC).  For Unix,
    enter the setenv PRINTER command before entering DATAPLOT.
 
Note:
    By default, Postscript output is generated.  To use another
    device, enter the following commands:
        DEVICE 3 CLOSE
        DEVICE 3 <device> <model>
 
Note:
    When generating complex and time consuming plots, you may want to
    suppress the DEVICE 3 output.  Enter the following commands to do
    this:
        DEVICE 3 CLOSE
        DEVICE 3 NULL
 
Note:
    For Postscript devices, DATAPLOT normally generates a blank page
    before the first plot (to avoid problems if diagrammatic graphics
    are done before the first plot).  This can be a bit of a nuisance
    for the PP command since only one plot is printed.  The BLANK
    POSTSCRIPT command is used to control whether this blank page
    is generated (by default, is not for DEVICE 3).
 
    This command does not affect Postscript output sent to device
    2 (use the PRE-ERASE OFF for a similar effect).
 
Default:
    None
 
Synonyms:
    ADD
 
Related Commands:
    / PRINTER   = Re-execute saved commands and send the output to the
                  printer.
    / PSPRINTER = Re-execute saved commands and send the output to the
                  printer in Postscript format.
 
Applications:
    Printing
 
Implementation Date:
    1992/07
 
Program:
    PLOT X**2 FOR X = 1 1 9
    PP
 
-----PPCC PLOT-------------------------------------------------------
 
PPCC PLOT
 
Name:
    ... PPCC PLOT
    ... KOLMOGOROV SMIRNOV PLOT
    ... ANDERSON DARLING PLOT
    ... CHI-SQUARE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a probability plot correlation coefficient (PPCC)
    plot.  Alternatively, generate the plot based on other
    goodness of fit criterion.
 
Description:
    A PPCC plot is a graphical data analysis technique for determining
    that member of the specified distributional family which provides
    a "best" distributional fit to the data.

    The PPCC plot is based on the following two ideas:

        1) The "straightness" of the probability plot is a good measure
           of distributional fit.  That is, the "best" distributional
           fit is the one with the most linear probability plot.

        2) The correlation coefficient of the points on the
           probabability plot is a good measure of the "straightness"
           (i.e., linearity) of the probability plot.

    The PPCC plot is formed by selecting a value of the shape parameter,
    generating the probability plot (this probability plot is not
    actually graphed), and then computing the correlation coefficient
    of the resulting probability plot.  The PPCC plot then consists of:

       Vertical   axis = probability plot correlation coefficient
                         value for the given value of the shape parameter;
       Horizontal axis = distributional family parameter value (i.e.,
                         the value of the shape parameter.

    The value of the distributional parameter (on the horizontal axis)
    which corresponds to the maximum of the PPCC plot curve (on the
    vertical axis) is, of course, of interest since it indicates the
    best-fit member of the family.

    The PPCC PLOT has been extended to support the following
    additional goodness of fit statistics:

       1) the Kolmogorov-Smirnov goodness of fit statistic;

       2) the Anderson-Darling goodness of fit statistic;

       3) the chi-square goodness of fit statistic.

    For these alternative measures of goodness of fit, we follow a
    similar procedure.  That is, we fix a value of the shape
    parameter, generate the corresponding probability plot in the
    background to obtain estimates for location and scale, and then
    compute the goodness of fit statistic based on these parameters.
    For these goodness of fit statistics, we are looking for the
    minimum value of the statistic rather than the maximum value of
    the statistic.

    Some advantages of the PPCC plot as a fitting technique are:

        1) The probability plot is invariant with respect to location
           and scale.  This means that the fundamental linearity of the
           probability plot does not depend on the values of the
           location and shape parameters (i.e., we could plug-in
           any arbitrary values for them and the probability plot
           would still have the same linearity as measured by the
           ppcc statistic.  The property follows from the fact that

               G(p;loc,scale,shape) = loc + scale*G(p;0,1,shape)

           where G denotes the percent point function of the
           specified distribution.  So for the probability plot,
           using different values for loc and scale will change the
           scale on the x-axis, but not the linearity.

           Once we determine the optimal value of the shape parameter
           from the PPCC plot, we can generate the corresponding
           probability plot.  The intercept and slope of line fit to
           the probability provide valid estimates of location and
           scale (the Dataplot probability plot is designed in such a
           way that this is true).

           Note: the Anderson-Darling, Kolmogorv-Smirnov, and
                 chi-square variants are based on the cumulative
                 distribution function and do not share this invariance
                 property.  However, we can still use the underlying
                 probability plot to obtain estimates of location and
                 scale for a given value of the shape parameter.

        2) The probability plot, and thus the PPCC plot, only depends on
           the percent point function.  That is, if we know how to
           compute the percent point function, we can use the
           PPCC plot/probability plot to estimate the parameters of
           the distribution.

           The Anderson-Darling, Kolmogorov-Smirnov, and chi-square
           variants also depend on computing the cumulative
           distribution function.

        3) The PPCC plot can show the sensitivity of the shape parameter.
           That is, it can show what neighborhood of the parameter
           estimate is likely to produce a reasonably straight
           probability plot.

        4) The PPCC plot can be applied to binned data.

            The chi-square variant can also be applied to binned data.
            Currently, the Anderson-Darling and Kolmogorov Smirnov
            variants cannot be applied to binned data.

        5) The PPCC plot can be applied to censored data.

           A censored PPCC plot is generated by finding the value
           of the shape parameter that results in the maximum
           correlation coefficient of the censored probability plot.
           For details on how the censored probablity plot is
           generated, enter the command

              HELP PROBABILITY PLOT

           The censoring variable should contain a 1 to indicate
           a failure time and a 0 to indicate a censoring time.
           The censored PPCC plot is not suppported for binned data.

           The censoring option is not currently supported by the
           Anderson-Darling, Kolmogorov-Smirnov, and chi-square
           variants of the plot.

    Some disadvantages of the PPCC plot as a fitting technique are:

        1) The PPCC plot (and its variants) do not have the
           mathematical optimality properties that analytic
           methods such as maximum likelihood have.

        2) If the percent point function is expensive to compute
           (e.g., if it involves the numerical inversion of a rather
           complicated cumulative distribution function), the ppcc
           plot can be slow to generate.  These types of percent
           point functions may also have convergence problems.  

           In these cases, the SET PPCC PLOT DATA POINTS may be
           helpful in reducing the computational burden.  See the
           Note section below.

        2) The PPCC plot does not produce interval estimates for the
           parameters.

           The bootstrap provides a method for generating these
           interval estimates.  For details, enter

               HELP DISTRIBUTIONAL BOOTSTRAP

        3) Heavy-tailed distributions may have very high variability
           in the extremes of the data.  This can sometimes lead to
           poor discrimination in the plot. 

           In our experience, the Anderson-Darling and
           Kolmogorov-Smirnov variants of the plot may perform better
           for these cases.

        4) If a shape parameter behaves much like a scale or
           location parameter, the PPCC plot may not discriminate
           well.

           The Anderson-Darling and Kolmogorov-Smirnov variants have
           the option of fixing the values of the location and scale
           parameters.  This can sometimes be useful in these cases.

        5) The PPCC plot does not generate smooth curves for discrete
           distributions due to the discreteness of the percent point
           function.  For discrete distributions, the chi-square
           variant of the plot typically produces smoother plots.

        6) The PPCC plot does not extend well to more than one
           shape parameter.

           Dataplot has extended the PPCC plot to distributions with
           two shape parameters.  Dataplot supports two formats for
           the PPCC plot with two shape parameters:

           1) As in the one shape parameter case, the Y axis will
              contain the value of the correlation coefficient.  The
              X axis will contain the value of the second shape
              parameter.  Each value of the first shape parameter will
              be represented by a separate trace (i.e., curve) on the
              plot.

              To change the order of the shape parameters in the
              above format, enter the command

                 SET PPCC PLOT AXIS ORDER REVERSE

              To restore the default order, enter the command
              
                 SET PPCC PLOT AXIS ORDER DEFAULT

           2) Alternatively, you can generate a 3D wireframe plot.

           You can specify which format to use with the command

               SET PPCC FORMAT <TRACE/3D>

    The PPCC plot now supports two different types of grouping.

       1) Some data sets are collected in binned format.  That is,
          the values for the data are split into intervals and the
          number of occurences of the data within each interval are
          are counted.

          Dataplot supports either equal sized bins (the bin
          variable contains the mid-point of the bin) or
          unequal size bins (two bin variables are specified:
          one contains the lower limit for the bins and the other
          contains the upper limits for the bins).

       2) The PPCC plot also supports the case where there are
          multiple batches of data.  In this case, a separate
          ppcc curve is drawn for each batch of data (for unbinned
          data a curve will also be drawn for the full data
          set).  We refer to this as the "replication" case
          below.  Replication can be used for either the raw data
          case or the binned data case.

          This form is useful for the case where we want to
          know if different batches of data can be modeled
          with a common shape parameter.  One example of this
          is accelerated testing where Weibull models should
          have a common shape parameter at different stress levels
          if a linear accelaraton model is valid.

    PPCC plots are available for the following continuous distributional
    families (with the distributional parameter in parentheses) with one
    shape parameter:

      1) Weibull                         (gamma)
      2) double weibull                  (gamma)
      3) inverted weibull                (gamma)
      4) gamma                           (gamma)
      5) double gamma                    (gamma)
      6) log gamma                       (gamma)
      7) inverted gamma                  (gamma)
      8) Wald                            (gamma)
      9) fatigue life                    (gamma)
     10) Pareto                          (gamma)
     11) Pareto second kind              (gamma)
     12) generalized Pareto              (gamma)
     13) generalized half logistic       (gamma)
     14) extreme value type 2            (gamma)
     15) generalized extreme value       (gamma)
     16) extreme value                   (gamma, combines Weibull,
                                         extreme value type 2)
     17) geometric extreme exponential   (gamma)
     18) Tukey lambda                    (lambda)
     19) skew normal                     (lambda)
     20) skew double exponential         (lambda)
     21) t                               (nu)
     22) folded t                        (nu)
     23) chi-squared                     (nu)
     24) chi                             (nu)
     25) generalized logistic            (alpha)
     26) generalized logistic type 2     (alpha)
     27) generalized logistic type 3     (alpha)
     28) generalized logistic type 5     (alpha)
     29) log double exponential          (alpha)
     30) error                           (alpha)
     31) McLeish                         (alpha)
     32) lognormal                       (sd)
     33) power-normal                    (p)
     34) Von Mises                       (b)
     35) reciprocal                      (b)
     36) log-logistic                    (delta)
     37) wrapped cauchy                  (c)
     38) power function                  (c)
     39) Bradford                        (beta)
     40) Topp and Leone                  (beta)
     41) asymmetric double exponential   (k)
 
    PPCC plots are available for the following continuous distributional
    families (with the distributional parameter in parentheses) with two
    shape parameters:

      1) inverse Gaussian                (gamma, mu)
      2) reciprocal inverse gaussian     (gamma, mu)
      3) generalized gamma               (gamma, c)
      4) exponentiated Weibull           (gamma, theta)
      5) exponential power               (alpha, beta)
      6) beta                            (alpha, beta)
      7) inverted beta                   (alpha, beta)
      8) beta-normal                     (alpha, beta)
      9) asymmetric log double expo      (alpha, beta)
     10) generalized Topp and Leone      (alpha, beta)
     11) reflected gene Topp and Leone   (alpha, beta)
     12) log beta                        (alpha, beta, assume
                                         c and d known)
     13) two-sided power                 (theta, n)
     14) Johnson SU                      (alpha1, alpha2)
     15) Johnson SB                      (alpha1, alpha2)
     16) alpha                           (alpha1, alpha2)
     17) Gompertz                        (c, b)
     18) g and h                         (g, h)
     19) F                               (nu1, nu2)
     20) log skew normal                 (lambda, sd)
     21) power lognormal                 (nu, sd)
     22) folded normal                   (mu, sd)
     23) folded Cauchy                   (loc, scale)
     24) skew t                          (nu, lambda)
     25) noncentral t                    (nu, lambda)
     26) noncentral chi-square           (nu, lambda)
     27) truncated exponential           (m, sd, assume truncation point,
                                         X0, is known)
     28) generalized Tukey-Lambda        (lambda3, lambda4)
     29) Gompertz-Makeham                (eta, zeta)
     30) generalized asymmetric Laplace  (k, tau or mu, tau)
     31) generalized McLeish             (alpha, a)
     32) trapezoid                       (b, c, assume a and d known)
     33) generalized logistic type 4     (p, q)

    PPCC plots are available for the following discrete distributional
    families (with the distributional parameter in parentheses):

      1) geometric               (p)
      2) Yule                    (p)
      3) Poisson                 (lambda)
      4) binomial                (p, assume n known)
      5) logarithmic series      (theta)
      6) Consul                  (theta or m)
      7) zeta                    (alpha)
      8) Hermite                 (alpha, beta)
      9) beta geometric          (alpha, beta)
     10) beta-binomial           (alpha, beta assume n known)
     11) Katz                    (alpha, beta)
     12) negative binomial       (k, p)
     13) zipf                    (alpha, n)
     14) discrete Weibull        (beta, q)
     15) Borel-Tanner            (lambda, k)
     16) Lagrange Poisson        (lambda, theta)
     17) Polya-Aeppli            (theta, p)
     18) lost games              (p, n)
     19) generalized loga series (theta, beta)
     20) geeta                   (theta, beta or mu, beta)
     21) generalized lost games  (p, a, assume j known)

    The percent point function for the discrete distributions is a
    step function (since X is restricted to integer values).  This can
    result in non-smooth ppcc and probability plots.  For discrete
    distributions, the KS PLOT (which will plot the minimum value
    of chi-square statistic) is recommended over the PPCC PLOT as
    long as the sample size is reasonably large.

Syntax 1:
    <family>  PPCC PLOT  <y>   <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of raw data values under analysis;
          <family> is one of the distributions listed above:
              WEIBULL, DOUBLE WEIBULL, INVERTED WEIBULL,
              GAMMA, DOUBLE GAMMA, LOG GAMMA, INVERTED GAMMA,
              WALD, FATIGUE LIFE, PARETO, PARETO SECOND KIND,
              GENERALIZED PARETO, GENERALIZED HALF LOGISTIC,
              FRECHET (for extreme value type 2),
              GENERALIZED EXTREME VALUE, EXTREME VALUE,
              GEOMETRIC EXTREME EXPONENTIAL,
              TUKEY LAMBDA, SKEW NORMAL, T, FOLDED T,
              CHI-SQUARE, CHI, GENERALIZED LOGISTIC,
              LOG DOUBLE EXPONENTIAL, ERROR, LOGNORMAL,
              POWER NORMAL, VON MISES, RECIPROCAL, LOG LOGISTIC,
              WRAPPED CAUCHY,
              INVERSE GAUSSIAN, RECIPROCAL INVERSE GAUSSIAN,
              GENERALIZED GAMMA, EXPONENTIATED WEIBULL,
              EXPONENTIAL POWER, BETA, INVERTED BETA,
              TWO SIDED POWER, JOHNSON SU, JOHNSON SB, ALPHA,
              GOMPERTZ, G AND H, F, LOG SKEW NORMAL,
              POWER LOGNORMAL, FOLDED NORMAL,
              FOLDED CAUCHY, SKEW T, NONCENTRAL T,
              GEOMTRIC, YULE, POISSON, LOGARITHMIC SERIES,
              HERMITE, BETA BINOMIAL, NEGATIVE BINOMIAL,
              WARING
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the raw data case.

    Note that the response variable can also be a matrix.  If a matrix
    name is encountered, a ppcc plot  will be drawn for all the values
    in the matrix.

    The syntax PPCC PLOT can be replaced with ANDERSON DARLING PLOT,
    KOLMOGOROV SMIRNOV PLOT, or  CHI-SQUARE PLOT to generate the
    Anderson-Darling, Kolmogorov-Smirnov, and chi-square variants of
    the plot, respectively.
 
Syntax 2:
    <family>  PPCC  PLOT  <y>  <x>   <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of pre-computed frequencies;
          <x> is the variable of distinct values for the variable
              under analysis;
          <family> is one of the families listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the binned data case where the bins
    are defined by the mid-points of each bin.

    The syntax PPCC PLOT can be replaced with CHI-SQUARE PLOT to
    generate the chi-square variant of the plot.  This syntax is
    not supported for the Anderson-Darling and Kolmogorov-Smirnov
    variants of the plot.
 
Syntax 3:
    <family>  PPCC  PLOT  <y>  <xlow>  <xhigh>
                          <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of pre-computed frequencies;
          <xlow> is the variable containing the lower limits for the
              bins;
          <xhigh> is the variable containing the upper limits for the
              bins;
          <family> is one of the families listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the binned data case where the bins
    are defined by the lower and upper limits of the bins (i.e.,
    the bins can be of unequal width).

    The syntax PPCC PLOT can be replaced with CHI-SQUARE PLOT to
    generate the chi-square variant of the plot.  This syntax is
    not supported for the Anderson-Darling and Kolmogorov-Smirnov
    variants of the plot.
 
Syntax 4:
    <family>  CENSORED PPCC PLOT  <y>  <x>
                             <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of raw data values under analysis;
          <x> is the censoring variabe;
          <family> is one of the distributions listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the raw data case where there is
    censoring.  A value of 1 indicates a failure time and a value
    of 0 indicates a censoring time.

    Censoring is not supported for discrete disributions or grouped
    data.  It is also not supported for the Anderson-Darling,
    Kolmogorov-Smirnov, and chi-square variants of the plot.
 
Syntax 5:
    <family>  CENSORED PPCC  PLOT  <y>  <censor>  <x>
                                   <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of pre-computed frequencies;
          <censor> is the censoring variabe;
          <x> is the variable of distinct values for the variable
              under analysis;
          <family> is one of the families listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where we have frequency (binned)
    data with censoring.  The bins are defined by their mid-points.
    When a particular bin has both censored and uncensored data,
    there will be 2 rows with the same value for <x>.

    A value of 1 indicates a failure time and a value of 0 indicates
    a censoring time.

    Censoring is not supported for discrete disributions or grouped
    data.  It is also not supported for the Anderson-Darling,
    Kolmogorov-Smirnov, and chi-square variants of the plot.

Syntax 6:
    <family>  CENSORED PPCC  PLOT  <y>  <censor>  <xlow>  <xhigh>
                             <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of pre-computed frequencies;
          <censor> is the censoring variabe;
          <xlow> is the variable containing the lower limits for the
              bins;
          <xhigh> is the variable containing the upper limits for the
              bins;
          <family> is one of the families listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where we have frequency (binned)
    data with censoring.  The bins are defined by their lower and upper
    limits.  This syntax allows bins with unequal widths.
    When a particular bin has both censored and uncensored data,
    there will be 2 rows with the same values for <xlow> and <xhigh>.

    A value of 1 indicates a failure time and a value of 0 indicates
    a censoring time for the censoring variable.

    Censoring is not supported for discrete disributions or grouped
    data.  It is also not supported for the Anderson-Darling,
    Kolmogorov-Smirnov, and chi-square variants of the plot.

Syntax 7:
    <family>  REPLICATED PPCC PLOT  <y>  <x1> ... <xk>
                             <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of raw data values under analysis;
          <x1> ... <xk> is a list of one to two group id variables;
          <family> is one of the distributions listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The group-id variables are cross-tabulated and a ppcc
    plot will be generated for each distinct combination of values
    for the group-id variables.  These plots will be overlaid on the
    same plot.
 
    The syntax PPCC PLOT can be replaced with ANDERSON DARLING PLOT,
    KOLMOGOROV SMIRNOV PLOT, or  CHI-SQUARE PLOT to generate the
    Anderson-Darling, Kolmogorov-Smirnov, and chi-square variants of
    the plot, respectively.

Syntax 8:
    <family>  CENSORED REPLICATED PPCC PLOT  <y>  <x>  <x1> .... <xk>
                             <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of raw data values under analysis;
          <x> is the censoring variabe;
          <x1> ... <xk> is a list of one to two group id variables;
          <family> is one of the distributions listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The group-id variables are cross-tabulated and a ppcc
    plot will be generated for each distinct combination of values
    for the group-id variables.  These plots will be overlaid on the
    same plot.
 
    Censoring is not supported for discrete disributions or grouped
    data.  It is also not supported for the Anderson-Darling,
    Kolmogorov-Smirnov, and chi-square variants of the plot.

Syntax 9:
    <family>  REPLICATED GROUPED PPCC  PLOT  <y>  <x>  <x1> ... <xk>
                          <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of pre-computed frequencies;
          <x> is the variable of distinct values for the variable
              under analysis;
          <x1> ... <xk> is a list of one to two group id variables;
          <groupid> is a group id variable;
          <family> is one of the families listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the binned data case where there are
    multiple batches of data.  The bins are defined by the mid-points
    of each bin and there are multiple batches of data.

    The syntax PPCC PLOT can be replaced with CHI-SQUARE PLOT to
    generate the chi-square variant of the plot.  This syntax is
    not supported for the Anderson-Darling and Kolmogorov-Smirnov
    variants of the plot.

Syntax 10:
    <family>  REPLICATED UNEQUAL GROUPED PPCC  PLOT
                         <y>  <xlow>  <xhigh>  <x1> ... <xk>
                         <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of pre-computed frequencies;
          <xlow> is the variable containing the lower limits for the
              bins;
          <xhigh> is the variable containing the upper limits for the
              bins;
          <x1> ... <xk> is a list of one to two group id variables;
          <family> is one of the families listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the binned data case where there are
    multiple batches of data.  The bins are defined by the lower and
    upper limits of the bins (i.e., the bins can be of unequal width).

    The syntax PPCC PLOT can be replaced with CHI-SQUARE PLOT to
    generate the chi-square variant of the plot.  This syntax is
    not supported for the Anderson-Darling and Kolmogorov-Smirnov
    variants of the plot.

Syntax 11:
    <family>  MULTIPLE PPCC PLOT  <y1> ... <yk>
                             <SUBSET/EXCEPT/FOR/qualification>
    where <family> is one of the distributions listed above;
          <y1> ... <yk> is a list of response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the response variables can also be matrices.  If a
    matrix name is encountered, a ppcc plot  will be drawn for
    all the values in the matrix.  For multiple response variables,
    the ppcc plots will be overlaid on the same plot.

    The syntax PPCC PLOT can be replaced with ANDERSON DARLING PLOT,
    KOLMOGOROV SMIRNOV PLOT, or  CHI-SQUARE PLOT to generate the
    Anderson-Darling, Kolmogorov-Smirnov, and chi-square variants of
    the plot, respectively.

Examples:
    LAMBDA PPCC PLOT X
    T PPCC PLOT X
    EXTREME VALUE TYPE 2 PPCC PLOT X
    POISSON PPCC PLOT X
    LAMBDA PPCC PLOT F X
    T PPCC PLOT F X
    EXTREME VALUE TYPE 2 PPCC PLOT F X
    POISSON PPCC PLOT F X
 
Note:
    The PPCC is not the only goodness of fit criterion that
    can be used.  The following additional options are available:

        KOLMOGOROV-SMIRNOV PLOT (or KS PLOT)
        ANDERSON DARLING PLOT   (or AD PLOT)
        CHI-SQUARE PLOT         (or CHISQUARE PLOT)

    Currently, these alternatives are limited to the uncensored
    case.  In addition, the KS PLOT and AD PLOT are restricted to
    the raw data case and the CHI-SQUARE PLOT is restricted to
    the binned data case.

    Note that the PPCC method is invariant to location and scale.
    This basically means that we can use the underlying probability
    plot to estimate the location and scale parameters.

    These other methods are not invariant to location and scale.
    By default, we still use the estimates from the underlying
    probability plot to estimate location and scale.  Although
    these estimates may not be "optimal", they should at least
    be reasonable.  However, you can fix the estimates of location
    and scale by entering the commands

        LET KSLOC   = <value>
        LET KSSCALE = <value>

    These apply to the Kolmogorov-Smirnov, Anderson-Darling, and
    chi-square variants of the plot.

Note:
    For information on how the Kolmogorov-Smirnov, Anderson-Darling,
    and chi-square goodness of fit statistics are computed, enter

        HELP GOODNESS OF FIT

Note:
    The chi-square variant of the plot is most frequently used when the
    data are received in pre-binned form (for raw data, the PPCC,
    Anderson-Darling or Kolmogorov-Smirnov variants are typically
    preferred).  However, you can use the chi-square test for raw data
    (you typically will want to have a reasonably large data set before
    doing this).  For raw data, you can specify the binning with the
    commands CLASS WIDTH, CLASS LOWER, and CLASS UPPER.  The default
    class width is 0.3 times the sample standard deviation.  To
    specify other default algorithms, enter

         HELP HISTOGRAM CLASS WIDTH

    The chi-square test is sensitive to the choice of bins.  There is no
    optimal choice for the bin width (since the optimal bin width
    depends on the distribution).  Most reasonable choices should
    produce similar, but not identical, results.

    For the chi-square approximation to be valid, the expected frequency
    should be at least 5.  The chi-square approximation may not be valid
    for small samples, and if some of the counts are less than five, you
    may need to combine some bins in the tails.

Note:
    The range of parameter is determined automatically.  However, if
    you wish to restrict the range, you can specify the lower and upper
    limits by appending a 1 or 2 to the parameter name and assigning
    a value.  For example, to restrict a Weibull ppcc plot to values
    0.5 and 20, do the following:

       LET GAMMA1 = 0.5
       LET GAMMA2 = 20
       WEIBULL PPCC PLOT Y

    A common use of this is to obtain a refinement of the estimate
    of the shape parameter.  That is, an initial iteration (typically
    just the default values of the parameter) is used to identify
    the appropriate neighborhood of the optimal value of the shape
    parameter.  Then a second iteration of the PPCC PLOT is generated
    with the parameter restricted to a much narrower range of values.
    Although this iteration can be repeated as many times as you
    like, for practical purposes a two iterations is typically sufficient.

Note:
    The PPCC PLOT automatically saves several parameters.  The MAXPPCC
    parameter contains the maximum correlation that was computed and
    the SHAPE parameter contains the value of the estimated
    distributional parameter (e.g., GAMMA for the Weibull distribution)
    that corresponds to MAXPPCC.
 
    In the case of two shape parameters, these are saved as SHAPE1 and
    SHAPE2.

Note:
    For the truncated exponential distribution, we assume that the
    truncation parameter, X0, is known.  To set this value, enter

        LET X0 = <value>

    before generating the ppcc plot.

    For the noncentral t and noncentral chi-square distributions,
    we can fix the value of the degrees of freedom parameter to a
    single value.  In this case, the ppcc plot reverts to a
    one shape parameter plot.  Enter the commands

        LET NU1 = <value>
        LET NU2 = <value>

    where <value> is the same for NU1 and NU2.
 
Note:
    The SET MINMAX command can be used to specify a minimum or maximum
    Weibull distribution.  A value of 1 specifies a maximum Weibull
    distribution and a value of 2 specifies a minimum Weibull
    distribution.
 
Note:
    When the percent point function is expensive to compute, the
    PPCC plot can take a long time to generate.  Two approaches
    to this are:

       1) You can bin the data before generating the PPCC plot.

       2) As an alternative to binning, you can use the command

             SET PPCC PLOT DATA POINTS <value>

          With this command, Dataplot will generate <value> equally
          spaced percentiles of the data.  The PPCC plot is then
          generated on these percentiles.

          If the number of data points in the response variable
          is less than <value>, then the full data set is used.

          The minimum number for <value> is 25.  Numbers in the
          range 50 to 200 are typically used.
          
Note:
    In the one shape parameter case, 50 values of the shape
    parameter are used.  For the two shape parameter case, the
    number of values used is dependent on the specific distribution.
    Typically, between 25 and 50 values are used in each direction.

    You can modify the number values used for the shape parameters
    by entering the command

        SET PPCC PLOT AXIS POINTS  <val1>  <val2>

    where <val1> is the number of values for the first shape
    parameter and <val2> is the number of values for the second
    shape parameter.

    There are two typical uses for this command:

       1) For distributions with a fast percent point function
          (e.g., the Weibull), you can increase the number of values
          in order to generate a more accurate estimate.

       2) For distributions with slow percent point functions,
          you might want to decrease the number of points in order
          to increase the speed of the PPCC plot.

Note:
    For discrete distributions, the data will typically consist of
    integers.  In this case, it is helpful to group the data based
    on these integer values.  The following code shows the
    recommended way for doing this:

      LET YLOW = MINIMUM Y
      LET YUPP = MAXIMUM Y
      LET YLOW = YLOW - 0.5
      CLASS LOWER YLOW
      LET YUPP = YUPP + 0.5
      CLASS UPPER YUPP
      CLASS WIDTH = 1
      LET Y2 X2 = BINNED Y
      LET LAMBDA = 4.2
      POISSON PPCC PLOT Y2 X2
      POISSON KS PLOT Y2 X2

    This will center the bins around the integer values and will
    cover the first and last class.

    In this case, the KS PLOT syntax will generate a plot that
    shows the minimum value of the chi-square statistic.  It is
    usually recommended that the minimum bin size be at least 5 in
    order for the chi-square goodness of fit to generate accurate
    critical values.  You can automatically combine bins with the
    command

       LET MINSIZE = <value>
       LET Y3 XLOW XHIGH = COMBINE FREQUENCY TABLE Y2 X2

Note:
    For the PPCC PLOT and the KS PLOT, the location and scale
    parameters are estimated via the probability plot.  For
    long-tailed distributions, more accurate estimates may be
    obtained by applying a biweight fit of the probability plot.
    To specify this option, enter the command

         SET PPCC PLOT LOCATION SCALE BIWEIGHT

    To restore the use of the regular least squares estimates
    of location and scale, enter

         SET PPCC PLOT LOCATION SCALE DEFAULT

    This option is primarily for the KS PLOT.  Since the
    PPCC PLOT is invariant to location and scale, we can
    simply wait to compute the biweight location and scale
    on the final probability plot.  However, the KS PLOT is
    not invariant for location and scale and for long-tailed
    distributions this option can sometimes lead to improved
    estimates for the parameters.

Note:
    The TO syntax is supported for the PPCC PLOT command.
    It is most useful for the MULTIPLE version of the command.

Note:
    The chi-square variant of the plot can sometimes produce very
    large numbers.  To improve the plot resolution for the smaller
    values of the chi-square statistic (which is the area of interest)
    you can provide a truncation value (i.e., values of the chi-square
    statistic greater than the truncation value will be set to the
    truncation value), enter the command

        SET CHISQUARE LIMIT <value>

Note:
    For the PPCC PLOT command, Dataplot fits a least squares line
    to the points on the underlying probability plot.  For the
    AD PLOT, KS PLOT, and CHI-SQUARE PLOT variants, this least
    squares fit is used to obtain estimates for the location and
    scale parameters.

    Alternatively, you can specify that Dataplot fit a robust regression
    using the biweight method by entering the command

        SET PPCC PLOT LOCATION SCALE BIWEIGHT

    To reset the default of non-robust least squares, enter

        SET PPCC PLOT LOCATION SCALE DEFAULT

    In our experience, this option can be useful for heavy tailed
    distributiuons such as the SLASH and CAUCHY distributions.

Default:
    None
 
Synonyms:
    AD PLOT is a synonym for ANDERSON DARLING PLOT
    KS PLOT is a synonym for KOLMOGOROV SMIRNOV PLOT

    FRECHET and EV2 are synonyms for EXTREME VALUE TYPE 2.

    LAMBDA PPCC PLOT and TUKEY PPCC PLOT are synonyms for TUKEY LAMBDA
    PPCC PLOT.

    STUDENT T PPCC PLOT is a synonym for T PPCC PLOT.

    The CHISQUARE term can be specified as CHISQUARE or CHI SQUARE.

    FL PPCC PLOT, BRIN SAUNDERS PPCC PLOT, and SAUNDERS BRIN are
    synonyms for FATIGUE LIFE PPCC PLOT.

    IG PPCC PLOT is a synonym for INVERSE GAUSSIAN PPCC PLOT.

    RIG PPCC PLOT is a synonym for RECIPROCAL INVERSE GAUSSIAN PPCC
    PLOT.

    GEP PPCC PLOT and GP PPCC PLOT are synonyums for GENERALIZED
    PARETO PLOT.
 
    LOGNORMAL PPCC PLOT and LOG-NORMAL PPCC PLOT are synonyms for
    LOG NORMAL PPCC PLOT.

    POWER LOG-NORMAL PPCC PLOT and POWER LOGNORMAL PPCC PLOT are
    synonyms for POWER LOG NORMAL PPCC PLOT.

    VONMISES PPCC PLOT and VON-MISES PPCC PLOT are synonyms for
    VON MISES PPCC PLOT.

    LOGLOGISTIC PPCC PLOT and LOG-LOGISTIC PPCC PLOT are synonyms for
    LOG LOGISTIC PPCC PLOT.

    SKEW LAPLACE PPCC PLOT is a synonym for
    SKEW DOUBLE EXPONENTIAL PPCC PLOT.

    ASYMMETRIC LAPLACE PPCC PLOT is a synonym for
    ASYMMETRIC DOUBLE EXPONENTIAL PPCC PLOT.

Related Commands:
    PROBABILITY PLOT   = Generates a probability plot.
    FREQUENCY PLOT     = Generates a frequency plot.
    HISTOGRAM          = Generates a histogram.
    PIE CHART          = Generates a pie chart.
    PERCENT POINT PLOT = Generates a percent point plot.
    PLOT               = Generates a data or function plot.
 
Reference:
    James J. Filliben (1975), "The Probability Plot Correlation
    Coefficient Test for Normality," Technometric, Vol. 17, No. 1.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    Pre-1987
    1990/5: Implemented IG, WALD, RIG, FL distributions.
    1993/12: Implemented GENERALIZED PARETO distribution.
    1995/5: Implemented LOGNORMAL, POWER NORMAL, POWER LOGNORMAL,
            POWER FUNCTION, CHI, VON MISES, and LOG LOGISTIC
            distributions implemented 95/5.
    2001/10: Implemented a number of 2 shape parameter distributions.
    2002/5: Implemented TWO-SIDED POWER distribution.
    2003/5: Implemented ERROR distribution.
    2004/1: Implemented FOLDED T, SKEWED T, SKEWED NORMAL, G AND H,
            INVERTED BETA distributions.
    2004/1: Support for additional two shape parameter distributions.
    2004/5: Added support for the SET PPCC FORMAT command
    2004/5: Fixed a number of bugs in various distributions.
    2004/5: Fixed a number of bugs in various distributions.
    2004/6: Implemented SKEW DOUBLE EXPONENTIAL, ASYMMETRIC DOUBLE
            EXPONENTIAL, MAXWELL
    2004/7: Implemented Meeker re-parametrization for GOMPERTZ MAKEHAM
    2004/9: Implemented GENERALIZED ASYMETRIC LAPLACE, BINOMIAL,
            MCLEISH, GENERALIZED MCLEISH 
    2004/9: Implemented SET PPCC PLOT DATA POINTS
    2004/9: Implemented SET PPCC PLOT AXIS POINTS
    2004/9: Implemented SET PPCC PLOT AXIS ORDER
    2004/10: Implemented CENSORED case
    2005/5: Implemented REPLICATION case
    2005/5: Implemented binned case where bins are specified by
            the lower and upper limits (i.e., unequal width bins)
    2007/2: Implemented SET PPCC PLOT BIWEIGHT LOCATION SCALE
    2007/2: Implemented a additional distributions
    2009/10: Support for matrix arguments and TO syntax
    2009/10: Support for MULTIPLE and REPLICATION options
    2009/10: Support for ANDERSON DARLING variation

Program 1:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    MULTIPLOT SCALE FACTOR 1.5
    TITLE AUTOMATIC
    X1LABEL THEORETICAL VALUE
    Y1LABEL DATA VALUE
    TITLE OFFSET 2
    X1LABEL DISPLACEMENT 10
    Y1LABEL DISPLACEMENT 14
    CHAR X
    LINE BLANK
    JUSTIFICATION RIGHT
    .
    LET LAMBDA = 1.5
    LET Y = TUKEY LAMBDA RANDOM NUMBERS FOR I = 1 1 100
    TUKEY LAMBDA PPCC PLOT Y
    MOVE 82 30
    TEXT LAMBDA = ^SHAPE
    MOVE 82 25
    TEXT PPCC = ^MAXPPCC
    .
    LET NU = 4
    LET Y = T RANDOM NUMBERS FOR I = 1 1 100
    T PPCC PLOT Y
    MOVE 82 30
    TEXT NU = ^SHAPE
    MOVE 82 25
    TEXT PPCC = ^MAXPPCC
    .
    LET GAMMA = 2.3
    LET Y = WALD RANDOM NUMBERS FOR I = 1 1 100
    WALD PPCC PLOT Y
    MOVE 82 30
    TEXT GAMMA = ^SHAPE
    MOVE 82 25
    TEXT PPCC = ^MAXPPCC
    .
    LET GAMMA = 1.6
    LET Y = WEIBULL RANDOM NUMBERS FOR I = 1 1 100
    SET PPCC PLOT AXIS POINTS 200
    LET GAMMA1 = 0.2
    LET GAMMA2 = 25
    LINE SOLID
    CHARACTER BLANK
    WEIBULL PPCC PLOT Y
    MOVE 82 30
    TEXT GAMMA = ^SHAPE
    MOVE 82 25
    TEXT PPCC = ^MAXPPCC
    .
    END OF MULTIPLOT

Program 2:
    let gamma = 5.1
    let y = weibull rand numb for i = 1 1 200
    .
    let gamma1 = 0.5
    let gamma2 = 50
    set ppcc plot axis points 449
    .
    multiplot corner coordinates 2 2 98 98
    multiplot scale factor 2
    multiplot 2 2
    title automatic
    title offset 2
    justification center
    height 1.7
    tic mark offset units screen
    ytic mark offset 3 0
    .
    weibull ppcc plot y
    let shape = round(shape,1)
    let maxppcc2 = round(maxppcc,3)
    move 50 5
    text Shape: ^shape, Max PPCC: ^maxppcc2
    .
    weibull anderson darling plot y
    let shape = round(shape,1)
    let minad2 = round(minad,3)
    move 50 5
    text Shape: ^shape, Min AD: ^minad2
    .
    weibull ks plot y
    let shape = round(shape,1)
    let minks = round(minks,3)
    move 50 5
    text Shape: ^shape, Min KS: ^minks
    .
    set chisquare limit 100
    weibull chi-square plot y
    let shape = round(shape,1)
    let minchsq = round(minchisq,3)
    move 50 5
    text Shape: ^shape, Min Chi-Square: ^minchsq
    .
    end of multiplot
 
-----PRECISION (LET)------------------------------
 
PRECISION
 
Name:
    PRECISION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the precision of a variable.
 
Description:
    The sample precision is defined as the reciprocal of the sample
    variance.  That is

        Prec = (n-1)/SUM[i=1 to n][(X(i) - xbar)**2]

    where n and xbar denote the sample size and the sample mean,
    respectively.

    Note that high variance implies low precision while low variance
    implies high precision.

    Some sources define the precision as the reciprocal of the standard
    deviation.

Syntax 1:
    LET <par> = PRECISION <y>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <par> is a parameter where the precision value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Syntax 2:
    LET <par> = DIFFERENCE OF PRECISION <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the difference of precision
              values is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET PREC = PRECISION Y1
    LET PREC = PRECISION Y1 SUBSET TAG > 2

    LET DIFFPREC = DIFFERENCE OF PRECISION Y1 Y2

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    VARIANCE                 = Compute the variance of a variable.
    MEAN                     = Compute the mean of a variable.
    STANDARD DEVIATION       = Compute the standard deviation of a
                               variable.
 
Applications:
    Data Analysis
 
Implementation Date:
    2017/01
    2017/03: Added DIFFERENCE OF PRECISION
 
Program 1:
    SKIP 25
    READ ZARR13.DAT Y
    LET P = PRECISION Y
 
Program 2:
    . Step 1:   Create the data
    .
    skip 25
    read gear.dat y x
    skip 0
    .
    char X
    line blank
    y1label Precision
    x1label Group
    x1tic mark offset 0.5 0.5
    label case asis
    title case asis
    title Precision of GEAR.DAT
    title offset 2
    .
    set statistic plot reference line average
    precision plot y x
    .
    set write decimals 5
    tabulate precision y x

Program 3:
    SKIP 25
    READ IRIS.DAT Y1 TO Y4 X
    .
    LET A = DIFFERENCE OF PRECISION Y1 Y2
    SET WRITE DECIMALS 4
    TABULATE DIFFERENCE OF PRECISION Y1 Y2 X
    .
    XTIC OFFSET 0.2 0.2
    X1LABEL GROUP ID
    Y1LABEL DIFFERENCE OF PRECISION
    CHAR X
    LINE BLANK
    DIFFERENCE OF PRECISION PLOT Y1 Y2 X
    CHAR X ALL
    LINE BLANK ALL
    BOOTSTRAP DIFFERENCE OF PRECISION PLOT Y1 Y2 X 
 
-----PRED-------------------------------------------------------
 
PRED
 
Name:
    PRED
 
Type:
    Keyword
 
Purpose:
    An internal DATAPLOT variable into which the predicted values
    (i.e., "fitted values") are automatically placed whenever the FIT,
    PRE-FIT, SPLINE FIT, EXACT RATIONAL FIT, YATES ANALYSIS, LOWESS,
    SMOOTH, ANOVA, and MEDIAN POLISH commands are executed.
 
Description:
    PRED can be used by the analyst in whatever fashion desired.  A
    very common post-fit operation is to superimpose the predicted
    values atop the raw data as a visual check of model adequacy.  This
    is usually done via
          CHARACTERS X BLANK
          LINES BLANK SOLID
          PLOT Y PRED VERSUS X
 
Syntax:
    None
 
Examples:
    WRITE X Y PRED RES
    PLOT Y PRED VERSUS X
    WRITE CALIB. X Y PRED RES
    LET PREDNEW = PRED
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RES                = A variable where residuals are stored.
    RESSD              = A parameter where the residual standard
                         deviation is stored.
    RESDF              = A parameter where the residual degrees of
                         freedom is stored.
    REPSD              = A parameter where the replication standard
                         deviation is stored.
    REPDF              = A parameter where the replication degrees of
                         freedom is stored.
    LOFCDF             = A parameter where the lack of fit cdf is
                         stored.
    FIT                = Carries out a least squares linear or
                         non-linear fit.
    EXACT RATIONAL FIT = Carries out an exact rational fit.
    PRE-FIT            = Carries out a least squares pre-fit.
    SPLINE FIT         = Carries out a spline fit.
    YATES ANALYSIS     = Carries out an analysis of a Yates design.
    LOWESS             = Carries out a locally weighted least squares
                         fit.
    SMOOTH             = Carries out a smoothing.
    ANOVA              = Carries out an ANOVA.
    MEDIAN POLISH      = Carries out a median polish.
    PLOT               = Generates a data/function plot.
 
Applications:
    Fitting
 
Implementation Date:
    Pre-1987
 
Program:
    SKIP 25
    READ BERGER1.DAT Y X
    CHARACTER X BLANK
    LINE BLANK SOLID
    PLOT Y PRED VS X
 
-----PREDICTION BOUNDS--------------------------------------
 
PREDICTION BOUNDS
 
Name:
    PREDICTION BOUNDS
 
Type:
    Analysis Command
 
Purpose:
    Generates prediction bounds for all m new observations given a
    previous sample.
 
Description:
    Given a sample of n observations with mean xbar and standard
    deviation s, the two-sided prediction interval to contain all of
    m new indpendent, identically distributed observations is

       xbar +/- r(1-alpha,m,n)*s

    A conservative approximation for r(1-alpha,m,n) is

       SQRT(1 + (1/n))*t(1-alpha/(2*m);n-1)

    with t denoting the t percent point function.  Dataplot uses the
    tabulated values given in Table A.13 of Hahn and Meeker when
    n and m are both less than or equal to 10.  Otherwise, the
    approximation above is used.

    The corresponding one-sided interval is

       lower limit = xbar - r'(1-alpha,m,n)*s
       upper limit = xbar + r'(1-alpha,m,n)*s

    A conservative approximation for r'(1-alpha,m,n) is

       SQRT(1 + (1/n))*t(1-alpha/*m;n-1)

    with t denoting the t percent point function.  Dataplot uses the
    tabulated values given in Table A.14 of Hahn and Meeker when
    n and m are both less than or equal to 10.  Otherwise, the
    approximation above is used.

    In the formula above, the only value from the new observations is
    the sample size.  That is, it can be applied before the new data is
    actually collected.  The number of observations for the new sample
    is entered with the command

        LET NNEW = <value>

    If NNEW is not defined, then a value of 1 is used.

    The difference between the PREDICTION BOUNDS command and the
    PREDICTION LIMITS command is that the PREDICTION LIMITS command
    generates a prediction interval for the mean of m new observations
    while the PREDICTION BOUNDS command generates a prediction interval
    to contain all of the new observations.

    This prediction interval is based on the assumption that the
    underlying data is approximately normally distributed.  Due to the
    central limit thereom, prediction limits for the mean are fairly
    robust against non-normality.  However, the central limit thereom
    does not apply to prediction intervals to cover all of the new
    observations.  So the PREDICTION BOUNDS command is much more
    sensitive to non-normality than is the PREDICTION LIMITS command.

Syntax 1:
    <LOWER/UPPER> <LOGNORMAL/BOXCOX> PREDICTION BOUNDS   <y>
                                     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    If LOWER is specified, a one-sided lower prediction limit is
    returned.  If UPPER is specified, a one-sided upper prediction
    limit is returned.  If neither is specified, a two-sided limit
    is returned.

    If the keyword LOGNORMAL is present, the log of the data will be
    taken, then the normal prediction bounds will be computed, and then
    the computed normal lower and upper limits will be exponentiated to
    obtain the lognormal prediction bounds.

    Similarly, if the keyword BOXCOX is present, a Box-Cox transformation
    to normality will be applied to the data before computing the normal
    prediction bounds.  The computed lower and upper limits will then
    be transformed back to the original scale.

    This syntax supports matrix arguments for the response variable.

Syntax 2:
    MULTIPLE <LOWER/UPPER> <LOGNORMAL/BOXCOX> PREDICTION BOUNDS
             <y1> ... <yk>    <SUBSET/EXCEPT/FOR qualification>
    where <y1>  .... <yk> is a list of 1 to 30 response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax will generate a prediction interval for each of
    the response variables.

    If LOWER is specified, a one-sided lower prediction limit is
    returned.  If UPPER is specified, a one-sided upper prediction
    limit is returned.  If neither is specified, a two-sided limit
    is returned.

    If the keyword LOGNORMAL is present, the log of the data will be
    taken, then the normal prediction bounds will be computed, and then
    the computed normal lower and upper limits will be exponentiated to
    obtain the lognormal prediction bounds.

    Similarly, if the keyword BOXCOX is present, a Box-Cox transformation
    to normality will be applied to the data before computing the normal
    prediction bounds.  The computed lower and upper limits will then
    be transformed back to the original scale.

    This syntax supports matrix arguments for the response variables.

Syntax 3:
    REPLICATED <LOWER/UPPER> <LOGNORMAL/BOXCOX> PREDICTION BOUNDS
               <y> <x1> ... <xk>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1>  .... <xk> is a list of 1 to 6 group-id variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax performs a cross-tabulation of the <x1> ... <xk>
    and generates a prediction interval for each unique combination
    of the cross-tabulated values.  For example, if X1 has 3 levels
    and X2 has 2 levels, six prediction intervals will be generated.

    If LOWER is specified, a one-sided lower prediction limit is
    returned.  If UPPER is specified, a one-sided upper prediction
    limit is returned.  If neither is specified, a two-sided limit
    is returned.

    If the keyword LOGNORMAL is present, the log of the data will be
    taken, then the normal prediction bounds will be computed, and then
    the computed normal lower and upper limits will be exponentiated to
    obtain the lognormal prediction bounds.

    Similarly, if the keyword BOXCOX is present, a Box-Cox transformation
    to normality will be applied to the data before computing the normal
    prediction bounds.  The computed lower and upper limits will then
    be transformed back to the original scale.

    This syntax does not support matrix arguments.

Examples:
    PREDICTION BOUNDS Y1
    PREDICTION BOUNDS Y1  SUBSET TAG > 2
    MULTIPLE PREDICTION BOUNDS Y1 TO Y5
    REPLICATED PREDICTION BOUNDS Y X
 
Note:
    A table of prediction limits is printed for alpha levels of
    50.0, 80.0, 90.0, 95.0, 99.0, and 99.9.
 
Note:
    In addition to the PREDICTION BOUNDS command, the following
    commands can also be used:

        LET ALPHA = 0.05
        LET NNEW = <value>

        LET A = LOWER PREDICTION BOUNDS Y
        LET A = UPPPER PREDICTION BOUNDS Y
        LET A = ONE SIDED LOWER PREDICTION BOUNDS Y
        LET A = ONE SIDED UPPER PREDICTION BOUNDS Y

        LET A = SUMMARY LOWER PREDICTION BOUNDS YMEAN YSD N
        LET A = SUMMARY UPPPER PREDICTION BOUNDS YMEAN YSD N
        LET A = SUMMARY ONE SIDED LOWER PREDICTION BOUNDS YMEAN YSD N
        LET A = SUMMARY ONE SIDED UPPER PREDICTION BOUNDS YMEAN YSD N

    The first two commands specify the significance level and the number
    of new observations.  The next four commands are used when you have
    raw data.  The last four commands are used when only summary data
    (mean, standard deviation, sample size) is available.

    In addition to the above LET command, built-in statistics are
    supported for about 20 different commands (enter HELP STATISTICS
    for details).

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PREDICTION LIMITS       = Generate prediction intervals for the mean
                              of new observations.
    SD PREDICTION BOUNDS    = Generate prediction limits for the
                              standard deviation.
    CONFIDENCE LIMITS       = Generate a confidence limit.
    TOLERANCE LIMITS        = Generate a tolerance limit.
 
Reference:
    Hahn and Meeker (1991), "Statistical Intervals: A Guide for
    Practitioners", Wiley, pp. 62-63.
 
Applications:
    Confirmatory Data Analysis
 
Implementation Date:
    2013/04
    2014/06: Support for LOGNORMAL and BOXCOX options
 
Program 1:
    SKIP 25
    READ ZARR13.DAT Y
    SET WRITE DECIMALS 5
    LET NNEW = 5
    .
    PREDICTION BOUNDS Y
    LOWER PREDICTION BOUNDS Y
    UPPER PREDICTION BOUNDS Y
 
Program 2:
    SKIP 25
    READ GEAR.DAT Y X
    SET WRITE DECIMALS 5
    LET NNEW = 5
    .
    REPLICATED PREDICTION BOUNDS Y X
 
Program 3:
    .  Following example from Hahn and Meeker's book.
    .
    let ymean = 50.10
    let ysd   = 1.31
    let n1    = 5
    let nnew  = 3
    let alpha = 0.05
    .
    set write decimals 5
    let slow1 = summary lower prediction bounds ymean ysd n1
    let supp1 = summary upper prediction bounds ymean ysd n1
    let slow2 = summary one sided lower prediction bounds ymean ysd n1
    let supp2 = summary one sided upper prediction bounds ymean ysd n1
    print slow1 supp1 slow2 supp2

-----PREDICTION LIMITS--------------------------------------
 
PREDICTION LIMITS
 
Name:
    PREDICTION LIMITS
 
Type:
    Analysis Command
 
Purpose:
    Generates a prediction interval for the mean of one or more
    new observations given a previous sample.
 
Description:
    Given a sample of n observations with mean xbar and standard
    deviation s, the prediction interval to contain the mean
    of m new indpendent, identically distributed observations is

       xbar +/- t(alpha/2,n-1)*s*SQRT((1/n) + (1/m))

    with t denoting the percent point function of the t distribution.

    In this formula, the only value from the new observations is the
    sample size.  That is, it can be applied before the new data is
    actually collected.  The number of observations for the new sample
    is entered with the command

        LET NNEW = <value>

    If NNEW is not defined, then a value of 1 is used.

    This prediction interval is based on the assumption that
    the underlying data is approximately normally distributed.
    However, this prediction interval is fairly robust against
    non-normality unless either the original sample size or the
    new sample is small or the departure from normality is severe
    (in particular, the data is not too skewed).  Note that this
    includes the case of a prediction interval for a single future
    observation.

Syntax 1:
    <LOWER/UPPER> <LOGNORMAL/BOXCOX>  PREDICTION LIMITS   <y>
                                      <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    If LOWER is specified, a one-sided lower prediction limit is
    returned.  If UPPER is specified, a one-sided upper prediction
    limit is returned.  If neither is specified, a two-sided limit
    is returned.

    If the keyword LOGNORMAL is present, the log of the data will be
    taken, then the normal prediction limits will be computed, and then
    the computed normal lower and upper limits will be exponentiated to
    obtain the lognormal prediction limits.

    Similarly, if the keyword BOXCOX is present, a Box-Cox transformation
    to normality will be applied to the data before computing the normal
    prediction limits.  The computed lower and upper limits will then
    be transformed back to the original scale.

    This syntax supports matrix arguments for the response variable.

Syntax 2:
    MULTIPLE <LOWER/UPPER> <LOGNORMAL/BOXCOX> PREDICTION LIMITS
                           <y1> ... <yk>
                           <SUBSET/EXCEPT/FOR qualification>
    where <y1>  .... <yk> is a list of 1 to 30 response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax will generate a prediction interval for each of
    the response variables.

    If LOWER is specified, a one-sided lower prediction limit is
    returned.  If UPPER is specified, a one-sided upper prediction
    limit is returned.  If neither is specified, a two-sided limit
    is returned.

    If the keyword LOGNORMAL is present, the log of the data will be
    taken, then the normal prediction limits will be computed, and then
    the computed normal lower and upper limits will be exponentiated to
    obtain the lognormal prediction limits.

    Similarly, if the keyword BOXCOX is present, a Box-Cox transformation
    to normality will be applied to the data before computing the normal
    prediction limits.  The computed lower and upper limits will then
    be transformed back to the original scale.

    This syntax supports matrix arguments for the response variables.

Syntax 3:
    REPLICATED <LOWER/UPPER> <LOGNORMAL/BOXCOX> PREDICTION LIMITS
                             <y> <x1> ... <xk>
                             <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1>  .... <xk> is a list of 1 to 6 group-id variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax performs a cross-tabulation of the <x1> ... <xk>
    and generates a prediction interval for each unique combination
    of the cross-tabulated values.  For example, if X1 has 3 levels
    and X2 has 2 levels, six prediction intervals will be generated.

    If LOWER is specified, a one-sided lower prediction limit is
    returned.  If UPPER is specified, a one-sided upper prediction
    limit is returned.  If neither is specified, a two-sided limit
    is returned.

    If the keyword LOGNORMAL is present, the log of the data will be
    taken, then the normal prediction limits will be computed, and then
    the computed normal lower and upper limits will be exponentiated to
    obtain the lognormal prediction limits.

    Similarly, if the keyword BOXCOX is present, a Box-Cox transformation
    to normality will be applied to the data before computing the normal
    prediction limits.  The computed lower and upper limits will then
    be transformed back to the original scale.

    This syntax does not support matrix arguments.

Examples:
    PREDICTION LIMITS Y1
    PREDICTION LIMITS Y1  SUBSET TAG > 2
    MULTIPLE PREDICTION LIMITS Y1 TO Y5
    REPLICATED PREDICTION LIMITS Y X
    LOGNORMAL PREDICTION LIMITS Y1
 
Note:
    A table of prediction limits is printed for alpha levels of
    50.0, 80.0, 90.0, 95.0, 99.0, and 99.9.
 
Note:
    In addition to the PREDICTION LIMIT command, the following
    commands can also be used:

        LET ALPHA = 0.05
        LET NNEW = <value>

        LET A = LOWER PREDICTION LIMIT Y
        LET A = UPPPER PREDICTION LIMIT Y
        LET A = ONE SIDED LOWER PREDICTION LIMIT Y
        LET A = ONE SIDED UPPER PREDICTION LIMIT Y

        LET A = SUMMARY LOWER PREDICTION LIMIT YMEAN YSD N
        LET A = SUMMARY UPPPER PREDICTION LIMIT YMEAN YSD N
        LET A = SUMMARY ONE SIDED LOWER PREDICTION LIMIT YMEAN YSD N
        LET A = SUMMARY ONE SIDED UPPER PREDICTION LIMIT YMEAN YSD N

    The first 2 commands specify the significance level and the number
    of new observations.  The next 4 commands are used when you have raw
    data.  The last 4 commands are used when only summary data (mean,
    standard deviation, sample size) is available.

    In addition to the above LET command, built-in statistics are
    supported for about 20 different commands (enter HELP STATISTICS
    for details).

Note:
    Prediction limits can also be generated for the case where the
    interval will contain ALL of the new points.  Enter HELP PREDICTION
    BOUNDS for details.

Note:
    The prediction limits described here are based on the assumption that
    the data follow an approximately normal distribution.  If the data is
    not normally distributed, lognormal or Box-Cox transformations can be
    applied to make the data more closely approximate a normal
    distribution.  The keywords LOGNORMAL and BOXCOX have been added to
    the command to allow these transformations to be applied automatically.

    Note that if these options are used, the limits will be transformed
    back to the original scale for the data.

Default:
    None
 
Synonyms:
    PREDICTION INTERVALS is a synonym for PREDICTION LIMITS
 
Related Commands:
    PREDICTION BOUNDS       = Generate prediction bounds.
    SD PREDICTION LIMITS    = Generate prediction limits for the
                              standard deviation.
    CONFIDENCE LIMITS       = Generate a confidence limit.
    TOLERANCE LIMITS        = Generate a tolerance limit.
 
Reference:
    Hahn and Meeker (1991), "Statistical Intervals: A Guide for
    Practitioners", Wiley, pp. 61-62.
 
Applications:
    Confirmatory Data Analysis
 
Implementation Date:
    2013/04
    2014/06: Support for LOGNORMAL and BOXCOX options
 
Program 1:
    SKIP 25
    READ ZARR13.DAT Y
    SET WRITE DECIMALS 5
    LET NNEW = 5
    .
    PREDICTION LIMITS Y
    LOWER PREDICTION LIMITS Y
    UPPER PREDICTION LIMITS Y
 
Program 2:
    SKIP 25
    READ GEAR.DAT Y X
    SET WRITE DECIMALS 5
    LET NNEW = 3
    .
    REPLICATED PREDICTION LIMITS Y X
 
Program 3:
    .  Following example from Hahn and Meeker's book.
    .
    let ymean = 50.10
    let ysd   = 1.31
    let n1    = 5
    let nnew  = 3
    let alpha = 0.05
    .
    set write decimals 5
    let slow1 = summary lower prediction limits ymean ysd n1
    let supp1 = summary upper prediction limits ymean ysd n1
    let slow2 = summary one sided lower prediction limits ymean ysd n1
    let supp2 = summary one sided upper prediction limits ymean ysd n1
    print slow1 supp1 slow2 supp2

-----PRE-ERASE-------------------------------------------------------
 
PRE-ERASE
 
Name:
    PRE-ERASE
 
Type:
    Plot Control Command
 
Purpose:
    Specifies whether or not the screen should be automatically erased
    at the beginning of subsequent plots.
 
Description:
    This command is typically used to overlay plots.  The PLOT and
    3D-PLOT command can do this with the AND syntax.  However, the AND
    syntax is not supported on any of the various other plot commands.
    The PRE-ERASE command can be used to overlay plots where the AND
    syntax is not allowed or is not convenient.
 
Syntax:
    PRE-ERASE   <ON or OFF>
    where ON specifies that the screen will be erased at the beginning
             of subsequent plots while OFF specifies that it will not.
 
Examples:
    PRE-ERASE ON
    PRE-ERASE OFF
    PRE-ERASE
 
Note:
    When overlaying plots, it is typically necessary to use the
    XLIMITS and YLIMITS commands to keep the axes on the same scales
    for all the overlaid plots.  In addition, the frame, titles,
    labels, legends, etc. are redrawn with each subsequent plot.
    Although this does not cause any harm, it can be time consuming
    (particularly if a software font is in effect).  You may want to
    shut these off after the original plot (e.g., TITLE ; FRAME OFF;
    LABEL ).
 
Note:
    The PRE-ERASE command with no arguments reverts the setting to
    default.
 
Default:
    The default is for plots to have automatic screen erasure (ON).
 
Synonyms:
    None
 
Related Commands:
    ERASE DELAY = Sets the delay after screen erasure.
    BELL        = Sets the automatic bell switch for plots.
    HARDCOPY    = Sets the automatic copy switch for plots.
    SEQUENCE    = Sets the automatic sequence switch for plots.
    PLOT        = Generates a data or function plot.
    RING        = Rings the bell (immediately).
    ERASE       = Erases the screen (immediately).
    COPY        = Copies the screen (immediately).
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    .  PURPOSE--GENERATE A QUARTILE PLOT OF POINT BARROW FREON-11 DATA
    SKIP 50
    SET READ FORMAT 3F4.0,F5.0,F6.0,F3.0,2F9.0
    READ PBF11.DAT YEAR DAY BOT SD F11 FLAG WV CO2
    .
    RETAIN YEAR DAY BOT SD F11 WV CO2 FLAG SUBSET FLAG 0
    LET MONTH=INT(DAY/30.25)+1
    .
    TITLE QUARTILE PLOT
    XLIMITS 0 15
    YLIMITS 1 1.01
    CHARACTER U U
    LINE BLANK SOLID
    UPPER QUARTILE PLOT WV MONTH
    PRE-ERASE OFF
    CHARACTER L L
    LOWER QUARTILE PLOT WV MONTH
 
-----PRE-FIT-------------------------------------------------------
 
PRE-FIT
 
Name:
    PRE-FIT
 
Type:
    Analysis Command
 
Purpose:
    Determines the "best fit" coefficients for a model, where the
    search is restricted to the points of a user-defined lattice.
 
Description:
    The desired lattice is defined by the FOR statements at the end of
    the command.  The"best fit" coefficients are determined by
    systematically evaluating the sum of squares surface at each of the
    points of the specified lattice of parameter values.  The minimum
    point over the lattice is determined and noted, along with other
    extrema information.  This command receives only light usage,
    typically in the following 2 contexts:
    1) immediately before the ... FIT command when the model is
       non-linear, when the starting values are unknown, and when the
       analyst is interested in gathering some preliminary information
       about the nature of the sum of squares surface.
    2) immediately after the ...FIT command when a least squares fit
       has been carried out, and the analyst is interested in examining
       the nature of the Lp surface (for p not = 2) in the vicinity of
       the least squares estimate.  In this context, the FIT POWER
       command is also used.
 
Syntax:
    PRE-FIT <y1> = <f> FOR <p> = <p1> <pinc> <p2>
                       FOR <q> = <q1> <qinc> <q2>
                            <additional optional FOR statements>
    where <y1> is the response (= dependent) variable;
          <f> is
                1) any general FORTRAN-like expression; or
                2) any function name that the user has already created
                   via the LET FUNCTION command);
          <p> is the name of a parameter in the function;
          <p1> is a number or parameter that specifies the minimum
                value for the parameter;
          <pinc> is a number or parameter that specifies the increment
                for the parameter;
          <p2> is a number or parameter that specifies the maximum
                value for the parameter;
          <q> is the name of another parameter in the function;
          <q1> is a number or parameter that specifies the minimum
                value for the parameter;
          <qinc> is a number or parameter that specifies the increment
                for the parameter;
          <q2> is a number or parameter that specifies the maximum
                value for the parameter;
    and any additional FOR statments have a similar syntax.
 
    All of the FOR statements should be on the same line.
 
Examples:
    PRE-FIT Y=A+B*EXP(-C*X) FOR A=10 1 20 FOR B=50 10 100 ...
                            FOR C = .1 .1 1
    PRE-FIT Y = A+EXP(C/X) FOR A = 1 2 10 FOR C = .5 .05 .6
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PRED               = A variable where predicted values are stored.
    RES                = A variable where residuals are stored.
    RESSD              = A parameter where the residual standard
                         deviation is stored.
    RESDF              = A parameter where the residual degrees of
                         freedom is stored.
    REPSD              = A parameter where the replication standard
                         deviation is stored.
    REPDF              = A parameter where the replication degrees of
                         freedom is stored.
    LOFCDF             = A parameter where the lack of fit cdf is
                         stored.
    FIT                = Carries out a least squares fit.
    EXACT RATIONAL FIT = Carries out an exact rational fit.
    SPLINE FIT         = Carries out a spline fit.
    SMOOTH             = Carries out a smoothing.
    ANOVA              = Carries out an ANOVA.
    MEDIAN POLISH      = Carries out a median polish.
    PLOT               = Generates a data or function plot.
 
Applications:
    Non-Linear Fitting
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----PREPOST-------------------------------------------------------
 
PREPOST
 
Name:
    PREPOST
 
Type:
    Output Device Command
 
Purpose:
    The DEFINE PREPLOT command allows the analyst to specify a string
    that is sent to an output device at the beginning of a plot.  The
    PREPOST command specifies the device that the DEFINE PREPLOT
    command applies to.
 
Description:
    These commands are particularly useful for device emulators which
    often require escape codes to set the proper emulation mode.
 
Syntax:
    PREPOST    <device>
    where <device> specifies the graphics device that DEFINE PREPLOT
              applies to.
 
Examples:
    PREPOST HP-GL
    PREPOST TEKTRONIX 4014
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    DEFINE PREPLOT  = Define the preplot string.
    DEFINE POSTPLOT = Define the postplot string.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    .  THE FOLLOWING SEQUENCE DEFINES CODES TO PUT A VT-240 IN
    .  AND OUT OF TEKTRONIX 4014 MODE.
    DEFINE PREPLOT ESC [ ? 3 8 h
    DEFINE POSTPLOT  ESC [ ? 3 8 l
    PREPOST TEKTRONIX 4014
    PLOT X**2 FOR X = 1 1 9
 
-----PRE-SORT-------------------------------------------------------
 
PRE-SORT
 
Name:
    PRE-SORT
 
Type:
    Plot Control Command
 
Purpose:
    Specifies whether or not data to be plotted is pre-sorted by the
    horizontal axis variable.
 
Description:
    By default, DATAPLOT pre-sorts the data before a plot according to
    the horizontal axis variable so that connected lines will look
    right.  However, there are situations (e.g., drawing a map,
    plotting a trajectory) where it is necessary to plot the data in
    the order that they reside in the variables.  The PRE-SORT command
    is used to specify this.
 
Syntax:
    PRE-SORT  <ON or OFF>
    where ON specifies that the data are pre-sorted while OFF specifies
            that they are not.
 
Examples:
    PRE-SORT ON
    PRE-SORT OFF
    PRE-SORT
 
Note:
    The PRE-SORT command with no arguments reverts the setting to
    default.
 
Default:
    The default is for plots to pre-sort the data.
 
Synonyms:
    None
 
Related Commands:
    PLOT       = Generates a data or function plot.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    PRE-SORT OFF
    FRAME OFF
    DEGREES
    LET THETA = SEQUENCE 0 10 1000
    LET R = 2*THETA
    LET Y = R*SIN(THETA)
    LET X = R*COS(THETA)
    TITLE A POLAR COORDINATE FUNCTION
    PLOT Y X
 
-----PRIME NUMBERS (LET)----------------------------------------------
 
PRIME
 
Name:
    PRIME NUMBERS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute prime numbers.
 
Description:
    Prime numbers are integers that are only divisible by 1 and the
    number itself.
 
Syntax:
    LET <resp> = PRIME NUMBERS  FOR I = <start>  <inc>  <stop>
    where <resp> is a variable where the prime numbers are saved;
          <start> is the first row in <resp> where the pattern is saved
              (typically has a value of 1);
          <inc> is the row increment for saving values in <resp>
              (typically has a value of 1); and
    and   <stop> is the last row in <resp> for saving values.
 
    This syntax saves the first N (where N is determined by the values
    of <start>, <inc>, and <stop>) prime numbers in the variable <resp>.
 
Examples:
    LET PRIME = PRIME NUMBERS FOR I = 1 1 100
    LET PRIME = PRIME NUMBERS FOR I = 1 1 10
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SEQUENCE            = Generate a sequence of numbers.
    PATTERN             = Generate numbers with a specific pattern.
    FIBONNACCI NUMBERS  = Generate Fibonnacci numbers.
    LOGISTIC NUMBERS    = Generate numbers from a logistic sequence.
    CANTOR NUMBERS      = Generate numbers from a Cantor set.
    DATA                = Place numbers in a variable.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET PRIME = PRIME NUMBERS FOR I = 1 1 50
    PLOT PRIME
 
-----PRINCIPAL COMPONENTS (LET)---------------------------------------
 
PRINCIPAL COMPONENTS
 
Name:
    PRINCIPAL COMPONENTS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Find the principal components of a matrix.
 
Description:
    Given a data matrix X with n cases and p variables (i.e., variables
    X1, X2, ... , Xp), a linear transformation to a new set of
    variables Y1, Y2, ... , Yp is calculated.  That is,
        Y1 = a11X1 + a21X2 + ... + ap1Xp
        Y2 = a12X1 + a22X2 + ... + ap2Xp
                ....
        Yp = a1pX1 + a2pX2 + ... + appXp
    The Y variables are called the principal components and they have
    the following characteristics:
       1) The p principal components are uncorrelated.
       2) The first principal component explains the largest percentage
          of the variation in the original p-dimensional data set (and
          the second principal component explains the second largest
          percentage and so on).  Typically the first few variables
          account for most of the variation while the remaining
          variables make a negligible contribution.
 
    Principle components are used to reduce large dimensional data
    sets to data sets with a few dimensions that still retain most of
    the information in the original data matrix.  That is, typically
    only the first few principal components are used.  If the first
    few principal components do not account for most of the variation,
    there is little advantage to using them.  By reducing the
    dimensionality of the original data, principal components can often
    simplify many analyses.  The primary disadvantage of principal
    components is that interpretation can be more difficult since you
    are no longer working with the original variables.
 
    Principle components reduce to the problem of finding the
    eigenvalues and eigenvectors of the covariance (or correlation
    matrix) of the data matrix.  The ith row of the A matrix
    is the eigenvector corresponding to the ith eigenvalue of the
    covariance (or correlation) matrix.  Also, the proportion of the
    variance in the original data matrix explained by the ith principal
    component is the ith eigenvalue divided by the sum of all p
    eigenvalues.  Using the covariance matrix is preferred when the
    original data are reasonably comparable scales.  If this is not
    the case, the correlation matrix is preferred.
 
    DATAPLOT returns the principal components (i.e., the Y matrix),
    the eigenvectors (i.e., the A matrix), and the eigenvalues in
    separate steps.
 
Syntax 1:
    LET <mat3> = PRINCIPAL COMPONENTS <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is the matrix for which the principal components are
                 computed (it can be the original data matrix, a
                 covariance matrix, or a correlation matrix);
          <mat3> is a p by p matrix where the principal components
                 (i.e., the Y matrix) are saved (column 1 is the first
                 principal component, column p is the pth principal
                 component);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Syntax 2:
    LET <resp> = <id> PRINCIPAL COMPONENTS <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is the matrix for which the principal components are
                 computed (it can be the original data matrix, a
                 covariance matrix, or a correlation matrix);
          <id> identifies a specific principal component to be
                 returned (FIRST, SECOND, THIRD, FOURTH, FIFTH, SIXTH,
                 SEVENTH, EIGHTH, NINTH, TENTH);
          <resp> is a variable of length p where the specific
                 principal component is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Syntax 3:
    LET <resp> = PRINCIPAL COMPONENTS EIGENVALUES <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is the matrix for which the principal components are
                 computed (it can be the original data matrix, a
                 covariance matrix, or a correlation matrix);
          <resp> is a variable of length p where the eigenvalues of
                 the covariance (or correlation) matrix are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Syntax 4:
    LET <par> = <id> PRINCIPAL COMPONENTS EIGENVALUES <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is the matrix for which the principal components are
                 computed (it can be the original data matrix, a
                 covariance matrix, or a correlation matrix);
          <id> identifies a specific eigenvalue to be returned (FIRST,
                 SECOND, THIRD, FOURTH, FIFTH, SIXTH, SEVENTH, EIGHTH,
                 NINTH, TENTH);
          <par> is a parameter where the specific eigenvalue is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Syntax: 5
    LET <mat3> = PRINCIPAL COMPONENTS EIGENVECTORS <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is the matrix for which the principal components are
                 computed (it can be the original data matrix, a
                 covariance matrix, or a correlation matrix);
          <mat3> is a p by p matrix where the eigenvectors of the
                 covariance (or correlation) matrix (i.e., the A
                 matrix) are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Syntax: 6
    LET <resp> = <id> PRINCIPAL COMPONENTS EIGENVECTORS <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is the matrix for which the principal components are
                 computed (it can be the original data matrix, a
                 covariance matrix, or a correlation matrix);
          <id> identifies a specific eigenvector to be returned (FIRST,
                 SECOND, THIRD, FOURTH, FIFTH, SIXTH, SEVENTH, EIGHTH,
                 NINTH, TENTH);
          <resp> is a variable where the specific eigenvector is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET Y = PRINCIPAL COMPONENTS X
    LET E = PRINCIPAL COMPONENTS EIGENVALUES X
    LET A = PRINCIPAL COMPONENTS EIGENVECTORS X
    LET Y1 = FIRST PRINCIPAL COMPONENT X
    LET E1 = FIRST PRINCIPAL COMPONENT EIGENVALUE X
    LET A1 = FIRST PRINCIPAL COMPONENT EIGENVECTOR X
 
Note:
    If the principal components are derived from the original data and
    the covariance matrix, the data matrix is scaled by subtracting
    the column mean before it is multiplied by the eigenvector matrix.
    That is, Y = A*(X-XBAR).
 
Note:
    The PRINCIPAL COMPONENT TYPE command is used to specify whether
    the original matrix is a data matrix, a covariance matrix, or a
    correlation matrix.  It also specifies whether the principal
    components are derived from the covariance or the correlation
    matrix.  The default is an original data matrix with the
    principal components derived from the correlation matrix.
 
Note:
    Principle components are sometimes used in regression problems
    to avoid multicolinearity problems while still maintaining most
    of the information in a large number of variables.  This is
    demonstrated in the second program example.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
    If you have more than 500 rows in your input data, you can use the
    LOOP command to generate a covariance matrix and compute the
    principal components from this covariance matrix.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    "Principle Components and Factor Analysis: Part I - Principle
    Components", Jackson, Journal of Quality Technology, October, 1980.
 
    "Multivariate Statistical Methods", Morrison, McGraw-Hill, 1976.
 
    "Graphical Exploratory Data Analysis", du Toit, Steyn, and Stumpf,
    Springer-Verlang, 1986.
 
    "Applied Regression Analysis", Draper and Smith, John Wiley, 1981.
 
Applications:
    Multivariate Analysis, Regression
 
Implementation Date:
    87/10
 
Program 1:
    . SOURCE: "GRAPHICAL EXPLORATORY DATA ANALYSIS", DU TOIT, ET AL
    . 28 STUDENTS FROM ABILITY TEST DATA SET (PAGE 6)
    DIMENSION 100 COLUMNS
    READ MATRIX X
    19 21 21 18 20 21 15 14 15 13 15 16 19 19 19 20 17 17
    21 20 15 24 22 18 11 18 16 19 14 17 21 15 17 18 18 19
    18 19 16 18 18 23 11 13 13 15 11 11 15 18 13 15 18 13
    18 23 10 18 16 16 11  9  8 15  6  9 12 16  8 13  9 15
    24 24 19 20 23 24 22 18 16 19 16 19 19 21 21 20 18 20
    19 19 23 21 23 23  9  8 13 15 20 15 17 12 20 16 16 21
    21 20 19 21 21 23 11 16 11 18 18 14 21 17 14 19 18 16
    21 20 21 20 16 22  7 11 17 16  8 10 13 17 16 17 15 11
    19 20 19 22 18 21 11 12  7 15  9 11 13 12 13 17 12 12
    19 23 22 22 16 25 12 15 16 19 15 10 15 20 18 18 17 13
    17 13  8 18 13 18 12  8  9 12 12 11  9 14 15 12 13  9
    21 22 22 15 23 23 16 12 16 15 13 14 19 17 16 18 19 18
    18 18 17 16 15 22  8 11 10 16  8 14 10 13 10 14  9 14
    13 18 21 16 17 15 11 12 11  9 11 11 16 18 14 13 15 18
    17 13 17 20 22 19 15 11 11 12 11 13 15 15 15 13 16 12
    18 12  9  9 15 17  9  5  3 12  7  7 12 10 10 13 10 12
    22 15 24 17 15 20 10 12 12 11  9 12 19 16 16  8 11 17
    18 17 18 18 13 18 14 12 15 11 10  9 21 14 12 15 11 13
    17 15 14 14 12 13  9 10 11  9  7 11 13 15 11 13 10 13
    16 20 17 13 15 16 10 16 12 10  7 13 12 18 13 18 10 15
    24 21 22 21 21 25 11 17 17 21 11 15 15 18 16 16 17 17
    23 23 21 22 16 21 10 18 16 14 14 13 17 21 19 16 17 19
    22 22 21 24 18 24  6 16 14 20 16 18 12 12 13 18 18 21
    22 17 19 19 21 20 17 15  9 13 16 17 18 11 13 16 19 14
    20 23 23 22 22 24 11 18 16 16 16 20 13 16 18 18 20 20
    22 17 21 17 17 22 10 14 16 16 13  8 13 18 21 12 13 15
    21 18 20 23 21 22  8 15  9 17 11 13 13 20 20 21 15 20
    21 22 19 20 18 17 11 15 12 14 11 10 11 13 14 14 15 14
    END OF DATA
    LET P = MATRIX NUMBER OF COLUMNS X
    PRINCIPAL COMPONENTS TYPE DATA COVARIANCE
    LET Y = PRINCIPAL COMPONENTS X
    LET A = PRINCIPAL COMPONENTS EIGENVECTORS X
    LET E = PRINCIPAL COMPONENTS EIGENVALUES X
    PRINT E
    LET ESUM = CUMULATIVE SUM E
    LET TEMP = ESUM(P)
    LET RATIO = 100*ESUM/TEMP
    .  FORM CORR(Xi,Y1) = Ai1*SQRT(L1)/Si
    LOOP FOR K = 1 1 P
       LET TEMP = STANDARD DEVIATION X^K
       LET SD(K) = TEMP
    END OF LOOP
    LET TEMP = E(1)
    LET R1 = A1*SQRT(TEMP)/SD
    .  FORM CORR(Xi,Y2) = Ai2*SQRT(L2)/Si
    LET TEMP = E(2)
    LET R2 = A2*SQRT(TEMP)/SD
    LINE BLANK ALL
    CHARACTER 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
    LET TAG = SEQUENCE 1 1 P
    X1LABEL CORRELATION (XLC()I,UC()Y1)
    Y1LABEL CORRELATION (XLC()I,UC()Y2)
    LET TEMP = RATIO(1)
    LEGEND 1 PC 1 - ^TEMP % EXPLAINED
    LET TEMP = RATIO(2)
    LEGEND 2 PC 2 - ^TEMP % EXPLAINED
    PLOT R2 R1 TAG
 
Program 2:
    . SOURCE: "APPLIED REGRESSION ANALYSIS", DRAPER AND SMITH.
    . HALD DATA (APPENDIX B)
    . PRINCIPAL COMPONENTS REGRESSION (CHAPTER 6-9 OF DRAPER, SMITH)
    .
    DIMENSION 100 COLUMNS
    READ X1 X2 X3 X4 Y
    7   26   6  60   78.5
    1   29  15  52   74.3
    11  56   8  20 104.3
    11  31   8  47  87.6
    7   52   6  33  95.9
    11  55   9  22 109.2
    3   71  17   6 102.7
    1   31  22  44  72.5
    2   54  18  22  93.1
    21  47   4  26 115.9
    1   40  23  34  83.8
    11  66   9  12 113.3
    10  68   8  12 109.4
    END OF DATA
    LET X = MATRIX DEFINITION X1 13 4
    LET CORR = CORRELATION MATRIX X
    PRINT CORR
    PRINCIPAL COMPONENT TYPE DATA CORRELATION
    LET W = PRINCIPAL COMPONENTS X
    LET E = PRINCIPAL COMPONENT EIGENVALUES X
    LET EVECT = PRINCIPAL COMPONENT EIGENVECTORS X
    LET RATIO = CUMULATIVE SUM E
    LET RATIO = RATIO/4.
    .
    PRINT E RATIO
    PRINT "EIGENVECTORS:"; PRINT EVECT
    PRINT "PRINCIPAL COMPONENTS:"; PRINT W
    FEEDBACK ON
    FIT Y W1 W2
 
-----PRINCIPAL COMPONENTS TYPE----------------------------------------
 
PRINCIPAL COMPONENTS TYPE
 
Name:
    PRINCIPAL COMPONENTS TYPE
 
Type:
    Support Command
 
Purpose:
    Specify the input format of the data for the PRINCIPAL COMPONENTS
    command.
 
Description:
    See the documentation for the PRINCIPAL COMPONENTS command for a
    description of principal components.
 
    Principle components reduce to the problem of finding the
    eigenvalues and eigenvectors of the covariance (or correlation
    matrix) of the data matrix.  In addition, the data matrix can be
    raw data, a covariance matrix, or a correlation matrix.
 
    The PRINCIPAL COMPONENTS TYPE command specifies two things.  First,
    it specifies whether the data matrix is raw data, a covariance
    matrix, or a correlation matrix.  Second, it specifies whether the
    principal components are calculated from the covariance or the
    correlation matrix.
 
Syntax:
    PRINCIPAL COMPONENTS TYPE  <key1>  <key2>
    where <key1> is one of the following:
                DATA        - original matrix is raw data
                COVARIANCE  - original matrix is a covariance matrix
                CORRELATION - original matrix is a correlation matrix;
    and   <key2> is one of the following:
                COVARIANCE  - principal components computed from a
                              covariance matrix
                CORRELATION - principal components computed from a
                              correlation matrix.
 
Examples:
    PRINCIPAL COMPONENTS TYPE DATA COVARIANCE
    PRINCIPAL COMPONENTS TYPE DATA CORRELATION
    PRINCIPAL COMPONENTS TYPE COVARIANCE COVARIANCE
    PRINCIPAL COMPONENTS TYPE COVARIANCE CORRELATION
    PRINCIPAL COMPONENTS TYPE CORRELATION CORRELATION
 
Note:
    If the original data is a correlation matrix, principal components
    can only be computed from a correlation matrix.  That is, the
    command PRINCIPAL COMPONENTS TYPE CORRELATION COVARIANCE is not
    supported.
 
Default:
    The original matrix is raw data and the principal components are
    calculated from a covariance matrix.
 
Synonyms:
    None
 
Related Commands:
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPAL COMPONENTS = Compute principal components.
 
Reference:
    "Principle Components and Factor Analysis: Part I - Principle
    Components", Jackson, Journal of Quality Technology, October, 1980.
 
    "Multivariate Statistical Methods", Morrison, McGraw-Hill, 1976.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    87/10
 
Program 1:
    . SOURCE: "GRAPHICAL EXPLORATORY DATA ANALYSIS", DU TOIT, ET AL
    . 28 STUDENTS FROM ABILITY TEST DATA SET (PAGE 6)
    DIMENSION 100 COLUMNS
    READ MATRIX X
    19 21 21 18 20 21 15 14 15 13 15 16 19 19 19 20 17 17
    21 20 15 24 22 18 11 18 16 19 14 17 21 15 17 18 18 19
    18 19 16 18 18 23 11 13 13 15 11 11 15 18 13 15 18 13
    18 23 10 18 16 16 11  9  8 15  6  9 12 16  8 13  9 15
    24 24 19 20 23 24 22 18 16 19 16 19 19 21 21 20 18 20
    19 19 23 21 23 23  9  8 13 15 20 15 17 12 20 16 16 21
    21 20 19 21 21 23 11 16 11 18 18 14 21 17 14 19 18 16
    21 20 21 20 16 22  7 11 17 16  8 10 13 17 16 17 15 11
    19 20 19 22 18 21 11 12  7 15  9 11 13 12 13 17 12 12
    19 23 22 22 16 25 12 15 16 19 15 10 15 20 18 18 17 13
    17 13  8 18 13 18 12  8  9 12 12 11  9 14 15 12 13  9
    21 22 22 15 23 23 16 12 16 15 13 14 19 17 16 18 19 18
    18 18 17 16 15 22  8 11 10 16  8 14 10 13 10 14  9 14
    13 18 21 16 17 15 11 12 11  9 11 11 16 18 14 13 15 18
    17 13 17 20 22 19 15 11 11 12 11 13 15 15 15 13 16 12
    18 12  9  9 15 17  9  5  3 12  7  7 12 10 10 13 10 12
    22 15 24 17 15 20 10 12 12 11  9 12 19 16 16  8 11 17
    18 17 18 18 13 18 14 12 15 11 10  9 21 14 12 15 11 13
    17 15 14 14 12 13  9 10 11  9  7 11 13 15 11 13 10 13
    16 20 17 13 15 16 10 16 12 10  7 13 12 18 13 18 10 15
    24 21 22 21 21 25 11 17 17 21 11 15 15 18 16 16 17 17
    23 23 21 22 16 21 10 18 16 14 14 13 17 21 19 16 17 19
    22 22 21 24 18 24  6 16 14 20 16 18 12 12 13 18 18 21
    22 17 19 19 21 20 17 15  9 13 16 17 18 11 13 16 19 14
    20 23 23 22 22 24 11 18 16 16 16 20 13 16 18 18 20 20
    22 17 21 17 17 22 10 14 16 16 13  8 13 18 21 12 13 15
    21 18 20 23 21 22  8 15  9 17 11 13 13 20 20 21 15 20
    21 22 19 20 18 17 11 15 12 14 11 10 11 13 14 14 15 14
    END OF DATA
    LET P = MATRIX NUMBER OF COLUMNS X
    PRINCIPAL COMPONENTS TYPE DATA COVARIANCE
    LET Y = PRINCIPAL COMPONENTS X
    LET A = PRINCIPAL COMPONENTS EIGENVECTORS X
    LET E = PRINCIPAL COMPONENTS EIGENVALUES X
 
-----PRINTFILE--------------------------------------------------
 
PRINTFILE
 
Name:
    PRINTFILE
 
Type:
    Support Command
 
Purpose:
    Print an ASCII file.

Description:
    This is an operating system dependent command.

    On Windows 7/8/10 platforms, the printing is invoked with the
    command

        write.exe -p <filename>

    This command uses WordPad to print the file.  Note that Wordpad
    can print RTF formatted files and some Microsoft Word formatted
    files (this can depend on what versions of Word and WorPad you
    have installed).  Currently, no provision is made for a non-default
    printer.

    On Linux/Unix and MacOS platforms, the printing is invoked with
    the command

        lpr <filename>

    If you have specified the printer name with the SET PRINTER command,
    then the following command is used
 
        lpr -P<printername> <filename>

Syntax:
    PRINTFILE  <file1>
    where <file1> is the name of the file to print.
 
    In order to avoid conflict with the PRINT command, PRINTFILE cannot
    be abbreviated.  Only the first 8 characters are evaluated, so a match
    up to PRINTFIL is succifient.
 
Examples:
    PRINTFILE BERGER1.DAT

Note:
    This command requires that the SYSTEM capability is supported.
    This should be the case for all currently supported platforms.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PP         = Print the current plot to a Postscript printer.
    COPY       = Copy a file to another file.
    LIST       = Print the contents of the file.
    SEARCH     = Search a file for a given string.
    EDIT       = Edit a file.
    SYSTEM     = Perform an operating system command.
 
Applications:
    Interactive Usage
 
Implementation Date:
    2019/03:
 
Program:
    SKIP 25
    READ BERGER1.DAT Y X
    SET WRITE DECIMALS 4
    CPATURE BERGER1.OUT
    FIT Y X
    END OF CAPTURE
    PRINTFILE BERGER1.OUT

-----PRINT-------------------------------------------------------
 
PRINT
 
Name:
    PRINT
 
Type:
    Support Command
 
Purpose:
    Writes variables (vectors), parameters (scalars), functions
    (including strings), and matrices to the screen or to a file.
 
Syntax 1:
    PRINT <variable list>
    where <variable list> is a list of parameters, variables, strings,
             or matrices (separated by spaces).
 
Syntax 2:
    PRINT <file name>  <variable list>
    where <file name> specifies the name of the output file;
    and   <variable list> is a list of parameters, variables, strings,
             or matrics (separated by spaces).
 
    If the file name does not contain a period, place a period (no
    spaces) at the end of the file name.
 
Examples:
    PRINT OUT. Y1 Y2 Y3 X
    PRINT DATA.SAVE X Y PRED RES
    PRINT X Y PRED RES
 
Note:
    Numbers are written in exponential format by default.  The analyst
    can specify a specific format with the SET WRITE FORMAT statement.
    The output file is rewound by default (that is, if the file
    already exists it is overwritten).  Use the SET WRITE REWIND OFF
    command to allow multiple writes to the same file.  The SET WRITE
    DECIMALS command can also be used to control the format of
    numbers.
 
Note:
    DATAPLOT writes to an ASCII text file.  No method of writing
    binary files is currently supported.
 
Note:
    Literal text can be written by enclosing it in double quotes.  For
    example,
        PRINT "Enter the value for X"
 
Note:
    DATAPLOT has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    DATAPLOT strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), DATAPLOT opens the file with the
    trailing period.
 
Note:
    File names are case sensitive on Unix file systems.  For Unix,
    DATAPLOT opens the file as given.  All other currently supported
    systems are not case sensitive regarding file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    XX
 
Synonyms:
    WRITE is a synonym for PRINT.
 
Related Commands:
    SET WRITE FORMAT    = Define a Fortran like format for writing
                          data.
    SET WRITE DECIMALS  = Specify the number of digits to the right of
                          the decimal point when printing numbers.
    SET WRITE REWIND    = Specify if the output file is rewound
                          before writing.
    READ                = Read variables, parameters, strings, and
                          matrices from a file.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y2 = EXPONENTIAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y3 = UNIFORM RANDOM NUMBERS FOR I = 1 1 100
    WRITE RANDOM.DAT Y1 Y2 Y3
 
-----PRINTER (SET)--------------------------------------------------
 
PRINTER
 
Name:
    PRINTER (SET)
 
Type:
    Set Subcommand
 
Purpose:
    This command sets the printer id for the PP command.
 
Description:
    The PP command is used to send the most recent plot to
    the printer.

    The PP command is operating system dependent.  It is
    currently supported in the Unix and Windows 95/98/NT
    environments.

    The PP command sends the graphics output to the default
    printer.  Specifically,

      1) On Unix, the PP command issues an "lpr dppl2f.dat"
         command.  The default printer in Unix is set by the
         UNIX command "setenv PRINTER <printer-id>" for the
         c shell (other shells may have a slightly different
         way for defining the default printer).

      2) On Windows 95/98/NT systems, the PP command issues the
         command "COPY DPPL2F.DAT PRN:".

    On either system, it is sometimes desirable to override the
    default printer.  The SET PRINTER command is used to override
    the default printer.  If the command "SET PRINTER printer-id"
    is entered in Dataplot, then the PP command does the following:

      1) On Unix, the PP command issues a
         "lpr -Pprinter-id dppl2f.dat" command.
    
      2) On Windows 95/98/NT systems, the PP command issues the
         command "COPY DPPL2F.DAT printer-id".  This is most often
         used to send the graphics output to a network printer
         rather than the local printer.

    The printer-id will be specific to your local host.  If
    you are unsure of the appropriate printer name, then contact
    your local system administrator for this information.
 
Syntax:
    SET PRINTER <printer-id>
    where <printer-id> is the desired printer id.
 
Examples:
    SET PRINTER lw7_duplex
 
Default:
    For Unix, the default printer is set by the "setenv PRINTER"
    command when using the c shell.  On Windows, the default
    printer is PRN:, i.e., the local printer.
 
Synonyms:
    None
 
Note:
    Dataplot has no way of determining if the given printer-id
    is valid on your system.

Related Commands:
    PP            = Print the current plot on the default printer.
    SYSTEM        = Enter an operating system command within a
                    Dataplot session.
 
Applications:
    Interactive Usage
 
Implementation Date:
    1998/5
 
Program:
    SET PRINTER lw7
    PLOT X**2 FOR X = 1 1 9
    PP
 
-----PRINTER TYPE------------------------------------------------
 
PRINTER TYPE
 
Note:
    ******* This command is not yet operational ******
 
Name:
    PRINTER TYPE
 
Type:
    Support Subcommand
 
Purpose:
    Specifies whether the output from the / PRINTER command is
    generated as an ASCII text file or as a Postscript file.
 
Description:
    The / command re-executes saved commands (see the documentation for
    the SAVE command for details).  The / PRINTER command re-executes
    saved commands and also re-directs the output to the printer.  The
    PRINTER TYPE command specifies whether this output is sent to the
    printer as a plain ASCII text file or is reformatted into a
    Postscript format.
 
Syntax:
    PRINTER TYPE <ASCII/POSTSCRIPT>
    where ASCII specifies a plain ASCII text file and POSTSCRIPT
             specifies a Postscript formatted file.
 
Examples:
    PRINTER TYPE ASCII
    PRINTER TYPE POSTSCRIPT
 
Default:
    The output is sent as a plain ASCII text file.
 
Synonyms:
    None
 
Related Commands:
    / PRINTER     = Re-executes saved commands and re-directs the
                    output to a printer.
    SAVE          = Specify commands to be saved for subsequent
                    re-execution.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----PRINTING-------------------------------------------------------
 
PRINTING
 
Name:
    PRINTING
 
Type:
    Support Command
 
Purpose:
    Specifies whether the usual tabular output that is generated by
    most analysis category commands (FIT, SMOOTH, ANOVA, SUMMARY,
    etc.) should be printed or suppressed.
 
Syntax:
    PRINTING   <ON or OFF>
    where ON specifies that the output should be printed while OFF
             specifies that is should not be printed.
 
Examples:
    PRINTING ON
    PRINTING OFF
    PRINTING
 
Note:
    The PRINTING command with no arguments is equivalent to
    PRINTING ON.
 
Default:
    At sign-on, the default is printing (i.e., ON).
 
Synonyms:
    None
 
Related Commands:
    ECHO         = Allows/suppresses command echoing.
    FEEDBACK     = Allows/suppresses feedback messages.
    PROMPT       = Allows/suppresses the prompt character.
    SET          = Sets the value of an internal variable (e.g., IPR).
    PROBE        = Displays the value of an internal variable (e.g.,
                   IPR).
 
Applications:
    Presentation
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----PROBABILITY PLOT-------------------------------------------------
 
PROBABILITY PLOT
 
Name:
    ... PROBABILITY PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a probability plot for one of 130+ distributions.
 
Description:
    A probability plot is a graphical data analysis technique for
    determining how well the specified distribution fits the data
    set.  Linearity in the probability plot is indicative of a good
    distributional fit.

    The probability plot consists of:

       Vertical   axis = ordered observations;
       Horizontal axis = percent point function of the order
                         statistic medians.

    This is essentially a plot of the data percentiles versus
    the percentiles of the theoretical distribution.  Dataplot
    computes the percent point function of the uniform order
    statistic medians to compute the percentiles of the theoretical
    distribution.

    DATAPLOT has extensive probability plot capabilities (130+
    distributions/distributional families are available).  When
    distributional families are specified, the LET command is used
    before the PROBABILITY PLOT command to specify which member
    of the distributional family is desired.  For example,

       LET GAMMA = 5.3
       WEIBULL PROBABILITY PLOT Y

    The name of the distributional parameter for families is given in
    the list below.
 
    Probability plots serve two primary uses.

       1) Distributional Modeling

          The slope and intercept of the line fit to the probability
          plot are estimates for the location and scale parameters
          of the distribution.

          The following provides one possible approach to
          distributional modeling.

          a) If the distribution has one or two shape parameters,
             use the PPCC PLOT or KS PLOT to obtain estimates for
             the shape parameters (HELP PPCC PLOT or HELP KS PLOT for
             details).

          b) Once the shape parameters (if any) have been estimated,
             generate the probability plot to obtain estimates for
             the location and scale parameters.

          c) The bootstrap can be used to obtain confidence intervals
             for the distribution parameters and selected quantiles.
             Enter HELP DISTRIBUTIONAL BOOTSTRAP for details.

       2) Goodness of Fit

          The probability plot provides a graphical assessment of
          goodness of fit.  The straighter the probability plot,
          the better the fit.  One advantage of the graphical
          approach over quantitative measures (e.g., Kolmogorov-Smirnov
          test) is that it provides an indication of how the
          distribution is not a good fit.  This can provide guidance
          to a better distributional model.

          The correlation coefficient of the points on the probability
          plot provides a numerical measure of the straightness of
          the probability plot.  Dataplot automatically saves this
          value in the internal parameter PPCC.  The PPCC values
          provide a useful ranking measure when comparing different
          distributional models.
        
Syntax 1:
    <dist>  PROBABILITY PLOT  <y>   <SUBSET/EXCEPT/FOR/qualification>
    where <y> is a response variable of raw data values;
          <dist> is one of the following distributions:

          Distributions with only location and scale parameters
            1) NORMAL
            2) HALFNORMAL
            3) SLASH
            4) COSINE
            5) LOGISTIC
            6) HALF LOGISTIC
            7) HYPERBOLIC SECANT
            8) CAUCHY
            9) HALF CAUCHY
           10) DOUBLE EXPONENTIAL
           11) EXPONENTIAL
           12) EXTREME VALUE TYPE 1  (or GUMBEL)
           13) UNIFORM
           14) SEMI-CIRCULAR
           15) ANGLIT
           16) ARCSIN
           17) RAYLEIGH

          Distributions with one shape parameter
            1) MAXWELL                     (SIGMA)
            2) WEIBULL                     (GAMMA)
            3) DOUBLE WEIBULL              (GAMMA)
            4) INVERTED WEIBULL            (GAMMA)
            5) GAMMA                       (GAMMA)
            6) LOG GAMMA                   (GAMMA)
            7) DOUBLE GAMMA                (GAMMA)
            8) INVERTED GAMMA              (GAMMA)
            9) WALD                        (GAMMA)
           10) FATIGUE LIFE                (GAMMA)
           11) EXTREME VALUE TYPE 2        (GAMMA)
           12) GENERALIZED EXTREME VALUE   (GAMMA)
           13) PARETO                      (GAMMA)
           14) PARETO SECOND KIND          (GAMMA)
           15) GENERALIZED PARETO          (GAMMA)
           16) GENERALIZED HALF LOGISTIC   (GAMMA)
           17) TUKEY LAMBDA                (LAMBDA)
           18) SKEWED NORMAL               (LAMBDA)
           19) SKEW DOUBLE EXPONENTIAL     (LAMBDA)
           20) POISSON                     (LAMBDA)
           21) T                           (NU)
           22) FOLDED T                    (NU)
           23) CHI-SQUARED                 (NU)
           24) CHI                         (NU)
           25) LOGNORMAL                   (SD)
           26) LOG DOUBLE EXPONENTIAL      (ALPHA)
           27) ERROR                       (ALPHA)
           28) GENERALIZED LOGISTIC        (ALPHA)
           29) GENERALIZED LOGISTIC TYPE 2 (ALPHA)
           30) GENERALIZED LOGISTIC TYPE 3 (ALPHA)
           31) GENERALIZED LOGISTIC TYPE 5 (ALPHA)
           32) MCLEISH                     (ALPHA)
           33) ZETA                        (ALPHA)
           34) WRAPPED CAUCHY              (C)
           35) POWER FUNCTION              (C)
           36) TRIANGULAR                  (C)
           37) LOG LOGISTIC                (DELTA)
           38) VON-MISES                   (B)
           39) DISCRETE UNIFORM            (N)
           40) LEADS IN COIN TOSSING       (N)
           41) GEOMETRIC                   (P)
           42) YULE                        (P)
           43) LOGARITHMIC SERIES          (THETA)
           44) RECIPROCAL                  (B)
           45) BRADFORD                    (BETA)
           46) TOPP AND LEONE              (BETA)
           47) ASYMMETRIC DOUBLE EXPO      (K)
           48) CLASSICAL MATCHING          (K)

          Distributions with two shape parameter
            1) POWER-NORMAL                (P, SD)
            2) POWER-LOGNORMAL             (P, SD)
            3) FOLDED NORMAL               (M, SD)
            4) FOLDED CAUCHY               (M, SD)
            5) SKEWED T                    (LAMBDA, NU)
            6) NONCENTRAL T                (NU, LAMBDA)
            7) NONCENTRAL CHISQUARE        (NU, LAMBDA)
            8) LOG SKEWED NORMAL           (LAMBDA, SD)
            9) BOREL TANNER                (LAMBDA, K)
           10) LAGRANGE POISSON            (LAMBDA, THETA)
           11) BETA                        (ALPHA, BETA)
           12) INVERTED BETA               (ALPHA, BETA)
           13) BETA BINOMIAL               (ALPHA, BETA)
           14) HERMITE                     (ALPHA, BETA)
           15) EXPONENTIAL POWER           (ALPHA, BETA)
           16) BETA NORMAL                 (ALPHA, BETA)
           17) ASYMMETRIC LOG DOUBLE EXPO  (ALPHA, BETA)
           18) BETA GEOMETRIC              (ALPHA, BETA)
           19) ALPHA                       (ALPHA, BETA)
           20) KATZ                        (ALPHA, BETA)
           21) GENERALIZED TOPP AND LEONE  (ALPHA, BETA)
           22) REFLECTED GENE TOPP LEONE   (ALPHA, BETA)
           23) G AND H                     (G, H)
           24) JOHNSON SB                  (ALPHA1, ALPHA2)
           25) JOHNSON SU                  (ALPHA1, ALPHA2)
           26) EXPONENTIATED WEIBULL       (GAMMA, THETA)
           27) GENERALIZED GAMMA           (GAMMA, C)
           28) INVERSE GAUSSIAN            (GAMMA, MU)
           29) RECIPROCAL INVERSE GAUSSIAN (GAMMA, MU)
           30) F                           (NU1, NU2)
           31) TWO-SIDED POWER             (THETA, N)
           32) POLYA AEPPLI                (THETA, P)
           33) GENERALIZED LOGA SERIES     (THETA, BETA)
           34) GEETA                       (THETA, BETA or MU, BETA)
           35) CONSUL                      (THETA, BETA or MU, BETA)
           36) BINOMIAL                    (N, P)
           37) WARING                      (A, C)
           38) GOMPERTZ                    (C, B)
           39) GENERALIZED MCLEISH         (ALPHA, A)
           40) ZIPF                        (ALPHA, N)
           41) NEGATIVE BINOMIAL           (K, P)
           42) GENERALIZED LOGISTIC TYPE 4 (P, Q)
           43) LOST GAMES                  (P, R)
           44) DISCRETE WEIBULL            (BETA, Q)
           45) CONSUL                      (THETA, M)

          Distributions with three or more shape parameter
            1) LOG SKEWED T                (LAMBDA, NU, SD)
            2) DOUBLY NONCENTRAL T         (NU, LAMBDA1, LAMBDA2)
            3) NONCENTRAL F                (NU1, NU2, LAMBDA)
            4) NONCENTRAL BETA             (ALPHA, BETA, LAMBDA)
            5) TRUNCATED EXPONENTIAL       (X0, M, SD)
            6) GENERALIZED EXPONENTIAL     (LAMBDA1, LAMBDA2, S)
            7) GOMPERTZ-MAKEHAM            (XI, LAMBDA, THETA)
            8) MIELKE BETA-KAPPA           (BETA, THETA, K)
            9) HYPERGEOMETRIC              (K, N, M)
           10) GENERALIZED INVERSE GAUSS   (CHI, LAMBDA, THETA)
           11) BESSEL I                    (SIGMA1SQ, SIGMA2SQ, NU)
                                           (B, C, M)
           12) BESSEL K                    (SIGMA1SQ, SIGMA2SQ, NU)
                                           (B, C, M)
           13) WAKEBY                      (GAMMA, BETA, DELTA)
           14) BETA-NEGATIVE BINOMIAL      (ALPHA, BETA, K)
           15) GENERALIZED NEGATIVE BINO   (THETA, BETA, M)
           16) QUASI BINOMIAL TYPE I       (P, M, PHI)
           17) GENERALIZED LOST GAMES      (P, A, J)

           18) DOUBLY NONCENTRAL F         (NU1, NU2, LAMBDA1, LAMBDA2)
           19) TRUNCATED NORMAL            (A, B, M, SD)
           20) TRAPEZOID                   (A, B, C, D)
           21) LOG BETA                    (ALPHA, BETA, C, D)
           22) TRUNCATED GENE NEGA BINO    (THETA, BETA, M, N)

           23) NORMAL MIXTURE              (MU1, SD1, MU2, SD2, P)
           24) BI-WEIBULL                  (SCALE1, GAMMA1, LOC2, SCALE2,
                                           GAMMA2)

           25) GENERALIZED TRAPEZOID       (A, B, C, D, NU1, NU3, ALPHA)
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where we have raw data.  Note that
    the response variable can also be a matrix.  If a matrix name is
    encountered, a probability plot will be drawn for all values in
    the matrix.

Syntax 2:
    <dist> CENSORED PROBABILITY PLOT <y> <x>
                      <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of raw data values under analysis;
          <x> is the censoring variable;
          <dist> is one of the distributions listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where we have censored data.
    A value of 1 indicates a failure time and a value of 0 indicates
    a censoring time.

    Censoring is not supported for discrete disributions or grouped data.

Syntax 3:
    <dist> PROBABILITY PLOT <y> <x>
                      <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of pre-computed frequencies;
          <x> is the variable of distinct values for the variable under
              analysis;
          <dist> is one of the distributions listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where we have frequency
    (binned) data.  The bins are defined by their mid-points.

Syntax 4:
    <dist> CENSORED PROBABILITY PLOT <y> <censor> <x>
                      <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of pre-computed frequencies;
          <censor> is a censoring variable;
          <x> is the variable of distinct values for the variable under
              analysis;
          <dist> is one of the distributions listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where we have frequency (binned)
    data with censoring.  The bins are defined by their mid-points.
    When a particular bin has both censored and uncensored data,
    there will be 2 rows with the same value for <x>.

    A value of 1 indicates a failure time and a value of 0 indicates
    a censoring time for the censoring variable.

    Censoring is not supported for discrete disributions or grouped data.

Syntax 5:
    <dist> PROBABILITY PLOT <y> <xlow> <xhigh>
                      <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of pre-computed frequencies;
          <xlow> is the variable containing the bin lower limit
              values;
          <xhigh> is the variable containing the bin upper limit
              values;
          <dist> is one of the distributions listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where we have frequency
    (binned) data.  The bins are defined by their lower and upper
    limits.  This syntax allows bins with unequal widths.

Syntax 6:
    <dist> CENSORED PROBABILITY PLOT <y> <censor> <xlow> <xhigh>
                      <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the variable of pre-computed frequencies;
          <censor> is a censoring variable;
          <xlow> is the variable containing the bin lower limit
              values;
          <xhigh> is the variable containing the bin upper limit
              values;
          <dist> is one of the distributions listed above;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where we have frequency (binned)
    data with censoring.  The bins are defined by their lower and upper
    limits.  This syntax allows bins with unequal widths.
    When a particular bin has both censored and uncensored data,
    there will be 2 rows with the same values for <xlow> and <xhigh>.

    A value of 1 indicates a failure time and a value of 0 indicates
    a censoring time for the censoring variable.

    Censoring is not supported for discrete disributions or grouped data.

Syntax 7:
    <dist>  MULTIPLE PROBABILITY PLOT  <y1> ... <yk>
                                       <SUBSET/EXCEPT/FOR/qualification>
    where <y1> ... <yk> is a list of response variables;
          <dist> is one of the supported distributions (see syntax 1);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    Note that response variables can also be matrices.  If a matrix
    name is encountered, a probability plot  will be drawn for
    all the values in the matrix.  For multiple response variables,
    the probability plots will be overlaid on the same plot.

Syntax 8:
    <dist>  REPLICATED PROBABILITY PLOT  <y>  <x1> ... <xk>
                                   <SUBSET/EXCEPT/FOR/qualification>
    where <y> is a response variable;
          <x1> .... <xk> is a list of one to six group-id variables;
          <dist> is one of the supported distributions (see syntax 1);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    The group-id variables are cross-tabulated and a probability
    plot will be generated for each distinct combination of values
    for the group-id variables.  These plots will be overlaid on the
    same plot.

Syntax 9:
    <dist>  REPLICATED CENSORED PROBABILITY PLOT <y> <x> <x1>  ... <xk>
                                <SUBSET/EXCEPT/FOR/qualification>
    where <y> is a response variable;
          <x> is a censoring variable;
          <x2> is a group-id variable;
          <x1> .... <xk> is a list of one to six group-id variables;
          <dist> is one of the supported distributions (see syntax 1);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    The group-id variables are cross-tabulated and a probability
    plot will be generated for each distinct combination of values
    for the group-id variables.  These plots will be overlaid on the
    same plot.

    This syntax is used for the case where we have censored data
    in addition to replication.  A value of 1 indicates a failure time
    and a value of 0 indicates a censoring time.

    Censoring is not supported for discrete disributions or grouped data.

Syntax 10:
    <dist>  SUBSET PROBABILITY PLOT  <y> <x1> ... <xk>
                                     <SUBSET/EXCEPT/FOR/qualification>
    where <y> is a response variable;
          <x1> ... <xk> is a list of one to two group-id variables;
          <dist> is one of the supported distributions (see syntax 1);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    The SUBSET option is similar to but distinct from the REPLICATED
    option.  For the REPLICATED option, separate probability plots
    are generated for the distinct groups.  For the SUBSET option, a
    single probability is generated.  However, the different groups
    in the data can be drawn with separate attributes.

Examples:
    NORMAL PROBABILITY PLOT X
    CAUCHY PROBABILITY PLOT X
    TUKEY LAMBDA PROBABILITY PLOT X
    LOGNORMAL PROBABILITY PLOT X
    WEIBULL PROBABILITY PLOT X
    EXTREME VALUE TYPE 1 PROBABILITY PLOT X
    POISSON PROBABILITY PLOT X
    NORMAL PROBABILITY PLOT F X
    CAUCHY PROBABILITY PLOT F X
    TUKEY LAMBDA PROBABILITY PLOT F X
    LOGNORMAL PROBABILITY PLOT F X
    WEIBULL PROBABILITY PLOT F X
    EXTREME VALUE TYPE 1 PROBABILITY PLOT F X
    POISSON PROBABILITY PLOT F X
 
Note:
    The PROBABILITY PLOT command automatically saves the following
    parameters:

        PPCC       - the correlation coeffcient of the points on
                     the probability plot
        PPA0       - the intercept of the line fitted to the probability
                     plot (estimate of the location parameter)
        PPA1       - the slope of the line fitted to the probability
                     plot (estimate of the scale parameter)
        SDPPA0     - the standard deviation of PPA0
        SDPPA1     - the standard deviation of PPA1
        PPRESSD    - the residual standard deviation of the line fitted
                     to the probability plot
        PPRESDF    - the residual degrees of freedom of the line fitted
                     to the probability plot
        PPA0BW     - the intercept of the line fitted to the probability
                     plot with biweight weighting of the residuals
        PPA1BW     - the slope of the line fitted to the probability
                     plot with biweight weighting of the residuals

    The PPCC value provides a measure of the linearity of the
    probability plot.

    The PPA0 and PPA1 provides estimates of the location and scale
    parameters.

    For some distributions with heavy tails (e.g., Cauchy, slash),
    there can be extreme variability in the first few and last few
    points in the probability plot.  This can distort the estimates
    of location and scale.  Two iterations of biweight weighting of
    the residuals are applied to obtain PPA0BW and PPA1BW.  In most
    cases, using PPA0 and PPA1 are preferred.  However, in cases
    where there is extreme non-linearity in the tails, using
    PPA0BW and PPA1BW may be preferred as the location and scale
    estimates.
 
Note:
    For uncensored data, Dataplot uses the uniform order statistic
    medians to determine the plotting positions.  This needs to be
    modified somewhat for censored data.

    For singly censored data (i.e., all the censored data have
    the same censoring time), we can use the N from the full sample
    to compute the uniform order statistics.  However, we only plot
    the failure times.

    An alternative that works with both singly and multiply (the
    censoring times are not necessarily the same) is to base the
    plotting positions on the Kaplan-Meier statistic.  That is,

    p(i) = ((n+0.7)/(n+0.4))*PRODUCT[k=1 to i][((n-k+0.7)/(n-k+1.7)]

    with n denoting the full sample size. Again, only plotting
    positiions corresponding to failure times are plotted.
    The percent point function is computed on the p(i) values.

    This method for censored probability plots is discussed in
    more detail on pp. 43-46 of the Bury book (see the References
    section below).

    To specify which method to use, enter the command

          SET CENSORED PROBABILITY PLOT
              <KAPLAN-MEIER/UNIFORM ORDER STATISTIC MEDIANS>

Note:
    An alternative to binning data is to use the command

         SET PROBABILITY PLOT DATA POINTS <value>

    When this command is entered, Dataplot will compute <value>
    equally spaced percentiles and compute the probability plot
    on these percentiles.  This option can be useful when generating
    probability plots on large data sets for distributions with
    expensive percent point functions.

Note:
    For discrete distributions, the data will typicall consist of
    integers.  In this case, it is helpful to group the data based
    on these integer values.  The following code shows the
    recommended way for doing this:

      LET YLOW = MINIMUM Y
      LET YUPP = MAXIMUM Y
      LET YLOW = YLOW - 0.5
      CLASS LOWER YLOW
      LET YUPP = YUPP + 0.5
      CLASS UPPER YUPP
      CLASS WIDTH = 1
      LET Y2 X2 = BINNED Y
      LET LAMBDA = 4.2
      POISSON PROBABILITY PLOT Y2 X2

    This will center the bins around the integer values and will
    cover the first and last class.

Note:
    By default, the theoretical distribution is plotted for the
    standard form (i.e., location = 0, scale = 1).  The slope
    and intercept of the line fit to points on the probability
    plot provide estimates for the location and scale parameters.

    However, if the location/scale parameters are estimated by
    some other method (e.g., maximum likelihood), it may be
    desirable to fix the location/scale parameters on the
    probability plot.  To do this, enter the commands

        LET PPLOC = <value>
        LET PPSCALE = <value>

Note:
    The TO syntax is supported for the PROBABILITY PLOT command.
    It is most useful for the MULTIPLE version of the command.

Default:
    None
 
Synonyms:
    EV2 and FRECHET are synonyms for EXTREME VALUE TYPE 2.
    EV1 and GUMBEL are synonyms for EXTREME VALUE TYPE 1.
    FATIGUE LIFE is a synonym for FL.
    RECIPROCAL INVERSE GAUSSIAN is a synonym for RIG.
    IG is a synonym for INVERSE GAUSSIAN.
    SKEW LAPLACE is a synonym for SKEW DOUBLE EXPONENTIAL
    ASYMMETRIC LAPLACE is a synonym for ASYMMETRIC DOUBLE EXPONENTIAL
    HIGHLIGHT PROBABILITY PLOT is a synonym for SUBSET PROBABILITY PLOT
 
Related Commands:
    FREQUENCY PLOT     = Generates a frequency plot.
    HISTOGRAM          = Generates a histogram.
    PIE CHART          = Generates a pie chart.
    PERCENT POINT PLOT = Generates a percent point plot.
    PPCC PLOT          = Generates probability plot correlation
                         coefficient plot.
    PLOT               = Generates a data or function plot.
 
References:
    "The Probability Plot Correlation Coefficient Test for Normality",
    James J. Filliben,  Technometrics, Vol. 17, No. 1, February 1975.
 
    "Graphical Methods of Data Analysis", Chambers, Cleveland, Kleiner,
    and Tukey,  Wadsworth, 1983.
 
    "Statistical Distributions in Engineering", Karl Bury, Cambridge
    University Press, 1999.

Applications:
    Distributional Analysis
 
Implementation Date:
    Pre-1987 
       1990/5: WALD, FL, RIG, INVERSE GAUSSIAN
       1993/12: GENERALIZED PARETO
       1994/9: DISCRETE UNIFORM, NON-CENTRAL T, 
               NON-CENTRAL F, NON-CENTRAL CHI-SQUARE,
               NON-CENTRAL BETA, DOUBLY NON-CENTRAL T,
               DOUBLY NON-CENTRAL F, HYPERGEOMETRIC
       1994/10: VON-MISES
       1995/5: POWER LOGNORMAL, POWER NORMAL, COSINE,
               ALPHA, POWER FUNCTION, CHI,
               LOGARITHMIC SERIES, LOG LOGISTIC, 
               GENERALIZED GAMMA, WARING
       1995/9: ANGLIT, ARCSIN, FOLDED NORMAL, TRUNCATED NORMAL
       1995/10: LOG GAMMA, HYPERBOLIC SECANT, GOMPERTZ
       1995/12: PARETO SECOND KIND, DOUBLE WEIBULL,
                WRAPPED UP CAUCHY, EXPONENTIATED WEIBULL,
                TRUNCATED EXPONENTIAL
                GENERALIZED LOGISTIC, EXPONENTIAL POWER
       1996/1: DOUBLE GAMMA, BETA-KAPPA, FOLDED CAUCHY
       1996/5: BETA BINOMIAL, GENERALIZED EXPONENTIAL
       1998/5: RECIPROCAL, NORMAL MIXTURE, INVERTED GAMMA
       2001/10: GENERALIZED LAMBDA, JOHNSON SU,
                JOHNSON SB, INVERTED WEIBULL,
                LOG DOUBLE EXPONENTIAL
       2002/5: TWO-SIDED POWER, BI-WEIBULL
       2003/5: ERROR
       2004/1: TRAPEZOID, GENERALIZED TRAPEZOID, FOLDED T,
               SKEWED T, SKEWED NORMAL, SLASH, INVERTED BETA,
               G AND H
       2004/5: Implemented the automatic computation of the
               biweight fit (PPA0BW and PPA1BW)
       2004/5: LOG SKEW NORMAL, LOG SKEW T, HERMITE, YULE
       2004/5: Fixed a number of bugs for various distributions
       2004/6: SKEW DOUBLE EXPONENTIAL, ASYMMETRIC DOUBLE EXPONENTIAL,
               MAXWELL, RAYLEIGH
       2004/8: Meeker reparameterization of GOMPERTZ MAKEHAM,
               GENERALIZED ASYMMETRIC LAPLACE,
               GENERALIZED INVERSE GAUSSIAN
       2004/9: MCLEISH, GENERALIZED MCLEISH, BESSEL I FUNCTION,
               BESSEL K FUNCTION
       2004/10: SET PROBABILITY DATA POINTS
       2004/10: Support for censored data
       2005/5: Support unequal bin widths for frequency data
       2009/9: Support for TO syntax and matrix arguments
       2009/9: Support for MULTIPLE and REPLICATION options
       2010/1: Support for HIGHLIGHT/SUBSET option
 
Program:
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE AUTOMATIC; X1LABEL THEORETICAL VALUE; Y1LABEL DATA VALUE
    .
    LET Y = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    NORMAL PROBABILITY PLOT Y
    .
    LET NU = 5
    LET Y = CHI-SQUARE RANDOM NUMBERS FOR I = 1 1 100
    CHI-SQUARE PROBABILITY PLOT Y
    .
    LET Y = EXPONENTIAL RANDOM NUMBERS FOR I = 1 1 100
    EXPONENTIAL PROBABILITY PLOT Y
    .
    LET Y = CAUCHY RANDOM NUMBERS FOR I = 1 1 1000
    LEGEND 1 CAUCHY RANDOM NUMBERS
    NORMAL PROBABILITY PLOT Y
    END OF MULTIPLOT
 
-----PROBABILITY WEIGHTED MOMENTS (LET)----------------------------
 
PROBABILITY WEIGHTED MOMENTS
 
Name:
    PROBABILITY WEIGHTED MOMENTS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the probability weighted moments of a variable.
 
Description:
    Given a random variable X with a cumulative distribution
    function F, the probability weighted moments are defined
    to be:

        M(p,r,s) = E[X**p{F(X)}**r{1 - F(X)}**s]

    Two special cases are

        alpha(r) = M(1,0,r) = E[X{1 - F(X)}**r]
        beta(r)  = M(1,r,0) = E[X{F(X)}**r]

    For an ordered sample x(1:n) <= x(2:n) <= ... <= x(n:n),
    unbiased estimators of alpha(r) and beta(r) are:

        a(r) = (1/n)*SUM[j=1 to n][(n-j)*(n-j-1)* ... *(n-j-r+1)/
               ((n-1)*(n-2)* ... *(n-r))]*xj:n

        b(r) = (1/n)*SUM[j=1 to n][(j-1)*(j-2)* ... *(j-r)/
               ((n-1)*(n-2)* ,,,*(n-r))]*xj:n

     The primary use of probability weighted moments (and the
     related L-moments) is in the estimation of parameters for
     a probability distribution.  For a more detailed description
     of probability weighted moments and L-moments, see the papers
     listed in the References section below (in particular, the
     papers by Hoskings).  Estimates based on probability
     weighted moments are often considered to be superior to
     standard moment-based estimates.  They are sometimes used
     when maximum likelihood estimates are unavailable or
     difficult to compute.  They may also be used as starting
     values for maximum likelihood estimates.  Estimation methods
     based on probability weighted moments are discussed 
     in the papers listed in the Reference section below
     (Dataplot generates L-moment based estimates for the
     maximum likelihood estimates for the generalized Pareto and
     the generalized extreme value distributions).
     
Syntax 1:
    LET <y> = PROBABILITY WEIGHTED MOMENTS <x> <nmom>
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is the response variable;
          <nmom> is the number of probability weighted moments
              that will be generated;
          <y> is a variable where the computed probability
              weighted moments are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the alpha probability weighted moments.

Syntax 2:
    LET <y> = BETA PROBABILITY WEIGHTED MOMENTS <x> <nmom>
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is the response variable;
          <nmom> is the number of probability weighted moments
              that will be generated;
          <y> is a variable where the computed probability
              weighted moments are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the beta probability weighted moments.

Examples:
    LET PWM = PROBABILITY WEIGHTED MOMENTS Y 5
    LET PWM = PROBABILITY WEIGHTED MOMENTS Y 4  SUBSET Y > 0
 
Note:
    Dataplot computes probability weighted moments using the
    SAMPWM routine written by Hoskings and documented in
    "Research Report: Fortran Routines for use with the Method
    of L-Moments" (see the Reference section below).
 
    This routine is available from the statlib archive
    (http://lib.stat.cmu.edu/) at the following URL

        http://lib.stat.cmu.edu/general/lmoments

Note:
    L-moments   are  linear combinations  of  probability weighted
    moments  and are frequently used  in the application of probability
    weighted moments.

Default:
    If the <nmom> parameter is omitted from the command, the
    first four sample probability weighted moments are computed.
 
    By default, Dataplot computes the alpha probability weighted
    moments.

Synonyms:
    None
 
Related Commands:
    L MOMENTS           = Compute the sample L-moments of a
                          variable.
    MAXIMUM LIKELIHOOD  = Compute maximum likelihood estimates for
                          a probability distribution.

References:
    "Research Report: Fortran Routines for use with the Method
    of L-Moments", J. R. M. Hosking, IBM Research Division,
    T. J. Watson Research Center, Yorktown Heights, NY 10598,
    6/2000.
 
    "Probability Weighted Moments: Definition and Relation to
    Parameters of Several Distributions Expressable in Inverse
    Form", Greenwood, Landwehr, Matalas, and Wallis, Water
    Resources Research, 15, 1079, 1049-1054.

    "Estimation of the Generalized Extreme Value Distribution
    by the Method of Probability-Weighte Moments", Hosking,
    Wallis, and Wood, Technometrics, 27, 1985, 251-261.

    "Probability Weighted Moments Compared with Some Traditional
    Techniques in Estimating Gumbel Parameters and Quantiles",
    Landwehr, Matalas, Wallis, Water Resources Research,
    15, (1979a), 1055-1064.

Applications:
    Distributional Modeling
 
Implementation Date:
    2005/12
 
Program:
    LET GAMMA = -0.3
    LET Y = GENERALIZED PARETO RANDOM NUMBERS FOR I = 1 1 100
    LET Y = 5*Y + 2
    LET PROBMOME = PROBABILITY WEIGHTED MOMENTS Y

-----PROBE---------------------------------------------

PROBE

Name:
    PROBE
 
Type:
    Support Command
 
Purpose:
    Dumps (prints out) the contents of certain internal underlying
    Fortran variables.
 
Description:
    This command provides information which may assist in
    implementation and debugging.  Hence it is normally only used by
    the service group which implements DATAPLOT on your computer.
 
Syntax:
    PROBE   <name>
    where <name> is the underlying Fortran variable to print.
 
Examples:
    PROBE NUMCOL
    PROBE NUMNAM
    PROBE IBUGSU
 
Note:
    The list of the variables that can probed is documented under
    the SET command.  Enter HELP SET to examine the list.
 
Note:
    The PROBE command is used to return the values of certain
    internal parameters and strings.  This command was updated
    so that the returned value is automatically saved.  If the
    returned value is an integer or real number, then the value
    is stored in the internal parameter PROBEVAL.  If the
    returned value is a string, then the value is stored in the
    internal string PROBESTR.  PROBESTR and PROBEVAL can then be
    used in the same way as other parameters and strings.

    This feature is typically used in macros.  For example, you
    might want to use the machine maximum value as a "missing
    value" indicator.  A host independent way of using this value
    would now be:

       PROBE CPUMAX
       LET MACHMAX = PROBVAL

    You could then use the parameter MACHMAX wherever you wanted
    to define a missing value.

    This feature was implemented 1998/8.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SET   = Specify the value for an underlying Fortran variable.
 
Applications:
    Implementation and debugging
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----PROCESS ID---------------------------------------------------
 
PROCESS ID
 
Name:
    PROCESS ID
 
Type:
    Support Command
 
Purpose:
    The PROCESS ID command returns the process id and stores it
    in the internal Dataplot parameter PID.
 
Description:
    This command is compiler dependent.  Dataplot currently
    supports this command on the following compilers/platforms:

       1. INTEL Fortran compiler (Windows 2000/XP)
       2. g77 (Linux, cygwin, Sun Solaris)
 
    The primary use of this command is to generate unique
    file names (for an example, see the Program example below).

Syntax:
    PROCESS ID
 
Example:
    PROCESS ID
 
Default:
    None
 
Synonyms:
    PID
 
Related Commands:
    SYSTEM        = Issue an operating system command.
    SLEEP         = Pause for <n> seconds.
    CD            = Change the current directory
 
Applications:
    Utility Command
 
Implementation Date:
    2006/3
 
Program:
    LET STRING BASENAME = dppl1f.dat
    PROCESS ID
    LET STRING PLOTNAME = ^basename.^pid
    SET IPL1NA ^PLOTNAME
    DEVICE 2 POSTSCRIPT
    PLOT X**2 FOR X = 1 1 9
    DEVICE 2 CLOSE
    SYSTEM lpr ^PLOTNAME
 
-----PRODUCT (LET)---------------------------------------------------
 
PRODUCT
 
Name:
    PRODUCT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the product of the elements in a variable.
 
Syntax:
    LET <par> = PRODUCT <x1>  <SUBSET/EXCEPT/FOR qualification>
    where <x1> is the variable for which the product will be computed;
          <par> is a parameter where the computed product is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET PROD = PRODUCT Y1
    LET PROD = PRODUCT Y1  SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SEQUENCE       = Generate a sequence of numbers.
    PATTERN        = Generate numbers with a specific pattern.
    SUM            = Compute the sum of the elements in a variable.
    INTEGRAL       = Compute the integral of the elements in a variable.
    PRODUCT PLOT   = Generate a products (versus subsets) plot.
 
Applications:
    Rare Usage
 
Implementation Date:
    XX
 
Program:
    .  THIS EXAMPLE COMPUTES FACTORIALS
    LET N = 10
    LOOP FOR K = 1 1 N
       LET Y1 = SEQUENCE 1 1 K
       LET A = PRODUCT Y1
       PRINT K A
    END OF LOOP
 
-----PRODUCT PLOT---------------------------------------------------
 
PRODUCT PLOT
 
Name:
    PRODUCT PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a product plot.
 
Description:
    A product plot is a plot consisting of subsample products versus
    subsample index.  The subsample product is the product of the data
    in the subsample.  The product plot is used to answer the
    question-- "Does the subsample product change over different
    subsamples?".  The plot consists of:
       Vertical   axis = subsample product;
       Horizontal axis = subsample index.
    The PRODUCT PLOT yields 2 traces--
       1. a subsample product trace; and
       2. a full-sample product reference line.
    Like usual, the appearance of these 2 traces is
    controlled by the first 2 settings of the LINES,
    CHARACTERS, SPIKES, BARS, and similar attributes.
 
Syntax:
    PRODUCT PLOT   <y>   <x>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    PRODUCT PLOT Y X
    PRODUCT PLOT Y X1  SUBSET X1 < 22
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS         = Sets the type for plot characters.
    LINES              = Sets the type for plot lines.
    SUM PLOT           = Generates a sum plot.
    PLOT               = Generates a data or function plot.
 
Applications:
    Rare Usage
 
Implementation Date:
    88/9
 
Program:
    LET Y = DATA 2 4 5 10 4 10 8 2 3
    LET X = DATA 1 1 1 2 2 3 3 3 3
    LINE BLANK DASH
    CHARACTER X BLANK
    XLIMITS 0.5 3.5
    YLIMITS 0 500
    Y1LABEL PRODUCT
    X1LABEL GROUP ID
    PRODUCT PLOT Y X
 
-----PROFICIENCY TEST --------------------------------------------

PROFICIENCY TEST
 
Name:
    PROFICIENCY TEST
 
Type:
    Analysis Command
 
Purpose:
    Generate the tables for either a one-sample or a two-sample
    proficiency test as defined by the ASTM E 2489 - 06 standard.
 
Description:
    The following document

        "Standard Practice for Statistical Analysis of One-Sample
        and Two-Sample Proficiency Testing Programs", ASTM
        International, 100 Barr Harbor Drive, PO BOX C700,
        West Conshohoceken, PA 19428-2959, USA.

    describes a methodology for performing either a one-sample or
    a two-sample proficiency test.

    Proficiency testing is the use of interlaboratory
    comparisons for the determination of laboratory testing
    or measurement performance.  The methods in the E 2489- 06
    standard provide direction for assessing and categorizing
    the performances of individual laboratories based on the
    relative likelihood of occurence of their test results.

    The standard recommends a minimum of 10 laboratories and states
    that it is desirable to have 30 or more participating
    laboratories.

    Proficiency testing programs typically have a larger number
    of participants than an interlaboratory test.  This results
    in a wider variation of test conditions, so a proficiency
    test can provide more information regarding the precision
    of test results that may be expected when a test method
    is used in the general testing community.

    In this standard, the median is used as the consensus value.
    The measure of variablility is the interquartile range.  In
    this standard, the interquartile range is defined as the difference
    between the upper hinge and the lower hinge (this is slightly
    different than the standard definition of the interquartile range
    as the difference between the 75th percentile and the 25th
    percentile).

    The lower hinge is the median of the points less than or
    equal to the median and the upper hinge is the median of the
    points greater than or equal to the median.

    The inner fence is the value equal to the upper (lower)
    hinge of the data set plus (upper) or minus (lower)
    1.5 times the interquartile range.

    The outer fence is the value equal to the upper (lower)
    hinge of the data set plus (upper) or minus (lower)
    3.0 times the interquartile range.

    A test result that is between the lower inner fence and
    upper inner fence is labeled as "typical".  A test result
    that is between the inner and outer fence values is labeled
    as "unusual".  A test result that is beyond the outer fence
    values is labeled as "extremely unusual".

    These statistics are used because they are both simple and robust.
    Note that the above values are used in generating a box plot.

Description of One-Sample Proficiency Test:
    The data consists of:

        1. A response variable containing measurements on a sample
        2. A lab-id variable

    For a one-sample proficiency analysis, each lab reports a
    single test result.

    This E 2489 one-sample proficiency analysis generates the three
    tables documented in the above document:

       1) The test results sorted by lab-id.

          The purpose of this table is to make it easy to
          identify the results for a given laboratory.

       2) The test results sorted in descending order with the
          median and lower and upper hinges marked.  Each lab's
          result is categorized as "extremely unusual", "unusual",
          or typical.

          The purpose of this table is to show the range and
          distribution of the test results.

       3) The test results sorted in descending order (as in
          table 2).  However, the data are divided into bins.

          The purpose of this table is to show the range and
          distribution of the test results.

    In addition to the tables, the standard also recommends
    complementing the tables with a dot plot.  These are also
    known as dot diagrams or strip plots.  In Dataplot, these are
    referred to as strip plots.  Enter the command HELP STRIP PLOT
    for details on generating these plots in Dataplot.  The first
    program example below demonstrates this plot.

    A strip plot is an alternative to a histogram for displaying
    univariate data.  The x-axis contains the value of the test result
    and the y-axis is simply a constant value.  If two or more test
    results have the same value, the points are stacked vertically.
    You can draw the points are drawn as filled circles.  Alternatively,
    you can draw the points drawn as the lab-id (this is useful for
    identifying outlying labs).

    You can also generate the strip plot with the data divided
    into bins (you can specify the bin width and the starting
    and ending bin limits).  In this form, the vertical axis
    will represent the number of occurences.  This form
    of the strip plot is essentially a histogram.

    Although the E 2489 - 06 standard does not explicitly talk about
    box plots, these can also be a useful complement to the tables since
    the box plot is a graphical representation of table 2.

Description of Two-Sample Proficiency Test:
    The data consists of:

        1. A response variable containing measurements on the
           first sample
        2. A response variable containing measurements on the
           second sample
        3. A lab-id variable

    For a two-sample proficiency analysis, each lab reports exactly
    two test results (i.e., a single measurement on each sample).

    The random error quantity is defined as
    
        (X - Y) - (Xmed -Ymed)

    where X and Y denote the test results for sample one and sample two,
    respectively, and Xmed and Ymed denote the medians of sample one and
    sample two, respectively.

    This E 2489 two-sample proficiency analysis generates the three
    tables documented in the above document:

       1) The test results for both samples sorted by lab-id.

          The purpose of this table is to make it easy to
          identify the results for a given laboratory.

       2) The test results sorted in descending order of the
          random error quantity with the median and lower and upper
          hinges marked.  The random error quantity for each lab's
          result is categorized as "extremely unusual", "unusual",
          or "typical".

          The purpose of this table is to show the range and
          distribution of the random error quantities.

       3) The test results sorted in descending order of sample
          two with the median and lower and upper hinges marked.
          The test results for each sample are categorized as
          "extremely unusual", "unusual", or "typical".

          The purpose of this table is to show the range and
          distribution of the test results for each sample.

    The standard also recommends complementing the tables with a
    Youden plot. This is demonstrated in the second program
    example below.

Syntax 1:
    ONE SAMPLE PROFICIENCY TEST <y> <labid>
                                <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <labid> is a lab id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Syntax 2:
    TWO SAMPLE PROFICIENCY TEST <y1> <y2> <labid>
                                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <labid> is a lab id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    ONE SAMPLE PROFICIENCY TEST Y  LABID
    TWO SAMPLE PROFICIENCY TEST Y1  Y2  LABID

Note:
    You can use the CAPTURE HTML command to generate these tables in
    HTML format.  You can use the CAPTURE LATEX command to generate
    these tables in Latex format.  You can use the CAPTURE RTF command
    to generate these tables in Rich Text Format (RTF).

Note:
    In table 2 of the one sample proficiency test, if multiple
    laboratories have the same value, only the first laboratory id is
    printed along with the number of occurrences of that value.

    For the "Unusual" and "Extremely Unusual" categories, it may be
    desirable to print the individual laboratory id's in the table.

    To specify that for both the "Unusual" and "Extremely Unusual"
    categories all laborotories will be identified, enter

        SET ONE SAMPLE PROFICIENCY TEST IDENTIFY LAB UNUSUAL

    To specify that for only the "Extremely Unusual" category all
    laborotories will be identified, enter

        SET ONE SAMPLE PROFICIENCY TEST IDENTIFY LAB EXTREMELY UNUSUAL

    To reset the default, enter

        SET ONE SAMPLE PROFICIENCY TEST IDENTIFY LAB DEFAULT

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    E691 INTERLAB      = Perform an E691 interlaboratory analysis.
    STRIP PLOT         = Generate a strip plot.
    BOX PLOT           = Generate a box plot.
    YOUDEN PLOT        = Generate a Youden plot.
    CAPTURE HTML       = Generate output in HTML format.
    CAPTURE LATEX      = Generate output in Latek format.
    CAPTURE RTF        = Generate output in RTF format.

Reference:
    "Standard Practice for Statistical Analysis of One-Sample
    and Two-Sample Proficiency Testing Programs", ASTM
    International, 100 Barr Harbor Drive, PO BOX C700,
    West Conshohoceken, PA 19428-2959, USA.

Applications:
    Interlaboratory Studies
 
Implementation Date:
    2009/01
    2019/08: Added the SET ONE SAMPLE PROFICIENCY TEST IDENTIFY LAB
             command
 
Program 1:
    .
    .  Read the data
    .
    SKIP 25
    READ E2489A.DAT LABID Y
    .
    .  Generate the tables to the screen
    .
    ONE SAMPLE PROFICIENCY TEST Y LABID
    .
    .  Now generate the tables in RTF format (for import into Word)
    .
    CAPTURE RTF ONE.RTF
    ONE SAMPLE PROFICIENCY TEST Y LABID
    END OF CAPTURE
    .
    .  Generate the strip plot for the raw (unbinned) data
    .
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    Y1LABEL Number of Occurences
    X1LABEL Data Values
    TITLE Dot Diagram for Original Data
    Y1TIC MARKS OFF
    Y1TIC MARK LABELS OFF
    Y2FRAME OFF
    X2FRAME OFF
    YLIMITS 0 2
    MAJOR YTIC MARK NUMBER 3
    MINOR YTIC MARK NUMBER 0
    SET STRIP PLOT STYLE STACK
    SET STRIP PLOT INCREMENT 0.1
    LET STRING SYMBL = CIRCLE
    IF SYMBL = CIRCLE
       CHARACTER CIRCLE ALL
       CHARACTER FILL ON ALL
       CHARACTER HW 1 0.75 ALL
    END OF IF
    IF SYMBL = LABID
       CHARACTER AUTOMATIC LABIDSRT
    END OF IF
    LINE BLANK ALL
    .
    STRIP PLOT Y
    .
    Y1TIC MARKS ON
    Y1TIC MARK LABELS ON
    .
    .  Generate the strip plot for the binned data
    .
    CLASS LOWER 0.5
    CLASS UPPER 5
    CLASS WIDTH 0.1
    FRAME CORNER COORDINATES 15 40 85 70
    Y1LABEL Number of Occurences
    X1LABEL Data Values
    TITLE Dot Diagram for Binned Data
    Y2FRAME OFF
    X2FRAME OFF
    LET MAXFREQ = MAXIMUM Y2
    LET NUMTIC = MAXFREQ + 1
    YLIMITS 0 MAXFREQ
    MAJOR YTIC MARK NUMBER NUMTIC
    MINOR YTIC MARK NUMBER 0
    Y1TIC OFFSET 1 1
    SET STRIP PLOT STYLE STACK
    SET STRIP PLOT INCREMENT 1
    CHARACTER CIRCLE ALL
    CHARACTER FILL ON ALL
    CHARACTER HW 1 0.75 ALL
    LINE BLANK ALL
    Y1TIC OFFSET 0 0
    .
    STRIP PLOT Y2 X2
    .
    FRAME CORNER COORDINATES
    CHAR FILL OFF ALL
    CHAR BLANK ALL
    CHAR HW
    LINE SOLID ALL
    LIMITS
    FRAME ON
    MAJOR TIC MARK NUMBER
    MINOR TIC MARK NUMBER
    .
    .  Now generate a box plot
    .
    Y1LABEL Test Results
    X1LABEL
    TITLE Box Plot for Proficiency Data
    XLIMITS 0 2
    XTIC MARKS OFF
    XTIC MARK LABELS OFF
    CHARACTER BOX PLOT
    LINE BOX PLOT
    FENCES ON
    .
    BOX PLOT Y
    XLIMITS
    X1TIC MARKS ON
    X1TIC MARK LABELS ON

Program 2:
    .
    .  Read the data
    .
    SKIP 25
    READ E2489B.DAT LABID Y1 Y2
    .
    .  Generate the tables to the screen
    .
    TWO SAMPLE PROFICIENCY TEST Y1 Y2 LABID
    .
    .  Now generate the tables in RTF format (for import into Word)
    .
    CAPTURE RTF TWO.RTF
    TWO SAMPLE PROFICIENCY TEST Y1 Y2 LABID
    END OF CAPTURE
    .
    .  Generate the Youden plot
    .
    LET STRING SYMBL = LABID
    IF SYMBL = CIRCLE
       CHARACTER CIRCLE ALL
       CHARACTER FILL ON ALL
       CHARACTER HW 1 0.75 ALL
    END OF IF
    IF SYMBL = BOX
       CHARACTER BOX ALL
       CHARACTER FILL ON ALL
       CHARACTER HW 1 0.75 ALL
    END OF IF
    IF SYMBL = DIAMOND
       CHARACTER DIAMOND ALL
       CHARACTER FILL ON ALL
       CHARACTER HW 1 0.75 ALL
    END OF IF
    IF SYMBL = LABID
       LET LABIDSRT = LABID
       LET YSORT = SORTC Y LABIDSRT
       CHARACTER HW 2 1.50 ALL
       CHARACTER AUTOMATIC LABIDSRT
    END OF IF
    LINE BLANK ALL
    .
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    X1LABEL Test Results for Sample One
    Y1LABEL Test Results for Sample Two
    TITLE Youden Plot of Test Results
    .
    LIMITS 0 5
    TIC OFFSET UNITS DATA
    TIC MARK OFFSET 0 0.5
    .
    YOUDEN PLOT Y2 Y1 LABID
    .
    PROBE FX1MIN
    LET AX1 = PROBEVAL
    PROBE FX1MAX
    LET AX2 = PROBEVAL
    PROBE FY1MIN
    LET AY1 = PROBEVAL
    PROBE FY1MAX
    LET AY2 = PROBEVAL
    .
    LINE SOLID
    DRAWDATA AX1 MEDX AX2 MEDX
    DRAWDATA MEDY AY1 MEDY AY2
    LINE DASH
    DRAWDATA AX1 AY1 AX2 AY2
    LINE SOLID

-----PROFILE PLOT------------------------------------------------
 
PROFILE PLOT
 
Name:
    PROFILE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a profile plot.
 
Description:
    A profile plot is a graphical data analysis technique for examining
    the relative behavior of all variables in a multivariate data set.
    The profile plot consists of a sequence of equi-spaced vertical
    spikes with each spike representing a different variable in the
    multivariate data set.  An individual profile plot examines the
    behavior of all such variables but only for a specified subset of
    the data (e.g., looking at all the attributes of car performance,
    but only for a particular car, such as Chevrolet).  The total length
    of a given spike is uniformly set to unity for sake of reference.
    The "data length" of a given spike is proportional to the magnitude
    of the variable for the subset relative to the maximum magnitude
    of the variable across all subsets.  (Thus we are looking at the
    ratio of the "local" value of the variable to the "global" maximum
    of the variable.) An interconnecting line cutting across each spike
    at the "data length" gives the profile plot its unique appearance
    and name.
 
Syntax:
    PROFILE PLOT <y1> <y2> ... <yk> <SUBSET/EXCEPT/FOR qualification>
    where <y1> ... <yk> are the response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> must be given.  It
            is not optional for this command as it is for most other
            DATAPLOT commands.
 
Examples:
    PROFILE PLOT Y1 Y2 Y3 Y4 Y5 SUBSET AUTO 4
    PROFILE PLOT Y1 Y2 Y3 Y4 Y5 Y6 Y7 Y8 Y9 SUBSET STATE 25
 
Note:
    A few variations of the profile plot exist, all of which DATAPLOT
    can easily generate by judicious use of the components in the LINE,
    CHARACTER, SPIKE, and BAR commands (and their attribute setting
    commands).  For example, suppose there are k variables in the
    profile plot (and so k spikes), then
       1) element 1 of LINES controls the appearance of the
          interconnecting line (this is usually SOLID);
       2) element 1 of SPIKE and SPIKE LINE controls the
          existence and appearance of the spikes from the base
          out to the interconnecting line (some analysts prefer
          this to be SOLID, others prefer this to be DOTTED).
    When using the SPIKE and SPIKE LINES commands in this context, note
    that both must be used if you want spikes to appear.  The SPIKE
    (ON/OFF) command sets whether spikes will appear or not while the
    SPIKE LINES command sets the desired line type (SOLID, DOTTED,
    DASHED, etc.).  Thus SPIKE ON and SPIKE LINES SOLID would for a
    profile plot turn the spikes on and set them to solid, respectively.
 
Note:
    The generation of multiple profile plots per page is typical (one
    profile plot for each subset of interest).  This is easily done in
    DATAPLOT by using the PROFILE PLOT command in conjunction with the
    MULTIPLOT and LOOP commands, as in the following which would
    generate 50 profile plots on the same page, where each profile plot
    would consist of 6 variables (spikes):
       MULTIPLOT 5 10
       LOOP FOR K = 1 1 50
           PROFILE PLOT Y1 Y2 Y3 Y4 Y5 Y6 SUBSET STATE K
       END OF LOOP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STAR PLOT     = Generates a (multivariate) star plot.
    ANDREWS PLOT  = Generates an Andrews (multivariate) plot.
    LINES         = Sets the type for plot lines.
    SPIKES        = Sets the type for plot spikes.
    MULTIPLOT     = Allows multiple plots per page.
    LOOP          = Starts a loop (iteration).
    END OF LOOP   = Terminates a loop.
    ^             = Allows string and value substitution.
 
Reference:
    "Graphical Methods of Data Analysis", Chambers, Cleveland, Kleiner,
    and Tukey.  Wadsworth, 1983 (pp. 162-163).
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    88/3
 
Program:
    READ CITY Y1 TO Y6
    1 18 8 307 130 3504 12
    2 15 7 350 165 3693 11.5
    3 13 8 318 150 3436 11.0
    4 16 6 304 134 3433 111.6
    END OF DATA
    READ STRING S1 S2 S3 S4
    BOSTON PHILADELPHIA CHICAGO DENVER
    LINES SO DO DO DO DO DO DO BL BL BL BL BL BL
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    LOOP FOR K = 1 1 4
    XLABEL ^S^K
    PROFILE PLOT Y1 Y2 Y3 Y4 Y5 Y6 SUBSET CITY K
    END OF LOOP
    END OF MULTIPLOT
 
-----SET PROMPT ADVANCE (SET)--------------------------------------------
 
PROMPT ADVANCE
 
Name:
    SET PROMPT ADVANCE (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify the name of the directory where DATAPLOT's auxiliary files
    are stored.
 
Description:
    When expecting a new command, Dataplot writes a prompt character
    (by default, a ">").  With Fortran I/O, this write is automatically
    followed by a carriage return/line feed so that the input is actually
    entered on the next line.

    Fortran 90 provides for an "ADVANCE" option for WRITE commands.
    Specifying an ADVANCE='NO' suppresses this carriage return/line feed
    so that the input is entered on the same line as the prompt.

    Entering the command

        SET PROMPT ADVANCE ON

    will utilize this option to suppress the carriage return/line feed
    after printing the prompt character.

    This feature is compiler dependent.  Some Fortran compilers do not
    support the ADVANCE option when writing to standard output.
    Specifcally, the Intel Fortran compiler used for the Microsoft
    Windows implementation does not support this (note that earlier
    versions of this compiler did support support this).  The gfortran
    compiler used for Linux/Unix and Mac OS X implementations does support
    this feature.

Syntax:
    SET PROMPT ADVANCE <ON/OFF>
    where <ON> specifies that the carriage return/line feed will be
               suppressed while <OFF> specifies that it will not.
 
Examples:
    SET PROMPT ADVANCE ON
    SET PROMPT ADVANCE OFF
    PROBE PROMPT ADVANCE

Note:
    The SET PROMPT ADVANCE ON will be ignored when running the graphical
    user interface (GUI) is running.

Default:
    OFF
 
Synonyms:
    None
 
Related Commands:
    PROMPT     = Specify whether the prompt will be printed.
 
Applications:
    Terminal usage
 
Implementation Date:
    2009/07
 
Program:
    SET PROMPT ADVANCE ON
 
-----PROMPT-------------------------------------------------------
 
PROMPT
 
Name:
    PROMPT
 
Type:
    Support Command
 
Purpose:
    Specifies that after the execution of a command is completed, a
    prompt character will appear as an indication to the analyst to
    enter another command.
 
Syntax:
    PROMPT   <ON or OFF>
    where ON specifies that the prompt will appear after subsequent
             commands while OFF specifies that it will not.
 
Examples:
    PROMPT ON
    PROMPT OFF
    PROMPT
 
Note:
    The PROMPT command with no arguments is equivalent to PROMPT ON.
 
Default:
    At sign-on, the default is a prompt (i.e., ON).
 
Synonyms:
    None
 
Related Commands:
    ECHO     = Allows/suppresses command echoing.
    FEEDBACK = Allows/suppresses feedback messages.
    PRINTING = Allows/suppresses analysis output.
    SET      = Sets the value of an internal variable (e.g., IPR).
    PROBE    = Displays the value of an internal variable (e.g., IPR).
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----PROPORTION CONFIDENCE LIMITS--------------------------------------
 
PROPORTION CONFIDENCE LIMITS
 
Name:
    PROPORTION CONFIDENCE LIMITS
 
Type:
    Analysis Command
 
Purpose:
    Generates a confidence interval for proportions.
 
Description:
    Given a set of N observations in a variable X, we can compute the
    proportion of successes.  The PROPORTION CONFIDENCE LIMITS command
    computes a confidence interval for the proportion of successes.

    In Dataplot, you define a success by entering the command

        ANOP LIMITS <lower limit>  <upper limit>

    before entering the PROPORTION CONFIDENCE LIMITS command.  That is,
    you specify the lower and upper values that define a success.  Then
    the estimate for the proportion of successes is simply the number of
    points in the success region divided by the total number of points.
    In most applications, successes are defined by 1's and failures by
    0's.  The default limits are 0.5 and 1.5, so if your data is defined
    by 0 and 1 values the ANOP LIMITS command can be omitted.

    Several methods have been proposed for the confidence limits for a
    binomial proportion.  The following methods are currently supported
    in Dataplot

    NORMAL APPROXIMATION

    The normal approximation interval is

        phat +/- NORPPF(1 - alpha/2)*SQRT(phat*(1 - phat)/n)

    where

        X      = the number of successes
        phat   = X/n
        NORPPF = the percent point function of the normal distribution

    Due to its simplicity, the method is commonly used.  However, its
    use should be restricted to cases with relatively large sample sizes
    where phat is not near 0 or 1.

    ADJUSTED WALD

    The adjusted Wald interval is

         p' +/- NORPPF(1-alpha/2)*SQRT(p'*(1-p'))/SQRT(n')

    where

         X' = X + NORPPF(1-alpha/2)**2/2     (X is the number of success)
         n' = n + NORPPF(1-alpha/2)**2
         p' = X'/n'
         NORPPF is the percent point function of the normal distribution

    This method improves upon the normal approximation.

    WILSON

    This method was originally proposed by Wilson in 1927.  Papers
    by Agresti and Coull and also by Brown, Cai and DasGupta
    recommended this interval and provided comparisons of this
    method to the adjusted Wald and other methods.

    This method solves for the two values of p0 (say,
    p(upper) and p(lower) that result from setting z = z(alpha/2)
    and solving for p(0) = p(upper), and then setting
    z = -z(alpha/2) and solving for p(0) = p(lower) where 
    z(alpha/2) denotes the variate value from the standard normal
    distribution such that the area to the right of the value is
    alpha/2.  The solution for the two values of p(0) results in
    the following confidence intervals:

       U. L. = {phat + z(alpha/2)**(2)/(2n) +
               z(alpha/2/(sqrt[(phat*(1-phat))/n +
               z(alpha/2)**(2)/(4n**2)]}/
               {1 + z(alpha/2)**(2)/n}

       L. L. = {phat + z(alpha/2)**(2)/(2n) -
               z(alpha/2/(sqrt[(phat*(1-phat))/n +
               z(alpha/2)**(2)/(4n**2)]}/
               {1 + z(alpha/2)**(2)/n}

    This approach can be justified on the grounds that it is the
    exact algebraic counterpart to the (large-sample) hypothesis test
    and is also supported by the research of Agresti and Coull.  One
    advantage of this procedure is that its worth does not strongly
    depend upon the value of <i>n</i> and/or <i>p</i>, and indeed was
    recommended by Agresti and Coull for virtually all combinations of
    <i>n</i> and <i>p</i>.  Simulations by Agresti and Coull and
    by Brown, Cai and DasGupta show that this method does a better
    job of maintaining the nomial coverage than does the adjusted
    Wald and normal approximation methods.  Another advantage is
    that the limits are in the (0,1) interval.

    JEFFREYS

    The Jeffreys interval (the derivation for this interval is given in
    the Brown, Cai, DasGupta paper) is

        LCL = BETPPF(alpha/2,X + 0.5)
        UCL = BETPPF(1 - alpha/2,n - X + 0.5)

    where BETPPF is the percent point function of the beta distribution
    and X is the number of successes.

    EXACT BINOMIAL (or CLOPPER-PEARSON)

    Exact binomial intervals are obtained by

       1) Solve the equation

             BINCDF(x;p(u),N) = alpha/2

          where BINCDF is the cumulative distribution function of the
          binomial distribution, x is the number of successes, and
          n is the number of trials.

       2) Next solve the equation

             BINCDF(x;p(l),n) = 1 - alpha/2

          for p(l) to obtain the lower 100(1 - alpha)% limit for p.

    Although this method is called "exact", it is not more
    accurate than the adjusted Wald or Wilson method.  The
    "exact" terminology is based on the use of the binomial
    CDF function.  However, since the binomial is a discrete
    distribution, the use of the CDF function does not
    result in "exact" 95% confidence intervals.  The Agresti
    and Coull paper gives arguments to justify why the
    "approximate" Wilson and adjusted Wald methods can often be
    more accurate than the "exact" method.

    To specify the method to use, enter the command

       SET BINOMIAL METHOD <WILSON/ADJUSTED WALD/JEFFREYS/NORMAL/EXACT>

    The default is the Wilson method.  The Brown, Cai, and DasGupta paper
    studied the coverage properties of various methods.  They specifically
    recommend the Wilson, the adjusted Wald, and the Jeffreys method as
    having the best coverage properties.  Specifically, they recommend the
    Wilson and Jeffreys methods for n <= 40.  For n > 40, these three
    methods have comparable performance.  Although the normal
    approximation and exact binomial methods are not typically
    recommended, Dataplot provides them since they are still used in
    practice.

    Dataplot computes this inverval for a number of different
    probability levels.
 
Syntax:
    PROPORTION CONFIDENCE LIMITS   <y>
                          <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    ANOP LIMITS 0.50 1.5
    PROPORTION CONFIDENCE LIMITS Y
 
    SET BINOMIAL METHOD ADJUSTED WALD
    PROPORTION CONFIDENCE LIMITS Y SUBSET TAG = 1 TO 3
 
Note:
    A table of confidence intervals is printed for alpha levels of
    50.0, 75.0, 90.0, 95.0, 99.0, 99.9, 99.99, and 99.999.  The sample
    size, sample number of successes, and sample proportion of
    successes are also printed.
 
Note:
    Prior versions of Dataplot used the following method for the
    confidence interval

       (BINPPF(ALPHA/2,P,N)/N, BINPPF(1-ALPHA/2,P,N)/N)

    where BINPPF is the percent point function of the binomial
    distribution.

    This method is no longer supported.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    AGRESTI COULL             = Compute either the lower or upper
                                confidence limit for either a one-sided or
                                a two-sided binomial proportion of a
                                variable (Wilson, adjusted Wald, or
                                Jeffreys method).
    EXACT BINOMIAL            = Compute either the lower or upper exact
                                binomial confidence limit for either a
                                one-sided or a two-sided binomial
                                proportion of a variable. 
    ANOP LIMITS               = Specify success region for proportions.
    DIFFERENCE OF PROPORTION  = Compute the confidence interval for
         CONFIDENCE LIMITS      the difference of proportions.
    ANOP PLOT                 = Generate an analysis of proportions
                                plot.
    CONFIDENCE LIMITS         = Generate the confidence limits for
                                the mean.
 
Reference:
    Agresti, A. and Coull, B. A. (1998), "Approximate is better than
    "exact" for interval estimation of binomial proportions",
    The American Statistician, 52(2), 119-126.

    Brown, L. D. Cai, T. T. and DasGupta, A. (2001), "Interval estimation
    for a binomial proportion," Statistical Science, 16(2), 101-133.

    Wilson (1927), "Probable inference, the law of succession, and
    statistical inference," Journal of the American Statistical
    Association, Vol. 22, pp. 209-212.

    "Statistical Methods", Eigth Edition, Snedecor and Cochran, 
    1989, Iowa State University Press, pp. 121-124.
 
    NIST/SEMATECH e-Handbook of Statistical Methods,
    http://www.itl.nist.gov/div898/handbook/prc/section2/prc241.htm.

Applications:
    Confirmatory Data Analysis
 
Implementation Date:
    1999/05
    2017/11: Change method for determining the confidence interval
 
Program:
    .           Create a binary variable with 30 rows
    .           with 8 successes.
    .
    let n = 30
    let nsuc = 8
    let y = 0 for i = 1 1 n
    let y = 1 for i = 1 1 nsuc
    .
    .          Now do proportions confidence interval
    .
    set write decimals 6
    set binomial method wilson
    proportion confidence interval y
    set binomial method adjusted wald
    proportion confidence interval y
    set binomial method jeffreys
    proportion confidence interval y
    set binomial method exact
    proportion confidence interval y
    set binomial method normal
    proportion confidence interval y

-----PROPORTION LIMITS--------------------------------------
 
PROPORTION LIMITS
 
Name:
    PROPORTION LIMITS
 
Type:
    Support Command
 
Purpose:
    Define the upper and lower bounds for counting a response a success
    or failure in a subsequent analysis of proportions plot (values
    between these two numbers are counted as "successes" while values
    outside the two points are counted as "failures").
 
Syntax:
    PROPORTION LIMITS <lower>  <upper>
    where <lower> is a decimal number or parameter that specifies the
              lower bound;
    and <upper> is a decimal number or parameter that specifies the
              upper bound.
 
Examples:
    PROPORTION LIMITS 0.2 0.7
    PROPORTION LIMITS YLOW YHIGH
 
    LET YLOW = Y(1) - 0.5
    LET YHIGH = Y(1) + 0.5
    PROPORTION LIMITS YLOW YHIGH
 
Default:
    None
 
Synonyms:
    ANOP LIMITS
 
Related Commands:
    ANOP PLOT      = Generate an analysis of proportions plot.
 
Applications:
    Analysis of Proportions
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET TAG = PATTERN 1 2 3 4 5 FOR I = 1 1 100
    PROPORTION LIMITS 0.2 0.7
    CHARACTER CIRCLE BLANK
    LINE BLANK SOLID
    ANOP PLOT Y1 TAG
 
-----PROPORTION PLOT---------------------------------------------------
 
PROPORTION PLOT
 
Name:
    PROPORTION PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a proportion plot.
 
Description:
    A proportion plot is a plot consisting of subsample proportions
    versus subsample index.  The subsample proportion is the percentage
    (0 to 100%) of the data in the subsample which falls in a
    pre-specified region of interest (see the PROPORTION LIMITS
    command).  The proportion plot is used to answer the question--
    "Does the proportion of data falling in a given region of interest
    change over different subsamples?".   Note that the "region of
    interest" is frequently the upper or lower 10% of the data, the
    upper or lower 25% of the data, or some other extreme region of the
    data.  The proportion plot consists of:
       Vertical   axis = subsample proportion;
       Horizontal axis = subsample index.
    The PROPORTION PLOT yields 2 traces:
       1. a subsample proportion trace; and
       2. a full-sample proportion reference line.
    Like usual, the appearance of these 2 traces is
    controlled by the first 2 settings of the LINES,
    CHARACTERS, SPIKES, BARS, and similar attributes.
 
Syntax:
    PROPORTION PLOT   <y>   <x>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    PROPORTION PLOT Y X
    PROPORTION PLOT Y X1
 
Default:
    None
 
Synonyms:
    ANOP PLOT
 
Related Commands:
    CHARACTERS         = Sets the type for plot characters.
    LINES              = Sets the type for plot lines.
    MEAN   PLOT        = Generates a mean plot.
    RANGE PLOT         = Generates a range plot.
    UPPER QUARTILE PLOT= Generates an upper quartile plot
    LOWER QUARTILE PLOT= Generates a  lower quartile plot
    BOX PLOT           = Generates a box plot.
    XBAR CHART         = Generates a xbar control chart.
    PLOT               = Generates a data or function plot.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    88/9
 
Program:
    LET Y =  NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET X =  SEQUENCE 1 10 1 10
    PROPORTION LIMITS 1 10000
    PROPORTION PLOT Y X
 
-----PSEUDO INVERSE (LET)----------------------------------------
 
PSEUDO INVERSE
 
Name:
    PSEUDO INVERSE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the transpose of the Moore-Penrose pseudo inverse of a
    matrix.
 
Description:
    If A is a square matrix of full rank, then the inverse of A
    exists (A is referred to as an invertible matrix) and

        A*x = b

    has the solution

       x = A**(-1)*b

    The Moore-Penrose pseudo inverse is a generalization of the
    matrix inverse when the matrix may not be invertible.  If A is
    invertible, then the Moore-Penrose pseudo inverse is equal to
    the matrix inverse.  However, the Moore-Penrose pseudo inverse
    is defined even when A is not invertible.

    More formally, the Moore-Penrose pseudo inverse, A+, of an m-by-n
    matrix is defined by the unique n-by-m matrix satisfying the
    following four criteria (we are only considering the case where A
    consists of real numbers).

       1) A*A+*A = A

       2) A+*A*A+ = A+

       3) (A*A+)' = A*A+

       4) (A+*A)' = A+*A

    If A is an mxn matrix where m > n and A is of full rank (= n),
    then

        A+ = (A'*A)**(-1)*A'

    and the solution of A*x = b is x = A+*b.  In this case, the
    solution is not exact.  It finds the solution that is
    closest in the least squares sense.
 
Syntax:
    LET <mat2> = PSEUDO INVERSE <mat1>
                 <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the pseudo inverse is to be
                 computed;
          <mat2> is a matrix where the resulting transpose of the pseudo
                 inverse is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET C = PSEUDO INVERSE A

Note:
    The pseudo inverse is also referred to as the generalized
    inverse.
 
Note:
    A pseudo inverse can be used for any operator pinv satisfying

       M*pinv(M)*M = M

    Dataplot specifically computes the Moore-Penrose pseudo inverse.
    Other formulations are not currently supported.

Note:
    Dataplot computes the pseudo inverse using the MATMPI routine
    written by Charles Reeve while he was a member of the NIST
    Statistical Engineering Division.  This routine is available at

       http://www.itl.nist.gov/div898/software/reeves/homepage.htm

    The MATMPI routine is based on the singular value decomposition.
    The singular value decomposition of A is

        A=U*S*V'

    where U and V are both nxn orthogonal matrices and S is an
    mxn diagonal matrix with singular values sigma(i) for
    i = 1, ..., n.   Then

       A+ = V*(S'*S)**(-1)*S'*U'

    If the rank r of A is less than n, the inverse of S'*S does
    not exist and we use only the first r singular values.  S
    is then a rxr matrix and U and V are shrunk accordingly.

Note:
    Matrices are created with the READ MATRIX, CREATE MATRIX and
    MATRIX DEFINITION commands.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  Enter HELP DIMENSION
    and HELP MATRIX DIMENSION for details.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX INVERSE       = Compute the inverse of a nxn matrix.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    DIMENSION            = Specify the maximum number of rows and
                           columns in the internal Dataplot storage.
    MATRIX DIMENSION     = Specify the row and column dimensions for
                           matrix operations.
 
Reference:
    Penrose (1956), "On Best Approximate Solution of Linear
    Matrix Equations", Proceedings of the Cambridge Philosophical
    Society, 52, pp. 17-19.

    Dongarra, Bunch, Moler, Stewart (1979), "LINPACK User's Guide",
    Siam.

Applications:
    Linear Algebra
 
Implementation Date:
    2009/1
 
Program:
    DIMENSION 100 COLUMNS
    READ MATRIX X
    16 16 19 21
    14 17 15 22
    24 23 21 24
    18 17 16 15
    18 11  9 18
    END OF DATA
    LET A = PSEUDO INVERSE X
    PRINT A
 
-----PSIFN (LET)--------------------------------
 
PSIFN
 
Name:
    PSIFN (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the scaled kth derivative of the digamma (or psi)
    function.
 
Description:
    The psifn function is defined as:
        psifn(x,k) = ((-1)**(K+1)/GAMMA(K+1))*PSI(X,K)
    where GAMMA is the gamma function and PSI(X,K) is the
    kth derivative of the digamma function.  Enter
    HELP DIGAMMA for details on the digamma function.

    Note that this is the kth derivative of the digamma
    function, not the log gamma function.  That is, for k=1, the
    trigamma function is computed, not the digamma function.

Syntax:
    LET <y> = PSIFN(<x>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, variable or a parameter;
          <y> is a variable or a parameter (depending on what <x>
               is) where the computed psifn values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PSIFN(1,2)
    LET X2 = PSIFN(X1,K)
 
Note:
    DATAPLOT uses the routine PSIFN from the SLATEC Common Mathematical
    Library to compute this function.  SLATEC is a large set of high
    quality, portable, public domain Fortran routines for various
    mathematical capabilities maintained by seven federal laboratories.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    GAMMA      = Compute the gamma function.
    DIGAMMA    = Compute the digamma function.
    LOGGAMMA   = Compute the log (to base e) gamma function.
    GAMMAI     = Compute the incomplete Gamma function.
    GAMMAIP    = Compute an alternate form of the incomplete gamma
                 function.
    GAMMAIC    = Compute the complementary incomplete Gamma function.
    GAMMAR     = Compute the reciprocal gamma function.
    TRICOMI    = Compute Tricomi's incomplete gamma function.
    BETA       = Compute the Beta function.
 
Reference:
    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 6).
 
Applications:
    Special Functions
 
Implementation Date:
    1998/5
 
Program:
    YLIMITS 0 100
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    TITLE AUTOMATIC
    PLOT PSIFN(X,1) FOR X = 0.1 0.1 3
    PLOT PSIFN(X,2) FOR X = 0.1 0.1 3
    PLOT PSIFN(X,3) FOR X = 0.1 0.1 3
    PLOT PSIFN(X,4) FOR X = 0.1 0.1 3
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATION CENTER
    TEXT SCALED PSI FUNCTIONS
 
-----PSVIEW-------------------------------------------------------
 
PSVIEW
 
Name:
    PSVIEW
 
Type:
    Support Command
 
Purpose:
    View the most recent plot in a Postscript viewer.
 
Description:
    DEVICE 3 (in file DPPL2F.DAT, the name may vary on some systems)
    output is closed and re-opened at the beginning of a plot command,
    so only the most recent plot is in the graphics file.

    This command will view this Postscript file using a Postscript
    viewer.  This command is currently supported for Windows and
    Unix/Linux systems.

    For both Windows and Unix/Linux systems, the default viewer is
    ghostview.  To specify a different viewer, enter the command

          SET POSTSCRIPT VIEWER  <viewer>

    On Unix/Linux systems, <viewer> is case sensitive.

    This command is useful when you want to view the Postscript
    version of the plot without leaving the Dataplot session.
    The Postscript version of the plot is typically of higher
    quality than the screen version of the plot.

    The October, 2016 version of Dataplot made the following updates
    to this command.

        1. You can now view the contents of the DEVICE 2 output (see
           Syntax 2 below).

        2. You can view an arbitrary Postscript file (see Syntax 3 below).
    The December, 2019 version of Dataplot made the following updates
    to this command.

        1. The default Postscript viewer for Linux is "xdg-open" and
           the default viewer for MacOS is "open".  These applications
           will select the default Postscript viewer for files that
           have a ".ps" or ".eps" extension.  You can use the
           SET POSTSCRIPT VIEWER command to request a specific
           Postscript viewer.

           One issue is that the default names for DEVICE 2 and
           DEVICE 3 have a ".dat" extension rather than a ".ps"
           extension.  For this reason, Dataplot added the command

               SET BACKUP VIEWER <viewer>

           The viewer specified by this command will be used when
           the given file name does not have a recognized extension.

        2. You can now view PDF files.  To specify the application
           that will be used to view the PDF file, enter the command

               SET PDF VIEWER <viewer>

           The PDF VIEWER will be used when the file has a
           ".pdf" extension.

           The default viewer will be the Adobe Acrobat reader under
           Windows.  For Linux systems, the default is to use "xdg-open"
           and for MacOS systems the default is to use "open".  These
           applications will select the default PDF viewer for the
           local platform.

        3. You can now view image files (e.g., PNG, JPG and GIF files).
           To specify the application that will be used to view the
           image file, enter the command

               SET IMAGE VIEWER <viewer>

           The IMAGE VIEWER will be used when the file has a
           ".png", ".jpg", ".jpeg", ".gif", ".tif",".tiff",
           ".bmp" or ".svg" extension.  There are a large number of
           image file extensions.  When an unrecognized file extension
           is found, Dataplot will use the viewer specified by the
           SET BACKUP VIEWER command.

           For Windows, the default is to simply specify the file
           name and let the operating system select the appropriate
           application (this is determined by the "file association").
           For Linux systems, the default is to use "xdg-open" and for
           MacOS systems the default is to use "open".  These
           applications will select the default image viewer for the
           local platform based on the file extension.

        4. This command will issue the following commands before
           invoking the viewer application

               SET SYSTEM HIDDEN ON
               SET SYSTEM PERSIST OFF
               SET COMMAND LINE EXECUTE WAIT OFF

           Enter HELP SYSTEM for details on the effect of these
           commands.  These settings will be reset to their previous
           values after the viewer is invoked.

    Although the default viewers will typically work well, you may
    prefer to specify the specific application to use.  You can
    use the SET POSTSCRIPT VIEWER, SET PDF VIEWER, and SET IMAGE
    VIEWER commands to use specific applications rather than selecting
    system defaults (i.e., "xdg-open" or "open").  These commands can
    be added to your dplogf.tex file to make them your personal
    defaults.

Syntax 1:
    PSVIEW

    This syntax displays the most recent plot (i.e., the dppl2f.dat file).
 
Syntax 2:
    PSVIEW DEVICE 2

    This syntax displays the plots in the DEVICE 2 file (i.e., the
    dppl1f.dat file).
 
Syntax 3:
    PSVIEW <file-name>

    This syntax displays the plot or imgage specified by <file-name>.
    An appropriate viewer (Postscript, PDF, image) is selected based on
    the file name extension.  Dataplot does not check for the existence
    of the file before invoking the application.

Examples:
    SET POSTSCRIPT VIEWER evince
    PSVIEW

    SET POSTSCRIPT VIEWER "C:\Program Files\GHOSTGUM\GSVIEW32.EXE"
    PSVIEW

    PSVIEW DEVICE 2
 
    PSVIEW PLOTS.PS
    PSVIEW PLOTS.PDF

    SET IMAGE VIEWER gimp
    PSVIEW PLOTS.PNG

Note:
    By default, the PSVIEW DEVICE 2 command will close the plot file
    before invoking the Postscript viewer.  This is so that the last plot
    in the file is complete.  However, this can be problematic if you
    want to generate additional plots.  Specifically, you need to enter
    a DEVICE 2 POSTSCRIPT command to resume generating plots to this file.
    However, this new DEVICE 2 command will erase the files that previously
    existed in the file.

    There are a several possible solutions to this.

    You can request that the plot file not be close by entering the command

        SET PSVIEW FILE CLOSE OFF

    This will suppress closing the file.  The disadvantage of this is that
    the last plot in the file may not be complete.  A warning will be
    printed that the last file may not be complete.  However, the
    advantage is that you can continue generating plots to the current
    plot file.

    Alternatively, you can do something like

        PSVIEW DEVICE 2
        SET IPL1NA PLOT_NEW.PS
        DEVICE 2 POSTSCRIPT

    The SET IPL1NA command allows you to specify the name of the plot
    file (this should come before the DEVICE 2 POSTSCRIPT command).  The
    advantage of this approach is that the last plot will be complete.
    The disadvantage is that you will create multiple plot files.

Note:
    If a Dataplot command starts with a file name, Dataplot interprets
    this as a CALL command.  For example, entering

        test.dp

    is equivalent to entering

        call test.dp

    Dataplot will now check the extension on the file name.
    Specifically if the file has a ".ps", ".PS", ".eps", ".EPS", ".jpg",
    ".JPG", ".jpeg", ".JPEG", ".png", ".PNG", ".gif", ".GIF", ".tif",
    ".TIF", ".tiff", or ".TIFF" extension, the following command will
    be executed

       PSVIEW  <file-name>

    As discussed above, the appropriate viewer (Postscript, PDF or
    image) will be selected based on the file extension.

Default:
    For Linux, the default viewer is "ghostview".  For Windows, the
    default viewer is "C:\Program Files\GHOSTGUM\GSVIEW\GSVIEW32.EXE".
 
Synonyms:
    SHOW is a synonym for PSVIEW
 
Related Commands:
    PP           = Print the most recent plot.
    SET IPL1NA   = Specify the name of the plot file for DEVICE 2.
    SYSTEM       = Invoke an operating system command.
    LIST         = List the contents of a file.
 
Applications:
    Interactive Usage
 
Implementation Date:
    2011/09
    2016/10: Support for PSVIEW DEVICE 2
    2016/10: Support for arbitrary Postscript files
    2018/04: Added SHOW as a synonym
    2019/12: Support for PDF and image files
 
Program 1:
    .  Generate a plot and use the "evince" program (Linux) to view the
    .  Postscript version of the graph.
    .
    SET POSTSCRIPT VIEWER evince
    PLOT X**2 FOR X = 1 1 9
    PSVIEW

Program 2:
    device 2 postscript
    .
    char X
    line blank
    y1label Y
    x1label X
    title automatic
    title offset 2
    .
    plot x for x = 1 1 9
    plot x**2 for x = 1 1 9
    plot x**3 for x = 1 1 9
    .
    set psview file close off
    psview device 2
    .
    plot x**4 for x = 1 1 9

-----PWD-------------------------------------------------------
 
PWD
 
Name:
    PWD
 
Type:
    Support Command
 
Purpose:
    This command returns the current working directory.
 
Description:
    There are times when it is convenient to be able to retrieve
    the current working directory.   The PWD command will print
    the current working directory.  In addition, it will save
    the returned directory name in the string CURDIR.  This
    string can be used to label plots.

Syntax:
    PWD
 
Examples:
    PWD
 
Default:
    None
 
Synonyms:
    GETCWD
    CURRENT DIRECTORY
 
Note:
    If the name CURDIR has already been defined for a non-string
    (i.e., a parameter or a variable name), then the CURDIR string
    will not be created.

Note:
    The returned working directory name will be truncated at 255
    characters (both in the printed feedback and for the CURDIR
    string).

Note:
    The PWD command is implemented using the library function
    GETCWD.  This is not part of the Fortran standard, so the
    PWD command may not be supported on all platforms.  It should
    be available on Unix/Linux systems.  It is also supported
    on Windows implementations built with the Intel compiler.

Related Commands:
    CD            = Change the current working directory.
    SYSTEM        = Enter an operating system command within a
                    Dataplot session.
 
Applications:
    Interactive Usage
 
Implementation Date:
    2011/1
 
Program:
    PWD
    PRINT CURDIR
 
-----PYRAMID-------------------------------------------------------
 
PYRAMID
 
Name:
    PYRAMID
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Draws a pyramid.
 
Description:
    The 3 pairs of coordinates define the (x,y) values for the
    vertices of the triangle that form the front of the pyramid.
 
Syntax:
    PYRAMID  <x1>   <y1>   <x2>   <y2>  <x3>   <y3>
    where <x1> is a decimal number or parameter in the range 0 to 100
              that specifies the x coordinate for the first vertex;
          <y1> is a decimal number or parameter in the range 0 to 100
              that specifies the y coordinate for the first vertex;
          <x2> is a decimal number or parameter in the range 0 to 100
              that specifies the x coordinate for the second vertex;
          <y2> is a decimal number or parameter in the range 0 to 100
              that specifies the y coordinate for the second vertex;
          <x3> is a decimal number or parameter in the range 0 to 100
              that specifies the x coordinate for the third vertex;
    and   <y3> is a decimal number or parameter in the range 0 to 100
              that specifies the y coordinate for the third vertex;
 
Examples:
    PYRAMID 20 20 50 20 35 60
 
Note:
    The line style (i.e., solid, dash), color, and thickness are
    controlled by the LINE, LINE COLOR, and LINE THICKNESS commands.
    The REGION FILL ON command can be used to generate solid filled
    pyramids.  The REGION PATTERN can be used to do a hatch pattern
    fill.  Other REGION commands can be used to control how the fill
    is done.
 
Note:
    If you use a software font, pyramids can be embedded in text (e.g.,
    the LEGEND or TEXT command) by entering the string PYRA().
    Pyramids can also be used as plot characters (e.g., CHARACTERS
    PYRAMID), in which case the attributes are set with the various
    CHARACTER commands.
 
Note:
    The keywords DATA and RELATIVE were added to the TRIANGLE
    command 7/1997.  These keywords are independent and can
    be used separately or together.  For example, 
    TRIANGLE DATA, TRIANGLE RELATIVE, or TRIANGLE DATA RELATIVE.
    The word DATA should come before the word RELATIVE if both
    appear.

    DATA means that the coordinates are specified in terms of
    the data units of the most recent plot rather than Dataplot
    0 to 100 screen units.

    RELATIVE means that the coordinates of the first point
    are drawn in absolute coordinates an all subsequent points
    in the figure are relative to that first point.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POINT            = Draws a point.
    ARROW            = Draws an arrow.
    TRIANGLE         = Draws a triangle.
    BOX              = Draws a box.
    HEXAGON          = Draws a hexagon.
    CIRCLE           = Draws a circle.
    SEMI-CIRCLE      = Draws a semi-circle.
    ARC              = Draws an arc.
    ELLIPSE          = Draws an ellipse.
    OVAL             = Draws an oval.
    DIAMOND          = Draws a diamond.
    CUBE             = Draws a cube.
    DRAW             = Draws a line.
    MOVE             = Moves to a point.
    LINES            = Sets the line type for figures and plot lines.
    LINE THICKNESSES = Sets the line thickness for figures and  plot
                       lines.
    LINE COLOR       = Sets the line colors for figures and plot lines.
    CROSS-HAIR       = Activates and reads the cross-hair.
    TEXT             = Writes a text string.
    REGION FILL      = Specifies whether a figure is filled or not.
    REGION PATTERN   = Sets the type of fill pattern to use for
                       figures.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    PYRAMID 10 10 20 10 15 20
    PYRAMID 60 10 80 3 65 30
    .
    THICKNESS 0.5
    PYRAMID 10 30 20 21 13 43
    THICKNESS 0.2
    .
    LINE DASH
    PYRAMID 10 50 20 50 15 60
    LINE SOLID
    .
    LINE COLOR G50
    THICKNESS 0.5
    PYRAMID 10 80 20 75 12 93
    THICKNESS 0.2
    LINE COLOR BLACK
    .
    REGION FILL ON
    PYRAMID 30 30 40 25 33 44
    REGION FILL COLOR G50
    PYRAMID 50 50 70 45 55 63
    REGION FILL COLOR BLACK
    REGION FILL ONTS
    PYRAMID 40 70 55 62 48 84
    REGION FILL ONF
    REGION PATTERN D1D2
    PYRAMID 85 10 95 3 88 19
    REGION PATTERN BLANK
    .
    FONT SIMPLEX; HEIGHT 6
    MOVE 40 85
    TEXT PYRA() DRAW A PYRAMID WITH THE TEXT COMMAND
 
-----PYTHON MEAN (LET)----------------------------------
 
PYTHON MEAN
 
Name:
    PYTHON MEAN (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the mean for a variable using Python.
 
Description:
    This command is primarily a proof of concept command as the mean
    of a variable can be computed using the MEAN command.

    This command works as follows:

       1. It is assumed that Python and any needed Python packages
          (e.g., numpy) are already installed on the local platform.
          This specific command does not require any additional Python
          packages.

       2. The Python script, mean.py, that computes the mean is stored in
          the "scripts" subdirectory of the Dataplot auxiliary files.

          The default Linux/Unix location is "/usr/local/lib/dataplot" and
          the default Windows location is
          "C:\Program Files (x86)\NIST\DATAPLOT".  However, the location on
          your local platform may vary.

       3. The values for the variable for which the mean is to be computed
          are written to the file "dpst1f.dat" in the current directory.

       4. The following command is executed

             SYSTEM python <path>/script/mean.py > dpst2f.dat

          with <path> denoting the the location of the Dataplot auxiliary
          files.  The file "dpst2f.dat" will contain the computed mean
          value.

       5. The computed mean will be saved in a user specified Dataplot
          parameter.

    This initial PYTHON command was designed to create the basic structure
    for incorporating Python-based commands into Dataplot.  It  is
    anticipated that additional non-trivial Python-based commands will be
    added in subsequent Dataplot releases.

Syntax:
    LET <par> = PYTHON MEAN <y>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed mean is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = PYTHON MEAN Y1
    LET A = PYTHON MEAN Y1 SUBSET TAG > 2
 
Note:
    If Python is not in your search path, you can use the command

        SET PYTHON PATH  <path>

    to specify the directory where the Python executable is located.  For
    example

        SET PYTHON PATH /usr/local/bin

Note:
    Both Python 2 and Python 3 are currently actively supported.  If both
    Python 2 and Python 3 are installed on your local platform, you can
    use the following command to specify which version to run

        SET PYTHON VERSION <2/3/DEFAULT>

    Specifying "2" will run "python2", specifying "3" will run "python3" 
    and specifying "DEFAULT" will run "python" (i.e., the default on your
    local platform).

    The Dataplot written scripts will be written to the Python 3
    standard.  However, if you only have Python 2 on your system, you can
    modify the "mean.py" script to be compatible with Python 2 (for this
    command, only the "print" commands should need to be changed).  We do
    not anticipate providing both Python 2 and Python 3 versions of the
    scripts.

Note:
    You can use the CAPTURE SCRIPT command to create Python scripts from
    within a Dataplot macro.  You can then use the SYSTEM command to
    execute that script.  That is, something like

       CAPTURE SCRIPT file.py
           ...   Python commands here ...
       END OF CAPTURE
       SYSTEM  file.py

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MEAN     = Compute the mean of a variable.
    SYSTEM   = Execute an operating system command.
 
Applications:
    Data Analysis
 
Implementation Date:
    2019/03
 
Program:
    SKIP 25
    READ ZARR13.DAT Y
    LET YMEAN = PYTHON MEAN Y
 
-----PYTHON-------------------------------------------------------
 
PYTHON
 
Name:
    PYTHON
 
Type:
    Support Command
 
Purpose:
    Run a Python script within a Dataplot session.
 
Description:
    It may on occassion be useful to run a Python script within a Dataplot
    session.  Dataplot assumes that Python is already installed on your
    local system.  Also, any Python packages that your script needs should
    already be installed.  Dataplot does not initiate an install of Python
    or of any Python packages if it not already installed.

    If Python is not installed on your default path, you can specify it
    using the SET PYTHON PATH command.  For example, the following is
    for the Anaconda installation of Python 3 under Windows (where
    Anaconda is installed for the single user heckert)

       set python path c:\Users\heckert\AppData\Local\Continum\anaconda3\

    There are several different Python distributions.  The appropriate
    Python path will depend on the specific distribution you used to
    install Python and whether you choose to install it for a single
    user or for all users.

    If you need to specify that you want to run version 3 of Python, you
    can enter

       set python version 3

    If you need to specify that you want to run version 2 of Python, you
    can enter

       set python version 2

    On Windows platforms, the PYTHON command is equivalent to entering

        set system persist off
        set system hidden on
        system <python-path>\python.exe <python-script-file>  <arg-list>

    Note that if either the Python path or the <python-script-file>
    contains spaces (and so will be quoted), then "set system hidden" will
    be set to "off".

    On Linux platforms, the PYTHON command is equivalent to entering

        system <python-path>/python  <python-script-file>  <arg-list>

Syntax:
    PYTHON <script-file> <arg-list>
    where <script-file> contains the name of a file containing a Python
          script;
    and where <arg-list> is an optional list of arguments to the script.
 
Examples:
    PYTHON  plot.py
 
Note:
    This command is host dependent.  It has been tested on Windows
    and Linux systems.  Note that the SYSTEM command must be activated
    for this command to work.

Note:
    Dataplot does no error checking on the specified script file.  It
    is passed as is to Python command.
 
Note:
    The CAPTURE SCRIPT command can be used to generate the Python script
    within a Dataplot macro.  This is demonstrated in the Program
    example below.

Note:
    The name of the script file is case sensitive on Linux and MacOS
    systems.  It is not case sensitive on Windows systems.

    If Dataplot does not find the Python script file, it will search for
    it in the "scripts" sub-directory in the Dataplot auxiliary
    directory.  Currently (2019/12), there are no Python scripts in that
    directory, although this may change in future releases of Dataplot.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SYSTEM          = Issue an operating system command within Dataplot.
    RSCRIPT         = Run a R script within Dataplot.
    CAPTURE SCRIPT  = Create a script file within Dataplot.
 
Applications:
    Run Python scripts
 
Implementation Date:
    2019/12
 
Program 1:
    . Step 1:   Create the Python script using "capture script"
    .
    .           This example is just meant to demostrate the
    .           mechanics of calling Python scripts.
    .
    rm output.txt
    rm test.py
    .
    capture script test.py
    # Step 1:   Open the output file
    #
    fout = open('output.txt', 'w')
    #
    # Step 2:   Now write some output lines
    #
    line1 = "Line 1\n"
    line2 = "Line 2\n"
    line3 = "Line 3\n"
    fout.write(line1)
    fout.write(line2)
    fout.write(line3)
    #
    # Step 3:   Now close the file
    #
    fout.close()
    #
    end of capture
    .
    list test.py
    pause
    .
    . Step 2:   Determine if running on Windows or Linux and set
    .           Python path and version
    .
    let computer = 1
    probe iopsy1
    if probeval = 1
       let computer = 2
    end of if
    .
    if computer = 1
       . Following should be modified for your system
       set python path c:\Users\heckert\AppData\Local\Continum\anaconda3\
       set python version 3
    else
      .
      .  On my CentOS Linux box, I need to do the following to invoke
      .  version 3 of Python
      .
      .        scl enable rh-python36 csh
      .
      set python version 3
    end of if
    .
    . Step 3:   Run the Python script
    .
    python  test.py
    .
    . Step 4:   Display the results
    .
    list output.txt
 
Program 2:
    . Purpose:  Use Python script to extract Excel file to a CSV
    .           file.  From this, create a space separated file with a
    .           descriptive header for subsequent Dataplot use.  Finally,
    .           generate a Dataplot macro tha will read the space
    .           delimited file.
    .
    .           This macro demonstrates the use of the PYTHON and
    .           the WRITE1 and WRITE2 commands.
    .           extract the Excel file to a CSV file.
    .
    . Step 0:   Define some basic strings and file names
    .
    dimension 40 columns
    probe path
    let string ipath = ^probestr
    probe iopsy1
    if probeval = 2
       let string islash = \
    else
       let string islash = /
    end of if
    let string subdir = data
    let ipath = string concatenate ipath subdir islash
    .
    let string base = CORONA_VIRUS_COUNTRY_RANKINGS_042920
    let base2 = string concatenate ipath base
    let string ext1 = .CSV
    let string ext2 = .TXT
    let string ext3 = .DP
    let string ext4 = .XLSX
    let fname1 = string concatenate base  ext1
    let fname2 = string concatenate base  ext2
    let fname3 = string concatenate base  ext3
    let fname4 = string concatenate base2 ext4
    .
    . Step 1:   Use Python to create the CSV file
    .
    capture script read_corona.py
    #  This Python script will read an Excel file and write the in
    #  contents as a CSV file".  This script is specific to the Corona
    #  virus Excel file, so omit the error checking code.
    #
    #  Step 1: Import needed packages
    #
    import pandas as pd
    from pandas import ExcelWriter
    from pandas import ExcelFile
    #
    #  Step 2: Read the Corona virus Excel file file with Pandas
    #
    df = pd.read_excel("^fname4")
    
    #
    #  Step 3: Now use Pandas to write the Excel file
    df.to_csv("^fname1")
    #
    end of capture
    .
    .           May need to use SET PYTHON PATH command
    .
    python read_corona.py
    .
    . Step 2:   Read Original File
    .
    set convert character categorical
    set read delimiter ,
    set read missing value -9999
    .
    skip 5
    read ^fname1 rowindex fileno country pop popurban medage areakm2 ...
                 areami2 denstkm2 denstmi2 junk cumcases cumdeath
    skip 0
    delete rowindex junk
    .
    let ig = character code string country
    let ntemp = size cumdeath
    .
    . Step 2:   Now create new output file
    .
    .           First generate the header
    .
    write1 ^fname2 "Name:        ^fname2"
    write1 ^fname2 "Description: Corona virus country rankings"
    write1 ^fname2 "Source:      xxxx"
    write1 ^fname2 "Data:        Column  1: Country"
    write1 ^fname2 "             Column  2: Population (millions)"
    write1 ^fname2 "             Column  3: Urban Population (millions)"
    write1 ^fname2 "             Column  4: Median Age"
    write1 ^fname2 "             Column  5: Area (1000 kilometers**2)"
    write1 ^fname2 "             Column  6: Area (1000 miles**2)"
    write1 ^fname2 "             Column  7: Population Density (1000 kilometers**2)"
    write1 ^fname2 "             Column  8: Population Density (1000 miles**2)"
    write1 ^fname2 "             Column  9: Cumulative Cases"
    write1 ^fname2 "             Column 10: Cumulative Deaths"
    write1 ^fname2 " "
    write1 ^fname2 " "
    write1 ^fname2 " "
    write1 ^fname2 " "
    write1 ^fname2 " "
    write1 ^fname2 " "
    write1 ^fname2 " "
    write1 ^fname2 " "
    write1 ^fname2 " "
    write1 ^fname2 " "
    write1 ^fname2 "COUNTRY  POP POPURBAN MEDAGE AREAKM2 AREAMI2 DENSTKM2 DENSTMI2 CUMCASES CUMDEATH"
    write1 ^fname2 "--------------------------------------------------------------------------------"
    .
    .           Now write the data
    .
    set write format F5.0,3F10.1,4F10.0,2F12.0
    write1 ^fname2 country pop popurban medage areakm2 ...
                   areami2 denstkm2 denstmi2 cumcases cumdeath
    set write format
    .
    . Step 3:   Now create Dataplot macro to read the new file
    .
    write2 ^fname3  ". Name:    ^fname3"
    write2 ^fname3  ". Purpose: Read ^fname2"
    write2 ^fname3  "."
    write2 ^fname3  "skip 25"
    write2 ^fname3  "set read format F5.0,3F10.1,4F10.0,2F12.0"
    write2 ^fname3  "read ^fname2 country pop popurban medage areakm2 areami2 denstkm2 denstmi2 cumcases cumdeath"
    write2 ^fname3  "skip 0"
    write2 ^fname3  "set read format"
    write2 ^fname3  "."
    loop for k = 1 1 ntemp
    write2 ^fname3  "let string cntry^k = ^ig^k"
    end of loop
    write2 ^fname3  "."

-------------------------------------------------------------

























































































-------------------------  *Q*  ZZZZZ--------------------
 
-----Q QUANTILE RANGE (LET)-------------------------------
 
Q QUANTILE RANGE
 
Name:
    Q QUANTILE RANGE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the q quantile range for a variable.
 
Description:
    The q quantile  range is:

        QQ = X(1-q) - X(q)

    where q defines a quantile between 0 and 0.5 and X(q)
    denotes the q-th quantile of the data.

    For example, if q = 0.20, then the q quantile range is
    the difference between the 80th and 20th quantiles of
    the data.  The interquartile range is a special case of
    the q quantile range with q = 0.25.
 
    The q quantile range is used as a robust measure of scale.

    You can also compute the difference of the q quantile range
    for two response variables.

Syntax 1:
    LET <par> = Q QUANTILE RANGE <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed q quantile range
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = Q QUANTILE RANGE Y1
    LET A = Q QUANTILE RANGE Y1 SUBSET TAG > 2
    LET A = Q QUANTILE RANGE Y1 Y2
 
Note:
    The desired quantile is specified with the following
    command

        LET QUANT = <value>

    If <value> is between 1 and 100, it is interpreted as as
    percentile (i.e., the quantile will be determined by
    dividing by 100).  If <value> is between 0.5 and 1, 
    then 1 - <value>  will be used.  If <value> is less than
    or equal to 0 or greater than or equal to 100, an error
    message will be printed.

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    QQUANTILE RANGE is a synonym for Q QUANTILE RANGE.
 
Related Commands:
    INTERQUARTILE RANGE        = Compute the interquartile range of a
                                 variable.
    RANGE                      = Compute the range of a variable.
    QUANTILE                   = Compute a specified quantile of a
                                 variable.
    STANDARD DEVIATION         = Compute the standard deviation of a
                                 variable.
    AVERAGE ABSOLUTE DEVIATION = Compute the average absolute
                                 deviation of a variable.
    MEDIAN ABSOLUTE DEVIATION  = Compute the median absolute
                                 deviation of a variable.
 
Reference:
    Rand Wilcox (1997), "Introduction to Robust Estimations and
    Hypothesis Testing," Academic Press, pp. 24-25.

Applications:
    Robust Data Analysis
 
Implementation Date:
    2012/9
 
Program 1:
    LET Y1 = LOGISTIC RANDOM NUMBERS FOR I = 1 1 1000
    LET Y2 = DOUBLE EXPONENTIAL RANDOM NUMBERS FOR I = 1 1 1000
    LET Y3 = NORMAL RANDOM NUMBERS FOR I = 1 1 1000
    LET QUANT = 0.10
    LET A1 = Q QUANTILE RANGE Y1
    LET A2 = Q QUANTILE RANGE Y2
    LET A3 = Q QUANTILE RANGE Y3
    PRINT A1 A2 A3
 
Program 2:
    SKIP 25
    READ GEAR.DAT DIAMETER BATCH
    TITLE AUTOMATIC
    TITLE CASE ASIS
    XLIMITS 1 10
    MAJOR XTIC MARK NUMBER 10
    MINOR XTIC MARK NUMBER 0
    XTIC OFFSET 1 1
    X1LABEL BATCH
    X2LABEL Q = 0.20
    Y1LABEL Q QUANTILE RANGE OF DIAMETER
    CHARACTER CIRCLE
    CHARACTER FILL ON
    CHARACTER HW 2 1.5
    LINE BLANK
    LET QUANT = 0.20
    Q QUANTILE RANGE PLOT DIAMETER BATCH
 
-----QBICDF (LET)--------------------------------
 
QBICDF
 
Name:
    QBICDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the quasi-binomial type I cumulative distribution
    function.
 
Description:
    The quasi-binomial type I distribution has the
    following probability mass function:

        p(x;p,phi,m)=
            (m  x)*p*(p+x*phi)**(x-1)*(1-p-x*phi)**(m-x)
            x = 0, 1, 2, 3, ,..., m;
            0 <= p <= 1; -p/m < phi < (1-p)/m

    with p, phi, and m denoting the shape parameters and
    (a  b} denoting the binomial coefficient:

      (a  b) = a!/(b!(a-b)!}
 
    The cumulative distribution function is computed using
    the following recurrence relation given by Consul and
    Famoye:

       p(x+1) = {(m-x)*(p+x*phi)/((x+1)*(1-p-x*phi))}*
                (1 + phi/(p+x*phi))**x*
                (1 - phi/(1-p-x*phi))**(m-x-1)*p(x)

Syntax:
    LET <y> = QBICDF(<x>,<p>,<theta>,<beta>) 
               <SUBSET/EXCEPT/FOR qualification>
    where <x> is a positive integer variable, number, or parameter;
          <p> is a number, parameter, or variable in the range 
               (0,1) that specifies the first shape parameter;
          <phi> is a number, parameter, or variable that
               specifies the second shape parameter;
          <m> is a number, parameter, or variable that
               specifies the third shape parameter;
          <y> is a variable or a parameter (depending on what <x>
               is) where the computed quasi binomial type I
               cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = QBICDF(10,0.5,0.005,20)
    LET Y = QBICDF(X,0.7,0.01,20)
    PLOT QBICDF(X,0.3,0.005,20) FOR X = 0  1  20

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    QBIPDF                   = Compute the quasi-binomial type I
                               probability mass function.
    QBIPPF                   = Compute the quasi-binomial type I
                               percent point function.
    BINPDF                   = Compute the binomial probability
                               mass function.
    BBNPDF                   = Compute the beta-binomial
                               probability mass function.
    NBPDF                    = Compute the negative binomial
                               probability mass function.
 
Reference:
    Consul and Famoye (2006), "Lagrangian Probability
    Distribution", Birkhauser, pp. 70-80.

Applications:
    Distributional Modeling
 
Implementation Date:
    2006/8
 
Program:
    title size 3
    tic label size 3
    label size 3
    legend size 3
    height 3
    x1label displacement 12
    y1label displacement 15
    .
    multiplot corner coordinates 0 0 100 95
    multiplot scale factor 2
    label case asis
    title case asis
    case asis
    tic offset units screen
    tic offset 3 3
    title displacement 2
    y1label Probability
    x1label X
    .
    ylimits 0 1
    major ytic mark number 6
    minor ytic mark number 3
    xlimits 0 20
    line blank
    spike on
    .
    multiplot 2 2
    .
    title P = 0.3, Phi = 0.01, M = 20
    plot qbicdf(x,0.3,0.01,20) for x = 1 1 20
    .
    title P = 0.3, Phi = -0.01, M = 20
    let phi = -0.01
    plot qbicdf(x,0.3,phi,20) for x = 1 1 20
    .
    title P = 0.7, Phi = 0.01, M = 20
    plot qbicdf(x,0.7,0.01,20) for x = 1 1 20
    .
    title P = 0.7, Phi = -0.01, M = 20
    let phi = -0.01
    plot qbicdf(x,0.7,phi,20) for x = 1 1 20
    .
    end of multiplot
    .
    justification center
    move 50 97
    text Cumulative Distribution Functions for Quasi Binomial Type I

-----QBIPDF (LET)--------------------------------
 
QBIPDF
 
Name:
    QBIPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the quasi-binomial type I probability mass
    function.
 
Description:
    The quasi-binomial type I distribution has the
    following probability mass function:

        p(x;p,phi,m)=
            (m  x)*p*(p+x*phi)**(x-1)*(1-p-x*phi)**(m-x)
            x = 0, 1, 2, 3, ,..., m;
            0 <= p <= 1; -p/m < phi < (1-p)/m

    with p, phi, and m denoting the shape parameters and
    (a  b} denoting the binomial coefficient:

      (a  b) = a!/(b!(a-b)!}
 
    The quasi-binomial type I distribution is used to model
    Bernoulli trials.  The parameter p denotes the initial
    probability of success, m denotes the number of Bernoulli
    trials, and phi denotes how the probability of success
    increases or decreases with the number of successes.
    Specificially, when phi = 0, the quasi-binomial type I
    distribution reduces to the binomial distribution.  When
    phi <> 0, the probability of success in the xth trial
    becomes

       p + x*phi

Syntax:
    LET <y> = QBIPDF(<x>,<p>,<phi>,<m>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a positive integer variable, number, or parameter;
          <p> is a number, parameter, or variable in the range 
               (0,1) that specifies the first shape parameter;
          <phi> is a number, parameter, or variable that
               specifies the second shape parameter;
          <m> is a number, parameter, or variable that
               specifies the third shape parameter;
          <y> is a variable or a parameter (depending on what <x>
               is) where the computed quasi binomial type I
               pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = QBIPDF(10,0.5,0.005,20)
    LET Y = QBIPDF(X,0.7,0.01,20)
    PLOT QBIPDF(X,0.3,0.005,20) FOR X = 0  1  20

Note:
    For a number of commands utilizing the quasi-binomial type I
    distribution, it is convenient to bin the data.  There are
    two basic ways of binning the data.

      1) For some commands (histograms, maximum likelihood
         estimation), bins with equal size widths are
         required.  This can be accomplished with the
         following commands:

            LET AMIN = MINIMUM Y
            LET AMAX = MAXIMUM Y
            LET AMIN2 = AMIN - 0.5
            LET AMAX2 = AMAX + 0.5
            CLASS MINIMUM AMIN2
            CLASS MAXIMUM AMAX2
            CLASS WIDTH 1
            LET Y2 X2 = BINNED

      2) For some commands, unequal width bins may be
         helpful.  In particular, for the chi-square goodness
         of fit, it is typically recommended that the minimum
         class frequency be at least 5.  In this case, it may
         be helpful to combine small frequencies in the tails.
         Unequal class width bins can be created with the
         commands

            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = INTEGER FREQUENCY TABLE Y

         If you already have equal width bins data, you can
         use the commands
         
            LET MINSIZE = <value>
            LET Y3 XLOW XHIGH = COMBINE FREQUENCY TABLE Y2 X2

         The MINSIZE parameter defines the minimum class
         frequency.  The default value is 5.

Note:
    You can generate quasi-binomial type I random numbers,
    probability plots, and chi-square goodness of fit
    tests with the following commands:

       LET M = VALUE
       LET P = <value>
       LET PHI = <value>
       LET Y = QUASI BINOMIAL TYPE I RANDOM NUMBERS FOR I = 1 1 N

       QUASI BINOMIAL TYPE I PROBABILITY PLOT Y
       QUASI BINOMIAL TYPE I PROBABILITY PLOT Y2 X2
       QUASI BINOMIAL TYPE I PROBABILITY PLOT Y3 XLOW XHIGH

       QUASI BINOMIAL TYPE I CHI-SQUARE GOODNESS OF FIT Y
       QUASI BINOMIAL TYPE I CHI-SQUARE GOODNESS OF FIT Y2 X2
       QUASI BINOMIAL TYPE I CHI-SQUARE ..
                   GOODNESS OF FIT Y3 XLOW XHIGH

    In fitting the quasi-binomial type I distribution to data,
    we typically assume that the number of trials, m, is
    fixed and known and we then estimate p and phi.

    To obtain the maximum likelihood estimates of p and phi,
    enter the command

        QUASI BINOMIAL TYPE I MAXIMUM LIKELIHOOD Y
        QUASI BINOMIAL TYPE I MAXIMUM LIKELIHOOD Y2 X2

    The maximum likelihood estimates are the solutions to the
    equations (for unbinned data):

        SUM[i=1 to N][(m-X(i))/(1 - P - X(i)*PHI] - M*N = 0

        SUM[i=1 to N][(X(i)*(X(i) - 1)/(p + X(i)*PHI) -
        SUM[i=1 to N][(M - X(i))/(1 - P - X(i)*PHI)] = 0

    For binned data, the equations become

        SUM[i=1 to k][n(i)*(i-1)*i/(p+i*phi)] -
        SUM[i=1 to k][n(i)*(m-1)*i/(1-p-i*phi)] = 0
        
        (n/p) + SUM[i=1 to k][n(i)*(i-1)/(p+i*phi)] -
        SUM[i=1 to k][n(i)*(m-1)/(1-p-i*phi)] = 0

    with k, n, and n(x) denoting the number of classes, the
    total sample size, and the frequency of the xth class,
    respectively.

    These equations are known to have multiple solutions,
    so good starting values are required.  By default, we use
    the starting values recommended by Consul and Famoye

        p = 1 - (f0/n)**(1/m)
        phi = (1/(2*(m-2))*(-1 +
              SQRT(1 + 4*(m-2)*(-1+xbar/(m*p))/(m-1)))

    with f0 denoting the frequency of the class x = 0 and
    xbar denoting the sample mean.

    Alternatively, you can specify your own starting values
    by entering the commands

       LET PSTART = <value>
       LET PHISTART = <value>

    Consul and Famoye give formulas for the Fisher information
    matrix (the inverse of the parameter variance-covariance
    matrix).

    You can generate estimates of p and phi based on the
    maximum ppcc value or the minimum chi-square goodness of fit
    with the commands

        LET P1 = <value>
        LET P2 = <value>
        LET PHI1  = <value>
        LET PHI2  = <value>
        QUASI BINOMIAL TYPE I KS PLOT Y
        QUASI BINOMIAL TYPE I KS PLOT Y2 X2
        QUASI BINOMIAL TYPE I KS PLOT Y3 XLOW XHIGH
        QUASI BINOMIAL TYPE I PPCC PLOT Y
        QUASI BINOMIAL TYPE I PPCC PLOT Y2 X2
        QUASI BINOMIAL TYPE I PPCC PLOT Y3 XLOW XHIGH

    The default values of p1 and p2 are 0.05 and 0.95,
    respectively.  The default values for phi1 and phi2 are
    phi1 = -p1/m and phi2 = (1-p1)/m.  Due to the discrete nature
    of the percent point function for discrete distributions, the
    ppcc plot will not be smooth.  For that reason, if there is
    sufficient sample size the KS PLOT (i.e., the minimum
    chi-square value) is typically preferred.  However, it may
    sometimes be useful to perform one iteration of the PPCC PLOT
    to obtain a rough idea of an appropriate neighborhood for the
    shape parameters since the minimum chi-square statistic can
    generate extremely large values for non-optimal values of the
    shape parameters.  Also, since the data is integer values, one
    of the binned forms is preferred for these commands.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    QBICDF                   = Compute the quasi-binomial type I
                               cumulative distribution function.
    QBIPPF                   = Compute the quasi-binomial type I
                               percent point function.
    BINPDF                   = Compute the binomial probability
                               mass function.
    BBNPDF                   = Compute the beta-binomial
                               probability mass function.
    NBPDF                    = Compute the negative binomial
                               probability mass function.
    INTEGER FREQUENCY TABLE  = Generate a frequency table at
                               integer values with unequal bins.
    COMBINE FREQUENCY TABLE  = Convert an equal width frequency
                               table to an unequal width frequency
                               table.
    KS PLOT                  = Generate a minimum chi-square plot.
    PPCC PLOT                = Generate a ppcc plot.
    PROBABILITY PLOT         = Generate a probability plot.
    MAXIMUM LIKELIHOOD       = Perform maximum likelihood
                               estimation for a distribution.
 
Reference:
    Consul and Famoye (2006), "Lagrangian Probability
    Distribution", Birkhauser, pp. 70-80.

Applications:
    Distributional Modeling
 
Implementation Date:
    2006/8
 
Program 1:
    title size 3
    tic label size 3
    label size 3
    legend size 3
    height 3
    x1label displacement 12
    y1label displacement 15
    .
    multiplot corner coordinates 0 0 100 95
    multiplot scale factor 2
    label case asis
    title case asis
    case asis
    tic offset units screen
    tic offset 3 3
    title displacement 2
    y1label Probability Mass
    x1label X
    .
    ylimits 0 1
    major ytic mark number 6
    minor ytic mark number 3
    xlimits 0 20
    line blank
    spike on
    .
    multiplot 2 2
    .
    title P = 0.3, Phi = 0.01, M = 20
    plot qbipdf(x,0.3,0.01,20) for x = 1 1 20
    .
    title P = 0.3, Phi = -0.01, M = 20
    let phi = -0.01
    plot qbipdf(x,0.3,phi,20) for x = 1 1 20
    .
    title P = 0.7, Phi = 0.01, M = 20
    plot qbipdf(x,0.7,0.01,20) for x = 1 1 20
    .
    title P = 0.7, Phi = -0.01, M = 20
    let phi = -0.01
    plot qbipdf(x,0.7,phi,20) for x = 1 1 20
    .
    end of multiplot
    .
    justification center
    move 50 97
    text Probability Mass Functions for Quasi Binomial Type I

Program 2:
    let p = 0.7
    let phi = 0.01
    let m = 20
    let psave = p
    let phisave = phi
    let y = quasi binomial type I rand numb for i = 1 1 500
    .
    let y3 xlow xhigh = integer frequency table y
    class lower -0.5
    class width 1
    class upper 20.5
    let y2 x2 = binned y
    .
    relative hist y2 x2
    limits freeze
    pre-erase off
    line color blue
    plot qbipdf(x,p,phi,m) for x = 0 1 20
    limits
    pre-erase on
    line color black
    .
    quasi binomial type I mle y
    let p = pml
    let phi = phiml
    .
    quasi binomial type I chi-square goodness of fit y3 xlow xhigh
    .
    char x
    line bl
    quasi binomial type I probability plot y3 xlow xhigh
    .
    char bl
    line so
    let p1 = 0.5
    let p2 = 0.9
    let a1 = (1 - p1)/m
    let a2 = (1 - p2)/m
    let phi1 = 0
    let phi2 = max(a1,a2)
    quasi binomial type I ks plot y3 xlow xhigh
    let p = shape1
    let phi = shape2
    quasi binomial type I chi-square goodness of fit y3 xlow xhigh

-----QBIPPF (LET)--------------------------------
 
QBIPPF
 
Name:
    QBIPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the quasi-binomial type I percent point function.
 
Description:
    The quasi-binomial type I distribution has the
    following probability mass function:

        p(x;p,phi,m)=
            (m  x)*p*(p+x*phi)**(x-1)*(1-p-x*phi)**(m-x)
            x = 0, 1, 2, 3, ,..., m;
            0 <= p <= 1; -p/m < phi < (1-p)/m

    with p, phi, and m denoting the shape parameters and
    (a  b} denoting the binomial coefficient:

      (a  b) = a!/(b!(a-b)!}
 
    The cumulative distribution function is computed using
    the following recurrence relation given by Consul and
    Famoye:

       p(x+1) = {(m-x)*(p+x*phi)/((x+1)*(1-p-x*phi))}*
                (1 + phi/(p+x*phi))**x*
                (1 - phi/(1-p-x*phi))**(m-x-1)*p(x)

    The percent point function is computed by summing the
    cumulative distribution function until the appropriate
    probability is obtained.

Syntax:
    LET <y> = QBIPPF(<x>,<p>,<phi>,<m>) 
               <SUBSET/EXCEPT/FOR qualification>
    where <x> is a positive integer variable, number, or parameter
               in the interval (0,1);
          <p> is a number, parameter, or variable in the range 
               (0,1) that specifies the first shape parameter;
          <phi> is a number, parameter, or variable that
               specifies the second shape parameter;
          <m> is a number, parameter, or variable that
               specifies the third shape parameter;
          <y> is a variable or a parameter (depending on what <x>
               is) where the computed quasi binomial type I
               ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = QBIPPF(0.95,0.5,0.005,20)
    LET Y = QBIPPF(P,0.7,0.01,20)
    PLOT QBIPPF(P,0.3,0.005,20) FOR P = 0  0.01  1

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    QBICDF                   = Compute the quasi-binomial type I
                               cumulative distribution function.
    QBIPDF                   = Compute the quasi-binomial type I
                               probability mass function.
    BINPDF                   = Compute the binomial probability
                               mass function.
    BBNPDF                   = Compute the beta-binomial
                               probability mass function.
    NBPDF                    = Compute the negative binomial
                               probability mass function.
 
Reference:
    Consul and Famoye (2006), "Lagrangian Probability
    Distribution", Birkhauser, pp. 70-80.

Applications:
    Distributional Modeling
 
Implementation Date:
    2006/8
 
Program:
    title size 3
    tic label size 3
    label size 3
    legend size 3
    height 3
    x1label displacement 12
    y1label displacement 15
    .
    multiplot corner coordinates 0 0 100 95
    multiplot scale factor 2
    label case asis
    title case asis
    case asis
    tic offset units screen
    tic offset 3 3
    title displacement 2
    x1label Probability
    y1label X
    .
    xlimits 0 1
    major xtic mark number 6
    minor xtic mark number 3
    .
    multiplot 2 2
    .
    title P = 0.3, Phi = 0.01, M = 20
    plot qbippf(x,0.3,0.01,20) for x = 0  0.01  1
    .
    title P = 0.3, Phi = -0.01, M = 20
    let phi = -0.01
    plot qbippf(x,0.3,phi,20) for x = 0  0.01  1
    .
    title P = 0.7, Phi = 0.01, M = 20
    plot qbippf(x,0.7,0.01,20) for x = 0  0.01  1
    .
    title P = 0.7, Phi = -0.01, M = 20
    let phi = -0.01
    plot qbippf(x,0.7,phi,20) for x = 0  0.01  1
    .
    end of multiplot
    .
    justification center
    move 50 97
    text Percent Point Functions for Quasi Binomial Type I

-----QMS-------------------------------------------------------
 
QMS
 
Name:
    QMS
 
Type:
    Output Device Command
 
Purpose:
    Direct graphical output to a QMS laser printer using the QUIC
    protocol.
 
Syntax 1:
    QMS
 
    This form directs the QMS output to the terminal screen.
 
Syntax 2:
    DEVICE <1/2/3> QMS
 
    This  form designates one of DATAPLOT's 3 devices (it will
    typically be device 2) to be a QMS device.
 
Examples:
    QMS
    DEVICE 2 QMS
    DEVICE 3 QMS
 
Note:
    QMS fonts (for hardware generated characters) can be specified
    with the following command:
        SET QMS FONT <font id>
    where <font id> is one of the following:
        10   - EDP font
        104  - Standard Roman Medium
        124  - Standard Roman Bold
        144  - Standard Roman Italic
        16   - Simplex Roman
        204  - Apollo Medium
        328  - Complex Roman Bold
        404  - Q-Typewriter
        444  - Q-Typewriter Italic
        532  - Union
        521  - Tektronix small
        522  - Tektronix medium
        523  - Tektronix large
        524  - Tektronix largest
        904  - Q-Gothic
        924  - Q-Gothic Italic
        536  - Q-Greek
        517  - Q-Greek
        664  - Special Math
    Fonts 10, 104, 124, 144, 16, 204, 328, 404, and 444 are supported
    on all QMS printers using QUIC.  The others are downloadable fonts
    that may or may not be available on a given QMS.  Additional
    information on QMS fonts can be found in the QMS Programmer's
    Manual for Quic.  In addition the following SET commands can be
    used to specify the margins and resolution of the particular QMS
    printer (these should normally not be required):
        SET QMS PPI <number> sets the resolution (in points per inch).
           The default is 300.
        SET QMS [LANDSCAPE/PORTRAIT] LEFT    MARGIN sets the left
           margin (in dots).
        SET QMS [LANDSCAPE/PORTRAIT] RIGHT   MARGIN sets the right
           margin (in dots).
        SET QMS [LANDSCAPE/PORTRAIT] BOTTOM  MARGIN sets the bottom
           margin (in dots).
        SET QMS [LANDSCAPE/PORTRAIT] TOP     MARGIN sets the top
            margin (in dots).
 
Default:
    Off
 
Synonyms:
    QUIC
DEVICE NOTES
    1) HARDWARE TEXT - QMS provides numerous hardware fonts.  QMS fonts
       are fixed size and orientation fonts.  Several are typeset
       quality fonts.
    2) COLOR - This device does not support color or gray scale.
    3) HARDWARE FILL - All area fills in software (although QMS
       provides a hardware fill, it is not reliable).
    4) DASH PATTERNS - Each dash specification generates a different
       type of dash pattern.
    5) LINE WIDTH - The QMS performs line width in hardware.
    6) GRAPHICS INPUT - The CROSS-HAIR command is ignored for this
       device.
 
Related Commands:
    POSTSCRIPT         = Direct graphical output to a Postscript
                         device.
    CALCOMP            = Direct graphical output to a Calcomp device.
    HPGL               = Direct graphical output to an HPGL device.
    TEKTRONIX          = Direct graphical output to a Tektronix device.
    X11                = Direct graphical output to an X11 device.
    DEVICE             = Specify certain actions for the graphics
                         output.
    SET QMS FONT       = Specify the font to use on the QMS device.
    SET QMS PPI        = Set the resolution of the QMS device.
    SET QMS ... MARGIN = Set the margin for the QMS device.
 
Applications:
    XX
 
Implementation Date:
    89/2
 
Program:
    XX
 
-----QN SCALE (LET)-------------------------------
 
QN SCALE
 
Name:
    QN SCALE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the Qn scale estimate for a variable.
 
Description:
    Mosteller and Tukey (see Reference section below) define
    two types of robustness:

      1) resistance means that changing a small part, even by a
         large amount, of the data does not cause a large change
         in the estimate

      2) robustness of efficiency means that the statistic has
         high efficiency in a variety of situations rather than
         in any one situation.  Efficiency means that the estimate
         is close to optimal estimate given that we know what
         distribution that the data comes from.  A useful measure
         of efficiency is:

              Efficiency = (lowest variance feasible)/
                           (actual variance)
   
    Many statistics have one of these properties.  However,
    it can be difficult to find statistics that are both
    resistant and have robustness of efficiency.

    The most common estimate of scale, the standard deviation,
    is the most efficient estimate of scale if the data come from
    a normal distribution.  However, the standard deviation is
    not robust in the sense that changing even one value can
    dramatically change the computed value of the standard deviation
    (i.e., poor resistance).  In addition, it does not have
    robustness of efficiency for non-normal data.

    The median absolute deviation (MAD) and interquartile range are
    the two most commonly used robust alternatives to the standard
    deviation.  The MAD in particular is a very robust scale
    estimator.  However, the MAD has the following limitations:

       1) It does not have particularly high efficiency for
          data that is in fact normal (37%).  In comparison, the
          median has 64% efficiency for normal data.

       2) The MAD statistic also has an implicit assumption of
          symmetry.  That is, it measures the distance from a
          measure of central location (the median).

    Rousseeuw and Croux proposed the Qn estimate of scale as an
    alternative to the MAD.  It shares desirable robustness
    properties with MAD (50% breakdown point, bounded influence
    function).  In addition, it has significantly better normal
    efficiency (82%) and it does not depend on symmetry.
      
    The Qn scale estimate is motivated by the Hodges-Lehmann
    estimate of location:

        HL = MEDIAN{(x(i) + x(j))/2; i < j}

    An analogous scale estimate can be obtained by replacing
    pairwise averages with pairwised distances:
 
        MEDIAN{|x(i) - x(j)|; i < j}

    This estimate has high efficiency for normal data (86%),
    but a breakdown point of only 29%.  Rousseeuw and Croux
    proposed the following variation of this statistic:

        Qn = d{|x(i) - x(j)|; i < j}(k)

    where d is a constant factor and k = (h choose 2) which is
    approximately (n choose 2)/4.   The value of h is [n/2]+1
    (i.e., roughly half the number of obserations).  In words,
    we take kth order statistic of the (n choose 2) interpoint
    distances.  The value of d is choosen to make Qn a
    consistent estimator of scale.  We use the value 2.2219
    since this is the value that makes Qn a consistent estimator
    for normal data.

    The Rousseeuw and Croux article (see the Reference section
    below) discusses the properties of the Qn estimate in
    detail.
 
Syntax:
    LET <par> = QN SCALE <y>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed Qn estimate is
              stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = QN SCALE Y1
    LET A = QN SCALE Y1 SUBSET TAG > 2
 
Note:
    Dataplot uses code provided by Rousseeuw and Croux to compute
    the Qn estimate.  This algorithm uses an efficient computational
    method for computing Qn.

Note:
    The Rousseeuw and Croux article also proposes the Sn scale
    estimate.  The article discusses the properties of both
    estimators in detail.

Note:
    In addition, the Qn statistic is supported for the following
    plots and commands

       QN SCALE PLOT Y X
       CROSS TABULATE QN SCALE PLOT Y X1 X2
       BOOTSTRAP QN SCALE PLOT Y
       JACKNIFE QN SCALE PLOT Y
       DEX QN SCALE PLOT Y X1 ... XK
       QN SCALE BLOCK PLOT Y X1 ... XK
       QN SCALE INFLUENCE CURVE Y
       QN SCALE INTERACTION PLOT Y X1 X2

       TABULATE QN SCALE Y X
       CROSS TABULATE SN Y X1 X2
       LET Z = CROSS TABULATE QN SCALE Y X1 X2
       LET Y = MATRIX COLUMN QN SCALE M 
       LET Y = MATRIX ROW QN SCALE M 


Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SN SCALE                   = Compute the Sn scale estimate of a
                                 variable.
    MEDIAN ABSOLUTE DEVIATION  = Compute the median absolute
                                 deviation of a variable.
    INTERQUARTILE RANGE        = Compute the interquartile range of
                                 a variable.
    STANDARD DEVIATION         = Compute the standard deviation of a
                                 variable.
    DIFFERENCE OF SN           = Compute the difference of the Sn
                                 scale estimates between two variables.
    STATISTIC PLOT             = Generate a statistic versus subset
                                 plot.
    CROSS TABULATE PLOT        = Generate a statistic versus subset
                                 plot (two subset variables).
    BOOTSTRAP PLOT             = Generate a bootstrap plot for a
                                 statistic.
 
Reference:
    "Alternatives to the Median Absolute Deviation",
    Peter J. Rousseuw and Christophe Croux, Journal of the American
    Statistical Association, December, 1993, Vol. 88, No. 424,
    pp. 1273-1283.

    "Data Analysis and Regression: A Second Course in Statistics",
    Mosteller and Tukey, Addison-Wesley, 1977, pp. 203-209.

Applications:
    Data Analysis
 
Implementation Date:
    2003/4
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    MULTIPLOT SCALE FACTOR 2
    X1LABEL DISPLACEMENT 12
    .
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 200
    LET SIGMA = 1
    LET Y2 = LOGNORMAL RANDOM NUMBERS FOR I = 1 1 200
    .
    BOOTSTRAP SAMPLES 500
    BOOTSTRAP QN SCALE PLOT Y1
    X1LABEL B025 = ^B025, B975=^B975
    HISTOGRAM YPLOT
    X1LABEL
    .
    BOOTSTRAP QN SCALE PLOT Y2
    X1LABEL B025 = ^B025, B975=^B975
    HISTOGRAM YPLOT
    .
    END OF MULTIPLOT
    JUSTIFICATION CENTER
    MOVE 50 96
    TEXT QN SCALE BOOTSTRAP: NORMAL
    MOVE 50 46
    TEXT QN SCALE BOOTSTRAP: LOGNORMAL
 
-----QUADE TEST-----------------------------------------
 
QUADE TEST
 
Name:
    QUADE TEST
 
Type:
    Analysis Command
 
Purpose:
    Perform a Quade test that k treatments have identical effects.
 
Description:
    The Quade test is a non-parametric test for analyzing randomized
    complete block designs.

    The Quade test assumes that there are k experimental
    treatments (k >= 2).  The observations are arranged in
    b blocks, that is

                     Treatment
    Block  1    2      ...      k
      1   X11  X12     ...     X1k
      2   X21  X22     ...     X2k
      3   X31  X32     ...     X3k
     ...  ...  ...     ...     ...
      b   Xb1  Xb2     ...     Xbk

    Let R(Xij) be the rank assigned to Xij within block i (i.e.,
    ranks within a given row).  Average ranks are used in the case
    of ties.

    Compute the range in each block (the maximum value - the minimum
    value for the original data) and then rank these:

         Q(i) = rank of the range for the i-th block

    Then let

         S(ij) = Q(i)*[R(X(ij)) - (k+1)/2]

    and

         S(j) = SUM[i=1 to b][S(ij)]     j = 1, 2, ..., k

    Then the Quade test is 

        H0: The treatment effects have identical effects
        HA: At least one treatment is different from at least
            one other treatment
        Test Statistic:

               T3 = (b-1)*B/(A2 - B)

            where

               A2 = SUM[i=1 to b][SUM[j=1 to k][S(ij)**2]]

               B = (1/b)*SUM[j=1 to k][S(j)**2]

             The T3 statistic is equivalent to performing a two-way
             analysis of variance of the S(ij).  The A2 term is equivalent
             to the total sum of squares and B is equivalent to the
             treatment sum of squares.
        Significance Level: ALPHA
        Critical Region:
            The critical region can be approximated with an F
            distribution:

               T3 > FPPF(ALPHA,k-1,(b-1)*(k-1)) where FPPF is the F
                    percent point function.

        Conclusion: Reject the null hypothesis if the test
                    statistic is in the critical region.

    If the hypothesis of identical treatment effects is rejected,
    it is often desirable to determine which treatments are
    different (i.e., multiple comparisons).  Treatments i and j
    are considered different if

       |S(i) - S(j)| > TPPF(1-alpha/2,(k-1)*(b-1))*
                       SQRT[2*b*(A2 - B)/((b-1)*(k-1))]

    This is equivalent to the Fisher least significant difference
    computed on the S(ij) rather than the data.

Syntax:
    QUADE TEST  <y>  <block> <treat>
                        <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <block> is a variable that identifies the block;
          <treat> is a variable that identifies the treatment;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    QUADE TEST Y BLOCK TREATMENT
    QUADE TEST Y X1 X2
    QUADE TEST Y BLOCK TREATMENT  SUBSET BLOCK > 2
 
Note:
    In Dataplot, the variables should be given as:
 
        Y   BLOCK   TREAT
       X11    1      1
       X12    1      2
       ...    1     ...
       X1k    1      k 
       X21    2      1
       X22    2      2
       ...    2     ...
       X2k    2      k 
 
       ...   ...    ...
 
 
       Xb1    b      1
       Xb2    b      2
       ...    b     ...
       Xb3    b      k 
 
    If your data are in a format similar to that given in the
    DESCRIPTION section (i.e., you have colums Y1 to Yk, each
    with b rows), you can convert it to the format required by
    Dataplot with the commands:
 
       LET NBLOCK = SIZE Y1
       LET BLOCKID = SEQUENCE 1 1 NBLOCK
       LET Y BLOCK TREAT = REPLICATED STACK Y1 Y2 Y3 Y4 Y5 BLOCKID
       QUADE TEST Y BLOCK TREAT

Note:
    The response, ranked response, block, and treatment are
    written to the file dpst1f.dat in the current directory.
 
    The treatment ranks and multiple comparisons are written to
    the file dpst2f.dat in the current directory.  Comparisons
    that are statistically significant at the 95% level are
    flagged with a single asterisk while comparisons that are
    statistically significant at the 99% level are flagged with
    two asterisks.

Note:
    The Quade test is based on the following assumptions:

       1) The b rows are mutually independent.  That means that
          the results within one block (row) do not affect
          the results within other blocks.

       2) The data can be meaningfully ranked.

       3) The data have at least interval scale so that the sample
          range may be determined within each block.

Note:
    The following statistics are also supported:

        LET A = QUADE TEST         Y X1 X2
        LET A = QUADE TEST CDF     Y X1 X2
        LET A = QUADE TEST PVALUE  Y X1 X2

    Enter HELP STATISTICS to see what commands can use these
    statistics.

Note:
    The Quade test is similar to the Friedman test.  A few distinctions:

        1) For k = 2, the Friedman test is equivalent to a sign test while
           the Quade test is equivalent to a signed rank test.

        2) According to Conover, the Quade test is typically more powerful
           for k < 5 while the Friedman test tends to become more powerful
           for k >= 5.

        3) The Friedman test only requires ordinal scale data (i.e., the
           data can be ranked) while the Quade test requires at least
           interval scale data (the range within a block can be computed).

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    FRIEDMAN              = Perform a Friedman test.
    ANOVA                 = Perform an analysis of variance.
    DURBIN                = Perform a Durbin test for two-way
                            incomplete balanced block designs.
    COCHRAN               = Perform a Cochran test for two-way
                            complete block designs (binary data).
    KRUSKAL WALLIS        = Perform a Kruskall Wallis test.
    SIGN TEST             = Perform a sign test.
    MEDIAN POLISH         = Carries out a robust ANOVA.
    T TEST                = Carries out a t test.
    RANK SUM TEST         = Perform a rank sum test.
    SIGNED RANK TEST      = Perform a signed rank test.
    DEX ... PLOT          = Generates a dex plot for a statistic.
 
Reference:
    W. J. Conover, (1999).  "Practical Nonparameteric Statistics",
    Third Edition, Wiley, pp. 373-380.
 
Applications:
    Analysis of Variance
 
Implementation Date:
    2011/7
 
Program:
    SKIP 25
    READ QUADE2.DAT Y X1 X2
    SET WRITE DECIMALS 5
    .
    LET A1 = QUADE TEST        Y X1 X2
    LET A2 = QUADE TEST CDF    Y X1 X2
    LET A3 = QUADE TEST PVALUE Y X1 X2
    PRINT A1 A2 A3
    .
    QUADE TEST Y X1 X2

-----QUADRATIC FORM (LET)----------------------------------------
 
QUADRATIC FORM
 
Name:
    QUADRATIC FORM (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the quadratic form of a matrix and a vector.
 
Description:
    The quadratic form of a matrix M and a vector X is defined as:

         A=X'MX

    where X' is the transpose of X.  If the vector X has n
    rows, then M must be an nxn matrix.

    Quadratic forms are common in statistics, particularly in
    linear models and multivariate analysis.  In Dataplot
    applications, the QUADRATIC FORM command is most typically
    used as an intermediate calculation in a larger macro.
 
Syntax:
    LET <mat2> = QUADRATIC FORM <mat1>  <x>
    where <mat1> is a matrix for which the quadratic form is to
              be computed;
          <x> is a vector for which the quadratic form is to
              be computed;
    and where <mat2> is a matrix where the resulting quadratic 
             form is saved.
 
Examples:
    LET A = QUADRATIC FORM M X
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    READ MATRIX               = Read a matrix.
    MATRIX COLUMN DIMENSION   = Dimension maximum number of columns
                                for Dataplot matrices.

    MATRIX MEAN               = Compute the overall mean for a matrix.
    MATRIX COLUMN STATISTIC   = Compute column statistics for a
                                matrix.
    MATRIX ROW STATISTIC      = Compute row statistics for a matrix.
    LINEAR COMBINATION        = Compute a linear combination of a
                                matrix and a vector.
 
Reference:
    Any standard text on linear algebra.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    1998/8
 
Program:
    .  Perform a Fisher's dsicriminant analysis on Iris data.
    .
    .  READ DATA,  3 GROUPS (N1=N2=N3=3), 2 VARIABLES
    FEEDBACK OFF
    DIMENSION 200 COLUMNS
    SKIP 25
    READ IRIS.DAT SEPLENG SEPWIDTH PETLENG PETWIDTH TAG
    SKIP 0
    LET NTOT = SIZE SEPLENG
    LET X = MATRIX DEFINITION SEPLENG NTOT 4
    LET P = MATRIX NUMBER OF COLUMNS X
    .
    LET GROUPID = DISTINCT TAG
    LET NG = SIZE GROUPID
    LET XMGRAND = MATRIX COLUMN MEANS X
    .
    .  CALCULATE B0 = SUM (I=1,NG) (XBARi - XBARALL)(XBARi-XBARALL)'
    .
    LET DIAG = 0 FOR I = 1 1 P
    LET B0 = DIAGONAL MATRIX DIAG
    .
    LOOP FOR K = 1 1 NG
       LET N^K = SIZE TAG SUBSET TAG = K
       LET XMEANI = MATRIX COLUMN MEANS X SUBSET TAG = K
       LET XMEANI= XMEANI - XMGRAND
       LET B0TEMP = VECTOR TIMES TRANSPOSE XMEANI
       LET B0 = MATRIX ADDITION B0 B0TEMP
    END OF LOOP
    .
    .  CALCULATE Spooled = (N1-1)S1 + .. + (Ng-1)Sg)/(N1+ .. + Ng - g)
    LET SPOOL = POOLED VARIANCE-COVARIANCE MATRIX X TAG
    LET DENOM = NTOT - NG
    LET WINVB = MATRIX MULTIPLICATION SPOOL DENOM
    LET WINVB = MATRIX INVERSE WINVB
    LET WINVB = MATRIX MULTIPLICATION WINVB B0
    .
    .  COMPUTE EIGENVALUES AND SORT IN DECREASING ORDER
    .  COMPUTE EIGENVECTORS, ONLY KEEP REAL COMPONENT, SORT
    .
    LET E = MATRIX EIGENVALUES WINVB
    LET EV = MATRIX EIGENVECTORS WINVB
    LET INDX = SEQUENCE 1 1 P
    RETAIN E FOR I = 1 1 P
    LET ESORT = SORTC E INDX
    LET REVERSE = SEQUENCE P 1 1
    LET REVERSE = SORTC REVERSE ESORT INDX
    LET EVECT = DIAGONAL MATRIX DIAG
    .  NORMALIZE L'SpooledL =1
    .  DIST = L'SpooledL, MULTIPLY EIGENVECTOR BY 1/SQRT(DIST)
    LOOP FOR K = 1 1 P
        LET LTAG = INDX(K)
        RETAIN EV^K  FOR I = 1 1 P
        LET EVECT^LTAG = EV^K
        LET DIST = QUADRATIC FORM SPOOL EVECT^LTAG
        LET EVECT^LTAG = (1/SQRT(DIST))*EVECT^LTAG
    END OF LOOP
    .  PLOT FIRST 2 DISCRIMINANTS
    LET ZY = LINEAR COMBINATION X EVECT1
    LET ZX = LINEAR COMBINATION X EVECT2
    DEVICE 1 OFF
    MEAN PLOT ZY TAG
    LET GMEANY = YPLOT
    MEAN PLOT ZX TAG
    LET GMEANX = YPLOT
    RETAIN GMEANX GMEANY SUBSET TAGPLOT = 1
    DEVICE 1 ON
    Y1LABEL FIRST DISCRIMINANT
    X1LABEL SECOND DISCRIMINANT
    CHARACTER CIRCLE SQUARE TRIANGLE
    LINE BLANK ALL
    LEGEND 1 CIRC() - SPECIES 1
    LEGEND 2 SQUA() - SPECIES 2
    LEGEND 3 TRIA() - SPECIES 3
    LEGEND FONT DUPLEX
    LEGEND SIZE 1.2
    TITLE PLOT FIRST 2 DISCRIMINANT FUNCTIONS
    PLOT ZY ZX TAG
    PRINT "FISHER's DISCRIMINANT ANALYSIS"
    PRINT " "
    PRINT " "
    PRINT "B0 MATRIX (= between group sums of cross-products):"
    PRINT B0
    PRINT " "
    PRINT " "
    PRINT "POOLED VARIANCE-COVARIANCE MATRIX:"
    PRINT SPOOL
    PRINT " "
    PRINT " "
    PRINT "EIGENVALUES:"
    PRINT ESORT
    PRINT " "
    PRINT " "
    PRINT "COLUMNS ARE THE DISCRIMINANT FUNCTIONS:"
    PRINT EVECT
    PRINT " "
    PRINT " "
    PRINT "GROUP MEANS:"
    PRINT GMEANX GMEANY
 
-----QUANTILE (LET)-----------------------------------------
 
QUANTILE
 
Name:
    QUANTILE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute a user specified quantile for a variable.
 
Description:
    The qth quantile of a data set is defined as that value
    where a q fraction of the data is below that value and (1-q)
    fraction of the data is above that value.  For example, the
    0.5 quantile is the median.
 
    Dataplot supports two methods for computing the quantile.

    The first method is based on the order statistic.  The
    formula is:

       X(q) = (1 - r)*X(NI1) + r*X(NI2)

   where

       X are the observations sorted in ascending order
       NI1 = INT(Q*(N+1))
       NI2 = NI1 + 1
       r = Q*(N+1) - INT(Q*(N+1))

   If q is < 1/(N+1), then X(1) is returned.  If q > N/(N+1), then X(N)
   is returned.

   An alternative method is called the Herrell-Davis
   estimate.  This method attempts to provide a lower standard
   error for X(q) by utilizing all the order statistics rather
   than a single (or a weighted average of two) order statistic.
   Note that there are cases where the Herrell-Davis has a
   substantially smaller standard error than the order statistic
   method.  However, there are also cases where the reverse is
   true.

   To compute the Herrell-Davis estimate, do the following:

      1. Sort the X in ascending order.

      2. A = (N+1)*q - 1

      3. B = (N+1)*(1-q) - 1

      4. W(i) = BETCDF(i/n, A, B) - BETCDF((i-1)/n, A, B)

         where BETCDF is the beta cumulative distribution
         function with shape parameters A and B.

      5. X(q) = SUM[i=1 to n][W(i)*X(i)]

   Note: The computations for A and B were modifed 2/2003 to:

         A = (N+1)*q
         B = (N+1)*(1-q)

   The original form was from the text in the Wilcox book.  However,
   checking his S+ macros and verifying against the original
   Herrell and Davis article indicated that the new formulas are
   the correct ones.

Syntax:
    LET <par> = <quan> QUANTILE <y>
                       <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <quan> is a number or parameter in the range (0,1) that
              specifies the desired quantile;
          <par> is a parameter where the computed quantile
              is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = 0.20 QUANTILE Y

    LET XQ = 0.50
    LET A = XQ QUANTILE Y SUBSET TAG > 2
 
Note:
    The PERCENTILE command is equivalent to the QUANTILE command
    using the order statistic method.  The only difference is
    that the requested percentile is given as a percentage
    between 0 and 100% rather than as a fraction.

Note:
    Note that there are a number of other ways of calculating percentiles
    in common use.  Hyndman and Fan (1996) in an American Statistician
    article evaluated nine different methods (we will refer to these as R1
    through R9) for computing percentiles relative to six desirable
    properties. Their goal was to advocate a "standard" definition for
    percentiles that would be implemented in statistical software. Although
    this has not in fact happened, the article does provide a useful
    summary and evaluation of various methods for computing percentiles.
    Most statistical and spreadsheet software use one of the methods
    described in Hyndman and Fan.

    The default method used by Dataplot described above is equivalent
    to method R6 of Hyndman and Fan.

    The method advocated by Hyndman and Fan is R8. For the R8 method,

       X(q) = X(NI1) + r*(X(NI2) - X(NI1))

    where

       X are the observations sorted in ascending order
       NI1 = INT(Q*(N+(1/3)) + (1/3))
       NI2 = NI1 + 1
       r = Q*(N+1) - INT(Q*(N+1))

    If q ≤ (2/3)/(N+(1/3)) the minimum value will be returned and if
    q ≥ (N-(1/3))/(N+(1/3)) the maximum value will be returned.

    Method R7 (this is the default method in R and Excel) is calculated by

       X(q) = X(NI1) + r*(X(NI2) - X(NI1))

    where

       X are the observations sorted in ascending order
       NI1 = INT(Q*(N-1) + 1)
       NI2 = NI1 + 1
       r = Q*(N+1) - INT(Q*(N+1))

    If q = 1, then X(N) is returned.

    The R6, R7, and R8 methods give fairly similar, but not exactly the
    same (particularly for small samples), results.  For most purposes,
    any of these three methods should be acceptable.

Note:
    The following command is used to determine which method
    is used to compute the quantile:

         SET QUANTILE METHOD <ORDER/HERRELL-DAVIS/R6/R7/R8>

    R6 is equivalent to ORDER.  ORDER is the default.

Note:
    Dataplot statistics can be used in 20+ commands.  For details, enter

         HELP STATISTICS

    When using these commands, the specific quantile to compute is
    specified by entering the following command (before the plot command):

       LET XQ = <value>

    where <value> is a number in the interval (0,1) that specifies
    the desired quantile.

Default:
    The default is to use the order statistic method to
    compute the quantile.
 
Synonyms:
    None
 
Related Commands:
    PERCENTILE                  = Compute a percentile of a variable.
    MEDIAN                      = Compute the median of a variable.
    LOWER QUARTILE              = Compute the lower quartile of a
                                  variable.
    UPPER QUARTILE              = Compute the upper quartile of a
                                  variable.
    FIRST DECILE                = Compute the first decile (the 10th 
                                  quantile) of a variable.
    STATISTIC PLOT              = Generate a statistic versus subset
                                  plot for numerous statistics.
    CROSS TABULATE PLOT         = Generate a statistic versus subset
                                  plot (two group variables) for a
                                  given statistics.
    BOOTSTRAP PLOT              = Generate a bootstrap plot for a
                                  given statistic.
 
References:
    Hyndman and Fan (November 1996), "Sample Quantiles in Statistical
    Packages", The American Statistician, Vol. 50, No. 4, pp. 361-365.

    Rand Wilcox (1997), "Introduction to Robust Estimation and Hypothesis
    Testing", Academic Press.

    Frank Herrell and C. E. Davis, (1982), "A New Distribution-Free Quantile
    Estimator", Biometrika, 69(3), 635-640.

Applications:
    Data Analysis
 
Implementation Date:
    2002/07
    2003/02: Correction in Herrell-Davis formulation.
    2015/02: Support for R7 and R8 methods
 
Program 1:
    LET Y1 = LOGISTIC RANDOM NUMBERS FOR I = 1 1 100
    LET Q05A = 0.05 QUANTILE Y1
    LET Q95A = 0.95 QUANTILE Y1
    SET QUANTILE METHOD HERRELL DAVIS
    LET Q05B = 0.05 QUANTILE Y1
    LET Q95B = 0.95 QUANTILE Y1
    LET Q95B = XQ QUANTILE Y1 
    LET Q05A = ROUND(Q05A,4)
    LET Q95A = ROUND(Q95A,4)
    LET Q05B = ROUND(Q05B,4)
    LET Q95B = ROUND(Q95B,4)
    PRINT "R6 METHOD: 0.05 Quantile = ^Q05A"
    PRINT "R6 METHOD: 0.95 Quantile = ^Q95A"
    PRINT "HD METHOD: 0.05 Quantile = ^Q05B"
    PRINT "HD METHOD: 0.95 Quantile = ^Q95B"
 
Program 2:
    . Step 1:   Read the data
    .
    read y
    95.1772
    95.1567
    95.1937
    95.1959
    95.1442
    95.0610
    95.1591
    95.1195
    95.1065
    95.0925
    95.1990
    95.1682 
    end of data
    .
    . Step 2:   Compute the quantiles using different methods
    .
    let xq = 0.90
    .
    let xqr6 = quantile y
    let xpr6 = round(xpr6,4)
    .
    set quantile method r7
    let xqr7 = quantile y
    let xqr7 = round(xqr7,4)
    .
    set quantile method r8
    let xqr8 = quantile y
    let xqr8 = round(xqr8,4)
    .
    . Step 3:   Print the results
    .
    print "Quantile with R6 method:  ^xqr6"
    print "Quantile with R7 method:  ^xqr7"
    print "Quantile with R8 method:  ^xqr8"
 
-----QUANTILE-QUANTILE PLOT--------------------------------------
 
QUANTILE QUANTILE PLOT
 
Name:
    QUANTILE-QUANTILE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a quantile-quantile plot.
 
Description:
    A quantile-quantile plot (or q-q plot) is a graphical data analysis
    technique for comparing the distributions of 2 data sets.  The
    quantile-quantile plot is a graphical alternative for the various
    classical 2-sample tests (e.g., t for location, F for dispersion).
    The plot consists of the following:

       Vertical axis   = estimated quantiles from data set 1;
       Horizontal axis = estimated quantiles from data set 2.
 
    The "quantiles" of a distribution are the distribution's "percent
    points" (e.g., .5 quantile = 50% point = median).  The advantage of
    the quantile-quantile plot is 2-fold:

       1) the sample sizes do not need to be identical;
       2) many distributional aspects can be simultaneously tested.
          For example, shifts in location, shifts in dispersion,
          changes in symmetry/skewness, outliers, etc.

    The quantile-quantile plot has 3 components:

       1) the quantile points themselves;
       2) a 45 degree reference line.
       3) a least squares line fit to the quantile points.

    If the two data sets come from similar distributions, then the
    points of the q-q plot should lie along the 45 degree reference
    line.

    Like usual, the appearance of these 2 components is controlled by
    the first 2 settings of the CHARACTERS and LINES commands.  It is
    typical for the quantile points to be represented as, say, X's with
    no connecting line, and the reference line to have no plot
    characters but to be solid.  This is demonstrated in the sample
    program below.
 
Syntax 1:
    QUANTILE-QUANTILE PLOT <y1> <y2>  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    HIGHLIGHT QUANTILE-QUANTILE PLOT <y1> <y2> <tag>
                                     <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <tag> is a group-id variable that defines the highlighting;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax can be used to plot different plot points with
    different attributes.  For example, it can used to highlight
    groups in the data or to emphasize the extremes.

Examples:
    QUANTILE-QUANTILE PLOT Y1 Y2
    QUANTILE-QUANTILE PLOT RUN1 RUN2
    QUANTILE-QUANTILE PLOT BATCH1 BATCH2
    QUANTILE-QUANTILE PLOT Y1 Y2 SUBSET AUTO 4
    QUANTILE-QUANTILE PLOT Y1 Y2 SUBSET STATE 25
 
Note:
    One of the distributions can be a theoretical distribution.  For
    example, the following program generates a quantile-quantile plot
    of a data set against a normal distribution (this is called a
    normal quantile plot).

        LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
        LET X = SEQUENCE .01 .01 .99
        LET Y2 = NORPPF(X)
        QUANTILE-QUANTILE PLOT Y1 Y2

    This same technique can be used other distributions (use the proper
    PPF function).  This is also fairly close to what a probability
    plot does (DATAPLOT has a PROBABILITY PLOT command for over 25
    distributions).
 
Note:
    For large data sets, it may be impractical to generate the plot for
    each individual point.  As an alternative, you can generate the plot
    for a user specified number of quantiles.  To do this, enter the
    command

        SET QUANTILE QUANTILE PLOT NUMBER OF PERCENTILES <value>

    where <value> specifies the desired number of quantiles.  This is
    demonstrated in the Program 2 example below.

Note:
    If the two data sets have similar distribution, then the points on
    the plot should fall along the 45 degree reference line.  For
    example, if you enter a QUANTILE QUANTILE PLOT Y Y command, then the
    points will lie exactly on the reference line.  This means that if
    a line is fit to the points on the plot and the two data sets come
    from similar distributions, then the itercept and the slope of the
    fitted line should be close to zero and one, respectively.  In
    addition, the correlation coefficient of the fitted line should be
    close to one.

    The parameters containing the intercept, slope, and correlation 
    coefficient are automatically saved in the parameters PPA0, PPA1,
    and PPCC, respectively.  This can be useful in labeling q-q plots.

Note:
    If you have more than two data sets, you can generate a matrix plot
    of the pairwise q-q plots with the SCATTER PLOT MATRIX command.  This
    is demonstrated in the Program 3 example.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    TUKEY MEAN DIFFERENCE PLOT  = Generates a Tukey mean difference plot.
    BOX PLOT                    = Generates a box plot.
    PLOT                        = Generates a data or function plot.
    BIHISTOGRAM                 = Generates a bihistogram.
    PROBABILITY PLOT            = Generates a probability plot.
    PERCENTILE PLOT             = Generates a percentile plot.
    T-TEST                      = Carries out a 2-sample t test.
    ANOVA                       = Carries out an ANOVA.
    MULTIPLOT                   = Allows multiple plots per page.
    CHARACTERS                  = Sets the type for plot characters.
    LINES                       = Sets the type for plot lines.
 
Reference:
    Chambers, Cleveland, Kleiner, and Tukey (1983), "Graphical Methods
    of Data Analysis", Wadsworth, pp. 48-57.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    1988/03
    2011/02: Support for highlight option
    2016/06: Support for SET QUANTILE QUANTILE PLOT NUMBER OF PERCENTILES
    2016/06: Generate a fitted line to the quantile points
    2016/06: Automatically save PPA0, PPA1, and PPCC
 
Program 1:
    SKIP 25
    READ AUTO83B.DAT Y1 Y2
    DELETE Y2 SUBSET Y2 < 0
    .
    LINE BLANK SOLID DASHED
    CHARACTER CIRCLE BLANK BLANK
    CHARACTER FILL ON OFF OFF
    CHARACTER HW 0.5 0.375
    TITLE AUTOMATIC
    TITLE OFFSET 2
    LABEL CASE ASIS
    Y1LABEL MPG for US Cars
    X1LABEL MPG for Japanese Cars
    .
    QUANTILE-QUANTILE PLOT Y1 Y2
    .
    LET PPA0 = ROUND(PPA0,3)
    LET PPA1 = ROUND(PPA1,3)
    LET PPCC = ROUND(PPCC,3)
    JUSTIFICATION LEFT
    MOVE 20 87; TEXT A0: ^PPA0
    MOVE 20 85; TEXT A1: ^PPA1
    MOVE 20 83; TEXT PPCC: ^PPCC
 
Program 2:
    LET Y1 = NORMAL RANDOM NUMBER FOR I = 1 1 1000000
    LET Y2 = DOUBLE EXPONENTIAL RANDOM NUMBER FOR I = 1 1 1000000
    .
    LINE BLANK SOLID DASH
    CHARACTER CIRCLE BLANK BLANK
    CHARACTER FILL ON OFF
    CHARACTER HW 0.5 0.375
    TITLE AUTOMATIC
    TITLE OFFSET 2
    LABEL CASE ASIS
    Y1LABEL Normal Random Numbers
    X1LABEL Double Exponential Random Numbers
    .
    SET QUANTILE QUANTILE PLOT NUMBER OF PERCENTILES 1000
    QUANTILE-QUANTILE PLOT Y1 Y2
    .
    LET PPA0 = ROUND(PPA),3)
    LET PPA1 = ROUND(PPA1,3)
    LET PPCC = ROUND(PPCC,3)
    JUSTIFICATION LEFT
    MOVE 20 87; TEXT A0: ^PPA0
    MOVE 20 85; TEXT A1: ^PPA1
    MOVE 20 83; TEXT PPCC: ^PPCC
 
Program 3:
    SKIP 25
    READ AUTO83B.DAT Y1 Y2
    DELETE Y2 SUBSET Y2 < 0
    .
    LINE BLANK BLANK SOLID DASH
    CHARACTER CIRCLE CIRCLE BLANK BLANK
    CHARACTER FILL ON ON
    CHARACTER HW 0.5 0.375 ALL
    CHARACTER COLOR BLACK RED
    TITLE AUTOMATIC
    TITLE OFFSET 2
    .
    LET N2 = SIZE Y2
    LET TAG = 1 FOR I = 1 1 N2
    LET TAG = 2 SUBSET Y2 > 32
    .
    HIGHLIGHT QUANTILE QUANTILE PLOT Y2 Y1 TAG

Program 4:
    . Step 1:   Read the data
    .
    skip 25
    read exp.dat      y1
    read weibbury.dat y2
    read gamma.dat    y3
    read frechet.dat  y4
    skip 0
    .
    variable label y1 exp.dat
    variable label y2 weibbury.dat
    variable label y3 gamma.dat
    variable label y4 frechet.dat
    .
    . Step 2:   Set some plot control features
    .
    case asis
    label case asis
    title case asis
    title offset 2
    tic mark offset units screen
    tic mark offset 5 5
    multiplot scale factor 4
    multiplot corner coordinates 10 10 90 90
    .
    line blank solid blank blank
    character circle blank blank blank
    character fill on
    character hw 0.5 0.375 all
    .
    . Step 3:   Scatter plot matrix of quantile-quantile plot
    .
    label displacement 18
    set scatter plot matrix type quantile quantile
    scatter plot matrix y1 y2 y3 y4
    .
    justification center
    move 50 97
    text Quantile-Quantile Plots of Four Data Sets

-----QUANTILE STANDARD ERROR (LET)------------------------------------
 
QUANTILE STANDARD ERROR
 
Name:
    QUANTILE STANDARD ERROR (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the standard error for a user specified quantile for
    a variable.
 
Description:
    The qth quantile of a data set is defined as that value
    where a q fraction of the data is below that value and (1-q)
    fraction of the data is above that value.  For example, the
    0.5 quantile is the median.
 
    Dataplot supports two methods for computing the quantile.
    The first method is the conventional method based on the order
    statistic.  The second method, called the Herrell-Davis method,
    is based on using all the order statistics.  The standard error
    methods given here only apply to the first method.

    Two methods for obtaining the standard errors for the quantiles
    are supported.

    The first method, called the Maritz-Jarrett method, is computed
    for the variable X and the desired quantile q as follows:

      1. Sort the X in ascending order.

      2. Let m = [q**n + 0.5]

      3. A = m - 1

      4. B = n - m

      5. W(i) = BETCDF(i/n, A, B) - BETCDF((i-1)/n, A, B)

         where BETCDF is the beta cumulative distribution
         function with shape parameters A and B.

      6. C(k) = SUM[i=1 to n][W(i)*X(i)**k]

      7. MJ = SQRT(C(2) - C(1)**2)

    The second method, based on the kernel density, is computed for
    a variable X as follows:

      1. Let h = 1.2*(Xhat(0.75) - Xhat(0.25))/n**(1/5).  Xhat is
         the estimated quantile.

      2. Compute the number of observations of X contained in the
         interval X +/- h.  Call this NINT.

      3. fhat(x) = NINT/(2*n*h)

      4. The stanard error of Xhat(q) = 1/[2*SQRT(n)*fhat(Xhat(q))]

Syntax:
    LET <par> = <quant> QUANTILE STANDARD ERROR <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <quant> is a number or parameter in the range (0.1) that
              specifies the desired quantile;
          <par> is a parameter where the computed quantile standard
              error is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    In order to specify the desired quantile, enter the command

        LET XQ = <value>

    where <value> is a number in the interval (0,1).

Examples:
    SET QUANTILE STANDARD ERROR MARITZ-JARRETT
    LET A = 0.20 QUANTILE STANDARD ERROR Y

    SET QUANTILE STANDARD ERROR KERNEL DENSITY
    LET XQ = 0.20
    LET A = XQ QUANTILE STANDARD ERROR Y
 
    SET QUANTILE STANDARD ERROR KERNEL DENSITY
    LET XQ = 0.20
    LET A = XQ QUANTILE STANDARD ERROR Y  SUBSET TAG > 1
 
Note:
    The following command is used to determine which method
    is used to compute the quantile standard error:

         SET QUANTILE STANDARD ERROR <KERNEL DENSITY/MARITZ JARRETT>

Note:
    Dataplot statistics can be used in 20+ commands.  For details, enter

         HELP STATISTICS

    The specific quantile for which the standard error is to be
    computed is specified by entering the following command (before
    the plot command):

       LET XQ = <value>

    where <value> is a number in the interval (0,1) that specifies
    the desired quantile.

Note:
  To obtain standard errors and confidence limits for the
  Herrell-Davis method, use the BOOTSTRAP PLOT command.  For
  example,

      LET XQ = 0.95
      SET QUANTILE METHOD HERRELL DAVIS
      BOOTSTRAP SAMPLES 500
      BOOTSTRAP QUANTILE STANDARD ERROR PLOT Y
      LET LCL = B025
      LET UCL = B975

   The bootstrap method can also be applied to quantile estimated
   using the order statistic method.

Default:
    The default is to use the Maritz-Jarrett method to
    compute the quantile standard error.
 
Synonyms:
    None
 
Related Commands:
    QUANTILE                    = Compute a quantile of a variable.
    MEDIAN                      = Compute the median of a variable.
    LOWER QUARTILE              = Compute the lower quartile of a
                                  variable.
    UPPER QUARTILE              = Compute the upper quartile of a
                                  variable.
    FIRST DECILE                = Compute the first decile (the 10th 
                                  quantile) of a variable.
    STATISTIC PLOT              = Generate a statistic versus subset
                                  plot for numerous statistics.
    CROSS TABULATE PLOT         = Generate a statistic versus subset
                                  plot (two group variables) for a
                                  given statistics.
    BOOTSTRAP PLOT              = Generate a bootstrap plot for a
                                  given statistic.
    INFLUENCE CURVE             = Generate an influence curve for a
                                  given statistic.
    DEX PLOT                    = Generate a dex plot for a given
                                  statistic.
    INTERACTION STATISTIC PLOT  = Generate a dex plot for a given
                                  statistic.
 
Reference:
    Rand Wilcox (1997), "Introduction to Robust Estimation and Hypothesis
    Testing", Academic Press.

    Frank Herrell and C. E. Davis, (1982), "A New Distribution-Free
    Quantile Estimator", Biometrika, 69(3), 635-640.

    Hyndman and Fan (November 1996), "Sample Quantiles in Statistical
    Packages", The American Statistician, Vol. 50, No. 4, pp. 361-365.

Applications:
    Data Analysis
 
Implementation Date:
    2002/7
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET XQ = 0.05
    LET P05 = XQ QUANTILE Y1
    LET P05SE = XQ QUANTILE STANDARD ERROR Y1
 
-----QUARTILE COEFFICIENT OF DISPERSION (LET)---------------------------
 
QUARTILE COEFFICIENT OF DISPERSION
 
Name:
    QUARTILE COEFFICIENT OF DISPERSION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the quartile coefficient of dispersion of a variable.
 
Description:
    The sample quartile coefficient of dispersion is defined as

         QCD = (Q3 - Q1)/(Q1 + Q3)

    where Q1 is the lower quartile (25-th percentile) and Q3 is the
    upper quartile (75-th percentile).

    This statistic has been suggested as a robust alternative to the
    coefficient of variation.

Syntax 1:
    LET <par> = QUARTILE COEFFICIENT OF DISPERSION <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <par> is a parameter where the quartile coefficient of
              dispersion value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Syntax 2:
    LET <par> = DIFFERENCE OF QUARTILE COEFFICIENT OF DISPERSION
                <y1> <y2>   <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the difference of the quartile
              coefficient of dispersion values are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET QCD = QUARTILE COEFFICIENT OF DISPERSION Y1
    LET QCD = QUARTILE COEFFICIENT OF DISPERSION Y1 SUBSET TAG > 2

    LET QCD = DIFFERENCE OF QUARTILE COEFFICIENT OF DISPERSION Y1 Y2

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    QCD
 
Related Commands:
    COEFFICIENT OF VARIATION  = Compute the coefficient of variation of
                                a variable.
    COEFFICIENT OF DISPERSION = Compute the coefficient of dispersion of
                                a variable.
    SIGNAL TO NOISE RATIO     = Compute the signal to noise ratio of a
                                variable.
    RELATIVE STANDARD DEVI    = Compute the standard deviation of a
                                variable.
    MEAN                      = Compute the mean of a variable.
    STANDARD DEVIATION        = Compute the standard deviation of a
                                variable.
 
Reference:
    Bonett, D. G. (2006). "Confidence interval for a coefficient of
    quartile variation", Computational Statistics & Data Analysis,
    50 (11): 2953–2957.

Applications:
    Data Analysis
 
Implementation Date:
    2017/01
    2017/06: Added QUARTILE COEFFICIENT OF DISPERSION
 
Program 1:
    SKIP 25
    READ ZARR13.DAT Y
    LET QCD = QUARTILE COEFFICIENT OF DISPERSION Y
 
Program 2:
    . Step 1:   Create the data
    .
    skip 25
    read gear.dat y x
    skip 0
    set write decimals 6
    .
    . Step 2:   Define plot control
    .
    title case asis
    title offset 2
    label case asis
    .
    y1label Quartile Coefficient of Dispersion
    x1label Group
    title Quartile Coefficient of Dispersion for GEAR.DAT
    let ngroup = unique x
    xlimits 1 ngroup
    major x1tic mark number ngroup
    minor x1tic mark number 0
    tic mark offset units data
    x1tic mark offset 0.5 0.5
    .
    character X
    line blank
    .
    set statistic plot reference line average
    quartile coefficient of dispersion plot y x
    .
    set write decimals 5
    tabulate quartile coefficient of dispersion y x

Program 3:
    SKIP 25
    READ IRIS.DAT Y1 TO Y4 X
    .
    LET A = DIFFERENCE OF QUARTILE COEFFICIENT OF DISPERSION Y1 Y2
    SET WRITE DECIMALS 4
    TABULATE DIFFERENCE OF QUARTILE COEFFICIENT OF DISPERSION Y1 Y2 X
    .
    XTIC OFFSET 0.2 0.2
    X1LABEL GROUP ID
    Y1LABEL DIFFERENCE OF QUARTILE COEFFICIENT OF DISPERSION
    CHAR X
    LINE BLANK
    DIFFERENCE OF COEFFICIENT OF DISPERSION PLOT Y1 Y2 X
    CHAR X ALL
    LINE BLANK ALL
    BOOTSTRAP DIFFERENCE OF QUARTILE COEFFICIENT OF DISPERSION PLOT ...
              Y1 Y2 X 
 
-----QUARTILE PLOT---------------------------------------------------
 
QUARTILE PLOT
 
Name:
    QUARTILE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a quartile plot.
 
Description:
    A quartile plot is a plot consisting of subsample quartiles versus
    subsample index.  The subsample quartile is the quartile of the
    data in the subsample.  The quartile plot is used to answer the
    question-- "Does the subsample spread change over different
    subsamples?".  It consist of:
       Vertical   axis = subsample quartile;
       Horizontal axis = subsample index.
    The quartile plot yields 2 traces:
       1. a subsample quartile trace; and
       2. a full-sample quartile reference line.
    Like usual, the appearance of these 2 traces is controlled by
    the first 2 settings of the LINES, CHARACTERS, SPIKES, BARS,
    and similar attributes.
 
Syntax:
    <UPPER/LOWER> QUARTILE PLOT  <y>  <x>
                 <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
          LOWER specifies a lower quartile plot and UPPER specifies an
              upper quartile plot;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    UPPER QUARTILE PLOT Y X
    LOWER QUARTILE PLOT Y X1  SUBSET X1 < 12
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS         = Sets the type for plot characters.
    LINES              = Sets the type for plot lines.
    MEAN   PLOT        = Generates a mean plot.
    SD   PLOT          = Generates a standard deviation plot.
    BOX PLOT           = Generates a box plot.
    XBAR CHART         = Generates a xbar control chart.
    PLOT               = Generates a data or function plot.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    88/2
 
Program:
    .  PURPOSE--GENERATE A QUARTILE PLOT OF POINT BARROW FREON-11 DATA
    SKIP 50
    SET READ FORMAT 3F4.0,F5.0,F6.0,F3.0,2F9.0
    READ PBF11.DAT YEAR DAY BOT SD F11 FLAG WV CO2
    .
    RETAIN YEAR DAY BOT SD F11 WV CO2 FLAG SUBSET FLAG 0
    LET MONTH=INT(DAY/30.25)+1
    .
    TITLE QUARTILE PLOT
    XLIMITS 0 15
    YLIMITS 1 1.01
    CHARACTER U U
    LINE BLANK SOLID
    UPPER QUARTILE PLOT WV MONTH
    PRE-ERASE OFF
    CHARACTER L L
    LOWER QUARTILE PLOT WV MONTH
 
-----QUERY-------------------------------------------------------
 
QUERY
 
Name:
    QUERY
 
Type:
    Support Command
 
Purpose:
    Sends a message to the DATAPLOT service group.  This message is
    placed in a file which can be scanned periodically by members of
    the DATAPLOT service group.
 
Syntax:
    QUERY   <message>
 
Examples:
    QUERY HAVE MODELING QUESTION
    QUERY PLEASE CALL J. SMITH (EXT. 3862)
 
Note:
    This command is essentially obsolete since most operating systems
    have sophisticated electronic mail capabilities.
 
Default:
    None
 
Synonyms:
    MESSAGE
 
Related Commands:
    MAIL    = Lists the mail file.
    HELP    = Lists portions of the help file.
    NEWS    = Lists the news file.
    BUGS    = Lists the bugs file.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----QUIC-------------------------------------------------------
 
QUIC
 
Name:
    QUIC
 
Type:
    Output Device Command
 
Purpose:
    Direct graphical output to a QMS laser printer using the QUIC
    protocol.
 
Syntax 1:
    QUIC
 
    This form directs the QUIC output to the terminal screen.
 
Syntax 2:
    DEVICE <1/2/3> QUIC
 
    This  form designates one of DATAPLOT's 3 devices (it will
    typically be device 2) to be a QUIC device.
 
Examples:
    QUIC
    DEVICE 2 QUIC
    DEVICE 3 QUIC
 
Note:
    QUIC fonts (for hardware generated characters) can be specified
    with the following command:
        SET QUIC FONT <font id>
    where <font id> is one of the following:
        10   - EDP font
        104  - Standard Roman Medium
        124  - Standard Roman Bold
        144  - Standard Roman Italic
        16   - Simplex Roman
        204  - Apollo Medium
        328  - Complex Roman Bold
        404  - Q-Typewriter
        444  - Q-Typewriter Italic
        532  - Union
        521  - Tektronix small
        522  - Tektronix medium
        523  - Tektronix large
        524  - Tektronix largest
        904  - Q-Gothic
        924  - Q-Gothic Italic
        536  - Q-Greek
        517  - Q-Greek
        664  - Special Math
    Fonts 10, 104, 124, 144, 16, 204, 328, 404, and 444 are supported
    on all QMS printers using QUIC.  The others are downloadable fonts
    that may or may not be available on a given QMS.  Additional
    information on QMS fonts can be found in the QMS Programmer's
    Manual for Quic.  In addition the following SET commands can be
    used to specify the margins and resolution of the particular QMS
    printer (these should normally not be required):
        SET QMS PPI <number> sets the resolution (in points per inch).
           The default is 300.
        SET QMS [LANDSCAPE/PORTRAIT] LEFT    MARGIN sets the left
           margin (in dots).
        SET QMS [LANDSCAPE/PORTRAIT] RIGHT   MARGIN sets the right
           margin (in dots).
        SET QMS [LANDSCAPE/PORTRAIT] BOTTOM  MARGIN sets the bottom
           margin (in dots).
        SET QMS [LANDSCAPE/PORTRAIT] TOP     MARGIN sets the top
            margin (in dots).
 
Default:
    Off
 
Synonyms:
    QMS
DEVICE NOTES
    1) HARDWARE TEXT - QMS provides numerous hardware fonts.  QMS fonts
       are fixed size and orientation fonts.  Several are typeset
       quality fonts.
    2) COLOR - This device does not support color or gray scale.
    3) HARDWARE FILL - All area fills in software (although QMS
       provides a hardware fill, it is not reliable).
    4) DASH PATTERNS - Each dash specification generates a different
       type of dash pattern.
    5) LINE WIDTH - The QMS performs line width in hardware.
    6) GRAPHICS INPUT - The CROSS-HAIR command is ignored for this
       device.
 
Related Commands:
    POSTSCRIPT         = Direct graphical output to a Postscript
                         device.
    CALCOMP            = Direct graphical output to a Calcomp device.
    HPGL               = Direct graphical output to an HPGL device.
    TEKTRONIX          = Direct graphical output to a Tektronix device.
    X11                = Direct graphical output to an X11 device.
    DEVICE             = Specify certain actions for the graphics
                         output.
    SET QMS FONT       = Specify the font to use on the QMS device.
    SET QMS PPI        = Set the resolution of the QMS device.
    SET QMS ... MARGIN = Set the margin for the QMS device.
 
Applications:
    XX
 
Implementation Date:
    89/2
 
Program:
    XX
 
-----QUIT-------------------------------------------------------
 
QUIT
 
Name:
    QUIT
 
Type:
    Support Command
 
Purpose:
    Terminates a DATAPLOT run.
 
Syntax:
    QUIT
 
Examples:
    QUIT
 
Default:
    None
 
Related Commands:
    XX
 
Synonyms:
    EXIT, END, HALT, STOP, BYE
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----QWIN-------------------------------------------------------
 
QWIN
 
Name:
    QWIN
 
Type:
    Output Device Command
 
Purpose:
    Direct graphical output to a the screen when using the version of
    Dataplot on the IBM-PC under the Windows operating system built
    using the Intel Fortran compiler.
 
Description:
    The production version of Dataplot is currently built under the
    Windows operating system (as of 2016/04 Windows XP, Windows 7, 
    and Windows 8 are supported) using the Intel Visual Fortran
    Composer XE (2013, SP1 version) compiler.

    Dataplot is built as a QuickWin application.  QuickWin provides
    access to some, but not all, parts of the Windows API.  QuickWin is
    intermediate between a console application and a full blown
    Windows application and provides the QuickWin graphics library to
    generate graphics on the screen.  The command

         DEVICE 1 QWIN

    is used to activate the Dataplot QuickWin device driver.  The
    default DPLOGF.TEX provided in the standard Dataplot installation
    for Windows will have this command, so typically you do not need to
    enter it.

Syntax 1:
    DEVICE 1 QWIN
 
    This form directs the graphics output to the terminal screen.
 
Syntax 2:
    DEVICE 1 QWIN  <width> <height>

    This form of the command allows you to specify the width and
    height of the graphics window in pixel units.
 
Examples:
    DEVICE 1 QWIN
    DEVICE 1 QWIN  500 350
 
Note:
    The Dataplot executable built as a QuickWin application is run
    as a stand alone program (we refer to this as the command line
    version).  For the Tcl/Tk based graphical user interface (GUI)
    for Dataplot, a console executable is built that does not support
    the QWIN device driver.  The QuickWin executable is not
    compatible with the Tcl/Tk scripts.

Note:
    A few notes on the QWIN screen driver.

       1) There are 3 distinct windows when running the QuickWin version
          of Dataplot under Windows.  The largest window is called the 
          frame window.  Upon starting Dataplot, a child window is
          automatically started for generating the alphanumeric input
          and output (this is called the text window).  These two windows
          can be resized by the user with standard Windows mouse
          operations.  When you enter the

               DEVICE 1 QWIN

          command, a graphics window is opened.

          There are some menu items available on each of these windows.
          These are standard Windows menu items, not Dataplot specified
          menu options (the Help menu has been customized, but otherwise
          these are the default QuickWin menus).

          In Windows, either the text or graphics window has the
          "focus".  The window with focus will be the window on top
          and this is the window that recieves I/O.  The default
          Dataplot behaviour is that when a graph is generated,
          focus switches to the graphics window and remains there
          after the plot is completed.  This leaves the graphics
          window over the text window.  To type a new command, click
          the mouse in the text window.  Clicking the mouse on a
          window switches the focus to that window.  Ideally, we 
          would like to leave the graphics window on top and have the
          I/O switch to the text window.  However, this doesn't
          seem possible at the moment.

          The 11/18/96 version added the command:

              SET QWIN FOCUS <TEXT/GRAPHICS>

          to allow the user to specify which window gets the focus
          after the completion of a plot.  Specifying TEXT returns
          the focus to the text window while specifying GRAPHICS
          leaves the focus on the graphics window.  The default value
          is TEXT.

          If the text and graphics windows are tiled, there is less need
          to set the focus to the graphics window.

          One other quirk is that sometimes the text window does not
          scroll properly when Dataplot is first initiated.  You can
          scroll the window manually via the mouse and scroll bar.  Also,
          the buffer for scrolling backward in the text window is rather
          limited (a few screens worth, but not much further).

          Note: The number of scroll lines in the buffer has been
                increased to 500 lines.  Also, the scrolling
                when Dataplot is first initiated now works better.

       2) This device driver supports color.  Enter the command
          SHOW COLORS VGA for a list of available colors.  Also,
          output sent to a black and white Postscript printer is
          NOT affected by the choice of colors for the screen.  This
          means you can chose foregrand and background colors that
          work well on the screen without harming your Postscript
          output.

          The initial version of the QWIN driver only supports the
          15 VGA colors.  A probable future enhancement is to
          extend the full range of Dataplot colors to super VGA
          and direct color monitors.

          Note: The QWIN device now supports the full range of
                colors supported in Dataplot.

       3) Hardware characters are supported.  Dataplot requests a
          fixed size font at the user specified size.  The QuickWin
          library returns the closest match to the requested font.

          The screen characters may seem smaller than characters
          generated with a software font.  This is due to the fact
          that the QWIN library will match to a smaller size rather
          than a larger size.  You can specify a software font to the
          screen while leaving the hardware font for the file
          devices by entering the command:

             DEVICE 1 FONT SIMPLEX

          We will probably add more complete support for the fonts
          provided by the QuickWin library in later releases.
          Specifically, this means allowing the user to specify the
          desired type face (e.g., Helvetica, Times Roman) and
          providing support for proportional spaced fonts.

       4) Dashed lines and software line thickness is supported for
          the QuickWin device.  The CROSS-HAIR command (for graphical
          input) is also supported.

       5) The Intel Fortran Compiler has trouble if the monitor
          is set to "True Color" mode.  The sympton is that the
          text window does not appear to show any characters
          (i.e., it is simply a blank screen).  True color is
          set from the Windows 95/98/NT control panel.

          If your monitor is set to true color mode, enter the
          following commands in the "C:\Dataplot\DPLOGF.TEX" 
          start-up file (the drive name may differ on your system):

               SET QWIN COLOR DIRECT
               DEVICE 1 QWIN

          Note that in this case, the order of the commands is
          critical.  That is, the color mode must be set when
          the QWIN device is initialized, not after.  The
          command SET QWIN COLOR COLOR VGA resets the default.

          For true color, the QWIN device driver supports the
          full range of color supported by Dataplot (enter
          HELP COLORS for a description of the Dataplot color
          model).  The default VGA mode only supports 16 colors.

          The foreground and background colors for the text
          window can be set for both standard VGA and the true
          color mode by entering the following commands after
          the SET QWIN COLOR <DIRECT/VGA> command but before the
          DEVICE 1 QWIN command:

               SET QWIN TEXT BACKGROUND COLOR <index>
               SET QWIN TEXT FOREGROUND COLOR <index>

          where <index> is an integer identifying the desired
          color (HELP COLOR gives the index to color mapping).
          For the default VGA mode, <index> is limtited to
          0 to 15.  For direct mode, <index> is between 0 and 88.
          The default is a white foreground on a black background.

          The colors for the graphics window are set with the
          normal Dataplot COLOR commands (e.g., LINE COLOR YELLOW).

          Note: The above section was relevant for older versions
                of the Intel compiler and older versions of the
                Windows operating systems.  You should no longer need
                to enter any of these commands.

Note:
    The following command line options are now supported:

    a) The size of the initial frame window (in pixels) can be set by
       selecting one of the following options:

          -svga  -large -extrawide

       where "-svga" sets a size of 950 by 700, -large sets a size of
       1150 by 1000, and -extrawide sets a size of 1600 by 1000.  These
       values are the number of pixels.  If none of these is entered,
       the -svga settings will be used.

       Alternatively, you can enter explicit values for the height and
       width of the frame window with the -w and -h options.  For example,
       to set the width and height to 1150 and 1000, respectively, enter

            -w1150  -h1000

       The recommended choice is basically a matter of taste and the
       resolution you have set for your monitor.

    b) You can use the following option to set "true color" mode:

          -true

       This is not preferred over the SET QWIN COLOR DIRECT as it
       will show the initial sign-on message.

       Note: This option is no longer needed and should not be used.

    c) By default, Dataplot overlaps the text and graphics windows.
       You can specify tiled mode with the following option:

           -tile

       You can also enter

           -notile

       to specify the non-tiled mode.

       Tile mode has the advantage that the text and graphics windows
       do not overlap.  The advantage of non-tiled mode is that the
       graphics window has a landscape orientation which is more similar
       to what the printed graphics will have.

    The order for these options does not matter.

Note:
    The menus accessible on the frame window are the default menus
    generated by the Intel compiler.

    As of the 11/2002 version, the menu items under the Help menu
    now access Dataplot help rather than help for the compiler.

Note:
    The handling of text with hardware fonts was upgraded for the
    2016/04 version.

    The following two commands were added:

         SET QWIN FONT WEIGHT <BOLD/NORMAL>
         SET QWIN FONT STYLE <ITALIC/NORMAL>

    These commands allow you to request bold and italic appearance
    for fonts.

    The SET QWIN FONT command was updated to support the following
    specific fonts

       SET QWIN FONT ARIAL
       SET QWIN FONT TIMES NEW ROMAN
       SET QWIN FONT SYMBOL
       SET QWIN FONT ROMAN
       SET QWIN FONT MODERN
       SET QWIN FONT SCRIPT
       SET QWIN FONT COURIER
       SET QWIN FONT HELVETICA
       SET QWIN FONT PALATINO
       SET QWIN FONT TERMINAL
       SET QWIN FONT SYSTEM
       SET QWIN FONT VERDANA
       SET QWIN FONT GEORGIA

    The fonts installed on a given system may vary on specific
    platforms.  The above fonts were chosen because they are
    relatively common and should be available on most systems.
    However, it is possible that you may not have one or more of
    these fonts on your system.

    Note that when Dataplot requests a font (the font family, the
    height and width, the use of bold or italic), the QuickWin
    library will try to match to the closest available font (the
    priority order is height, font family, width, and fixed or
    proportional font).

    The SYMBOL font can be used to print Greek characters using
    hardware text.

Note:
    The QuickWin library was originally part of the MicroSoft Fortran
    compiler.  The Microsoft Fortran compiler became the Compaq Fortran
    compiler and then the Digital Visual Fortrtan compiler before being
    merged into the Intel Fortran compiler.

Default:
    None
 
Synonyms:
    None

DEVICE NOTES
    1) HARDWARE TEXT - limited support.  Dataplot requests a fixed
       space font at the user requested size.  The QuickWin library
       returns the closest matching font.
    2) COLOR - the QWIN driver supports the full range of colors
       supported by Dataplot.
    3) HARDWARE FILL - Solid fills are generated in software.
    4) DASH PATTERNS - Dash patterns are supported.
    5) LINE WIDTH - Thick lines are generated in software as multiple
       lines.
    6) GRAPHICS INPUT - The CROSS-HAIR command is supported for this
       device.
 
Related Commands:
    HPGL                  = Direct graphical output to an HPGL device.
    DEVICE                = Specify certain actions for the graphics
                            output.
    POSTSCRIPT            = Direct graphical output to a Postscript
                            device.
 
Applications:
    Screen Graphics
 
Implementation Date:
    11/1996
    2002/11: Added the "-tile" option
    2002/11: The "Help" menus modified to access Dataplot (rather than
             the compiler) help
    2014/12: Increase the size of the buffer in the text window and
             fix the initial scrolling
    2015/10: Check if graphics window is already open when a
             DEVICE 1 QWIN command is entered
    2016/04: Updated handling of text with hardware fonts
    2016/04: Added SET QWIN FONT WEIGHT
    2016/04: Added SET QWIN FONT STYLE
 
Program:
    DEVICE 1 QWIN
    PLOT SIN(X) FOR X = -6 0.1 6
 
-----QWIN SYSTEM (SET)---------------------------------------
 
QWIN SYSTEM
 
Name:
    QWIN SYSTEM (SET)
 
Type:
    Set Subcommand
 
Purpose:
    For the version of Dataplot built with the Visual Fortran compiler,
    it specifies whether operating system commands are invoked with
    the SYSTEMQQ library function or the WinExec library function.
 
Description:
    The Dataplot command SYSTEM is used to invoke an operating system
    command or an external program (e.g., a web browser).  In addition,
    several other Dataplot commands (e.g., WEB HELP) invoke external
    programs.  Note that invoking operating system commands and
    external programs is not part of the Fortran standard, so this
    capability in Dataplot is operating system and compiler dependent.

    The command line version of Dataplot is built using the Visual
    Fortran (previously the Microsoft) compiler as a QuickWin (QWIN)
    application.  By default, the SYSTEMQQ library routine is used to
    invoke operating system commands and external programs.  The
    primary drawback of this option is that control does not return to
    Dataplot until the operating system command completes execution.

    Alternatively, the WinExec function can be used.  The advantage of
    this method is that control passes back to Dataplot after the
    command is issued (i.e., it doesn't wait for the command to
    complete).  However, the drawback is that DOS type commands do not
    work.

    The basic recommendation is that if you want to execute a Windows
    application (e.g., the browser, notepad, Word, etc.), then set this
    option to WINEXEC.  However, to issue a DOS type command via the
    Dataplot SYSTEM command, you should set this option to SYSTEMQQ (the
    default).

    In particular, I recommend setting this option to WINEXEC before
    using the WEB HELP (or any other command starting with WEB) command.
    This allows you to enter additional Dataplot commands without
    exiting the browser.

Syntax:
    SET QWIN SYSTEM <SYSTEMQQ/WINEXEC>
    where SYSTEMQQ specifies that calls to the operating system are
          invoked with SYSTEMQQ and WINEXEC specificies that calls to
          to the operating system are invoked with WinExec.
 
Examples:
    SET QWIN SYSTEM WINEXEC
    SET QWIN SYSTEM SYSTEMQQ
 
Note:
    This command only applies tom the command line version of Dataplot
    under Microsoft Windows (i.e., the executable built with the
    Visual Fortran (previously the Microsoft) compiler.  It is
    ignored on all other systems.

Default:
    The default is SYSTEMQQ.
 
Synonyms:
    None
 
Related Commands:
    WEB HELP      = View the Dataplot online Reference Manual.
    SYSTEM        = Enter an operating system command.
 
Applications:
    Interacting with Microsoft Windows
 
Implementation Date:
    2002/11
 
Program:
    SET QWIN SYSTEM WINEXEC
    WEB HELP PLOT
    SET QWIN SYSTEM SYSTEMQQ
    SYSTEM  DIR C:\DATAPLOT\DATA | MORE
 
---------------------------------------------------------










































































-------------------------  *R*  ZZZZZ--------------------

-----R CHART-------------------------------------------------------
 
R CHART
 
Name:
    R CHART
 
Type:
    Graphics Command
 
Purpose:
    Generates a range control chart.
 
Description:
    A range control chart is a data analysis analysis technique for
    determining if a measurement process has gone out of statistical
    control.  The R chart is sensitive to changes in variation in the
    measurement process.  It consist of:
      Vertical   axis = the range  for each sub-group;
      Horizontal axis = sub-group designation.
    In addition, horizontal lines are drawn at the mean range value
    and at the upper and lower control limits.
 
Syntax:
    R CHART   <y>   <x>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable (containing the
              raw data values);
          <x> is an independent variable (containing the sub-group
              identifications);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    R CHART Y X
 
Note:
    The distribution of the response variable is assumed to be normal.
    This assumption is the basis for calculating the upper and lower
    control limits.
 
Note:
    The attributes of the 4 traces can be controlled by the standard
    LINES, CHARACTERS, BARS, and SPIKES commands.  Trace 1 is the
    response variable, trace2 is the mean line, and traces 3 and 4 are
    the control limits.  Some analysts prefer to draw the response
    variable as a spike or character rather than a connected line.
 
Default:
    None
 
Synonyms:
    RANGE CHART for R CHART
    R CONTROL CHART for R CHART
    RANGE CONTROL CHART for R CHART
 
Related Commands:
    X CHART             = Generates a mean control chart.
    S CHART             = Generates a standard deviation control chart.
    P CHART             = Generates a p control chart.
    NP CHART            = Generates a Np control chart.
    U CHART             = Generates a U control chart.
    C CHART             = Generates a C control chart.
    CHARACTERS          = Sets the types for plot characters.
    LINES               = Sets the types for plot lines.
    SPIKES              = Sets the on/off switches for plot spikes.
    BARS                = Sets the on/off switches for plot bars.
    PLOT                = Generates a data or function plot.
    LAG PLOT            = Generates a lag plot.
    4-PLOT              = Generates 4-plot univariate analysis.
    RANGE PLOT          = Generates a range (vs subset) plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    SKIP 25
    READ GEAR.DAT DIAMETER BATCH
    .
    LINE SOLID SOLID DOT DOT
    TITLE AUTOMATIC
    X1LABEL GROUP-ID
    Y1LABEL RANGE
    RANGE CONTROL CHART DIAMETER BATCH
 
-----RADIANS-------------------------------------------------------
 
RADIANS
 
Name:
    RADIANS
 
Type:
    Support Command
 
Purpose:
    Specifies that all subsequent trigonometric calculations (e.g.,
    LET Y = SIN(X) and ANGLE 1.570746) be carried out in radians (as
    opposed to degrees or grads).
 
Syntax:
    RADIANS   <ON or OFF>
    where ON specifies that radian units will be used while OFF
             reverts the units to degrees.
 
Examples:
    RADIANS
    RADIANS ON
    RADIANS OFF
 
Note:
    Entering the RADIANS command without any arguments is equivalent
    to entering RADIANS ON.
 
Default:
    Radians
 
Synonyms:
    None
 
Related Commands:
    TEXT        = Writes a text string.
    DEGREES     = Sets the angle units to degrees.
    GRADS       = Sets the angle units to grads.
    ANGLE UNITS = Sets the angle units (to degrees/radians/grads).
    ANGLE       = Sets the angle for TEXT string.
    FONT        = Sets the font for TEXT characters.
 
Applications:
    Trigonometry
 
Implementation Date:
    Pre-1987
 
Program:
    RADIANS
    PLOT SIN(X) FOR X = -6  0.1 6
 
-----RANDOM COMPOSITION (LET)-----------------------------------------
 
RANDOM COMPOSITION
 
Name:
    RANDOM COMPOSITION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate a random composition.
 
Description:
    Given positive integers n and k, a composition of n into k parts
    is defined as

       n = r1 + r2 + ... + rk  (r(i) >= 0, i = 1,k)

    The number of compositions is given by

        (n+k-1   n)  = (n+k-1)!/[(n!*(k-1)!]

    This command generates a single random composition.

    The output is an array of size k.

Syntax:
    LET <y> = RANDOM COMPOSITION FOR I =  1  1  <k>
    where <k> is a number or parameter that specifies the size of
              the composition;
    and   <y> is a variable where the random composition is saved.
 
    This command must be preceeded with the command

        LET N = <value>

Examples:
    LET N = 5
    LET K = 3
    LET Y = RANDOM COMPOSITION FOR I = 1 1 K
 
Note:
    Dataplot implements this command using the RANCOM algorithm 
    described in Nijenhuis and Wilf (see Reference section
    below).
 
Note:
    Dataplot supports a number of different random number
    generators.  Enter HELP RANDOM NUMBER GENERATOR for details.

    The SEED command can be used to specify a seed for the random
    number generator.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                          = Generate data transformations.
    RANDOM PERMUTATION           = Generate a random permutation.
    RANDOM SUBSET                = Generate a random subset.
    RANDOM K-SET OF N-SET        = Generate a random k-set of n-set.
    RANDOM PARTITION             = Generate a random partition.
    RANDOM EQUIVALENCE RELATION  = Generate a random equivalence relation.
    NEXT SUBSET                  = Generate the next subset of a set.
    NEXT PERMUTATION             = Generate the next permutation.
    NEXT K-SET OF N-SET          = Generate the next k-set of n-set.
    NEXT COMPOSITION             = Generate the next composition.
    NEXT PARTITION               = Generate the next partition.
    NEXT EQUIVALENCE RELATION    = Generate the next composition.
 
References:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 6.

Applications:
    Combinatorial Analysis
 
Implementation Date:
    2008/4
 
Program:
    LET N = 8
    LET K = 3
    LET Y = RANDOM COMPOSITION FOR I =  1  1  K
    PRINT Y

-----RANDOM EQUIVALENCE RELATION (LET)-------------------------------
 
RANDOM EQUIVALENCE RELATION
 
Name:
    RANDOM EQUIVALENCE RELATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate a random equivalence relation of an n-element set.
 
Description:
    Given a set S = {1, 2, ..., n}, a random partition of S
    is defined as a collection of sets T1, T2, ... , Tk
    satisfying

        1) The intersection of T(i) and T(j) is the empty
           set for i not equal j.

        2) The union of all k sets contains all the elements
           of S.

    For example, if n = 3, then there are 5 possible partitions:

        {1, 2, 3}
        {1,2} {3}
        {1, 3} {2}
        {2, 3} {1}
        {1} {2} {3}
      
    The output of this command is an array of size n where
    the ith element identifies the class which i belongs to.
    For example, the following array (for n = 5)

        3  3  1  2  2

    identifies the partition

       {3}  {4, 5}  {1, 2}
   
Syntax:
    LET <y> = RANDOM EQUIVALENCE RELATION
    where <y> is a variable where the random equivalence relation
              is saved.
 
    This command must be preceeded with the command

        LET N = <value>

Examples:
    LET N = 5
    LET Y = RANDOM EQUIVALENCE RELATION
 
Note:
    Dataplot implements this command using the RANEQU algorithm 
    described in Nijenhuis and Wilf (see Reference section
    below).
 
Note:
    Dataplot supports a number of different random number
    generators.  Enter HELP RANDOM NUMBER GENERATOR for details.

    The SEED command can be used to specify a seed for the random
    number generator.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                          = Generate data transformations.
    RANDOM PERMUTATION           = Generate a random permutation.
    RANDOM SUBSET                = Generate a random subset.
    RANDOM K-SET OF N-SET        = Generate a random k-set of n-set.
    RANDOM COMPOSITION           = Generate a random composition.
    RANDOM PARTITION             = Generate a random partition.
    NEXT SUBSET                  = Generate the next subset of a set.
    NEXT PERMUTATION             = Generate the next permutation.
    NEXT K-SET OF N-SET          = Generate the next k-set of n-set.
    NEXT COMPOSITION             = Generate the next composition.
    NEXT PARTITION               = Generate the next partition.
    NEXT EQUIVALENCE RELATION    = Generate the next composition.
 
References:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 12.

Applications:
    Combinatorial Analysis
 
Implementation Date:
    2008/6
 
Program:
    LET N = 8
    LET Y = RANDOM EQUIVALENCE RELATION
    PRINT Y

-----RANDOM ERROR QUANTITY (LET)-----------------------------------------
 
RANDOM ERROR QUANTITY
 
Name:
    RANDOM ERROR QUANTITY (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the random error quantity.
 
Description:
    In a two sample proficiency study, a laboratory measures two
    samples.  We refer to these as sample X and sample Y.  The
    random error quantity is then defined as

       REQ = [(X(i) - Y(i)) - (Xmed - Ymed)]

    with Xmed and Ymed denoting the medians of samples X and Y,
    respectively.

    The ASTM E 2489 - 06 standard gives the following rationale for the
    random error quantity.

       1. The medians for each sample define consensus values
          for each sample.

       2. For a given laboratory, X(i) contains variation from the
          consensus value (the median value) due to random error
          (within-laboratory error) and systematic error (bias).
          Likewise for Y(i).

       3. It is assumed that the systematic error is the same for sample X
          and sample Y for a given laboratory.  Based on this, X(i) - Y(i)
          will subtract out the systematic error leaving only random
          error.

       4. Subtracting Xmed - Ymed removes any difference that appears
          for the medians of sample X and sample Y.

       5. The random error quantity should then contain only the
          laboratories random error.  These values can be used to
          compare the within-laboratory performance of the various
          laboratories.

Syntax:
    LET <yout> = RANDOM ERROR QUANTITY <x> <y>
                                      <SUBSET/EXCEPT/FOR qualification>
    where <x> is the variable containing the measurements for sample X;
          <y> is the variable containing the measurements for sample Y;
          <yout> is a variable where the computed random error quantities
              are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    Note that <x> and <y> are paired so they must be of the same length.
 
Examples:
    LET RANERR = RANDOM ERROR QUANTITY X Y
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    TWO SAMPLE PROFICIENCY TEST = Perform a two sample proficiency test
                                  based on ASTM E 2489.
    MEDIAN                      = Compute the median of a variable.
 
Reference:
    "Standard Practice for Statistical Analysis of One-Sample
    and Two-Sample Proficiency Testing Programs", ASTM
    International, 100 Barr Harbor Drive, PO BOX C700,
    West Conshohoceken, PA 19428-2959, USA.

Applications:
    Proficiency Testing
 
Implementation Date:
    2014/12
 
Program:
    skip 25
    read e2489b.dat lab y1 y2
    .
    let ranerr = random error quantity y1 y2
    set write decimals 2
    print lab ranerr

-----RANDOM K-SET OF N-SET (LET)-----------------------------------------
 
RANDOM K-SET OF N-SET
 
Name:
    RANDOM K-SET OF N-SET (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate a random k-set of a an n-set.
 
Description:
    Given a set of n elements {1, 2, ..., n}, a basic
    combinatorial problem is the combination of n things
    taken k at a time.  For a given n and k, there are 

        (n k)  = n!/[k!*(n-k)!]

    k-sets of the original n-set.

    This command generates a single random k-set.

    The output is an array of size k that identifies the
    elements included in the k-set.

Syntax:
    LET <y> = RANDOM K-SET OF N-SET FOR I =  1  1  <k>
    where <k> is a number or parameter that specifies the size of
              the k-set;
    and where <y> is a variable where the random k-set is saved.
 
    This command must be preceeded with the command

        LET N = <value>

Examples:
    LET N = 5
    LET K = 3
    LET Y = RANDOM K-SET OF N-SET FOR I = 1 1 K
 
Note:
    Dataplot implements this command using the algorithm 
    RANKSB described in Nijenhuis and Wilf (see Reference section
    below).
 
Note:
    Dataplot supports a number of different random number
    generators.  Enter HELP RANDOM NUMBER GENERATOR for details.

    The SEED command can be used to specify a seed for the random
    number generator.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                          = Generate data transformations.
    RANDOM PERMUTATION           = Generate a random permutation.
    RANDOM SUBSET                = Generate a random subset.
    RANDOM COMPOSITION           = Generate a random composition.
    RANDOM PARTITION             = Generate a random partition.
    RANDOM EQUIVALENCE RELATION  = Generate a random equivalence relation.
    NEXT SUBSET                  = Generate the next subset of a set.
    NEXT PERMUTATION             = Generate the next permutation.
    NEXT K-SET OF N-SET          = Generate the next k-set of n-set.
    NEXT COMPOSITION             = Generate the next composition.
    NEXT PARTITION               = Generate the next partition.
    NEXT EQUIVALENCE RELATION    = Generate the next composition.
 
References:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 4.

Applications:
    Combinatorial Analysis
 
Implementation Date:
    2008/4
 
Program:
    LET N = 8
    LET K = 3
    LET Y = RANDOM K-SET OF N-SET FOR I =  1  1  K
    PRINT Y

-----RANDOM PARTITION (LET)-----------------------------------------
 
RANDOM PARTITION
 
Name:
    RANDOM PARTITION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate a random partition of a positive integer.
 
Description:
    Given a positive integer n, a partition of n is defined as

        n = r1 + r2 + ... + rk  (r1 >= r2 >= ... >= rk)

    where r1, r2, ...., rk are positive integers.

    For example, if n = 6, then there are 3 partitions:

        6 = 4 + 1 + 1
          = 3 + 2 + 1
          = 2 + 2 + 2
   
Syntax:
    LET <y> = RANDOM PARTITION
    where <y> is a variable where the random partition is saved.
 
    This command must be preceeded with the command

        LET N = <value>

Examples:
    LET N = 5
    LET Y = RANDOM PARTITION
 
Note:
    Dataplot implements this command using the RANPAR algorithm 
    described in Nijenhuis and Wilf (see Reference section
    below).
 
Note:
    Dataplot supports a number of different random number
    generators.  Enter HELP RANDOM NUMBER GENERATOR for details.

    The SEED command can be used to specify a seed for the random
    number generator.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                          = Generate data transformations.
    RANDOM PERMUTATION           = Generate a random permutation.
    RANDOM SUBSET                = Generate a random subset.
    RANDOM K-SET OF N-SET        = Generate a random k-set of n-set.
    RANDOM COMPOSITION           = Generate a random composition.
    RANDOM EQUIVALENCE RELATION  = Generate a random equivalence relation.
    NEXT SUBSET                  = Generate the next subset of a set.
    NEXT PERMUTATION             = Generate the next permutation.
    NEXT K-SET OF N-SET          = Generate the next k-set of n-set.
    NEXT COMPOSITION             = Generate the next composition.
    NEXT PARTITION               = Generate the next partition.
    NEXT EQUIVALENCE RELATION    = Generate the next composition.
 
References:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 10.

Applications:
    Combinatorial Analysis
 
Implementation Date:
    2008/4
 
Program:
    LET N = 8
    LET Y = RANDOM PARTITION
    PRINT Y

-----RANDOM PERMUTATION (LET)-----------------------------------------
 
RANDOM PERMUTATION
 
Name:
    RANDOM PERMUTATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate a set of random permutations.
 
Description:
    For a given size N, the integers from 1 to N are randomly sampled
    (without replacement) until all elements have been selected.
 
    This command is useful for randomly assigning a list of items (to
    groups, treatments, etc.).
 
Syntax:
    LET <resp> = RANDOM PERMUTATION FOR I = <start> <inc> <stop>
    where <start> is a number or parameter that identifies the first
              row of <resp> in which the permutated values are saved
             (typically it has a value of 1);
          <inc> is a number or parameter that identifies the row
              increment of <resp> in which the permutated values are
              saved (typically it has a value of 1);
          <stop> is a number or parameter that identifies the last row
              of <resp> in which the permutated values are saved;
          <resp> is a variable where the permutated values are saved.
 
Examples:
    LET RP = RANDOM PERMUTATION FOR I = 1 1 100
 
Note:
    The following are similar:
         LET Y1 = RANDOM PERMUTATION FOR I = 1 1 N
    and
         LET N = 100
         LET Y2 = DISCRETE UNIFORM RANDOM NUMBERS FOR I = 1 1 N
    The distinction is that the first command (RANDOM PERMUTATIONS)
    does the sampling without replacement while the second command does
    the sampling with replacement (so you can have repeat values).
 
Note:
    The SEED command can be used to specify a seed for the random
    number generation.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                 = Generate data transformations.
    BOOTSTRAP SAMPLE    = Generate a bootstrap sample.
    BOOTSTRAP INDEX     = Generate a bootstrap index.
    JACKNIFE INDEX      = Generate a jacknife index.
    BOOTSTRAP PLOT      = Generate a bootstrap plot.
    JACKNIFE PLOT       = Generate a jacknife plot.
 
Applications:
    Experimental Design
 
Implementation Date:
    Pre-1987
 
Program:
    LET N = 35
    LET Y = RANDOM PERMUTATION FOR I = 1 1 N
    PRINT Y
 
-----RANDOM NUMBER GENERATOR (SET)------------------------------------
 
RANDOM NUMBER GENERATOR
 
Name:
    RANDOM NUMBER GENERATOR (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify which uniform random number generator to use.
 
Description:
    Random numbers for all supported probability distributions
    are ultimately based on an underlying uniform (0,1) distribution.

    Much research has been devoted to developing good uniform
    random number generators.  Dataplot now supports a number of
    alternative uniform random number generators.
 
    Note that the default generator (i.e., the one that has been in
    Dataplot for many years) is based on Fibonacci sequence as
    defined by Marsagalia.  Note that this is equivalent to the
    generator UNI of Jim Blue, David Kahaner, and George Marsagalia
    that is in the NIST CMLIB library.

    Support is now provided for a linear congruential generator
    written by Fullerton (NIST CMLIB routine RUNIF) and a multiplicative
    congruential generator (ACM algorithm 599).  In addition,
    two generators based on the generalized feedback shift
    register (GFSR) methods are supported.  The first is based on the
    original algorithm of Lewis and Payne (Journal of the ACM,
    Volume 20, pp. 456-468).  The second is an alternative
    implementation given by Fushimi and Tezuka (Journal of the
    ACM, Volume 26, pp. 516-523).  Both are based on codes
    given by Monohan (2000) in "Numerical Methods of Statistics".
    Support is also provided for the Applied Statistics algorithm
    183.  AS183 is based on the fractional part of the sum of 3
    multiplicative congruential generators.  It requires 3 integers
    be specified initially.  Dataplot uses the multiplicative
    congruenetial generator (which depends on the SEED command)
    to randomly generate these 3 integers.

    These 6 generators are used to generate uniform random numbers.
    Random numbers for other distributions are then derived from
    these uniform random numbers.

    Note that you can use the SEED command to change the random numbers
    generated as well.  The SEED does not apply to the 2 GFSR
    generators (these each have their own initialization routines).
 
Syntax:
    SET RANDOM NUMBER GENERATOR <generator>
    where <generator> is one of the following:
 
        FIBONACCI
        LINEAR CONGRUENTIAL
        MULTIPLICATIVE CONGRUENTIAL
        GFSR
        FUSHIMI
        AS183
        GENZ
        LUXURY
        FIBONACCI CONGRUENTIAL
        MERSENNE TWISTER
 
Examples:
    SET RANDOM NUMBER GENERATOR FIBONACCI
    SET RANDOM NUMBER GENERATOR LINEAR CONGRUENTIAL
    SET RANDOM NUMBER GENERATOR MULTIPLICATIVE CONGRUENTIAL
    SET RANDOM NUMBER GENERATOR GFSR
    SET RANDOM NUMBER GENERATOR FUSHIMI
    SET RANDOM NUMBER GENERATOR AS183
    SET RANDOM NUMBER GENERATOR GENZ
    SET RANDOM NUMBER GENERATOR LUXURY
    SET RANDOM NUMBER GENERATOR FIBONACCI CONGRUENTIAL
    SET RANDOM NUMBER GENERATOR MERSENNE TWISTER
 
Note:
    The following additional random number generators have been
    added:

       1) GENZ - Alan Genz implementation of Pierre L'Ecuyer
          generator described in "Combined Multiple Recursive
          Random Number Generators" (see Reference section below).

        2) LUXURY - based on the Marsagalia and Zaman
           borrow-and-carry generator.  Uses a code written
           by F. James and incorporating improvements by
           M. Luscher.

        3) FIBONNACI CONGRUENTIAL - combines the Fibonnaci generator
           with a congruential generator.  Method from Kahander and
           Marsagalia in "Numerical Methods and Software".

        4) MERSENNE TWISTER - original C algorithm coded by
           Takuji Nishimura.  Dataplot uses the Fortran 90
           translation provided by Hiroshi Takano.  This generator
           may not work as intended on versions of Dataplot compiled
           with Fortran 77 compilers.  It uses some intrinsic
           functions that are part of the Fortran 90 standard,
           but not the Fortran 77 standard.  Some Fortran 77
           compilers may support these functions, but this support
           is optional.

Default:
    FIBONACCI
 
Synonyms:
    None
 
Related Commands:
    RANDOM NUMBERS     = Generate random numbers for 60+ distributions.
    PROBABILITY PLOT   = Generate a probability plot.
    HISTOGRAM          = Generate a histogram.
    RUNS TEST          = Generate a runs test.
 
Reference:
    "Applied Statistics Algorithms", P. Griffiths and I. D. Hill,
    Ellis Horwood Limited, 1985.
 
    "Numerical Analysis for Statistics", John Monohan,
    Oxford University Press, 2000.
 
    "Combined Multiple Recursive Random Number Generators",
    Pierre L'Ecuyer, Operations Research 44, 1996, pp. 816-822.

    M. Luscher, Computer Physics Communications, 79 (1994) 100.

    F. James, Computer Physics Communications, 79 (1994) 111.

    "Numerical Methods and Software", David Kahaner, Cleve Moler,
    and Stephen Nash, Prentice-Hall, 1989.

Applications:
    Random number generation
 
Implementation Date:
    2002/5
    2003/5: Added support for the Alan Genz and Luxury random number
            generators
    2003/10: Added support for the Fibonnaci-Congruential and
             Mersenne twister random number generators
 
Program:
    title case asis
    case asis
    .
    multiplot corner coordinates 0 0 100 100
    multiplot scale factor 2
    multiplot 2 2
    .
    let y = uniform random numbers for i = 1 1 1000
    title Dataplot (Fibonacci) Random Numbers
    uniform prob plot y
    move 50 8
    just center
    text PPCC = ^ppcc
    .
    set random number generator linear congruential
    let y2 = uniform random numbers for i = 1 1 1000
    title Linear Congruential Random Numbers
    uniform prob plot y2
    move 50 8
    just center
    text PPCC = ^ppcc
    .
    set random number generator multiplicative congruential
    let y3 = uniform random numbers for i = 1 1 1000
    title Multiplicative Congruential Random Numbers
    uniform prob plot y3
    move 50 8
    just center
    text PPCC = ^ppcc
    .
    end of multiplot
 
-----RANDOM SUBSET (LET)-----------------------------------------
 
RANDOM SUBSET
 
Name:
    RANDOM SUBSET (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate a random subset.
 
Description:
    A basic combinatorial problem is to generate the 2**n subsets
    of the set {1, 2, ..., n}.

    This command generates a single random subset among the
    2**n possible subsets.

    The output is an array of zero and one values where zero
    for the ith element of the set indicates the element is not
    present and a value of one indicates the ith element is
    present.  For example, if n = 5 an output array of

        1 0 0 1 1

    specifies that elements 1, 4, and 5 are present while
    elements 2 and 3 are not.

Syntax:
    LET <y> = RANDOM SUBSET FOR I =  1  1  <n>
    where <n> is a number or parameter that specifies the size of
              the set;
    and   <y> is a variable where the random subset is saved.
 
Examples:
    LET N = 5
    LET Y1 = RANDOM SUBSET FOR I = 1 1 N
 
Note:
    Dataplot implements this command using the algorithm 
    described in Nijenhuis and Wilf (see Reference section
    below).
 
Note:
    Dataplot supports a number of different random number
    generators.  Enter HELP RANDOM NUMBER GENERATOR for details.

    The SEED command can be used to specify a seed for the random
    number generator.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                          = Generate data transformations.
    RANDOM PERMUTATION           = Generate a random permutation.
    RANDOM K-SET OF N-SET        = Generate a random k-set of n-set.
    RANDOM COMPOSITION           = Generate a random composition.
    RANDOM PARTITION             = Generate a random partition.
    RANDOM EQUIVALENCE RELATION  = Generate a random equivalence relation.
    NEXT SUBSET                  = Generate the next subset of a set.
    NEXT PERMUTATION             = Generate the next permutation.
    NEXT K-SET OF N-SET          = Generate the next k-set of n-set.
    NEXT COMPOSITION             = Generate the next composition.
    NEXT PARTITION               = Generate the next partition.
    NEXT EQUIVALENCE RELATION    = Generate the next composition.
 
References:
    Nijenhuis and Wilf (1978), "Combinatorial Algorithms",
    Second Edition, Academic Press, Chapter 2.

Applications:
    Combinatorial Analysis
 
Implementation Date:
    2008/4
 
Program:
    LET N = 10
    LET Y = RANDOM SUBSET FOR I =  1  1  N
    PRINT Y

-----RANGE (LET)---------------------------------------------------
 
RANGE
 
Name:
    RANGE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the range of a variable.
 
Description:
    The range is the difference between the largest and smallest value.
 
Syntax:
    LET <par> = RANGE <y1>  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the variable for which the range is to be computed;
          <par> is a parameter where the computed range is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RANGE Y1
    LET A = RANGE Y1 SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MEAN (LET)               = Compute the mean of a variable.
    STANDARD DEVIATION (LET) = Compute the standard deviation of
                               a variable.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    XX
 
Program:
    LET X1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET A = RANGE Y1
 
-----RANGE PLOT--------------------------------------------------
 
RANGE PLOT
 
Name:
    RANGE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a range plot.
 
Description:
    A range plot is a plot consisting of subsample ranges versus
    subsample index.  The subsample range is the difference between the
    maximum and minimum of the data in the subsample.  The range plot
    is used to answer the question-- "Does the subsample variation
    change over different subsamples?".  It consists of:
       Vertical   axis = subsample range;
       Horizontal axis = subsample index.
    The range plot yields 2 traces:
       1. a subsample range trace; and
       2. a full-sample range reference line.
    Like usual, the appearance of these 2 traces is
    controlled by the first 2 settings of the LINES,
    CHARACTERS, SPIKES, BARS, and similar attributes.
 
Syntax:
    RANGE PLOT   <y>   <x>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    RANGE PLOT Y X
    RANGE PLOT Y X1
 
Default:
    None
 
Synonyms:
    R PLOT
 
Related Commands:
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    STANDARD DEVIATION PLOT = Generates a standard deviation plot.
    VARIANCE  PLOT          = Generates a variance plot.
    MEAN PLOT               = Generates a mean plot.
    MEDIAN PLOT             = Generates a median plot.
    BOX PLOT                = Generates a box plot.
    RANGE CHART             = Generates a range control chart.
    S CHART                 = Generates a standard deviation control
                              chart.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    SKIP 25
    READ GEAR.DAT Y X
    LINE BLANK DASH
    CHARACTER X BLANK
    XTIC OFFSET 0.2 0.2
    Y1LABEL RANGE
    X1LABEL SAMPLE ID
    TITLE AUTOMATIC
    RANGE PLOT Y X
 
-----RANK2 (LET)---------------------------------------------------
 
RANK2
 
Name:
    RANK2 (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Rank the elements of a response variable when there are one,
    two, or three group-id variables.
 
Description:
    The RANK command is used to rank a response variable.  However,
    there may be cases where you want to rank the data withing
    groups.  The RANK2, RANK3, and RANK4 commands let you perform
    the ranking for the cases with one, two, or three group-id
    variables, respectively.

    Nonparameteric analysis is often based on ranked data rather
    than the original data.  This command may be helpful in implementing
    nonparameteric methods that are not directly supported by Dataplot.

Syntax 1:
    LET <y2> = RANK2 <y1> <x1>
                    <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a response variable to be ranked;
          <x1> is a group-id variable;
          <y2> is a variable where the ranked <y1> values are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where we are ranking based
    on one group-id variable.

Syntax 2:
    LET <y2> = RANK3 <y1> <x1> <x2>
                    <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a response variable to be ranked;
          <x1> is the first group-id variable;
          <x2> is the second group-id variable;
          <y2> is a variable where the ranked <y1> values are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where we are ranking based
    on two group-id variables.

Examples:
    LET Y2 = RANK2 Y X1
    LET Y2 = RANK2 Y X1 X2
    LET Y2 = RANK2 Y X1  SUBSET X1 > 2
 
Note:
    The response values are ranked in ascending order.

Note:
    The groups in the data do not need to be pre-sorted or
    contiguous.  The ranked response variable will be in the
    same order as the original response variable (i.e., the
    groups are not sorted on output).

    If you want to extract the rankings for a specific group,
    you can do something like the following

       LET Y2 = RANK3 Y X1 X2
       LET ZY2 = Y2
       LET ZY  = Y
       RETAIN ZY2 ZY SUBSET X1 =2 SUBSET X2 = 3

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RANK         = Rank the elements of a variable.
    SORT         = Sort the elements of a variable.
    SORTC        = Sort the elements of a variable and carry one or
                   more variables along.
    COCODE       = Generate a cocoded variable.
    CODE         = Generate a coded variable.
    SEQUENCE     = Generate a sequence of numbers.
    PATTERN      = Generate numbers with a specific pattern.
 
Applications:
    Data Management
 
Implementation Date:
    2008/12
 
Program 1:
    skip 25
    read gear.dat y x
    .
    let y2 = rank2 y x
    .
    set write decimals 3
    print x y y2
 
Program 2:
    skip 25
    read ripken.dat y x1 x2 x3 x4
    .
    let y2 = rank3 y x1 x2
    .
    set write decimals 3
    print x1 x2 y y2
 
-----RANK INDEX (LET)---------------------------------------------
 
RANK INDEX
 
Name:
    RANK INDEX (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the ranks of a variable where each rank will be a unique
    integer value.
 
Description:
    When the RANK command encouters ties in the response variable,
    all tied values are given the same average rank.  For example,
    if ranks 5 and 6 denote the same value, then each would be
    assinged a rank of 5.5.

    The RANK INDEX command performs ranking.  However, it handles
    ties differently.  For example, if ranks 5 and 6 denote the same
    value, this command will return 5 and 6 as the ranks rather than
    5.5 for both.

    This command is useful when you want to use the rank as an index
    to another variable.  An example is given in the program example
    below.
 
Syntax:
    LET <y> = RANK INDEX <x>    <SUBSET/EXCEPT/FOR qualification>
    where <x> is the variable for which the ranks are to be computed;
          <y> is a variable where the computed ranks are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y = RANK INDEX X
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RANK (LET)      = Rank the elements in a variable.
    RANK2 (LET)     = Rank the elements in a variable where there is
                      grouping in the data.
    SORT (LET)      = Sort the elements in a variable.
    SORTC (LET)     = Sort the elements in a variable and carry one or
                      more variables along.
 
Applications:
    Nonparametric statistics
 
Implementation Date:
    2010/6
 
Program:
    skip 25
    read splett2.dat y x
    let string s1 = Tinius1
    let string s2 = Tinius2
    let string s3 = Satec
    let string s4 = Tokyo
    .
    let xsort iindx = sort by median y x
    set let cross tabulate collapse
    let y2 = cross tabulate median y x
    let x2 = rank index y2
    loop for k = 1 1 4
        let ival = x2(k)
        let string t^ival = ^s^k
    end of loop
    x1tic mark label case asis
    x1tic mark label format alpha
    x1tic mark label content ^t1 ^t2 ^t3 ^t4
    .
    char box plot
    line box plot
    fences on
    .
    xlimits 1 4
    major xtic mark number 4
    minor xtic mark number 0
    xtic offset 0.5 0.5
    .
    title case asis
    title offset 2
    title Charpy V-NIST Notch Testing
    label case asis
    x1label Machine Manufacturer
    y1label Absorbed Energy
    .
    box plot y xsort
 
-----RANK (LET)---------------------------------------------------
 
RANK
 
Name:
    RANK (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the ranks of a variable.
 
Syntax:
    LET <resp> = RANK <y1>  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the variable for which the ranks are to be computed;
          <resp> is a variable where the computed ranks are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RANK Y1
 
Note:
    Ties are assigned an average rank.  For example, if the 2nd and 3rd
    highest values are equal, each is assigned a rank of 2.5.
 
Note:
    Many nonparametric statistical methods are based on ranks.  The
    program sample shows the use of ranks in computing the
    Kruskal-Wallis test for one-way ANOVA.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SORT (LET)      = Sort the elements in a variable.
    SORTC (LET)     = Sort the elements in a variable and carry one or
                      more variables along.
 
Applications:
    Nonparametric statistics
 
Implementation Date:
    Pre-1987
 
Program:
    .  Perform a Kruskal-Wallis non-parametric 1-way ANOVA
    .  Data from "Probability and Statistics for Engineers and
    .  Scientists" by Walpole and Myers.
    LET P = 3
    LET X1 = DATA 24.0 16.7 22.8 19.8 18.9
    LET X2 = DATA 23.2 19.8 18.1 17.6 20.2 17.8
    LET X3 = DATA 18.4 19.1 17.3 17.3 19.7 18.9 18.8 19.3
    .
    LOOP FOR K = 1 1 P
       LET N^K = SIZE X^K
       LET TAG^K = K FOR I = 1 1 N^K
    END OF LOOP
    LOOP FOR L = 2 1 P
       LET TEMP = X^L
       EXTEND X1 TEMP
       LET TEMP = TAG^L
       EXTEND TAG1 TEMP
       DELETE TEMP
    END OF LOOP
    .
    LET N = SIZE X1
    LET R = RANK X1
    LET SUM1 = 0
    LOOP FOR K = 1 1 P
       LET R^K = SUM R SUBSET TAG1 = K
       LET SUM1 = SUM1 + (R^K)**2/N^K
    END OF LOOP
    .
    LET H = SUM1*(12/(N*(N+1))) - 3*(N+1)
    LET ALPHA = 0.95
    LET DF = P - 1
    LET CRITICAL = CHSPPF(ALPHA,DF)
    .
    CAPTURE KRUSKAL_WALLIS_OUT.DAT
    PRINT " "
    PRINT "H0: ^P INDEPENDENT SAMPLES ARE FROM IDENTICAL POPULATIONS"
    PRINT "HA: ^P INDEPENDENT SAMPLES ARE FROM DIFFERENT POPULATIONS"
    PRINT "KRUSKAL-WALLIS H STATISTIC = ^H"
    PRINT "CHI-SQUARE CRITICAL VALUE = ^CRITICAL"
    IF H <= CRITICAL
      PRINT "ACCEPT NULL HYPOTHESIS"
    END OF IF
    IF H > CRITICAL
      PRINT "REJECT NULL HYPOTHESIS"
    END OF IF
    END OF CAPTURE
 
-----RANK COMOVEMENT (LET)--------------------------------
 
RANK COMOVEMENT
 
Name:
    RANK COMOVEMENT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the rank Leigh-Perlman comovement coefficient for a
    variable.
 
Description:
    The comovement coefficient is the sum of cross products divided by
    N-1.  It is computed as:
          COMOVE = SUMXY/(SQRT(SUMX)*SQRT(SUMY))
    where
          SUMXY = SUM ((X(i)-X(i-1))*(Y(i)-Y(I-1)))
          SUMX  = SUM(X(i)-X(i-1))
          SUMY  = SUM(Y(i)-Y(i-1))
    and the summations are done from 2 to N.  The computed coefficient
    has a value between -1 and +1.
 
    The rank comovement coefficient is computed from the ranks of the
    data rather than the original data.  However, it uses the same
    computational formula given above.
 
Syntax:
    LET <par> = RANK COMOVEMENT <y1> <y2>
               <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed rank comovement is
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RANK COMOVEMENT Y1 Y2
    LET A = RANK COMOVEMENT Y1 Y2 SUBSET TAG > 2
 
Note:
    The two variables must have the same number of elements.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    COMOVEMENT       = Compute the comovement of two variables.
    CORRELATION      = Compute the correlation of a variable.
    RANK CORRELATION = Compute the rank correlation of a variable.
    COVARIANCE       = Compute the covariance between two variables.
    VARIANCE         = Compute the variance of a variable.
 
Reference:
    "An Index for Comovement of Time Sequences with Geophysical
    Applications: A Working Paper", Penn State Interface Conference on
    Astronomy, August, 1991.
 
Applications:
    XX
 
Implementation Date:
    91/8
 
Program:
    LET Y1 = EXPONENTIAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y2 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET A1 = RANK COMOVEMENT Y1 Y2
 
-----RANK CORRELATION (LET)--------------------------------
 
RANK CORRELATION
 
Name:
    RANK CORRELATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the Spearman rank correlation between two variables.
 
Description:
    If the measurements in the two samples are replaced with their ranks
    (and average ranks in the case of ties) and the Pearson correlation
    coefficient (HELP CORRELATION for details) is computed, the result is
    the Spearman rho correlation coefficient.

    The rank correlation is recommended in the following cases:
      1) When the underlying data does not have a meaningful numerical
         measure, but it can be ranked;
      2) When the relationship between the two variables is not
         linear;
      3) When the normality assumption for two variables is not
         valid.
 
Syntax:
    LET <par> = RANK CORRELATION <y1> <y2>
               <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed rank correlation is
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RANK CORRELATION Y1  Y2
    LET A = RANK CORRELATION Y1 Y2 SUBSET TAG > 2
 
Note:
    The two variables must have the same number of elements.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CORRELATION (LET)      = Compute the Pearson correlation
                             coefficient between two variables.
    AUTOCORRELATION (LET)  = Compute the autocorrelation of a variable.
    RANK COVARIANCE (LET)  = Compute the rank covariance between two
                             variables.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    Pre-1987
 
Program:
    LET Y1 = DATA 14 17 28 17 16 13 24 25 18 31
    LET Y2 = DATA 0.9 1.1 1.6 1.3 1.0 0.8 1.5 1.4 1.2 2.0
    LET A1 = RANK CORRELATION Y1 Y2
 
-----RANK CORRELATION INDEPENDENCE TEST--------------------------------------
 
RANK CORRELATION INDEPENDENCE TEST
 
Name:
    RANK CORRELATION INDEPENDENCE TEST
 
Type:
    Analysis Command
 
Purpose:
    Perform a Spearman rho rank correlation test for whether two samples
    are independent (i.e., not correlated).
 
Description:
    If the measurements in the two samples are replaced with their ranks
    (and average ranks in the case of ties) and the Pearson correlation
    coefficient (HELP CORRELATION for details) is computed, the result is
    the Spearman rho correlation coefficient.

    A value of +1 indicates perfect positive correlation, a value
    of -1 indicates perfect negative correlation, and a value of 0
    indicates no relation (i.e., independence).

    The rank correlation independence test is a test whether the 
    rank correlation coefficient is equal to zero.

    For larger n (e.g., n > 30) or the case where there are many ties,
    the p-th upper quantile of the rank correlation statistic can be
    approximated by

        w(p) = z(p)/SQRT(n-1)

    with z(p) and n denoting the p-th quantile of the standard
    normal distribution and the sample size, respectively.  The
    lower quantile is the negative of the upper quantile.

    For a two-sided test, the p-value is computed as twice the
    minimum of the lower tailed and upper tailed quantiles.

    For n <= 30, tabulated quantiles (from Table A10 on p. 542 of
    Conover) are used.  These quantiles are exact when there are
    no ties in the data.

Syntax 1:
    <LOWER TAILED/UPPER TAILED> RANK CORRELATION INDEPENDENCE TEST
                                <y1>  <y2>
                                <SUBSET/EXCEPT/FOR qualification>
    where <LOWER TAILED/UPPER TAILED> is an optional keyword that
               specifies either a lower tailed or an upper tailed
               test;
          <y1> is the first response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    If neither LOWER TAILED or UPPER TAILED is specified, a two-tailed
    test is performed.

    Lower tailed tests are used to test for negative correlation and
    upper tailed tests are used to test for positive correlation).

Syntax 2:
    <LOWER TAILED/UPPER TAILED> RANK CORRELATION INDEPENDENCE TEST
                                <y1>  ... <yk>
                                <SUBSET/EXCEPT/FOR qualification>
    where <LOWER TAILED/UPPER TAILED> is an optional keyword that
               specifies either a lower tailed or an upper tailed
               test;
          <y1> ... <yk> is a list of 1 to 30 response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax will perform all the pair-wise tests for the <y1> ...
    <yk> response variables.  For example,

         RANK CORRELATION INDEPENDENCE TEST Y1 TO Y4

    is equivalent to

         RANK CORRELATION INDEPENDENCE TEST Y1 Y2
         RANK CORRELATION INDEPENDENCE TEST Y1 Y3
         RANK CORRELATION INDEPENDENCE TEST Y1 Y4
         RANK CORRELATION INDEPENDENCE TEST Y2 Y3
         RANK CORRELATION INDEPENDENCE TEST Y2 Y4
         RANK CORRELATION INDEPENDENCE TEST Y3 Y4

Examples:
    RANK CORRELATION INDEPENDENCE TEST Y1 Y2
    RANK CORRELATION INDEPENDENCE TEST Y1 TO Y5
    LOWER TAILED RANK CORRELATION INDEPENDENCE TEST Y1 Y2
    UPPER TAILED RANK CORRELATION INDEPENDENCE TEST Y1 Y2
 
Note:
    This command can be used to test for trend in a univariate
    variable.  For example

       LET N = SIZE Y
       LET X = SEQUENCE 1 1 N
       RANK CORRELATION INDEPENDENCE TEST Y X

    According to Conover, this test is more powerful than the
    Cox and Stuart test.  However, it is not as widely applicable
    as the Cox and Stuart test.

    This test for trend is referred to as the Daniels test for trend.

Note:
    The KENDALL TAU INDEPENDENCE TEST can be used to perform
    a test for independence based on the Kendall tau statistic.

    The CORRELATION CONFIDENCE LIMITS command can be used to generate
    a confidence interval for the Pearson correlation coefficient.
    This can be used for a parametric test for independence (i.e.,
    does the confidence interval contain zero?).

Note:
    By default, critical values are based on tabulated values for
    n <= 30.  The command 

        SET RANK CORRELATION CRITICAL VALUES NORMAL APPROXIMATION

    can be used to specify that they should be based on the normal
    approximation given above.  This may be preferred if there are
    ties in the data.  To reset the default, enter the command

        SET RANK CORRELATION CRITICAL VALUES TABLE

Note:
    The RANK CORRELATION INDEPENDENCE TEST will accept matrix arguments.
    If a matrix is given, the data elements in the matrix will be collected
    in column order to form a vector before performing the test.
 
Note:
    Dataplot saves the following internal parameters after a
    rank correlation independence test:

        STATVAL   = the value of the test statistic
        STATCDF   = the CDF of the test statistic
        PVALUE    = the p-value for the two-sided test
        PVALUELT  = the p-value for the lower tailed test
        PVALUEUT  = the p-value for the upper tailed test
        CUTLOW90  = the 90% lower tailed critical value
        CUTUPP90  = the 90% upper tailed critical value
        CUTLOW95  = the 95% lower tailed critical value
        CUTUPP95  = the 95% upper tailed critical value
        CTLOW975  = the 97.5% lower tailed critical value
        CTUPP975  = the 97.5% upper tailed critical value
        CUTLOW99  = the 99% lower tailed critical value
        CUTUPP99  = the 99% upper tailed critical value
        CTLOW995  = the 99.5% lower tailed critical value
        CTUPP995  = the 99.5% upper tailed critical value
        CTLOW999  = the 99.9% lower tailed critical value
        CTUPP999  = the 99.9% upper tailed critical value

Note:
    The following statistics can also be computed

        LET A = RANK CORRELATION Y1 Y2
        LET A = RANK CORRELATION CDF Y1 Y2
        LET A = RANK CORRELATION PVALUE Y1 Y2
        LET A = RANK CORRELATION LOWER TAILED PVALUE Y1 Y2
        LET A = RANK CORRELATION UPPER TAILED PVALUE Y1 Y2

    The cdf and p-values are based on the normal approximation
    given above.

    To see a list of commands in which these statistics can be
    used, enter

        HELP STATISTICS

Note:
    The run sequence plot can be used to graphically assess
    whether or not there is trend in the data.  The 4-plot can
    be used to assess the more general assumption of
    "independent, identically distributed" data.

    The paired data can also be analyzed using other techniques for
    comparing two response variables (e.g., t-test, bihistogram,
    quantile-quantile plot).

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    KENDALL TAU INDEPENDENCE TEST  = Compute an independence test
                                     based on the Kendall tau statistic.
    CORRELATION CONFIDENCE LIMITS  = Generate confidence limits for the
                                     Pearson correlation coefficient.
    COX AND STUART TEST            = Compute a Cox and Stuart trend test.
    T-TEST                         = Compute a t-test.
    4-PLOT                         = Generate a 4-plot.
    RUN SEQUENCE PLOT              = Generate a run sequence plot.
    BIHISTOGRAM                    = Generates a bihistogram.
    QUANTILE-QUANTILE PLOT         = Generate a quantile-quantile plot.
 
Reference:
    Conover (1999), "Practical Nonparametric Statistics",
    Third Edition, Wiley, pp. 319-327.
 
Applications:
    Confirmatory Data Analysis
 
Implementation Date:
    2013/3
 
Program:
    skip 25
    read kendall.dat y1 y2
    set write decimals 5
    .
    let statval  = rank correlation y1 y2
    let statcdf  = rank correlation cdf y1 y2
    let pvalue   = rank correlation pvalue y1 y2
    let pvallt   = rank correlation lower tailed pvalue y1 y2
    let pvalut   = rank correlation upper tailed pvalue y1 y2
    print statval statcdf pvalue pvallt pvalut
    .
    rank correlation independence test y1 y2
    .
    upper tailed rank correlation independence test y1 y2
    .
    set rank correlation critical values normal approximation
    upper tailed rank correlation independence test y1 y2

-----RANK COVARIANCE (LET)--------------------------------
 
RANK COVARIANCE
 
Name:
    RANK COVARIANCE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the rank covariance between two variables.
 
Description:
    The covariance is computed as:
        cov(x,y) = sum(x-xmean)*sum(y-ymean)/(N-1)
    The rank covariance uses the above formula on the ranks of the
    data rather than the original data.
 
    The rank covariance is recommended in the following cases:
      1) When the underlying data does not have a meaningful numerical
         measure, but it can be ranked;
      2) When the relationship between the two variables is not linear;
      3) When the normality assumption for two variables is not valid.
 
Syntax:
    LET <par> = RANK COVARIANCE <y1> <y2>
               <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed rank covariance is
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RANK COVARIANCE Y1  Y2
    LET A = RANK COVARIANCE Y1 Y2 SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CORRELATION (LET)      = Compute the Pearson correlation
                             coefficient between two variables.
    AUTOCORRELATION (LET)  = Compute the autocorrelation of a variable.
    RANK CORRELATION (LET) = Compute the rank correlation between two
                             variables.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    XX
 
Program:
    LET Y1 = DATA 14 17 28 17 16 13 24 25 18 31
    LET Y2 = DATA 0.9 1.1 1.6 1.3 1.0 0.8 1.5 1.4 1.2 2.0
    LET A1 = RANK COVARIANCE Y1 Y2
 
-----RANK SUM TEST--------------------------------------
 
RANK SUM TEST
 
Name:
    RANK SUM TEST
 
Type:
    Analysis Command
 
Purpose:
    Perform a two sample rank sum test.
 
Description:
    The t-test is the standard test for testing that the
    difference between population means for two non-paired
    samples are equal.  If the populations are non-normal,
    particularly for small samples, then the t-test may not
    be valid.  The rank sum test is an alternative that can
    be applied when distributional assumptions are suspect.
    However, it is not as powerful as the t-test when the
    distributional assumptions are in fact valid.

    The rank sum test is also commonly called the Mann-Whitney
    rank sum test or simply the Mann-Whitney test.  Note that
    even though this test is commonly called the Mann-Whitney
    test, it was in fact developed by Wilcoxon.

    To form the rank sum test, rank the combined samples.
    Then compute the sum of the ranks for sample one, T1, and
    the sum of the ranks for sample two, T2.  If the sample
    sizes are equal, the rank sum test statistic is the minimum
    of T1 and T2.  If the sample sizes are unequal, then
    find T1 equal the sum of the ranks for the smaller sample.
    Then compute T2 = N1(N1 + N2 + 1) - T1.  T is the minimum
    of T1 and T2.  Sufficiently small values of T cause
    rejection of the null hypothesis that the sample means
    are equal.
    
    Significance levels have been tabulated for small values of
    N1 and N2.  For sufficiently large N1 and N2, the following
    normal approximation is used:

         Z = (ABS(u - T) - 0.5)/sigma

    where
         
         u = N1*(N1 + N2 + 1)/2
         sigma = SQRT(N2*u/6)

Syntax 1:
    RANK SUM TEST  <y1>  <y2>    <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs a two-sided test.

Syntax 2:
    LOWER TAILED RANK SUM TEST  <y1>  <y2>
                                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs a lower-tailed test.

Syntax 3:
    UPPER TAILED RANK SUM TEST  <y1>  <y2>
                                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs an upper-tailed test.

Examples:
    RANK SUM TEST Y1  Y2
    LOWER TAILED RANK SUM TEST Y1  Y2
    UPPER TAILED RANK SUM TEST Y1  Y2
    RANK SUM TEST Y1  Y2  SUBSET TAG > 2
 
Note:
    The May, 2011 implementation of Dataplot switched from the
    formulation of the test given in Walpole and Meyers to the
    formulation given in Conover.  The primary motivation for
    this is that Conover provides more extensive tables for
    small sample sizes.  Specifically, Conover provides tables
    for N1 <= 20 and N2 <= 20 (both sample sizes have to be
    <= 20).

    The Conover implementation is






Note:
    Dataplot saves the following internal parameters after a
    sign test:

        STATVAL   = The rank sum test statistic
        STATCDF   = CDF value for the test statistic
        PVALUE    = P-value for a two-sided test
        PVALUELT  = P-value for a lower-tailed test
        PVALUEUT  = P-value for a upper-tailed test
        CUTLO001  = 0.001 percent point for test statistic
        CUTLO005  = 0.005 percent point for test statistic
        CUTLO025  = 0.025 percent point for test statistic
        CUTLOW01  = 0.01  percent point for test statistic
        CUTLOW05  = 0.05  percent point for test statistic
        CUTLOW10  = 0.10  percent point for test statistic
        CUTUPP90  = 0.90  percent point for test statistic
        CUTUPP95  = 0.95  percent point for test statistic
        CUTUP975  = 0.975 percent point for test statistic
        CUTUPP99  = 0.99  percent point for test statistic
        CUTUP995  = 0.995 percent point for test statistic
        CUTUP999  = 0.999 percent point for test statistic

Note:
    The following statistics are also supported:

        LET A = MANN WHITNEY RANK SUM TEST                 Y1 Y2
        LET A = MANN WHITNEY RANK SUM TEST CDF             Y1 Y2
        LET A = MANN WHITNEY RANK SUM TEST PVALUE          Y1 Y2
        LET A = MANN WHITNEY RANK SUM LOWER TAILED PVALUE  Y1 Y2
        LET A = MANN WHITNEY RANK SUM UPPER TAILED PVALUE  Y1 Y2

    In addition to the above LET command, built-in statistics are
    supported for about 20+ different commands (enter HELP STATISTICS
    for details).

Default:
    None
 
Synonyms:
    The following are synonyms for RANK SUM TEST:

        MANN WHITNEY RANK SUM TEST
        MANN WHITNEY RANK SUM
        MANN WHITNEY TEST
        MANN WHITNEY
        RANK SUM
 
Related Commands:
    T-TEST                     = Compute a t-test.
    SIGN TEST                  = Compute a sign test.
    SIGNED RANK TEST           = Compute a signed rank test.
    CHI-SQUARED 2 SAMPLE TEST  = Compute a two sample chi-square
                                 test.
    BIHISTOGRAM                = Generates a bihistogram.
    QUANTILE-QUANTILE PLOT     = Generate a quantile-quantile plot.
    BOX PLOT                   = Generates a box plot.
 
Reference:
    Walpole and Meyers (19xx), "Engineering Statistics,",
    xxx, pp. xxx.

    Snedecor and Cochran (1989), "Statistical Methods", Eigth Edition,
    Iowa State University Press, pp. 142-144.
 
    Conover (1999), "Practical Nonparametric Statistics," Third
    Edition, Wiley, pp. 272-281.

Applications:
    Two sample tests
 
Implementation Date:
    1999/05
    2011/05: Switch from Walpole and Meyers formulation to Conover
             formulation (Conover has a more complete set of tables
             for small sample sizes)
    2023/06: Fixed a bug where the last column in the decision table
             for the lower and upper tailed versions of the test
             was not printing the hypothesis decision
 
Program 1:
    SKIP 25
    READ NATR323.DAT Y1 Y2
    RETAIN Y2 SUBSET Y2 > -90
    RANK SUM TEST Y1 Y2

Program 2:
    SKIP 25
    READ RANKSUM.DAT Y1 Y2
    RETAIN Y1 SUBSET Y1 > 0
    RANK SUM TEST Y1 Y2

-----RATIO OF <STAT> (LET)-----------------------------------
 
RATIO OF
 
Name:
    RATIO OF <STAT> (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the ratio of a user specified statistic for two response
    variables.
 
Description:
    When comparing the scale statistics of two response variables, it
    is common to compare the ratio of the statistics rather than the
    difference.  For example, given the variables Y1 and Y2, the command

        LET R = RATIO OF STANDARD DEVIATION Y1 Y2

    is equivalent to entering

        LET S1 = STANDARD DEVIATION Y1
        LET S2 = STANDARD DEVIATION Y2
        LET R  = S1/S2

    The advantage of using the RATIO OF command is that you can use
    the ratio statistic in commands such as the BOOTSTRAP PLOT and
    <STAT> PLOT.

    The statistic specified in the RATIO OF command must be one that
    is computed for a single response variable (e.g., the CORRELATION
    statistic is not supported by this command).  Although the RATIO OF
    command was motivated by scale statistics, it can be used for any
    supported statistic for a single response variable.

Syntax:
    LET <par> = RATIO OF  <stat>  <y>  <SUBSET/EXCEPT/FOR qualification>
    where <stat> is one of Dataplot's supported statistics for a single
              response variable;
          <y> is the response variable;
          <par> is a parameter where the computed ratio is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET A = RATIO OF STANDARD DEVIATIONS Y1 Y2
    LET A = RATIO OF STANDARD DEVIATIONS Y1 Y2  SUBSET Y2 > 0
    LET A = RATIO OF MEDIAN ABSOLUTE DEVIATIONS Y1 Y2
    LET A = RATIO OF RANGE Y1 Y2
    LET A = RATIO OF INTERQUARTILE RANGE Y1 Y2
 
Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    BOOTSTRAP PLOT       = Generate a bootstrap plot.
    RANGE                = Compute the range of a variable.
    STANDARD DEVIATION   = Compute the standard deviation of a variable.
    VARIANCE             = Compute the variance of a variable.
 
Applications:
    Statistics
 
Implementation Date:
    2023/08
 
Program:
    SKIP 25
    READ AUTO83B.DAT Y1 Y2
    RETAIN Y2 SUBSET Y2 >= 0
    .
    BOOTSTRAP RATIO OF MEDIAN ABSOLUTE DEVIATION PLOT Y1 Y2
 
-----RATIO (LET)-------------------------------------------
 
RATIO
 
Name:
    RATIO (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the ratio of the sum of two variables.
 
Description:
    This statistic computes

        SUM[i=1 to n][Y1(i)]/SUM[i=1 to n][Y2(i)]

    In the current implementation, Y1 and Y2 are assumed to
    have the same number of elements.

    In the typical use of this command, Y2 denotes the
    number of cases or number of trials while Y1 denotes
    the corresponding number of successes or failures (e.g.,
    the number of successes might be the number of false
    negatives or false positives).  This statistic then computes
    the success rate over all groups.

Syntax:
    LET <par> = RATIO <y1> <y2>  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed ratio is
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RATIO Y1 Y2
    LET A = RATIO Y1 Y2 SUBSET TAG > 2
 
Note:
    The following additional commands are supported

        TABULATE RATIO  Y1 Y2 X
        CROSS TABULATE RATIO Y1 Y2 X1 X2

        RATIO PLOT Y1 Y2 X
        RATIO CROSS TABULATE PLOT Y1 Y2 X1 X2

        BOOTSTRAP RATIO PLOT Y1 Y2
        JACKNIFE RATIO PLOT Y1 Y2

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    TABULATE            = Compute a statistic for data with a
                          single grouping variable.
    CROSS TABULATE      = Compute a statistic for data with
                          two grouping variables.
    STATISTIC PLOT      = Generate a plot of a statistic for data
                          with a single grouping variable.
    CROSS TABULATE PLOT = Generate a plot of a statistic for data
                          with two grouping variables.
    BOOTSTRAP PLOT      = Generate a bootstrap plot for a given
                          statistic.

Applications:
    Linear Regression

Implementation Date:
    12/2005
 
Program:
    LET Y1 = DATA 2 4 0 1 8 5 5 5 2 2
    LET Y2 = 10 FOR I = 1 1 10
    LET A = RATIO Y1 Y2
 
-----RATIO OF MEANS CONFIDENCE INTERVAL--------------------------
 
RATIO OF MEANS CONFIDENCE INTERVAL
 
Name:
    RATIO OF MEANS CONFIDENCE INTERVAL
 
Type:
    Analysis Command
 
Purpose:
    Generates a confidence interval for the ratio of two means
    for paired samples.
 
Description:
    There are cases where a measurement is actually the ratio of
    two different measurements.  That is,

         R(i) = Y(i)/X(i)

    It is often desired to generate the confidence interval for
    this ratio.  Note that computing a standard confidence interval
    for R does not generate satisfactory results.  This is due to
    the fact that, assuming Y and X are independent,

            E[Rhat] = E[Yhat/Xhat]
                    = E[Yhat]*E[1/Xhat]

    However, E[1/Xhat] is not equal to 1/E[Xhat].

    There have been a number of approaches to this problem.  This
    command supports three different methods.

    Fieller derived confidence intervals for the case where Y and X are
    distributed as bivariate normal.  Define the quantities

        Xbar                = mean of X
        Ybar                = mean of Y
        sigmahat**2(Xbar)   = variance of Xbar
                            = 1/(N*(N-1))*SUM[i=1 to N][(X(i)-Xbar)**2]
        sigmahat**2(Ybar)   = variance of Ybar
                            = 1/(N*(N-1))*SUM[i=1 to N][(Y(i)-Ybar)**2]
        sigmahat(Ybar,Xbar) = 1/(N*(N-1))*
                              SUM[i=1 to N][X(i) - Xbar)*(Y(i)-Ybar)]
        t(q)                = t percent point value with N - 1 degrees of
                              freedom

    The test statistic is

          Rhat = Ybar/Xbar

    For Fieller's confidence limits, we first compute

          Xbar**2/sigmahat(Xbar)**2

    If this quantity is less than or equal to t**2(q), then an unbounded
    interval results and Dataplot will not generate the confidence
    interval.  Basically, this results if the confidence interval for X
    contains zero.

    If this quantity is less than or equal to t**2(q), then the following
    confidence interval is obtained

       Lower Limit = {(Xbar*Ybar - t**2(q)*sigmahat(Xbar,Ybar)) -
                      SQRT[(Xbar*Ybar - t**2(q)*sigmahat(Xbar,Ybar))**2 -
                      (Xbar**2 - t**2(q)*sigmahat**2(Xbar)*
                      (Ybar**2 - t**2(q)*sigmahat**2(Ybar)]}/
                      (Xbar**2 - t**2(q)*sigmahat(Xbar))

       Upper Limit = {(Xbar*Ybar - t**2(q)*sigmahat(Xbar,Ybar)) +
                      SQRT[(Xbar*Ybar - t**2(q)*sigmahat(Xbar,Ybar))**2 -
                      (Xbar**2 - t**2(q)*sigmahat**2(Xbar)*
                      (Ybar**2 - t**2(q)*sigmahat**2(Ybar)]}/
                      (Xbar**2 - t**2(q)*sigmahat(Xbar))

    The large sample approximation method (this is called the Taylor or
    delta-method in the Franz paper) generates the following confidence
    interval

        Lower Limit = Rhat - t(alpha/2,n-1)*Rhat*
                      SQRT{C(Ybar,Ybar) + C(Xbar,Xbar) - 2*C(Ybar,Xbar)}

        Upper Limit = Rhat + t(alpha/2,n-1)*Rhat*
                      SQRT{C(Ybar,Ybar) + C(Xbar,Xbar) - 2*C(Ybar,Xbar)}

    where

        C(Ybar,Ybar) = (1/N)*s**2(Y)/Ybar**2
        C(Xbar,Xbar) = (1/N)*s**2(X)/Xbar**2
        C(Ybar,Xbar) = (1/N)*s(Y,X))/(Xbar*Ybar)

    with s(Y), s(X), and s(Y,X) denoting the standard deviation of X,
    the standard deviation of Y and the covariance between Y and X,
    respectively.

    The log ratio method generates the following confidence interval

        Lower Limit = Rhat*EXP{-t(alpha/2,n-1)*
                      SQRT{C(YBAR,YBAR) + C(XBAR,XBAR) - 2*C(YBAR,XBAR)}
        Upper Limit = Rhat*EXP{t(alpha/2,n-1)*
                      SQRT{C(YBAR,YBAR) + C(XBAR,XBAR) - 2*C(YBAR,XBAR)}

    The large sample approximation and the log ratio method do not
    generate unbounded intervals.  Also, the log ratio method can
    generate asymmetric intervals.

    Note that there is some disagreement in the literature about the
    appropriateness of these methods.  For example, Franz argues that
    the unbounded intervals are a result of the denominator being close
    to zero with the consequence that the ratio can assume arbitrarily
    large values.  Therefore any method that does not allow for unbounded
    intervals is not valid.  On the other hand, Sherman argues that the
    unbounded Fieler intervals are simply nonsensical and advocates the
    use of the large sample approximation and log ratio methods.

    To specify the method to use, enter the command

        SET RATIO OF MEANS METHOD <FIELER/LOG RATIO/LARGE SAMPLE>

Syntax:
    RATIO OF MEANS CONFIDENCE INTERVAL  <y1>  <y2>
                                        <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first (numerator) response variable;
          <y2> is the second (denominator) response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The variables <y1> and <y2> must be of the same length and are assumed
    to be paired.

Examples:
    RATIO OF MEANS CONFIDENCE INTERVAL Y X
    RATIO OF MEANS CONFIDENCE INTERVAL Y X  SUBSET TAG > 2
    RATIO OF MEANS CONFIDENCE INTERVAL Y1 Y2  SUBSET Y1 > 0
 
Note:
    A table of confidence intervals is printed for alpha levels of
    50.0, 75.0, 90.0, 95.0, 99.0, 99.9, 99.99, and 99.999.  The sample
    sizes, sample means, sample standard deviations, and the standard
    error are also printed.  The t-value and t-value X standard
    error are printed in the table.
 
Note:
    The RATIO OF MEANS CONFIDENCE LIMIT command automatically saves the
    following parameters:

       CUTLOW90   = the lower 90% confidence limit
       CUTUPP90   = the upper 90% confidence limit
       CUTLOW95   = the lower 95% confidence limit
       CUTUPP95   = the upper 95% confidence limit
       CUTLOW99   = the lower 99% confidence limit
       CUTUPP99   = the upper 99% confidence limit
       CTLOW999   = the lower 99.9% confidence limit
       CTUPP999   = the upper 99.9% confidence limit

Note:
    In addition to the RATIO OF MEANS CONFIDENCE LIMIT command, the
    following commands can also be used:

        LET A = RATIO OF MEANS Y X

        LET ALPHA = <value>
        LET A = RATIO OF MEANS LOWER CONFIDENCE LIMIT Y X
        LET A = RATIO OF MEANS UPPER CONFIDENCE LIMIT Y X

    These statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CONFIDENCE LIMITS                   = Generate a confidence interval
                                          for the mean.
    DIFFERENCE OF MEANS CONF LIMIT      = Generate a confidence interval
                                          for the difference of two means.
    T-TEST                              = Perform a two sample t-test.
    BIHISTOGRAM                         = Generate a bihistogram.
    QUANTILE-QUANTILE PLOT              = Generate a quantile-quantile
                                          plot.
    KOLMOGOROV-SMIRNOV TWO SAMPLE TEST  = Generate a Kolmogorov-
                                          Smirnov two sample test.
 
Reference:
    V. H. Franz ((2007), "Ratios: A Short Guide to Confidence Limits and
    Proper Use," arXiv:0710.2024 [stat.AP].

    E. C. Fieler (1940), "The Biological Standardization of Insulin,"
    Supplement to the Journal of the Royal Statistical Society, Vol. 7,
    No. 1, pp. 1-64.

    E. C. Fieler (1940), "A Fundamental Formula in the Statistics of
    Biological Assays and Some Applications", Quarterly Journal of
    Pharmacy and Pharmacology, Vol. 17, pp. 117-123.

    E. C. Fieler (1940), "Some Problems in Interval Estimation," Journal
    of the Royal Statistical Society (B), Vol. 16, No. 2, pp. 175-185.

    Sherman, Maity, and Wang (2011), "Inferences for the Ratio: Fieller's
    Interval, Log Ratio, and Large Sample Based Confidence Intervals",
    AStA Adv Stat Anal 95:313–323.

    Cochran (1977), "Sampling Techniques," Wiley, New York.

    Lohr (2009), "Sampling: Design and Analysis," Second Edition,
    Brooks/Cole, Pacific Grove.

Applications:
    Confirmatory Data Analysis
 
Implementation Date:
    2019/09
 
Program 1:
    . Step 1:   Define data (taken from Sherman article, original source
    .
    .           Lehtonen and Pahkinen (2004), "Practical Methods for
    .           Design and Analysis of Complex Surveys," 2nd Edition,
    .           New York: Wiley.
    .
    read y x
     4123   26881
      760    4896
      721    3730
      142     556
      187    1463
      331    1946
      127     834
      219     932
    end of data
    .
    . Step 2:   Large sample interval
    .
    let alpha = 0.95
    set write decimals 4
    set ratio of means method large sample
    let r1   = ratio of means y x
    let r1ll = ratio of means lower confidence limit y x
    let r1ul = ratio of means upper confidence limit y x
    .
    ratio of means confidence limit y x
    pause
    .
    set ratio of means method log ratio
    let r2   = ratio of means y x
    let r2ll = ratio of means lower confidence limit y x
    let r2ul = ratio of means upper confidence limit y x
    .
    ratio of means confidence limit y x
    pause
    .
    set ratio of means method fieler
    let r3   = ratio of means y x
    let r3ll = ratio of means lower confidence limit y x
    let r3ul = ratio of means upper confidence limit y x
    .
    ratio of means confidence limit y x
 
Program 2:
    . Step 1:   Define data
    .
    read y x
      0.1268825E+10  0.1246669E+10
      0.1295448E+10  0.1246669E+10
      0.1295448E+10  0.1268825E+10
      0.1168487E+08  0.1014325E+08
      0.1141398E+08  0.1014325E+08
      0.1168487E+08  0.1141398E+08
      0.3298360E+06  0.2902920E+06
      0.3298360E+06  0.1718490E+06
      0.2902920E+06  0.1718490E+06
      0.2415666E+07  0.1637297E+07
      0.2415666E+07  0.1347629E+07
      0.1637297E+07  0.1347629E+07
      0.9904356E+08  0.9530938E+08
      0.1049126E+09  0.9530938E+08
      0.1049126E+09  0.9904356E+08
      0.4930919E+08  0.4662120E+08
      0.4934958E+08  0.4662120E+08
      0.4934958E+08  0.4930919E+08
      0.1278483E+08  0.1232513E+08
      0.1286868E+08  0.1232513E+08
      0.1286868E+08  0.1278483E+08
      0.7029193E+07  0.4878485E+07
      0.7029193E+07  0.3244763E+07
      0.4878485E+07  0.3244763E+07
      0.1490000E+07  0.1040000E+07
      0.1860000E+07  0.1040000E+07
      0.1860000E+07  0.1490000E+07
      0.2680523E+07  0.2601516E+07
      0.2724237E+07  0.2601516E+07
      0.2724237E+07  0.2680523E+07
      0.8905137E+07  0.8303097E+07
      0.8905137E+07  0.8271071E+07
      0.8303097E+07  0.8271071E+07
      0.6956520E+06  0.6798450E+06
      0.6921780E+06  0.6798450E+06
      0.6956520E+06  0.6921780E+06
      0.3290000E+09  0.2890000E+09
      0.3300000E+09  0.2890000E+09
      0.3300000E+09  0.3290000E+09
      0.7091179E+05  0.6553055E+05
      0.7443393E+05  0.6553055E+05
      0.7443393E+05  0.7091179E+05
      0.8031739E+08  0.5416613E+08
      0.8031739E+08  0.4975062E+08
      0.5416613E+08  0.4975062E+08
      0.6830980E+07  0.6738330E+07
      0.6973430E+07  0.6738330E+07
      0.6973430E+07  0.6830980E+07
      0.2010000E+07  0.1980000E+07
      0.2600000E+07  0.2010000E+07
      0.2600000E+07  0.1980000E+07
      0.3193846E+08  0.3059341E+08
      0.3222820E+08  0.3059341E+08
      0.3222820E+08  0.3193846E+08
      0.1784258E+08  0.1460987E+08
      0.1784258E+08  0.1099276E+08
      0.1460987E+08  0.1099276E+08
      0.3150562E+09  0.3052555E+09
      0.3150562E+09  0.2994084E+09
      0.3052555E+09  0.2994084E+09
      0.7998000E+08  0.7574000E+08
      0.8017000E+08  0.7574000E+08
      0.8017000E+08  0.7998000E+08
      0.3983000E+08  0.3886000E+08
      0.4086000E+08  0.3886000E+08
      0.4086000E+08  0.3983000E+08
      0.2334030E+07  0.1387010E+07
      0.2544590E+07  0.2334030E+07
      0.2544590E+07  0.1387010E+07
      0.3126721E+09  0.2310785E+09
      0.2490103E+09  0.2310785E+09
      0.3126721E+09  0.2490103E+09
      0.1000900E+03  0.9977000E+02
      0.1255000E+03  0.9977000E+02
      0.1255000E+03  0.1000900E+03
      0.9860323E+04  0.9400626E+04
      0.9882525E+04  0.9400626E+04
      0.9882525E+04  0.9860323E+04
      0.2548997E+04  0.2482806E+04
      0.2640000E+08  0.2510000E+08
      0.2680000E+08  0.2510000E+08
      0.2680000E+08  0.2640000E+08
    end of data
    .
    set write decimals 4
    .
    . Step 2:   Large sample interval
    .
    set ratio of means method large sample
    ratio of means confidence limit y x
    .
    . Step 3:   Log Ratio interval
    .
    set ratio of means method log ratio
    ratio of means confidence limit y x
    .
    . Step 4:   Fieler interval
    .
    set ratio of means method fieler
    ratio of means confidence limit y x

-----RATIO OF STANDARD DEVIATIONS CONFIDENCE LIMITS----------------------
 
RATIO OF STANDARD DEVIATIONS CONFIDENCE LIMITS
RATIO OF VARIANCES CONFIDENCE LIMITS
 
Name:
    RATIO OF STANDARD DEVIATIONS CONFIDENCE LIMITS
    RATIO OF VARIANCES CONFIDENCE LIMITS
 
Type:
    Analysis Command
 
Purpose:
    Generates a confidence interval for the ratio of two standard
    deviations (or variances).
 
Description:
    This is the confidence interval for the ratio of the standard
    deviations (or variances) for two unpaired samples.  If the
    confidence interval for the ratio, this implies that the
    standard deviations (or variances) are equal.

    The confidence interval or the ratio of the variances is:

       ((s1**2/s2**2)/F(alpha/2,n2,n1), (s1**2/s2**2)*F(alpha/2,n2-1,n1-1))

    where s1**2 and S2**2 are the sample variances, n1 and n2 are the
    sample sizes and F is the percent point function of the F
    distribution.  The confidence intervals are given for several values
    of alpha.  This interval is not necessarily symmetric about the
    ratio s1**2/s2**2.

    To obtain the confidence interval for the ratio of standard
    deviations, take the square root of the lower and upper confidence
    limits for the ratio of the variances.


    This confidence interval assumes that both distributions have normal
    distributions.  It is also known that this interval is quite senstive
    to departures from normality.  There have been several proposals in
    the literature to make this test more robust.  This is discussed
    further in the "Note:" section below.

Syntax 1:
    RATIO OF STANDARD DEVIATIONS CONFIDENCE LIMITS  <y1>  <y2>
                                 <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Syntax 2:
    RATIO OF VARIANCES CONFIDENCE LIMITS  <y1>  <y2>
                                  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    RATIO OF STANDARD DEVIATIONS CONFIDENCE LIMITS Y1  Y2
    RATIO OF SD CONFIDENCE LIMITS Y1  Y2
    RATIO OF VARIANCE CONFIDENCE LIMITS Y1  Y2
    RATIO OF SD CONFIDENCE LIMITS Y1  Y2   SUBSET Y2 > 0

Note:
    This ratio is known to be quite sensitive to departures from
    normality.

    Shoemaker (2003) proposed the following adjustment to the degrees
    of freedom to make the F test more robust against non-normality.
 
    The degrees of freedom are

        r(i) = 2*n(i)/[(mu4/sigma**4) - (n(i)-3)/(n(i)-1)]

    where

        mu4 = SUM[i=1 to 2][SUM[j=1 to n(i)]
                 [[(Y(ij) - YBAR(i))**4]]/(n1+n2)

        sigma**2 = {(n1-1)*s1**2 + (n2-1)**s2**2}/(n1+n2)

    with Y(.j), n(i), s(i) and YBAR(i) denoting the data, the sample size,
    the standard deviation and the mean, respectively, of the i-th
    variable.

    This typically results in fractional degrees of freedom.  The
    Dataplot FCDF, FPDF and FPPF routines were updated to support
    fractional degrees of freedom (fractional degrees of freedom less
    than 1 are set to 1).

    The justification and derivation of this modification is given in
    Shoemaker's paper.  Simulations by Shoemaker indicated that the
    standard F test tends to be too conservative for light tailed
    distributions and too liberal for heavy tailed and skewed
    distributions.  Using the Shoemaker modifications for degrees of
    freedom generally had good coverage properties with the exception
    of heavily skewed distributions with small samples where it was
    still too liberal.

    Bonett (2006) suggested that rounding the numerator degrees of
    freedom up to the nearest integer degrees of freedom and rounding
    the denominator degrees of freedom down to the nearest integer
    degrees of freedom (but not less than 1) prevented some anomalous
    behavior while reducing coverage performance only slightly.

    Bonett proposed the following interval:

        EXP[LN(c*s1**2/s2**2) +/- NORPPF(alpha/2)*se]

    where

        ak4     = (n1+N2)*SUM[i=1,2]SUM[j=1,n(i)][(Y(ij) - m(i)]/
                  {SUM[i=1,2]SUM[j=1,n(i)][(Y(ij) - ybar(i)**2)]}**2

        m(i)    = sample trimmed mean of the i-th variable with trimming
                  proportion 1/SQRT(2*(n(i) - 4))
        ybar(i) = sample mean of the i-th variable

        se      = SQRT{(ak4-k1)/(n1-1) + (ak4-k2)/(n2-1)}
        k1      = (n1-3)/n1
        k2      = (n2-3)/n2

        c       = {n1*(1-NORPPF(alpha/2)}/{n2*(n2-NORPPF(alpha/2))}
        NORPPF  = the percent point function of the normal distribution

    The parameter c is a small sample adjustment to help equalize the
    tail probabilities.  It equals 1 when n1 and n2 equal and
    approaches 1 as n1 and n2 get large.

    The above formula is for the variance.  For the standard
    deviation, take the square root.

    This interval is based on a standard normal distribution rather
    than an F distribution.

    The justification and derivation of this test is given in the
    Bonett paper.  Based on his simulations, he claims this method
    improves somewhat on the Shoemaker modification for heavy-tailed
    (particularly skewed) distributions.

    To specify Shoemaker's modification with fractional degrees
    of freedom, enter

         SET F TEST DEGREES OF FREEDOM SHOEMAKER

    To specify Shoemaker's modification with integral degrees
    of freedom as suggested by Bonett, enter

         SET F TEST DEGREES OF FREEDOM SHOEMAKER ROUNDED

    To specify Bonett's method, enter

         SET F TEST DEGREES OF FREEDOM BONETT

Note:
    Shoemaker suggests that when more than two groups of data are
    available, it can improve accuracy to use all of the groups
    in the estimates of the pooled location (mu4) and pooled variance
    (sigma**2) instead of just the two groups being tested.  That is,

        mu4 = SUM[i=1 to k][SUM[j=1 to n(i)]
                 [[(Y(ij) - YBAR(i))**4]]/(n1+n2+ ... + nk)

        sigma**2 = {(n1-1)*s1**2 + (n2-1)**s2**2 + ... + (nk-1)*sk**2}/
                   (n1+n2+ ... +nk)

    To use these values, enter the commands

         SET SHOEMAKER F TEST POOLED MU       <value>
         SET SHOEMAKER F TEST POOLED VARIANCE <value>

    To reset the default of Dataplot computing these from the two groups
    being tested, enter

         SET SHOEMAKER F TEST POOLED MU
         SET SHOEMAKER F TEST POOLED VARIANCE 0

Note:
    The following parameters are saved after the F test is
    performed.

         CUTUPP90  - upper 90% confidence limit
         CUTUPP95  - upper 95% confidence limit
         CUTUPP99  - upper 99% confidence limit
         CUTUP999  - upper 99.5% confidence limit
         CUTLOW90  - lower 90% confidence limit
         CUTLOW95  - lower 95% confidence limit
         CUTLOW99  - lower 99% confidence limit
         CUTLW999  - lower 99.5% confidence limit

Note:
    In addition to the RATIO OF STANDARD DEVIATION CONFIDENCE LIMITS
    command, the following commands can also be used:

       LET LCL = RATIO OF SD LOWER CONFIDENCE LIMTIS Y1 Y2
       LET UCL = RATIO OF SD UPPER CONFIDENCE LIMTIS Y1 Y2
       LET LCL = RATIO OF VARIANCE LOWER CONFIDENCE LIMTIS Y1 Y2
       LET UCL = RATIO OF VARIANCE UPPER CONFIDENCE LIMTIS Y1 Y2

    In addition to the above LET commands, built-in statistics are
    supported for 30+ different commands (enter HELP STATISTICS for
    details).

Note:
    The F TEST can be used to generate the corresponding hypothesis
    test.
 
Default:
    None
 
Synonyms:
    SD is a synonym for STANDARD DEVIATION
    CONFIDENCE INTERVAL is a synonym for CONFIDENCE LIMIT
 
Related Commands:
    F TEST                = Perform a normal-based test that two standard
                            deviations are equal.
    SIEGEL TUKEY TEST     = Perform a ranks based test that two standard
                            deviations are equal.
    BARTLETTS TEST        = Perform a k-sample Bartlett test for
                            homogeneous variances.
    LEVENE TEST           = Perform a k-sample Levene test for
                            homogeneous variances.
    SQUARED RANKS TEST    = Perform a k-sample squared ranks test for
                            homogeneous variances.
    KLOTZ TEST            = Perform a k-sample Klotz test for homogeneous
                            variances.
    SD CONFIDENCE LIMITS  = Compute the confidence limits for the
                            standard deviation.
    CHI-SQUARE TEST       = Performs a one sample chi-square test that the
                            standard deviation is equal to a given value.
    T TEST                = Performs a two-sample t test for equal means.
    CONFIDENCE LIMITS     = Compute the confidence limits for the mean of
                            a sample.
    STANDARD DEVIATION    = Computes the standard deviation of a variable.
 
Reference:
    F-based intervals for the ratio of two standard deviations are
    discussed in most introductory statistics books.

    Shoemaker (2003), "Fixing the F-Test for Equal Variances," The American
    Statistician, Vol. 57, pp. 105-114.

    Bonett (2006), "Robust Confidence Intervals for a Ratio of Standard
    Deviations," Applied Pyschological Measurement, Vol. 30, No. 5,
    pp. 432-439.

Applications:
    Confirmatory Data Analysis
 
Implementation Date:
    2023/06
 
Program 1:
    SKIP 25
    READ AUTO83B.DAT Y1 Y2
    DELETE Y2 SUBSET Y2 < 0
    .
    RATIO OF SD CONFIDENCE LIMITS Y1 Y2
     
Program 2:
    . Step 1:   Read the data
    .
    skip 25
    read shoemake.dat bottom mid surface
    let y x = stack bottom mid surface
    let temp1 = cross tabulate mean y x
    let temp2 = (y - temp1)**4
    let num = sum temp2
    let den = size y
    let mu4 = num/den
    let y1var = variance bottom
    let y2var = variance mid
    let y3var = variance surface
    let n1 = size bottom
    let n2 = size mid
    let n3 = size surface
    let num   = (n1 - 1)*y1var + (n2 -1)*y2var + (n3 - 1)*y3var
    let poolvar = num/den
    .
    . Step 2:   Generate a box plot
    .
    character box plot
    line box plot
    xlimits 1 3
    major xtic mark number 3
    minor xtic mark number 0
    xtic mark offset 0.5 0.5
    x1tic mark label format alpha
    x1tic mark label content Bottom Middepth Surface
    tic mark label case asis
    set box plot fences on
    box plot y x
    .
    . Step 3:   Default confidence interval
    .
    set f test degrees of freedom default
    print "Standard F interval"
    ratio of sd confidence limits bottom mid
    let lcl = ratio of sd lower confidence limit bottom mid
    let ucl = ratio of sd upper confidence limit bottom mid
    print lcl ucl
    .
    . Step 4:   Shoemaker F-test
    .
    set f test degrees of freedom shoemaker
    print "Shoemaker degrees of freedom interval"
    ratio of sd confidence limits bottom mid
    print "Use pooled location and variance for Shoemaker"
    set shoemaker f test pooled variance poolvar
    set shoemaker f test pooled mu       mu4
    ratio of sd confidence limits bottom mid
    print "Shoemaker rounded degrees of freedom F Test"
    set f test degrees of freedom shoemaker rounded
    ratio of sd confidence limits bottom mid
    set shoemaker f test pooled variance 0
    set shoemaker f test pooled mu
    .
    . Step 5:   Bonett
    .
    set f test degrees of freedom bonett
    print "Bonett method"
    ratio of sd confidence limits bottom mid

-----RAYCDF (LET)--------------------------------
 
RAYCDF
 
Name:
    RAYCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Rayleigh cumulative distribution function.
 
Description:
    The Rayleigh distribution is a special case of the
    chi distribution with degrees of freedom parameter = 2 and
    scale parameter sigma.  It is also a special case of the
    Weibull distribution with shape parameter = 2 and scale
    parameter = SQRT(2).  Note that some sources may define the
    Rayleigh distribution as a Weibull with shape parameter = 2
    and scale parameter = 1.

    The Rayleigh distribution has the following cumulative
    disribution function:

       F(x,mu,sigma)=1 - EXP(-(1/2)**(x-mu)/sigma)**2)
                    x > mu, sigma > 0
 
    with mu and sigma denoting the location and scale parameters,
    respectively.

    The standard Rayleigh distribution is the case with
    mu = 0 and sigma = 1.

Syntax:
    LET <y> = RAYCDF(<x>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <scale> is an optional positive number or parameter that
              specifies the value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Rayleigh cdf value
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y = RAYCDF(3)
    LET Y = RAYCDF(X1,0,SIGMA)
    PLOT RAYCDF(X,0,SIGMA) FOR X = 0.01  0.01  5
       
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RAYPDF = Compute the Rayleigh probability density function.
    RAYPPF = Compute the Rayleigh percent point function.
    MAXPDF = Compute the Maxwell probability density function.
    CHPDF  = Compute the chi probability density function.
    WEIPDF = Compute the Weibull probability density function.
    NORPDF = Compute the normal probability density function.
    LGNPDF = Compute the lognormal probability density function.
 
Reference:
    "Continuous Univariate Distributions: Volume I", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, pp. 453, 686.

Applications:
    Distributional Modeling, Statistical Physics
 
Implementation Date:
    6/2004
 
Program:
    Y1LABEL Probability
    X1LABEL X
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE Rayleigh Cumulative Disribution
    PLOT RAYCDF(X) FOR X = 0  0.01  5
 
-----RAYPDF (LET)--------------------------------
 
RAYPDF
 
Name:
    RAYPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Rayleigh probability density function.
 
Description:
    The Rayleigh distribution is a special case of the
    chi distribution with degrees of freedom parameter = 2 and
    scale parameter sigma.  It is also a special case of the
    Weibull distribution with shape parameter = 2 and scale
    parameter = SQRT(2).  Note that some sources may define the
    Rayleigh distribution as a Weibull with shape parameter = 2
    and scale parameter = 1.

    The Rayleigh distribution has the following probability
    density function:

       f(x,mu,sigma)=((x-mu)/sigma**2)*EXP(-(1/2)*(x-mu)**2/(sigma**2))
                    x > mu, sigma > 0
 
    with mu and sigma denoting the location and scale parameters,
    respectively.

    The standard Rayleigh distribution is the case with
    mu = 0 and sigma = 1.

Syntax:
    LET <y> = RAYPDF(<x>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <scale> is an optional positive number or parameter that
              specifies the value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Rayleigh pdf value
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y = RAYPDF(3)
    LET Y = RAYPDF(X1,0,SIGMA)
    PLOT RAYPDF(X,0,SIGMA) FOR X = 0.01  0.01  5
 
Note:
    To generate Rayleigh random numbers, enter the command

        LET Y = RAYLEIGH RANDOM NUMBERS FOR I = 1 1 N

    To generate a Rayleigh probability plot or a Rayleigh
    Kolmogorov-Smirnov or chi-square goodness of fit test,
    enter the following commands

        RAYLEIGH PROBABILITY PLOT Y
        RAYLEIGH KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
        RAYLEIGH CHI-SQUARE GOODNESS OF FIT Y
       
    The location and scale parameters for the Rayleigh distribution
    can be estimated by generating the Rayleigh probability
    plot (the intercept and slope of the line fit to the probability
    plot, PPA0 and PPA1, are estimates of location and scale).

    Alternatively, you can estimate the location and scale
    parameters using maximum likelihood:

        RAYLEIGH MAXIMUM LIKELIHOOD Y

    The maximum likelihood estimate of the scale parameter is:

     sigmahat = SQRT(SUM[i=1 to n][X(i)**2]/(2*n))

    with X containing the data and n denoting the sample size.
    By default, Dataplot will use the sample minimum as the
    estimate of location (and subtract this value from X before
    computing the maximum likelihood estimate of sigma).  If you
    want to specify a different estimate of location, enter the
    command

         LET RAYLOC = <value>

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RAYCDF = Compute the Rayleigh cumulative distribution function.
    RAYPPF = Compute the Rayleigh percent point function.
    MAXPDF = Compute the Maxwell cumulative distribution function.
    CHPDF  = Compute the chi probability density function.
    WEIPDF = Compute the Weibull probability density function.
    NORPDF = Compute the normal probability density function.
    LGNPDF = Compute the lognormal probability density function.
 
Reference:
    "Continuous Univariate Distributions: Volume I", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, pp. 453, 686.

Applications:
    Distributional Modeling, Statistical Physics
 
Implementation Date:
    6/2004
 
Program:
    Y1LABEL Probability
    X1LABEL X
    TITLE Rayleigh Probability Density
    LABEL CASE ASIS
    TITLE CASE ASIS
    PLOT RAYPDF(X) FOR X = 0  0.01  5
 
-----RAYPPF (LET)--------------------------------
 
RAYPPF
 
Name:
    RAYPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Rayleigh percent point function.
 
Description:
    The Rayleigh distribution is a special case of the
    chi distribution with degrees of freedom parameter = 2 and
    scale parameter sigma.  It is also a special case of the
    Weibull distribution with shape parameter = 2 and scale
    parameter = SQRT(2).  Note that some sources may define the
    Rayleigh distribution as a Weibull with shape parameter = 2
    and scale parameter = 1.

    The Rayleigh distribution has the following percent point
    function:

       G(x,mu,sigma) = mu + sigma*SQRT(2*LOG(1/(1-P)))
                    0 <= p < 1; sigma > 0
 
    with mu and sigma denoting the location and scale parameters,
    respectively.

    The standard Rayleigh distribution is the case with
    mu = 0 and sigma = 1.

Syntax:
    LET <y> = RAYPPF(<p>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable,number, or a parameter in the interval
              [0,1);
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <scale> is an optional positive number or parameter that
              specifies the value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed Rayleigh ppf value
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y = RAYPPF(0.95)
    LET Y = RAYPPF(P1,0,SIGMA)
    PLOT RAYPPF(P,0,SIGMA) FOR P = 0  0.01  0.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RAYCDF = Compute the Rayleigh cumulative distribution function.
    RAYPDF = Compute the Rayleigh probability density function.
    MAXPDF = Compute the Maxwell cumulative distribution function.
    CHPDF  = Compute the chi probability density function.
    WEIPDF = Compute the Weibull probability density function.
    NORPDF = Compute the normal probability density function.
    LGNPDF = Compute the lognormal probability density function.
 
Reference:
    "Continuous Univariate Distributions: Volume I", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, pp. 453, 686.

Applications:
    Distributional Modeling
 
Implementation Date:
    6/2004
 
Program:
    X1LABEL Probability
    Y1LABEL X
    TITLE Rayleigh Percent Point
    LABEL CASE ASIS
    TITLE CASE ASIS
    PLOT RAYPPF(P) FOR P = 0  0.01  0.99

-----RC (LET)----------------------------------------------
 
RC
 
Name:
    RC (LET)
 
Type:
    Library Function
 
Purpose:
    Compute Carlson's degenrate elliptic integral.
 
Description:
    Carlson's degenerate elliptic integral is defined as:
        RC(x,y)=0.5*INTEGRAL[1/SQRT((t+x)*(t+y)**2)]dt
    where INTEGRAL is the integral from 0 to infinity.  The parameters
    x and y must all be non-negative.

Syntax:
    LET <a> = RC(<x>,<y>,<z>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, parameter, or variable;
          <y> is a non-negative number, parameter, or variable;
          <a> is a variable or a parameter (depending on what <x>,
               <y>, and <z> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RC(2,1)
    LET A = RC(X,4)
    LET X2 = RC(1,Y)
 
Note:
    The Carlson elliptic integrals are computed using the RC, RD, RF,
    and RJ routines from the SLATEC Common Mathematical Library.
    SLATEC is a large set of high quality, portable, public domain
    Fortran routines for various mathematical capabilities maintained
    by seven federal laboratories.

Note:
    DATAPLOT computes Legendre elliptic integrals by computing the
    equivalent Carlson elliptic integrals.  See the documentation for
    the ELLIP1, ELLIP2, ELLIP3, ELLIPC1, and ELLIPC2 functions for
    details on computing Legendre elliptic functions in DATAPLOT.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RF      = Compute the Carlson elliptic integral of the first kind.
    RD      = Compute the Carlson elliptic integral of the second kind.
    RJ      = Compute the Carlson elliptic integral of the third kind.
    ELLIPC1 = Compute the Legendre complete elliptic integral of the
              first kind.
    ELLIPC2 = Compute the Legendre complete elliptic integral of the
              second kind.
    ELLIP1  = Compute the Legendre elliptic integral of the first
              kind.
    ELLIP2  = Compute the Legendre elliptic integral of the second
              kind.
    ELLIP3  = Compute the Legendre's elliptic integral of the third
              kind.
 
Reference:
    "Algorithms for Incomplete Elliptic Integrals by Duplication", 
    Carlson, ACM Transactions on Mathematical Software, 7,
    pp. 398-403.

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 17).

Applications:
    Special Functions
 
Implementation Date:
    94/9
 
Program:
    TITLE CARLSON ELLIPTIC FUNCTIONS
    PLOT RC(X,1) FOR X = 0.1 0.1 10 AND
    PLOT RC(1,X) FOR X = 0.1 0.1 10
 
-----RD (LET)----------------------------------------------
 
RD
 
Name:
    RD (LET)
 
Type:
    Library Function
 
Purpose:
    Compute Carlson's elliptic integral of the second kind.
 
Description:
    Carlson's elliptic integral of the second kind is defined as:
        RD(x,y,z,p)=1.5*INTEGRAL[1/SQRT((t+x)*(t+y)*(t+z)**3)]dt
    where INTEGRAL is the integral from 0 to infinity.  The parameters
    x, y, and z must all be non-negative with at most one of them
    being zero.  The p parameter must be non-zero.

Syntax:
    LET <a> = RD(<x>,<y>,<z>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, parameter, or variable;
          <y> is a non-negative number, parameter, or variable;
          <z> is a non-negative number, parameter, or variable;
          <a> is a variable or a parameter (depending on what, <p>,
               <x>, <y>, and <z> are) where the computed values are
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RD(2,1,3)
    LET A = RD(X,0,4)
    LET X2 = RD(1,1,Y)
 
Note:
    The Carlson elliptic integrals are computed using the RC, RD, RF,
    and RJ routines from the SLATEC Common Mathematical Library.
    SLATEC is a large set of high quality, portable, public domain
    Fortran routines for various mathematical capabilities maintained
    by seven federal laboratories.

Note:
    DATAPLOT computes Legendre elliptic integrals by computing the
    equivalent Carlson elliptic integrals.  See the documentation for
    the ELLIP1, ELLIP2, ELLIP3, ELLIPC1, and ELLIPC2 functions for
    details on computing Legendre elliptic functions in DATAPLOT.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RF      = Compute the Carlson elliptic integral of the first kind.
    RJ      = Compute the Carlson elliptic integral of the third kind.
    RC      = Compute the degenerate Carlson elliptic integral.
    ELLIPC1 = Compute the Legendre complete elliptic integral of the
              first kind.
    ELLIPC2 = Compute the Legendre complete elliptic integral of the
              second kind.
    ELLIP1  = Compute the Legendre elliptic integral of the first
              kind.
    ELLIP2  = Compute the Legendre elliptic integral of the second
              kind.
    ELLIP3  = Compute the Legendre's elliptic integral of the third
              kind.
 
Reference:
    "Algorithms for Incomplete Elliptic Integrals by Duplication", 
    Carlson, ACM Transactions on Mathematical Software, 7,
    pp. 398-403.

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 17).

Applications:
    Special Functions
 
Implementation Date:
    94/9
 
Program:
    TITLE CARLSON ELLIPTIC FUNCTIONS
    PLOT RD(X,1,2) FOR X = 0.1 0.1 10 AND
    PLOT RD(1,X,2) FOR X = 0.1 0.1 10 AND
    PLOT RD(1,2,X) FOR X = 0.1 0.1 10
 
-----READ-------------------------------------------------------
 
READ
 
Name:
    READ
 
Type:
    Support Command
 
Purpose:
    Reads data into variables
       1) from an ASCII mass storage file;
       2) from within a CALLed DATAPLOT sub-program;
       3) from the terminal.
 
Description:
    The READ command is primarily intended for reading from the terminal
    or from ASCII files.  Dataplot has limited support for binary data
    files (see the Note sections below with regards to reading Fortran
    unformatted files and image data).

    Also, Dataplot does not currently support directly reading files
    from other statistical/spreadsheet programs or database files.
    Some support may be provided in future releases, but for now
    you need to save the data from these programs in an ASCII file
    in order to read them into Dataplot.  XML based data files are
    becoming increasingly popular as well.  At this time, Dataplot does
    not support XML based data files.

    IDEAL CASE

    By default, Dataplot assumes rectangular data files containing
    numeric data where the data columns are separated by one or
    more spaces.  Commas or tabs may be used as delimiters as well.

    In this case, you can read the file with a command like the
    following:

        READ  FILE.DAT  Y X1 X2

    The first argument after the READ is the name of the ASCII file.
    The remaining arguments identify the variable names.  Variable
    names can be up to eight characters long and should be limited
    to alphabetic (A-Z) and numeric (0-9) characters.  Although
    other characters can in fact be used, this is discouraged
    since their use can cause problems in some contexts.  Variable
    names are not case sensitive (Dataplot converts all alphabetic
    characters to upper case).

    Dataplot recognizes the first argument as a file name if it
    finds a "." in the name.  If no "." is found, Dataplot assumes
    the first argument is a variable name and it tries to read
    from the keyboard rather than the file.

    For this ideal case, the following are the basic rules.

       1) If there are k variables listed on the READ statement, then
          each line image must have at least k data values.  Only the
          first k data values are read (this is how the READ command
          differs from the SERIAL READ command), and these are read
          into successive elements of the individual variables.  Thus

             READ X Y
             1 1 1
             2 4 8
             3 9 27
             END OF DATA

          results in X containing the 3 elements 1, 2, and 3; Y
          containing the 3 elements 1, 4, and 9; and the values 1, 8,
          and 27 not being read at all.

       2) In scanning for the k variables, the full line image is
          scanned.  By default, the full line image is 255 characters.

          The COLUMN LIMITS can be used to restrict the read to certain
          columns.  The case where the data line is longer than 255
          characters is discussed below.

       3) Data values on a line image must be separated by at least one
          blank or comma.  Non-printing characters, such as tabs, are
          treated as spaces.

       4) Data values may be free-format.  That is, they need not be
          aligned in specific columns.  If your data file is aligned
          in specific columns, you may be able to significantly speed
          up the read by specifying a format for the data.  This is
          discussed below.

       5) The format of individual data values is general.  It can be
          integer, floating point, or exponential.  It is stored
          internally as a single precision real number.

          Support for character data is discussed below.

       6) All reads start from the beginning of the file.  The SKIP and
          ROW LIMITS can be used to skip header lines are to restrict
          which row of the file are read.

       7) The analyst need not be concerned about the number of
          observations for each variable;  DATAPLOT automatically
          determines and reports this value at the end of the read.

       8) The read terminates when a line image is encountered which
          consists of

             END OF DATA
          or

             END DATA

          or when the end of the file is reached.

    Many ASCII files will not be in the "ideal" format.  The remainder of
    this section discusses various issues that may cause problems when
    reading ASCII files and provides suggestions on how to deal with these
    issues.  The following topics are discussed:

       1) Viewing ASCII files within Dataplot
       2) Header lines/restricted rows or columns
       3) Long data records
       4) Automatic variable names
       5) Reading fixed columns
       6) Reading variables with unequal lengths
       7) Reading character data
       8) Reading row oriented data
       9) Comment lines in data files
      10) Reading Excel (or other spreadsheet) files
      11) Cut and Paste
      12) Comma as decimal point
      13) Missing values and undefined numbers
      14) Reading date and time fields
      15) Reading IP addresses
      16) Reading monetary data (e.g., $23,461.58)
      17) Reading numeric values with trailing "+" or "-" or "*" or "%"
      18) Commas within character fields
      19) Reading binary data
      20) Reading image data
      21) What if all of the data will not fit into memory?

    If you create the ASCII file yourself, it is recommended that
    you create it with variables of equal length (pick some numeric
    value to signify missing data) and with data items separated by one
    or more spaces.  Inclusion of a header giving a description of
    the data file is optional, but we find it helpful (Dataplot
    can skip over the header lines).  When the ASCII files are created
    by another program (e.g., Excel), then you may have less control
    over the format of the file.  Hopefully, most ASCII files you
    encounter can be handled using the commands discussed below.


    VIEWING THE ASCII FILE WITHIN DATAPLOT

    In order to identify some of the issues discussed below, it is
    often helpful to view the ASCII file before trying to read it into
    Dataplot.  You can do this with the command

        LIST FILE.DAT

    This will list the file 20 lines (you can change the number
    of lines with the SET LIST LINES command) at a time.  You
    can then enter a carriage return to view the next 20 lines or
    a "no" to stop viewing the file.

    For some of the commands given below, you need to either know
    approriate line numbers or column numbers.

    To view the file with line numbers, enter the command

       NLIST  FILE.DAT

    To identify appropriate columns, enter the command

       RULER

    This will identify the first 80 columns.


    HEADER LINES/RESTRICTED ROWS OR COLUMNS

    Many data files contain header lines at the beginning of the
    file that provide a description of the file.  In order to
    skip over these lines, enter the command

        SKIP N

    where N identifies how many lines to skip.

    Most of the sample data files that are distributed with Dataplot
    contain a line starting with hyphens ("---").  You can use the
    command 

        SKIP AUTOMATIC

    for these files.  Dataplot will skip all lines until a line
    starting with three or more hypens is encoutered.

    In a related issue, if you want to restrict the read to certain
    rows in the file, you can enter the command

        ROW LIMITS  N1  N2

    with N1 and N2 denoting the first and last rows to read,
    respectively. 

    You can also restrict the read to certain columns of the file
    using the command

        COLUMN LIMITS  C1  C2

    with C1 denoting the first column to read and C2 the last column
    to read.


    LONG DATA RECORDS

    When reading from the keyboard, Dataplot restricts a single record
    to a maximum of 255 columns.
    
    When reading from a file, Dataplot previously restricted a single
    record to a maximum of 132 columns.  The March, 2003 version raised
    the default limit to 255 characters.  In addition, the following
    command was added:

       MAXIMUM RECORD LENGTH  N

    with N denoting the size of the largest record to be read.

    Dataplot accepts values of N up to 9999.  However, be aware
    that some Fortran compilers may impose their own limit.  These
    limits tend not to be well documented, but with modern compilers
    they tend to be sufficiently large that this should not be a
    problem in practice.

    Note that if you specify a MAXIMUM RECORD LENGTH command, you
    should also specify the COLUMN LIMITS command.  For example,

        MAXIMUM RECORD LENGTH 512
        COLUMN LIMITS 1 512

    If you specify a SET READ FORMAT command (discussed below), you
    do not need to specify the maximum record length.


    AUTOMATIC VARIABLE NAMES

    Dataplot normally reads variable names on the READ command.
    However, many ASCII files will have the name of the variables
    given directly in the file or Dataplot can assign the variable
    names automatically.

    Specific methods include the following.

      1. Many of the sample files provided in the Dataplot 
         installation use a syntax like
    
             Y     X1   X2
            ----------------
               <data values>
    
         For these files, you can enter the commands
    
             SKIP AUTOMATIC
             SET VARIABLE NAMES FILE
             READ FILE.DAT
    
         In this case, Dataplot will skip all lines until a line
         starting with three or more hypens is encountered.  It
         will then backspace to the previous line and read the
         variable names from that line.

         Alternatively, you can specify the number of lines to skip with
         the command

             SKIP N

         where N specifies the number of lines in the header.  If the
         SET VARIABLE NAME FILE command has been given, Dataplot will look
         at the last line of the header (i.e., line N).  If it starts with
         three or more hyphens, then Dataplot assumes that the variable
         names are on line N-1.  If line N does not start with hyphens,
         then Dataplot assumes that the variable names are on line N.

      2. Many non-Dataplot ASCII data files will have the variable names on
         the first line of the file.  For these files, you can enter the
         commands

            SET VARIABLE LABELS ON
            READ FILE.DAT

         Dataplot then assumes line one of the file contains the variable
         names and the data start with line two.

         This is equivalent to using

             SKIP 1
             SET VARIABLE NAMES FILE
             READ FILE.DAT

      3. If you would like Dataplot to simply assign the variable
         names, enter the commands
    
             SET VARIABLE NAMES AUTOMATIC
             READ FILE.DAT
    
         Dataplot will read the first line of the file to determine
         the number of variables.  It will then assign the names
         COL1, COL2, and so on to the variable names.  Prior to
         2014/10, Dataplot used default names of X1, X2, and so on.
         You can specify what to use for the base of the variable
         names by entering the command

              SET AUTOMATIC VARIABLE BASE NAME <value>

         The use of SET VARIABLE NAMES AUTOMATIC applies to either the
         SKIP AUTOMATIC or the SKIP N cases.

    Note that Dataplot's usual rules for variable names still apply.
    That is, a maximum of eight characters will be used and spaces (commas
    can also be used as the delimiter and non-printing characters such as
    tabs will be treated as spaces) will delimit variable names.  The use
    of special (i.e., not a number and not an alphabetic character)
    characters is discouraged.  You may need to edit the file if the
    variable names do not follow these rules (more than eight characters will
    simply be ignored, so the issue is more one of duplicate variable names
    in the first eight characters).

    The SET VARIABLE NAMES <AUTOMATIC/FILE> command was implemented 2014/10.
    Prior to that, the SKIP AUTOMATIC worked equivalently to the
    SET VARIABLE NAMES FILE and the SKIP N worked equivalently to the
    SET VARIABLE NAMES AUTOMATIC.  The default is AUTOMATIC.
    
    Note 2020/08: The following tweaks were made to the reading of
    variable names.

      1. Previously, only the first 255 characters of the line were read.
         This has been extended to support the number of characters
         specified by the MAXIMUM RECORD LENGTH command (if this command is
         not given, the default remains 255).

      2. Dataplot will now automatically strip spaces and other special
         characters out of the variable names.  Specifically, only
         alphabetic characters (A-Z), numbers (0-9), and underscores are
         retained.

      3. Dataplot only supports eight characters for variable names.  This
         can lead to duplicate file names.  To reduce the possibility of
         duplicate names, Dataplot does the following if a duplicate name
         is found.

           a. If the name has less than eight characters, a "Z" is
              appended to the end of one of the names.  The right most
              name will be modified.

           b. If the name has eight characters exactly, the right most
              name will change the last character to a Z (or if that
              character is already a Z, then to a X).

           c. If blank names are encountered, these will be changed to
              Zxxx where "xxx" is a sequence number (i.e., if there are
              three blank names encountered, they wiil be set to Z1, Z2,
              and Z3).


    READING FIXED COLUMNS
    
    By default, Dataplot performs free format reads.  That is,
    you do not need to line up the columns neatly.  You do need
    to provide one or more spaces (tabs, commas, colons, semi-colons,
    parenthesis, or brackets can be used as well) between data fields.
    
    Many data files will contain fixed fields.  There are several reasons
    you may want or need to take advantage of these fixed fields rather
    than using a free format read.
    
       1. If your data fields do not contain spaces (or some other
          delimiter) between data columns, you need to tell
          Dataplot how to interpret the columns.
    
       2. In some cases, you may only want to read selected
          variables in the data file.
    
       3. Using a formatted read can significantly speed up the reading
          of the data.  If you have small or moderate size data files (say
          500 rows or fewer), this is really not an issue.  However, if you
          are reading 50,000 rows, you can significantly speed up the read
          by specifying the format.
    
       4. If the data fields have unequal lengths, Dataplot will not
          interpret the data file correctly with a free format read.
          It assigns the data items in the order they are encountered
          to the variable names in the order they are given.  Dataplot
          does not try to guess if a data item is missing based on the
          columns.
    
          The issue of unequal lengths is discussed in detail in the
          next section.
    
    There are two basic cases for fixed fields.
    
       1. The data fields are justified by the decimal point.
    
          In this case, you can use the 
    
              SET READ FORMAT  <format>
    
          command to specify a Fortran-like format to read the file.
          Enter HELP READ FORMAT for details.
    
          Using a formatted read is significantly faster than a
          free format read.
    
       2. Many programs will write ASCII files with fixed columns,
          but the data fields will be either left or right justified
          rather than lined up by the decimal point.
    
          In this case, you can use a special form of the
          COLUMN LIMITS command that was introduced with the
          January, 2004 version.  Normally, the first and last columns
          to read are specified.  However, you can now enter variables for
          the lower and upper limits as in the following example:
    
             LET LOWER = DATA  1  21   41
             LET UPPER = DATA 10  30   50
             COLUMN LIMITS LOWER UPPER
    
          That is, if variables rather than parameters are specified,
          separate column limits are specified for each data field.
          In this case, the first data field is between columns
          1 and 10, the second field is between columns 21 and 30, and
          the third field is between 41 and 50.
    
          When this syntax is used, only one variable is read for
          each specified field.  If the field is blank, then this is
          interpreted as a missing value.
    
    
    READING VARIABLES OF UNEQUAL LENGTH
    
    Dataplot normally expects all variables to be of equal length.
    If some variables have missing rows, this can have undesired
    results.  Dataplot will assign the first value read to the
    first variable name, the second value to second variable and
    so on.  If fewer values than variables are specified, then variables
    that have no data values are not read at all (even if they have
    values for other rows).
    
    If you have a data file where the columns have unequal lengths,
    you can do one of the following things.
    
       1. Pick some value to represent a missing value and fill
          in missing data points with that value.  After reading
          the data, you can use a RETAIN command to remove them.
          For example, if you use -99 to signify a missing value,
          you can enter
    
              RETAIN Y SUBSET Y > -99
    
          Alternatively, you can use a SUBSET clause on subsequent
          plot and analysis commands.
    
       2. Use the variable form of the COLUMN LIMITS command as
          described above.  By default, when a blank field is
          encountered, it is set to zero.  You can specify the
          value to use by entering the command
    
            SET READ MISSING VALUE  <value>
    
          This option depends on having consistent columns for
          each of the data fields.
    
       3. If your data has both columns of unequal length and
          inconsistent columns for given data fields, an alternative
          is to use a comma delimited data file.  That is, separate
          data values with a comma.  If there is no data data between
          successive commas, this is treated as a missing value.  The
          default is to assign a value of zero.  Alternatively, you
          can use the SET READ MISSING VALUE command described above.
    
          You can specify a delimiter other than a comma with the
          command
    
              SET READ DELIMITER <character>
    
          The variable form of the COLUMN LIMITS, the
          SET READ MISSING VALUE, and the SET READ DELIMITER commands
          were introduced in the January, 2004 version.  The
          interpretation of successive commas as a missing value was
          also introduced in the January, 2004 version.
    
    
    READING DATA WITH CHARACTER FIELDS
    
    Dataplot has not previously supported character data.  The one
    execption is that you could read row labels with the READ ROW LABEL
    command (enter HELP READ ROW LABEL for details).  If encountered,
    Dataplot would generate an error message and not read the data file
    correctly. 
    
    With the January 2004 version, we have introduced some limited
    support for character data.  Specifically, we have added the command
    
         SET CONVERT CHARACTER <ON/CATEGORICAL/IGNORE/ERROR>
    
    Setting this to ERROR will continue the current Dataplot action of
    reporting character data as an error.  This is recommended for the
    case when a file is suppossed to contain only numeric data and the
    presence of character data is in fact indicative of an error in the
    data file.
    
    Setting this to IGNORE will instruct Dataplot to simply ignore any
    fields containing character data.  This can be useful if you simply
    want to extract the numeric data fields in the file without
    entering COLUMN LIMITS or SET READ FORMAT commands.
    
    Setting this to ON will read character fields and write them to the
    file "dpzchf.dat".  Note that Dataplot saves numeric data
    "in memory" for fast access.  Since character data has limited
    use in Dataplot, we have decided to save character data 
    externally to minimize memory requirements.  Dataplot keeps a
    separate name table for the character data fields (the names for
    character variables are stored in the file "dpzchf.dat").
    
    Setting this to CATEGORICAL is similar to ON.  However, CATEGORICAL
    will additionally create a coded numeric variable in addtion to
    the character variable.  The numeric variable is useful for computing
    purposes while the character variable is used for labeling purposes.

    There are some restrictions on when Dataplot will try to
    read character data:
    
       1) This only applies to the variable read case.  That
          is, READ PARAMETER and READ MATRIX will ignore
          character fields or treat them as an error.
    
       2) Dataplot will only try to read character data from
          a file.  When reading from the keyboard (i.e., when
          READ is specified with no file name), character data
          will be ignored when a SET CONVERT CHARACTER ON is
          specified.

          Note: The 2020/01 version of Dataplot has removed this
                restriction.  You can now read character data from
                the terminal.
    
       3) This capability is not supported for the SERIAL READ
          case.
    
       4) The SET READ FORMAT command does not accept the
          "A" format specification for reading character
          fields.
    
       5) A maximum of 20 character variables will be saved.
    
       6) A maximum of 24 characters for each character variable
          will be saved.
    
       7) The character variables from at most one data file
          will be saved in a given session.
    
    Some of these restrictions may be addressed in subsequent
    releases of Dataplot.
    
    Currently, Dataplot has limited support for character variables.
    Specifically,
    
       1) The row label can be used for the plot character by
          entering the command
    
            CHARACTER ROWLABEL
    
       2) You can convert a character variable to a coded numeric
          variable with the command
    
            LET Y = CHARACTER CODE IX
            LET Y = ALPHABETIC CHARACTER CODE IX
    
          with IX denoting the name of the character variable.  These
          command assigns a numeric value for each unique name in
          the character variable.
    
          For the CHARACTER CODE case, the coding is from 1 to K where
          K is the number of unique values.  The order is based on
          the order these values are found in the file.
    
          For the ALPHABETIC CHARACTER CODE case, the coding is from
          1 to K where K is the number of unique values.  The order is
          performed in alpabetical order.
    
    We anticipate additional use of character variables in subsequent
    releases of Dataplot.
    
    If your character fields contain non-numeric/non-alphabetic characters,
    then it is recommended that the character fields be enclosed in
    quotes.  When Dataplot encounters a quote (either a single or double
    quote), it interprets everything until a matching quote is found
    as part of that character field.  If the quotes are not used,
    then spaces, tabs, parenthesis, brackets, colons, and semi-colons
    are interpreted as delimiters that signify the end of that data item.
    
    
    READING ROW ORIENTED DATA
    
    Dataplot assumes a column oriented format.  That is, a row of
    data represents a single record (or case) and a column of data 
    represents a variable.  If a data file has a row orientation, then
    this is reversed.  A row of data represents a variable and a column
    of data represents a record (or case).
    
    The following example shows one way of correctly reading the data
    into Dataplot.  Suppose that your data file contains five rows with
    each row corresponding to a single variable.  You can do the following:
    
       LOOP FOR K = 1 1 5
          ROW LIMITS K K
          SERIAL READ FILE.DAT  X^K
       END OF LOOP

    Note: The 2018/10 version of Dataplot added a "READ ROW" command that
          will read each row into a separate Dataplot variable.
    
    
    COMMENT LINES IN DATA FILES
    
    It is sometimes convenient to include comments in data files.
    If these comments are contained at the beginning of the file, then
    the SKIP command can be used.  To have Dataplot check for comment
    lines in the data file, enter the command
    
        COMMENT CHECK ON
    
    The default comment character is a ".".  That is, any line starting
    with a ". " is treted as a comment line and ignored.  To specify
    a different comment character, enter the command
    
        COMMENT CHARACTER  <char>
    
    with <char> denoting the desired comment character.
    
    
    EXCEL FILES
    
    At the current time (1/2004), Dataplot does not support the
    direct reading of Excel data files.  We are planning to add
    this capability in a future release of Dataplot.  Until that
    time, you need to save the data in Excel to an ASCII file and
    read that ASCII file into Dataplot.
     
    Excel provides the following options for writing ASCII data
    files:
    
      1. Formatted text (space delimited) (.PRN extension)
    
         This format will use consistent columns for the data fields.
         The variable form of the COLUMN LIMITS command can be used
         when the data columns have unequal length.
    
         Character fields will often not have the separating space.  The
         variable form of the COLUMN LIMITS command can be used in this
         case as well.
    
      2. CSV (Comma delimited) (.CSV extension)
    
         This format will separate data fields with a single comma.
         Missing data is represented with successive commas.  Dataplot
         can now (as of the January 2004 version) handle this correctly.
    
      3. Text (Tab delimited) (.TXT extension)
         Text (MS-DOS) (.TXT extension)
    
         These files will separate data fields with a tab character.
         Note that Dataplot converts all non-printing characters
         (including tabs) to a single space character.
    
         This format is not appropriate for data containing variables
         with unequal lengths since it will not generate consistent
         columns for the data fields.  Use either the space delimited
         or comma delimited file for that case.

      Other spreadsheets will typically have similar options.  However, the
      details may vary depending on the specific spreadsheet program.

      Note that directly exporting the Excel data to an ASCII file tends
      to work well when the data sheet is "clean".  That, is you basically
      have a single rectangular set of data cells.  If your spreadsheet
      contains graphs or multiple rectangular areas of data, then the
      generated ASCII file will tend to be difficult to work with.  In
      this case, it is recommended that you either copy the relevant data
      to a clean sheet or paste it into an ASCII editor and save the file
      from there.

      The next section discusses cut and paste within Dataplot.  In many
      cases, this may provide the simplest way to retrieve data from a
      spreadsheet.

      Note: The 2020/02 version of Dataplot added the READ EXCEL command
            to read Excel files using a Python script.  Enter
            HELP READ EXCEL for details.

    CUT AND PASTE

    In some contexts, it may be desirable to simply cut and paste relevant
    data into Dataplot.  For example, this can provide an alternative way
    to import data from spreadsheets and other statistical software.

    How well cut and paste works is dependent on the operating system and
    the compiler used to build Dataplot.  If you do this, we recommend
    limiting it to the case of numeric data.

    Some specific cases are

        1. Linux systems with the gfortran compiler

           As an example, suppose that the system clipboard contains three
           columns of data.  You can then do something like

               READ  Y X1 X2
                   <paste the contents of the clipboard>
               END OF DATA

           That is, you do a terminal read, paste your data, and then
           enter an END OF DATA command to terminate the READ.

        2. Windows systems with the Intel compiler

           For earlier versions of the compiler, the operations described
           for Linux/gfortran worked for this environment as well.  However,
           for the version of the compiler currently being used, this is
           no longer working.  Some testing has shown that it works for one
           or two lines, but Dataplot crashes for more than that.  We are
           investigating this to see if we can get it working again.

           Note: The 2014/12 version of Dataplot added numerous commands
                 for reading from (and writing to) the clipboard.  The
                 initial implementation is for the Windows environments,
                 although this should be extended to Linux and Mac OS X
                 platforms in subsequent releases.  Enter HELP CLIPBOARD
                 for details.  In many cases, using the READ CLIPBOARD
                 capability may be the easiest method for reading
                 spreadsheet data into Dataplot.

        3. Tcl/Tk GUI

           The spreadsheet in the Dataplot Tcl/Tk GUI does not accept
           paste operations in the data spreadsheet.

    COMMA AS DECIMAL POINT

    Dataplot follows the United States convention where the decimal
    point is the period ".".  Some locales may use a different
    character to denote the decimal point.  In particular, some
    countries use the comma ",".

    To allow Dataplot to read files that use a character other than
    the "." for the decimal point, enter the command

         SET DECIMAL POINT <value>

    where <value> denotes the character that specifies the decimal point.

    Note this support is fairly limited.  Specifically, it applies
    to free-format reads (i.e., no SET READ FORMAT command has been
    entered).  In addition,

       1. This option is not supported for the WRITE command.  WRITE
          will always use a period for the decimal point.

       2. Dataplot alphanumeric output (e.g., the output from the FIT
          command) is generated with the period as the decimal point.

       3. As mentioned above, if you read your data with a 
          SET READ FORMAT command, the data must use the period
          for the decimal point.

    MISSING VALUES AND UNDEFINED NUMBERS

    Some software programs will have special characters to denote
    missing values or undefined values (e.g., the result of trying
    to divide by 0).

    In particular, Unix/Linux software often uses "nan" to denote an
    undefined number.  If Dataplot encounters an "nan" in a numeric
    field, it will convert it to the Dataplot "missing value".  The "nan"
    search is not case sensitive (i.e., it will check for "NAN", "NaN",
    etc.).  You can specify what Dataplot will use for the missing value
    by entering the command

        SET READ MISSING VALUE  <value>

    where <value> is a numeric value.

    Missing value flags are specific to individual programs.  You can
    specify a character string that denotes a missing value with the
    command

        SET DATA MISSING VALUE <value>

    where <value> is a string with 1 to 4 characters.  If Dataplot
    encounters <value> in a numeric field, it will convert it to the
    Dataplot "missing value".  The missing value string is not case
    sensitive.  You can specify what Dataplot will use for the missing
    value by entering the command

        SET READ MISSING VALUE  <value>

    where <value> is a numeric value.

    The above discussion was for missing numeric data.  If you have
    missing data for a character field, you can specify the string
    that will denoted missing data by entering the command

        SET READ CHARACTER MISSING VALUE <string>

    The default string is ZZZZNULL.

    READING DATE AND TIME FIELDS

    Date and time fields will typically have syntax like

       2016/06/22
       12:43:08

    Dataplot treats the "/" and ":" as indicating character fields
    (based on the SET CHARACTER CONVERT command, this will either cause
    an error, result in this field being ignored, or the field being
    read as a character variable).

    The following commands were added (2016/06) to help deal with date and
    time fields.

       SET DATE DELIMITER <character>
       SET TIME DELIMITER <character>

    Although Dataplot does not have explicit date or time variables,
    these commands allow the components of date and time fields to
    be read as separate numeric variables.  For example,

       SET DATE DELIMITER /
       SET TIME DELIMITER :
       READ YEAR MONTH DAY HOUR MIN SEC
       2016/06/22  23:19:03
       END OF DATA

    READING IP ADDRESSES

    IP addresses typically have a syntax like

       129.6.37.209

    By default, Dataplot will generate an error when trying to read a
    field of this type.  To address this, you can enter the command

       SET READ IP ADDRESSES ON

    If this switch is ON, Dataplot will scan the line and if a field is
    encountered that conains more than one period ".", Dataplot will
    convert these periods to spaces before parsing the line.

    The default is OFF since this adds additional processing time to
    the READ and most data sets do not contain IP addresses.

    READING MONETARY DATA

    Monetary data may sometimes be given as

       $11,456.12  $1,021,111.10

    The "$" and "," in these numeric fields will cause problems.  The
    "$" will be treated as a non-numeric value (depending on other
    SET commands, this will be treated as an error or the numeric field
    will be read as a character field).  The comma is typically treated
    as a field delimiter.  If you have this kind of data, enter the
    commands

        set read dollar sign ignore on
        set read comma ignore on

    To reset the defaults, enter

        set read dollar sign ignore off
        set read comma ignore off

    Note that if you enter the SET READ COMMA IGNORE ON command, the
    comma will no longer be treated as the delimiter.  Dataplot cannot
    currently handle the case where the comma is used both for monetary
    data and also as a field delimiter.

    READING NUMERIC VALUES WITH TRAILING "+" OR "-" OR "*" OR "%"

    On occassion, numeric fields may have a trailing "+", a trailing
    "-", a trailing "*" or a trailing "%".

    The "+" is typically used to indicate that the value is greater
    than or equal to the entered value.  Likewise, the "-" is used to
    indicate that the value is less than or equal to the entered value.
    This may be used when data is truncated at a high or low value.  If
    you have data that uses this convention, enter

        set read trailing plus minus ignore on

    Dataplot does not have any convention for indicating that a number
    in fact means "greater than" or "less than", so it will read the
    numeric value and simply ignore the "+" or "-".

    To reset the defualt, enter

        set read trailing plus minus ignore off

    Trailing asterisks ("*") are sometimes used to indicate statistical
    significance.  To ignore these asterisks, enter

        set read asterisk ignore on

    If this command is not given, the field will be treated as a
    character field.  To reset the default, enter

        set read asterisk ignore off

    Percentage data will sometimes include a trailing percent sign
    ("%").  To ignore the percent sign, enter

        set read percent sign ignore on

    If this command is not given, the field will be treated as a
    character field.  To reset the default, enter

        set read percent sign ignore off

    COMMAS WITHIN CHARACTER FIELDS

    If you are reading data that may contain character fields, you can
    specify whether you want commas in the character fields to be
    treated as part of the character field or as a delimiter.

    To have the comma treated as a delimiter, enter

        set character field comma delimiter on

    To have the comma not be interpreted as a delimiter (i.e., it
    will simply be another character in the character field), enter
 
        set character field comma delimiter off

    The default is OFF.

    READING BINARY DATA

    Currently, the only types of binary data that Dataplot currently
    supports are:

      1) A few types of image files can be read on some platforms.
         This is discussed in the next section.

      2) Dataplot may be able to read some files created using Fortran
         unformatted data files.  Dataplot is most likely to have success
         reading unformatted Fortran files that contain only numeric data
         and use a consistent record structure.  Unformatted Fortran
         files that contain a mixture of character and numeric data
         will not be read successfully.

    Support for other types of binary files may be added in future
    releases.  However, this support will probably be for specific
    types of binary files as oppossed to arbitrary binary files.

    The advantage of using unformatted Fortran files is that file sizes
    may be significantly smaller and reading the data can be significantly
    faster.  One potential use of unformatted Fortran files is to save
    a large data file that you will read many times in Dataplot.

    The disadvantages of using unformatted Fortran files are that they
    are not human readable, they cannot be edited or modified using an
    ASCII editor, and, most importantly, they are not portable between
    operating systems and compilers.  That is, unformatted Fortran files
    typically need to be read using the same operating system and compiler
    that was used to create them.

    For details on using unformatted Fortran files, enter

         HELP SET READ FORMAT

    READING IMAGE DATA

    If Dataplot was built with support for the GD library, Dataplot
    can read image data in PNG, JPEG, or GIF format.  If you have
    image data in another format, you may be able to use an image
    conversion program (e.g., NetPBM or ImageMagick) to convert it
    to one of the supported formats.

    For further information, enter

        HELP READ IMAGE

    WHAT IF ALL THE DATA WILL NOT FIT INTO MEMORY?

    Dataplot was designed primarily for interactive usage.  For this reason,
    it reads all data into memory.  The current default is to have a
    workspace that accomodates 10 columns with 1,500,000 rows (you can
    re-dimension to obtain more columns at the expense of fewer rows, however
    you cannot increase the maximum number of rows).

    With the advent of "big data", there are more data files that cannot be
    read into Dataplot's available memory.  For these data files, there are
    several things that can potentially be done

       1. For some platforms, if you have a large amount of memory you may
          be able to build a version of Dataplot that raises the maximum
          number of rows.  For example, on a Linux system with 64MB of RAM,
          we were able to build a version that supports a maximum of
          10,000,000 rows.  Contact Alan Heckert if you need assistance
          with this.

       2. The STREAM READ command was added.  This command uses one pass
          algorithms to do a number of things.
    
          a. You can create a new file that uses SET WRITE FORMAT.  This
             is typically done once so that you can use SET READ FORMAT on
             subsequent reading of the data file (this can substantially
             speed up processing of these large files).
    
          b. You can generate various summary statistics either for the full
             data set or for groups in the data.
    
          c. You can generate cross tabulation statistics (up to 4
             cross tabulation variables may be specified).
    
          d. You can create various types of distance (e.g., Euclidean
             distances, correlation distances) matrices either for the full
             data set or for cross tabulations of the data.
     
             Distance matrices are often used for various types of
             multivariate analysis.

          e. You can generate approximate percentiles either for the full
             data set or for cross tabulations of the data.  Based on this,
             you can perform distributional modeling for a single variable
             or distributional comparisons between variables (e.g.,
             quantile quantile plots, bihistograms, two sample KS tests, and
             so on).

          The STREAM READ command allows you to do a fair bit of exploratory
          analyses on these large data sets even though the full data set is
          not read into memory.

Syntax 1:
    READ  <x1>   <x2>   ... <xk>
    where <x1>, <x2>, ... <xk> are the desired names for the variables
                 into which the data are read.
 
    This syntax is used to read from the terminal or from within a
    macro file.  All lines are read until an END OF DATA is
    encountered.
 
Syntax 2:
    READ   <file>   <x1>   <x2>   <x3>   etc.
    where <file> is the name of the mass storage file where the data
             resides;
    and   <x1>, <x2>, ... <xk> are the desired names for the variables
                 into which the data in <file> are read.
 
    This syntax is used to read from a file.  All lines are read until
    an END OF DATA or the physical end of file is encountered.
 
Examples:
    READ CALIB. PRES TEMP TIME
    READ ASTM.DAT Y1 Y2 Y3 X DAY LAB
    READ Y1 Y2 Y3 X DAY LAB
 
Note:
    By default, Dataplot does free format reads.  However, it has the
    capability for supporting Fortran style formats.  Formatted reads
    can be about 10 times faster on many systems which can be helpful
    for large data files.  Enter HELP READ FORMAT for more details.

    Note that Fortran formats are based on the decimal point lining up
    consistenly between rows.  Spreadsheet programs such as Excel tend to
    generate either right justified or left justified columns when
    generating fixed width ASCII files.  These are typically not
    consistent with Fortran formatted reads.

Note:
    Blank lines in data files are ignored.
 
Note:
    In order to determine whether the first argument is a file name or
    a variable name, it looks for a period in the name.  If it finds
    one, it assumes a file name.  If it does not, it assumes a variable
    name.  If your file name does not contain a period, attach a
    trailing period (no spaces) to the file name on the READ command.
 
Note:
    Dataplot does not assume specific extensions for file names.  Although
    using conventions (e.g., ".DAT" or ".TXT" for data files, ".DP" for
    Dataplot macros) can be helpful for distinguishing between types of
    files, this is more for the analysts convenience.  Dataplot itself
    does not enforce any conventions.

    File names have the following restrictions:

        1. The file name should be a valid file name for the local
           operating system.

        2. The file name should contain a period "." in the file name
           itself or as a trailing character.  Dataplot strips off trailing
           periods on those systems where it is appropriate to do so.  On
           systems where trailing periods can be a valid file name (e.g.,
           Unix), Dataplot tries to open the file with the trailing period.
           If this fails, it then tries to open the file with the trailing
           period stripped off.

        3. If the file name contains spaces or hyphens, then it needs to be
           enclosed in quotes.

        4. File names are currently limited to 80 characters.  This can
           in particular be a problem if the file name is contained within
           a long path name.  The following can be helpful in these cases.

           a. You can use the CD command to make the path where the file
              is stored the current directory.  This is most useful for
              data files.  For example,

                  pwd
                  cd  <path where data file resided>
                  read  file.dat ...
                  cd ^CURDIR

              The pwd command is used to save the current directory.  The
              cd command is then used to set the current directory to the
              path where the data resides, the read is performed, and then
              the cd command is used to restore the original working
              directory (the cd command saves the current path in the
              string CURDIR).

           b. You can use the SEARCH DIRECTORY command to specify an
              additional directory to search for file names.

Note:
    File names are case sensitive on Unix/Linux/Mac OS X systems.  For these
    systems, Dataplot attempts to open the file as given.  If this fails, it
    attempts to open the file as all upper case characters.  If this fails, it
    attempts to open the file as all lower case characters.
 
    As a further caution for Unix/Linux hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.

Note:
    In general, Dataplot does not read binary data.  However, it can
    read and write binary data using Fortran unformatted I/O.  Note that
    although the Fortran standard includes unformatted I/O, the
    implementation details are left to the individual compiler.  This
    means that Fortran unformatted files are not portable across systems
    and compilers.

    The primary use for this option is if you have a large data file that
    you will be accessing frequently. In this case, it can speed up the
    I/O to save a binary version of the file (you should keep the original
    ASCII version).

    For details, enter HELP SET READ FORMAT.

Note:
    Many data sets are now collected as images.  On some implementations,
    Dataplot can use the GD library to read image data into numeric arrays.

    Although the GD library supports a limited number of image formats,
    open source software packages such as Image Magick and Netpbm can be
    used to convert a large number of image formats to ones supported by
    the GD library.

    For details, enter HELP READ IMAGE.

Note:
    There are variants of this command for reading matrices, parameters, 
    and strings/functions.  See the Related Commands section below.

Note:
    After a READ command, Dataplot creates the following parameters:

        ISKIP  - the number of header lines skipped
        NUMLRD - the number of data lines read
        NUMVRD - the number of variables read

    In addition, the variable names read are saved in the strings
    ZZZV1, ZZZV2, ZZZV3, and so on.  These parameters and strings are
    updated each time a READ is performed.

    This capability was added 2014/12.

Default:
    1) If no file name is specified and a CALL is being executed, then
       the data values should be listed directly in the DATAPLOT
       sub-program immediately after the READ command (do not forget
       the END OF DATA statement).

    2) If no file name is specified and the commands are being manually
       entered/executed one at a time from the terminal, then the data
       should be entered directly from the terminal immediately after
       the READ command (also terminated by an END OF DATA statement).
 
Synonyms:
    None
 
Related Commands:
    READ FUNCTION          = Read a function.
    READ MATRIX            = Read a matrix.
    READ PARAMETER         = Read a parameter.
    READ STRING            = Read a string.
    READ IMAGE             = Read an image format into numeric arrays.
    READ STACKED VARIABLE  = Read a list of variables into a single
                             response variable and a group-id variable.
    SERIAL READ            = Perform a serial read.
    SET READ FORMAT        = Define a FORTRAN style format for reads.
    DATA (LET)             = Enter data values into a variable.
    CLIPBOARD              = Various commands for reading from the
                             system clipboard.
 
Applications:
    Data Input
 
Implementation Date:
    Pre-1987
    1988/02 Ignore column limits when reading from the terminal
    1990/05 Check for comment character in data files
    1995/04 Support for unformatted read
    1996/04 Ignore SET READ FORMAT for READ STRING
    1997/10 Support for SKIP AUTOMATIC
    1998/11 Support for more than 100 variable names
    1999/12 Support for READ ROWID
    2002/07 Support for quotes on file name
    2003/02 Maximum number of characters per record user settable
    2004/01 Support for reading variable names from file
    2004/01 Support for reading character data
    2004/11 PACK/DISPERSE options for READ with SUBSET
    2014/11 Support for reading from system clipboard
    2014/12 Create several automatic parameters/strings for READ
    2016/06 Support for SET DATE DELIMITER
    2016/06 Support for SET TIME DELIMITER
    2016/06 Support for SET READ IP ADDRESSES
    2019/03 Support for SET READ ASTERISK IGNORE
    2019/12 Support for SET READ PERCENT SIGN IGNORE
    Numerous bug fixes over the years
 
Program 1:
    SKIP 25
    READ BERGER1.DAT Y X BATCH
 
Program 2:
    READ X Y
    1  1
    2  4
    3  9
    4 16
    5 25
    END OF DATA
    PRINT X Y
 
-----READ DECIMAL POINT (SET)----------------------------------------
 
READ DECIMAL POINT (SET)
 
Name:
    READ DECIMAL POINT (SET)
 
Type:
    Subcommand under SET
 
Purpose:
    Specifies the character to be interpreted as the decimal
    point when reading data.
 
Description:
    Dataplot follows the United States convention where the
    decimal point is the period ".".  Some locales may use a
    different character to denote the decimal point.  In
    particular, some countries use the comma ",".
    
    In order to make it easier for Dataplot to read files which
    use a different convention for the decimal point, this command
    allows you to specify a different character, such as the comma,
    to denote the decimal point.
    
    Note this support is fairly limited.  Specifically, it only
    applies to free-format reads.
    
       1. This option is not supported for the WRITE command.  The
          WRITE command will always use a period for the decimal
          point.
    
       2. Dataplot alphanumeric output (e.g., the output from the
          FIT command) is generated with the period as the decimal
          point.
    
       3. If you read your data with a SET READ FORMAT command, the
          data must use the period for the decimal point.

Syntax:
    SET READ DECIMAL POINT   <value>
    where <value> denotes the character to interpret as the decimal
               point.
 
Examples:
    SET READ DECIMAL POINT ,
    SET READ DECIMAL POINT .
 
Default:
    The period "." is the default decimal point character.
 
Synonyms:
    None
 
Related Commands:
    READ             = Carries out a column-wise input of data.
    ASCII FILES      = Provides guidance on reading ASCII files.
 
Applications:
    Input/Output
 
Implementation Date:
    2005/5
 
Program:
    SET READ DECIMAL ,
    READ FILE.DAT  Y X
 
-----READ DELIMITER (SET)----------------------------------------
 
READ DELIMITER (SET)
 
Name:
    READ DELIMITER (SET)
 
Type:
    Subcommand under SET
 
Purpose:
    Specifies the character that is used as the delimiter to
    separate data fields in an ASCII data file.
 
Description:
    If Excel writes a comma delimited ASCII file (.CSV), then
    missing values are denoted with ",,".  In order to interpert
    these files correctly, you can enter the command

       SET READ DELIMITER  <value>

    where <value> specifies the desired delimiter.  The default
    delimiter is a comma.

    If Dataplot encounters the delimiter before any valid data
    has been found, it interprets this as a missing value. 

    By default, missing values are set to 0.  If you would like
    to specify a different value to use for missing values, enter
    the command 

        SET READ MISSING VALUE  <value>
 
Syntax:
    SET READ DELIMITER   <value>
    where <value> denotes the value to use as the delimiter.
 
Examples:
    SET READ DELIMITER :
    SET READ DELIMITER ,
    SET READ DELIMITER %
 
Default:
    Comma
 
Synonyms:
    None
 
Related Commands:
    READ                = Carries out a column-wise input of data.
    READ MISSING VALUE  = Specify the value to use for missing data.
 
Applications:
    Input/Output
 
Implementation Date:
    2004/1
 
Program:
    SET READ DELIMITER  ,
    SET MISSING VALUE -99
    READ DUMMY.CSV  Y X
    PLOT Y X   SUBSET Y > -99 SUBSET X > -99
 
-----READ EXCEL-------------------------------------------------
 
READ EXCEL
 
Name:
    READ EXCEL
 
Type:
    Support Command
 
Purpose:
    Read variables (vectors) from an Excel file.

Description:
    Spreadsheet programs are a popular method for saving data.  Most
    spreadsheet programs support the Microsoft Excel file format.

    Dataplot does not natively support reading or writing to Excel format
    files.  The READ EXCEL command works as follows

        1. Dataplot writes the name of the Excel file to line 1
           of the file "dpst5f.dat".  It writes the name of the
           Excel sheet to line 2 of "dpst5f.dat".  The default
           sheet name is "Sheet1".  To change the sheet name, enter
           the command

               SET EXCEL SHEET <sheet-name>

        2. Dataplot then invokes a Python script to read the variables
           from the specified Excel file and then writes the variables
           to the file "dpst1f.dat".

           The Python script, "read_excel.py", is located in the
           "scripts" subdirectory of the Dataplot auxiliary directory.
           This script uses the Pandas function "dataframe.read_excel"
           to read the data from the Excel file.  It then uses the
           Pandas function "pandas.to_csv" to write the variables as
           a comma separated file (CSV) to the file "dpst1f.dat".

        3. Dataplot reads the contents of the variables from the
           file "dpst1f.dat".

    This command assumes that Python and the Python package Pandas
    are already installed on your local platform.  Dataplot does not
    check if Python is installed and it does not initiate the
    Python installation if it is not already installed.

    As Python is used by many popular applications on Linux platforms,
    most Linux platforms will already have Python installed.  However,
    this is not the case for Windows and MacOS platforms.

    If you need to install Python, there are a number of Python
    distributions (see https://wiki.python.org/moin/PythonDistributions).
    However, the most common are ActivePython from ActiveState and
    Anaconda from Continuum Analytics.  Dataplot does not depend on a
    specific Python distribution and we make no recommendation for the
    preferred distribution.

    This command will typically work well with Excel files that are
    clean rectangular data sets.  If you have added graphs, formulas,
    cross-tabulations, and so on to the Excel sheet, then the
    READ EXCEL command is likely to be unsatisfactory.  You can either
    copy the data portion of the spreadsheet to a new sheet or use
    one of the other methods for reading data from spreadsheets
    listed below.

    Broman and Woo (see References below) wrote a useful article
    in The American Statistician that provides useful guidelines
    for creating Excel files that can be more easily read by
    non-Excel programs.

    If you infrequently need to read Excel files and do not already
    have Python installed on your local platform, there are several
    additional methods for reading the data from Excel files.  However,
    if you anticipate the need for frequently reading Excel files, then
    going through the Python installation is probably worth the effort.

    In addition to READ EXCEL, the following methods can also be used
    to read data from Excel files.

         1. Spreadsheets typically support writing data to ASCII files.
            For example, Excel can write formatted text (space delimited)
            (.PRN extension), comma delimited files (.CSV extension), or
            tab delimited files (.TXT extension).  Enter HELP READ for
            details of this.

            As with READ EXCEL, this option works best with clean
            rectangular data sets.  If you do not have a clean Excel
            sheet, you will probably need to manually edit the ASCII
            file before trying to read it with Dataplot.  However, it is
            a viable alternative to READ EXCEL when you do not have Python
            installed on your platform and do not wish to install it.

         2. You can also use Copy and Paste.  On Windows platforms,
            you can Copy the desired data to the clipboard and then use
            the READ CLIPBOARD command.  Alternatively, you can paste
            the data into an ASCII editor (e.g., Notepad or Wordpad on
            Windows, vi or Emacs on Linux), save the file and then use
            the Dataplot READ command.

            This option is particularly useful when your spreadsheet is
            not a clean rectangular data set.

Syntax:
    READ EXCEL <fname> <variable list>
               <SUBSET/EXCEPT/FOR qualification>
    where <fname> is the name of the Excel file;
          <variable list> is the list of variables to read;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    Note that Pandas adds a "row index" variable as the first column
    in the CSV file.  Be sure to add this variable to <variable list>.

Examples:
    READ EXCEL FILE.XLSX Y1 Y2 Y3 X

Note:
    This command will not work successfully on all Excel files.
    Spreadsheets commonly contain external information such as
    cross tabulations and graphs.
    It tends to work reasonably well for 

Note:
    The Pandas pandas.to_csv function will add a row id variable to
    the ASCII file.

Note:
    The python script will currently read the entire spreadsheet.
    Additional commands to specify columns and rows in the spreadsheet
    to read are under development but not yet available.

    Also, Dataplot will not search for the Excel file in the
    Dataplot auxiliary files directories as it does for the
    READ for ASCII files.

    Note: The 2020/05 version of Dataplot now supports specifying the
          first and last rows of the Excel file to read with the
          following commands 

              SET EXCEL START ROW <value>
              SET EXCEL STOP  ROW <value>

          Python/Pandas start row numbers with 0.  Also, the first
          line read is assumed to contain the variable names.  So if
          the first good line is row 3 in the Excel file, use

              SET EXCEL START ROW 1

          Currently you need to specify both the START ROW and the
          STOP row.  Otherwise, Pandas will include all rows in the
          Excel sheet.

          One use of this is to skip over header lines in the Excel file.

Note:
    Pandas by default assumes that the first row of the Excel file
    is a header line containing the variable names.  If your Excel
    file does not contain a header line, enter the command

        SET EXCEL HEADER NONE

    To reset the default of a header line, enter the command

        SET EXCEL HEADER ON

    This command was added 2021/07.  The "read_python.py" script
    was also updated at this time to support this option.

Note:
    Excel (or some other spreadsheet program) does not need to be
    installed on your local platform.  For example, you can create
    the Excel file on a Windows platform and then move the Excel file
    to a Linux platform.

Note:
    If Python is not installed on your default path, you can specify it
    using the SET PYTHON PATH command. For example, the following is for
    the Anaconda installation of Python 3 under Windows (where Anaconda
    is installed for the single user heckert)

       set python path c:\Users\heckert\AppData\Local\Continum\anaconda3\

    There are several different Python distributions. The appropriate
    Python path will depend on the specific distribution you used to
    install Python and whether you choose to install it for a single user
    or for all users. 

Note:
    On Windows platforms, the "read_excel.py" script will be copied to
    the current directory.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    WRITE EXCEL = Write variables to an Excel file.
    PYTHON      = Run a user specified Python script from within Dataplot.
    READ        = Read variables, strings, parameters and matrices.
 
References:
    McKinney (2018), "Python for Data Analysis," Second Edition,
    O'Reilly.

    Chen (2018), "Pandas for Everyone: Python Data Analysis,"
    O'Reilly.

    Broman and Woo (2018), "Data Organization in Spreadsheets,"
    The American Statistician, Vol. 72, No. 1, pp. 2-10.

Applications:
    Data Input
 
Implementation Date:
    2020/02
    2020/05: Added SET EXCEL START ROW and SET EXCEL STOP ROW
    2021/07: Added SET EXCEL HEADER

Program 1:
    dimension 40 columns
    . Path name for Windows
    . read excel "C:\Program Files (x86)\NIST\DATAPLOT\LIB\DATA\FIBERS.XLSX" ...
    .     rowid breakid xcent ycent xc1 yc1 xc2 yc2 xc3 yc3 xc4 yc4 length
    . Path name for Linux
    read excel /usr/local/lib/data/FIBERS.XLSX ...
         rowid breakid xcent ycent xc1 yc1 xc2 yc2 xc3 yc3 xc4 yc4 length
    set write decimals 3
    print breakid xcent length

Program 2:
    . Step 1: READ EXCEL does not search Dataplot sub-directories, so need
    .         to pre-pend the appropriate sub-directory to Excel file name.
    .
    probe path
    let string ipath = ^probestr
    probe iopsy1
    if probeval = 2
       let string islash = \
    else
       let string islash = /
    end of if
    let string subdir = data
    let ipath = string concatenate ipath subdir islash
    .
    let string fname = TEST.XLSX
    let fname = string concatenate ipath fname
    .
    . Step 2: Read the Excel file
    .
    set excel start row 1
    set excel stop  row 77
    read excel ^fname rowid labid y1 y2
    .
    . Step 3: Print the first few lines of the Excel file
    .
    set write decimals 2
    print rowid labid y1 y2 for i = 1 1 10

-----READ FORMAT (SET)-------------------------------------------
 
READ FORMAT (SET)
 
Name:
    READ FORMAT (SET)
 
Type:
    Subcommand under SET
 
Purpose:
    Sets the (optional) FORTRAN format for the READ and SERIAL READ
    commands.  Unformatted Fortran files are now also supported (see
    NOTE section below).
 
Description:
    The default format for the READ and SERIAL READ command is
    free-format.  This allows the analyst to input data into DATAPLOT
    without having to worry about how the data is residing out on the
    file.  On the other hand, if the data happens to reside on the
    file in a structured format, and if the analyst knows what the
    format is, then the analyst can optionally specify to DATAPLOT
    this format information.  The advantage of this is speed since
    formatted READs and SERIAL READs are 10 to 15 times faster.  For
    small data sets (less than a few hundred lines), there is little
    to gain.  However, if your data file is large (say more than 500
    lines) and formatted, then the time for I/O can be drastically
    reduced by making use of such format information.  Any
    FORTRAN-like format must contain only F (floating-point), E
    (exponential), and X (blanks) specifications.  I (integer), D
    (double-precision), H (hollerith), etc.  specifications are not
    permitted.  The restriction against I format is no restriction at
    all.  Simply use the corresponding F format (e.g., I2 becomes
    F2.0, I8 becomes F8.0).
 
Syntax:
    SET READ FORMAT   <s>
    where <s> is a FORTRAN format-like string.
 
Examples:
    SET READ FORMAT 4F10.0
    SET READ FORMAT 5X,F6.0,F6.2,4X,2F5.0
    SET READ FORMAT 10X,3E12.4,5X,F10.0
    SET READ FORMAT DEFAULT
 
    SET READ FORMAT 3F10.0
    READ CALIB.DAT X Y Z
 
Note:
    Support was added for reading Fortran unformatted data files.
    This was done primarily for sites that have created "mega" size
    versions of DATAPLOT where the time entailed in reading large
    data files becomes important.  For standard size DATAPLOT
    (typically a maximum of 10,000 rows with 10 columns for 100,000
    data points total), the use of the SET READ FORMAT command
    provides adequate performance.  However, the unformatted read
    capability is available regardless of the workspace size.  The
    advantage of unformatted reads is that the data files are much
    smaller (typically by a factor of 10 or more) and reading the
    data is significantly faster (e.g., reading 10,000 rows of data is
    almost instantaneous).  The disadvantage is that unformatted
    files are binary, and thus cannot be modified or viewed with a
    standard text editor.  Also, Fortran unformatted files are NOT
    transportable across different computer systems.

    An unformatted read is accomplished by entering the command:

       SET READ FORMAT UNFORMATTED

    and then entering a standard READ command.  For example,

       READ LARGE.DAT X1 X2 X3

    There are 2 ways to create the unformatted file in Fortran.  For
    example, suppose X and Y are to be written to an unformatted
    file.  The WRITE can be generated by:

    a)    WRITE(IUNIT) (X(I),Y(I),I=1,N)
    b)    WRITE(IUNIT) X,Y

    The distinction is that (a) stores the data as X(1), Y(1),
    X(2), Y(2), ..., X(N), Y(N) while (b) stores all of X then
    all of Y.  There is no inherent advantage in either method in
    terms of performance or file size.  The SET READ FORMAT
    UNFORMATTED command assumes (a).  To specify (b), enter the
    command:

          SET READ FORMAT COLUMNWISE (or UNFORMATTEDCOLUMNWISE)

    Unformatted reading is supported only for variables or matrices
    (i.e., not for parameters or strings).  Also, it only applies
    when reading from a file.  The limits for the maximum number of
    rows and columns for a matrix still apply (500 rows and 100
    columns on most systems).  When reading a matrix, the number of
    columns must be specified via the SET UNFORMATTED COLUMNS
    command.  For example,

          SET READ FORMAT UNFORMATTED
          SET UNFORMATTED COLUMNS 25
          READ MATRIX.DAT M

    The maximum size of the file that DATAPLOT can read is equal to
    the workspace size on your implementation (100,000 or 200,000
    points on most installations).  For larger files, it will read
    up to this number of data values.

    The data is assumed to be a rectangular grid of data written in
    a single chunk.  Only single precision real numbers are
    supported.  By default, the entire file (up to the maximum number
    of points) is read.  DATAPLOT does provide 2 commands to allow
    some control of what portion of the file is read:

          SET UNFORMATTED OFFSET <value>
          SET UNFORMATTED RECORDS <value>

    The OFFSET specifies the number of data values at the begining of
    the file to skip.  This is useful for skipping header lines
    (similar to a SKIP command for reading ASCII files) and other
    miscellaneous values.  The RECORDS value is useful for reading
    part of a larger file.

    Be aware that Fortran unformatted files are NOT transportable
    across systems.  This is due to the fact that the file contains
    various header bytes (the Fortran standard leaves implementation
    of this up to vendor) that are not standard.  Also, the storage
    of real numbers can vary between platforms.  This means that
    the SET READ FORMAT UNFORMATTED command can NOT be used to read
    raw binary files (as might be produced by a C program) and it
    cannot, in general, be used to read unformatted Fortran files
    created on systems other than the one you are running DATAPLOT on.

Default:
    Free-format (i.e., no format).
 
Synonyms:
    None
 
Related Commands:
    READ        = Carries out a column-wise input of data.
    SERIAL READ = Carries out a line-wise input of data.
 
Applications:
    Input/Output
 
Implementation Date:
    1988/03 (support for reading unformatted Fortran files added 1995/04)
 
Program:
    SET READ FORMAT 2F10.1
    READ X Y
    21.0      110.7
    31.2      120.6
    55.4      100.2
    END OF DATA
    WRITE X Y
 
-----READ FUNCTION--------------------------------------------------
 
READ FUNCTION
 
Name:
    READ FUNCTION
 
Type:
    Support Command
 
Purpose:
    Reads a function into DATAPLOT:
       1) from a mass storage file;
       2) from within a CALLed DATAPLOT sub-program;
       3) from the terminal.
 
Description:
    The rules regarding READ FUNCTION are as follows:
       1) Only one line is read.  Unlike a READ of variables, no END OF
          DATA is searched for.
       2) Typically, only one function is read at a time.  Reading more
          than one function is allowed (but not recommended).  If more
          than one function is read from the same line, separate the
          functions with at least one space and leave no spaces within
          a given function.  For example,
             READ FUNCTION F G
             X**2+8X-4     X**3-X+1
       3) In scanning for the function, the full line image is scanned
          (for reading from a mass storage file, the full line image is
          132 columns; for reading from within a sub-program and for
          reading from the terminal, the full line image is 80
          columns).  For variations on this, see the COLUMN LIMITS
          command.
       4) If one function is read, blanks are ignored in the function.
          However, if more than one function is read, blanks are used
          to separate the functions (and are therefor significant).
       5) Function definitions can be free-format  They need not be
          aligned in specific columns.
       6) All reads start from the beginning of the file (for
          variations of this, see the SKIP and ROW LIMITS commands).
 
Syntax 1:
    READ FUNCTION   <f1>   <f2>   ...   <fk>
    where <f1>, <f2>, ..., <fk> are the desired functions (typically
              only one is given).
 
    This syntax is used to read a function from the terminal or from
    within a DATAPLOT sub-program.
 
Syntax 2:
    READ FUNCTION   <file>   <f1>   <f2>   ...   <fk>
    where <file> is the name of the mass storage file where the
              function resides;
    and   <f1>, <f2>, ..., <fk> are the desired functions (typically
              only one is given).
 
    This syntax is used to read a function from a file.
 
Examples:
    READ FUNCTION CALIB. F
    READ FUNCTION F
      X**2+4*X-1
 
Default:
    1) If no file name is specified, and if a CALL is being executed,
       then the function should be listed directly in the DATAPLOT
       sub-program immediately after the READ FUNCTION command.
    2) If no file name is specified, and if commands are being manually
       entered/executed 1-at-a-time from the terminal, then the
       function should be entered directly from the terminal
       immediately after the READ FUNCTION command.
 
Related Commands:
    SERIAL READ        = Perform a serial read.
    READ               = Read variables.
    READ PARAMETER     = Read a parameter.
    READ MATRIX        = Read a matrix.
    READ STRING        = Read a string.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    READ FUNCTION F
    X**2+2*X-6
    PLOT F FOR X = -3 .1 3
 
-----READ IMAGE----------------------------------------
 
READ IMAGE
 
Name:
    READ IMAGE
 
Type:
    Input Command
 
Purpose:
    Reads an image file that is in JPEG, PNG, or GIF format.
 
Description:
    Scientific data is increasingly collected in the form of
    images.  Although Dataplot does not currently support an
    explicit image data type, the READ IMAGE command can be used
    to read images into Dataplot in the form of real numbers
    (i.e., each real number represents the intensity value of
    a given pixel in the image).

    There are two forms for this command:

       1) You can read the image data into a matrix.

       2) You can read the image data into a response variable,
          a row-id variable, and a column-id variable.

    The best choice depends on what analysis you intend to
    perform on the data.  If you will not be using the matrix
    specific commands, the second form is typically more useful.

    Images can be either grey scale (i.e., a single color with
    varying intensity levels) or color.  Color images are
    represented with intensity values for red, green, and
    blue (RGB).  Although RGB is not the only color model used,
    it is currently the only one supported in Dataplot.

    Dataplot implements the READ IMAGE command using the GD
    library.  The GD library was developed by the Boutell company.
    GD in turn uses three additional libraries: zlib, libpng, and
    libjpeg.  These libraries are all freely downloadable from the
    web.  The URL for GD is (this site contains links to the other
    three libraries):

        http://www.libgd.org/

    The READ IMAGE command depends on the GD library being
    integrated into Dataplot.  Currently, it should be available
    on most Linux and Mac OSX implementations.  However, it is
    not currently available on the Microsoft Windows
    implementation.

    Note that the primary purpose of reading images into Dataplot
    is in order to perform data analysis on the image data.
    Although you can use the LET comamnd to perform some basic
    image manipulation tasks, image manipulation is not a primary
    goal for the Dataplot developers.

Syntax 1:
    READ IMAGE <file>  <m>
    where <file> is the name of the file containing the image;
    and   <m> is the matrix where the image will be saved.
 
    This syntax is used to save a grey scale image into a matrix.

Syntax 2:
    READ IMAGE <file>  <r>  <g>  <b>
    where <file> is the name of the file containing the image;
          <r> is the matrix where the red component of the image
              will be saved.
          <g> is the matrix where the green component of the image
              will be saved.
    and   <b> is the matrix where the blue component of the image
              will be saved.
 
    This syntax is used to save an RGB image into 3 separate matrices
    (one matrix for each color).

Syntax 3:
    READ IMAGE TO VARIABLES  <file>  <y>  <rowid>  <colid>
    where <file> is the name of the file containing the image;
          <y> is the variable where the image data will be saved;
          <rowid> is a variable that identifies the row of the image;
     and  <colid> is a variable that identifies the column of the
              image.
 
    This syntax is used to save a grey scale image into a single
    response variable and corresponding row-id and column-id
    variables.

Syntax 4:
    READ IMAGE TO VARIABLES  <file>  <r> <b> <g> <rowid>  <colid>
    where <file> is the name of the file containing the image;
          <r> is the variable where the red component of the image data
              will be saved;
          <b> is the variable where the blue component of the image data
              will be saved;
          <g> is the variable where the green component of the image data
              will be saved;
          <rowid> is a variable that identifies the row of the image;
     and  <colid> is a variable that identifies the column of the
              image.
 
    This syntax is used to save an RGB image into a three response
    variables (one for each color component) and corresponding row-id
    and column-id variables.

Examples:
    READ IMAGE TO VARIABLES IMAGE_GREY.JPG  Y ROW COL
    READ IMAGE TO VARIABLES IMAGE_COLOR.JPG  RED BLUE GREEN
    READ IMAGE IMAGE_GREY.JPG  M
    READ IMAGE IMAGE_COLOR.JPG RED BLUE GREEN
 
Note:
    The current implementation supports a limited number of image
    file formats.  If you have image data in some other format
    (and there is a long list of available image formats), you will
    need to convert the image to either JPEG, PNG, or GIF format.

    ImageMagick and Netpbm are two freely downloadable software
    suites that are capable of converting image formats for a wide
    variety of image formats (they also contains many image
    manipulation tools).  ImageMagick and Netpbm will often be
    installed on Unix/Linux platforms and they are freely
    downloadable for most common computer platforms.  In addition,
    programs such as Perl have integrated the Image Magick libraries
    to provide image conversion and manipulation capabilities.

    If you need to perform some basic image manipulation tasks,
    it is probably easier to use one of these software programs
    (or some other image manipulation tool) first before reading the
    image into Dataplot.

    The ImageMagick software can be downloaded from the following
    web site:

         http://www.imagemagick.org/

    The Netpbm software can be downloaded from the following
    web site:

         http://netpbm.sourceforge.net/

    Windows users may find it more convenient to use

         http://gnuwin32.sourceforge.net/packages/netpbm.htm

    We are investigating the possibility of integrating one or both
    of these libraries into a future release of Dataplot in order to
    provide direct access to a greater range of image formats and to
    provide some basic image manipulation capabilities.

Note:
    There are some limitations on the size of the images that
    Dataplot can handle.

    If you use the READ IMAGE TO VARIABLES form of the command,
    the limiting factor is the maximum number of rows for a single
    variable.  On most platforms, the default is to have 10 columns
    with a maximum of 1,000,000 rows.  You can use the DIMENSION
    command to create more columns at the expense of fewer rows.
    However, you cannot create more rows (i.e., the minimum number
    of columns is 10).

    So multiply the number of rows by the number of columns in your
    image to see the minimum number of rows you need.  For example,
    if you have a 512x512 image, you need 262,144 rows of data.  If
    your version of Dataplot has a maximum of 1,000,000 rows, then
    you can accomodate images up to 1,000x1,000.

    You may want to do something like the following before using the
    READ IMAGE TO VARIABLES command:

         LET NUMROW = 512
         LET NUMCOL = 512
         LET MAXROW = NUMROW*NUMCOL
         DIMENSION MAXROW ROWS

    If you use the READ IMAGE command, you will typically need to
    create a large number of columns (which means you will be able
    to accomodate fewer rows in any variables you create).  You may
    want to do something like the following before using the READ IMAGE
    command:

         LET NUMROW = 512
         LET NUMCOL = 512
         DIMENSION NUMROW
         MATRIX DIMENSION ROWS NROWS

    This will give you the maximum number of columns based on the
    number of rows in your image.  The MATRIX DIMENSION is used to
    dimension temporary matrices in the various Dataplot MATRIX
    commands.

    The maximum row size is set before Dataplot is built.  To see
    what it is on your platform, you can enter the command

         DIMENSION 10 COLUMNS

    The value given for the line MAXIMUM NUMBER OBS/VARIABLE (ROWS)
    specifies the maximum number of rows for your implementation.

Note:
    Unlike most of the other READ commands, the file name argument
    is required on the READ IMAGE command.
 
Note:
    DATAPLOT has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    DATAPLOT strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), DATAPLOT tries to open the file with
    the trailing period.  If this fails, it then tries to open the file
    with the trailing period stripped off.
 
    Although Dataplot does not require specific file extensions for
    the other READ commands, it does require them for the READ IMAGE
    command.  The file extension is used to determine whether a
    JPEG, PNG, or GIF file is being read.  JPEG files should have
    a ".jpeg", ".jpg", ".JPEG", or ".JPG" extension, GIF files should
    have a ".gif" or ".GIF" extension, and PNG files should have
    a ".png" or ".PNG" extension.

Note:
    File names are case sensitive on Unix file systems.  For Unix,
    DATAPLOT attempts to open the file as given.  If this fails, it
    attempts to open the file as all upper case characters.  If this
    fails, it attempts to open the file as all lower case characters.
    All other currently supported systems are not case sensitive
    regarding file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    IMAGE PLOT              = Display an image.
    READ                    = Read variables.
    READ MATRIX             = Read matrix data.
    READ STACKED VARIABLES  = Read a list of variables into a
                              single response variable and a 
                              group-id variable.
    CREATE MATRIX           = Create a matrix from a list of
                              variables.
 
Applications:
    Data Input
 
Implementation Date:
    2008/3
 
Program:
    dimension 10 variables
    read image to variables takashi.jpg  red blue green rowid colid
    .
    probe iopsy1
    if probeval = 1
      device 1 x11
      device 1 picture points 600 600
    end of if
    .
    erase
    erase
    set ipl1na takashi_image.jpg
    set gd color true
    device 2 gd jpg
    device 2 picture points 600 600
    .
    char size 1
    frame off
    frame corner coordinates 5 5 95 95
    .
    title offset 2
    title Takashi Image
    image plot red rowid colid
    .
    device 2 close
 
-----READ LINE (SET)-------------------------------------------
 
READ LINE (SET)
 
Name:
    READ LINE (SET)
 
Type:
    Subcommand under SET
 
Purpose:
    Specifies whether or not the GNU READLINE library will be used
    to parse commands entered from the terminal.
 
Description:
    The GNU READLINE library allows command line editing and
    history recall (with editing).  This library is available
    on most Unix/Linux platforms.  Dataplot does not support
    this capability for Windows implementations.

    By default, this feature is disabled.  To specify that
    command lines should be parsed by the READLINE library,
    enter the command

        SET READ LINE ON

    This capability is provided as a convenience for those
    Unix/Linux users who are familiar with the capabilities
    of READLINE from other applications.

    This capability only applies to commands that are entered from
    the terminal (i.e., commands read from macros or other files
    do not use this capability).

    When the READLINE capability is supported and the
    SET READLINE ON command is entered, then the following is
    available:

       1) The current command line can be edited.  By default,
          the editing is performed using EMACS style commands.
          Alternatively, you can request vi style editing commands.

       2) You can recall previously entered commands (use
          Cntrl-r to search the history list starting with the
          most recently entered commands and Cntrl-f to search the
          history list in the order the commands were entered).

          The history list only starts with commands entered
          after the SET READ LINE ON command was entered and it
          will only include commands entered from the termininal
          (i.e., it will not include commands entered from the
          macro files).

    The editing capabilities supported by readline are extensive
    and we do not document them here.  They are documented in full
    at the readline web site:

          http://tiswww.case.edu/php/chet/readline/rltop.html

    This documentation lists the editing commands that are
    available and shows how you can customize key bindings.
    Note that Dataplot does not provide any customized commands
    or command completion.

Syntax:
    SET READ FORMAT   <ON/OFF>
    where <ON> specifies that the READLINE capability will be used
          and <OFF> specifies that it will not.
 
Examples:
    SET READ LINE ON
    SET READ LINE OFF

Note:
    Dataplot allows recently entered commands to be listed with
    the LIST (or L) command.  Selective commands may be re-executed
    or saved with the REPEAT (or R) and SAVE (or S) commands,
    respectively.  However, no editing capability is provided
    for the REPEAT and SAVE commands.

    The LIST, REPEAT, and SAVE capabilities are independent of the
    READLINE capabilities.  Commands entered via the READLINE
    capability are added to the DATAPLOT command list (i.e., the
    commands displayed by the LIST command).

Note:
    The maximum line length for a command is 255 characters.  This
    is true whether READLINE is used or not.

Default:
    The READLINE capability is off.
 
Synonyms:
    None
 
Related Commands:
    LIST        = List previously entered commands.
    REPEAT      = Execute previously entered commands.
    SAVE        = Save previously entered commands.
 
Applications:
    Input/Output
 
Implementation Date:
    2009/4
 
Program:
    XX
 
-----READ MISSING VALUE (SET)----------------------------------------
 
READ MISSING VALUE (SET)
 
Name:
    READ MISSING VALUE (SET)
 
Type:
    Subcommand under SET
 
Purpose:
    Specifies the value to be used when a missing value is
    encountered with the array form of the COLUMN LIMITS
    command.
 
Description:
    The January, 2004 version of Dataplot added support for
    an array form of the COLUMN LIMITS command.  This form is
    used to specify the lower and upper columns to read for
    each data field.  One specific case this was intended to
    handle was data files containing columns of unequal length.
    This is a common occurence when Excel files are saved to
    ASCII data files.

    When the array form of the COLUMN LIMITS comamnd is used,
    an empty field is interpreted as a missing value.  By default,
    Dataplot will assign a value of zero.  If you want to assign
    a value other than zero, use the SET READ MISSING VALUE command
    to specify that value.
 
Syntax:
    SET READ MISSING VALUE   <value>
    where <value> denotes the value to assign when an empty data
               field is encoutered.
 
Examples:
    SET READ MISSING VALUE -999
    SET READ MISSING VALUE 0
    SET READ MISSING VALUE -1
 
Note:
    This command only applies when the array form of the
    COLUMN LIMITS command has been invoked.  Otherwise, if the
    number of values read is less than the number of variables
    specified on the READ command, Dataplot treats this as an
    error.

Default:
    Zero
 
Synonyms:
    None
 
Related Commands:
    READ             = Carries out a column-wise input of data.
    COLUMN LIMITS    = Specify what columns to read.
 
Applications:
    Input/Output
 
Implementation Date:
    2004/1
 
Program:
    SET READ MISSING VALUE -99
    LET LOWLIM = DATA  1 11
    LET UPPLIM = DATA 10 20
    COLUMN LIMITS LOWLIM UPPLIM
    READ DUMMY.DAT  Y X
    PLOT Y X   SUBSET Y > -99 SUBSET X > -99
 
-----READ PAD MISSING COLUMNS (SET)--------------------------------
 
READ PAD MISSING COLUMNS (SET)
 
Name:
    READ PAD MISSING COLUMNS (SET)
 
Type:
    Subcommand under SET
 
Purpose:
    If the number of variables specified on a READ command is
    greater than the number of values read from a data record,
    specify whether these extra values will be set to a
    "missing value" or this data record will be
    considered an error.
 
Description:
    Dataplot typically expects all variables to be of equal length.  That
    is, the data is rectangular with no empty fields.

    Dataplot reads the data file one row at a time.  When reading a row,
    Dataplot assigns the first value read to the first variable name, the
    second value read to the second variable name, and so on.  By default,
    the row with the smallest number of values defines the number of
    variables that will be read.  For example, if you entered the command

         READ FILE.DAT Y X1 X2 X3

    and one of the rows has only two values, then only Y and X1 will
    be read into Dataplot.

    In some cases, it may be more convenient to assign a missing value to
    any variables that did not have a corresponding data item.  To do
    this enter the command

        SET READ PAD MISSING COLUMNS ON

    You can specify the value to use for missing values (the default is
    zero) with the command

       SET READ MISSING VALUE <value>

    This works well if the empty fields are the end columns.  However,
    be aware that if your empty fields are the beginning or middle
    columns, the data values may not be assigned to the variables
    in the way you expect.  See the NOTE: section below for alternative
    methods for dealing with empty fields are columns of unequal length.

    NOTE 2019/04: The default behavior was modifed.  Now, Dataplot will
    always pad with missing values.  The only distinction between ON
    and OFF is that OFF is set a warning message will be printed when
    a row is encountered with less than the expected number of values.

Syntax:
    SET READ PAD MISSING COLUMNS   <ON/OFF>
    where ON specifies that missing columns will be padded with
          a missing data value and OFF specifies that missing
          columns will be treated as an error.
 
    NOTE 2019/04: Now missing columns will always be padded with the
                  missing value code.  If OFF is specified, a warning
                  message will be printed when rows with a fewer than
                  expected number of values are encountered.  If ON
                  is specified, no warning messages will be printed.

Examples:
    SET READ PAD MISSING COLUMN ON
    SET READ PAD MISSING COLUMN OFF
 
Note:
    When your data file has columns of unequal length or empty
    fields, there are several alternative approaches.

       1. Pick some value to represent a missing value and fill in
          missing data points with that value. After reading the data,
          you can use a RETAIN command to remove them. For example, if
          you use -99 to signify a missing value, you can enter
          something like

            RETAIN Y SUBSET Y > -99 

          Alternatively, you can use a SUBSET clause on subsequent plot
          and analysis commands.

          There are two SET commands that pertain to missing values.

          SET DATA MISSING VALUE <value> specifies a character string
          that will be interpreted as a missing value in the data file
          (this character string can be a numeric value).

          SET READ MISSING VALUE <value> specifies the numeric value that
          will be saved to the Dataplot variable when a missing value (as
          defined by the SET DATA MISSING VALUE) is encountered. 

          Where feasible, this is the recommended solution.

       2. If your data file has consistent formats for the rows, then
          there are two possible solutions.

          If the fields are justified by the decimal point so that a
          Fortran format statement can be applied, then you can use the
          SET READ FORMAT command. In this case, empty fields are read as
          zero. If zero can be a valid data value for one or more of your
          variables, then it can be ambiguous whether a zero in your
          variable denotes a valid data point or a missing value. The
          SET READ MISSING VALUE setting does not apply when the
          SET READ FORMAT is used.

          Many spreadsheets have an option for saving data to a "fixed
          width" ASCII text file. In these cases, the fields are typically
          either right or left justified. However, the column for the
          decimal point will not be consistent so that the SET READ FORMAT
          command cannot be used. In this case, you can use the variable
          form of the COLUMN LIMITS command. That is

             COLUMN LIMITS LOWLIMIT  UPPLIMIT

          where LOWLIMIT and UPPLIMIT are variables containing the start
          and stop columns, respectively, for each of the variables.  By
          default, when a blank field is encountered, it is set to zero.
          You can specify the value to use by entering the command

             SET READ MISSING VALUE <value> 

       3. If your data has both columns of unequal length (or empty
          fields) and inconsistent columns for given data fields, an
          alternative is to use a comma delimited data file. If there is
          no data between successive commas, this is treated as a missing
          value. The default is to assign a value of zero. Alternatively,
          you can use the SET READ MISSING VALUE command described above.

          You can specify a delimiter other than a comma with the command

              SET READ DELIMITER <character> 

Default:
    OFF
 
Synonyms:
    None
 
Related Commands:
    READ                    = Carries out a column-wise input of
                              data.
    COLUMN LIMITS           = Specify what columns to read.
    SET READ MISSING VALUE  = Specify the value used to denote a
                              missing value.
    SET DATA MISSING VALUE  = Specify the missing value code in a data
                              file.
    SET READ DELIMITER      = Specify the character that will be
                              interperted as a delimiter between
                              fields on a data record.
 
Applications:
    Input/Output
 
Implementation Date:
    2004/10
    2019/04: The default behavior for empty fields changed.
 
Program:
    SET READ MISSING VALUE -99
    SET READ PAD MISSING COLUMN ON
    READ DUMMY.DAT  Y X
    RETAIN Y X SUBSET Y > -99 SUBSET X > -99
    PLOT Y X
 
-----READ SUBSET (SET)--------------------------------
 
READ SUBSET (SET)
 
Name:
    READ SUBSET (SET)
 
Type:
    Subcommand under SET
 
Purpose:
    Specify how SUBSET clauses are to be interpreted on
    READ commands.
 
Description:
    The SUBSET/EXCEPT/FOR clause on a READ command is ambiguous.  The
    ambiguity aries from the fact that it is not clear whether the
    SUBSET/EXCEPT/CLAUSE command refers to the lines in the data file
    being read or to the output variables that are created by the
    READ command.  We address this with the following command:

        SET READ SUBSET  <PACK/DISPERSE>   <PACK/DISPERSE>

    In this command, PACK means the SUBSET/EXCEPT/FOR clause does not
    apply while DISPERSE means that it does.  The first setting applies
    to the input file while the second setting applies to the created
    data variables.

    This is demonstrated with the following example (note that P-D means
    the data file is set to PACK and the output variable is set to
    DISPERSE).  The first column is the data in the file while the
    remaining columns show what the resulting data variable should look
    like.

         LET TAG = 1 FOR I = 1 1 10
         LET TAG = 0 FOR I = 2 2 10
         READ FILE.DAT  X  SUBSET TAG = 1

         X      P-D       P-P          D-P      D-D
         ===========================================
          1       1         1            1        1
          2       0         2            3        0
          3       2         3            5        3
          4       0         4            7        0
          5       3         5            9        5
          6       0         6            -        0
          7       4         7            -        7
          8       0         8            -        0
          9       5         9            -        9
         10       -        10            -        -

    The default setting is PACK-DISPERSE (this is the default
    because this is the behavior of previous versions of Dataplot).
    However, the DISPERSE-PACK option is the one most likely to be
    used.  The PACK-PACK option is equivalent to not using the
    SUBSET clause at all, so is unlikely to be used.

Syntax:
    SET READ SUBSET  <PACK/DISPERSE>   <PACK/DISPERSE>
    where the first <PACK/DISPERSE> specifies how the SUBSET clause
    applies to the data file and second <PACK/DISPERSE> specifies
    how the output file is created.
 
Examples:
    SET READ SUBSET PACK DISPERSE
    SET READ SUBSET PACK PACK
    SET READ SUBSET DISPERSE PACK
    SET READ SUBSET DISPERSE DISPERSE

Note:
    This command works as documented for SUBSET clauses.
    It is not currently working correctly for FOR clauses.

Default:
    The default is SET READ SUBSET PACK DISPERSE.
 
Synonyms:
    None
 
Related Commands:
    READ                    = Carries out a column-wise input of
                              data.
    COLUMN LIMITS           = Specify what columns to read.
    SET READ MISSING VALUE  = Specify the value used to denote a
                              missing value.
    SET READ DELIMITER      = Specify the character that will be
                              interperted as a delimiter between
                              fields on a data record.
 
Applications:
    Input/Output
 
Implementation Date:
    2004/10
 
Program:
    .  This example shows how to read every other line
    .  of the input file.
    .
    SKIP 25
    SET READ SUBSET DISPERSE PACK
    LET N = 107
    LET TAG = 1 FOR I = 1 1 N
    LET TAG = 0 FOR I = 2 2 N
    READ BERGER1.DAT  Y X  SUBSET TAG = 1
 
-----READ VARIABLE LABEL (SET)----------------------------------------
 
READ VARIABLE LABEL (SET)
 
Name:
    READ VARIABLE LABEL (SET)
 
Type:
    Subcommand under SET
 
Purpose:
    Specifies whether variable names will be read from the data
    file or not.
 
Description:
    Typically, Dataplot reads variable names from the READ
    command.  For example,

       READ BERGER1.DAT Y X BATCH

    Alternatively, you can omit the variable names:

       READ BERGER1.DAT

    In this case, Dataplot will automatically assign the variable
    names X1, X2, and X3.

    Some data files contain the variable names as the first
    line of the data file.  In this case, you can enter the
    command

        SET READ VARIABLE LABEL ON

    to instruct Dataplot to read the variable names from the
    first line.
 
Syntax:
    SET READ VARIABLE LABEL   <ON/OFF>
    where <ON> specifies that variable labels will be read from
               the data file and <OFF> specifies that they will
               not.
 
Examples:
    SET READ VARIABLE LABEL ON
    SET READ VARIABLE LABEL OFF
 
Note:
    If the SKIP command has been entered, the variable labels
    will be read from the first line after the skipped lines.
    For example, SKIP 24 implies that the variable labels will
    be read from line 25.

Note:
    Many of the built-in Dataplot sample files contain the
    variable names on line 24 and a line of dashes ("-") on
    line 25.  These files can be read with

         SKIP AUTOMATIC
         READ FILE.DAT


Default:
    OFF (variable labels will not be read from the file)
 
Synonyms:
    None
 
Related Commands:
    READ                   = Carries out a column-wise input of data.
    SERIAL READ            = Carries out a line-wise input of data.
    SET CONVERT CHARACTER  = Specifies whether character data will
                             be read.
    SKIP                   = Specifies number of header lines to
                             bypass.
    COLUMN LIMITS          = Specify what columns to read.
 
Applications:
    Input/Output
 
Implementation Date:
    2004/1
 
Program:
    SET READ VARIABLE LABEL ON
    READ TEST.DAT
 
-----READ MATRIX TO VARIABLES----------------------------------------
 
READ MATRIX TO VARIABLES
 
Name:
    READ MATRIX TO VARIABLES
 
Type:
    Input Command
 
Purpose:
    Reads matrix data into a response variable, a row-id
    variable, and a column-id variable.
 
Description:
    The READ MATRIX command is used to read a data file
    into a matrix.  This is useful for utilizing the Dataplot
    commands that explicitly work on matrices.

    However, in some cases it may be more convenient to
    read the matrix as a single response variable.  For
    example, you may want to use commands that work on variables
    rather than matrices.  In these cases, you can use the
    READ MATRIX TO VARIABLES command instead of the READ MATRIX
    command.  This command will create row-id and column-id
    variables in addition to the response variable.

Syntax:
    READ MATRIX TO VARIABLES  <file>  <y>  <rowid>  <colid>
    where <file> is the name of the file that contains the matrix
                 data;
          <y> is the response variable where the data will be
                 saved;
          <rowid> is a variable that identifies the row of the
                 matrix for each response variable;
     and  <colid> is a variable that identifies the column of the
                 matrix for each response variable.
 
     The <file> argument is optional.  If it is omitted, Dataplot
     will read the matrix data from the terminal rather than a file.

Examples:
    READ MATRIX TO VARIABLES FILE.DAT  Y ROW COL
 
Note:
    By default, DATAPLOT does free format reads.  However, it has the
    capability for supporting FORTRAN style formats.  Formatted reads
    can be about 10 times faster on many systems.   This can be helpful
    for large data files.  Enter HELP READ FORMAT for more details.
 
Note:
    Blank lines in data files are ignored.
 
Note:
    DATAPLOT supports the ability to embed comment lines within
    the data file.  Enter HELP COMMENT CHECK for details.
 
Note:
    In order to determine whether the first argument is a file name or
    a variable name, it looks for a period in the name.  If it finds
    one, it assumes a file name.  If it does not, it assumes a variable
    name.  If your file name does not contain a period, attach a
    trailing period (no spaces) to the file name on the
    READ MATRIX TO VARIABLES command.
 
Note:
    DATAPLOT has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    DATAPLOT strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), DATAPLOT tries to open the file with
    the trailing period.  If this fails, it then tries to open the file
    with the trailing period stripped off.
 
    Some users prefer to give all data files a ".DAT" or ".dat"
    extension.  Although this is a useful method for keeping track of
    data files, it is strictly a user convention and is not enforced
    by DATAPLOT in any way.
 
Note:
    File names are case sensitive on Unix file systems.  For Unix,
    DATAPLOT attempts to open the file as given.  If this fails, it
    attempts to open the file as all upper case characters.  If this
    fails, it attempts to open the file as all lower case characters.
    All other currently supported systems are not case sensitive
    regarding file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    READ MATRIX             = Read matrix data.
    READ                    = Read variables.
    READ IMAGE TO VARIABLES = Read an image file into one or more
                              response variables.
    READ STACKED VARIABLES  = Read a list of variables into a
                              single response variable and a 
                              group-id variable.
    CREATE MATRIX           = Create a matrix from a list of
                              variables.
    SERIAL READ             = Perform a serial read.
    SET READ FORMAT         = Define a FORTRAN style format for
                              reads.
    READ PARAMETER          = Read a parameter.
    READ STRING             = Read a string.
 
Applications:
    Data Input
 
Implementation Date:
    2009/1
 
Program:
    READ MATRIX TO VARIABLES Y ROWID COLID
    1 3 2
    7 3 1
    8 1 2
    END OF DATA
    PRINT Y ROWID COLID
    
    The following output results for Y, ROWID and COLID:

    1  1  1
    3  1  2
    2  1  3
    7  2  1
    3  2  2
    1  2  3
    8  3  1
    1  3  2
    2  3  3

-----READ MATRIX------------------------------------------------
 
READ MATRIX
 
Name:
    READ MATRIX
 
Type:
    Support Command
 
Purpose:
    Reads data into a matrix:
       1) from a mass storage file;
       2) from within a CALLed DATAPLOT sub-program;
       3) from the terminal.
 
Description:
    The rules regarding READ MATRIX are as follows:
       1) Only one matrix is read for a given READ MATRIX command
          (additional matrices on the READ FUNCTION line are ignored).
       2) In scanning for the matrix, the full line image is scanned
          (for reading from a mass storage file, the full line image
          is 132 columns; for reading from within a sub-program and for
          reading from the terminal, the full line image is 80
          columns).  For variations on this, see the COLUMN LIMITS
          command.
       2) In scanning for the matrix, the full line image is scanned.
          By default, a maximum of 1024 characters are read from
          a file.  To increase this, use the command
          MAXIMUM RECORD LENGTH.  When reading from the terminal, a
          maximum of 255 characters are read.
       3) Data values on a line image must be separated by at least
          one blank.
       4) Data values can be free-format.  They need not be aligned in
          specific columns.
       5) The format of individual data values is general.  It can be
          integer, floating point, or exponential.  It is stored
          internally as a single precision real number.
       6) All reads start from the beginning of the file (for
          variations of this, see the SKIP and ROW LIMITS commands).
       7) The analyst need not be concerned about the number of
          observations or the number of variables for the matrix.
          DATAPLOT automatically determines and reports these values at
          the end of the read.
       8) The read terminates when a line image is encountered which
          consists of
             END OF DATA
          or
             END DATA
          or when the end of the file is reached.
       9) The individual columns of the matrix are available as
          variables (e.g., for matrix M, the columns are M1, M2, and
          so on).
 
Syntax 1:
    READ   MATRIX  <mat>
    where <mat> is the name for the matrix.
 
    This syntax is used to read a matrix from the terminal or from
    within a DATAPLOT sub-program.
 
Syntax 2:
    READ   MATRIX  <file>   <mat>
    where <file> is the name of the mass storage file where the data
              resides;
    and   <mat> is the name for the matrix.
 
    This syntax is used to read a matrix from a file.
 
Examples:
    READ MATRIX CALIB. M
 
Note:
    By default, DATAPLOT does free format reads.  However, it has the
    capability for supporting FORTRAN style formats.  Formatted reads
    can be about 10 times faster on many systems.   This can be helpful
    for large data files.  Enter HELP READ FORMAT for more details.
 
Note:
    The command

        DIMENSION MATRIX COLUMNS <value>

    defines the maximum number of columns in a matrix whenn executing
    matrix-based commands.

    If you are using free format reads, this value needs to be set
    as least as large as the number of columns you want to read.

    If you have entered a SET READ FORMAT command, then this value
    must be set to exactly the number of columns you want to read.
    If the value is not exact, then the REASD MATRIX command will
    not give the expected results.

    The default value is 100 columns.

Note:
    If you are reading a large number of columns, you may need
    to enter the following command

          MAXIMUM RECORD LENGTH <value>

    with <value> denoting the maximum number of columns to read
    in the file.  The default value is 1024.

Note:
    Blank lines in data files are ignored.
 
Note:
    DATAPLOT supports the ability to embed comment lines within
    the data file.  Enter HELP COMMENT CHECK for details.
 
Note:
    In order to determine whether the first argument is a file name or
    a variable name, it looks for a period in the name.  If it finds
    one, it assumes a file name.  If it does not, it assumes a variable
    name.  If your file name does not contain a period, attach a
    trailing period (no spaces) to the file name on the READ command.
 
Note:
    DATAPLOT has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    DATAPLOT strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), DATAPLOT tries to open the file with
    the trailing period.  If this fails, it then tries to open the file
    with the trailing period stripped off.
 
    Some users prefer to give all data files a ".DAT" or ".dat"
    extension.  Although this is a useful method for keeping track of
    data files, it is strictly a user convention and is not enforced
    by DATAPLOT in any way.
 
Note:
    File names are case sensitive on Unix file systems.  For Unix,
    DATAPLOT attempts to open the file as given.  If this fails, it
    attempts to open the file as all upper case characters.  If this
    fails, it attempts to open the file as all lower case characters.
    All other currently supported systems are not case sensitive
    regarding file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    1) If no file name is specified and a CALL is being executed, then
       the data values should be listed directly in the DATAPLOT
       sub-program immediately after the READ MATRIX command (do not
       forget the END OF DATA statement).
    2) If no file name is specified and commands are being manually
       entered/executed one at a time from the terminal, then the data
       should be entered directly from the terminal immediately after
       the READ MATRIX command (also terminated by an END OF DATA
       statement).
 
Synonyms:
    None
 
Related Commands:
    MATRIX DEFINITION  = Copy variables into a matrix.
    SERIAL READ        = Perform a serial read.
    SET READ FORMAT    = Define a FORTRAN style format for reads.
    READ               = Read variables.
    READ PARAMETER     = Read a parameter.
    READ STRING        = Read a string.
 
Applications:
    Data I/O
 
Implementation Date:
    Pre-1987
 
Program:
    READ MATRIX M
    1 3 2
    7 3 1
    8 1 2
    END OF DATA
 
-----READ PARAMETER--------------------------------------------------
 
READ PARAMETER
 
Name:
    READ PARAMETER
 
Type:
    Support Command
 
Purpose:
    Reads a parameter into DATAPLOT:
       1) from a mass storage file; or
       2) from within a CALLed DATAPLOT sub-program; or
       3) from the terminal.
 
Description:
    The rules regarding READ PARAMETER are as follows:
       1) Only one line is read.  Unlike a READ of variables, no END
          OF DATA is searched for.
       2) If more than one parameter is read, enter them on the same
          line separated by one or more spaces.
       3) In scanning for the parameter, the full line image is scanned
          (for reading from a mass storage file, the full line image is
          132 columns; for reading from within a sub-program and for
          reading from the terminal, the full line image is 80
          columns).  For variations on this, see the COLUMN LIMITS
          command.
       4) Parameters can be free-format.  They need not be aligned in
          specific columns.
       5) All reads start from the beginning of the file (for
          variations of this, see the SKIP and ROW LIMITS commands).
 
Syntax 1:
    READ PARAMETER   <p1>   <p2>   ...   <p3>
    where <p1>, <p2>, ..., <pk> are the desired parameters.
 
    This syntax is used to read parameters from the terminal or from a
    DATAPLOT sub-program.
 
Syntax 2:
    READ PARAMETER   <file>   <p1>   <p2>   ...   <p3>
    where <file> is the name of the mass storage file where the
              parameters reside;
    and   <p1>, <p2>, ..., <pk> are the desired parameters.
 
    This syntax is used to read parameters from a file.
 
Examples:
    READ PARAMETER CALIB. P1 P2
    READ PARAMETER P
      5.2
 
Note:
    In order to determine whether the first argument is a file name or
    a variable name, it looks for a period in the name.  If it finds
    one, it assumes a file name.  If it does not, it assumes a variable
    name.  If your file name does not contain a period, attach a
    trailing period (no spaces) to the file name on the READ command.
 
Note:
    DATAPLOT has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    DATAPLOT strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), DATAPLOT tries to open the file with
    the trailing period.  If this fails, it then tries to open the file
    with the trailing period stripped off.
 
    Some users prefer to give all data files a ".DAT" or ".dat"
    extension.  Although this is a useful method for keeping track of
    data files, it is strictly a user convention and is not enforced
    by DATAPLOT in any way.
 
Note:
    File names are case sensitive on Unix file systems.  For Unix,
    DATAPLOT attempts to open the file as given.  If this fails, it
    attempts to open the file as all upper case characters.  If this
    fails, it attempts to open the file as all lower case characters.
    All other currently supported systems are not case sensitive
    regarding file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    1) If no file name is specified, and if a CALL is being
       executed, then the parameter should be listed directly
       in the DATAPLOT sub-program immediately after the READ
       PARAMETER command.
    2) If no file name is specified, and if commands are being
       manually entered/executed 1-at-a-time from the terminal,
       then the parameter should be entered directly from the
       terminal immediately after the READ PARAMETER command.
 
Related Commands:
    SERIAL READ        = Perform a serial read.
    READ               = Read variables.
    READ FUNCTION      = Read a function.
    READ MATRIX        = Read a matrix.
    READ STRING        = Read a string.
    LET                = Define a parameter.
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
 
Program:
    READ PARAMETER A B C
    10  20  30
 
-----READ ROW---------------------------------------------------
 
READ ROW
 
Name:
    READ ROW
 
Type:
    I/O Command
 
Purpose:
    Reads row oriented data into variables.
 
Description:
    Dataplot is a column oriented system.  That is, columns denote
    variables while rows denote observations.

    Sometimes you may encounter data files that are row oriented, that
    is rows denote variables while columns denote observations.  This is
    often the case when the number of variables is significantly greater
    than the number of observations.

    The READ ROW command was added to better accomodate these types of
    data files.  With the ROW READ the file is read one row at a time
    and each row is added as a Dataplot variable.  Only a single
    variable name is given to READ ROW command.  This name serves as the
    "base name".  So if Y is the variable name given and there are 25
    rows of data, variables Y1, Y2, ..., Y25 will be created by the
    READ ROW command.

    The READ ROW command is only supported for numeric data.  However,
    the rows do not need to contain the same number of data values.

    If the maximum number of available columns is reached, the READ ROW
    command will be terminated.  However, any rows that have already been
    successfully read will still be retained.  If there in error in
    reading a specific row, that row will be skipped and Dataplot will go
    to the next row.

    The READ ROW command generates a limited amount of feedback.  It
    prints feedback for the first row read and the last row read only.
    If you want to see what variable names were created, you can enter
    the command

        STATUS VARIABLES  (or STATUS V)

Syntax 1:
    READ ROW <y>
    where <y> is the base name for the variables being read.
 
    This syntax is used to read from the terminal or from within a
    macro file.  All lines are read until an END OF DATA is
    encountered.

    In practice, READ ROW is not typically used for terminal reads.
    However, it does work.
 
Syntax 2:
    READ   <file>   <y>
    where <file> is the name of the file where the data resides;
    and where  <y> is the base name for the variables being read.

    This syntax is used to read from a file.  All lines are read until an
    END OF DATA is encountered, the physical end of file is encountered,
    or the maximum number of variables is reached.

Examples:
    READ ROW FILE.DAT Y
 
Note:
    By default, Dataplot does free format reads.  However, it has the
    capability for supporting Fortran style formats.  Formatted reads
    can be about 10 times faster on many systems which can be helpful
    for large data files.  Enter HELP READ FORMAT for more details.

    Note that Fortran formats are based on the decimal point lining up
    consistenly between rows.  Spreadsheet programs such as Excel tend to
    generate either right justified or left justified columns when
    generating fixed width ASCII files.  These are typically not
    consistent with Fortran formatted reads.

Note:
    Blank lines in data files are ignored.
 
Note:
    In order to determine whether the first argument is a file name or
    a variable name, it looks for a period in the name.  If it finds
    one, it assumes a file name.  If it does not, it assumes a variable
    name.  If your file name does not contain a period, attach a
    trailing period (no spaces) to the file name on the READ command.
 
Note:
    Dataplot does not assume specific extensions for file names.  Although
    using conventions (e.g., ".DAT" or ".TXT" for data files, ".DP" for
    Dataplot macros) can be helpful for distinguishing between types of
    files, this is more for the analysts convenience.  Dataplot itself
    does not enforce any conventions.

    File names have the following restrictions:

        1. The file name should be a valid file name for the local
           operating system.

        2. The file name should contain a period "." in the file name
           itself or as a trailing character.  Dataplot strips off trailing
           periods on those systems where it is appropriate to do so.  On
           systems where trailing periods can be a valid file name (e.g.,
           Unix), Dataplot tries to open the file with the trailing period.
           If this fails, it then tries to open the file with the trailing
           period stripped off.

        3. If the file name contains spaces or hyphens, then it needs to be
           enclosed in quotes.

        4. File names are currently limited to 80 characters.  This can
           in particular be a problem if the file name is contained within
           a long path name.  The following can be helpful in these cases.

           a. You can use the CD command to make the path where the file
              is stored the current directory.  This is most useful for
              data files.  For example,

                  pwd
                  cd  <path where data file resided>
                  read  file.dat ...
                  cd ^CURDIR

              The pwd command is used to save the current directory.  The
              cd command is then used to set the current directory to the
              path where the data resides, the read is performed, and then
              the cd command is used to restore the original working
              directory (the cd command saves the current path in the
              string CURDIR).

           b. You can use the SEARCH DIRECTORY command to specify an
              additional directory to search for file names.

Note:
    File names are case sensitive on Unix/Linux/Mac OS X systems.  For these
    systems, Dataplot attempts to open the file as given.  If this fails, it
    attempts to open the file as all upper case characters.  If this fails, it
    attempts to open the file as all lower case characters.
 
    As a further caution for Unix/Linux hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.

Default:
    1) If no file name is specified and a CALL is being executed, then
       the data values should be listed directly in the DATAPLOT
       sub-program immediately after the READ command (do not forget
       the END OF DATA statement).

    2) If no file name is specified and the commands are being manually
       entered/executed one at a time from the terminal, then the data
       should be entered directly from the terminal immediately after
       the READ command (also terminated by an END OF DATA statement).
 
Synonyms:
    None
 
Related Commands:
    READ                   = Read data into variables.
    SERIAL READ            = Perform a serial read.
    READ FUNCTION          = Read a function.
    READ MATRIX            = Read a matrix.
    READ PARAMETER         = Read a parameter.
    READ STRING            = Read a string.
    READ IMAGE             = Read an image format into numeric arrays.
    READ STACKED VARIABLE  = Read a list of variables into a single
                             response variable and a group-id variable.
    SET READ FORMAT        = Define a FORTRAN style format for reads.
    DATA (LET)             = Enter data values into a variable.
    CLIPBOARD              = Various commands for reading from the
                             system clipboard.
 
Applications:
    Data Input
 
Implementation Date:
    2018/10
 
Program:
    READ ROW Y
    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
    16 17 18 19 20 21 22 23 24 25
    END OF DATA
    SET WRITE DECIMALS 0
    PRINT Y1 Y2

-----READ ROW LABEL--------------------------------------------------
 
READ ROW LABEL
 
Name:
    READ ROW LABEL
 
Type:
    Support Command
 
Purpose:
    Reads row labels into DATAPLOT:
      1) from a mass storage file; or
      2) from within a CALLed DATAPLOT sub-program; or
      3) from the terminal.
 
Description:
    Row labels are primarily used for improved labeling.  For
    this initial implementation, the use of row labels is currently
    limited to labeling plot points via the CHARACTER ROWLABEL
    command.  However, the uses of row labels will expand
    in future implementations.

Syntax 1:
    READ ROW LABEL
 
    This syntax has no file name and no arguments.  Row labels
    are read from the terminal (one label per row) until an
    END OF DATA is entered.

Syntax 2:
    READ ROW LABEL <file name>
    where <file> is the name of the mass storage file where the
              row labels reside.
 
    This syntax reads the row label from the specified mass storage
    file.

Examples:
    SKIP 25
    COLUMN LIMITS 1 19
    READ ROW LABELS AUTO79.DAT
    COLUMN LIMITS
 
Note:
    The row labels may have up to 32 characters.
 
Note:
    The READ ROW LABELS command is almost always preceeded by
    a COLUMN LIMITS command.  That is, if the data file contains
    both a text label and data, then the file is typically read
    twice.  One read sets the column limits to cover the text
    for the row labels and the other sets the column limits
    to read the data.  Dataplot does not currently allow both
    the row labels and data to be read at the same time.
 
Note:
    In order to determine whether the first argument is a file name or
    a variable name, it looks for a period in the name.  If it finds
    one, it assumes a file name.  If it does not, it assumes a variable
    name.  If your file name does not contain a period, attach a
    trailing period (no spaces) to the file name on the READ command.
 
Note:
    DATAPLOT has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    DATAPLOT strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), DATAPLOT tries to open the file with
    the trailing period.  If this fails, it then tries to open the file
    with the trailing period stripped off.
 
    Some users prefer to give all data files a ".DAT" or ".dat"
    extension.  Although this is a useful method for keeping track of
    data files, it is strictly a user convention and is not enforced
    by DATAPLOT in any way.
 
Note:
    File names are case sensitive on Unix file systems.  For Unix,
    DATAPLOT attempts to open the file as given.  If this fails, it
    attempts to open the file as all upper case characters.  If this
    fails, it attempts to open the file as all lower case characters.
    All other currently supported systems are not case sensitive
    regarding file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    All row labels are blank.
 
Synonyms:
    None
 
Related Commands:
    READ                  = Read data.
    READ PARAMETER        = Read parameters.
    READ STRING           = Read strings..
 
Applications:
    Presentation Graphics
 
Implementation Date:
    2000/1
 
Program:
    SKIP 25
    COLUMN LIMITS 1 19
    READ ROW LABELS AUTO79.DAT
    COLUMN LIMITS 20 80
    READ AUTO79.DAT Y1 Y2
    CHARACTER ROWLABELS
    LINE BLANK
    PLOT Y1 VERSUS Y2

-----READ REWIND (SET)-------------------------------------------
 
READ REWIND (SET)
 
Name:
    READ REWIND (SET)
 
Type:
    Subcommand under SET
 
Purpose:
    Normally DATAPLOT reads file from the beginning.  This command
    specifies that files being read are not rewound (more specifically,
    when a read is performed, the file is left open at its current
    position).
 
Description:
    This can be useful when portions of a file are being read (e.g.,
    the analyst has identifier strings in a file stored one per line).
 
Syntax:
    SET READ REWIND   <ON/OFF>
    where ON specifies that the file is rewound before reading and OFF
             specifies that it is not rewound.
 
Examples:
    SET READ REWIND ON
    SET READ REWIND OFF
 
Default:
    Files are rewound before reading (i.e., ON).
 
Synonyms:
    None
 
Related Commands:
    READ            = Carries out a column-wise input of data.
    SERIAL READ     = Carries out a line-wise input of data.
    READ FUNCTION   = Read a function.
    READ PARAMETER  = Read a parameter.
    READ MATRIX     = Read a matrix.
    READ STRING     = Read a string.
    WRITE REWIND    = Specify file rewind when writing to file.
 
Applications:
    Input/Output
 
Implementation Date:
    88/3
 
Program:
    SET READ REWIND OFF
    LOOP FOR K = 1 1 50
        READ STRING STATES.DAT  S^K
    END OF LOOP
    SET READ REWIND ON
 
-----READ STACKED VARIABLES----------------------------------------
 
READ STACKED VARIABLES
 
Name:
    READ STACKED VARIABLES
 
Type:
    Input Command
 
Purpose:
    Reads a list of variables into a single response variable
    and a corresponding group-id variable.
 
Description:
    A number of Dataplot commands expect data in the form

       Y  X

    where Y is a response variable and X is a group-id variable.
    For example,

       BOX PLOT Y X
       MEAN PLOT Y X

    However, many data files are in the form where the data for
    each group is stored as a separate column.  The command
    READ STACKED VARIABLES can be used to read these files into
    the Y X format needed by many Dataplot commands.

Syntax:
    READ STACKED VARIABLES  <file>  <y>  <groupid>  <var-list>
    where <file> is the name of a data file;
          <y> is the response variable where the data will be
                 saved;
          <groupid> is a variable that identifies the group for
                 each row of the response variable;
     and  <var-list> is a list of one or more variables to read
                 from the data file.
 
     The file name is optional.  If the file name is omitted, the
     read will be from the terminal (until an END OF DATA is
     entered).

     The first variable read will have a group-id value of 1,
     the second variable read will have a group-id value of 2
     and so on.

Examples:
    READ STACKED VARIABLES FILE.DAT  Y GROUP X1 X2
    READ STACKED VARIABLES FILE.DAT  Y GROUP X1 X2 X3
    READ STACKED VARIABLES FILE.DAT  Y GROUP X1 X2 X3 X4
 
Note:
    This command is similar to the READ MATRIX TO VARIABLES
    command.  The distinction is that the READ MATRIX TO VARIABLES
    returns both a row-id and a column-id variable.  The
    READ STACKED VARIABLES just returns a group-id variable
    (i.e., a column-id).

    The STACK command is also similar.  However, it works on
    variables that have already been read into Dataplot.

Note:
    By default, DATAPLOT does free format reads.  However, it has the
    capability for supporting FORTRAN style formats.  Formatted reads
    can be about 10 times faster on many systems.   This can be helpful
    for large data files.  Enter HELP READ FORMAT for more details.
 
Note:
    Blank lines in data files are ignored.
 
Note:
    DATAPLOT supports the ability to embed comment lines within
    the data file.  Enter HELP COMMENT CHECK for details.
 
Note:
    In order to determine whether the first argument is a file name or
    a variable name, it looks for a period in the name.  If it finds
    one, it assumes a file name.  If it does not, it assumes a variable
    name.  If your file name does not contain a period, attach a
    trailing period (no spaces) to the file name on the
    READ STACKED VARIABLES command.
 
Note:
    DATAPLOT has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    DATAPLOT strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), DATAPLOT tries to open the file with
    the trailing period.  If this fails, it then tries to open the file
    with the trailing period stripped off.
 
    Some users prefer to give all data files a ".DAT" or ".dat"
    extension.  Although this is a useful method for keeping track of
    data files, it is strictly a user convention and is not enforced
    by DATAPLOT in any way.
 
Note:
    File names are case sensitive on Unix file systems.  For Unix,
    DATAPLOT attempts to open the file as given.  If this fails, it
    attempts to open the file as all upper case characters.  If this
    fails, it attempts to open the file as all lower case characters.
    All other currently supported systems are not case sensitive
    regarding file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STACK                    = Convert a set of response variables to
                               a single response variable and a
                               group-id variable.
    READ MATRIX TO VARIABLES = Read a matrix into a single response
                               variable.
    READ IMAGE TO VARIABLES  = Read an image into variables.
    READ                     = Read variables.
    SERIAL READ              = Perform a serial read.
    READ MATRIX              = Read matrix data.
    READ PARAMETER           = Read a parameter.
    READ STRING              = Read a string.
    SET READ FORMAT          = Define a FORTRAN style format for
                               reads.
 
Applications:
    Data Input
 
Implementation Date:
    2008/3
 
Program:
    SKIP 25
    READ STACKED VARIABLES MONTGOME.DAT  Y GROUP X1 X2 X3
    .
    TITLE Mean Plot
    TITLE OFFSET 2
    TITLE CASE ASIS
    XLIMITS 1 3
    TIC OFFSET UNITS DATA
    XTIC OFFSET 0.5  0.5
    MAJOR XTIC MARK NUMBER 3
    MINOR XTIC MARK NUMBER 0
    XTIC MARK LABEL FORMAT ALPHA
    XTIC MARK LABEL CONTENT Large Medium Small
    TIC MARK LABEL CASE ASIS
    Y1LABEL Mean Percentage
    X1LABEL Group
    LABEL CASE ASIS
    CHARACTER X BLANK
    LINE BLANK SOLID
    .
    MEAN PLOT Y GROUP
 
-----READ STRING--------------------------------------------------
 
READ STRING
 
Name:
    READ STRING
 
Type:
    Support Command
 
Purpose:
    Reads a string into DATAPLOT:
       1) from a mass storage file; or
       2) from within a CALLed DATAPLOT sub-program; or
       3) from the terminal.
 
Description:
    The rules regarding READ STRING are as follows:
       1) Only one line is read.  Unlike a READ of variables, no
          END OF DATA is searched for.
       2) Typically, only one string is read at a time.  Reading more
          than one STRING is allowed (but not recommended).  If more
          than STRING is read from the same line, separate the strings
          with at least one space and leave no spaces within a given
          string.  For example,
             READ STRING S1 S2
             String1    String2
       3) In scanning for the string, the full line image is scanned
          (for reading from a mass storage file, the full line image
          is 132 columns; for reading from within a sub-program and
          for reading from the terminal, the full line image is 80
          columns).  For variations on this, see the COLUMN LIMITS
          command.
       4) If one string is read, embedded blanks are included in the
          string.  However, if more than one string is read, blanks
          are used to separate the strings.
       5) All reads start from the beginning of the file (for
          variations of this, see the SKIP and ROW LIMITS commands).
 
Syntax 1:
    READ STRING   <s1>   <s2>   ...    <sk>
    where <s1>, <s2>, ..., <sk> are the desired strings (typically
              only one is given).
 
    This syntax is used to read strings from the terminal or from a
    DATAPLOT sub-program.
 
Syntax 2:
    READ STRING   <file>   <s1>   <s2>   ...    <sk>
    where <file> is the name of the mass storage file where the
              strings reside;
    and   <s1>, <s2>, ..., <sk> are the desired strings (typically
              only one is given).
 
    This syntax is used to read strings from a file.
 
Examples:
    READ STRING CALIB. S
    READ STRING S
      This is a sample string
 
Note:
    The LET command can also be used to define a string (e.g.,
    LET S = STRING THIS IS A STRING).  However, there is one important
    distinction.  The LET command automatically converts the string to
    upper case while the READ STRING command preserves the case that
    is read.
 
Note:
    In order to determine whether the first argument is a file name or
    a variable name, it looks for a period in the name.  If it finds
    one, it assumes a file name.  If it does not, it assumes a variable
    name.  If your file name does not contain a period, attach a
    trailing period (no spaces) to the file name on the READ command.
 
Note:
    DATAPLOT has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    DATAPLOT strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), DATAPLOT tries to open the file with
    the trailing period.  If this fails, it then tries to open the file
    with the trailing period stripped off.
 
    Some users prefer to give all data files a ".DAT" or ".dat"
    extension.  Although this is a useful method for keeping track of
    data files, it is strictly a user convention and is not enforced
    by DATAPLOT in any way.
 
Note:
    File names are case sensitive on Unix file systems.  For Unix,
    DATAPLOT attempts to open the file as given.  If this fails, it
    attempts to open the file as all upper case characters.  If this
    fails, it attempts to open the file as all lower case characters.
    All other currently supported systems are not case sensitive
    regarding file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    1) If no file name is specified and a CALL is being executed, then
       the string should be listed directly in the DATAPLOT
       sub-program immediately after the READ STRING command.
    2) If no file name is specified and commands are being manually
       entered/executed one at a time from the terminal, then the
       string should be entered directly from the terminal immediately
       after the READ STRING command.
 
Related Commands:
    SERIAL READ        = Perform a serial read.
    READ               = Read variables.
    READ FUNCTION      = Read a function.
    READ PARAMETER     = Read a parameter.
    READ MATRIX        = Read a matrix.
    LET                = Define a string.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    SET READ REWIND OFF
    LOOP FOR K = 1 1 50
        READ STRING STATES.DAT  S^K
    END OF LOOP
    SET READ REWIND ON
 
-----RF (LET)----------------------------------------------
 
RF
 
Name:
    RF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute Carlson's elliptic integral of the first kind.
 
Description:
    Carlson's elliptic integral of the first kind is defined as:
        RF(x,y,z)=0.5*INTEGRAL[1/SQRT((t+x)*(t+y)*(t+z))]dt
    where INTEGRAL is the integral from 0 to infinity.  The parameters
    x, y, and z must all be non-negative with at most one of them
    being zero.

Syntax:
    LET <a> = RF(<x>,<y>,<z>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, parameter, or variable;
          <y> is a non-negative number, parameter, or variable;
          <z> is a non-negative number, parameter, or variable;
          <a> is a variable or a parameter (depending on what <x>,
               <y>, and <z> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RF(2,1,3)
    LET A = RF(X,0,4)
    LET X2 = RF(1,1,Y)
 
Note:
    The Carlson elliptic integrals are computed using the RC, RD, RF,
    and RJ routines from the SLATEC Common Mathematical Library.
    SLATEC is a large set of high quality, portable, public domain
    Fortran routines for various mathematical capabilities maintained
    by seven federal laboratories.

Note:
    DATAPLOT computes Legendre elliptic integrals by computing the
    equivalent Carlson elliptic integrals.  See the documentation for
    the ELLIP1, ELLIP2, ELLIP3, ELLIPC1, and ELLIPC2 functions for
    details on computing Legendre elliptic functions in DATAPLOT.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RC      = Compute the degenerate Carlson elliptic integral.
    RD      = Compute the Carlson elliptic integral of the second kind.
    RF      = Compute the Carlson elliptic integral of the first kind.
    RJ      = Compute the Carlson elliptic integral of the third kind.
    ELLIPC1 = Compute the Legendre complete elliptic integral of the
              first kind.
    ELLIPC2 = Compute the Legendre complete elliptic integral of the
              second kind.
    ELLIP1  = Compute the Legendre elliptic integral of the first
              kind.
    ELLIP2  = Compute the Legendre elliptic integral of the second
              kind.
    ELLIP3  = Compute the Legendre's elliptic integral of the third
              kind.
 
Reference:
    "Algorithms for Incomplete Elliptic Integrals by Duplication", 
    Carlson, ACM Transactions on Mathematical Software, 7,
    pp. 398-403.

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 17).

Applications:
    Special Functions
 
Implementation Date:
    94/9
 
Program:
    TITLE CARLSON ELLIPTIC FUNCTIONS
    PLOT RF(X,1,2) FOR X = 0.1 0.1 10 AND
    PLOT RF(1,X,2) FOR X = 0.1 0.1 10 AND
    PLOT RF(1,2,X) FOR X = 0.1 0.1 10
    
 
-----RECCDF (LET)--------------------------------
 
RECCDF
 
Name:
    RECCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reciprocal probability density function.
 
Description:
    The probability density function is:
       f(x.b) = 1/(x*LOG(b))       for 1/b <= x < 1,  b > 1
    where b is the shape parameter.  The formula for the cumulative
    distribution function is:
       F(x,b) = (LOG(x) + LOG(b))/LOG(b)   for 1/b <= x < 1, b > 1
 
Syntax:
    LET <y> = RECCDF(<x>,<b>)   <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed reciprocal cdf value is saved;
          <b> is a number, parameter, or variable that specifies
               the shape parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RECCDF(0.5,1.5)
    LET X2 = RECCDF(X1,B)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RECPDF = Compute the reciprocal probability density function.
    RECPPF = Compute the reciprocal percent point function.
    BRACDF = Compute the Bradford cumulative distribution function.
    BRAPDF = Compute the Bradford probability density function.
    BRAPPF = Compute the Bradford percent point function.
    BETCDF = Compute the beta cumulative distribution function.
    BETPDF = Compute the beta probability density function.
    BETPPF = Compute the beta percent point function.
 
Reference:
    "Numerical Methods for Scientists and Engineers", 2nd. Ed., 
    Hamming, Dover Publications, 1973.
 
Applications:
    Data Analysis
 
Implementation Date:
    96/5
 
Program:
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE AUTOMATIC
    X1LABEL X
    Y1LABEL PROBABILITY
    LET B = 10
    X1LABEL  BETA = ^B
    PLOT RECCDF(X,B) FOR X = 0.1 0.01 0.99
    LET B = 100
    X1LABEL  BETA = ^B
    PLOT RECCDF(X,B) FOR X = 0.01 0.01 0.99
    LET B = 5
    X1LABEL  BETA = ^B
    PLOT RECCDF(X,B) FOR X = 0.2 0.01 0.99
    LET B = 2
    X1LABEL  BETA = ^B
    PLOT RECCDF(X,B) FOR X = 0.5 0.01 0.99
    END OF MULTIPLOT
 
-----RECIPE---------------------------------------------
 
RECIPE
 
Name:
    RECIPE
 
Type:
    Analysis Command
 
Purpose:
    Compute REgression Confidence Intervals on PErcentiles
    (RECIPE).
 
Description:
    RECIPE is used to compute approximate one-sided tolerance
    limits (or equivalently, confidence intervals on 
    percentiles) for a wide range of situations where one is
    able to assume a normal probability model.  Arbitrary
    regression models with or without a random effect can be
    analyzed.  It is this ability to accomodate between batch
    variability that makes the RECIPE code perhaps unique.

    The development of RECIPE was motivated for use in
    determining design allowables for composite materials in
    aircraft applications, particularly in the prescence of
    between-batch variability.

    Note that an A-basis value is a (0.99,0.95) lower tolerance
    limit and a B-basis value is a (0.90,0.95) lower tolerance
    limit.  Alternatively A- and B-basis values can be
    interpreted to be 95% lower confidence bounds on the 1st
    and 10th population percentiles respectively.

    In Dataplot, the A BASIS and B BASIS commands can be used
    to compute A-basis and B-basis values for univariate
    data for normal, lognormal, and Weibull distributions.

    RECIPE is used to calculate basis values for regression
    models with or without a random batch effect.  This
    methodology was developed by NIST statistician Mark Vangel
    as part of his involvement with MIL-HDBK-17E (or MIL-17
    Handbook).  Dataplot adapted source code provided by
    Mark Vangel to implement this command within Dataplot.

    More formally, let

       y = X*theta + Z*b + e

    denote a mixed model with two components of variance.  The
    fixed part of the model is X*theta, where X is an nxr 
    known matrix having l <= n distinct rows and theta is an
    unkown rXl vector.  The random part is Z*b + e where Z
    is an nxm known matrix of zeros and ones, 
    b follows a normal distribution with mean zero and standard
    deviation sigma(b)**2*I(m), and e follows a normal
    distribution with mean zero and standard deviation
    sigma(e)**2*I(n).  Let w be an arbitrary rx1 vector, and
    assume (w**T)*theta, sigma(b)**2, and sigma(e)**2 are
    estimable.  RECIPE uses y to obtain approximate one-sided
    beta-content tolerance intervals for the population
    U where U follows a normal distribution with mean
    (w**T)*theta and standard deviation 
    sigma(b)**2 + sigma(e)**2.

    A complete discussion of this methodolgy is available at
    the following web site (including the original Fortran
    source code):

       http://www.itl.nist.gov/div898/software/recipe/

    These web pages discuss both the mathematical model
    for RECIPE and its application to real problems.  
    Additional discussion is contained in the papers listed
    in the Reference section.  The example programs below
    give some typical applications of RECIPE.

    Note that the input model for the original Fortran
    implementation of RECIPE is different than the Dataplot
    implementation.

    RECIPE is typically preceeded by a regression or ANOVA
    analysis.  RECIPE is then typically applied to the final
    regression or ANOVA model.  RECIPE supports the following
    types of models:

       1) 1-factor regression (including polynomial models)
       2) multi-factor regression
       3) multi-factor ANOVA

    RECIPE is generally used in the context of the MIL-17
    Handbook standards for obtaining A- and B-basis material
    property values.  

    The primary output from the RECIPE command is a set of
    tolerance values.
 
Syntax 1:
    RECIPE FIT  <y> <x> <batch> <xpred> 
                            <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the independent variable;
          <batch> is a batch identifier variable;
          <xpred> is a variable containing the points at
              which the tolerances are calculated;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for linear regression and polynomial
    models.
 
    The degree of the fit can be specified by entering the
    following command before the RECIPE FIT command:

    RECIPE FIT DEGREE <N>
    where <N> is a positive integer that specifies the degree 
          polynomial to fit (usually 1 or 2, but higher degrees
          are allowed).

    If the RECIPE FIT DEGREE command is not entered, a linear
    fit is assumed.

Syntax 2:
    RECIPE FIT  <y> <x1 ... xk> <batch> <xpred1 ... xpredk> 
                            <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x1 ... xk> is a list of one or more independent
              variables;
          <batch> is a batch identifier variable;
          <xpred1 ... xpredk> is a list of one or more variables
              containing the points at which the tolerances are
              calculated;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the multilinear regression case.

Syntax 3:
    RECIPE ANOVA  <y> <x1> ... <xk> <batch>
                            <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x1> ... <xk> are the k independent variables;
          <batch> is a batch identifier variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for multilinear and ANOVA models.
 
    The <batch> variable is optional.  To specify whether or not
    the last variable is a batch variable or one of the factor
    variables, enter the following command:

    RECIPE FACTORS <N>
    where <N> is a positive integer that specifies the number 
          of factor (indpendent) variables on the RECIPE ANOVA
          command.

Examples:
    RECIPE ANOVA Y X BATCH
    RECIPE ANOVA Y X BATCH  SUBSET BATCH = 1 TO 3

    RECIPE FIT Y X BATCH X2
    RECIPE FIT Y X1 X2 BATCH X1P X2P

Note:
    By default, Dataplot compute a 95% confidence interval for the
    90% coverage interval (i.e., the 10th percentile).

    To change the confidence interval calculated, enter

        RECIPE CONFIDENCE <val>

    where <val> defines the desired confidence.  Typical values
    are 0.95, 0.90, or 0.99.

    To change the coverage interval, enter

        RECIPE PROBABILITY CONTENT <val>
 
    where <val> defines the desired coverage.  Typical values are
    0.90 and 0.99.

Note:
    By default, the tolerance values outout from the RECIPE commands
    are automatically saved in the internal variable TOL.  If you
    want to save these values in a variable with a different name,
    then enter the following command before the RECIPE FIT or
    RECIPE ANOVA command:

       RECIPE OUTPUT <varname>

    where <varname> is the desired variable name.  Note that after
    the RECIPE FIT or RECIPE ANOVA command, this variable can be
    used like any other Dataplot variable.

Note:
    If the between batch variance is zero, then tolerance limits
    produced by RECIPE are exact.  However, when between batch
    variability exists, the actual confidence level will depend on
    the ratio of between batch variability and to within batch
    variability sigma(b)**2/sigma(e)**2, or equivalently, to
    the intraclass correlation

         p = sigma(b)**2/(sigma(b)**2 + sigma(e)**2)

    The intraclass correlation is the correlation between
    observations from the same batch.

    The nuisance parameter p is unknown and typically the number
    of batches is too small to even estimate it well.  We would
    like to have a tolerance limit procedure for which the
    actual confidence interval equals the nominal level, whatever
    p might be.  Although this goal is probably unobtainable in
    general, one can come extremely close for certain simple
    regression models.  RECIPE provides tolerance intervals for
    which the confidence levels do not depend strongly on p,
    and for which the actual confidence is generally fairly close
    to the nominal level.

    In order to determine how close the actual and nominal
    confidence levels are, it is necessary to simulate.  The
    following commands

         RECIPE SIMCOV FIT
         RECIPE SIMCOV ANOVA

    correspond to the RECIPE FIT and RECIPE ANOVA commands and
    can be used to simulate the actual confidence.  The
    RECIPE SIMCOV commands have the same syntax as the RECIPE
    commands.

    The output from the RECIPE SIMCOV commands is a column of
    values for p with the corresponding actual confidence
    level.  One can expect this command to show that the RECIPE
    intervals are conservative when p is near zero, somewhat
    anticonservative for intermediate values of p, and nearly
    exact for p near 1.  For highly unbalanced data, the
    confidence may vary substatially from the nominal level
    when p=1.

    If the actual confidence levels differ too substantially
    from the nominal levels, this indicates that a
    Satterthwaite approximation used by RECIPE is not
    adequate and can be improved upon by replacing the
    Satterthwaite approximation with the appropriate quantile
    of a simulated pivotal random variable.  By doing this,
    one can obtain an actual confidence level that is nearly
    exact for p=1 and typically better than Satterthwaite
    approximation for intermediate values of p as well.

    If the RECIPE SIMCOV command shows that the Satterthwaite
    approximation is not adequate, enter the following command
    to use simulated pivotal values instead:

         RECIPE SATTERTHWAITE NO

    To restore the use of Satterthwaite approximation, enter
 
         RECIPE SATTERTHWAITE NO

    To control the number of correlation values at which to
    compute SIMCOV probabilites, enter

         RECIPE CORRELATION <n>

    where <n> is the desired number of values.  The default
    is 11 (that is, p = 0, 0.1, 0.2, 0.3, ... , 0.9 1.0).

    To control the number of replicates used in computing the
    SIMCOV confidence levels, enter 

         RECIPE SIMCOV REPLICATES <n>

    where <n> is the number of replicates.  The default is 10,000.

    If Satterthwaite approximation is turned off (and simulated
    pivotal values are used instead), the number of replicates used
    in computing the simulated pivotal values can be specified 
    by entering the command

         RECIPE SIMPVT REPLICATES <n>

    where <n> is the number of replicates.  The default is 10,000.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    FIT                     = Perform a lest squares fit.
    ANOVA                   = Perform an ANOVA.
    BASIS TOLERANCE LIMITS  = Generate A- and B-basis tolerance
                              limits.
    TOLERANCE LIMITS        = Generate tolerance limits for the mean.
    ANDERSON-DARLING K      = Perform an Anderson-Darling k sample
       SAMPLE TEST            test.
    ANDERSON-DARLING TEST   = Perform an Anderson-Darling goodness
                              of fit test.
    GRUBBS TEST             = Perform Grubbs test for outliers.
 
References:
    "MIL-HDBK-17 Volume 1: Guidelines for Characterization of
    Structural Materials", Depeartment of Defense, chapter 8.
    The URL for MIL-HDBK-17 is http://mil-17.udel.edu/.
 
    "A User's Guide to RECIPE: A FORTRAN Program for Determining
    One-Sided Tolerance Limits for Mixed Models With Two
    Components of Variance Version 1.0", Mark Vangel, 
    unpublished document available online at
    http://www.itl.nist.gov/div898/software/recipe/recidoc.pdf.

    "New Methods for One-Sided Tolerance Limits for a One-Way
    Balanced Random Effects ANOVA Model", Mark Vangel,
    Technometrics, Vol. 34, 1992, pp. 176-185.

    "One-Sided B-Content Tolerance Limits for Mixed Models
    with Two Components of Variance", Mark Vangel,
    Technometrics, submitted.
 
    "Design Allowables From Regression Models Using Data From
    Several Batches", Mark Vangel, 12th Symposium on Composite
    Materials: Testing and Design, American Society of Testing
    and Materials, 1996.

Applications:
    Materials Science
 
Implementation Date:
    1997/9
 
Program 1: (UNIVARIATE EXAMPLE)
    . The complete analysis can be viewed by:
    .     LIST VANGEL31.DP
    . RECIPE Tolerance Limits Analysis of Graphite/Epoxy Tape Strength
    . Univariate Case
    . ------------------------
    . Step 1--Read in the data
    .
    skip 25
    read vangel31.dat y
    . ------------------------------------------------
    . Step 6--Compute (recipe/normal) tolerance limits
    .
    recipe content 90
    recipe confidence 95
    recipe factors 1
    let n = size y
    let x = 1 for i = 1 1 n
    let b = 1 for i = 1 1 n
    recipe anova y x b
    .
    let tol1 = tol(1)
    relative histogram y
    drawdata tol1 0 tol1 +.01
 
Program 2: (NON-LINEAR EXAMPLE)
    . The complete analysis can be viewed by:
    .     LIST VANGEL32.DP
    . RECIPE Tolerance Limits Analysis of Graphite/Epoxy Tape Strength
    . Regression Case
    . Date--September 1997
    .
    . ------------------------
    . Step 1--Read in the data
    .
    skip 25
    read vangel32.dat y x b
    .
    . ------------------------------------------------
    . Step 6--Compute (recipe/normal) tolerance limits
    .
    recipe content 90
    recipe confidence 95
    recipe degree 1
    let x2 = sequence -75 25 200
    recipe fit y x b x2
    .
    .
    characters x blank box
    lines blank solid dotted
    plot y pred versus x and
    plot tol versus x2
 
Program 3: (ANOVA EXAMPLE)
    . The complete analysis can be viewed by:
    .     LIST VANGEL33.DP
    . RECIPE Tolerance Limits Analysis of Graphite/Epoxy Fabric Strength
    . ANOVA Case
    . Date--September 1997
    .
    . ------------------------
    . Step 1--Read in the data
    .
    skip 25
    read vangel33.dat y x b
    .
    . ------------------------------------------------
    . Step 6--Compute (recipe/normal) tolerance limits
    .
    recipe content 90
    recipe confidence 95
    recipe factors 1
    recipe anova y x b
    .
    characters x blank box
    lines blank blank blank
    xtic offset 0.3 0.3
    major xtic mark number 2
    minor xtic mark number 0
    plot y pred versus x and
    plot tol versus x

-----RECPDF (LET)--------------------------------
 
RECPDF
 
Name:
    RECPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reciprocal probability density function.
 
Description:
    The probability density function is:
       f(x.b) = 1/(x*LOG(b))       for 1/b <= x < 1,  b > 1
    where b is the shape parameter.
 
Syntax:
    LET <y> = RECPDF(<x>,<b>)   <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed reciprocal pdf value is saved;
          <b> is a number, parameter, or variable that specifies
               the shape parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RECPDF(0.5,1.5)
    LET X2 = RECPDF(X1,B)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RECCDF = Compute the reciprocal cumulative distribution function.
    RECPPF = Compute the reciprocal percent point function.
    BRACDF = Compute the Bradford cumulative distribution function.
    BRAPDF = Compute the Bradford probability density function.
    BRAPPF = Compute the Bradford percent point function.
    BETCDF = Compute the beta cumulative distribution function.
    BETPDF = Compute the beta probability density function.
    BETPPF = Compute the beta percent point function.
 
Reference:
    "Numerical Methods for Scientists and Engineers", 2nd. Ed., 
    Hamming, Dover Publications, 1973.
 
Applications:
    Data Analysis
 
Implementation Date:
    96/5
 
Program:
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE AUTOMATIC
    X1LABEL X
    Y1LABEL PROBABILITY
    LET B = 10
    X1LABEL  BETA = ^B
    PLOT RECPDF(X,B) FOR X = 0.1 0.01 0.99
    LET B = 100
    X1LABEL  BETA = ^B
    PLOT RECPDF(X,B) FOR X = 0.01 0.01 0.99
    LET B = 5
    X1LABEL  BETA = ^B
    PLOT RECPDF(X,B) FOR X = 0.2 0.01 0.99
    LET B = 2
    X1LABEL  BETA = ^B
    PLOT RECPDF(X,B) FOR X = 0.5 0.01 0.99
    END OF MULTIPLOT
 
-----RECPPF (LET)--------------------------------
 
RECPPF
 
Name:
    RECPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reciprocal probability density function.
 
Description:
    The probability density function is:
       f(x.b) = 1/(x*LOG(b))       for 1/b <= x < 1,  b > 1
    where b is the shape parameter.  The formula for the percent
    point function is:
       G(p,b) = EXP(LOG(b)*(p-1))          for 0 <= p < 1, b > 1
 
Syntax:
    LET <y> = RECPPF(<p>,<b>)   <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, a number, or a parameter in the 
               range (0,1);
          <y> is a variable or a parameter (depending on what <p> is)
               where the computed reciprocal ppf value is saved;
          <b> is a number, parameter, or variable that specifies
               the shape parameter;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RECPPF(0.5,1.5)
    LET X2 = RECPPF(P,B)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RECCDF = Compute the reciprocal cumulative distribution function.
    RECPDF = Compute the reciprocal probability density function.
    BRACDF = Compute the Bradford cumulative distribution function.
    BRAPDF = Compute the Bradford probability density function.
    BRAPPF = Compute the Bradford percent point function.
    BETCDF = Compute the beta cumulative distribution function.
    BETPDF = Compute the beta probability density function.
    BETPPF = Compute the beta percent point function.
 
Reference:
    "Numerical Methods for Scientists and Engineers", 2nd. Ed., 
    Hamming, Dover Publications, 1973.
 
Applications:
    Data Analysis
 
Implementation Date:
    96/5
 
Program:
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE AUTOMATIC
    Y1LABEL X
    X1LABEL PROBABILITY
    LET B = 10
    X1LABEL  BETA = ^B
    PLOT RECPPF(P,B) FOR P = 0 0.01 0.99
    LET B = 100
    X1LABEL  BETA = ^B
    PLOT RECPPF(P,B) FOR P = 0 0.01 0.99
    LET B = 5
    X1LABEL  BETA = ^B
    PLOT RECPPF(P,B) FOR P = 0 0.01 0.99
    LET B = 2
    X1LABEL  BETA = ^B
    PLOT RECPPF(P,B) FOR P = 0 0.01 0.99
    END OF MULTIPLOT
 
-----REGION BASE-------------------------------------------------------
 
REGION BASE
 
Name:
    REGION BASE
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the base location for regions on plots.
 
Description:
    On a plot, a region is defined as the figure formed by the line
    connecting points belonging to a common trace and a region base
    (typically zero).  The REGION FILL command can be used to generate
    a solid fill or a cross-hatch fill of this region.  The attributes
    of the fill are set with additional REGION commands (see the
    RELATED COMMANDS section below).  The attributes of the region
    border are set with LINE, LINE COLOR, and LINE THICKNESS commands.
 
    There are 3 special cases for the region base.  Specifying REGION
    BASE POLYGON specifies that the points in the trace form a closed
    polygon.  DATAPLOT automatically connects the first and last point
    if they are not already the same.  This option is useful for
    drawing filled 2d polygons with the standard PLOT command.  Drawing
    statistical maps is one application of this.  The PROGRAM 2 example
    demonstrates this case.
 
    The REGION BASE AUTOMATIC and REGION BASE INTERPOLATE commands
    are typically used together to fill in the area between 2 curves.
    The REGION BASE AUTOMATIC command specifies a variable to be used
    as arguments for the REGION BASE command which allows a moving
    region base between points.  However, in the case of filling the
    area between curves, the base is not horizontal between points.
    The REGION BASE INTERPOLATE command specifies that the base should
    be drawn to connect pairs of base points.  The PROGRAM 3 example
    shows how these two commands can be used to draw two curves with
    the are between them filled.  The key trick in this macro is to
    define each consecutive pair of points on the second curve as a
    single trace.  Generally, it is better practice to explicitly plot
    differences than it is to draw filled area curves.
 
    The REGION AUTOMATIC and REGION BASE INTERPOLATE commands are
    actually not needed because the REGION BASE POLY command supports
    the capability they provide in a simpler manner.  The PROGRAM 4
    example generates the same plot as the PROGRAM 3 example, but it
    uses the REGION BASE POLY command.
 
Syntax 1:
    REGION BASE  <number>  <number>  <number>  etc.
    where <number> is a decimal number or trace that specifies the
              desired region base.  Up to 100 region bases can be
              specified.
 
Syntax 2:
    REGION BASE POLYGON <ON/OFF> <ON/OFF> etc.
    where ON specifies that the trace is treated as a closed polygon
              while OFF specifies that it is not.  Up to 100 region
              bases can be specified.
 
Syntax 3:
    REGION BASE  AUTOMATIC <var>
    where <var> is a variable whose elements are used as arguments to
              the REGION BASE command.
 
Syntax 2:
    REGION BASE INTERPOLATE <ON/OFF> <ON/OFF> etc.
    where ON specifies that the region base is drawn between the
             entered values for 2 consecutive bases while OFF
             specifies that it is not.  Up to 100 region bases can be
             specified.
 
Examples:
    REGION BASES 0. 0. 10.
    REGION BASES 20. 20. 20.
    REGION BASES 0. ALL
    REGION BASES ALL 0.
    REGION BASES
    REGION BASE POLYGON ON
    REGION BASE INTERPOLATE ON
    REGION BASE AUTOMATIC Y1
 
Note:
    The REGION BASE command with no arguments sets the region base to
    zero for all regions.  The REGION BASE command with the word ALL
    before or after the specified base assigns that region base to all
    regions; thus REGION BASE 0. ALL or REGION BASE ALL 0. uses a base
    of 0. for all regions.  The REGION, BAR, SPIKE, CHARACTER, and LINE
    switch all work independently of each other.  That is, a plot point
    can be a line, a character, a region, a spike or a bar or any
    combination of the above.
 
Default:
    All region bases are 0.0.
 
Synonyms:
    None
 
Related Commands:
    PLOT                   = Generates a data or function plot.
    REGION FILL            = Sets the on/off switches for region fills.
    REGION FILL COLOR      = Sets the color for solid region fills.
    REGION PATTERN         = Sets the types for region fill patterns.
    REGION PATTERN COLOR   = Sets the color for hatched region fills.
    REGION PATTERN LINE    = Sets the line types for region fill
                             patterns.
    REGION PATTERN SPACING = Sets the line spacing for region fill
                             patterns.
    REGION PATTERN THICK   = Sets the line thickness for region fill
                             patterns.
    LINE BORDER COLOR      = Sets the color for region border lines.
    LINE BORDER LINE       = Sets the types for region border lines.
    LINE BORDER THICKNESS  = Sets the line thickness for region border
                             lines.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    XX
 
    The REGION BASE POLYGON option was added 94/4.
 
    The REGION BASE AUTOMATIC and REGION BASE INTERPOLATE commands and
    the ability to do hatch fills of non-rectangular regions were
    added 93/10.
 
Program 1:
    LET FUNCTION F = SHIFT + AMPL*SIN(PERIOD*X+PHASE)
    LET SHIFT = 3
    LET AMPL = 2
    LET PERIOD = 0.5
    LET PHASE = PI
    .
    REGION FILL ON
    REGION BASE SHIFT
    .
    TITLE SINE WAVE
    LET MIN = -2*PI
    LET MAX = 2*PI
    XLIMITS -7 7
    PLOT F FOR X = MIN 0.1 MAX
 
Program 2:
    SKIP 25
    READ TEXAS.DAT X Y
    .
    FRAME OFF
    FRAME CORNER COORDINATES 5 5 95 95
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    PRE-SORT OFF
    PLOT Y X
    PRE-SORT ON
    REGION BASE POLYGON
    REGION FILL ON
    PLOT Y X
    REGION PATTERN COLOR G25
    PLOT Y X
    REGION PATTERN D1D2
    REGION PATTERN SPACING 5
    PLOT Y X
    END OF MULTIPLOT
 
Program 3:
    . PERCENTAGE BELOW POVERTY LEVEL
    . SOURCE: "SOCIAL INDICATORS 1976", US CENSUS BUREAU
    . Y1 = AGES 22-42    Y2 = AGES 65+
    .
    LET Y1 = DATA 9.8 9.1 8.2 7.7 8.3 8.5 8.2 7.6 7.7 8.8
    LET Y2 = DATA 28.5 29.5 25.0 25.3 24.5 21.6 18.6 16.3 14.6 15.3
    LET N = SIZE Y1
    .
    XLIMITS 1 N; XTIC OFFSET 1 1
    MAJOR X1TIC MARK NUMBER N; MINOR X1TICMARK NUMBER 0
    X1TIC MARK FORMAT ALPHA
    X1TIC MARK CONTENT 66 67 68 69 70 71 72 73 74 75
    YLIMITS 0 30
    .
    PLOT Y1
    PRE-ERASE OFF
    LET N1 = N - 1
    LET N2 = N + 1
    .
    REGION BASE INTERPOLATION ON
    REGION BASE AUTOMATIC Y1
    REGION FILL ON ALL
    . CREATE X AND TAG VARIABLES
    LET X = SEQUENCE 1 1 N1
    LET NLAST = 2*N1
    LET X = SEQUENCE 2 1 N FOR I = N 1 NLAST
    LET TAG = SEQUENCE 1 1 N1 FOR I = 1 1 NLAST
    . CREATE Y VARIABLE
    LET JUNK = Y2
    DELETE JUNK(1)
    DELETE Y2(^N)
    EXTEND Y2 JUNK
    PLOT Y2 X TAG
 
Program 4:
    . PERCENTAGE BELOW POVERTY LEVEL
    . SOURCE: "SOCIAL INDICATORS 1976", US CENSUS BUREAU
    . Y1 = 22-42    Y2 = 65+
    .
    LET Y1 = DATA 9.8 9.1 8.2 7.7 8.3 8.5 8.2 7.6 7.7 8.8
    LET Y2 = DATA 28.5 29.5 25.0 25.3 24.5 21.6 18.6 16.3 14.6 15.3
    LET X = SEQUENCE 1966 1 1975
    LET XREV = X
    LET N = SIZE Y1
    LET INDX = SEQUENCE N -1 1
    LET INDX = SORTC INDX XREV Y2
    .
    EXTEND Y1 Y2
    EXTEND X XREV
    REGION BASE POLYGON
    REGION FILL ON ALL
    XLIMITS 1966 1975; XTIC OFFSET 1 1
    MAJOR X1TIC MARK NUMBER N; MINOR X1TICMARK NUMBER 0
    TITLE FILLED AREA PLOT
    PLOT Y1 X
 
-----REGION FILL--------------------------------------------------
 
REGION FILL
 
Name:
    REGION FILL
 
Type:
    Plot Control Command
 
Purpose:
    Specifies whether or not regions on subsequent plots are filled.
    Additionally, it is used to specify whether or not certain types
    of diagrammatic graphics are filled.
 
Description:
    On a plot, a region is defined as the figure formed by the line
    connecting points belonging to a common trace and a region base
    (typically zero).  The REGION FILL command can be used to generate
    a solid fill or a cross-hatch fill of this region.  The attributes
    of the fill are set with additional REGION commands (see the
    RELATED COMMANDS section below).  The attributes of the region
    border are set with LINE, LINE COLOR, and LINE THICKNESS commands.
 
    The diagrammatic graphics commands CIRCLE, CUBE, DIAMOND, ELLIPSE,
    HEXAGON, PYRAMID, SEMI-CIRCLE, and TRIANGLE can be filled using the
    REGION FILL command.  The BOX command has its own attribute
    setting commands.
 
Syntax:
    REGION FILL <ON/OFF>  <ON/OFF>  <ON/OFF>  etc.
    where ON specifies that the region is filled while OFF specifies
             that it is not.  Up to 100 region fill switches can be
             specified.
 
Examples:
    REGION FILL ON OFF ON OFF
    REGION FILL OFF OFF ON
    REGION FILL ON ALL
    REGION FILL ALL ON
    REGION
 
Note:
    The diagrammatic graphics commands use the first setting of the
    REGION FILL command only.
 
Note:
    Regions can be used for the following applications in DATAPLOT:
       1) They can be used to draw filled or cross-hatched 2d
          polygons.  These polygons are not limited to convex polygons.
       2) Statistical maps can be generated.  The boundary for each
          area (e.g., state or county) should be defined as a common
          trace.  This area can then be treated as a polygon.  At this
          time, DATAPLOT does not provide map files.  Hopefully, some
          will be added in the future.
       3) Area plots can be generated or the area between curves can
          be filled.  Although this type of plot is possible with
          DATAPLOT, it is generally not a recommended graphical
          technique.
 
Note:
    At this time, the region fill capability should not be used for
    3d plots.  The results will be unpredictable.
 
Note:
    The REGION FILL command with no arguments sets the region fill to
    OFF for all traces.  The REGION FILL command with the word ALL
    before or after the specified fill switch assigns that region type
    to all traces; thus REGION FILL ON ALL or REGION FILL ALL ON plots
    regions for all traces.
 
Note:
    The BAR, REGION, SPIKE, CHARACTER, and LINE switch all work
    independently of each other.  That is, a plot point can be a line,
    a character, a bar, a spike or a region or any combination of the
    above.
 
Default:
    All regions off
 
Synonyms:
    None
 
Related Commands:
    PLOT                   = Generates a data or function plot.
    REGION BASE            = Sets the base locations for plot regions.
    REGION FILL COLOR      = Sets the color for solid region fills.
    REGION PATTERN         = Sets the types for region fill patterns.
    REGION PATTERN COLOR   = Sets the color for region hatched fills.
    REGION PATTERN LINE    = Sets the line types for region fill
                             patterns.
    REGION PATTERN SPACING = Sets the line spacing for region fill
                             patterns.
    REGION PATTERN THICK   = Sets the line thickness for region fill
                             patterns.
    LINE BORDER COLOR      = Sets the color for region border lines.
    LINE BORDER LINE       = Sets the types for region border lines.
    LINE BORDER THICKNESS  = Sets the line thickness for region border
                             lines.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    XX
 
Program 1:
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE SIZE 3
    .
    REGION FILL ON OFF
    REGION BASE 0 ALL
    TITLE NORPDF FROM -1.5 TO -1
    PLOT NORPDF(X) FOR X = -1.5 0.01 -1 AND
    PLOT NORPDF(X) FOR X = -3 0.01 3
    .
    TITLE PLOT OF SINE CURVE
    PLOT SIN(X) FOR X = -6.28 0.1 6.28
    .
    LET X = DATA 81 82 83 84 85
    LET Y = DATA 2 5 9 15 28
    TITLE AREA CURVE
    PLOT Y X
    .
    TITLE PIE CHART
    LINE THICKNESS 0.3 ALL
    REGION FILL ON ALL
    REGION BASE
    REGION FILL COLOR G10 G30 G50 G70 G90
    PIE CHART Y X
    END OF MULTIPLOT
 
Program 2:
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE SIZE 3
    .
    READ X2 Y2
       .6255459213E+002       .4360801888E+002
       .6408000851E+002       .4019557142E+002
       .7055372143E+002       .3765282536E+002
       .7249774456E+002       .3541294813E+002
       .7415955067E+002       .3788125515E+002
       .7837881279E+002       .3731980515E+002
       .8329592896E+002       .3269992304E+002
       .8584967327E+002       .2901664400E+002
       .9298062229E+002       .3339557743E+002
       .9053282833E+002       .3760073233E+002
       .8058299351E+002       .4461946392E+002
       .7574584389E+002       .4518656731E+002
       .7132878590E+002       .4718765020E+002
       .6534696388E+002       .4567384863E+002
       .6277094793E+002       .4543599606E+002
    END OF DATA
    REGION FILL ON
    REGION BASE POLYGON
    TITLE PLOT A POLYGON
    PLOT Y2 X2
    .
    SKIP 25
    READ TEXAS.DAT X Y
    REGION FILL ON
    REGION BASE POLYGON
    FRAME OFF
    TITLE MAP OF TEXAS
    PLOT Y X
    REGION BASE 0
    .
    TITLE; PLOT
    MOVE 50 97; JUSTIFICATION CENTER
    TEXT FILLED DIAGRAMMATIC GRAPHICS REGION FILL ON
    CIRCLE 10 10 20 20
    REGION FILL ONTS
    CUBE 40 70 48 78
    REGION FILL ON
    ELLIPSE 10 90 15 80 20 90
    DIAMOND 80 70 84 65 88 70
    HEXAGON 60 10 80 30
    END OF MULTIPLOT
 
-----REGION FILL COLOR---------------------------------------------
 
REGION FILL COLOR
 
Name:
    REGION FILL COLOR
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the color used for solid fill regions on subsequent
    plots or for certain types of diagrammatic graphics.
 
Description:
    On a plot, a region is defined as the figure formed by the line
    connecting points belonging to a common trace and a region base
    (typically zero).  The REGION FILL command can be used to generate
    a solid fill or a cross-hatch fill of this region.  The REGION FILL
    command is used to set the color for solid fill regions (the REGION
    PATTERN COLOR command is used to set the color for hatch fill
    regions).  Other attributes of the fill are set with additional
    REGION commands (see the RELATED COMMANDS section below).  The
    attributes of the region border are set with LINE, LINE COLOR, and
    LINE THICKNESS commands.
 
    The diagrammatic graphics commands CIRCLE, CUBE, DIAMOND, ELLIPSE,
    HEXAGON, PYRAMID, SEMI-CIRCLE, and TRIANGLE can be filled using the
    REGION FILL command.  The BOX command has its own attribute
    setting commands.

    Dataplot provides two methods for specifying colors.

        1. Colors can be defined by name (or by the corresponding index).
           Dataplot adopted it's named colors from the X11 project.
           Currently, 162 named colors and 100 levels of grayscale are
           supported.  Grayscale can be specified with either G0, G1, ...,
           G100 (or -1, -2, ..., -100).  Many older devices support only a
           limited number of colors.  For these devices, unsupported colors
           will be mapped to one of the available colors.  To specify a
           named color, see Syntax 1.

        2. Most modern graphics devices support full RGB (RedBlueGreen)
           color.  You can alternatively specify RGB colors by entering
           three integer values to represent the Red, Green and Blue
           components, respectively.  These values should be in the range
           0 to 255.

    When setting the region fill color, Dataplot first checks if the
    device supports RGB colors. If not, the named color will be used.
    If the device does support RGB color, Dataplot will check if an RGB
    color has been specified.  If yes, then that RGB color is used.  If
    not, the named color will be used.

    To see the list of supported named colors (with the associated index
    number), see

    https://www.itl.nist.gov/div898/software/dataplot/refman1/ch11/homepage.htm

Syntax 1:
    REGION FILL COLOR  <color>  <color>  <color>  etc.
    where <color> is a character string or index number that specifies
                the desired color.  Up to 100 region fill colors can
                be specified.
 
Syntax 2:
    REGION FILL RGB COLOR  <ired>  <igreen>  <iblue>
                           <ired>  <igreen>  <iblue>  etc.
    where <ired> specifies the red component of the region fill color;
          <igreen> specifies the green component of the region fill color;
    and   <iblue> specifies the blue component of the region fill color.

    Up to 100 triplets of RGB colors can be specified.

    The components should be integer values in the range 0 - 255.  To turn
    off the RGB color, set the components to -1 (any negative value will
    work and if any of the three components is negative the RGB color will
    be turned off).

Examples:
    REGION FILL COLOR RED BLUE GREEN
    REGION FILL COLOR BLACK ALL
    REGION FILL COLOR ALL BLACK
    REGION FILL COLOR
    REGION FILL RGB COLOR 201 101 88
    REGION FILL RGB COLOR 201 101 88 ALL
    REGION FILL RGB COLOR 201 101 88 240 200 175
    REGION FILL RGB COLOR -1 -1 -1 ALL
 
Default:
    All solid region fills are black.
 
Synonyms:
    None
 
Note:
    The diagrammatic graphics commands use the first setting of the
    REGION FILL COLOR command only.
 
Note:
    The REGION FILL COLOR command with no arguments sets the region
    fill color to default for all regions.  The REGION FILL COLOR
    command with the word ALL before or after the specified color
    assigns that region fill color to all regions; thus REGION FILL
    COLOR BLACK ALL or REGION FILL COLOR ALL BLACK plots all region
    fills in black.
 
Note:
    The REGION, BAR, SPIKE, CHARACTER, and LINE switch all work
    independently of each other.  That is, a plot point can be a line,
    a character, a spike a region, a bar or any combination of the
    above.
 
Related Commands:
    PLOT                   = Generates a data or function plot.
    REGION BASE            = Sets the base locations for plot regions.
    REGION FILL            = Sets the on/off switches for region fills.
    REGION PATTERN         = Sets the types for region fill patterns.
    REGION PATTERN COLOR   = Sets the color for region hatched fills.
    REGION PATTERN LINE    = Sets the line types for region fill
                             patterns.
    REGION PATTERN SPACING = Sets the line spacing for region fill
                             patterns.
    REGION PATTERN THICK   = Sets the line thickness for region fill
                             patterns.
    LINE                   = Sets the types for plot lines.
    LINE COLOR             = Sets the color for plot lines.
    LINE THICKNESS         = Sets the line thickness for plot lines.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
    2021/11: Support for RGB color
 
Program 1:
    SKIP 25
    READ TEXAS.DAT X Y
    .
    FRAME OFF
    FRAME CORNER COORDINATES 5 5 95 95
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    REGION BASE POLYGON
    REGION FILL ON
    TITLE BLACK
    PLOT Y X
    REGION FILL COLOR G75
    TITLE G75
    PLOT Y X
    REGION FILL COLOR G50
    TITLE G50
    PLOT Y X
    REGION FILL COLOR G25
    TITLE G25
    PLOT Y X
    END OF MULTIPLOT
 
Program 2:
    skip 25
    read wright11.dat pressure angle wing
    let angled = distinct angle
    let nangle = size angled
    let wingd = distinct wing
    let nwing = size wingd
    .
    title case asis
    title offset 2
    title Response Variable = Pressure
    label case asis
    x1label Wing Type
    y1label uc()Alc()ngle
    y1label displacement 12
    tic offset units data
    x1limits 1 nwing
    major xtic mark number nwing
    minor xtic mark number 0
    xtic mark offset 0.8 0.8
    x1tic mark label format alpha
    x1tic mark label content 1 2 3 4 5 6 7 8 9 10 11 12 13 15 16 17
    y1limits 1 nangle
    major ytic mark number nangle
    minor ytic mark number 0
    y1tic mark offset 0.8 0.8
    y1tic mark label format alpha
    y1tic mark label content 0 2.5 5 7.5 10 12.5 15 17.5 20 25 30 35 40 45
    .
    let ylevel = data 10 20 30 40 50
    region fill on all
    region fill color   red orange yellow green cyan blue
    region border color red orange yellow green cyan blue
    line color          red orange yellow green cyan blue
    region fill rgb color   239 243 255  198 219 239  158 202 225 ...
                            107 174 214   49 130 189    8  81 156
    region border rgb color 239 243 255  198 219 239  158 202 225 ...
                            107 174 214   49 130 189    8  81 156
    line color              239 243 255  198 219 239  158 202 225 ...
                            107 174 214   49 130 189    8  81 156
    .
    tabulation mean plot pressure angle wing ylevel
    .
    box fill pattern solid
    box shadow hw 0 0
    .
    box fill color blue
    box fill rgb color 8 81 156
    box 86 90 90 86
    move 91 87; text > 50
    .
    box fill color cyan
    box fill rgb color 49 130 189
    box 86 86 90 82
    move 91 83; text 40 - 50
    .
    box fill color green
    box fill rgb color 107 174 214
    box 86 82 90 78
    move 91 79; text 30 - 40
    .
    box fill color yellow
    box fill rgb color 158 202 225
    box 86 78 90 74
    move 91 75; text 20 - 30
    .
    box fill color orange
    box fill rgb color 198 219 239
    box 86 74 90 70
    move 91 71; text 10 - 20
    .
    box fill color red
    box fill rgb color 239 243 255
    box 86 70 90 66
    move 91 67; text < 10

-----REGION PATTERN---------------------------------------------------
 
REGION PATTERN
 
Name:
    REGION PATTERN
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the type of fill pattern for regions on subsequent plots
    or for certain types of diagrammatic graphics.
 
Description:
    On a plot, a region is defined as the figure formed by the line
    connecting points belonging to a common trace and a region base
    (typically zero).  The REGION FILL command can be used to generate
    a solid fill or a cross-hatch fill of this region.  The REGION
    PATTERN command can be used to specify the type of pattern fill.
    Other attributes of the fill are set with additional REGION
    commands (see the RELATED COMMANDS section below).  The attributes
    of the region border are set with LINE, LINE COLOR, and LINE
    THICKNESS commands.
 
    The diagrammatic graphics commands CIRCLE, CUBE, DIAMOND, ELLIPSE,
    HEXAGON, PYRAMID, SEMI-CIRCLE, and TRIANGLE can be filled using the
    REGION FILL command.  The BOX command has its own attribute
    setting commands.
 
Syntax:
    REGION PATTERN  <pattern>  <pattern>  <pattern>  etc.
    where <pattern> is a character string that specifies the desired
              fill pattern.
 
Examples:
    REGION PATTERN SOLID VERTICAL HORIZONTAL BLANK
    REGION PATTERN D1 D2 D1D2 HOD1 VED2 VEDD
    REGION PATTERN D1 ALL
    REGION PATTERN ALL D1
    REGION PATTERN
 
Note:
    The following region fill patterns are available:
        BLANK   - no fill
        EMPTY   - no fill
        OFF     - no fill
        SOLID   - solid fill
        ON      - solid fill
        HORI    - horizontal lines
        VERT    - vertical lines
        D1      - up diagonals
        D2      - down diagonals
        D1D2    - both up and down diagonals
        VED1    - both vertical lines and up diagonals
        VED2    - both vertical lines and down diagonals
        HOD1    - both horizontal lines and up diagonals
        HOD2    - both vertical lines and down diagonals
        VEDD    - both horizontal and vertical lines, and
                  both up and down diagonals
    In practice, the first 7 (OFF, ON, HORI, VERT, D1, D2, D1D2) are
    heavily used and the last 5 (VED1, VED2, HOD1, HOD2, VEDD) are
    rarely used.
 
Note:
    The diagrammatic graphics commands use the first setting of the
    REGION PATTERN command only.
 
Note:
    The REGION PATTERN command with no arguments sets the region
    pattern type to blank for all regions.  The REGION PATTERN command
    with the word ALL before or after the specified pattern type
    assigns that region pattern type to all regions; thus REGION
    PATTERN D1 ALL or REGION PATTERN ALL D1 fills all regions with
    pattern D1.
 
Note:
    The REGION, SPIKE, CHARACTER, BAR, and LINE switch all work
    independently of each other.  That is, a plot point can be a line,
    a region, a character, a spike, a region, or any combination of the
    above.
 
Default:
    All region patterns are blank.
 
Synonyms:
    None
 
Related Commands:
    PLOT                   = Generates a data or function plot.
    REGION BASE            = Sets the base locations for plot regions.
    REGION FILL            = Sets the on/off switches for region fills.
    REGION FILL COLOR      = Sets the color for region solid fills.
    REGION PATTERN COLOR   = Sets the color for region hatched fills.
    REGION PATTERN LINE    = Sets the line types for region fill
                             patterns.
    REGION PATTERN SPACING = Sets the line spacing for region fill
                             patterns.
    REGION PATTERN THICK   = Sets the line thickness for region fill
                             patterns.
    LINE COLOR             = Sets the color for region border lines.
    LINE                   = Sets the types for region border lines.
    LINE THICKNESS         = Sets the line thickness for region border
                             lines.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    The ability to generate hatch fills for non-rectangular regions
    was added 93/10.
 
Program:
    LET C = 1
    LET FUNCTION F1 = C
    LET FUNCTION F2 = -1.5*X + 9
    LET FUNCTION F3 = 6
    LET FUNCTION F4 = 1+0.3*X**2
    .
    XMINIMUM 0; YLIMITS 0 10
    TITLE PLOT INEQUALITY REGIONS
    .
    REGION FILL ON ALL
    REGION BASE 0 10 10 0
    REGION PATTERN D1 HORI D2 VERT
    REGION PATTERN SPACING 5 ALL
    .
    LINE THICKNESS 0.3
    LINE SOLID DASH SOLID DASH
    X1LABEL SOLID = EQUALITY
    X2LABEL DASH = INEQUALITY
    .
    PLOT F1 FOR X = 0 5 5 AND
    PLOT F2 FOR X = 0 5 5 AND
    PLOT F3 FOR X = 0 5 5 AND
    PLOT F4 FOR X = 0 0.01 5
 
-----REGION PATTERN COLOR---------------------------------------------
 
REGION PATTERN COLOR
 
Name:
    REGION PATTERN COLOR
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the color used for cross-hatch fill regions on subsequent
    plots or for certain types of diagrammatic graphics.
 
Description:
    On a plot, a region is defined as the figure formed by the line
    connecting points belonging to a common trace and a region base
    (typically zero).  The REGION FILL and REGION PATTERN commands can
    be used to generate a solid or cross-hatch fill of this region.
    The REGION FILL COLOR command specifies the color for solid fill
    regions while the REGION PATTERN COLOR command specifies the color
    for cross-hatch lines.  Other attributes of the fill are set with
    additional REGION commands (see the RELATED COMMANDS section
    below).  The attributes of the region border are set with LINE,
    LINE COLOR, and LINE THICKNESS commands.
 
    The diagrammatic graphics commands CIRCLE, CUBE, DIAMOND, ELLIPSE,
    HEXAGON, PYRAMID, SEMI-CIRCLE, and TRIANGLE can be filled using the
    REGION FILL command.  The BOX command has its own attribute
    setting commands.
 
    Dataplot provides two methods for specifying colors.

        1. Colors can be defined by name (or by the corresponding index).
           Dataplot adopted it's named colors from the X11 project.
           Currently, 162 named colors and 100 levels of grayscale are
           supported.  Grayscale can be specified with either G0, G1, ...,
           G100 (or -1, -2, ..., -100).  Many older devices support only a
           limited number of colors.  For these devices, unsupported colors
           will be mapped to one of the available colors.  To specify a
           named color, see Syntax 1.

        2. Most modern graphics devices support full RGB (RedBlueGreen)
           color.  You can alternatively specify RGB colors by entering
           three integer values to represent the Red, Green and Blue
           components, respectively.  These values should be in the range
           0 to 255.

    When setting the region pattern color, Dataplot first checks if the
    device supports RGB colors. If not, the named color will be used.
    If the device does support RGB color, Dataplot will check if an RGB
    color has been specified.  If yes, then that RGB color is used.  If
    not, the named color will be used.

    To see the list of supported named colors (with the associated index
    number), see

    https://www.itl.nist.gov/div898/software/dataplot/refman1/ch11/homepage.htm

Syntax 1:
    REGION PATTERN COLOR  <color>  <color>  <color>  etc.
    where <color> is a character string or index number that specifies
              the desired color.  Up to 100 region pattern colors can
              be specified.
 
Syntax 2:
    REGION PATTERN RGB COLOR  <ired>  <igreen>  <iblue>
                              <ired>  <igreen>  <iblue>  etc.
    where <ired> specifies the red component of the region pattern color;
          <igreen> specifies the green component of the region pattern
                   color;
    and   <iblue> specifies the blue component of the region pattern
                   color.

    Up to 100 triplets of RGB colors can be specified.

    The components should be integer values in the range 0 - 255.  To turn
    off the RGB color, set the components to -1 (any negative value will
    work and if any of the three components is negative the RGB color will
    be turned off).

Examples:
    REGION PATTERN COLOR RED BLUE GREEN
    REGION PATTERN COLOR BLACK ALL
    REGION PATTERN COLOR ALL BLACK
    REGION PATTERN COLOR
    REGION PATTERN RGB COLOR 201 101 88
    REGION PATTERN RGB COLOR 201 101 88 ALL
    REGION PATTERN RGB COLOR 201 101 88 240 200 175
    REGION PATTERN RGB COLOR -1 -1 -1 ALL
 
Note:
    The diagrammatic graphics commands use the first setting of the
    REGION PATTERN COLOR command only.
 
Note:
    The REGION PATTERN COLOR command with no arguments sets the region
    pattern color to default for all regions.  The REGION PATTERN COLOR
    command with the word ALL before or after the specified color
    assigns that region pattern color to all regions; thus REGION
    PATTERN COLOR BLACK ALL or REGION PATTERN COLOR ALL BLACK plots all
    region fills in black.
 
Note:
    The REGION, BAR, SPIKE, CHARACTER, and LINE switch all work
    independently of each other.  That is, a plot point can be a line,
    a character, a spike, a region, a bar, or any combination of the
    above.
 
Default:
    All region pattern colors are black.
 
Synonyms:
    None
 
Related Commands:
    PLOT                   = Generates a data or function plot.
    REGION BASE            = Sets the base locations for plot regions.
    REGION FILL            = Sets the on/off switches for region fills.
    REGION FILL COLOR      = Sets the color for region solid fills.
    REGION PATTERN         = Sets the types for region fill patterns.
    REGION PATTERN LINE    = Sets the line types for region fill
                             patterns.
    REGION PATTERN SPACING = Sets the line spacing for region fill
                             patterns.
    REGION PATTERN THICK   = Sets the line thickness for region fill
                             patterns.
    LINE COLOR             = Sets the color for plot lines.
    LINE                   = Sets the types for plot lines.
    LINE THICKNESS         = Sets the line thickness for plot lines.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
    1993/10: Added the capability to do cross-hatch fills for non-rectangular
             regions
    2020/11: Added support for RGB colors
 
Program 1:
    REGION FILL ON
    REGION PATTERN D1D2
    REGION PATTERN SPACING 3
    REGION PATTERN THICKNESS 0.3
    REGION PATTERN COLOR RED
    LINE COLOR BLUE
    LINE THICKNESS 0.5
    .
    Y1LABEL X**2
    X1LABEL X
    TITLE DEMONSTRATE THE REGION PATTERN COLOR COMMAND
    .
    PLOT X**2 FOR X = 1 1 9
 
Program 2:
    skip 25
    read wright11.dat pressure angle wing
    let angled = distinct angle
    let nangle = size angled
    let wingd = distinct wing
    let nwing = size wingd
    .
    title case asis
    title offset 2
    title Response Variable = Pressure
    label case asis
    x1label Wing Type
    y1label uc()Alc()ngle
    y1label displacement 12
    tic offset units data
    x1limits 1 nwing
    major xtic mark number nwing
    minor xtic mark number 0
    xtic mark offset 0.8 0.8
    x1tic mark label format alpha
    x1tic mark label content 1 2 3 4 5 6 7 8 9 10 11 12 13 15 16 17
    y1limits 1 nangle
    major ytic mark number nangle
    minor ytic mark number 0
    y1tic mark offset 0.8 0.8
    y1tic mark label format alpha
    y1tic mark label content 0 2.5 5 7.5 10 12.5 15 17.5 20 25 30 35 40 45
    .
    let ylevel = data 10 20 30 40 50
    region fill on all
    region pattern d1d2 all
    region pattern thickness 0.5
    region pattern spacing 3
    .
    region pattern color       red orange yellow green cyan blue
    line color                 red orange yellow green cyan blue
    region pattern rgb color   239 243 255  198 219 239  158 202 225 ...
                               107 174 214   49 130 189    8  81 156
    line rgb color             239 243 255  198 219 239  158 202 225 ...
                               107 174 214   49 130 189    8  81 156
    .
    tabulation mean plot pressure angle wing ylevel
    .
    box fill thickness 0.5
    box fill pattern d1d2
    box fill gap 3
    box shadow hw 0 0
    .
    box fill color blue
    box fill rgb color 8 81 156
    box 86 90 90 86
    move 91 87; text > 50
    .
    box fill color cyan
    box fill rgb color 49 130 189
    box 86 86 90 82
    move 91 83; text 40 - 50
    .
    box fill color green
    box fill rgb color 107 174 214
    box 86 82 90 78
    move 91 79; text 30 - 40
    .
    box fill color yellow
    box fill rgb color 158 202 225
    box 86 78 90 74
    move 91 75; text 20 - 30
    .
    box fill color orange
    box fill rgb color 198 219 239
    box 86 74 90 70
    move 91 71; text 10 - 20
    .
    box fill color red
    box fill rgb color 239 243 255
    box 86 70 90 66
    move 91 67; text < 10

-----REGION PATTERN LINE----------------------------------------------
 
REGION PATTERN LINE
 
Name:
    REGION PATTERN LINES
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the line patterns used to do region fills on subsequent
    plots and certain types of diagrammatic graphics.
 
Description:
    On a plot, a region is defined as the figure formed by the line
    connecting points belonging to a common trace and a region base
    (typically zero).  The REGION FILL and REGION PATTERN commands can
    be used to generate a solid fill or a cross-hatch fill of this
    region.  The REGION PATTERN LINE command is used to specify the
    line type (i.e., solid, dashed) when generating cross-hatch fills.
    The attributes of the fill are set with additional REGION commands
    (see the RELATED COMMANDS section below).  The attributes of the
    region border are set with LINE, LINE COLOR, and LINE THICKNESS
    commands.
 
    The diagrammatic graphics commands CIRCLE, CUBE, DIAMOND, ELLIPSE,
    HEXAGON, PYRAMID, SEMI-CIRCLE, and TRIANGLE can be filled using the
    REGION FILL command.  The BOX command has its own attribute
    setting commands.
 
    The line type (e.g., solid or dashed) is distinct from the pattern
    type (e.g., solid or horizontal).
 
Syntax:
    REGION PATTERN LINE  <type>  <type>  <type>  etc.
    where <type> is a character string that specifies the desired line
                type.  Up to 100 region pattern line types can be
                specified.
 
Examples:
    REGION PATTERN LINE SOLID DASH DOT
    REGION PATTERN LINES SOLID ALL
    REGION PATTERN LINES ALL SOLID
    REGION PATTERN LINES
 
Note:
    The REGION PATTERN LINE command with no arguments sets the region
    type to default for all regions.  The REGION PATTERN LINE command
    with the word ALL before or after the specified type assigns that
    pattern line type to all regions; thus REGION PATTERN LINE SOLID
    ALL or REGION PATTERN LINE ALL SOLID plots region patterns with
    solid lines for all regions.
 
Note:
    The REGION, BAR, SPIKE, CHARACTER, and LINE switch all work
    independently of each other.  That is, a plot point can be a line,
    a character, a region, a spike, a bar, or any combination of the
    above.
 
Default:
    All region pattern line types are solid.
 
Synonyms:
    None
 
Related Commands:
    PLOT                   = Generates a data or function plot.
    REGION BASE            = Sets the base locations for plot regions.
    REGION FILL            = Sets the on/off switches for region fills.
    REGION FILL COLOR      = Sets the color for region solid fills.
    REGION PATTERN         = Sets the types for region fill patterns.
    REGION PATTERN COLOR   = Sets the color for region hatched fills.
    REGION PATTERN SPACING = Sets the line spacing for region fill
                             patterns.
    REGION PATTERN THICK   = Sets the line thickness for region fill
                             patterns.
    LINE COLOR             = Sets the color for region border lines.
    LINE                   = Sets the types for region border lines.
    LINE THICKNESS         = Sets the line thickness for region border
                             lines.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    The ability to generate cross-hatch fills of non-rectangular
    regions was added 93/10.
 
Program:
    LET C = 1
    LET FUNCTION F1 = C
    LET FUNCTION F2 = -1.5*X + 9
    LET FUNCTION F3 = 6
    LET FUNCTION F4 = 1+0.3*X**2
    .
    XMINIMUM 0; YLIMITS 0 10
    TITLE PLOT INEQUALITY REGIONS
    .
    REGION FILL ON ALL
    REGION BASE 0 10 10 0
    REGION PATTERN D1 HORI D2 VERT
    REGION PATTERN SPACING 5 ALL
    LINE SOLID DASH SOLID DASH
    REGION PATTERN LINE SOLID DASH SOLID DASH
    .
    X1LABEL SOLID = EQUALITY
    X2LABEL DASH = INEQUALITY
    .
    PLOT F1 FOR X = 0 5 5 AND
    PLOT F2 FOR X = 0 5 5 AND
    PLOT F3 FOR X = 0 5 5 AND
    PLOT F4 FOR X = 0 0.01 5
 
-----REGION PATTERN SPACING------------------------------------------
 
REGION PATTERN SPACING
 
Name:
    REGION PATTERN SPACING
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the spacing to be used between lines when doing
    cross-hatch pattern fills of regions on subsequent plots or for
    certain types of diagrammatic graphics.
 
Description:
    On a plot, a region is defined as the figure formed by the line
    connecting points belonging to a common trace and a region base
    (typically zero).  The REGION FILL and REGION PATTERN commands can
    be used to generate a solid fill or a cross-hatch fill of this
    region.  The REGION PATTERN SPACING controls the spacing between
    lines for cross-hatch fills.  Other attributes of the fill are set
    with additional REGION commands (see the RELATED COMMANDS section
    below).  The attributes of the region border are set with LINE,
    LINE COLOR, and LINE THICKNESS commands.
 
    The diagrammatic graphics commands CIRCLE, CUBE, DIAMOND, ELLIPSE,
    HEXAGON, PYRAMID, SEMI-CIRCLE, and TRIANGLE can be filled using the
    REGION FILL command.  The BOX command has its own attribute
    setting commands.
 
    The region pattern spacing is given in 0.0 to 100.0 DATAPLOT units.
    A value of 0.1 gives a solid fill on most devices.  Typical values
    are between 1 and 5.
 
Syntax:
    REGION PATTERN SPACINGS  <number>  <number>  <number>  etc.
    where <number> is a number or parameter that specifies the desired
                region pattern spacing.  Up to 100 region pattern
                spacings can be specified.
 
Examples:
    REGION PATTERN SPACINGS 1.0 0.5 3.0 5.0
    REGION PATTERN SPACINGS 1.0 ALL
    REGION PATTERN SPACINGS ALL 1.0
    REGION PATTERN SPACINGS
 
Note:
    The diagrammatic graphics commands use the first setting of the
    REGION FILL command only.
 
Note:
    The REGION PATTERN SPACING command with no arguments sets the
    region pattern spacing to default for all regions.  The REGION
    PATTERN SPACING command with the word ALL before or after the
    specified pattern spacing assigns that pattern spacing to all
    regions; thus REGION PATTERN SPACING 1.0 ALL or REGION PATTERN
    SPACING ALL 1.0 uses a pattern spacing of 1.0 for all regions on
    the plot.
 
Note:
    The REGION, SPIKE, BAR, CHARACTER, and LINE switch all work
    independently of each other.  That is, a plot point can be a bar, a
    line, a character, a spike, a region, or any combination of the
    above.
 
Default:
    All region pattern spacings are 1.0.
 
Synonyms:
    None
 
Related Commands:
    PLOT                   = Generates a data or function plot.
    REGION BASE            = Sets the base locations for plot regions.
    REGION FILL            = Sets the on/off switches for region fills.
    REGION FILL COLOR      = Sets the color for region solid fills.
    REGION PATTERN         = Sets the types for region fill patterns.
    REGION PATTERN COLOR   = Sets the color for region hatched fills.
    REGION PATTERN LINE    = Sets the line types for region fill
                             patterns.
    REGION PATTERN THICK   = Sets the line thickness for region fill
                             patterns.
    LINE COLOR             = Sets the color for region border lines.
    LINE                   = Sets the types for region border lines.
    LINE THICKNESS         = Sets the line thickness for region border
                             lines.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    The ability to generate cross-hatch fills for non-rectangular
    regions was added 93/10.
 
Program:
    LET C = 1
    LET FUNCTION F1 = C
    LET FUNCTION F2 = -1.5*X + 9
    LET FUNCTION F3 = 6
    LET FUNCTION F4 = 1+0.3*X**2
    .
    XMINIMUM 0; YLIMITS 0 10
    TITLE PLOT INEQUALITY REGIONS
    .
    REGION FILL ON ALL
    REGION BASE 0 10 10 0
    REGION PATTERN D1 HORI D2 VERT
    REGION PATTERN SPACING 5 2 4 3
    .
    PLOT F1 FOR X = 0 5 5 AND
    PLOT F2 FOR X = 0 5 5 AND
    PLOT F3 FOR X = 0 5 5 AND
    PLOT F4 FOR X = 0 0.01 5
 
-----REGION PATTERN THICKNESS-----------------------------------------
 
REGION PATTERN THICKNESS
 
Name:
    REGION PATTERN THICKNESS
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the thickness of lines used when generating cross-hatch
    pattern fills of regions on subsequent plots or for certain
    diagrammatic graphics.
 
Description:
    On a plot, a region is defined as the figure formed by the line
    connecting points belonging to a common trace and a region base
    (typically zero).  The REGION FILL and REGION PATTERN commands can
    be used to generate a solid or cross-hatch fill of this region.
    The REGION PATTERN THICKNESS command is used to specify the line
    thickness for a cross-hatch pattern.  Other attributes of the fill
    are set with additional REGION commands (see the RELATED COMMANDS
    section below).  The attributes of the region border are set with
    LINE, LINE COLOR, and LINE THICKNESS commands.
 
    The diagrammatic graphics commands CIRCLE, CUBE, DIAMOND, ELLIPSE,
    HEXAGON, PYRAMID, SEMI-CIRCLE, and TRIANGLE can be filled using the
    REGION FILL command.  The BOX command has its own attribute
    setting commands.
 
    The line thickness is specified in 0.0 to 100.0 DATAPLOT units.
    Typical values are between 0.05 and 0.3.
 
Syntax:
    REGION PATTERN THICKNESSS  <thick>  <thick>  <thick> etc.
    where <thick> is a number or parameter that specifies the desired
               thickness.  Up to 100 region pattern line thicknesses
               can be specified.
 
Examples:
    REGION PATTERN THICKNESSS 0.1 0.2 0.1 0.2
    REGION PATTERN THICKNESSS 0.2 0.2 0.1
    REGION PATTERN THICKNESSS 0.1 ALL
    REGION PATTERN THICKNESSS ALL 0.1
    REGION PATTERN THICKNESSS
 
Note:
    The diagrammatic graphics commands use the first setting of the
    REGION FILL command only.
 
Note:
    The REGION PATTERN THICKNESS command with no arguments sets
    the region pattern line thickness to default for all regions.
    The REGION PATTERN THICKNESS command with the word ALL before
    or after the specified thickness assigns that region pattern
    line thickness to all regions; thus REGION PATTERN THICKNESS
    0.1 ALL or REGION PATTERN THICKNESS ALL 0.1 plots region
    pattern fills with a line thickness of 0.1 for all regions
    on the plot.
 
Note:
    The REGION, SPIKE, CHARACTER, BAR, and LINE switches all work
    independently of each other.  That is, a plot point can be a line,
    a bar, a character, a spike, a region, or any combination of the
    above.
 
Default:
    All region pattern line thicknesses are 0.1.
 
Synonyms:
    None
 
Related Commands:
    PLOT                   = Generates a data or function plot.
    REGION BASE            = Sets the base locations for plot regions.
    REGION FILL            = Sets the on/off switches for region fills.
    REGION FILL COLOR      = Sets the color for region solid fills.
    REGION PATTERN         = Sets the types for region fill patterns.
    REGION PATTERN COLOR   = Sets the color for region hatched fills.
    REGION PATTERN LINE    = Sets the line types for region fill
                             patterns.
    REGION PATTERN SPACING = Sets the line spacing for region fill
                             patterns.
    LINE COLOR             = Sets the color for region border lines.
    LINE                   = Sets the types for region border lines.
    LINE THICKNESS         = Sets the line thickness for region border
                             lines.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    The ability to generate cross-hatch fills of non-rectangular
    regions was added 93/10.
 
Program:
    LET C = 1
    LET FUNCTION F1 = C
    LET FUNCTION F2 = -1.5*X + 9
    LET FUNCTION F3 = 6
    LET FUNCTION F4 = 1+0.3*X**2
    .
    XMINIMUM 0; YLIMITS 0 10
    TITLE PLOT INEQUALITY REGIONS
    .
    REGION FILL ON ALL
    REGION BASE 0 10 10 0
    REGION PATTERN D1 HORI D2 VERT
    REGION PATTERN SPACING 5 ALL
    REGION PATTERN THICKNESS 0.1 0.3 0.1 0.5
    .
    PLOT F1 FOR X = 0 5 5 AND
    PLOT F2 FOR X = 0 5 5 AND
    PLOT F3 FOR X = 0 5 5 AND
    PLOT F4 FOR X = 0 0.01 5
 
-----REGIS-------------------------------------------------------
 
REGIS
 
Name:
    REGIS
 
Type:
    Output Device Command
 
Purpose:
    The REGIS command is used to direct graphical output to a REGIS
    device.
 
Description:
    This is the protocol supported on many DEC terminals (e.g., the
    VT-240 and VT-340).
 
Syntax 1:
    REGIS  <model>
    where <model> is 240 for VT-240 class terminals and 340 for VT-340
              class terminals.
 
    This form designates device 1 (the terminal) as a Regis device.
 
Syntax 2:
    DEVICE <1/2/3> REGIS  <model>
    where <model> is 240 for VT-240 class terminals and 340 for VT-340
              class terminals.
 
    This form designates one of of DATAPLOT's 3 devices (it will
    typically be device 1) as a Regis device.
 
Examples:
    REGIS
    DEVICE 1 REGIS
    DEVICE 1 REGIS 340
 
Note:
    Regis supports both monochrome and color terminals.  By default,
    the Regis driver is monochrome.  To specify color Regis, enter
    the command DEVICE 1 COLOR ON after the REGIS command.
 
Note:
    Regis terminals support 64 colors.  However, only a subset of these
    can be active at a given time.  For the VT-240 type terminals, 4
    colors can be active.  For the VT-340 type terminals, 16 colors
    can be active.  One color is reserved for the background and the
    rest for the foreground.  The command REGIS COLORS can be used to
    specify the active colors.  If this command is not used, then the
    3 (or 15 for the VT-340) foreground colors are assigned in the
    order requested.  Any additional colors are assigned to the last
    position (which can cause current colors on the screen to change
    when the new one is assigned).
 
Default:
    Off
 
Synonyms:
    None
DEVICE NOTES
    1) HARDWARE TEXT - Regis supports 17 hardware characters, although
       only the first few are generally useful.  The first size is
       9x10 pixels, the second is 9x15.  The rest are integer multiples
       of the 9x15 pixel size.  This means there is a fairly large
       jump between successive character strings.  Regis hardware
       characters are of low quality.  They are not rotated.
    2) COLOR - Some Regis terminals support color.  Regis defines a
       database of 64 fixed colors.  The VT-240 allows 4 of these
       colors to be active (1 background color, 3 foreground colors) at
       one time.  The VT-340 allows 15 foreground colors to be active.
    3) HARDWARE FILL - Solid area fills are done in hardware.
    4) DASH PATTERNS - The Regis driver supports unique dash patterns
       for DASH, DOT, DASH2, DASH3, and DASH4.  DASH5 is the same
       as DASH4.
    5) LINE WIDTH - Thick lines are generated as multiple lines.
    6) GRAPHICS INPUT - The CROSS-HAIR command is supported for this
       device.
 
Related Commands:
    POSTSCRIPT        = Direct graphical output to a Postscript device.
    HPGL              = Direct graphical output to an HPGL device.
    TEKTRONIX         = Direct graphical output to a Tektronix device.
    X11               = Direct graphical output to an X11 device.
    DEVICE            = Specify certain actions for the graphics
                        output.
    SHOW REGIS COLOR  = Show the available colors on the Regis device.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----REGIS COLORS--------------------------------------------------
 
REGIS COLORS
 
Name:
    REGIS COLORS
 
Type:
    Output Devices Command
 
Purpose:
    Assign the active colors for a Regis graphics device.
 
Description:
    Regis color devices support 64 colors.  However, only 4 (for VT-240
    class terminals) or 16 (for VT-340 class terminals) colors can be
    active at a given time.  This command allows the analyst to specify
    the active colors.
 
Syntax:
    REGIS COLORS <color> <index>
    where <color> is a character string that specifies the desired
             color;
    and   <index> is an integer number or parameter between 1 and 16.
 
Examples:
    REGIS COLORS SHOW
    REGIS COLORS RED 4
 
Default:
    The following is the default for VT-240 class terminals
        1     WHITE
        2     YELLOW
        3     RED
    The following is the default for VT-340 class terminals
        1     WHITE
        2     YELLOW
        3     RED
        4     BLACK
        5     GREEN
        6     CYAN
        7     BLUE
        8     ORANGE
        9     TURQUOISE
       10     MAGENTA
       11     YELLOW GREEN
       12     TAN
       13     GOLD
       14     VIOLET RED
       15     LIGHT GRAY
 
Synonyms:
    REGIS PEN MAP
 
Related Commands:
    SHOW COLORS    = Print the available colors for various devices.
    REGIS          = Direct graphical output to a Regis device.
 
Applications:
    XX
 
Implementation Date:
    90/6
 
Program:
    DEVICE 1 REGIS 340
    DEVICE 1 COLOR ON
    REGIS COLORS BLACK 1
    REGIS COLORS BLUE   2
    REGIS COLORS GREEN  3
    REGIS COLORS RED 4
 
-----REGRESSION DIAGNOSTICS------------------------------------

REGRESSION DIAGNOSTICS

Name:
    REGRESSION DIAGNOSTICS

Description:
    The help for FIT and LINEAR FIT describe the standard outputs and
    intervals that are generated by the fits and the standard residual
    analysis that is typically performed after a fit to validate the
    model. This help section describes the following.

        1. There are a number of plots that can be generated to
           help determine the most appropriate model.

        2. A number of additional intervals and tests that are not
           included in the standard Dataplot outputs can be generated
           from information that is provided by the fit.

        3. There are a number of regression diagnostics that go beyond
           standard residual analysis.  

        4. When there are multiple independent variables being
           considered, it may be useful to assess multi-collinearity.

    The above are demonstrated in the Program example below.  Note
    that this program example is meant to show the mechanics of
    the various plots and commands and is not intended to be treated
    as a case study.

    One purpose of many regression diagnostics is to identify
    observations with either high leverage or high influence.  High
    leverage points are those that are outliers with respect to the
    independent variables.  Influential points are those that cause
    large changes in the parameter estimates when they are deleted.
    Although an influential point will typically have high leverage, a
    high leverage point is not necessarily an influential point.  The
    leverage is typically defined as the diagonal of the hat matrix
    (hat matrix = H = X(X'X)**(-1)X').  Dataplot currently writes a
    number of measures of influence and leverage to the file dpst3f.dat
    (e.g., the diagonal of the hat matrix, Cook's distance, DFFITS).

Pre-Fit Plots
    When there are multiple independent variables, it is common to plot
    the dependent variable against each of the independent variable.
    However, these basic plots do not account for the effect of the other
    independent variables in the model into account.  Several plots have
    been proposed to address this.  Specifically,

        1. Partial Residual Plot

           Partial residual plots attempt to show the relationship
           between a given independent variable and the response
           variable given that other independent variables are in the
           model.

           Partial residual plots are formed as:

               Res + Beta(i)*X(i) versus X(i)

           where

               Res     = residuals from the full model
               Beta(i) = regression coefficient from the i-th independent
                         variable in the full model
               X(i)    = the i-th independent variable

           Partial residual plots are widely discussed in the regression
           diagnostics literature.  Although they can often be useful, be
           aware that they can also fail to indicate the proper
           relationship. In particular, if X(i) is highly correlated with
           any of the other independent variables, the variance indicated
           by the partial residual plot can be much less than the actual
           variance. 

           Enter HELP PARTIAL RESIDUAL PLOT for further information.

        2. Component and Component-Plus-Residual (CCPR) Plot

           The CCPR plot is a refinement of the partial residual plot.
           It generates a partial residual plot but also adds

              Betahat(i)*X(i) versus X(i)

           This is the "component" part of the plot and is intended to
           show where the "fitted line" would lie. 

           Enter HELP PARTIAL RESIDUAL PLOT for further information.

        3. Partial Regression Plot

           Partial regression plots are also referred to as added
           variable plots, adjusted variable plots and individual
           coefficient plots. 

           Partial regression plots attempt to show the effect of adding
           an additional variable to the model (given that one or more
           independent variables are already in the model). Partial
           regression plots are formed by:

                i. Compute the residuals of regressing the response
                   variable against the independent variables but
                   omitting X(i).

               ii. Compute the residuals from regressing X(i) against the
                   remaining independent variables.

              iii. Plot the residuals from (i) against the residuals from
                   (ii). 

           Velleman and Welsch (see References below) express this
           mathematically as:

                 Y.[i] versus Xi.[i] 

           where

                 Y.[i]  = residuals from regressing Y (the response
                          variable) against all the independent variables
                          except X(i)
                 Xi.[i] = residuals from regressing X(i) against the
                          remaining indpependent variables. 

           Velleman and Welsch list the following useful properties for
           this plot:

                i. The least squares linear fit to this plot has the
                   slope Beta(i) and intercept zero.

               ii. The residuals from the least squares linear fit to
                   this plot are identical to the residuals from the
                   least squares fit of the original model (Y against all
                   the independent variables including X(i)).

              iii. The influences of individual data values on the
                   estimation of a coefficient are easy to see in this
                   plot.

               iv. It is easy to see many kinds of failures of the model
                   or violations of the underlying assumptions
                   (nonlinearity, heteroscedasticity, unusual patterns).

           Partial regression plots are related to, but distinct from,
           partial residual plots. Partial regression plots are most
           commonly used to identify leverage points and influential data
           points that might not be leverage points. Partial residual
           plots are most commonly used to identify the nature of the
           relationship between Y and X(i) (given the effect of the other
           independent variables in the model).  Since the simple
           correlation betweeen the two sets of residuals plotted is
           equal to the partial correlation between the response variable
           and X(i) partial regression plots will show the correct
           strength of the linear relationship between the response
           variable and X(i).  This is not true for partial residual
           plots.  On the other hand, for the partial regression plot,
           the x axis is not X(i).  This limits its usefulness in
           determining the need for a transformation (which is the
           primary purpose of the partial residual plot).

           Enter HELP PARTIAL REGRESSION PLOT for further information.

        4. Partial Leverage Plot

           Partial leverage is used to measure the contribution of the
           individual independent variables to the leverage of each
           observation.  That is, if h(i) is the i-th row of the diagonal
           of the hat matrix, how does h(i) change as we add a variable
           to the regression model.

           The partial leverage is computed as:

               (PL(j))(i) = (X(j.[j]))**2(i)/
                            SUM[k=1 to n][(X(j.[j]))**2(k)

           where

               j        = j-th independent variable
               i        = the i-th observation
               X(j.[j]) = residuals from regressing X(j) against the
                          remaining indpependent variables

           The partial leverage is the leverage of the i-th point in the
           partial regression plot for the j-th variable.

           The interpretation of the partial leverage plot is that data
           points with large partial leverage for an independent
           variable can exert undue influence on the selection of that
           variable in automatic regression model building procedures
           (e.g., the BEST CP command in Dataplot). 

           Enter HELP PARTIAL LEVERAGE PLOT for further information.

Additional Tests and Intervals:
    The standard Dataplot output (including what is written to
    dpst1f.dat, ... , dpst5f.dat) for linear fits includes parameter
    estimates and associated confidence intervals, prediction limits
    and associated confidence intervals (including Bonferonni and
    Hotelling joint confidence intervals), and the parameter
    covariance and correlation matrices.  There are some additional
    tests and intervals can also be generated from information provided
    by the fit.

        1. The Program example demonstrates how to obtain point estimates
           and confidence intervals (including joint confidence intervals)
           for one or more new points.

        2. The Program example demonstrates how to compute confidence
           intervals for the prediction limits when a different
           significance level is desired.

Regression Diagnostics
    After a fit, it is recommended that various diagnostics be generated
    to assess the adequacy of the model.  The typical assumptions for
    a good model are that the errors from the model are independent and
    identically distributed (typically a normal distribution).

    At a minimum, the following diagnostics should be generated

       1. a 4-plot of the residuals.  The 4-plot generates a run sequence
          plot (to assess common location and scale for the residuals),
          a lag plot (to check for first order autocorrelation of the
          residuals), a histogram, and a normal probability plot.

          This plot provides a useful check on the basic assumptions
          for the error term.  If the assumptions are violated, this
          is an indication that there is structure in the data that is
          not accounted for.

       2. If there is a single independent variable, then it is useful
          to plot the predicted values and the dependent variable against
          the independent variable.

    The term "regression diagnostics" is typically used to denote
    diagnostic statistics and plots that go beyond the standard residual
    analysis.  This is a brief discussion of "regression diagnostics"
    with respect to linear fits performed with a non-iterative algorithm.

    Regression diagnostics are used to identify outliers in the dependent
    variable, identify influential points, to identify high leverage
    points, or in general to uncover features of the data that could
    cause difficulties for the fitted regression model.

    The books by Belsley, Kuh, and Welsch and by Cook and Weisberg listed
    in the References section discuss regression diagnostics in detail.
    The mathematical derivations for the diagnostics covered here can be
    found in these books.  Chapter 11 of the Neter, Wasserman, and
    Kuntner book listed in the References section discusses regression
    diagnostics in a less theoretical way.  We will only give a brief
    overview of the various regression diagnostics.  For more thorough
    guidance on when these various diagnostics are appropriate and how
    to interpret them, see one of these texts (or some other text on
    regression that covers these topics).

    At a minimum, diagnostic analysis of a linear fit includes the
    various plots of the residuals and predicted values described above.
    For more complete diagnostics, the variables written to the file
    dpst3f.dat can be analyzed.  Specifically, this file contains

       Column 1: the diagonals of the hat matrix (the hat matrix is
                 X(X'*X)X' where X' is the transpose of the X
                 matrix).  In themselves, the diagonal elements are
                 measures of the leverage of a given point.  The
                 minimum leverage is (1/N), the maximum leverage is
                 1.0 and the average leverage is (P/N) where P is
                 the number of variables in the fit.  These elements
                 are also used to calculate many other diagnostic
                 statistics.  Note that

                     H(ii) = VAR(Predicted value)/Residual Variance

       Column 2: the variance of the residuals.

                     VAR(res) = MSE*(1 - H(ii))

       Column 3: the standardized residuals.  These are the residuals
                 divided by the square root of the mean square error.

                     STRES = Residual/SQRT(MSE)

       Column 4: the internally studentized residuals.  These are
                 the residuals divided by their standard deviations.

       Column 5: the deleted residuals.  These are residuals obtained
                 from subtracting the predicted values with the i-th
                 case omitted from the observed value.

       Column 6: the externally studentized residuals.  These are the
                 deleted residuals divided by their standard deviation.

       Column 7: Cook's distance.  This is a measure of the impact of the
                 i-th case on all of the estimated regression
                 coefficients.

                     Cook = (res**2/(p*MSE))*H(ii)/(1 - H(ii))**2

       Column 8: DFFITS = EXTSRES*SQRT(H(ii)*(1 - H(ii))

    Additional diagnostic statistics can be computed from these
    values.  Several of the texts in the REFERENCE section
    below discuss the use and interpretation of these statistics
    in more detail.  These variables can be read in as follows:

        SKIP 1
        SET READ FORMAT 8E15.7
        READ DPST3F.DAT HII VARRES STDRES ISTUDRES DELRES ...
                        ESTUDRES COOK DFFITS
        SKIP 0

    Many analysts prefer to use the standardized residuals or the
    internally studentized residuals for the basic residual analysis.
    Deleted residuals and externally deleted residuals are used to
    identify outlying Y observations that the normal residuals do not
    identify (cases with high leverage tend to generate small residuals
    even if they are outliers).

    Many regression diagnostics depend on the Hat matrix (X(X'X)**(-1)X').
    Dataplot has limits on the maximum number of columns/rows for a
    matrix which may prohibit the creation of the full hat matrix for
    some problems.  Fortunately, most of the relevant statistics can be
    derived from the diagonal elements of this matrix (which can be read
    from the dpst3f.dat file). These are also referred to as the leverage
    points. The minimum leverage is (1/N), the maximum leverage is 1.0,
    and the average leverage is (P/N) where P is the number of variables
    in the fit.  As a rule of thumb, leverage points greater than twice
    the average leverage can be considered high leverage.  High leverage
    points are outliers in terms of the X matrix and have an unduly large
    influence on the predicted values. High leverage points also tend to
    have small residuals, so they are not typically detected by standard
    residual analysis.

    The DFFITS values are a measure of influence that observation i has
    on the i-th predicted value.  As a rule of thumb, for small or
    moderate size data sets, values greater than 1 indicate an
    influential case.  For large data sets, values greater than
    2*SQRT(P/N) indicate influential cases.

    Cook’s distance is a measure of the combined impact of the i-th
    observation on all of the regression coefficients. It is typically
    compared to the F distribution.  Values near or above the 50-th
    percentile imply that observation has substantial influence on the
    regression parameters.

    The DFFITS values and the Cook’s distance are used to identify high
    leverage points that are also influential (in the sense that they have
    a large effect on the fitted model).

    Once these variables have been read in, they can be printed, plotted,
    and used in further calculations like any other variable.  This is
    demonstrated in the program example below.  They can also be used to
    derive additional diagnostic statistics.  For example, the program
    example shows how to compute the Mahalanobis distance and Cook’s V
    statistic.  The Mahalanobis distance is a measure of the distance of
    an observation from the “center” of the observations and is
    essentially an alternate measure of leverage.  The Cook’s V statistic
    is the ratio of the variances of the predicted values and the
    variances of the residuals.   Another popular diagnostic is the
    DFBETA statistic. This is similar to Cook’s distance in that it tries
    to identify points that have a large influence on the estimated
    regression coefficients.  The distinction is that DFBETA assesses the
    influence on each individual parameter rather than the parameters as
    a whole.  The DFBETA statistics require the catcher matrix, which is
    described in the multi-collinearity section below, for easy
    computation.  The usual recommendation for DFBETA is that absolute
    values larger than 1 for small and medium size data sets and larger
    than (2/SQRT(N)) for large data sets should be considered
    influential.  The variables written to file dpst3f.dat are
    calculated without computing any additional regressions.  The
    statistics based on a case being deleted are computed from
    mathematically equivalent formulas that do not require additional
    regressions to be performed. The Neter, Wasserman, and Kunter text
    gives the formulas that are actually used.

    Robust regression is often recommended when there are significant
    outliers in the data. One common robust technique is called
    iteratively reweighted least squares (IRLS) (or M-estimation).  Note
    that these techniques protect against outlying Y values, but they do
    not protect against outliers in the X matrix. Also, they test for
    single outliers and are not as sensitive for a group of similar
    outliers.  See the documentation for WEIGHTS, BI-WEIGHT, and TRI-CUBE
    for more information on performing IRLS regression in DATAPLOT.
    Techniques for protecting against outliers in the X matrix use
    alternatives to least squares.  Two such methods are least median
    squares regression (also called LSQ regression) and least trimmed
    squares regression (also called LTS regression).  Dataplot does not
    support these techniques at this time.  The documentation for the
    WEIGHTS command in the Support chapter discusses one approach for
    dealing with outliers in the X matrix in the context of IRLS.

Multi-collinearity
    Multi-collinearity results when the columns of the X matrix have
    significant interdependence (that is, one column is close to a linear
    combination of some collection of other columns).  Multi-collinearity
    typically results in numerically unstable estimates in the sense that
    small changes in the X matrix can result in significant changes in
    the estimated regression coefficients. It can also cause other
    significant problems. mPairwise collinearity can be determined from
    correlation coefficients between independent variables (or from
    pairwise plots).  However, this does not detect higher order
    multi-collinearity. One measure of this is the multiple correlation
    coefficient between the j-th variable and the rest of the independent
    variables.  The Variance Inflation Factor (VIF) is a scaled version
    of this with the following formula:

       VIF(j) = 1/(1 - R(j)**2)

    The VIF values are often given as their reciprocals (this is called
    the tolerance).  Fortunately, these values can be computed without
    performing any additional regressions. The computing formulas are
    based on the catcher matrix, which is X(X'X)**(-1).  The equation is:

       VIF(j) = SUM[i=1 to n][c(ij)**2]*
                SUM[i=1 to n][(x(ij) - xbar(j)**2]

    where c is the catcher matrix.  The CATCHER MATRIX command can be
    used to compute the catcher matrix.  The program example shows how to
    compute the R(j)**2  and the VIF’s.

    Another measure of multi-collinearity are the condition indices. The
    condition indices are calculated as follows:

       1. Scale the columns of the X matrix to have unit sums of squares.

       2. Calculate the singular values of the scaled X matrix and square
          them.

References:
    Cook and Weisberg (1982), "Residuals and Influence in Regression",
    Chapman and Hall.
 
    Belsley, Kuh, and Welsch, (1980),  "Regression Diagnostics",
    John Wiley.

    Neter, Wasserman, and Kunter (1990), "Applied Linear Statistical
    Models", 3rd ed., Irwin.

Program:
    . Note: this program example is meant simply to show how to create
    .       the various plots, intervals and statistics.  It is not a
    .       case study.
    .
    . ZARTHAN COMPAY EXAMPLE FROM
    . "APPLIED LINEAR STATISTICAL MODELS", BY NETER, WASSERMAN, KUTNER
    .
    . Y = SALES
    . X1 = CONSTANT TERM
    . X2 = TARGET POPULATION (IN THOUSANDS)
    . X3 = PER CAPITA DISCRETIONARY INCOME (DOLLARS)
    .
    . Step 1: Read the data
    .
    DIMENSION 500 COLUMNS
    LET NVAR = 2
    READ DISTRICT Y X2 X3
    1 162 274 2450
    2 120 180 3254
    3 223 375 3802
    4 131 205 2838
    5 67 86 2347
    6 169 265 3782
    7 81 98 3008
    8 192 330 2450
    9 116 195 2137
    10 55 53 2560
    11 252 430 4020
    12 232 372 4427
    13 144 236 2660
    14 103 157 2088
    15 212 370 2605
    END OF DATA
    .
    LET N = SIZE Y
    LET X1 = 1 FOR I = 1 1 N
    LET STRING SY  = Sales
    LET STRING SX2 = Population
    LET STRING SX3 = Income
    LET P = NVAR + 1
    .
    . Step 1: Basic Preliminary Plots
    .         1) Independent against dependent
    .         2) INDEPENDENT AGAINST INDEPENDENT
    .
    TITLE OFFSET 2
    TITLE AUTOMATIC
    TITLE CASE ASIS
    LABEL CASE ASIS
    CASE ASIS
    .
    LINE BLANK
    CHARACTER CIRCLE
    CHARACTER HW 1 0.75
    CHARACTER FILL ON
    Y1LABEL DISPLACEMENT 12
    X1LABEL DISPLACEMENT 10
    X2LABEL DISPLACEMENT 15
    .
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    MULTIPLOT SCALE FACTOR 2
    MULTIPLOT 2 2
    .
    Y1LABEL ^SY
    LOOP FOR K = 2 1 P
        LET RIJ = CORRELATION Y X^K
        LET RIJ = ROUND(RIJ,3)
        X1LABEL ^SX^K
        X2LABEL Correlation: ^RIJ
        PLOT Y VS X^K
    END OF LOOP
    .
    LOOP FOR K = 2 1 P
        LET IK1 = K + 1
        Y1LABEL ^SX^K
        LOOP FOR J = IK1 1 P
            LET RIJ = CORRELATION X^K X^J
            LET RIJ = ROUND(RIJ,3)
            X1LABEL ^SX^J
            X2LABEL Correlation: ^RIJ
            PLOT X^K VS X^J
        END OF LOOP
    END OF LOOP
    END OF MULTIPLOT
    LABEL
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Basic Preliminary Plots
    .
    . Step 2: Generate the fit
    .
    SET WRITE DECIMALS 5
    SET LIST NEW WINDOW OFF
    FEEDBACK OFF
    capture program3.out
    FIT Y X2 X3
    WRITE " "
    WRITE " "
    WRITE " "
    WRITE "         ANOVA Table"
    WRITE " "
    LIST dpst5f.dat
    WRITE " "
    WRITE " "
    CAPTURE SUSPEND
    .
    . Step 3b: Generate the basic residual analysis
    .
    TITLE SIZE 4
    TIC MARK LABEL SIZE 4
    CHARACTER HW 2 1.5
    SET 4PLOT MULTIPLOT ON
    TITLE AUTOMATIC
    4-PLOT RES
    TITLE SIZE 2
    TIC MARK LABEL SIZE 2
    CHARACTER HW 1 0.75
    .
    MULTIPLOT 2 2
    TITLE AUTOMATIC
    Y1LABEL Predicted Values
    X1LABEL Response Values
    PLOT PRED VS Y
    Y1LABEL Residuals
    X1LABEL Predicted Values
    PLOT RES VS PRED
    LOOP FOR K = 2 1 P
        Y1LABEL Residuals
        X1LABEL Predicted Values
        PLOT RES VS X^K
    END OF LOOP
    END OF MULTIPLOT
    LABEL
    TITLE
    .
    . Step 3c: Read the information written to auxiliary files.  Some of
    .          these values will be used later in this macro.
    .
    SKIP 1
    READ dpst1f.dat COEF COEFSD TVALUE PARBONLL PARBONUL
    READ dpst2f.dat PREDSD PRED95LL PRED95UL PREDBLL PREDBUL PREDHLL PREDHUL
    READ dpst3f.dat HII VARRES STDRES STUDRES DELRES ESTUDRES COOK DFFITS
    READ dpst4f.dat TEMP1 TEMP2
    LET S2B    = VARIABLE TO MATRIX TEMP1 P
    LET XTXINV = VARIABLE TO MATRIX TEMP2 P
    DELETE TEMP1 TEMP2
    SKIP 0
    .
    . Step 4: Partial Residual and Partial Regression Plots, CCPR and
    .         Partial Leverage Plots not generated
    .
    MULTIPLOT 2 2
    TITLE AUTOMATIC
    Y1LABEL Residuals + A1*X2
    X1LABEL X2
    PARTIAL RESIDUAL   PLOT Y X2 X3 X2
    Y1LABEL Residuals + A2*X3
    X1LABEL X3
    PARTIAL RESIDUAL   PLOT Y X2 X3 X3
    .
    Y1LABEL Residuals: X2 Removed
    X1LABEL Residuals: X2 Versus X3
    PARTIAL REGRESSION PLOT Y X2 X3 X2
    Y1LABEL Residuals: X3 Removed
    X1LABEL Residuals: X3 Versus X2
    PARTIAL REGRESSION PLOT Y X2 X3 X3
    END OF MULTIPLOT
    TITLE
    LABEL
    JUSTIFICATION CENTER
    MOVE 50 97
    Text Partial Residual and Partial Regression Plots
    .
    . Step 5: Calculate function to calculate regression estimate
    .         for new data (F)
    .
    LET A0 = COEF(1)
    LET FUNCTION F = A0
    LET DUMMY = PREDSD(1)
    .
    .         Use (2*NVAR) rather than (2*P) if no constant term in
    .         joint interval
    .
    LOOP FOR K = 1 1 NVAR
        LET INDX = K + 1
        LET A^K = COEF(INDX)
        LET FUNCTION F = F + (A^K)*(Z^K)
    END OF LOOP
    .
    LET Z1 = DATA 220 375
    LET Z2 = DATA 2500 3500
    LET YNEW = F
    .
    CAPTURE RESUME
    PRINT " "
    PRINT " "
    PRINT "NEW X VALUES, ESTIMATED NEW VALUE"
    PRINT Z1 Z2 YNEW
    CAPTURE SUSPEND
    .
    . Step 5b: Print the X'X inverse matrix and parameter
    .          variance-covariance matrix
    .
    CAPTURE RESUME
    PRINT " "
    PRINT " "
    PRINT "THE X'X INVERSE MATRIX"
    PRINT XTXINV
    .
    PRINT " "
    PRINT " "
    PRINT "THE PARAMETER VARIANCE-COVARIANCE MATRIX"
    PRINT S2B
    CAPTURE SUSPEND
    .
    . Step 5c: Calculate:
    .          1) The variance of a new point (S2YHAT)
    .          2) A confidence interval for a new point
    .          3) A joint confidence interval for more than one point
    .          4) A prediction interval for a new point
    .          5) A Scheffe joint prediction interval for more than one point
    .
    LET NPT = SIZE YNEW
    LET NP = N - P
    LOOP FOR IK = 1 1 NPT
        LET XNEW(1) = 1
        LET XNEW(2) = Z1(IK)
        LET XNEW(3) = Z2(IK)
        LOOP FOR K = 1 1 P
            LET DUMMY2 = VECTOR DOT PRODUCT XNEW S2B^K
            LET SUMZ(K) = DUMMY2
        END OF LOOP
        LET S2YHAT = VECTOR DOT PRODUCT SUMZ XNEW
        LET S2YPRED = MSE + S2YHAT
        LET YHATS2(IK) = S2YHAT
        LET YPREDS2(IK) = S2YPRED
        LET SYHAT = SQRT(S2YHAT)
        LET YHATS(IK) = SYHAT
        LET SYPRED = SQRT(S2YPRED)
        LET YPREDS(IK) = SYPRED
        LET YHAT = YNEW(IK)
        CAPTURE RESUME
        PRINT " "
        PRINT " "
        PRINT "THE PREDICTED VALUE FOR THE NEW POINT = ^YHAT"
        PRINT "THE VARIANCE OF THE NEW VALUE = ^S2YHAT"
        PRINT "THE VARIANCE FOR PREDICTION INTERVALS = ^S2YPRED"
        CAPTURE SUSPEND
        LET T = TPPF(.975,NP)
        LET YHATU = YHAT + T*SYHAT
        LET YHATL = YHAT - T*SYHAT
        LET YPREDU = YHAT + T*SYPRED
        LET YPREDL = YHAT - T*SYPRED
        CAPTURE RESUME
        PRINT " "
        PRINT "95% CONFIDENCE INTERVAL FOR YHAT: ^YHATL <= YHAT <= ^YHATU"
        PRINT "95% PREDICTION INTERVAL FOR YHAT: ^YPREDL <= YHAT <= ^YPREDU"
        CAPTURE SUSPEND
    END OF LOOP
    .
    LET ALPHA = 0.10
    LET DUMMY = 1 - ALPHA/(2*NPT)
    LET B = TPPF(DUMMY,NP)
    LET JOINTBU = YNEW + B*YHATS
    LET JOINTBL = YNEW - B*YHATS
    CAPTURE RESUME
    PRINT " "
    PRINT "90% BONFERRONI JOINT CONFIDENCE INTERVALS FOR NEW VALUES"
    PRINT JOINTBL YNEW JOINTBU
    CAPTURE SUSPEND
    LET W = P*FPPF(.90,P,NP)
    LET W = SQRT(W)
    LET JOINTWU = YNEW + W*YHATS
    LET JOINTWL = YNEW - W*YHATS
    CAPTURE RESUME
    PRINT " "
    PRINT "90% HOTELLING JOINT CONFIDENCE INTERVALS FOR NEW VALUES"
    PRINT JOINTWL YNEW JOINTWU
    CAPTURE SUSPEND
    LET JOINTBU = YNEW + B*YPREDS
    LET JOINTBL = YNEW - B*YPREDS
    CAPTURE RESUME
    PRINT " "
    PRINT "90% BONFERRONI JOINT PREDICTION INTERVALS FOR NEW VALUES"
    PRINT JOINTBL YNEW JOINTBU
    CAPTURE SUSPEND
    LET S = NPT*FPPF(.90,NPT,NP)
    LET S = SQRT(S)
    LET JOINTSU = YNEW + S*YPREDS
    LET JOINTSL = YNEW - S*YPREDS
    CAPTURE RESUME
    PRINT " "
    PRINT "90% SCHEFFE JOINT PREDICTION INTERVALS FOR NEW VALUES"
    PRINT JOINTSL YNEW JOINTSU
    CAPTURE SUSPEND
    .
    . Step 6: Plot various diagnostic statistics
    .
    .         Derive Cook's V statistic and Mahalanobis distance
    .
    LET V = (PREDSD**2)/(RESSD**2)
    LET MAHAL = ((HII-1/N)/(1-HII))*(N*(N-2)/(N-1))
    LET HBAR = P/N
    LET DUMMY = SUM HII
    SET WRITE FORMAT 5F10.5
    CAPTURE RESUME
    PRINT " "
    PRINT "            HII           COOK         DFFITS              V          MAHAL"
    PRINT HII COOK DFFITS V MAHAL
    CAPTURE SUSPEND
    SET WRITE FORMAT
    .
    . Step 6b: Plot various diagnostic statistics
    .
    .          Plot various residuals
    .
    X1LABEL
    XLIMITS 0 15
    MAJOR XTIC MARK NUMBER 4
    XTIC OFFSET 0 1
    MULTIPLOT 2 2
    TITLE STANDARDIZED RESIDUALS
    PLOT STDRES
    TITLE INTERNALLY STUDENTIZED RESIDUALS
    PLOT STUDRES
    TITLE DELETED RESIDUALS
    X1LABEL PRESS STATISTIC = ^PRESSP
    PLOT DELRES
    X1LABEL
    TITLE EXTERNALLY STUDENTIZED RESIDUALS
    PLOT ESTUDRES
    END OF MULTIPLOT
    .
    .          Plot several diagnotic statistics
    .
    .
    MULTIPLOT 2 2
    CHARACTER FILL ON OFF
    CHARACTER CIRCLE BLANK
    LINE BLANK SOLID DOTTED
    TITLE PLOT OF LEVERAGE POINTS
    Y1LABEL
    X1LABEL DOTTED LINE AT 2*AVERAGE LEVERAGE
    YTIC OFFSET 0 0.1
    LET TEMP6 = DATA 1 N
    LET DUMMY = 2*HBAR
    LET TEMP4 = DATA DUMMY DUMMY
    LET TEMP5 = DATA HBAR HBAR
    SPIKE ON
    SPIKE BASE HBAR
    SPIKE LINE DOTTED
    .
    PLOT HII AND
    PLOT TEMP4 TEMP5 VS TEMP6
    SPIKE OFF
    YTIC OFFSET 0 0
    .
    CHARACTER CIRCLE BLANK BLANK
    LINE BLANK DOTTED DOTTED
    Y1LABEL
    X1LABEL DOTTED LINES AT 1 AND 2*SQRT(P/N)
    LET TEMP4 = DATA 1 1
    LET DUMMY = 2*SQRT(P/N)
    LET TEMP5 = DATA DUMMY DUMMY
    TITLE PLOT OF DFFITS POINTS
    .
    PLOT DFFITS AND
    PLOT TEMP4 TEMP5 VS TEMP6
    .
    X1LABEL DOTTED LINES AT 20 AND 50TH PERCENTILES OF F DISTRIBUTION
    LET DUMMY = FPPF(.20,P,NP)
    LET TEMP4 = DATA DUMMY DUMMY
    LET DUMMY = FPPF(.50,P,NP)
    LET TEMP5 = DATA DUMMY DUMMY
    TITLE PLOT OF COOK'S DISTANCE
    .
    PLOT COOK AND
    PLOT TEMP4 TEMP5 VS TEMP6
    .
    X1LABEL
    TITLE PLOT OF MAHALANOBIS DISTANCE
    PLOT MAHAL
    .
    END OF MULTIPLOT
    .
    . Step 6c: Calculate:
    .
    .          1. Catcher matrix
    .          2. Variance inflation factors
    .          3. Condition numbers of X'X (based on singular
    .             values of scaled X)
    .          4. Partial regression plots (also called added variable plots)
    .          5. Partial leverage plots
    .          6. DFBETA'S
    .
    LET XMAT  = CREATE MATRIX X1 X2 X3
    LET C     = CATCHER MATRIX XMAT
    LET VIF   = VARIANCE INFLATION FACTORS XMAT
    LET RJ    = 0 FOR I = 1 1 NP
    LET RJ    = 1 - (1/VIF)  SUBSET VIF > 0
    LET TOL   = 1/VIF        SUBSET VIF > 0
    LET DCOND = CONDITION INDICES XMAT
    CAPTURE RESUME
    PRINT " "
    PRINT " "
    PRINT "                                 CONDITION"
    PRINT " Rj-SQUARE       VIF   TOLERANCE   INDICES"
    SET WRITE FORMAT 5X,F5.3,F10.5,F12.5,F10.5
    PRINT RJ VIF TOL DCOND
    CAPTURE SUSPEND
    .
    MULTIPLOT 2 2
    CHARACTER CIRCLE
    LINE BLANK
    SPIKE BLANK
    LIMITS DEFAULT
    TIC OFFSET 0 0
    MAJOR TIC MARK NUMBER DEFAULT
    .
    LOOP FOR K = 2 1 P
        TITLE Partial Regression Plot for X^K
        PARTIAL REGRESSION PLOT Y X2 X3 X^K
        .
        TITLE PARTIAL LEVERAGE FOR X^K
        PARTIAL LEVERAGE PLOT Y X2 X3 X^K
        .
        LET DUMMY = XTXINV^K(K)
        LET DFBETA^K = (C^K*ESTUDRES)/SQRT(DUMMY*(1-HII))
    END OF LOOP
    END OF MULTIPLOT
    .
    LET DUMMY = XTXINV1(1)
    TITLE PLOT OF DFBETA'S (B0, B1, B2)
    LINE BLANK ALL
    CHARACTER B0 B1 B2
    CHARACTER SIZE 2 ALL
    LET TEMP4 = SEQUENCE 1 1 N
    LET DFBETA1 = (C1*ESTUDRES)/SQRT(DUMMY*(1-HII))
    PLOT DFBETA1 DFBETA2 DFBETA3 VS TEMP4

-----RJ (LET)----------------------------------------------
 
RJ
 
Name:
    RJ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute Carlson's elliptic integral of the third kind.
 
Description:
    Carlson's elliptic integral of the third kind is defined as:
        RJ(x,y,z,p)=1.5*INTEGRAL[1/((t+p)*SQRT((t+x)*(t+y)*(t+z)))]dt
    where INTEGRAL is the integral from 0 to infinity.  The parameters
    x, y, and z must all be non-negative with at most one of them
    being zero.  The p parameter must be non-zero.

Syntax:
    LET <a> = RJ(<x>,<y>,<z>,<p>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, parameter, or variable;
          <y> is a non-negative number, parameter, or variable;
          <z> is a non-negative number, parameter, or variable;
          <p> is a non-zero number, parameter, or variable;
          <a> is a variable or a parameter (depending on what, <p>,
               <x>, <y>, and <z> are) where the computed values are
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RJ(2,1,3,1)
    LET A = RJ(X,0,4,1)
    LET X2 = RJ(1,1,Y,P)
 
Note:
    The Carlson elliptic integrals are computed using the RC, RD, RF,
    and RJ routines from the SLATEC Common Mathematical Library.
    SLATEC is a large set of high quality, portable, public domain
    Fortran routines for various mathematical capabilities maintained
    by seven federal laboratories.

Note:
    DATAPLOT computes Legendre elliptic integrals by computing the
    equivalent Carlson elliptic integrals.  See the documentation for
    the ELLIP1, ELLIP2, ELLIP3, ELLIPC1, and ELLIPC2 functions for
    details on computing Legendre elliptic functions in DATAPLOT.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RF      = Compute the Carlson elliptic integral of the first kind.
    RC      = Compute the degenerate Carlson elliptic integral.
    RD      = Compute the Carlson elliptic integral of the second kind.
    ELLIPC1 = Compute the Legendre complete elliptic integral of the
              first kind.
    ELLIPC2 = Compute the Legendre complete elliptic integral of the
              second kind.
    ELLIP1  = Compute the Legendre elliptic integral of the first
              kind.
    ELLIP2  = Compute the Legendre elliptic integral of the second
              kind.
    ELLIP3  = Compute the Legendre's elliptic integral of the third
              kind.
 
Reference:
    "Algorithms for Incomplete Elliptic Integrals by Duplication", 
    Carlson, ACM Transactions on Mathematical Software, 7,
    pp. 398-403.

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 17).

Applications:
    Special Functions
 
Implementation Date:
    94/9
 
Program:
    TITLE CARLSON ELLIPTIC FUNCTIONS
    PLOT RJ(X,1,2,1) FOR X = 0.1 0.1 10 AND
    PLOT RJ(1,X,2,2) FOR X = 0.1 0.1 10 AND
    PLOT RJ(1,2,2,P) FOR P = 0.1 0.1 10
 
-----RELATIVE DISPERSION INDEX (LET)-----------------------------------------
 
RELATIVE DISPERSION INDEX
 
Name:
    RELATIVE DISPERSION INDEX (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Given a vector of counts, compute the difference from uniformity
    based on a transformation of the variational distance.
 
Description:
    In spatial analysis, it is sometimes desired to determine if the
    points in the given space are consistent with a uniform
    distribution.  One such measure is based on the variational distance
    which is defined as

        d = 0.5*SUM[k=0 to infinity][|P(Unif=k) - P(data=k)|]

    Given that the points have been converted to a set of N counts, X(k),
    this formula becomes


        d = 0.5*SUM[k=1 to N][|((1/N) - X(k))/SUM[k=1 to N][X(k)]|]

    The value of the variational distance is between zero and one with
    values closer to zero indicating greater consistency with a uniform
    distribution.

    The relative dispersion index is a scaled version of the variational
    distance

       RDI = 100*(1 - d)

    where d is the variational distance statistic.  This transforms the
    zero to one scale to a zero to 100 scale.  Values close to 100 indicate
    consistency with a uniform distribution.

Syntax:
    LET <a> = RELATIVE DISPERSION INDEX <y>
                       <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <a> is a parameter where the computed statistic is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RELATIVE DISPERSION INDEX Y1
    LET A = RELATIVE DISPERSION INDEX Y1  SUBSET TAG > 2
 
Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    VARIATIONAL DISTANCE       = Compute the variational distance of
                                 a variable containing a set of counts.
    UNIFORM CHISQUARE STAT     = Compute the chi-square statistic for 
                                 uniformity for a variable containing a
                                 set of counts.
    GOODNESS OF FIT            = Perform a goodness of fit test.
 
Reference:
    Kashiwagi, Fagan, Douglas, Yamamoto, Heckert, Leigh, Obrzut, Du, Lin-Gibson,
    Mu, Winey, Haggennueller (2007), "Relationship between dispersion metric and
    properties of PMMA/SWNT nanocomposites", Polymer Journal, Vol. 48,
    pp. 4855 - 4866.

Applications:
    Spatial Statistics
 
Implementation Date:
    2014/3
 
Program:
    LET Y  = UNIFORM RANDOM NUMBERS FOR I = 1 1 1000
    LET Y1 X1 = BINNED Y
    LET Y  = NORMAL RANDOM NUMBERS FOR I = 1 1 1000
    LET Y2 X2 = BINNED Y
    LET Y  = EXPONENTIAL RANDOM NUMBERS FOR I = 1 1 1000
    LET Y3 X3 = BINNED Y
    LET A1 = RELATIVE DISPERSION INDEX Y1
    LET A2 = RELATIVE DISPERSION INDEX Y2
    LET A3 = RELATIVE DISPERSION INDEX Y3
    SET WRITE DECIMALS 4
    PRINT A1 A2 A3
 
-----RELATIVE RISK (LET)--------------------------------
 
RELATIVE RISK
 
Name:
    RELATIVE RISK (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the relative risk between two binary variables.
 
Description:
    Given two variables with n parired observations where each
    variable has exactly two possible outcomes, we can generate
    the following 2x2 table:

                      |       Variable 2        |
        Variable 1    |   Success      Failure  |  Row Total
        ====================================================
        Success       |   N11            N12    |  N11 + N12
        Failure       |   N21            N22    |  N21 + N22
        ====================================================
        Column Total  |   Success      Failure  |  Total

    The parameters N11, N12, N21, and N22 denote the counts
    for each category.
 
    Success and failure can denote any binary response.
    Dataplot expects "success" to be coded as "1" and "failure"
    to be coded as "0".  Some typical examples would be:

       1) Variable 1 denotes whether or not a patient has a
          disease (1 denotes disease is present, 0 denotes
          disease not present).  Variable 2 denotes the result
          of a test to detect the disease (1 denotes a positive
          result and 0 denotes a negative result).

       2) Variable 1 denotes whether an object is present or
          not (1 denotes present, 0 denotes absent). Variable 2
          denotes a detection device (1 denotes object detected
          and 0 denotes object not detected).

    In these examples, the "ground truth" is typically given
    as variable 1 while some estimator of the ground truth is
    given as variable 2.
   
    The relative risk is defined as the ratio of the
    probability of "success" probabilities, that is

        relative risk = {N11/(N11+N21)}/{N12/(N12+N22)}

    The relative risk is a useful statistic when comparing the
    difference in two binomial proportions when the probabilities
    of success are close to zero.  For example, page 21 of
    Agresti gives the example where the absolute difference of
    proportions between 0.410, 0.401 and 0.010, 0.001 are both
    0.09.  However the relative risks are 0.410/0.401 = 1.02
    and 0.010/0.001 = 10.

Syntax:
    LET <par> = RELATIVE RISK <y1> <y2>
                              <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed relative risk
               proportion is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RELATIVE RISK Y1 Y2
    LET A = RELATIVE RISK Y1 Y2 SUBSET TAG > 2
 
Note:
    The two variables need not have the same number of elements.
 
Note:
    Dataplot statistics can be used in 20+ commands.  For details, enter

         HELP STATISTICS

Note:
    There are two ways you can define the response variables:

       1) Raw data - in this case, the variables contain
          0's and 1's.

          If the data is not coded as 0's and 1's, Dataplot
          will check for the number of distinct values.  If
          there are two distinct values, the minimum value
          is converted to 0's and the maximum value is
          converted to 1's.  If there is a single distinct
          value, it is converted to 0's if it is less than
          0.5 and to 1's if it is greater than or equal to
          0.5.  If there are more than two distinct values,
          an error is returned.

       2) Summary data - if there are two observations, the
          data is assummed to be the 2x2 summary table.
          That is,

              Y1(1) = N11
              Y1(2) = N21
              Y2(1) = N12
              Y2(2) = N22
 
    Note that the above commands expect the variables to have
    the same number of observations.  If the two samples are
    in fact of different sizes, there are two ways to address
    the issue:

       1) Y1 and Y2 can contain the summary data.  That is,

            Y1(1) = N11
            Y1(2) = N21
            Y2(1) = N12
            Y2(2) = N22

          This is a useful option in that the data is sometimes
          only available in summary form.  Note that this will
          not work for the BOOTSTRAP PLOT and JACKNIFE PLOT
          commands (these require raw data).

       2) You can specify a missing value for the smaller
          sample.  For example, if Y1 has 100 observations and
          Y2 has 200 observations, you can do something like

              SET STATISTIC MISSING VALUE -99
              LET Y1 = -99 FOR I = 101  1  200
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    ODDS RATIO                 = Compute the bias corrected
                                 log(odds ratio).
    ODDS RATIO STANDARD ERROR  = Compute the standard error of the
                                 bias corrected log(odds ratio).
    FALSE POSITIVES            = Compute the proportion of
                                 false positives.
    FALSE NEGATIVES            = Compute the proportion of
                                 false negatives.
    TRUE NEGATIVES             = Compute the proportion of
                                 true negatives.
    TRUE POSITIVES             = Compute the proportion of
                                 true positives.
    TEST SENSITIVITY           = Compute the test sensitivity.
    TEST SPECIFICITY           = Compute the test specificity.
    TABULATE                   = Compute a statistic for data with
                                 a single grouping variable.
    CROSS TABULATE             = Compute a statistic for data with
                                 two grouping variables.
    STATISTIC PLOT             = Generate a plot of a statistic for
                                 data with a single grouping
                                 variable.
    CROSS TABULATE PLOT        = Generate a plot of a statistic for
                                 data with two grouping variables.
    BOOTSTRAP PLOT             = Generate a bootstrap plot for a
                                 given statistic.
 
References:
    Fleiss, Levin, and Paik (2003), "Statistical Methods for
    Rates and Proportions", Third Edition, Wiley, chapter 1.
 
    Agresti (2007), "Introduction to Categorical Data Analysis",
    Second Edition, Wiley.

Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/4
 
Program:
    let n = 1
    .
    let p = 0.2
    let y1 = binomial rand numb for i = 1 1 100
    let p = 0.1
    let y2 = binomial rand numb for i = 1 1 100
    .
    let p = 0.4
    let y1 = binomial rand numb for i = 101 1 200
    let p = 0.08
    let y2 = binomial rand numb for i = 101 1 200
    .
    let p = 0.15
    let y1 = binomial rand numb for i = 201 1 300
    let p = 0.18
    let y2 = binomial rand numb for i = 201 1 300
    .
    let p = 0.6
    let y1 = binomial rand numb for i = 301 1 400
    let p = 0.45
    let y2 = binomial rand numb for i = 301 1 400
    .
    let p = 0.3
    let y1 = binomial rand numb for i = 401 1 500
    let p = 0.1
    let y2 = binomial rand numb for i = 401 1 500
    .
    let x = sequence 1 100 1 5
    .
    let a = relative risk y1 y2 subset x = 1
    tabulate relative risk y1 y2 x
    .
    label case asis
    xlimits 1 5
    major xtic mark number 5
    minor xtic mark number 0
    xtic mark offset 0.5 0.5
    y1label Relative Risk
    x1label Group ID
    character x blank
    line blank solid
    .
    relative risk plot y1 y2 x
 
-----RELATIVE STANDARD DEVIATION (LET)------------------------------
 
RELATIVE STANDARD DEVIATION
 
Name:
    RELATIVE STANDARD DEVIATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the relative standard deviation of a variable.
 
Description:
    The relative standard deviation is:
         relsd = 100*(standard deviation/abs(mean))
    Some analysts prefer to call this the percent relative standard
    deviation and the value obtained without multiplying by 100 the
    relative standard deviation.  If this is your preference, simply
    divide the obtained value by 100 with the LET command.
 
Syntax:
    LET <par> = RELATIVE STANDARD DEVIATION <x1>
               <SUBSET/EXCEPT/FOR qualification>
    where <x1> is a response variable;
          <par> is a parameter where the relative standard deviation
              value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET RSD = RELATIVE STANDARD DEVIATION Y1
    LET RSD = RELATIVE STANDARD DEVIATION Y1  SUBSET TAG > 2
 
Note:
    Versions prior to 94/2 use the mean rather than the absolute value
    of the mean.
 
Default:
    None
 
Synonyms:
    COEFFICIENT OF VARIATION
    COEFFICIENT VARIATION
    RELATIVE SD
 
Related Commands:
    MEAN (LET)        = Compute the mean of a variable.
    STAND DEVI (LET)  = Compute the standard deviation of a variable.
    RELATIVE SD PLOT  = Generate a relative standard deviation (versus
                        subset) plot.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET RSD = RELATIVE STANDARD DEVIATION X1
 
-----RELATIVE VARIANCE (LET)------------------------------
 
RELATIVE VARIANCE
 
Name:
    RELATIVE VARIANCE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the relative variance of a variable.
 
Description:
    The relative variance is:
         relvar = 100*(variance/mean)
    Some analysts prefer to call this the percent relative variance and
    the value obtained without multiplying by 100 the relative variance.
    If this is your preference, simply divide the obtained value by 100
    with the LET command.  If you prefer to use the absolute value of
    the mean, use the LET command to calculate the absolute value of
    the value (e.g., LET RELVAR = ABS(RELVAR)).
 
Syntax:
    LET <par> = RELATIVE VARIANCE <y> <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <par> is a parameter where the relative variance value is
              stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET RELVAR = RELATIVE VARIANCE Y1
    LET RELVAR = RELATIVE VARIANCE Y1  SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MEAN                    = Compute the mean of a variable.
    VARIANCE                = Compute the variance of a variable.
    STANDARD DEVIATION      = Compute the standard deviation of a
                              variable.
    RELATIVE VARIANCE PLOT  = Generate a relative variance versus
                              subset plot.
    RELATIVE STANDARD DEVI  = Compute the relative standard deviation
                              of a variable.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    SKIP 25
    READ GEAR.DAT DIAMETER
    LET RELVAR = RELATIVE VARIANCE DIAMETER
 
-----RELATIVE VARIANCE PLOT-----------------------------------------
 
RELATIVE VARIANCE PLOT
 
Name:
    RELATIVE VARIANCE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a relative variance plot.
 
Description:
    A relative variance plot is a plot consisting of subsample relative
    variances versus subsample index.  The relative variance is the
    variance divided by the mean times 100.  The subsample relative
    variance is the relative variance of the data in the subsample.  The
    relative variance plot is used to answer the question--"Does the
    subsample spread change over different subsamples?".  The plot
    consists of:
       Vertical   axis = subsample relative variance;
       Horizontal axis = subsample index.
    The relative variance plot yields 2 traces:
       1. a subsample relative variance trace; and
       2. a full-sample relative variance reference line.
    Like usual, the appearance of these 2 traces is controlled by
    the first 2 settings of the LINES, CHARACTERS, SPIKES, BARS,
    and similar attributes.
 
Syntax:
    RELATIVE VARIANCE PLOT <y> <x>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    RELATIVE VARIANCE PLOT Y X
    RELATIVE VARIANCE PLOT Y TAG SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RELATIVE VARIANCE  = Compute the relative variance of a variable.
    RELSD PLOT         = Generates a relative standard deviation plot.
    CHARACTERS         = Sets the type for plot characters.
    LINES              = Sets the type for plot lines.
    MEAN   PLOT        = Generates a mean plot.
    SD   PLOT          = Generates a standard deviation plot.
    BOX PLOT           = Generates a box plot.
    XBAR CHART         = Generates a mean control chart.
    PLOT               = Generates a data or function plot.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    88/2
 
Program:
    SKIP 25
    READ GEAR.DAT DIAMETER BATCH
    LINE BLANK DASH
    CHARACTER X BLANK
    XTIC OFFSET 0.2 0.2
    Y1LABEL RELATIVE VARIANCE
    X1LABEL SAMPLE BATCH
    TITLE AUTOMATIC
    RELATIVE VARIANCE PLOT DIAMETER BATCH
 
-----RELDIF (LET)--------------------------------
 
RELDIF
 
Name:
    RELDIF (LET)
 
Type:
    Library Function
 
Purpose:
    Return the relative difference of two numbers.

Description:
    The definition of the relative difference between X1 and X2 used
    by Dataplot is:

         Relative Difference = ABS(X1 - X2)/MAX(ABS(X1),ABS(X2))
 
    Dataplot also supports the alternative formula

         Relative Difference = ABS((X1 - X2)/((X1 + X2)/2))
 
Syntax 1:
    LET <y> = RELDIF(<y1>,<y2>)      <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter;
          <y>  is a variable or a parameter (depending on what <y1> and
               <y2> are) where the computed relative difference values
               are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax implements the first formula given above (the
    denominator is the maximum of the two values).

Syntax 2:
    LET <y> = RELDIF2(<y1>,<y2>)      <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter;
          <y>  is a variable or a parameter (depending on what <y1> and
               <y2> are) where the computed relative difference values
               are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax implements the second formula given above (the
    denominator is the average of the two values).

Examples:
    LET A = RELDIF(14,10)
    LET A = RELDIF(A1,A2)
    LET X2 = RELDIF(X1,X4)
    LET X2 = RELDIF(X1-4,X2+6)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RELERR   = Compute the relative error of two numbers.
    PERCDIF  = Compute the percent difference of two numbers.
    PERCERR  = Compute the percent error of two numbers.
    MIN      = Compute the minimum of two numbers.
    MAX      = Compute the maximum of two numbers.
    ABS      = Compute the absolute value of a number.
 
Applications:
    Data Management
 
Implementation Date:
    2010/12
 
Program:
    LET X = SEQUENCE 0.1  0.1  3
    LET Y1 = X**2
    LET Y2 = X**(1/2)
    LET Y3 = RELDIF(Y1,Y2)
    SET WRITE DECIMALS 5
    PRINT Y1 Y2 Y3
 
-----RELERR (LET)--------------------------------
 
RELERR
 
Name:
    RELERR (LET)
 
Type:
    Library Function
 
Purpose:
    Return the relative error of two numbers.

Description:
    The definition of the relative error between a "true" value
    X(t) and an observed value X(o) used by Dataplot is:

         Relative Error = (X(t) - X(o))/X(t)

    There may be some slight differences for this formula in other
    sources.  Specifically,

    1) Some sources take the absolute value of the above
       quantity.  In Dataplot, you can use the ABS function
       to obtain this form.

    2) Some sources may reverse the order of the X(t) and X(o) values.
       This changes the sign of the result, but not the magnitude.

 
Syntax:
    LET <y> = RELERR(<y1>,<y2>)      <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter;
          <y>  is a variable or a parameter (depending on what <y1> and
               <y2> are) where the computed relative error values
               are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = RELERR(14,10)
    LET A = RELERR(A1,A2)
    LET X2 = RELERR(X1,X4)
    LET X2 = RELERR(X1-4,X2+6)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RELDIF   = Compute the relative difference of two numbers.
    PERCDIF  = Compute the percent difference of two numbers.
    PERCERR  = Compute the percent error of two numbers.
    MIN      = Compute the minimum of two numbers.
    MAX      = Compute the maximum of two numbers.
    ABS      = Compute the absolute value of a number.
 
Applications:
    Data Management
 
Implementation Date:
    2010/12
 
Program:
    LET X = SEQUENCE 0.1  0.1  3
    LET Y1 = X**2
    LET Y2 = X**(1/2)
    LET Y3 = RELERR(Y1,Y2)
    SET WRITE DECIMALS 5
    PRINT Y1 Y2 Y3
 
-----RELIABILITY TRENDS TEST---------------------------------
 
RELIABILITY TRENDS TEST
 
Name:
    RELIABILITY TRENDS TEST
 
Type:
    Analysis Command
 
Purpose:
    Compute tests to determine whether or not the repair times of
    a system show significant trend.  The trend may be either an
    improvement or a degradation.

    Specifically, it computes the following three tests

        1) The reverse arrangement test.
        2) The military handbook test.
        3) The Laplace test.

Description:
    Determining if repair times exhibit a trend is necessary for
    choosing an appropriate reliability model.  These formal tests
    for trend in repair times are a compliment to the Duane plot
    for detecting trend.

    Each of these tests will be described separately.

    1) The Reverse Arrangement Test

       Given r repairs, T1, T2, ...., Tr, the interarrival
       times I2=R2-T1, I3=T3-T2, ...., Ir=Tr-T(r-1), and the
       censoring time T(end) > Tr, we calculate how many instances
       we have of a later interarrival time being strictly greater
       than an earlier interarrival time.  These are called 
       reversals.  Too many reversals indicates a significant
       improving trend and too few reversals indicates a
       significant degradation trend.  More formally,

          1) Count a reversal every time I(j) < I(k) for some
             j and k with j < k.

          2) Compute the total number of reversals, R.

          3) For r repair times, the maximum possible number of
             reversals is r(r-1)/2.

          4) If there are no trends, the expected number of 
             reversals is r(r-1)/4.

          5) For r > 12, the following approximation can be
             used to determine if the number of reversals is
             statistically significant.

                z = R - C1 + 0.5/SQRT(C2)

             where

                C1 = r(r-1)/4
                C2 = (2r+5)(r-1)r/72

             The test statistic is compared to a standard
             normal distribution.  That is, if |z| > 1.96, we
             have statistical significance at the 95% level.

             For r <= 12, tabled values are used.

       The advantage of this test is that it is simple and it
       makes no assumptions about a model for the possible trend.

    2) The Military Handbook Test

       Given r repairs, T1, T2, ...., Tr and the censoring time
       T(end) > Tr, we calculate the test statistic

           T = 2*SUM(ln(T(end)/T(i)))

       where the summation is from i=1 to r.

       This test statistic follows a chi-square distribution with
       2*r degrees of freedom.

       This test is recommended for the case when the choice is
       between no trend and a non-homogeneous Poisson process
       (NHPP) power law (Duane) model.

    3) The Laplace Test

       Given r repairs, T1, T2, ...., Tr and the censoring time
       T(end) > Tr, we calculate the test statistic

           z = SQRT(12*r)*SUM(T(i) - T(end)/2)/r*T(end)

       where the summation is from i=1 to r.

       This test statistic follows a standard normal distribution.

       This test is recommended for the case when the choice is
       between no trend and a non-homogeneous Poisson process
       (NHPP) exponential law model.

    If you have internet access, you can enter the following
    command to see a discussion of the power law model

          WEB HANDBOOK NHPP POWER LAW

Syntax:
    RELIABILITY TREND TEST <y>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    RELIABILITY TREND TEST Y
    RELIABILITY TREND TEST Y  SUBSET TAG > 0
 
Note:
    These commands require a censoring time.  Enter the following
    command before the RELIABILITY TREND TEST command to 
    specify the censoring time:

        LET TEND = <censor time>

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    DUANE PLOT                = Generate a Duane plot.
    POWER LAW RANDOM NUMBERS  = Generate random number from a 
                                NHPP power law model.
    INTERARRIVAL TIME         = Compute interarrival times of a
                                variable.
 
Applications:
    Reliability
 
Implementation Date:
    1998/5
 
Program:
    skip 25
    read hahn.dat y tag
    .
    LET TEND = 135000
    RELIABILITY TREND TEST Y SUBSET TAG = 1
 
    The following output is generated:


     ***** NOTE--
           SUBSET VARIABLE = TAG
           SUBSET MINIMUM  =  0.9999989867E+00
           SUBSET MAXIMUM  =  0.1000000954E+01
           INPUT  NUMBER OF OBSERVATIONS  =       96
           NUMBER OF OBSERVATIONS IGNORED =       59
           OUTPUT NUMBER OF OBSERVATIONS  =       37
      
     REVERSE ARRANGEMENTS TEST:
           NUMBER OF FAILURE TIMES               =       37
           OBSERVED NUMBER OF REVERSALS          =      215
           MAXIMUM POSSIBLE NUMBER OF REVERSALS  =      666
           EXPECTED NUMBER OF REVERSALS          =      333
           VALUE OF TEST STATISTIC               =  -21.40790
           90% CRITICAL VALUE FOR NO IMPROVEMENT = 1.282
           95% CRITICAL VALUE FOR NO IMPROVEMEMT = 1.645
           99% CRITICAL VALUE FOR NO IMPROVEMENT = 2.33
      
      
     MILITARY HANDBOOK TEST:
           NUMBER OF FAILURE TIMES               =       37
           CHI-SQUARE TEST STATISTIC VALUE       =    35.72037
           CHI-SQUARE TEST STATISTIC CDF VALUE   =   0.4925163E-04
      
           IMPROVEMENT TEST
           HYPOTHESIS     ACCEPTANCE INTERVAL    CONCLUSION
           NO TREND          (0.000,0.900)         ACCEPT
           NO TREND          (0.000,0.950)         ACCEPT
           NO TREND          (0.000,0.990)         ACCEPT
      
      
           DEGRADATION TEST
           HYPOTHESIS     ACCEPTANCE INTERVAL    CONCLUSION
           NO TREND          (0.100,1)             REJECT
           NO TREND          (0.050,1)             REJECT
           NO TREND          (0.010,1)             REJECT
      
      
      
     LAPLACE TEST:
           NUMBER OF FAILURE TIMES               =       37
           NORMAL TEST STATISTIC VALUE       =    3.416969
           NORMAL TEST STATISTIC CDF VALUE   =   0.9996833
      
           IMPROVEMENT TEST
           HYPOTHESIS     ACCEPTANCE INTERVAL    CONCLUSION
           NO TREND          (0.000,0.900)         REJECT
           NO TREND          (0.000,0.950)         REJECT
           NO TREND          (0.000,0.990)         REJECT
      
      
           DEGRADATION TEST
           HYPOTHESIS     ACCEPTANCE INTERVAL    CONCLUSION
           NO TREND          (0.100,1)             ACCEPT
           NO TREND          (0.050,1)             ACCEPT
           NO TREND          (0.010,1)             ACCEPT
      
      
-----RELSD PLOT------------------------------------------------
 
RELSD PLOT
 
Name:
    RELSD PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a relative standard deviation plot.
 
Description:
    A relative standard deviation plot is a plot consisting of
    subsample relative standard deviations versus subsample index.
    The subsample relative standard deviation is the relative standard
    deviation of the data in the subsample.  The relative standard
    deviation plot is used to answer the question--"Does the subsample
    spread change over different subsamples?".  It consists of:
       Vertical   axis = subsample relative standard deviation;
       Horizontal axis = subsample index.
    The relative standard deviation plot yields 2 traces:
       1. a subsample relative standard deviation trace; and
       2. a full-sample relative standard deviation reference line.
    Like usual, the appearance of these 2 traces is controlled by
    the first 2 settings of the LINES, CHARACTERS, SPIKES, BARS,
    and similar attributes.
 
Syntax:
    RELSD PLOT   <y>   <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    RELSD PLOT Y X
    RELSD PLOT Y TAG SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS         = Sets the type for plot characters.
    LINES              = Sets the type for plot lines.
    MEAN   PLOT        = Generates a mean plot.
    SD   PLOT          = Generates a standard deviation plot.
    BOX PLOT           = Generates a box plot.
    XBAR CHART         = Generates a xbar control chart.
    PLOT               = Generates a data or function plot.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    88/2
 
Program:
    SKIP 25
    READ GEAR.DAT DIAMETER BATCH
    LINE BLANK DASH
    CHARACTER X BLANK
    XTIC OFFSET 0.2 0.2
    Y1LABEL RELATIVE STANDARD DEVIATION
    X1LABEL SAMPLE BATCH
    TITLE AUTOMATIC
    RELSD PLOT DIAMETER BATCH
 
-----RENAME-------------------------------------------------------
 
RENAME
    RENAME
 
Type:
    Support Command
 
Purpose:
    Specifies an additional name to be assigned to an already-existing
    variable.
 
Description:
    This is useful, for example, if the analyst has written a generic
    sub-program which makes reference to, say, X and Y, while the
    variable names in the main program are, say, PRESSURE and TEMP.
    The RENAME command is efficient in that it does not duplicate the
    data.  Thus RENAME X PRESSURE will not duplicate the data already
    existing in the variable PRESSURE (as would LET X = PRESSURE).  It
    merely adds the additional name X by which that same data in
    PRESSURE can be subsequently referred.
 
Syntax:
    RENAME   <name 1>   <name 2>
    where <name 1> is the name of an already-existing variable;
    and   <name 2> is the desired additional name by which that
                   variable can be referred.
 
Examples:
    RENAME PRESSURE Y
 
Note:
    The name list can be extended in pairs; thus
       RENAME PRESSURE Y TEMP X CONC Z
    is equivalent to
       RENAME PRESSURE Y
       RENAME TEMP X
       RENAME CONC Y
 
Default:
    None
 
Synonyms:
    NAME
 
Related Commands:
    LET       = Copies variables (and many other operations).
    STATUS    = Displays dimension, variables, parameters, functions,
                etc.
    DELETE    = Deletes (all or part of) a variable.
    DIMENSION = Changes internal workspace size.
    CALL      = Executes the commands in a "macro" file.
 
Applications:
    Data Management
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----REPAIR PLOT--------------------------------------
 
REPAIR PLOT
 
Name:
    REPAIR PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a plot of repair times where there may be
    multiple groups and a censoring time for each group.
 
Description:
    In reliability studies, it is often necessary to
    analyze repair times.  A first step in analyzing these
    repair times is to simply plot the repair data.

    The repair data consists of the following:

       1) The repair times.

       2) A system id corresponding to each of the repair
          times.

       3) If the test continued to run after the last failure
          time, then a censoring time needs to be included.
          Note that there should be at most one censoring time
          for each system.

          The Dataplot convention is to code the repair times
          as 1 and censoring times as 0.

    The vertical coordinate is the system id and the horizontal
    coordinates are the repair/censoring times.

    The appearance of the plot can be controlled by appropriate
    settings for the LINE and CHARACTER commands.  The traces
    (i.e., curves) are defined as follows:

        1) The first trace consists of all the repair times.
           For this trace, the line setting is typically set to
           a blank value while the character is set to some
           non-blank value.

        2) If there are N systems, traces 2 through N+1 correspond
           to the repair and censoring times for each of these
           systems.  The line settings are typically set to a
           non-blank value while the character settings are
           typically set to blank.
   
    A typical sequence of commands to set the character and
    line settings would be

        LINES SOLID ALL
        CHARACTER BLANK ALL
        LINE BLANK
        CHARACTER *
    

    The system id and censoring variables are optional.  If you
    specify a censoring variable, a group variable must be
    given.  If you have a single system with a censoring time,
    simply create a variable the same length as the response
    variable that has all values equal to 1.  For example,

        LET N = SIZE Y
        LET GROUPID = 1 FOR I = 1 1 N
     
Syntax 1:
    REPAIR PLOT <y> <x> <cens>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a variable containing repair times;
          <x> is a variable containing the group id's;
          <cens> is a variable containing the censoring values;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used to plot repair times for the case where
    there multiple systems, but there are no censoring times.

Syntax 2:
    REPAIR PLOT <y> <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a variable containing repair times;
          <x> is a variable containing the group id's;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used to plot repair times for the case where
    there multiple systems, but there are no censoring times.

Syntax 3:
    REPAIR PLOT <y>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a variable containing repair times;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used to plot repair times for the case where
    there is only a single system and there is no censoring time.

Examples:
    REPAIR PLOT Y BATCH CENSOR
    REPAIR PLOT Y BATCH
    REPAIR PLOT Y BATCH CENSOR  SUBSET BATCH > 1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINES                     = Sets the type for plot lines.
    CHARACTERS                = Sets the type for plot characters.
    MEAN REPAIR FUNCTION PLOT = Generates a mean repair function
                                plot.
    DUANE PLOT                = Generates a Duane plot.
    KAPLAN-MEIER PLOT         = Generates a Kaplan-Meier plot.
    PLOT                      = Generates a data or function plot.
 
Applications:
    Reliability (Repairable Systems)
 
Implementation Date:
    2006/10
 
Program:
    skip 25
    read tob312.dat  y  x  cens
    .
    tic offset units screen
    tic offset 5 5
    ylimits 1 3
    major ytic mark number 3
    minor ytic mark number 0
    line blank
    char *
    title Repair Plot
    y1label System ID
    x1label System Age
    title case asis
    title offset 2
    label case asis
    .
    repair plot y x cens
 
-----REPDF-------------------------------------------------------
 
REPDF
 
Name:
    REPDF
 
Type:
    Keyword
 
Purpose:
    An internal DATAPLOT parameter into which the replication
    degrees of freedom is automatically placed whenever the FIT,
    SPLINE FIT, EXACT RATIONAL FIT, LOWESS, ANOVA, SMOOTH, YATES
    ANALYSIS, PRE-FIT, and MEDIAN POLISH commands are executed.
 
Description:
    In general, the replication degrees of freedom is computable only
    when replication exists in the data.  The formula is:
       REPDF = total number of observations - number of subsets
    REPDF may be used by the analyst in whatever fashion desired.
 
Syntax:
    None
 
Examples:
    WRITE RESDF REPSD RESDF RESSD LOGCDF
    LET SSQD = RESDF*(REPSD**2)
    WRITE CALIB. RESDF REPSD RESDF RESSD LOGCDF
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PRED               = A variable where predicted values are stored.
    RES                = A variable where residuals are stored.
    RESSD              = A parameter where the residual standard
                         deviation is stored.
    RESDF              = A parameter where the residual degrees of
                         freedom is stored.
    REPSD              = A parameter where the replication standard
                         deviation is stored.
    LOFCDF             = A parameter where the lack of fit cdf is
                         stored.
    FIT                = Carries out a least squares linear or
                         non-linear fit.
    EXACT RATIONAL FIT = Carries out an exact rational fit.
    PRE-FIT            = Carries out a least squares pre-fit.
    SPLINE FIT         = Carries out a spline fit.
    YATES ANALYSIS     = Carries out an analysis of a Yates design.
    LOWESS             = Carries out a locally weighted least squares
                         fit.
    SMOOTH             = Carries out a smoothing.
    ANOVA              = Carries out an ANOVA.
    MEDIAN POLISH      = Carries out a median polish.
    PLOT               = Generates a data/function plot.
 
Applications:
    Fitting
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----REPLACE (LET)-------------------------------------
 
REPLACE
 
Name:
    REPLACE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Match two columns (typically group-id vaues) and use
    the indices of any matching rows to replace the
    values in one array with the values in another array.
 
Description:
    Given the command

       LET Y2 = REPLACE GROUPID GROUP2 Y1

    This command does the following:

       1) It matches the values in GROUP2 against GROUPID
          and returns the indices of the matching rows for
          the GROUPID array.

       2) The indices are used to access the corresponding
          value in the Y1 array.

       3) The corresponding row of Y2 is replaced with the
          Y1 value.

    The motivation for adding this command was to address
    the problem where you have two sets of labs (each data set
    contains a lab-id and a corresponding measurement) and you
    need to create a new data set that contains the data for
    the labs that are common to both sets.  The program example
    below demonstrates how the REPLACE command can help
    accomplish this.

Syntax 1:
    LET <y2> = REPLACE <groupid>  <group2> <y1>
               <SUBSET/EXCEPT/FOR qualification>
    where <groupid> is a variable (typically a group-id variable);
          <group2> is a variable (typically a group-id variable);
          <y1> is a variable containing the values to be
              extracted;
          <y2> is a variable where the extracted values from
              <y1> are placed;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The <groupid> and <group2> variable do not need to be the
    same length.  The <y2> variable should be a previously
    existing variable.

Syntax 2:
    LET <y2> = REPLACE <groupid>  <group2>
               <SUBSET/EXCEPT/FOR qualification>
    where <groupid> is a variable (typically a group-id variable);
          <group2> is a variable (typically a group-id variable);
          <y2> is the returned variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This is an abbreviated syntax where the <y1> variable is
    assummed to be all 1's.

    The <groupid> and <group2> variable do not need to be the
    same length.  The <y2> variable should be a previously
    existing variable.

Examples:
    LET Y2 = REPLACE LAB1 LAB2 Y1
    LET Y2 = REPLACE LAB1 LAB2
    LET Y2 = REPLACE LAB1 LAB2 Y1 SUBSET LAB1 > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATCH       = Compare two column of numbers and return the
                  indices of any matching values.
    SORT        = Sort a column of numbers.
    RANK        = Rank a column of numbers.
    CODE        = Code a column of numbers.
 
Applications:
    Data Transformation
 
Implementation Date:
    2006/3
 
Program:
    .
    .  Problem:
    .
    .  We have 2 sets of labs and we want to create a new
    .  data set that contains the labs common to both sets
    .  (for each set, there is a lab-id and a measurement).
    .
    .  Step 1: Create some data
    .
    let lab1 = data 1 3 4  5 7 8 11 13 15 16 18 19
    let n1 = size lab1
    let y1 = norm rand numb for i = 1 1 n1
    .
    let lab2 = data 1 2 5 6 8 12 15 18 20
    let n2 = size lab2
    let y2 = norm rand numb for i = 1 1 n2
    .
    .  Step 2: Identify the common labs
    .
    let labint = set intersection lab1 lab2
    .
    .  Step 3: Create the tag variables for
    .          each lab
    .
    let tag1 = 0 for i = 1 1 n1
    let tag1 = replace lab1 labint
    .
    let tag3 = 0 for i = 1 1 n2
    let tag3 = replace lab2 labint
    .
    .  Step 5: Retain the common labs
    .
    set write decimals 2
    retain y1 lab1 subset tag1 = 1
    retain y2 lab2 subset tag3 = 1
    print lab1 y1 y2

-----REPLICATED STACK---------------------------------------------
 
REPLICATED STACK
 
Name:
    REPLICATED STACK
 
Type:
    Support Command
 
Purpose:
    Convert a set of response variables and a single group-id
    variable to a single response variable and two group-id
    variables.
 
Description:
    Many commands in Dataplot expect the data to be in the
    form of a single response variable and two group-id variables
    (specifically, the INTERLAB E691 command).  However, many
    data files will contain this data in column form.  That is,
    each column contains the response for one value of the first
    group-id variable.  One of the columns will contain the value
    of the second group-id variable.

    That is, the data is the form

         X1  X2  X3  ...  XK  LABID

    The REPLICATED STACK command will convert this to

        X1(1)   1   LAB(1)
          .     .     .
        X1(n)   1   LAB(n)
        X2(1)   2   LAB(1)
          .     .     .
        X2(n)   2   LAB(n)
               ...
        Xk(1)   k   LAB(1)
          .     .     .
        Xk(n)   k   LAB(n)


Syntax:
    LET <y> <matid> <labid> = REPLICATED STACK <x1> ... <xk> <lab>
                            <SUBSET/EXPCEPT/FOR qualification>
    where <x1> ... <xk> is a set of one or more response variables;
          <lab> is the first group-id variable (often a lab-id);
          <y> is the variable to contain <x1> ... <xk> in a
               single response variable; 
          <matid> is the variable that contain the value of the
               second group-id variable (i.e., the column number);
          <labid> is the variable that contain the value of the
               first group-id variable (i.e., the value of <lab>);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y MATID LABID = REPLICATED STACK Z1 Z2 Z3 Z4 Z5 LAB
 
Default:
    None.
 
Synonyms:
    None
 
Related Commands:
    STACK         = Convert column data to a single response
                    variable and a group-id variable;
    EXTEND        = Extends a variable by another variable.
    LET           = Creates, transforms, etc. a variable.
    E691 INTERLAB = Peform an interlab analysis based on the
                    E691 standard.
 
Applications:
    Data Management
 
Implementation Date:
    2005/4
 
Program:
    SKIP 25
    READ GLUCOSE2.DAT LAB X1 TO X5
    .
    LET Y MATID LABID = REPLICATED STACK X1 X2 X3 X4 X5 LAB
    .
    E691 INTERLAB Y MATID LABID
  
-----REPLOT-------------------------------------------------------
 
REPLOT
 
Name:
    REPLOT
 
Type:
    Support Command
 
Purpose:
    This command regenerates the most recently created plot.
 
Syntax:
    REPLOT
 
Examples:
    PLOT SIN(X) FOR X = 0 0.1 6.28
    TITLE SIN FUNCTION
    REPLOT
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SAVE      = Save one or more commands for later execution.
    LIST      = List previously entered commands.
    REPEAT    = Re-execute previously entered commands.
    /         = Re-execute previously saved commands.
 
Applications:
    Interactive Usage
 
Implementation Date:
    1997/12
 
Program:
    PLOT SIN(X) FOR X = 0 0.1 6.28
    TITLE SIN FUNCTION
    REPLOT
 
-----REPRODUCIBILITY STANDARD DEVIATION (LET)--------------------------
 
REPRODUCIBILITY STANDARD DEVIATION
 
Name:
    REPRODUCIBILITY STANDARD DEVIATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the reproducibility standard deviation of a variable
    as defined by the ASTM E 691 - 99 standard.
 
Description:
    The reproducibility standard deviation is a core concept
    defined in the ASTM E 691 - 99 standard.  This standard
    is described in detail in the following document:

      "Standard Practice for Conducting an Interlaboratory Study
      to Determine the Precision of a Test Method", ASTM
      International, 100 Barr Harbor Drive, PO BOX C700,
      West Conshohoceken, PA 19428-2959, USA.

    This document describes reproducibility in the following way.

       Reproducability is the variability between single test
       results obtained in different laboratories, each of which
       has applied the test method to test specimens taken at
       random from a single quantity of homogeneous material.

    The reproducibility standard deviation is computed as

        s(R) = MAX(s(R)*,s(r))
 
    with
 
        s(R)*    = SQRT(s(xbar)**2 + (S(r)**2*(n-1)/n)
 
        s(xbar)  = Standard deviation of the cell averages
        n        = cell sample size (currently, equal cell sizes
                   expected)
 
    and S(r) denoting the repeatability standard deviation
 
        Sr = SQRT(SUM[i=1 to p][s(i)**2/p]
 
    with

        p      = number of labs
        s(i)   = Standard deviation of group i.
 
    In an interlaboratory study, the reproducibility standard
    deviation is computed for each material.
 
Syntax:
    LET <par> = REPRODUCIBILITY STANDARD DEVIATION <y> <labid>
               <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <labid> is a lab-id variable;
          <par> is a parameter where the reproducibility standard
              deviation value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET RSD = REPRODUCIBILITY STANDARD DEVIATION Y LAB
    LET RSD = REPRODUCIBILITY STANDARD DEVIATION Y LAB  SUBSET MAT = 1
 
Note:
    The reproducibility standard deviation can be computed for
    multiple materials with the command

         TABULATE REPRODUCIBILITY STANDARD DEVIATION Y LABID MATID

    The reproducibility standard deviation can be plotted for
    multiple materials with the command

         REPRODUCIBILITY STANDARD DEVIATION PLOT Y LABID MATID

Default:
    None
 
Synonyms:
    REPRODUCIBILITY SD
 
Related Commands:
    E691 INTERLAB                      = Perform an E691 interlab
                                         analysis.
    REPEATABILITY STANDARD DEVIATION   = Compute the repeatability
                                         standard deviation.
 
Reference:
    "Standard Practice for Conducting an Interlaboratory Study
    to Determine the Precision of a Test Method", ASTM
    International, 100 Barr Harbor Drive, PO BOX C700,
    West Conshohoceken, PA 19428-2959, USA.

Applications:
    Interlaboratory Analysis
 
Implementation Date:
    2005/4
 
Program:
    SKIP 25
    READ GLUCOSE.DAT Y LABID MATID
    .
    LET MATDIST = DISTINCT MATID
    LET NMAT = SIZE MATDIST
    XLIMITS 1 NMAT
    MAJOR XTIC MARK NUMBER NMAT
    MINOR XTIC MARK NUMBER 0
    XTIC OFFSET 0.5 0.5
    Y1LABEL REPRODUCIBILITY SD
    X1LABEL MATERIAL
    LINE BLANK
    CHARACTER X
    .
    REPRODUCIBILITY SD PLOT Y LABID MATID
 
-----REPSD-------------------------------------------------------
 
REPSD
 
Name:
    REPSD
 
Type:
    Keyword
 
Purpose:
    An internal DATAPLOT parameter into which the replication standard
    deviation is automatically placed whenever the FIT, PRE-FIT, SPLINE
    FIT, YATES ANALYSIS, LOWESS, ANOVA, and MEDIAN POLISH commands are
    executed.
 
Description:
    The replication standard deviation is a model-free estimate of the
    population standard deviation and is computable only when
    replication exists in the data.  REPSD may be used by the analyst
    in whatever fashion desired.
 
Syntax:
    None
 
Examples:
    WRITE RESDF REPSD RESDF RESSD LOGCDF
    LET SSQD = RESDF*(REPSD**2)
    WRITE CALIB. RESDF REPSD RESDF RESSD LOGCDF
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PRED               = A variable where predicted values are stored.
    RES                = A variable where residuals are stored.
    RESSD              = A parameter where the residual standard
                         deviation is stored.
    RESDF              = A parameter where the residual degrees of
                         freedom is stored.
    REPDF              = A parameter where the replication degrees of
                         freedom is stored.
    LOFCDF             = A parameter where the lack of fit cdf is
                         stored.
    FIT                = Carries out a least squares linear or
                         non-linear fit.
    EXACT RATIONAL FIT = Carries out an exact rational fit.
    PRE-FIT            = Carries out a least squares pre-fit.
    SPLINE FIT         = Carries out a spline fit.
    YATES ANALYSIS     = Carries out an analysis of a Yates design.
    LOWESS             = Carries out a locally weighted least squares
                         fit.
    SMOOTH             = Carries out a smoothing.
    ANOVA              = Carries out an ANOVA.
    MEDIAN POLISH      = Carries out a median polish.
    PLOT               = Generates a data/function plot.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----REPEAT-------------------------------------------------------
 
REPEAT
 
Name:
    REPEAT
 
Type:
    Support Command
 
Purpose:
    Selectively re-execute one of, or a set of, the last 20 DATAPLOT
    commands that had been entered.
 
Syntax:
    REPEAT  <id of first command>   <id of last command>
    where <id1> is the line number of the first command to re-execute;
    and   <id2> is the line number of the last command to re-execute.
 
    The line numbers are obtained by preceding the REPEAT command by
    a LIST command with no arguments.  All the commands between the
    first and last line are re-executed as well.
 
Examples:
    REPEAT 6 3     --to repeat commands 6, 5, 4, and 3 ago
    REPEAT 3 6     --to repeat commands 6, 5, 4, and 3 ago
    REPEAT 6 6     --to repeat command 6 ago
    REPEAT 6       --to repeat command 6 ago
    REPEAT 1       --to repeat the last command
    REPEAT         --to repeat the last command
 
Note:
    The REPEAT command is almost always preceded by the LIST command
    (with no arguments).  LIST will print the last 20 commands that
    were entered.  Based on that list, the analyst can then enter the
    REPEAT command to selectively execute one or more of those
    commands.  For example,
 
       LIST
       REPEAT 6 3
 
    would list the last 20 commands and then re-execute the sixth,
    fifth, fourth, and third commands ago.  See the documentation for
    the LIST command for details.
 
Note:
    DATAPLOT actually saves the last 200 (50 in earlier versions)
    commands.  Enter the command SET LIST LINES <n> where <n> is
    between 1 and 200 to control the number of commands that LIST
    prints.
 
Note:
    The REPEAT command is commonly used for the re-execution of long
    complicated commands (e.g., PLOT with a complicated mathematical
    expression).
 
Note:
    The R synonym for the REPEAT command is heavily used.
 
Note:
    At this time, there is no way to edit the re-executed commands
    with the REPEAT command.  You can use SAVE to a file and then use
    the built-in editor (EDIT command).  However, this may be more
    trouble than it is worth.
 
Default:
    If only one argument is entered, then only that command is
    re-executed.
    If no arguments are entered, then the last command is re-executed.
 
Synonyms:
    R
 
Related Commands:
    LIST     = List the previously entered commands.
    SAVE     = Select previously entered commands to be re-executed
               with the "/" command.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----REPEATABILITY STANDARD DEVIATION (LET)--------------------------
 
REPEATABILITY STANDARD DEVIATION
 
Name:
    REPEATABILITY STANDARD DEVIATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the repeatability standard deviation of a variable
    as defined by the ASTM E 691 - 99 standard.
 
Description:
    The repeatability standard deviation is a core concept
    defined in the ASTM E 691 - 99 standard.  This standard
    is described in detail in the following document:

      "Standard Practice for Conducting an Interlaboratory Study
      to Determine the Precision of a Test Method", ASTM
      International, 100 Barr Harbor Drive, PO BOX C700,
      West Conshohoceken, PA 19428-2959, USA.

    This document describes repeatability in the following way.

        Repeatability concerns the variability between independent
        test results obtained within a single laboratory in the
        shortest practical period of time by a single operator with
        a specific set of test apparatus using test specimens taken
        at random from a single quantity of homogeneous material.

    The repeatability standard deviation is computed as

        Sr = SQRT(SUM[i=1 to p][s(i)**2/p]
 
    with

        p      = number of labs
        s(i)   = Standard deviation of group i.
 
    In an interlaboratory study, the repeatability standard
    deviation is computed for each material.
 
Syntax:
    LET <par> = REPEATABILITY STANDARD DEVIATION <y> <labid>
               <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <labid> is a lab-id variable;
          <par> is a parameter where the repeatability standard
              deviation value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET RSD = REPEATABILITY STANDARD DEVIATION Y LAB
    LET RSD = REPEATABILITY STANDARD DEVIATION Y LAB  SUBSET MAT = 1
 
Note:
    The repeatability standard deviation can be computed for
    multiple materials with the command

         TABULATE REPEATABILITY STANDARD DEVIATION Y LABID MATID

    The repeatability standard deviation can be plotted for
    multiple materials with the command

         REPEATABILITY STANDARD DEVIATION PLOT Y LABID MATID

Default:
    None
 
Synonyms:
    REPEATABILITY SD
 
Related Commands:
    E691 INTERLAB                      = Perform an E691 interlab
                                         analysis.
    REPRODUCIBILITY STANDARD DEVIATION = Compute the reproducibility
                                         standard deviation.
 
Reference:
    "Standard Practice for Conducting an Interlaboratory Study
    to Determine the Precision of a Test Method", ASTM
    International, 100 Barr Harbor Drive, PO BOX C700,
    West Conshohoceken, PA 19428-2959, USA.

Applications:
    Interlaboratory Analysis
 
Implementation Date:
    2005/4
 
Program:
    SKIP 25
    READ GLUCOSE.DAT Y LABID MATID
    .
    LET MATDIST = DISTINCT MATID
    LET NMAT = SIZE MATDIST
    XLIMITS 1 NMAT
    MAJOR XTIC MARK NUMBER NMAT
    MINOR XTIC MARK NUMBER 0
    XTIC OFFSET 0.5 0.5
    Y1LABEL REPEATABILITY SD
    X1LABEL MATERIAL
    LINE BLANK
    CHARACTER X
    .
    REPEATABILITY SD PLOT Y LABID MATID
 
-----RES-------------------------------------------------------
 
RES
 
Name:
    RES
 
Type:
    Keyword
 
Purpose:
    An internal DATAPLOT variable into which the residuals are
    automatically placed whenever the FIT, PRE-FIT, SPLINE FIT, LOWESS,
    YATES ANALYSIS, SMOOTH, ANOVA, and MEDIAN POLISH commands are
    executed.
 
Description:
    In general, the residuals are defined as
       raw data - predicted values
    where the predicted values are the "fitted values" from fitting,
    pre-fitting, spline fitting, smoothing, ANOVA, locally weighted
    least squares fitting, Yates analysis, and median polish.  RES can
    be used by the analyst in whatever fashion desired.  Residuals are
    extremely important because they serve as the base for testing
    model adequacy via the battery of techniques known as residual
    analysis.  Typical operations with these residuals include:
    1) plotting the residuals versus any independent variable to check
       for latent relationships (e.g., PLOT RES X);
    2) generating a lag plot of the residuals to check for
       autocorrelation (e.g., LAG PLOT RES);
    3) generating a histogram of the residuals to check for general
       distributional structure (e.g., HISTOGRAM RES);
    4) generating a normal probability plot of the residuals to check
       for normality (e.g., NORMAL PROBABILITY PLOT RES).
 
Syntax:
    None
 
Examples:
    WRITE X Y PRED RES
    PLOT RES X
    LET RES2=ABS(RES)
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PRED               = A variable where predicted values are stored.
    RESSD              = A parameter where the residual standard
                         deviation is stored.
    RESDF              = A parameter where the residual degrees of
                         freedom is stored.
    REPSD              = A parameter where the replication standard
                         deviation is stored.
    REPDF              = A parameter where the replication degrees of
                         freedom is stored.
    LOFCDF             = A parameter where the lack of fit cdf is
                         stored.
    FIT                = Carries out a least squares linear or
                         non-linear fit.
    EXACT RATIONAL FIT = Carries out an exact rational fit.
    PRE-FIT            = Carries out a least squares pre-fit.
    SPLINE FIT         = Carries out a spline fit.
    YATES ANALYSIS     = Carries out an analysis of a Yates design.
    LOWESS             = Carries out a locally weighted least squares
                         fit.
    SMOOTH             = Carries out a smoothing.
    ANOVA              = Carries out an ANOVA.
    MEDIAN POLISH      = Carries out a median polish.
    PLOT               = Generates a data/function plot.
 
Applications:
    Fitting
 
Implementation Date:
    Pre-1987
 
Program:
    SKIP 25
    READ BERGER.DAT Y X
    FIT Y X
    4-PLOT RES
 
-----RESCALED SUM (LET)-----------------------------------------
 
RESCALED SUM
 
Name:
    RESCALED SUM (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the rescaled sum of a variable.
 
Description:
    The rescaled sum has the formula:

         RS = SUM[i=1 to N][X(i)]/SQRT(N)

    with N denoting the number of observations.  This statistic has
    application in the ISO 13528 proficiency testing.
 
Syntax 1:
    LET <par> = RESCALED SUM <y>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed rescaled sum is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <par> = DIFFERENCE OF RESCALED SUM <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed difference of
              the rescaled sums is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax computes the recaled sum of <y1> and <y2> and then
    computes the difference of the two sums.
 
Examples:
    LET A = RESCALED SUM Y1
    LET A = RESCALED SUM Y1  SUBSET TAG > 2
    LET A = DIFFERENCE OF RESCALED SUM Y1 Y2
 
Note:
    The rescaled sum is sometimes used in the context of ISO 13528
    proficiency studies for the case where there are multiple rounds
    of the proficiency study.  Specifcally, the following two plots
    are sometimes generated

       1) A plot of the rescaled sum versus the laboratory where the
          summation is over all rounds and all materials for a given
          laboratory.  Laboratories with an absolute value greater than
          2 are of possible concern (i.e., warning) and those with an
          absolute value greater than 3 are of concern (i.e., action
          signal). The advantage of this statistic is that it has the
          same interpretation as the z-scores. The disadvantage is that
          large magnitude z-scores of opposite sign can cancel each other.

       2) A plot of the relative laboratory performance (RLP) versus the
          rescaled sum for all laboratories.  A box is formed for
          the rescaled sum between -2 and 2 and for RLP between 0 and 1.5.
          Laboratories outside this box are identified as needing
          attention.

Note:
    In some applications it may be desired to cap the value
    of outliers.  This is most common when the response variable
    is a z-score or some other standardized score.

    To specify this value, enter the command

        LET CAPVALUE = <value>

    where <value> is typically 3 or 4 (if the reponse data are
    z-scores or z-score type data).  Note that the value represents
    an absolute value.  For example, if CAPVALUE is 4, values greater
    than 4 will be set to 4 and values less than -4 will be set to -4.

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MEAN                 = Compute the mean of a variable.
    STANDARD DEVIATION   = Compute the standard deviation of a variable.
    SUM OF SQUARES       = Compute the sum of squares of a variable.
    ROOT MEAN SQUARE     = Compute the root mean square error of a
                           variable.
 
Applications:
    ISO 13528 Proficiency Testing
 
Implementation Date:
    2012/2
    2012/6: Added DIFFERENCE OF RESCALED SUM
 
Program 1:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET RSUM = RESCALED SUM Y1
 
Program 2:
    SKIP 25
    READ GEAR.DAT Y X
    LET Y = ZSCORE Y
    .
    CHARACTER X BLANK
    LINE BLANK SOLID
    TIC MARK OFFSET UNITS DATA
    X1TIC MARK OFFSET 0.5 0.5
    .
    LABEL CASE ASIS
    Y1LABEL Rescaled Sum
    X1LABEL Batch
    RESCALED SUM PLOT Y X
 
-----RESDF-------------------------------------------------------
 
RESDF
 
Name:
    RESDF
 
Type:
    Keyword
 
Purpose:
    An internal DATAPLOT parameter into which the residual degrees of
    freedom is automatically placed whenever the FIT, PRE-FIT, SPLINE
    FIT, SMOOTH, ANOVA, YATES ANALYSIS, LOWESS, and MEDIAN POLISH
    commands are executed.
 
Description:
    In general, the formula is:
       RESDF = total number of observations - number of parameters
               + the number of constraints.
    RESDF can be used by the analyst in whatever fashion desired.
 
Syntax:
    None
 
Examples:
    WRITE RESDF REPSD RESDF RESSD LOGCDF
    LET SSQD = RESDF*(REPSD**2)
    WRITE CALIB. RESDF REPSD RESDF RESSD LOGCDF
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PRED               = A variable where predicted values are stored.
    RES                = A variable where residuals are stored.
    RESSD              = A parameter where the residual standard
                         deviation is stored.
    REPSD              = A parameter where the replication standard
                         deviation is stored.
    REPDF              = A parameter where the replication degrees of
                         freedom is stored.
    LOFCDF             = A parameter where the lack of fit cdf is
                         stored.
    FIT                = Carries out a least squares linear or
                         non-linear fit.
    EXACT RATIONAL FIT = Carries out an exact rational fit.
    PRE-FIT            = Carries out a least squares pre-fit.
    SPLINE FIT         = Carries out a spline fit.
    YATES ANALYSIS     = Carries out an analysis of a Yates design.
    LOWESS             = Carries out a locally weighted least squares
                         fit.
    SMOOTH             = Carries out a smoothing.
    ANOVA              = Carries out an ANOVA.
    MEDIAN POLISH      = Carries out a median polish.
    PLOT               = Generates a data/function plot.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----RESET-------------------------------------------------------
 
RESET
 
Name:
    RESET
 
Type:
    Support Command
 
Purpose:
    Resets all internal Dataplot parameters, variables, functions, and
    switches to default sign-on conditions.
 
Description:
    The RESET command allows the analyst to clear all of Dataplot's
    internal settings so as to start afresh.

    You can also selectively reset internal settings based on a
    keyword (see Syntax 2).  You can also specifiy names that will
    not be reset for the DATA, VARIABLES, PARAMETERS, FUNCTIONS, and
    MATRICES options (see Syntax 3).
 
Syntax 1:
    RESET
 
    This resets all internal settings.
 
Syntax 2:
    RESET <keyword>
    where <keyword is one of the following:
              ALL         - reset all internal settings
              CONTROL     - reset the plot control settings
              DATA        - reset the data settings
              SUPPORT     - resets the support settings
              GRAPHICS    - resets the graphics settings
              I/O         - resets the I/O settings
              CLSB        - resets the CLSB (CHARACTER, LINE, SPIKE, BAR)
                            settings
              LIMITS      - resets the LIMITS settings
              VARIABLES   - reset variable settings
              PARAMETERS  - reset parameter settings
              FUNCTIONS   - reset function settings
              MATRICES    - reset matrix settings.
 
Syntax 3:
    RESET NO RESET <name> <ON/OFF>
    where <name> identifies a single name;
    and where ON specifies the name will be added to the list and
        OFF specifies the name will be removed from the list.
 
    Dataplot maintains a list of 1 to 30 names that will not be
    reset by the RESET DATA, RESET VARIABLES, RESET PARAMETERS,
    RESET FUNCTIONS, and RESET MATRICES commands.  You can use this
    syntax to add or remove names from the list.  The ON switch is
    optional for adding a name.  However, the OFF switch is required to
    delete a name from the list.
 
Syntax 4:
    RESET COMMAND LINE ARGUMENTS
 
    This syntax can be used to clear the argument list for macros.
    Enter HELP MACRO SUBSTITUTION CHARACTER for details.
 
Examples:
    RESET
    RESET DATA
    RESET LIMITS
    RESET VARIABLES
    RESET NO RESET Y
 
Default:
    None
 
Synonyms:
    CLEAR
 
Related Commands:
    SAVE MEMORY     = Dumps all of DATAPLOT' interal parameters,
                      variables, functions, and switches to a file.
    DIMENSION       = Set the number of columns and rows for
                      DATAPLOT's work array.
 
Applications:
    Data Management
 
Implementation Date:
    Pre-1987
    1993/09: Added RESET LIMITS and RESET CLSB
    2015/12: For Windows, do not reset the QuickWin device
    2016/09: Added RESET NO RESET option
    2016/09: Added RESET COMMAND LINE ARGUMENTS
 
Program:
    SKIP 25
    READ BERGER1.DAT Y X BATCH
    FIT Y X
    RESET VARIABLES
    READ LEW.DAT Y
    4-PLOT Y
 
-----RESISTOR-------------------------------------------------------
 
RESISTOR
 
Name:
    RESISTOR
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Draws a (fixed value) resistor (a component used in electronic
    circuit diagrams).
 
Description:
    The 2 pairs of coordinates define the (x,y) values for the start
    point and the end point (respectively) of the resistor.  Note that
    the height of the wrinkles in the resistor is controlled by the
    HEIGHT command.
 
Syntax:
    RESISTOR   <x1>   <y1>   <x2>   <y2>
    where <x1> is a decimal number or parameter in the range 0 to 100
              that specifies the x coordinate of the start point;
          <y1> is a decimal number or parameter in the range 0 to 100
              that specifies the y coordinate of the start point;
          <x2> is a decimal number or parameter in the range 0 to 100
              that specifies the x coordinate of the end point;
    and   <y2> is a decimal number or parameter in the range 0 to 100
              that specifies the y coordinate of the end point.
 
Examples:
    RESISTOR 50 50 60 50
    RESISTOR 50 50 60 60
    RESISTOR 20 20 25 20
    RESISTOR 20 70 25 70
    RESISTOR 30.55 50.7 40.23 50.7
    RESISTOR X1 Y1 X2 Y2
 
Note:
    The line style (i.e., solid, dash), color, and thickness are
    controlled by the LINE, LINE COLOR, and LINE THICKNESS commands.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    GROUND           = Draws a ground.
    AMPLIFIER        = Draws an amplifier.
    CAPACITOR        = Draws a capacitor.
    INDUCTOR         = Draws an inductor.
    RESISTOR         = Draws a resistor.
    DRAW             = Draws a line.
    MOVE             = Moves to a point.
    LINES            = Sets the line type for figures and plot lines.
    LINE THICKNESSES = Sets the line thickness for figures and  plot
                       lines.
    LINE COLOR       = Sets the line colors for figures and plot lines.
    CROSS-HAIR       = Activates and reads the cross-hair.
    TEXT             = Writes a text string.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LINE SOLID
    LINE COLOR BLACK
    LINE THICKNESS 0.2
    RESISTOR 20 70 50 70
    MOVE 20 90
    TEXT RESISTOR COORDINATES (20,70), (50,70)
 
-----RESSD-------------------------------------------------------
 
RESSD
 
Name:
    RESSD
 
Type:
    Keyword
 
Purpose:
    An internal DATAPLOT parameter into which the residual standard
    deviation is automatically placed whenever the FIT, PRE-FIT, SPLINE
    FIT, SMOOTH, ANOVA, LOWESS, YATES ANALYSIS, and MEDIAN POLISH
    commands are executed.
 
Description:
    The residual standard deviation is a model-dependent estimate of
    the population standard deviation.  It is a measure of the
    variability that remains after the model has been accounted for.
    It is the single most important number in the output from the above
    commands.  RESSD can be used by the analyst in whatever fashion
    desired.
 
Syntax:
    None
 
Examples:
    WRITE RESDF RESSD RESDF RESSD LOGCDF
    LET SSQD = RESDF*(RESSD**2)
    WRITE CALIB. RESDF RESSD RESDF RESSD LOGCDF
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PRED               = A variable where predicted values are stored.
    RES                = A variable where residuals are stored.
    RESDF              = A parameter where the residual degrees of
                         freedom is stored.
    REPSD              = A parameter where the replication standard
                         deviation is stored.
    REPDF              = A parameter where the replication degrees of
                         freedom is stored.
    LOFCDF             = A parameter where the lack of fit cdf is
                         stored.
    FIT                = Carries out a least squares linear or
                         non-linear fit.
    EXACT RATIONAL FIT = Carries out an exact rational fit.
    PRE-FIT            = Carries out a least squares pre-fit.
    SPLINE FIT         = Carries out a spline fit.
    YATES ANALYSIS     = Carries out an analysis of a Yates design.
    LOWESS             = Carries out a locally weighted least squares
                         fit.
    SMOOTH             = Carries out a smoothing.
    ANOVA              = Carries out an ANOVA.
    MEDIAN POLISH      = Carries out a median polish.
    PLOT               = Generates a data/function plot.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-------------RESTORE MEMORY------------------------------------
 
RESTORE MEMORY
 
Name:
    RESTORE MEMORY
 
Type:
    Support Command
 
Purpose:
    Reloads all internal DATAPLOT parameters, variables, functions,
    and switches that were previously dumped to a file via the SAVE
    MEMORY command.
 
Description:
    The RESTORE MEMORY command thus allows the analyst to restore all
    of DATAPLOT's internal settings so that a run my be resumed after
    being interrupted by a meeting, lunch, etc.
 
Syntax:
    RESTORE MEMORY   <file name>
    where <file name> is the name of a file where the internal
              settings were previously saved.
 
    If the file name does not contain a period, place a period (no
    spaces) at the end of the file name.
 
    If no file name is given, the default name "dpsavf.tex" will
    be used.

Examples:
    RESTORE MEMORY OUT.
    RESTORE MEMORY SCRATCH.
    RESTORE MEMORY TEMP.
 
Note:
    This command was significantly updated to reflect many new
    settings.

Note:
    DATAPLOT has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    DATAPLOT strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), DATAPLOT tries to open the file with
    the trailing period.  If this fails, it then tries to open the file
    with the trailing period stripped off.
 
Note:
    File names are case sensitive on Unix file systems.  For Unix,
    DATAPLOT attempts to open the file as given.  If this fails, it
    attempts to open the file as all upper case characters.  If this
    fails, it attempts to open the file as all lower case characters.
    All other currently supported systems are not case sensitive
    regarding file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SAVE MEMORY    = Dump all internal DATAPLOT settings to a file.
    RESTORE DATA   = Restore a user specified list of variables and
                     parameters.
    SAVE DATA      = Save a user specified list of variables and
                     parameters.
    RESET          = Reset internal DATAPLOT settings to their default
                     values.
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
    2020/12: Updated to include many new settings
    2020/12: Use "dpsavf.tex" if no file name is given
    2020/12: Added better error trapping
 
Program:
    XX
 
-----RESTORE VARIABLE---------------------------------------------
 
RESTORE VARIABLE
 
Name:
    RESTORE VARIABLE
 
Type:
    Support Command
 
Purpose:
    Restore a user specified list of variables and parameters that
    were saved to a file by the SAVE VARIABLE command.

Description:
    The primary purpose of this command is for use with general
    purpose macros.  Specifically, macros can save the current
    values for certain variables, re-use those variables in the
    macro and then restore the original values to the variables.
 
    You can save variables and parameters.  However, matrices and
    strings/functions are not currently supported.

    The SAVE VARIABLE command is used to save the variables to a
    file.  The RESTORE VARIABLE command can then be used to restore
    the variables and parameters in this file.

Syntax:
    RESTORE VARIABLE <file-name>
    where <file-name> is the name of a file where the variables and
               parameters were previously saved.

    If no <file-name> is given, the file "dpsavf.tex" is used.

    No variable list is given as the variable and parameter names
    are contained in the file.

Examples:
    RESTORE VARIABLES
    RESTORE VARIABLES VARLIST.DAT
 
Note:
    The format of the save file is something like

        Y        VARIABLE
                 3
          0.1800000E+02
          0.3800000E+02
          0.1500000E+02
        AVAL     PARAMETER
          0.1000000E+01

    For each name, the first line prints the variable/parameter name
    and also prints the type (VARIABLE or PARAMETER).  If the name is
    a variable, the next line specifies the number of elements in
    the variable.  The contents of the variable are then printed one
    element per line.  If the name is a parameter, then the value of
    the parameter is printed on the next line.

    Variables and parameters are printed one at a time.

    When the RESTORE VARIABLE command is given, Dataplot will
    go through the list of names.  The name will be checked against
    the current Dataplot name table.  If the name currently exists as
    a string or a function, the name will not be restored.  If the
    name exists as a parameter or a variable, it will be overwritten
    by the values in the file.  One complication is when the type
    in the current name table does not match the type in the save
    file.  If the current name is being upgraded from a parameter
    to a variable, this should not cause any problems.  However,
    if the current name is being modified from variable to a
    parameter, it is recommended that you delete the current variable
    before issuing the RESTORE VARIABLE command.  If no match is
    found in the current name table, the variable or parameter will
    be added.  Names that are in the current name table but not in
    the save file will not be changed.

Note:
    Dataplot has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    Dataplot strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), Dataplot opens the file with the
    trailing period.
 
Note:
    File names are case sensitive on Unix/Linux and MacOSX file
    systems.  For these systems, Dataplot opens the file as given.  All
    other currently supported systems are not case sensitive regarding
    file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SAVE VARIABLE    = Save variables and parameters to a file.
    SAVE MEMORY      = Save all internal Dataplot settings to a file.
    RESTORE MEMORY   = Restore all internal Dataplot settings from a
                       previously saved file.
    RESET            = Reset internal DATAPLOT settings to their default
                       values.
 
Applications:
    Utility for Macros
 
Implementation Date:
    2020/12
 
Program:
    SKIP 25
    READ BERGER1.DAT Y X BATCH
    SAVE VARIABLES Y X BATCH
    .
    LET Y = NORMAL RANDOM NUMBERS FOR I =  1 1 100
    LET X = SEQUENCE 1 1 10
    LET BATCH = 1 FOR I = 1 1 10
    .
    RESTORE VARIABLES
    PRINT Y X BATCH
 
-----RETAIN-------------------------------------------------------
 
RETAIN
 
Name:
    RETAIN
 
Type:
    Support Command
 
Purpose:
    Retains (keeps) the specified rows or subset of a variable,
    deletes the unspecified rows or subset, and packs the kept
    elements into the "top" of the variable.
 
Syntax 1:
    RETAIN   <list>   <SUBSET/EXCEPT/FOR qualification>
    where <list> is a list of variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is required.
 
Syntax 2:
    RETAIN   <list>
    where <list> is a list of elements of a variable.
 
Examples:
    RETAIN Y SUBSET X 2 TO 4
    RETAIN Y1 Y2 X SUBSET X 8 TO INFINITY
    RETAIN X Y Z FOR I = 11 1 20
    RETAIN X(100)
    RETAIN X(2) Y(7) Z(15)
    RETAIN X(2) Y(2) PRED(2) RES(2)
 
Default:
    None
 
Synonyms:
    KEEP
 
Related Commands:
    DELETE = Deletes rows or subsets of a variable.
    LET    = Transforms rows or subsets of a variable (plus other
             capabilities).
    SUBSET = Allows specification of a subset.
    EXCEPT = Allows exclusion-specification of a subset.
    FOR    = Allows row-specification of a subset.
 
Applications:
    Data Manipulation
 
Implementation Date:
    Pre-1987
 
Program:
    SKIP 25
    READ AUTO83B.DAT Y1 Y2
    RETAIN Y2 > -998
    BIHISTOGRAM Y1 Y2
 
-----REVERSE (LET)--------------------------------
 
REVERSE
 
Name:
    REVERSE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Reverse the order of the elements in a variable.
    That is, if Y has N elements, Y(1) = Y(N), Y(2)=Y(N-1), ... ,
    Y(N)=Y(1).
 
Syntax:
    LET <y2> = REVERSE <y1>    <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a  response variable;
          <y2> is a variable where the reversed data is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y2 = REVERSE Y
    LET Y2 = REVERSE Y FOR I = 1 1 30
 
Default:
    None
 
Synonyms:
    FLIP is a synonym for REVERSE.
 
Related Commands:
    SORT             = Sort the elements in a variable.
    RANK             = Rank the elements in a variable.
    SORT DIRECTION   = Specify whether sorting is done in a
                       descending or ascending order.
 
Applications:
    Data Manipulation
 
Implementation Date:
    1998/5
 
Program:
    LET Y = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y2 = RANK Y
    LET Y3 = REVERSE Y2
 
-----RF SPREAD PLOT--------------------------------------
 
RF SPREAD PLOT
 
Name:
    RF SPREAD PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a residuals-fitted (r-f) spread plot.
 
Description:
    The residuals-fitted (r-f) spread plot is a graphical measure
    of the goodness of fit.  That is, this command is preceeded
    by some type of fit.  It plots percent point (or quantile)
    plots of the fitted values minus their mean and the residuals
    arranged side by side with a common vertical scale.

    The vertical spread of the residuals compared to the vertical
    spread of the fitted values gives an indication of how much
    of the variation is explained by the fit.

    Dataplot assumes that some type of fit has already been
    performed and that the predicted values are stored in the
    internal variable PRED and the residuals are stored in the
    internal variable RES.  If you want to generate the rf
    spread plot for variables that are not automatically
    stored on PRED and RES, then simply copy the desired variables
    into PRED and RES before entering the RF SPREAD PLOT (e.g.,
    LET PRED = Y).

Syntax:
    RF SPREAD PLOT           <SUBSET/EXCEPT/FOR qualification>
    where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    FIT Y X
    RF SPREAD PLOT

    LOWESS Y X
    RF SPREAD PLOT

    SPLINE FIT Y X
    RF SPREAD PLOT
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINES               = Sets the type for plot lines.
    CHARACTER           = Sets the type for plot characters.
    PERCENT POINT PLOT  = Generates a percent point plot.
    PLOT                = Generates a data or function plot.
 
References:
    "Visualizing Data", Cleveland, William S., Hobart Press, 1993.

Applications:
    Exploratory Data Analysis
 
Implementation Date:
    2000/1
 
Program:
    SKIP 25
    READ BERGER1.DAT Y X
    FIT Y X
    CHARACTER CIRCLE
    LINE BLANK
    RF SPREAD PLOT
 
-----RGTCDF (LET)--------------------------------
 
RGTCDF
 
Name:
    RGTCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reflected generalized Topp and Leone cumulative
    distribution function with shape parameters alpha and beta.
 
Description:
    The reflected generalized Topp and Leone distribution has
    the following cumulative distribution function:

        F(x;alpha,beta,a,b) = 1 -
            ((b - x)/(b-a))**beta*
            {alpha - (alpha-1)*((b-x)/(b-a))}**beta
            a <= x <= b, beta > 0, 0 < alpha <= 2
 
    with alpha and beta denoting the shape parameters and
    a and b the lower and upper limits, respectively.

    The case where a = 0 and b = 1 is referred to as the
    standard reflected generalized Topp and Leone distribution.

    The lower and upper limits are related to the location
    and scale parameters as follows:

        location = a
        scale    = b - a

   Kotz and van Dorp have proposed this distribution as an
   alternative to the beta distribution.  It is distinguished
   from the beta distribution in that it can have positive
   density at the lower limit with a strict positive mode.

Syntax:
    LET <y> = RGTCDF(<x>,<alpha>,<beta>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing
              values in the interval (a,b);
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed reflected generalized
              topp and leone cdf value is stored;
          <alpha> is a number, parameter, or variable in the
              interval (0, 2) that specifies the first shape
              parameter;
          <beta> is a positive number, parameter, or variable that
              specifies the second shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = RGTCDF(0.3,0.2,1.2)
    LET Y = RGTCDF(X,0.5,2)
    PLOT RGTCDF(X,2,3) FOR X = 0  0.01  1
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RGTPDF = Compute the reflected generalized Topp and Leone
             probability density function.
    RGTPPF = Compute the reflected generalized Topp and Leone
             percent point function.
    GTLCDF = Compute the generalized Topp and Leone probability
             density function.
    TOPPDF = Compute the Topp and Leone probability density
             function.
    TSPPDF = Compute the two-sided power probability density
             function.
    BETPDF = Compute the beta probability density function.
    TRIPDF = Compute the triangular probability density function.
    TRAPDF = Compute the trapezoid probability density function.
    UNIPDF = Compute the uniform probability density function.
    POWPDF = Compute the power probability density function.
    JSBPDF = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond Beta:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, chapter 7.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/2
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 3 3
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 3
    .
    LET ALPHA = 2
    LET BETA  = 3
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTCDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 1.5
    LET BETA  = 6
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTCDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 1.5
    LET BETA  = 2
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTCDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 1.5
    LET BETA  = 1
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTCDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 0.5
    LET BETA  = 2
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTCDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 0.5
    LET BETA  = 1
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTCDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 0.5
    LET BETA  = 0.75
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTCDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 0.5
    LET BETA  = 0.25
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTCDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 1
    LET BETA  = 1
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTCDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Reflected Generalized Topp and Leone CDF Functions
 
-----RGTPDF (LET)--------------------------------
 
RGTPDF
 
Name:
    RGTPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reflected generalized Topp and Leone probability
    density function with shape parameters alpha and beta.
 
Description:
    The reflected generalized Topp and Leone distribution has
    the following probability density function:

        f(x;alpha,beta,a,b) = (beta/(b-a))*
            ((b-x)/(b-a))**(beta-1)*
            {alpha - (alpha-1)*((b-x)/(b-a))}**(beta-1)*
            {alpha - 2*(alpha-1)*((b-x)/(b-a))}
            a <= x <= b, beta > 0, 0 < alpha <= 2
 
    with alpha and beta denoting the shape parameters and
    a and b the lower and upper limits, respectively.

    The case where a = 0 and b = 1 is referred to as the
    standard reflected generalized Topp and Leone distribution.

    The lower and upper limits are related to the location
    and scale parameters as follows:

        location = a
        scale    = b - a

    Kotz and van Dorp have proposed this distribution as an
    alternative to the beta distribution.  It is distinguished
    from the beta distribution in that it can have positive
    density at the lower limit with a strict positive mode.

Syntax:
    LET <y> = RGTPDF(<x>,<alpha>,<beta>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing
              values in the interval (a,b);
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed reflected generalized
              topp and leone pdf value is stored;
          <alpha> is a number, parameter, or variable in the
              interval (0, 2) that specifies the first shape
              parameter;
          <beta> is a positive number, parameter, or variable that
              specifies the second shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = RGTPDF(0.3,0.2,1.2)
    LET Y = RGTPDF(X,0.5,2)
    PLOT RGTPDF(X,2,3) FOR X = 0  0.01  1
 
Note:
    Reflected generalized Topp and Leone random numbers,
    probability plots, and goodness of fit tests can be
    generated with the commands:

       LET ALPHA = <value>
       LET BETA = <value>
       LET A = <value>
       LET B = <value>
       LET Y = REFLECTED GENERALIZED TOPP LEONE ...
               RANDOM NUMBERS FOR I = 1 1 N
       REFLECTED GENERALIZED TOPP LEONE PROBABILITY PLOT Y
       REFLECTED GENERALIZED TOPP LEONE PROBABILITY PLOT Y2 X2
       REFLECTED GENERALIZED TOPP LEONE PROBABILITY PLOT ...
               Y3 XLOW XHIGH
       REFLECTED GENERALIZED TOPP LEONE KOLMOGOROV SMIRNOV ...
               GOODNESS OF FIT Y
       REFLECTED GENERALIZED TOPP LEONE CHI-SQUARE ...
               GOODNESS OF FIT Y2 X2
       REFLECTED GENERALIZED TOPP LEONE CHI-SQUARE ...
               GOODNESS OF FIT Y3 XLOW XHIGH

    The following commands can be used to estimate the alpha
    and beta shape parameters for the reflected generalized
    Topp and Leone distribution:

       LET ALPHA1 = <value>
       LET ALPHA2 = <value>
       LET BETA1 = <value>
       LET BETA2 = <value>
       REFLECTED GENERALIZED TOPP LEONE PPCC PLOT Y
       REFLECTED GENERALIZED TOPP LEONE PPCC PLOT Y2 X2
       REFLECTED GENERALIZED TOPP LEONE PPCC PLOT Y3 XLOW XHIGH
       REFLECTED GENERALIZED TOPP LEONE KS PLOT Y
       REFLECTED GENERALIZED TOPP LEONE KS PLOT Y2 X2
       REFLECTED GENERALIZED TOPP LEONE KS PLOT Y3 XLOW XHIGH

    The default values for ALPHA1 and ALPHA2 are 0.1 and 2.
    The default values for BETA1 and BETA2 are 0.5 and 10.

    The probability plot can then be used to estimate the
    lower and upper limits (lower limit = PPA0,
    upper limit = PPA0 + PPA1).

    The following options may be useful for these commands.

       1) Instead of generating the ppcc plot or ks plot on
          the original data, we can generate them on
          selected percentiles of the data.  For example,
          if we have 1,000 points, we can choose to generate
          the plots on 100 evenly spaced percentiles with
          the command

             SET PPCC PLOT DATA POINTS 100

          This can be used to speed up the generation of 
          the plot for larger data sets.

       2) For the ks plot, we can fix the location and scale.
          This is equivalent to assuming that the lower and
          upper limits are known (e.g., we could use the
          data minimum and maximum as the lower and upper
          limit values).  Given that the lower and upper
          limits are LOWLIM and UPPLIM, enter the commands

             LET KSLOC   = LOWLIM
             LET KSSCALE = UPPLIM

          The ppcc plot is invariant to location and scale,
          so we cannot fix the lower and upper limits.

    Kotz and Van Dorp describe an approximate maximum likelihood
    method for estimating the alpha and beta parameters of the standard
    reflected generalized Topp and Leone distribution.  It is assumed
    that the data are grouped into m intervals [x(i)-1,x(i)] where the
    ith interval has n(i) observations.  The midpoint of the interval is
    denoted as xbar(i).  For unbinned data, the intervals consist of the
    individual observations (and the frequency is equal to 1).  The total
    sample size, N, is the sum of the n(i).

    The parameter alpha is the solution to the following equation:

        G(alpha) = {N/SUM[i=1 to m][n(i)*LOG(1/(alpha*y(i) - 
                   (alpha - 1)*y(i)**2)]) - 1}*
                   SUM[i=1 to m][n(i)*(1 - y(i)/(alpha - (alpha - 1)*y(i))]
                   + SUM[i=1 to m]
                   [n(i)*(1 - 2*y(i)/(alpha - 2*(alpha - 1)*y(i))]

    where

        y(i) = 1 - xbar(i)

    The maximum likelihood estimate of beta is then:

        betahat = N/
                  SUM[i=1 to m][n(i)*LOG(1/(alpha*y(i)-(alpha-1)*y(i)**2))]

    If the data lie outside the (0,1) interval, then we first apply the
    transformation

        X'(i) = (X(i) - Lower Limit)/(Upper Limit - Lower Limit)

    To generate the approximate maximum likelihood estimates for
    ungrouped data in Dataplot, enter the command

        REFLECTED GENERALIZED TOPP AND LEONE MLE Y

    For grouped data, enter one of the following commands

        REFLECTED GENERALIZED TOPP AND LEONE MLE Y X
        REFLECTED GENERALIZED TOPP AND LEONE MLE Y XLOW XHIGH

    In the first case, X denotes the mid-points of the bins and Y
    denotes the corresponding frequency.  In the second case,
    XLOW denotes the lower end-points of the bins and XHIGH denotes
    the upper end-points of the bins.

    If the lower and upper limits are fixed and known, you
    can enter the following commands:

       LET LOWLIMIT = <value>
       LET UPPLIMIT = <value>

    For the unknown case, the minimum and maximum of the data
    will be used (an epsilon value will be subtracted/added
    to the minimum/maximum).  Alternatively, you can use
    the estimates of the lower/upper limits generated by
    either the PPCC plot method or the KS plot methods and
    specify the LOWLIMIT and UPPLIMIT as above.

    To specify starting values for alpha and beta, enter
    the commands

       LET ALPHASV = <value>
       LET BETASV  = <value>

    For example, the estimates obtained from the PPCC plot or the
    KS plot can be used as starting values for the maximum likelihood
    estimates.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RGTCDF = Compute the reflected generalized Topp and Leone
             cumulative distribution function.
    RGTPPF = Compute the reflected generalized Topp and Leone
             percent point function.
    GTLPDF = Compute the generalized Topp and Leone probability
             density function.
    TOPPDF = Compute the Topp and Leone probability density
             function.
    TSPPDF = Compute the two-sided power probability density
             function.
    BETPDF = Compute the beta probability density function.
    TRIPDF = Compute the triangular probability density function.
    TRAPDF = Compute the trapezoid probability density function.
    UNIPDF = Compute the uniform probability density function.
    POWPDF = Compute the power probability density function.
    JSBPDF = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond Beta:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, chapter 7.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/2
 
Program 1:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 3 3
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 3
    .
    LET ALPHA = 2
    LET BETA  = 3
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 1.5
    LET BETA  = 6
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 1.5
    LET BETA  = 2
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 1.5
    LET BETA  = 1
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 0.5
    LET BETA  = 2
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 0.5
    LET BETA  = 1
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 0.5
    LET BETA  = 0.75
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 0.5
    LET BETA  = 0.25
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    LET ALPHA = 1
    LET BETA  = 1
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPDF(X,ALPHA,BETA) FOR X = 0  0.01  1
    .
    END OF MULTIPLOT
 
Program 2:
    let alpha = 1.5
    let beta = 2
    .
    let y = reflected generalized topp leone rand numb for i = 1 1 200
    .
    let alphsav = alpha
    let betasav = beta
    reflected generalized topp leone ppcc plot y
    just center
    move 50 5
    let alpha = shape1
    let beta = shape2
    text maxppcc = ^maxppcc, Alpha = ^alpha, Beta = ^beta
    move 50 2
    text Alphasav = ^alphsav, Betasav = ^betasav
    .
    char x
    line blank
    reflected generalized topp leone prob plot y
    move 50 5
    text PPA0 = ^ppa0, PPA1 = ^ppa1
    move 50 2
    let upplim = ppa0 + ppa1
    text Lower Limit = ^ppa0, Upper Limit = ^upplim
    char blank
    line solid
    .
    let ksloc = ppa0
    let ksscale = upplim
    reflected generalized topp leone kolm smir goodness of fit y
    .
    bootstrap reflected generalized topp leone plot y
    .

-----RGTPPF (LET)--------------------------------
 
RGTPPF
 
Name:
    RGTPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reflected generalized Topp and Leone percent
    point function with shape parameters alpha and beta.
 
Description:
    The standard reflected generalized Topp and Leone
    distribution has the following percent point function:

        G(p;alpha,beta,a,b) = 
            1-{alpha-SQRT(alpha**2-4*(alpha-1)*(1-p)**(1/beta)}/
            {2*(alpha-1)}            for 1 < alpha <= 2

            1 - (1-p)**(1/beta)      for alpha = 1

            1-{alpha+SQRT(alpha**2-4*(alpha-1)*(1-p)**(1/beta)}/
            {2*(alpha-1)}            for 0 < alpha < 1

            0 <= p <= 1, beta > 0
 
    with alpha and beta denoting the shape parameters.

    The standard distribution can be generalized with
    lower and upper bound parameters, a and b respectively,
    by utilizing the following relation:

        G(p;alpha,beta,a,b) = a + (b-a)*G(p;alpha,beta,0,1)

    The lower and upper limits are related to the location
    and scale parameters as follows:

        location = a
        scale    = b - a

Syntax:
    LET <y> = RGTPPF(<p>,<alpha>,<beta>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, parameter, or variable containing
              values in the interval (0,1);
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed reflected generalized
              topp and leone ppf value is stored;
          <alpha> is a number, parameter, or variable in the
              interval (0, 2) that specifies the first shape
              parameter;
          <beta> is a positive number, parameter, or variable that
              specifies the second shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = RGTPPF(0.95,0.2,1.2)
    LET Y = RGTPPF(P,0.5,2)
    PLOT RGTPPF(P,2,3) FOR P = 0  0.01  1
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RGTCDF = Compute the reflected generalized Topp and Leone
             cumulative distribution function.
    RGTPDF = Compute the reflected generalized Topp and Leone
             probability density function.
    GTLPPF = Compute the generalized Topp and Leone probability
             density function.
    TOPPDF = Compute the Topp and Leone probability density
             function.
    TSPPDF = Compute the two-sided power probability density
             function.
    BETPDF = Compute the beta probability density function.
    TRIPDF = Compute the triangular probability density function.
    TRAPDF = Compute the trapezoid probability density function.
    UNIPDF = Compute the uniform probability density function.
    POWPDF = Compute the power probability density function.
    JSBPDF = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond Beta:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, chapter 7.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/2
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 3 3
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 3
    .
    LET ALPHA = 2
    LET BETA  = 3
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPPF(P,ALPHA,BETA) FOR P = 0  0.01  1
    .
    LET ALPHA = 1.5
    LET BETA  = 6
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPPF(P,ALPHA,BETA) FOR P = 0  0.01  1
    .
    LET ALPHA = 1.5
    LET BETA  = 2
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPPF(P,ALPHA,BETA) FOR P = 0  0.01  1
    .
    LET ALPHA = 1.5
    LET BETA  = 1
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPPF(P,ALPHA,BETA) FOR P = 0  0.01  1
    .
    LET ALPHA = 0.5
    LET BETA  = 2
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPPF(P,ALPHA,BETA) FOR P = 0  0.01  1
    .
    LET ALPHA = 0.5
    LET BETA  = 1
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPPF(P,ALPHA,BETA) FOR P = 0  0.01  1
    .
    LET ALPHA = 0.5
    LET BETA  = 0.75
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPPF(P,ALPHA,BETA) FOR P = 0  0.01  1
    .
    LET ALPHA = 0.5
    LET BETA  = 0.25
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPPF(P,ALPHA,BETA) FOR P = 0  0.01  1
    .
    LET ALPHA = 1
    LET BETA  = 1
    TITLE Alpha = ^alpha, Beta = ^beta
    PLOT RGTPPF(P,ALPHA,BETA) FOR P = 0  0.01  1
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Reflected Generalized Topp and Leone PPF Functions
 
-----RIGCDF (LET)--------------------------------
 
RIGCDF
 
Name:
    RIGCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reciprocal inverse Gaussian cumulative distribution
    function with shape parameters gamma and mu.
 
Description:
    The reciprocal inverse Gaussian distribution is the distribution
    of (1/X) when X has an inverse Gaussian distribution.  It has
    the following cumulative distribution function:

      F(x;gamma,mu) = NORCDF[-(1/(mu*x) - 1)*SQRT(gamma*x)] - 
                      EXP(2/gamma**2)*
                      NORCDF[-(1/(mu*x) - 1)*SQRT(gamma*x)]
                      x >= 0; gamma, mu > 0

    with gamma and mu denoting the shape parameters and NORCDF denoting
    the cumulative distribution function of the standard normal
    distribution.

    The reciprocal inverse Gaussian distribution can be computed
    in terms of the inverse Gaussian distribution by

       RIGCDF(x;gamma,mu) = IGCDF((1/x);gamma,mu)/(x**2)

    The reciprocal inverse Gaussian distribution can be generalized
    with location and scale parameters in the usual way.

Syntax:
    LET <y> = RIGCDF(<x>,<gamma>,<mu>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <gamma> is number or parameter that specifies the first
              shape parameter;
          <mu> is number or parameter that specifies the second
              shape parameter;
          <loc> is number or parameter that specifies the location
              parameter;
          <scale> is number or parameter that specifies the scale
              parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed reciprocal inverse Gaussian cdf
              value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

Examples:
    LET A = RIGCDF(3,2,1)
    LET A = RIGCDF(A1,2,1)
    LET X2 = RIGCDF(X1,2,3)
    PLOT RIGCDF(X,2,1.5) FOR X = 0.1  0.1  5
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RIGPDF  = Compute the reciprocal inverse Gaussian probability
              density function.
    RIGCHAZ = Compute the reciprocal inverse Gaussian cumulative
              hazard function.
    RIGHAZ  = Compute the reciprocal inverse Gaussian hazard
              function.
    RIGPPF  = Compute the reciprocal inverse Gaussian percent point
              function.
    IGPDF   = Compute the reciprocal inverse Gaussian probability
              density function.
    CHSPDF  = Compute the chi-square probability density function.
    FPDF    = Compute the F probability density function.
    NORPDF  = Compute the normal probability density function.
    TPDF    = Compute the t probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    WALPDF  = Compute the Wald probability density function.
    FLPDF   = Compute the fatigue life probability density function.

Reference:
    "Continuous Univariate Distributions--Volume 1", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, chapter 15.

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 114-116.

Applications:
    Distributional Modeling
 
Implementation Date:
    1990/5: Original implementation
    2003/12: Modified to treat mu as a shape parameter instead of
             a location parameter
 
Program:
    Y1LABEL Probability
    X1LABEL X
    LABEL CASE ASIS
    X1LABEL DISPLACEMENT 12
    Y1LABEL DISPLACEMENT 12
    MULTIPLOT SCALE FACTOR 2
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    TITLE GAMMA = 2, MU = 1
    PLOT RIGCDF(X,2,1) FOR X = 0.01  0.01  5
    TITLE GAMMA = 5, MU = 1
    PLOT RIGCDF(X,5,1) FOR X = 0.01  0.01  5
    TITLE GAMMA = 2, MU = 2
    PLOT RIGCDF(X,2,2) FOR X = 0.01  0.01  5
    TITLE GAMMA = 5, MU = 2
    PLOT RIGCDF(X,5,2) FOR X = 0.01  0.01  5
    END OF MULTIPLOT
    JUSTIFICATION CENTER
    MOVE 50 97
    CASE ASIS
    TEXT Reciprocal Inverse Gaussian CDF

-----RIGCHAZ (LET)--------------------------------
 
RIGCHAZ
 
Name:
    RIGCHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reciprocal inverse Gaussian cumulative hazard
    function with shape parameters gamma and mu.
 
Description:
    The reciprocal inverse Gaussian distribution is the distribution
    of (1/X) when X has an inverse Gaussian distribution.  It has
    the following cumulative hazard function:

       H(x;gamma,mu) = -LOG[1 - RIGCDF(x;gamma,mu)]
                       x >= 0; gamma, mu > 0

    with gamma and mu denoting the shape parameters and RIGCDF
    denoting the reciprocal inverse Gaussian cumulative
    distribution function.

    The reciprocal inverse Gaussian distribution can be generalized
    with location and scale parameters in the usual way.

Syntax:
    LET <y> = RIGCHAZ(<x>,<gamma>,<mu>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <gamma> is number or parameter that specifies the first
              shape parameter;
          <mu> is number or parameter that specifies the second
              shape parameter;
          <loc> is number or parameter that specifies the location
              parameter;
          <scale> is number or parameter that specifies the scale
              parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed reciprocal inverse Gaussian 
              cumulative hazard value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

Examples:
    LET A = RIGCHAZ(3,2,1)
    LET A = RIGCHAZ(A1,2,1)
    LET X2 = RIGCHAZ(X1,2,3)
    PLOT RIGCHAZ(X,2,1.5) FOR X = 0.1  0.1  5
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RIGCDF  = Compute the reciprocal inverse Gaussian cumulative
              distribution function.
    RIGHAZ  = Compute the reciprocal inverse Gaussian hazard
              function.
    RIGPDF  = Compute the reciprocal inverse Gaussian probability
              density function.
    RIGPPF  = Compute the reciprocal inverse Gaussian percent point
              function.
    IGPDF   = Compute the reciprocal inverse Gaussian probability
              density function.
    CHSPDF  = Compute the chi-square probability density function.
    FPDF    = Compute the F probability density function.
    NORPDF  = Compute the normal probability density function.
    TPDF    = Compute the t probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    WALPDF  = Compute the Wald probability density function.
    FLPDF   = Compute the fatigue life probability density function.

Reference:
    "Continuous Univariate Distributions--Volume 1", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, chapter 15.

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 114-116.

Applications:
    Distributional Modeling
 
Implementation Date:
    1990/5: Original implementation
    2003/12: Modified to treat mu as a shape parameter instead of
             a location parameter
 
Program:
    Y1LABEL Cumulative Hazard
    X1LABEL X
    LABEL CASE ASIS
    X1LABEL DISPLACEMENT 12
    Y1LABEL DISPLACEMENT 12
    MULTIPLOT SCALE FACTOR 2
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    TITLE GAMMA = 2, MU = 1
    PLOT RIGCHAZ(X,2,1) FOR X = 0.01  0.01  5
    TITLE GAMMA = 5, MU = 1
    PLOT RIGCHAZ(X,5,1) FOR X = 0.01  0.01  5
    TITLE GAMMA = 2, MU = 2
    PLOT RIGCHAZ(X,2,2) FOR X = 0.01  0.01  5
    TITLE GAMMA = 5, MU = 2
    PLOT RIGCHAZ(X,5,2) FOR X = 0.01  0.01  5
    END OF MULTIPLOT
    JUSTIFICATION CENTER
    MOVE 50 97
    CASE ASIS
    TEXT Reciprocal Inverse Gaussian Cumulative Hazard

-----RIGHAZ (LET)--------------------------------
 
RIGHAZ
 
Name:
    RIGHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reciprocal inverse Gaussian hazard function with
    shape parameters gamma and mu.
 
Description:
    The reciprocal inverse Gaussian distribution is the distribution
    of (1/X) when X has an inverse Gaussian distribution.  It has
    the following hazard function:

       h(x;gamma,mu) = RIGPDF(x;gamma/mu)/[1 - RIGCDF(x;gamma,mu)]
                       x >= 0; gamma, mu > 0

    with gamma and mu denoting the shape parameters and RIGPDF and
    RIGCDF denoting the reciprocal inverse Gaussian probability
    density and cumulative distribution functions, respectively.

    The reciprocal inverse Gaussian distribution can be generalized
    with location and scale parameters in the usual way.

Syntax:
    LET <y> = RIGHAZ(<x>,<gamma>,<mu>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <gamma> is number or parameter that specifies the first
              shape parameter;
          <mu> is number or parameter that specifies the second
              shape parameter;
          <loc> is number or parameter that specifies the location
              parameter;
          <scale> is number or parameter that specifies the scale
              parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed reciprocal inverse Gaussian cdf
              value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

Examples:
    LET A = RIGHAZ(3,2,1)
    LET A = RIGHAZ(A1,2,1)
    LET X2 = RIGHAZ(X1,2,3)
    PLOT RIGHAZ(X,2,1.5) FOR X = 0.1  0.1  5
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RIGPDF  = Compute the reciprocal inverse Gaussian probability
              density function.
    RIGCDF  = Compute the reciprocal inverse Gaussian cumulative
              distribution function.
    RIGCHAZ = Compute the reciprocal inverse Gaussian cumulative
              hazard function.
    RIGPPF  = Compute the reciprocal inverse Gaussian percent point
              function.
    IGPDF   = Compute the reciprocal inverse Gaussian probability
              density function.
    CHSPDF  = Compute the chi-square probability density function.
    FPDF    = Compute the F probability density function.
    NORPDF  = Compute the normal probability density function.
    TPDF    = Compute the t probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    WALPDF  = Compute the Wald probability density function.
    FLPDF   = Compute the fatigue life probability density function.

Reference:
    "Continuous Univariate Distributions--Volume 1", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, chapter 15.

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 114-116.

Applications:
    Distributional Modeling
 
Implementation Date:
    1990/5: Original implementation
    2003/12: Modified to treat mu as a shape parameter instead of
             a location parameter
 
Program:
    Y1LABEL Hazard
    X1LABEL X
    LABEL CASE ASIS
    X1LABEL DISPLACEMENT 12
    Y1LABEL DISPLACEMENT 12
    MULTIPLOT SCALE FACTOR 2
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    TITLE GAMMA = 2, MU = 1
    PLOT RIGHAZ(X,2,1) FOR X = 0.01  0.01  5
    TITLE GAMMA = 5, MU = 1
    PLOT RIGHAZ(X,5,1) FOR X = 0.01  0.01  5
    TITLE GAMMA = 2, MU = 2
    PLOT RIGHAZ(X,2,2) FOR X = 0.01  0.01  5
    TITLE GAMMA = 5, MU = 2
    PLOT RIGHAZ(X,5,2) FOR X = 0.01  0.01  5
    END OF MULTIPLOT
    JUSTIFICATION CENTER
    MOVE 50 97
    CASE ASIS
    TEXT Reciprocal Inverse Gaussian Hazard

-----RIGPDF (LET)--------------------------------
 
RIGPDF
 
Name:
    RIGPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reciprocal inverse Gaussian probability density
    function with shape parameters gamma and mu.
 
Description:
    The reciprocal inverse Gaussian distribution is the distribution
    of (1/X) when X has an inverse Gaussian distribution.  It has
    the following probability density function:

       f(x;gamma,mu) = SQRT(gamma/(2*PI*x))*
                       EXP(-gamma*(1-mu*x)**2/(2*mu**2*x))
                       x >= 0; gamma, mu > 0

    with gamma and mu denoting the shape parameters.

    The reciprocal inverse Gaussian distribution can be computed
    in terms of the inverse Gaussian distribution by

       RIGPDF(x;gamma,mu) = IGPDF((1/x);gamma,mu)/(x**2)

    The reciprocal inverse Gaussian distribution has mean
    (gamma + mu)/(gamma*mu) and standard deviation
    SQRT((gamma + 2*mu)/(gamma**2*mu)).
 
    The reciprocal inverse Gaussian distribution can be generalized
    with location and scale parameters in the usual way.

    The reciprocal inverse Gaussian distribution is also known as
    the random walk distribution.

Syntax:
    LET <y> = RIGPDF(<x>,<gamma>,<mu>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <gamma> is number or parameter that specifies the first
              shape parameter;
          <mu> is number or parameter that specifies the second
              shape parameter;
          <loc> is number or parameter that specifies the location
              parameter;
          <scale> is number or parameter that specifies the scale
              parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed reciprocal inverse Gaussian pdf
              value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

Examples:
    LET A = RIGPDF(3,2,1)
    LET A = RIGPDF(A1,2,1)
    LET X2 = RIGPDF(X1,2,3)
    PLOT RIGPDF(X,2,1.5) FOR X = 0.1  0.1  5
 
Note:
    Random numbers, probability plots, and Kolmogorov-Smirnov and
    chi-square goodness of fit tests can be generated with the
    commands:

       LET GAMMA = <value>
       LET MU = <value>
       LET Y = RECIPROCAL INVERSE GAUSSIAN RANDOM NUMBERS FOR I = 1 1 N
       RECIPROCAL INVERSE GAUSSIAN PROBABILITY PLOT Y
       RECIPROCAL INVERSE GAUSSIAN KOLMOGOROV-SMIRNOV GOODNESS OF FIT Y
       RECIPROCAL INVERSE GAUSSIAN CHI-SQUARE FIT Y

    The following commands can be used to generate estimates for the
    shape parameters of the reciprocal inverse Gaussian distribution:

       LET GAMMA1 = <value>
       LET GAMMA2 = <value>
       LET MU1 = <value>
       LET MU2 = <value>
       RECIPROCAL INVERSE GAUSSIAN PPCC PLOT Y
       RECIPROCAL INVERSE GAUSSIAN KS PLOT Y

    The default values for GAMMA1 and GAMMA2 are 0.5 and 25.  The
    default values for MU1 and MU2 are 0.5 and 25.
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RIGCDF  = Compute the reciprocal inverse Gaussian cumulative
              distribution function.
    RIGCHAZ = Compute the reciprocal inverse Gaussian cumulative
              hazard function.
    RIGHAZ  = Compute the reciprocal inverse Gaussian hazard
              function.
    RIGPPF  = Compute the reciprocal inverse Gaussian percent point
              function.
    IGPDF   = Compute the reciprocal inverse Gaussian probability
              density function.
    CHSPDF  = Compute the chi-square probability density function.
    FPDF    = Compute the F probability density function.
    NORPDF  = Compute the normal probability density function.
    TPDF    = Compute the t probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    WALPDF  = Compute the Wald probability density function.
    FLPDF   = Compute the fatigue life probability density function.

Reference:
    "Continuous Univariate Distributions--Volume 1", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, chapter 15.

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 114-116.

Applications:
    Distributional Modeling
 
Implementation Date:
    1990/5: Original implementation
    2003/12: Modified to treat mu as a shape parameter instead of
             a location parameter
 
Program:
    Y1LABEL Probability
    X1LABEL X
    LABEL CASE ASIS
    X1LABEL DISPLACEMENT 12
    Y1LABEL DISPLACEMENT 12
    MULTIPLOT SCALE FACTOR 2
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    TITLE GAMMA = 2, MU = 1
    PLOT RIGPDF(X,2,1) FOR X = 0.01  0.01  5
    TITLE GAMMA = 5, MU = 1
    PLOT RIGPDF(X,5,1) FOR X = 0.01  0.01  5
    TITLE GAMMA = 2, MU = 2
    PLOT RIGPDF(X,2,2) FOR X = 0.01  0.01  5
    TITLE GAMMA = 5, MU = 2
    PLOT RIGPDF(X,5,2) FOR X = 0.01  0.01  5
    END OF MULTIPLOT
    JUSTIFICATION CENTER
    MOVE 50 97
    CASE ASIS
    TEXT Reciprocal Inverse Gaussian PDF

-----RIGPPF (LET)--------------------------------
 
RIGPPF
 
Name:
    RIGPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reciprocal inverse Gaussian percent point function
    with shape parameters gamma and mu.
 
Description:
    The reciprocal inverse Gaussian distribution is the distribution
    of (1/X) when X has an inverse Gaussian distribution.  It has
    the following cumulative distribution function:

      F(x;gamma,mu) = NORCDF[-(1/(mu*x) - 1)*SQRT(gamma*x)] - 
                      EXP(2/gamma**2)*
                      NORCDF[-(1/(mu*x) - 1)*SQRT(gamma*x)]
                      x >= 0; gamma, mu > 0

    with gamma and mu denoting the shape parameters and NORCDF denoting
    the cumulative distribution function of the standard normal
    distribution.

    The percent point function is the inverse of the cumulative
    distribution function.  The percent point function for the
    reciprocal inverse Gaussian distribution does not exist in
    simple, closed form.

    The reciprocal inverse Gaussian percent point function can be
    computed in terms of the inverse Gaussian percent point
    function by

       RIGPPF(p;gamma,mu) = 1/IGPPF(1-p;gamma,mu)

    Dataplot uses this relationship to compute the reciprocal
    inverse gaussian percent point function.

    The reciprocal inverse Gaussian distribution can be generalized
    with location and scale parameters in the usual way.

Syntax:
    LET <y> = RIGPPF(<p>,<gamma>,<mu>,<loc>,<scale>)
              <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable or a parameter in the interval (0,1);
          <gamma> is number or parameter that specifies the first
              shape parameter;
          <mu> is number or parameter that specifies the second
              shape parameter;
          <loc> is number or parameter that specifies the location
              parameter;
          <scale> is number or parameter that specifies the scale
              parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed reciprocal inverse Gaussian ppf
              value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Note that the location and scale parameters are optional.

Examples:
    LET A = RIGPPF(0.95,2,1)
    LET A = RIGPPF(P1,2,1)
    PLOT RIGPPF(P,2,1.5) FOR P = 0  0.01  0.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RIGCDF  = Compute the reciprocal inverse Gaussian cumulative
              distribution function.
    RIGCHAZ = Compute the reciprocal inverse Gaussian cumulative
              hazard function.
    RIGHAZ  = Compute the reciprocal inverse Gaussian hazard
              function.
    RIGPDF  = Compute the reciprocal inverse Gaussian probability
              density function.
    IGPDF   = Compute the reciprocal inverse Gaussian probability
              density function.
    CHSPDF  = Compute the chi-square probability density function.
    FPDF    = Compute the F probability density function.
    NORPDF  = Compute the normal probability density function.
    TPDF    = Compute the t probability density function.
    WEIPDF  = Compute the Weibull probability density function.
    WALPDF  = Compute the Wald probability density function.
    FLPDF   = Compute the fatigue life probability density function.

Reference:
    "Continuous Univariate Distributions--Volume 1", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, chapter 15.

    "Statistical Distributions", Third Edition, Evans, Hastings,
    and Peacock, Wiley, 2000, pp. 114-116.

Applications:
    Distributional Modeling
 
Implementation Date:
    1990/5: Original implementation
    2003/12: Modified to treat mu as a shape parameter instead of
             a location parameter
 
Program:
    X1LABEL Probability
    Y1LABEL X
    LABEL CASE ASIS
    X1LABEL DISPLACEMENT 12
    Y1LABEL DISPLACEMENT 12
    MULTIPLOT SCALE FACTOR 2
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    TITLE GAMMA = 2, MU = 1
    PLOT RIGPPF(P,2,1) FOR P = 0  0.01  0.99
    TITLE GAMMA = 5, MU = 1
    PLOT RIGPPF(P,5,1) FOR P = 0  0.01  0.99
    TITLE GAMMA = 2, MU = 2
    PLOT RIGPPF(P,2,2) FOR P = 0  0.01  0.99
    TITLE GAMMA = 5, MU = 2
    PLOT RIGPPF(P,5,2) FOR P = 0  0.01  0.99
    END OF MULTIPLOT
    JUSTIFICATION CENTER
    MOVE 50 97
    CASE ASIS
    TEXT Reciprocal Inverse Gaussian Percent Point

-----RING BELL-------------------------------------------------------
 
RING BELL
 
Name:
    RING BELL
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Rings the bell (immediately).
 
Syntax:
    RING BELL   <number>
    where <number> is an integer number or parameter that specifies
              the number of times to ring the bell.
 
Examples:
    RING BELL
    RING BELL 3
 
Note:
    RING BELL with no arguments is equivalent ot RING BELL 1.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    ERASE     = Erases the screen (immediately).
    COPY      = Copies the screen (immediately).
    BELL      = Sets the automatic bell switch for plots.
    PRE-ERASE = Sets the automatic pre-erase switch for plots.
    HARDCOPY  = Sets the automatic copy switch for plots.
    SEQUENCE  = Sets the automatic sequence switch for plots.
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----RLP (LET)-----------------------------------------
 
RLP
 
Name:
    RLP (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Given a response variable containing z-scores and an associated
    variable containing the material-id, compute the relative laboratory
    performance (RLP) of a variable.
 
Description:
    One scenario for proficiency testing described in the ISO 13528
    standard is for the case where there are multiple rounds of testing.
    The proficiency data typically consists of

         Z        - a variable containing the response data in z-score
                    units
         MATID    - a variable containing the material-id
         ROUNDID  - a variable containing the round-id
         LABID    - a variable containing the lab-id

    For ISO 13528 multi-round proficiency studies, the relative
    laboratory performance (RLP) for a given laboratory with N z-scores
    (Z(i)) is defined as

         RLP = SQRT{SUM[i=1 to N][Z(I)**2]/NMAT}

    where NMAT is the number of materials.  An RLP near 1 indicates
    average performance and an RLP greater than 1.5 indicates that
    the laboratory may be problematic.  An advantage of this
    statistic is that z-scores of opposite sign do not cancel each
    other out.  A disadvantage is that this statistic is suspectible
    to outliers in the z-scores.

    The RLP statistic is discussed in Uhlig and Lischer (1998).  The RLP
    statistic is an examples of a combination score (i.e., the statistic
    is a combination of many individual z-scores).  Although the
    ISO 13528 standard recommends against using combination scores, these
    can be helpful in judging the overall performance of a
    laboratory.  These combination scores can be used to identify
    laboratories that are potentially problematic.  These
    laboratories can then be examined more carefully.  For
    example: is the poor performance due to one or a few outliers?
    is the lab consistently high or consistently low?  does the
    laboratory need to carefully examine their procedures?

    This statistic is used to compute the RLP for a single
    laboratory.  Note that the material-id variable is only
    used to determine the number of materials (NMAT in the
    above formula).

    The most typical use of this statistic is with the
    TABULATE command or the STATISTIC PLOT command where the
    group-id variable is the laboratory-id variable.  For
    example, the command

         RLP PLOT Z MATID LABID

    can be used to generate a plot of the RLP values for each
    laboratory.

Syntax:
    LET <par> = RLP <z> <matid>   <SUBSET/EXCEPT/FOR qualification>
    where <z> is the response variable containing z-scores;
          <matid> is a variable containing the material-id's;
          <par> is a parameter where the computed rlp is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    The SUBSET clause can be used to specify a specific laboratory
    for which to compute the statistic.
 
Examples:
    LET A = RLP Z MAT
    LET A = RLP Z MAT  SUBSET LAB = 23
    TABULATE RLP Z MATID LABID
    RLP PLOT Z MATID LABID

Note:
    The ISO 13528 standard defines a number of methods for computing the
    z-scores (enter HELP ISO 13528 ZSCORE, HELP ISO 13528 ZPRIME SCORE,
    and HELP ISO 13528 ZETA SCORE for details).  For this reason, the
    ISO 13528 RLP PLOT command does not automatically compute the
    z-scores from the original response data.

Note:
    In some applications it may be desired to cap the value
    of outliers.  This is most common when the response variable
    is a z-score or some other standardized score.

    To specify this value, enter the command

        LET CAPVALUE = <value>

    where <value> is typically 3 or 4 (if the reponse data are
    z-scores or z-score type data).  Note that the value represents
    an absolute value.  For example, if CAPVALUE is 4, values greater
    than 4 will be set to 4 and values less than -4 will be set to -4.

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    ISO 13528 RLP PLOT       = Generate a plot of relative laboratory
                               performance against the rescaled sums.
    ISO 13528 PLOT           = Generate an ISO 13528 plot.
    ISO 13528 ZSCORE PLOT    = Generate an ISO 13528 zscore plot.
    ISO 13528 CONTROL CHART  = Generate an ISO 13528 control chart.
    ISO 13528 ZSCORE         = Compute z-scores as defined in the
                               ISO 13528 standard.
    ISO 13528 ZPRIME SCORE   = Compute z-prime scores as defined in the
                               ISO 13528 standard.
    ISO 13528 ZETA SCORE     = Compute zeta scores as defined in the
                               ISO 13528 standard.
    TABULATE                 = Compute a statistic for one or more
                               group variables.
    STATISTIC PLOT           = Generate a statistic versus index plot.

References:
    Uhlig and Lischer (1998), "Statistically-based Performance
    Characteristics in Laboratory Performance Studies", Analyst,
    123, pp. 167-172.

    ISO 13528 (2005), "Statistical Methods for use in proficiency
    testing by interlaboratory comparisons," First Edition,
    2005-09-01.
 
Applications:
    Multiple Round Proficiency Testing
 
Implementation Date:
    2015/2
 
Program 1:
    . Step 1:   Read the data
    .
    dimension 40 columns
    skip 25
    read turner.dat labid z year quarter matid matave
    skip 0
    let labcoded = code labid
    .
    . Step 2:   Set plot control setting
    .
    case asis
    title case asis
    title offset 2
    label case asis
    y1label Relative Laboratory Performance
    x1label Laboratory
    title RLP Versus Laboratory for TURNER.DAT
    y1tic mark label decimal 1
    tic mark offset units data
    x1tic mark offset 2 0
    y1tic mark offset 0.2 0.5
    ylimits 0 3
    .
    line blank
    character circle
    character hw 0.5 0.375
    character fill on
    .
    . Step 3:   Generate plot of RLP vs Lab
    .
    rlp plot z matid labcoded
    line dash
    line color blue
    drawsdsd 15 1.5 85 1.5
    line color red
    drawsdsd 15 3.0 85 3.0
    .
    . Step 4:   Tabulate RLP values for each laboratory
    .
    set write decimals 4
    tabulate rlp z matid labid

-----RM-------------------------------------------------------
 
RM
RMDIR
 
Name:
    RM
    RMDIR
 
Type:
    Support Command
 
Purpose:
    This command deletes one or more files or directories.
 
Description:
    This command uses an operating system command to delete
    one or more files or one or more directories.

    For Unix/Linux/MacOS systems, the RM command issues a

        rm ....

    command to the operating system and the RMDIR command issues a

        rm -r ...

    command to the operating system.

    For Windows systems, the RM command issues an

        ERASE ....

    command to the operating system and the RMDIR command issues a

        DELTRE ...

    command to the operating system.

    The RMDIR command will remove any files or sub-directories
    under the directory being removed.

    The string that follows the RM or RMDIR on the command line
    is passed to the operating system as is.  Dataplot does no
    error checking of this string.

    This command should be used with caution so that files
    are not accidentally deleted.

    This is a system dependent command.  It is currently supported
    for Unix/Linux/MacOS and Windows platforms.

Syntax 1:
    RM <file-list>
    where <file-list> is a string containing a list of one or more
               files to delete.
 
Syntax 2:
    RMDIR <file-list>
    where <file-list> is a string containing a list of one or more
               directories to delete.
 
Examples:
    RM  *.ps
    RM  macro.out  macro.ps  macro.pdf
    RMDIR  macros tmp
 
Note:
    The RM capability can be implemented by direct use of the
    SYSTEM command.  For example, under Linux do something like

         system  rm  junk*.out

    The motivation for adding this as a separate command is to
    allow the capability to be implemented in an operating
    system independent way.  This can be useful when writing
    general purpose macros that may be used on different
    operating systems.

Default:
    None
 
Synonyms:
    None (we have not added DELETE or ERASE as synonyms as these
    commands are already used in Dataplot)
 
Note:
    Dataplot does no checking to ensure that a valid file name
    or directory name was specified.  The entered string is
    passed to the operating system as entered.

Note:
    File names are case sensitive on Unix/Linux/MacOS file
    systems.  For this reason, case is preserved in passing the
    file list to the operating system.
 
Related Commands:
    SYSTEM      = Enter an operating system command within a
                  Dataplot session.
    CD          = Change the current working directory.
    PWD         = Retrieve the current working directory.
    CAT         = List the contents of a file.
    MKDIR       = Create a new directory.
    DIR         = List the contents of a directory.
 
Applications:
    Interactive Usage
 
Implementation Date:
    2019/09
 
Program:
    . Automatically convert Postscript output to PDF and then
    . delete the original Postscript file
    .
    SKIP 25
    READ BERGER1.DAT Y X
    .
    SET POSTSCRIPT CONVERT PDF
    SET IPL1NA PLOT.PS
    CHARACTER X
    LINE BLANK
    .
    PLOT Y X
    .
    DEVICE 2 CLOSE
    RM PLOT.PS
 
-----ROBUST POOLED STANDARD DEVIATION (LET)-----------------------------
 
ROBUST POOLED STANDARD DEVIATION
 
Name:
    ROBUST POOLED STANDARD DEVIATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the robust pooled standard deviation of a variable.
 
Description:
    The definition for the robust pooled standard deviation from
    the ISO 13528 standard.  It is computed as follows.

    Let w1, w2, ... , wp be the standard deviations from the p labs.
    The degrees of freedom for w(i) = n(i) - 1 where n(i) is the number
    of replications for lab i.
 
    Compute

        Limit Factor = LF = SQRT(CHSPPF(0.9,nu)/nu)

        Adjustment Factor = AF = 1/SQRT(CHSCDF(nu*LF**2),nu+2) + 0.1*LF**2)

    The limit factor and adjustment factor assume that each lab has the
    same number of replications.  If the number of replications are not
    equal, Dataplot will use the average number of replications.

    The initual value of w* is set to the median of the w(i)'s.

    To update the value of w*, compute

       psi = limit factor times w*

    For each w(i), 

       w(i)* = psi    if w(i) >  psi
             = w(i)   if w(i) <= psi

    The updated value of w* is

       w* = Adjustment Factor * SQRT(SUM[i=1 to p][(w(i))**2]/p)

    The value of w* is iterated until the difference between two
    successive values of w* is sufficiently small.

    The ISO 13528 standard also allows this computation to be performed
    on the lab ranges.  In this case, the robust pooled range uses the
    same computation as above with the exception that the degrees of
    freedom, nu, is set to 1.

Syntax 1:
    LET <par> = ROBUST POOLED STANDARD DEVIATION  <y>  <x>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x> is the lab-id variable;
          <par> is a parameter where the computed robust pooled sd
              is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <par> = ROBUST POOLED RANGE  <y>  <x>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x> is the lab-id variable;
          <par> is a parameter where the computed robust pooled range
              is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET SD = ROBUST POOLED STANDARD DEVIATION Y X
    LET SD = ROBUST POOLED STANDARD DEVIATION Y X  SUBSET TAG > 2
    LET SD = ROBUST POOLED RANGE Y X
 
Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    ROBUST POOLED SD is a synonym for ROBUST POOLED STANDARD DEVIATION
 
Related Commands:
    MEAN                   = Compute the mean of a variable.
    MEDIAN                 = Compute the median of a variable.
    RANGE                  = Compute the range of a variable.
    STANDARD DEVIATION     = Compute the standard deviation of a variable.
    H15 SCALE              = Compute the H15 scale estimate of a variable.
    WEIGHTED STAND DEVI    = Compute the weighted standard deviation of
                             a variable.
    HOMOSCEDASTICITY PLOT  = Compute the standard deviation of a variable.
 
Applications:
    Data Analysis, Proficiency Analysis
 
Reference:
    ISO 13528 (2005), "Statistical Methods for use in proficiency
    testing by interlaboratory comparisons," Section C.2 Algorithm S.

Implementation Date:
    2010/12
 
Program:
    SKIP 25
    READ GEAR.DAT Y X
    .
    SET LET CROSS TABULATE COLLAPSE
    LET YSD = CROSS TABULATE SD Y X
    LET NSIZE = CROSS TABULATE SIZE X
    LET NREPL = MEAN NSIZE
    .
    LET A = ROBUST POOLED STANDARD DEVIATION Y X
 
-----ROC CURVE (LET)--------------------------------
 
ROC CURVE
 
Name:
    ROC CURVE (LET)
 
Type:
    Graphics Command
 
Purpose:
    Generate a Reciever Operating Characterisitc (ROC) curve.
 
Description:
    Given two variables with n parired observations where each
    variable has exactly two possible outcomes, we can generate
    the following 2x2 table:

                      |       Variable 2        |
        Variable 1    |   Success      Failure  |  Row Total
        ====================================================
        Success       |   N11            N12    |  N11 + N12
        Failure       |   N21            N22    |  N21 + N22
        ====================================================
        Column Total  |   N11+N21      N12+N22  |  N11+N12+N21+N22

    The parameters N11, N12, N21, and N22 denote the counts
    for each category.
 
    Success and failure can denote any binary response.
    Dataplot expects "success" to be coded as "1" and "failure"
    to be coded as "0".  Some typical examples would be:

       1) Variable 1 denotes whether or not a patient has a
          disease (1 denotes disease is present, 0 denotes
          disease not present).  Variable 2 denotes the result
          of a test to detect the disease (1 denotes a positive
          result and 0 denotes a negative result).

       2) Variable 1 denotes whether an object is present or
          not (1 denotes present, 0 denotes absent). Variable 2
          denotes a detection device (1 denotes object detected
          and 0 denotes object not detected).

    In these examples, the "ground truth" is typically given
    as variable 1 while some estimator of the ground truth is
    given as variable 2.
   
    In the above table, we can define the following
    quantities:

        1) True Positives  = N11 (i.e., number of cases where
                             disease present and test detects it)
                            
        2) True Negatives  = N22 (i.e., number of cases where
                             disease not present and test did not
                             detect it)
                            
        3) False Positives = N21 (i.e., number of cases where
                             disease not present and test detects
                             it)
                            
        4) False Negatives = N12 (i.e., number of cases where
                             disease is present and test does not
                             detect it)

        5) Sensitivity     = N11/(N11+N12) (i.e., the probability
                             that the test detects the disease
                             given that the disease is present)
                            
        6) Specificity     = N21/(N21+N22) (i.e., the probability
                             that the test detects the disease
                             given that the disease is not
                             present)

    The ROC curve is a plot of the sensitivity versus
    1 - the specificity.  Points in the upper left corner
    (i.e., high sensitivity and high specificity) are
    desirable.

    We have two typical scenarios for generating the
    ROC curve.

       1) We have a medical test and we want to determine
          an optimal level for deciding whether the disease
          is present.  Setting the level too low results
          in too many false negatives (i.e., we fail to
          detect the disease when it is in fact present).
          This is low sensitivity.  On the other hand, if
          we set the level too high we may obtain too many
          false positives (i.e., we detect the disease when
          it is in fact not present).  This is low specificity.

          In this case, we typically want to generate the
          ROC curve as a connected line to show the
          tradeoff between sensitivity and specificity
          as we change the threshold level.

       2) We are testing sensors to determine which provides
          the best performance in detecting some substances.

          Since these are distinct devices, we would typically
          want to plot these as distinct points rather than
          as a connected curve.

    You can also combine these scenarios.  That is, we may
    testing multiple devices (scenario 2) where each device
    may have multiple settings.

Syntax 1:
    ROC CURVE <y1> <y2> <x>     <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <x> is a group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the cases where

       a) we have multiple settings for a single machine
       b) we have multiple machines each with a single setting

Syntax 2:
    ROC CURVE <y1> <y2> <x1> <x2>    <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <x1> is a group-id variable;
          <x2> is a variable that identifies the setting within
               the group;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where we have multiple
    settings for multiple machines.

Examples:
    ROC CURVE Y1 Y2 X
    ROC CURVE Y1 Y2 X  SUBSET X > 2
    ROC CURVE Y1 Y2 X1 X2
    ROC CURVE Y1 Y2 X1 X2 SUBSET X1 > 2
 
Note:
    Some guidelines for interperting the ROC curve are:

      1) Points in the upper left corner denote high
         accuracy.

      2) Dataplot draws a line from the (0,0) point to the
         (1,1) point.  This is referred to as the no
         discrimination line.  Points falling on this line
         indicate a test that is no better than flipping a
         coin.

      For the case where we are changing the threshold of a
      test, the ROC curves does an excellent job of demonstrating
      the tradeoff between specificity and sensitivity.  That is,
      as we decrease the chance of a false negative (i.e., we do
      not miss detection), we inevitably increase the chance of
      a false positive.  So what we are looking for is a test
      that follows the left x-axis and then the top y-axis.  In
      other words, the closer the curve is to the no discrimination
      line, the poorer the test.

Note:
    The three (or four) variables must have the same number of
    elements.
 
Note:
    There are two ways you can define the response variables:

       1) Raw data - in this case, the variables contain
          0's and 1's.

          If the data is not coded as 0's and 1's, Dataplot
          will check for the number of distinct values.  If
          there are two distinct values, the minimum value
          is converted to 0's and the maximum value is
          converted to 1's.  If there is a single distinct
          value, it is converted to 0's if it is less than
          0.5 and to 1's if it is greater than or equal to
          0.5.  If there are more than two distinct values,
          an error is returned.

       2) Summary data - if there are two observations for
          a group, the data is assummed to be the 2x2 summary
          table.  That is,

              Y1(1) = N11
              Y1(2) = N21
              Y2(1) = N12
              Y2(2) = N22

Note:
    As noted above, there are two distinct cases for which ROC
    curves can be used.  Consider the example where we are testing
    whether an instrument can detect some specified object. 

       1) In one case, we may want to compare instruments from
          different vendors.  In this case, the ROC curve
          would be used to help determine which vendor
          has the best instrument.

       2) In the other case, we may be able to change the
          level at which we determine whether or not we
          have detected the object.  In this case, the
          ROC curve can be used to help determine an
          optimal setting for the instrument.  In this case,
          there is typically a trade-off between sensitivity
          and specificity (i.e., as our instrument becomes
          more sensitive to the prescence of the object,
          we also increase the probability of a false
          positive).

    Of course, we can have a combination of these cases
    (i.e., multiple instruments each with multiple possible
    settings).

Note:
    You can control the appearance of the plot using the
    LINE and CHARACTER (and their various attribute setting
    commands).

    For Syntax 1, the following traces are generated for the
    plot:

       1) trace 1  - a line from (0,0) to (1,1).  This is the
                     "no discrimination line".

       2) trace 2  - a curve containing all the points on the
                     ROC curve.

       3) trace 3 and above - each point is drawn as a separate
                              trace.  This is useful for the case
                              when each point represents a distinct
                              instrument.

    For Syntax 2, the following traces are generated for the
    plot:

       1) trace 1  - a line from (0,0) to (1,1).  This is the
                     "no discrimination line".

       2) trace 2 and above  - each curve contains all the settings
                               for one group (i.e., trace 2 contains
                               the settings for group 1, trace 3
                               contains the settings for group 2, and
                               so on).

Note:
    Dataplot automatically returns the area under the curve
    as the parameter AUC (points are added at (0,0) and (1,1)).
    This area is determined by numerical integration.

    This statistic is only meaningful for the case where we
    are plotting different settings of the same instrument.

    For the case where we have multiple settings for multiple
    vendors, we write the AUC statistic to the file
    dpst1f.dat (in the current directory).  Column 1 contains
    the group-id value and column 2 contains the value of the
    AUC statistic for that group.

Default:
    None
 
Synonyms:
    None

Related Commands:
    ROSE PLOT                  = Generate a Rose plot.
    BINARY TABULATION PLOT     = Generate a binary tabulation plot.
    TEST SPECIFICITY           = Compute the test specificity.
    TEST SENSITIVITY           = Compute the test sensitivity.
    FALSE NEGATIVES            = Compute the proportion of
                                 false negatives.
    FALSE POSITIVES            = Compute the proportion of
                                 false positives.
    TRUE NEGATIVES             = Compute the proportion of
                                 true negatives.
    TRUE POSITIVES             = Compute the proportion of
                                 true positives.
    ODDS RATIO                 = Compute the bias corrected
                                 log(odds ratio).
    ODDS RATIO STANDARD ERROR  = Compute the standard error of the
                                 bias corrected log(odds ratio).
    RELTIVE RISK               = Compute the relative risk.
 
Reference:
    Hosmer and Lemeshow (2000), "Applied Logistic Regression",
    Second Edition, Wiley, pp. 160-164.
 
Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/7: Support for syntax 2 added
 
Program 1:
    let n = 1
    .
    let p = 0.2
    let y1 = binomial rand numb for i = 1 1 100
    let p = 0.1
    let y2 = binomial rand numb for i = 1 1 100
    .
    let p = 0.4
    let y1 = binomial rand numb for i = 101 1 200
    let p = 0.08
    let y2 = binomial rand numb for i = 101 1 200
    .
    let p = 0.15
    let y1 = binomial rand numb for i = 201 1 300
    let p = 0.18
    let y2 = binomial rand numb for i = 201 1 300
    .
    let p = 0.6
    let y1 = binomial rand numb for i = 301 1 400
    let p = 0.45
    let y2 = binomial rand numb for i = 301 1 400
    .
    let p = 0.3
    let y1 = binomial rand numb for i = 401 1 500
    let p = 0.1
    let y2 = binomial rand numb for i = 401 1 500
    .
    let x = sequence 1 100 1 5
    .
    limits 0  1
    major xtic mark number 6
    minor xtic mark number 1
    tic mark offset 0.05 0.05
    .
    label case asis
    title case asis
    title offset 2
    x1label 1 - Specificity
    y1label Sensitivity
    character blank blank 1 2 3 4 5
    line blank all
    line dotted
    roc curve y1 y2 x

Program 2:
    .  Following sample data from Wikipedia site
    read y1 y2 x
    63 37 1
    28 72 1
    77 23 2
    77 23 2
    24 76 3
    88 12 3
    88 12 4
    24 76 4
    end of data
    .
    character blank blank A B C D
    line blank all
    line dotted
    limits 0 1
    major tic mark number 6
    minor tic mark number 1
    tic mark offset 0.05 0.05
    .
    label case asis
    title case asis
    title offset 2
    title ROC Curve
    y1label Sensitivity
    x1label 1 - Specificity
    .
    roc curve y1 y2 x

-----ROOTS (LET)-------------------------------------------------
 
ROOTS
 
Name:
    ROOTS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Determine the real roots of a function.
 
Syntax:
    LET <resp> = ROOTS <func>  WRT <var> FOR <var> = <lower> <upper>
    where <func> is the name of a previously defined function or a
              functional expression;
          <var> is the variable for which the roots are being computed;
          <lower> is a number or parameter defining the lower limit for
              finding roots;
          <upper> is a number or parameter defining the upper limit for
              finding roots;
          <resp> is a parameter where the computed roots are stored.
 
Examples:
    LET A = ROOTS X**2+2*X**2-4*X+5 WRT X FOR X = -10 10
    LET A = ROOTS F1 WRT X FOR X = 0 B
 
Note:
    DATAPLOT uses an inward bracketing followed by bisection algorithm
    to find roots.  The Numerical Recipes book listed in the REFERENCE
    gives a description of these methods (although DATAPLOT does not
    use their implementation).
 
Note:
    DATAPLOT uses the following convergence test:
        value = delta x / x
    where delta x is the difference between two iterations in the root
    finding algorithm and x is the current value of the root.
    Convergence is assumed when this value is smaller than a specified
    cutoff (hard-coded to 0.000001).
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    POLYNOMIAL ROOTS  = Compute the roots of a polynomial.
    DERIVATIVE        = Compute the derivative of a function.
    INTEGRAL          = Compute the integral of a function.
    RUNGE KUTTA       = Runge Kutta differential equation solver.
    INTERPOLATE       = Interpolate a function.
 
Reference:
    "A First Course in Numerical Analysis", 2nd ed., Ralston and
    Rabinowitz, 1978, McGraw-Hill.
 
    "Numerical Recipes: The Art of Scientific Computing (FORTRAN
    Version)", Press, Flannery, Teukolsky, and Vetterling.  Cambridge
    University Press, 1989 (chapter 9).
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET FUNCTION F1 = X**3+2*X**2-4*X+5
    PLOT F1 FOR X = -10  0.1   10
    LET A1 = ROOTS F1 WRT X FOR X = -10 10
 
-----ROOT ACCURACY---------------------------------------------------
 
ROOT ACCURACY
 
Note:
    This command is currently ignored by the ROOTS command.  The ROOTS
    command uses a hard-coded value of 0.000001.
 
Name:
    ROOT ACCURACY
 
Type:
    Support Command
 
Purpose:
    Specify the root accuracy for the ROOTS command.
 
Description:
    When DATAPLOT finds roots, it computes
        delta x / x
    where delta x is the difference between two iterations in the root
    finding algorithm and x is the current value of the root.  If this
    value is less than the root accuracy, then convergence is assumed.
 
Syntax:
    ROOT ACCURACY  <val>
    where <val> is a number or parameter that specifies the root
                accuracy.
 
Examples:
    ROOT ACCURACY 0.001
    ROOT ACCURACY 0.00001
 
Default:
    0.000001
 
Synonyms:
    XX
 
Related Commands:
    ROOTS         = Find the real roots of an equation.
    COMPLEX ROOTS = Find the complex roots of a polynomial.
 
Applications:
    Mathematics
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----ROOT MEAN SQUARE ERROR (LET)-----------------------------------------
 
ROOT MEAN SQUARE ERROR
 
Name:
    ROOT MEAN SQUARE ERROR (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the root means square error of a variable.
 
Description:
    The root mean square error has the formula:

         RMS = SQRT(SUM[i=1 to N][X(i)**2]/N)
 
Syntax 1:
    LET <par> = ROOT MEAN SQUARE ERROR <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed root mean square error
              is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <par> = DIFFERENCE OF ROOT MEAN SQUARE ERROR <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed difference of
              root mean square errors is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax computes the root mean square error of <y1> and
    <y2> and then computes the difference of the two root mean
    square error values.
 
Examples:
    LET A = ROOT MEAN SQUARE ERROR Y1
    LET A = ROOT MEAN SQUARE ERROR Y1  SUBSET TAG > 2
    LET A = DIFFERENCE OF ROOT MEAN SQUARE ERROR Y1 Y2
 
Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    ROOT MEAN SQUARE
    RMS
 
Related Commands:
    MEAN                 = Compute the mean of a variable.
    RANGE                = Compute the range of a variable.
    STANDARD DEVIATION   = Compute the standard deviation of a variable.
    VARIANCE             = Compute the variance of a variable.
 
Applications:
    Statistics
 
Implementation Date:
    2010/1
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET RMS = ROOT MEAN SQUARE ERROR Y1
 
-----ROOTOGRAM-------------------------------------------------------
 
ROOTOGRAM
 
Name:
    ... ROOTOGRAM
 
Type:
    Graphics Command
 
Purpose:
    Generates a rootogram.
 
Description:
    A rootogram is a graphical data analysis technique for summarizing
    the distributional information of a variable.  It consists of:
      Vertical   axis = square root of frequencies or relative
                        frequencies;
      Horizontal axis = response variable.
    There are 4 types of rootograms:
          1) rootogram (absolute counts);
          2) relative rootogram (converts counts to proportions);
          3) cumulative rootogram;
          4) cumulative relative rootogram.
    The rootogram is a modified version of a histogram.  It plots the
    square roots of the frequencies rather than the raw frequencies.
    Many univariate data sets can be normalized with a square root
    transformation (particularly counts or measurement data that have
    a lower bound and tend to be skewed at the upper tail).
 
Syntax 1:
    ROOTOGRAM   <x>                   <SUBSET/EXCEPT/FOR qualification>
    RELATIVE ROOTOGRAM   <x>          <SUBSET/EXCEPT/FOR qualification>
    CUMULATIVE ROOTOGRAM   <x>        <SUBSET/EXCEPT/FOR qualification>
    CUMULATIVE RELATIVE ROOTOGRAM <x> <SUBSET/EXCEPT/FOR qualification>
    where <x> is the variable of raw data values which will appear on
              the horizontal axis;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used when you have raw data only.
 
Syntax 2:
    ROOTOGRAM <y> <x>                 <SUBSET/EXCEPT/FOR qualification>
    RELATIVE ROOTOGRAM <y> <x>        <SUBSET/EXCEPT/FOR qualification>
    CUMULATIVE ROOTOGRAM <y> <x>      <SUBSET/EXCEPT/FOR qualification>
    CUMULATIVE RELATIVE ROOTOGRAM <y> <x>
                                      <SUBSET/EXCEPT/FOR qualification>
    where <y> is the variable of pre-computed frequencies to appear on
              the vertical axis;
          <x> is the variable of raw data values which will appear on
              the horizontal axis;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used when you have pre-computed frequencies at each
    horizontal axis value.
 
Examples:
    ROOTOGRAM TEMP
    RELATIVE ROOTOGRAM TEMP
    CUMULATIVE ROOTOGRAM TEMP
    CUMULATIVE RELATIVE ROOTOGRAM TEMP
    ROOTOGRAM COUNTS STATE
    RELATIVE ROOTOGRAM COUNTS STATE
    CUMULATIVE ROOTOGRAM COUNTS STATE
    CUMULATIVE RELATIVE ROOTOGRAM COUNTS STATE
 
Note:
    The appearance of the bars on the rootogram (i.e., whether they are
    filled or not, the line width of the bar border, etc.) are
    controlled by the various bar attribute commands.  A few are listed
    in the RELATED COMMANDS section below.  See the documentation for
    the BAR command for a complete list of the bar attribute commands.
 
Note:
    Although DATAPLOT does not have a FREQUENCY TABLE command, one can
    be generated with the following commands:
       HISTOGRAM Y
       LET YFREQ = YPLOT
       LET XVAL = XPLOT
    Then the variables YFREQ and XVAL essentially contain a frequency
    table.  There is a LET subcommand called FREQUENCY.  However, it
    does not generate a frequency table in the sense that a histogram
    or a frequency plot does.  The frequency table can also be
    generated by replacing HISTOGRAM with ROOTOGRAM in the above
    sequence.  However, be aware that this generates the square roots
    of the frequencies, not the raw frequencies.
 
Note:
    By default, DATAPLOT uses a class width of 0.3 X the standard
    deviation of the variable.  Use the CLASS WIDTH command to override
    this default.  DATAPLOT also tends to generate a large number of
    zero frequency classes at the lower and upper tails.  This tends to
    compress the histogram on the horizontal axis.  Use the XLIMITS
    command or the CLASS LOWER and CLASS UPPER commands to avoid
    plotting these zero frequency classes.
 
Default:
    None
 
Synonyms:
    A synonym for CUMULATIVE RELATIVE ROOTOGRAM is RELATIVE CUMULATIVE
    ROOTOGRAM
 
Related Commands:
    HISTOGRAM          = Generate a histogram.
    FREQUENCY PLOT     = Generates a frequency plot.
    PIE CHART          = Generates a pie chart.
    PERCENT POINT PLOT = Generates a percent point plot.
    PROBABILITY PLOT   = Generates a probability plot.
    PPCC PLOT          = Generates probability plot correlation
                         coefficient plot.
    CLASS LOWER        = Sets the lower class minimum for histograms,
                         frequency plots, and pie charts.
    CLASS UPPER        = Sets the upper class maximum for histograms,
                         frequency plots, and pie charts.
    CLASS WIDTH        = Sets the class width for histograms, frequency
                         plots, and pie charts.
    MINIMUM            = Sets the frame minima for all plots.
    MAXIMUM            = Sets the frame maxima for all plots.
    LIMITS             = Sets the frame limits for all plots.
    PLOT               = Generates a data or function plot.
    BARS               = Sets the on/off switches for plot bars.
    BAR WIDTH          = Sets the widths for plot bars.
    BAR FILL           = Sets the on/off switches for plot bar fills.
    BAR PATTERN        = Sets the types for bar fill patterns.
    BAR BORDER LINE    = Sets the types for bar border lines.
 
Reference:
    Most introductory statistics book discuss frequency polygons and
    histograms.  The rootogram is described in "Exploratory Data
    Analysis", John Tukey, Addison-Wesley, 1977.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET Y = NORMAL RANDOM NUMBERS FOR I = 1 1 1000
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    XLIMITS -5 5
    ROOTOGRAM Y
    BAR FILL ON
    RELATIVE ROOTOGRAM Y
    BAR FILL OFF
    BAR BORDER THICKNESS 0.3
    CUMULATIVE ROOTOGRAM Y
    BAR FILL ON
    BAR PATTERN D1
    BAR PATTERN SPACING 3
    CUMULATIVE RELATIVE ROOTOGRAM Y
    END OF MULTIPLOT
 
-----ROSE PLOT-------------------------------------------------------
 
ROSE PLOT
 
Name:
    ROSE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generate a rose plot.
 
Description:
    The rose plot is a variation of the common pie chart.  For
    both, we have k data points where each point denotes a
    frequency or a count.  Pie charts and rose plots both use
    the area of segments of a circle to convey amounts.  The
    pie chart uses a common radius and varies the central angle
    according to the data.  That is, the angle is proportional
    to the frequency.  So if the ith point has count X and the
    total count is N, the ith angle is 360*(X/N).  For the rose
    plot, the angle is constant (i.e., divide 360 by the number
    of groups, k) and it is the square root of the radius that is
    proportional to the data.

    According to Wainer (1997), the use of a common angle is the
    strength of the rose plot since it allows us to easily compare
    a sequence of rose plots (i.e., the corresponding segments in
    different rose plots are always in the same relative
    position).  In particular, this makes rose plots an effective
    technique for displaying the data in contingency tables.

    Friendly (2000) refers to the special case of 2x2 tables as
    the fourfold plot.  As with the general case, an effective
    use of these plots is when we have a sequence of related 2x2
    tables.  Using the MULTIPLOT command, Dataplot can easily
    generate the sequence of rose plots or fourfold plots on a
    single page.

    As an interesting historical note, Wainer points out that
    rose plots were used by Florence Nightingale (she referred to
    them as coxcombs).

Syntax 1:
    ROSE PLOT  <x>    <SUBSET/EXCEPT/FOR qualification>
    where <x> is the variable containing counts;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Use this syntax when you have a single variable of
    counts (or proportions).

Syntax 2:
    ROSE PLOT  <y1>  <y2>   <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    With this syntax, the <y1> and <y2> variables are
    cross-tabulated to generate a 2x2 table.  The rose plot
    is then generated from this 2x2 table.

Examples:
    ROSE PLOT X
    ROSE PLOT X  SUBSET TAG > 2
    ROSE PLOT Y1 Y2
 
Note:
    Each wedge is drawn with a common set of attributes.  The
    attributes of the wedge borders are set with the LINE,
    LINE COLOR, and LINE THICKNESS commands (typically they are
    all set the same).  The attributes of the interior are set
    with the various REGION commands.  Any labels for the wedges
    must be set with the LEGEND or TEXT commands.  The CROSS HAIR
    command can help in positioning labels.  The program example
    below shows how to set the attributes.  Dataplot does not
    support features such as 3d rose plots or exploding slices
    that are common in many business graphics programs.

Note:
    You can use the CONDITION PLOT command for the case where
    you want to generate rose plots for a series of 2x2 tables.
    This is demomstrated in the program examples below.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PIE CHART          = Generates a pie chart.
    HISTOGRAM          = Generates a histogram.
    PERCENT POINT PLOT = Generates a percent point plot.
    PLOT               = Generates a plot (including bar plots).
    LINE               = Sets the types for plot lines.
    LINE COLOR         = Sets the colors for plot lines.
    LINE THICKNESS     = Sets the thicknesses for plot lines.
    REGION             = Sets the types for plot regions.
    REGION FILL        = Sets on/off switches for region fills.
 
Reference:
    Wainer (1997), "Visual Revelations: Graphical Tales of Fate
    and Deception from Napolean Bonaporte to Ross Perot",
    Copernicus, Chapter 11.
 
    Friendly (2000), "Visualizing Categorical Data", SAS Institute
    Inc., p. 90.

Applications:
    Categorical Data Analysis
 
Implementation Date:
    2007/4
 
Program 1:
    let y = data 48 12 53 7
    .
    region fill on on on on
    region fill color black blue red green
    rose plot y
    .
    case asis
    justification left
    move 15 90
    text Truecr()Positives
    move 15 10
    text Falsecr()Positives
    move 75 90
    text Falsecr()Negatives
    move 75 10
    text Truecr()Negatives

Program 2:
    let n = 1
    let x = sequence 1 100 1 5
    .
    let p = 0.8
    let y1 = binomial rand numb for i = 1 1 100
    let p = 0.92
    let y2 = binomial rand numb for i = 1 1 100
    .
    let p = 0.6
    let y1 = binomial rand numb for i = 101 1 200
    let p = 0.95
    let y2 = binomial rand numb for i = 101 1 200
    .
    let p = 0.96
    let y1 = binomial rand numb for i = 201 1 300
    let p = 0.98
    let y2 = binomial rand numb for i = 201 1 300
    .
    let p = 0.3
    let y1 = binomial rand numb for i = 301 1 400
    let p = 0.2
    let y2 = binomial rand numb for i = 301 1 400
    .
    let p = 0.9
    let y1 = binomial rand numb for i = 401 1 500
    let p = 0.2
    let y2 = binomial rand numb for i = 401 1 500
    .
    region fill on on on on
    region color black blue red green
    rose plot y1 y2 subset x = 5
    .
    set conditioning plot type two variable rose
    region fill off on on on on
    region color white black blue red green
    condition plot y1 y2 x

Program 3:
    orientation square
    .
    .  Berkeley Admissions Data from p. 391 of
    .  Friendly (2000), "Visualizing Categorical Data",
    .  SAS Institute Inc.
    .
    read y1 y2 x
    512 313 1
    353 207 1
     89  19 2
     17   8 2
    120 205 3
    138 279 3
    202 391 4
    131 244 4
     53 138 5
     22 351 5
     94 299 6
     24 317 6
    end of data
    . 
    multiplot corner coordinates 0 0 100 95
    multiplot scale factor 2
    multiplot 3 3
    .
    legend case asis
    legend justification left
    legend 2 justification right
    legend 4 justification right
    legend 1 coordinates 17 83
    legend 2 coordinates 83 83
    legend 3 coordinates 17 22
    legend 4 coordinates 83 22
    .
    region fill on on on on
    region fill color black blue red green
    box shadow hw 0 0
    .
    label case asis
    title case asis
    y1label Admit = Yes
    y2label Admit = No
    x1label Sex: Female
    x2label Sex: Male
    x2label displacement -74
    .
    let string t1 = Department A
    let string t2 = Department B
    let string t3 = Department C
    let string t4 = Department D
    let string t5 = Department E
    let string t6 = Department F
    .
    let icnt = 0
    let icnt2 =0
    loop for k = 1 1 6
       let icnt = icnt+1
       let atemp = y1(icnt)
       legend 1 ^atemp
       let atemp = y2(icnt)
       legend 2 ^atemp
       let icnt = icnt+1
       let atemp = y1(icnt)
       legend 3 ^atemp
       let atemp = y2(icnt)
       legend 4 ^atemp
       title ^t^k
       let icnt2 = icnt2 + 1
       if k = 3
          let icnt2 = icnt2 + 1
       end of if
       if k = 5
          let icnt2 = icnt2 + 1
       end of if
       multiplot 3 3 icnt2
       rose plot y1 y2 subset x = k
       box 15 20 85 90
    end of loop
    .
    end of multiplot
    .
    case asis
    justification center
    move 30 97
    text Rose Plots for Berkeley Admissions Data
     
-----ROTATE EYE--------------------------------------------------
 
ROTATE EYE
 
Name:
    ROTATE EYE
 
Type:
    Plot Control Command
 
Purpose:
    Specifies a direction and angle to rotate the current eye
    coordinates for 3-d plots.
 
Description:
    Changing the viewing position allows you to view a 3-d plot from
    a different perspective.  This can sometimes allow you to see more
    clearly certain structures that are hidden in the default viewing
    position.  The ROTATE EYE command can be used to do this
    automatically.  It is often used in conjunction with the LOOP
    command.
 
    The rotation has both a direction and an angle.  The direction can
    be one of the following:
        LEFT    - rotate left (in the XY plane);
        RIGHT   - rotate right (in the XY plane);
        UP      - rotate up (this case not implemented yet);
        DOWN    - rotate down (this case not implemented yet);
        XY      - rotate in the XY plane (equivalent to RIGHT);
        XZ      - rotate in the XZ plane;
        YZ      - rotate in the YZ plane.
    The angle is specified in degrees.
 
Syntax:
    ROTATE EYE  <dir>  <angle>
    where <dir> is one of the character strings listed above that
               specifies the desired direction;
    and   <angle> is a number or parameter that specifies the number of
               degrees to rotate the eye coordinates.
 
Examples:
    ROTATE
    ROTATE EYE
    ROTATE EYE 20
    ROTATE EYE RIGHT
    ROTATE EYE RIGHT 40
 
Default:
    If the <dir> argument is omitted, LEFT is used.  If the <angle>
    argument is omitted, 10 degrees is used.
 
Synonyms:
    ROTATE is a synonym for ROTATE EYE.
 
Related Commands:
    EYE COORDINATES    = Specifies the eye coordinates for a 3d plot.
    3D-PLOT            = Generates a 3-d data or function plot.
    3D-FRAME           = Specifies what type of 3D frame is drawn.
 
Applications:
    XX
 
Implementation Date:
    93/10
 
Program:
    LET FUNCTION F = SIN(X+COS(Y))
    3DFRAME 3PLANE
    FEEDBACK OFF
    .
    MULTIPLOT 4 4; MULTIPLOT CORNER COORDINATES 0 0 100 100
    LOOP FOR K = 1 1 16
       ROTATE
       3DPLOT F FOR X = -2 .2 2 FOR Y = -2 .2 2
    END LOOP
 
-----ROUND (LET)--------------------------------
 
ROUND
 
Name:
    ROUND (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the rounded value of a number to a user specified number of
    decimal places.
 
Syntax:
    LET <y2> = ROUND(<y1>,<n>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter containing decimal numbers
               to be rounded;
          <n>  is a number or parameter that specifies the number of
               decimal places to use for the rounding;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed rounded values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = ROUND(14.2835,1)
    LET A = ROUND(A1,2)
    LET X2 = ROUND(X1,1)
    LET X2 = ROUND(X1-4,2)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    INT    = Compute the integer portion of number.
    FRACT  = Compute the fractional portion of number.
    OCTDEC = Perform an octal to decimal conversion.
    MOD    = Compute the modulo function.
 
Applications:
    Data Transformations
 
Implementation Date:
    Pre-1987
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y2 = ROUND(Y1,1)
    PRINT Y1 Y2
 
-----ROWLABEL-------------------------------------------------
 
ROWLABEL
 
Name:
    ROWLABEL (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Converts previously read character data to row labels.
 
Description:
    The command READ ROW LABELS can be used to read the row labels
    from a file.  Alternatively, Dataplot can read character data
    using the
 
        SET CONVERT CHARACTER ON

    command.  This command stores the character fields in the
    file "dpchzf.dat".
 
    The two primary uses of character data are:

       1) Provide a row identifier for the data.

       2) Define a group (or factor) variable.  For example, we
          can identify sex by coding males as M and females as F.

    The ROWLABEL command (Syntax 1) is used to convert one of the
    previosuly read character variables to a row label.

    You can also copy a string to a specific row (Syntax 2 or
    Syntax 3).

    Once a row label has been defined, you can use the

        CHARACTER ROWLABEL
  
    command to label plot points.  Additional uses for row labels
    are anticipated in future releases of Dataplot.

Syntax 1:
    LET ROWLABEL = <ix>
    where <ix> specifies the name of the character variable in
               the file dpzchf.dat.

    The character variable is originally created with a READ
    command where the SET CONVERT CHARACTER ON was entered prior
    to the READ.

Syntax 2:
    LET ROWLABEL = STRING TO ROW LABEL <irow>  <s>
    where <s> is a previously defined string;
    and   <irow> is a parameter that identifies which row to set.

    This syntax is used to set a specific row of the row labels to
    a previously defined string.

Syntax 3:
    LET ROWLABEL <ival> = <string>
    where <string> is a literal string;
    and   <ival> is a parameter which specifies the row number.

    This syntax copies <string> into the <ival>-th row of the row
    labels.

Syntax 4:
    LET ROWLABEL = DELETE

    This syntax re-initializes all row labels to blank.
    labels.

Syntax 5:
    LET ROWLABEL = SHIFT LEFT <ival>
    where <ival> is a parameter.

    This syntax shifts all row labels left (= down) by <ival> rows.
    Vacated row labels will be set blank.

Syntax 6:
    LET ROWLABEL = SHIFT RIGHT <ival>
    where <ival> is a parameter.

    This syntax shifts all row labels right (= up) by <ival> rows.
    Vacated row labels will be set blank.

Examples:
    SET CONVERT CHARACTER ON
    READ TEST.DAT  Y X IX
    LET IG = ROW LABEL IX
 
Note:
    Row labels can be up to 24 characters long.

Note:
    Row labels can also be defined using the READ ROW LABELS
    command.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    READ                        = Carries out a column-wise input of
                                  data.
    CONVERT CHARACTER           = Specify how Dataplot will handle
                                  character data.
    CHARACTER CODE              = Converts character data to a coded
                                   numeric variable.
    GROUP LABELS                = Define row labels from character
                                  data.
 
Applications:
    Input/Output
 
Implementation Date:
    2004/1
    2012/08: Support for Syntax 2 - Syntax 6 added.
 
Program 1:
    let rowlabel 1 = 100101
    let rowlabel 2 = 100102
    let rowlabel 3 = 100103
    let rowlabel 4 = 100104
    let rowlabel 5 = 100105
    let rowlabel 6 = 100106
    let rowlabel 7 = 100107
    let rowlabel 8 = 100108
    let rowlabel 9 = 100109
    let rowlabel 10 = 100110
    .
    tic mark offset units screen
    tic mark offset 5 5
    character rowlabel
    plot x**2 for x = 1 1 10

Program 2:
    skip 25
    read antibody.dat lab  ymean  ysd  nrep
    .
    title case asis
    label case asis
    x1label Mean
    y1label Standard Deviation
    .
    xlimits 0.8  2.4
    major xtic mark number 9
    minor xtic mark number 1
    ylimits 0    1.6
    major ytic mark number 9
    minor ytic mark number 1
    .
    system rm dpzchf.dat
    let rowlabel = lab
    character blank all
    character blank blank blank rowlabel
    line blank all
    line solid dash dotted
    .
    title Highlight/Summary Form of Homoscedasticity Plot with Contour Linescr() ...
    for ANTIBODY.DAT
    set homo plot circle technique on
    summary homoscedasticity plot ymean ysd nrep

-----ROW LIMITS-------------------------------------------------------
 
ROW LIMITS
 
Name:
    ROW LIMITS
 
Type:
    Support Command
 
Purpose:
    Specifies the row limits in a file between which the read scan is
    restricted during subsequent READ and SERIAL READ commands.
 
Description:
    The specified rows and all rows in between are included in the
    data read.
 
Syntax:
    ROW LIMITS   <row 1>   <row 2>
    where <row 1> is a number or parameter that specifies the desired
               starting row;
    and   <row 2> is a number or parameter that specifies the desired
                ending row;
 
Examples:
    ROW LIMITS 10 30
    ROW LIMITS 1 15
    ROW LIMITS 50 63
 
Note:
    The NLIST command can be used to list a file with row numbers.
    This can sometimes be useful when setting row limits.
 
Default:
    All rows in the file are read.
 
Synonyms:
    None
 
Related Commands:
    READ           = Reads data (column-wise) into variables.
    SERIAL READ    = Reads data (row-wise) into variables.
    COLUMN LIMITS  = Sets the file columns to be included in the read.
    SKIP           = Sets the number of lines to skip over before the
                     read.
    WRITE          = Writes variables, parameters, and functions to
                     the screen or to a file.
    LIST           = Lists a file or the last 20 commands.
    NLIST          = Lists a file with row numbers.
 
Applications:
    Data Input
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----RPOCDF (LET)--------------------------------
 
RPOCDF
 
Name:
    RPOCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reflected power cumulative distribution function
    with shape parameter c.
 
Description:
    The standard reflected power distribution has the
    following cumulative distribution function:

       F(x;c) = 1 - (1-x)**c
                0 <= x <= 1, c > 0
 
    with c denoting the shape parameter.

    This distribution can be extended with lower and upper
    bound parameters.  If a and b denote the lower and upper
    bounds, respectively, then the location and scale 
    parameters are:

        location = a
        scale    = b - a

    The general form of the distribution can then be found
    by using the relation

        F(x;c,a,b) = F((x-a)/(b-a);c,0,1)

    The reflected power distribution is a special case of the
    beta distribution where the first shape parameter = 1
    (the power distribution is a special case of beta
    distribution where the second shape parameter = 1).

Syntax:
    LET <y> = RPOCDF(<x>,<c>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing
              values in the interval (a,b);
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed reflected power cdf value
              is stored;
          <c> is a positive number, parameter, or variable that
              specifies the shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = RPOCDF(0.3,0.2)
    LET Y = RPOCDF(X,0.5,0,5)
    PLOT RPOCDF(X,2.3) FOR X = 0  0.01  1
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RPOPDF  = Compute the reflected power probability density
              function.
    RPOPPF  = Compute the reflected power percent point function.
    RPOHAZ  = Compute the reflected power hazard function.
    RPOCHAZ = Compute the reflected power cumulative hazard
              function.
    POWPDF  = Compute the power probability density function.
    BETPDF  = Compute the beta probability density function.
    TOPPDF  = Compute the Topp and Leone probability density
              function.
    RGTPDF  = Compute the generalized reflected Topp and Leone
              probability density function.
    GTLPDF  = Compute the generalized Topp and Leone probability
              density function.
    TSPPDF  = Compute the two-sided power probability density
              function.
    TRIPDF  = Compute the triangular probability density function.
    TRAPDF  = Compute the trapezoid probability density function.
    UNIPDF  = Compute the uniform probability density function.
    JSBPDF  = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond Beta:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, pp. 199-201.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/12
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR
    .
    LET C  = 0.5
    TITLE C = ^c
    PLOT RPOCDF(X,C) FOR X = 0  0.01  1
    .
    LET C  = 1
    TITLE C = ^c
    PLOT RPOCDF(X,C) FOR X = 0  0.01  1
    .
    LET C  = 1.5
    TITLE C = ^c
    PLOT RPOCDF(X,C) FOR X = 0  0.01  1
    .
    LET C  = 2
    TITLE C = ^c
    PLOT RPOCDF(X,C) FOR X = 0  0.01  1
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Reflected Power Cumulative Distribution Functions
 
-----RPOCHAZ (LET)--------------------------------
 
RPOCHAZ
 
Name:
    RPOCHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reflected power cumulative hazard function
    with shape parameter c.
 
Description:
    The standard reflected power distribution has the
    following cumulative hazard function:

       H(x;c) = -LOG((1-x)**c)
                0 <= x <= 1, c > 0
 
    with c denoting the shape parameter.

    This distribution can be extended with lower and upper
    bound parameters.  If a and b denote the lower and upper
    bounds, respectively, then the location and scale 
    parameters are:

        location = a
        scale    = b - a

    The general form of the distribution can then be found
    by using the relation

        H(x;c,a,b) = H((x-a)/(b-a);c,0,1)

    The reflected power distribution is a special case of the
    beta distribution where the first shape parameter = 1
    (the power distribution is a special case of beta
    distribution where the second shape parameter = 1).

Syntax:
    LET <y> = RPOCHAZ(<x>,<c>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing
              values in the interval (a,b);
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed reflected power cumulative
              hazard value is stored;
          <c> is a positive number, parameter, or variable that
              specifies the shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = RPOCHAZ(0.3,0.2)
    LET Y = RPOCHAZ(X,0.5,0,5)
    PLOT RPOCHAZ(X,2.3) FOR X = 0  0.01  0.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RPOPDF  = Compute the reflected power probability density
              function.
    RPOCDF  = Compute the reflected power cumulative distribution
              function.
    RPOPPF  = Compute the reflected power percent point function.
    RPOHAZ  = Compute the reflected power hazard function.
    POWPDF  = Compute the power probability density function.
    BETPDF  = Compute the beta probability density function.
    TOPPDF  = Compute the Topp and Leone probability density
              function.
    RGTPDF  = Compute the generalized reflected Topp and Leone
              probability density function.
    GTLPDF  = Compute the generalized Topp and Leone probability
              density function.
    TSPPDF  = Compute the two-sided power probability density
              function.
    TRIPDF  = Compute the triangular probability density function.
    TRAPDF  = Compute the trapezoid probability density function.
    UNIPDF  = Compute the uniform probability density function.
    JSBPDF  = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond Beta:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, pp. 199-201.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/12
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR
    .
    LET C  = 0.5
    TITLE C = ^c
    PLOT RPOCHAZ(X,C) FOR X = 0  0.01  0.99
    .
    LET C  = 1
    TITLE C = ^c
    PLOT RPOCHAZ(X,C) FOR X = 0  0.01  0.99
    .
    LET C  = 1.5
    TITLE C = ^c
    PLOT RPOCHAZ(X,C) FOR X = 0  0.01  0.99
    .
    LET C  = 2
    TITLE C = ^c
    PLOT RPOCHAZ(X,C) FOR X = 0  0.01  0.99
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Reflected Power Cumulative Hazard Functions
 
-----RPOHAZ (LET)--------------------------------
 
RPOHAZ
 
Name:
    RPOHAZ (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reflected power hazard function with
    shape parameter c.
 
Description:
    The standard reflected power distribution has the
    following hazard function:

       h(x;c) = c/(1-x)
                0 <= x <= 1, c > 0
 
    with c denoting the shape parameter.

    This distribution can be extended with lower and upper
    bound parameters.  If a and b denote the lower and upper
    bounds, respectively, then the location and scale 
    parameters are:

        location = a
        scale    = b - a

    The general form of the distribution can then be found
    by using the relation

        h(x;c,a,b) = (1/(b-a))*h((x-a)/(b-a);c,0,1)

    The reflected power distribution is a special case of the
    beta distribution where the first shape parameter = 1
    (the power distribution is a special case of beta
    distribution where the second shape parameter = 1).

Syntax:
    LET <y> = RPOHAZ(<x>,<c>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing
              values in the interval (a,b);
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed reflected power hazard
              value is stored;
          <c> is a positive number, parameter, or variable that
              specifies the shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = RPOHAZ(0.3,0.2)
    LET Y = RPOHAZ(X,0.5,0,5)
    PLOT RPOHAZ(X,2.3) FOR X = 0  0.01  1
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RPOPDF  = Compute the reflected power probability density
              function.
    RPOCDF  = Compute the reflected power cumulative distribution
              function.
    RPOPPF  = Compute the reflected power percent point function.
    RPOCHAZ = Compute the reflected power cumulative hazard
              function.
    POWPDF  = Compute the power probability density function.
    BETPDF  = Compute the beta probability density function.
    TOPPDF  = Compute the Topp and Leone probability density
              function.
    RGTPDF  = Compute the generalized reflected Topp and Leone
              probability density function.
    GTLPDF  = Compute the generalized Topp and Leone probability
              density function.
    TSPPDF  = Compute the two-sided power probability density
              function.
    TRIPDF  = Compute the triangular probability density function.
    TRAPDF  = Compute the trapezoid probability density function.
    UNIPDF  = Compute the uniform probability density function.
    JSBPDF  = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond Beta:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, pp. 199-201.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/12
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR
    .
    LET C  = 0.5
    TITLE C = ^c
    PLOT RPOHAZ(X,C) FOR X = 0.01  0.01  0.99
    .
    LET C  = 1
    TITLE C = ^c
    PLOT RPOHAZ(X,C) FOR X = 0.01  0.01  0.99
    .
    LET C  = 1.5
    TITLE C = ^c
    PLOT RPOHAZ(X,C) FOR X = 0.01  0.01  0.99
    .
    LET C  = 2
    TITLE C = ^c
    PLOT RPOHAZ(X,C) FOR X = 0.01  0.01  0.99
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Reflected Power Hazard Functions
 
-----RPOPDF (LET)--------------------------------
 
RPOPDF
 
Name:
    RPOPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reflected power probability density function
    with shape parameter c.
 
Description:
    The standard reflected power distribution has the
    following probability density function:

       f(x;c) = c*(1-x)**(c-1)   
                0 <= x <= 1, c > 0
 
    with c denoting the shape parameter.

    This distribution can be extended with lower and upper
    bound parameters.  If a and b denote the lower and upper
    bounds, respectively, then the location and scale 
    parameters are:

        location = a
        scale    = b - a

    The general form of the distribution can then be found
    by using the relation

        f(x;c,a,b) = f((x-a)/(b-a);c,0,1)/(b-a)

    The reflected power distribution is a special case of the
    beta distribution where the first shape parameter = 1
    (the power distribution is a special case of the beta
    distribution where the second shape parameter = 1).

Syntax:
    LET <y> = RPOPDF(<x>,<c>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing
              values in the interval (a,b);
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed reflected power pdf value
              is stored;
          <c> is a positive number, parameter, or variable that
              specifies the shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = RPOPDF(0.3,0.2)
    LET Y = RPOPDF(X,0.5,0,5)
    PLOT RPOPDF(X,2.3) FOR X = 0  0.01  1
 
Note:
    Reflected power random numbers, probability plots, and
    goodness of fit tests can be generated with the commands:

       LET C = <value>
       LET A = <value>
       LET B = <value>
       LET Y = REFLECTED POWER RANDOM NUMBERS FOR I = 1 1 N
       REFLECTED POWER PROBABILITY PLOT Y
       REFLECTED POWER PROBABILITY PLOT Y2 X2
       REFLECTED POWER PROBABILITY PLOT Y3 XLOW XHIGH
       REFLECTED POWER KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       REFLECTED POWER CHI-SQUARE GOODNESS OF FIT Y2 X2
       REFLECTED POWER CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    The following commands can be used to estimate the c
    shape parameter for the reflected power distribution:

       LET C1 = <value>
       LET C2 = <value>
       REFLECTED POWER PPCC PLOT Y
       REFLECTED POWER PPCC PLOT Y2 X2
       REFLECTED POWER PPCC PLOT Y3 XLOW XHIGH
       REFLECTED POWER KS PLOT Y
       REFLECTED POWER KS PLOT Y2 X2
       REFLECTED POWER KS PLOT Y3 XLOW XHIGH

    The default values for C1 and C2 are 0.5 and 25.

    The probability plot can then be used to estimate the
    lower and upper limits (lower limit = PPA0,
    upper limit = PPA0 + PPA1).

    The following options may be useful for these commands.

       1) Instead of generating the ppcc plot or ks plot on
          the original data, we can generate them on
          selected percentiles of the data.  For example,
          if we have 1,000 points, we can choose to generate
          the plots on 100 evenly spaced percentiles with
          the command

             SET PPCC PLOT DATA POINTS 100

          This can be used to speed up the generation of 
          the plot for larger data sets.

          The percent point function for the reflected power
          distribution is available in closed form, so
          this option is typically not needed.

       2) For the ks plot, we can fix the location and scale.
          This is equivalent to assuming that the lower and
          upper limits are known (e.g., we could use the
          data minimum and maximum as the lower and upper
          limit values).  Given that the lower and upper
          limits are LOWLIM and UPPLIM, enter the commands

             LET KSLOC   = LOWLIM
             LET KSSCALE = UPPLIM

          The ppcc plot is invariant to location and scale,
          so we cannot fix the lower and upper limits.

    The BOOTSTRAP DISTRIBUTION command can be used to find
    uncertainty intervals for the ppcc plot, ks plot, and
    maximum likelihood estimates.
       
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RPOCDF  = Compute the reflected power cumulative distribution
              function.
    RPOPPF  = Compute the reflected power percent point function.
    RPOHAZ  = Compute the reflected power hazard function.
    RPOCHAZ = Compute the reflected power cumulative hazard
    POWPDF  = Compute the power probability density function.
    BETPDF  = Compute the beta probability density function.
    TOPPDF  = Compute the Topp and Leone probability density
              function.
    RGTPDF  = Compute the generalized reflected Topp and Leone
              probability density function.
    GTLPDF  = Compute the generalized Topp and Leone probability
              density function.
    TSPPDF  = Compute the two-sided power probability density
              function.
    TRIPDF  = Compute the triangular probability density function.
    TRAPDF  = Compute the trapezoid probability density function.
    UNIPDF  = Compute the uniform probability density function.
    JSBPDF  = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond Beta:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, pp. 199-201.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/12
 
Program 1:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR
    .
    LET C  = 0.5
    TITLE C = ^c
    PLOT RPOPDF(X,C) FOR X = 0  0.01  0.99
    .
    LET C  = 1
    TITLE C = ^c
    PLOT RPOPDF(X,C) FOR X = 0  0.01  1
    .
    LET C  = 1.5
    TITLE C = ^c
    PLOT RPOPDF(X,C) FOR X = 0  0.01  1
    .
    LET C  = 2
    TITLE C = ^c
    PLOT RPOPDF(X,C) FOR X = 0  0.01  1
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Reflected Power Probability Density Functions
 
Program 2:
    let c = 2.2
    let y = reflected power rand numb for i = 1 1 200
    let csav = c
    .
    let c1 = 0.5
    let c2 = 4
    reflected power ppcc plot y
    just center
    move 50 5
    let c = shape
    text maxppcc = ^maxppcc, C = ^c
    move 50 2
    text Csav = ^csav
    .
    char x
    line blank
    reflected power prob plot y
    move 50 5
    text PPA0 = ^ppa0, PPA1 = ^ppa1
    move 50 2
    let upplim = ppa0 + ppa1
    text Lower Limit = ^ppa0, Upper Limit = ^upplim
    char blank
    line solid
    .
    class lower 0
    class upper 1
    class width 0.05
    relative hist y
    line color blue
    limits freeze
    pre-erase off
    let a = ppa0
    let b = a + (ppa1 - ppa0)
    plot rpopdf(x,c,a,b) for x = a 0.01 b
    limits
    pre-erase on
    line color black all
    .
    let ksloc = ppa0
    let ksscale = upplim
    reflected power kolm smir goodness of fit y

-----RPOPPF (LET)--------------------------------
 
RPOPPF
 
Name:
    RPOPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the reflected power percent point function
    with shape parameter c.
 
Description:
    The standard reflected power distribution has the
    following percent point function:

       G(p;c) = 1 - (1-p)**(1/c)
                0 <= p <= 1, c > 0
 
    with c denoting the shape parameter.

    This distribution can be extended with lower and upper
    bound parameters.  If a and b denote the lower and upper
    bounds, respectively, then the location and scale 
    parameters are:

        location = a
        scale    = b - a

    The general form of the distribution can then be found
    by using the relation

        G(p;c,a,b) = a + (b-a)*G(p;c,0,1)

    The reflected power distribution is a special case of the
    beta distribution where the first shape parameter = 1
    (the power distribution is a special case of beta
    distribution where the second shape parameter = 1).

Syntax:
    LET <y> = RPOPPF(<p>,<c>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, parameter, or variable containing
              values in the interval (0,1);
          <y> is a variable or a parameter (depending on what
              <p> is) where the computed reflected power ppf value
              is stored;
          <c> is a positive number, parameter, or variable that
              specifies the shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = RPOPPF(0.95,0.2)
    LET Y = RPOPPF(X,0.5,0,5)
    PLOT RPOPPF(X,2.3) FOR X = 0  0.01  1
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RPOPDF  = Compute the reflected power probability density
              function.
    RPOCDF  = Compute the reflected power cumulative distribution
              function.
    RPOHAZ  = Compute the reflected power hazard function.
    RPOCHAZ = Compute the reflected power cumulative hazard
              function.
    POWPDF  = Compute the power probability density function.
    BETPDF  = Compute the beta probability density function.
    TOPPDF  = Compute the Topp and Leone probability density
              function.
    RGTPDF  = Compute the generalized reflected Topp and Leone
              probability density function.
    GTLPDF  = Compute the generalized Topp and Leone probability
              density function.
    TSPPDF  = Compute the two-sided power probability density
              function.
    TRIPDF  = Compute the triangular probability density function.
    TRAPDF  = Compute the trapezoid probability density function.
    UNIPDF  = Compute the uniform probability density function.
    JSBPDF  = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond Beta:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, pp. 199-201.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/12
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR
    .
    LET C  = 0.5
    TITLE C = ^c
    PLOT RPOPPF(P,C) FOR P = 0.01  0.01  1
    .
    LET C  = 1
    TITLE C = ^c
    PLOT RPOPPF(P,C) FOR P = 0  0.01  1
    .
    LET C  = 1.5
    TITLE C = ^c
    PLOT RPOPPF(P,C) FOR P = 0  0.01  1
    .
    LET C  = 2
    TITLE C = ^c
    PLOT RPOPPF(P,C) FOR P = 0  0.01  1
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Reflected Power Percent Point Functions
 
-----RSCRIPT-------------------------------------------------------
 
RSCRIPT
 
Name:
    RSCRIPT
 
Type:
    Support Command
 
Purpose:
    Run an R script within a Dataplot session.
 
Description:
    It may on occassion be useful to run an R script within a Dataplot
    session.  Note that Dataplot assumes that R is already installed on
    your local system.  Also, any R packages that your script needs should
    already be installed.  Dataplot does not initiate an install of R if
    it not already installed.

    If R is not installed on your default path, you can specify it
    using the SET R PATH command.  For example, the following can
    be used for version 3.6.1 under Windows

       set r path "c:\program files\r\r-3.6.1\bin\"

    On Linux systems, R is typically installed in "/usr/bin" which is in
    the default path on most systems.  So for Linux systems, the
    SET R PATH command is typically not required.  However, if R is not
    in the default path, you can use the SET R PATH command.

    On Windows platforms, the RSCRIPT command is equivalent to entering

        set system persist off
        set system hidden on
        system <r-path>\rscript.exe <r-script-file>  <arg-list>

    Note that if either the R path or the <r-script-file> contains
    spaces (and so will be quoted), then "set system hidden" will be
    set to "off".

    On Linux platforms, the RSCRIPT command is equivalent to entering

        system <r-path>/Rscript  <r-script-file>  <arg-list>

    Rscript is a binary front end to R for scripting with R.

Syntax:
    RSCRIPT <script-file> <arg-list>
    where <script-file> contains the name of a file containing an
              R script;
    and where <arg-list> is an optional list of arguments to the script.
 
Examples:
    RSCRIPT  plot.R
 
Note:
    This command is host dependent.  It has been tested on Windows
    and Linux systems.  Note that the SYSTEM command must be activated
    for this command to work.

Note:
    Dataplot does no error checking on the specified script file.  It
    is passed as is to the Rscript (RSCRIPT.EXE) command.
 
Note:
    The CAPTURE SCRIPT command can be used to generate the R script
    within a Dataplot macro.  This is demonstrated in the Program
    example below.

Note:
    The name of the script file is case sensitive on Linux and MacOS
    systems.  It is not case sensitive on Windows systems.

    If Dataplot does not find the R script file, it will search for
    it in the "scripts" sub-directory in the Dataplot auxiliary
    directory.  Currently (2019/12), there are no R scripts in that
    directory, although this may change in future releases of Dataplot.

Note:
    Dataplot does not support R as a synonym for RSCRIPT.  This is
    due to the fact that R has long been used as a synonym for the
    REPEAT command.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SYSTEM          = Issue an operating system command within Dataplot.
    PYTHON          = Run a Python script within Dataplot.
    CAPTURE SCRIPT  = Create a script file within Dataplot.
    PSVIEW          = View Postscript, PDF and image files.
    LIST            = View the contents of a file.
 
Applications:
    Run R scripts
 
Implementation Date:
    2019/12
 
Program:
    . Step 1: Create the R script using "capture script"
    .
    rm rout.txt  rout.pdf  r_test.r
    .
    capture script r_test.r
    # This is R program file     r_test.r     11/4/19
    # Purpose: Generate a sequence, square it, and plot it
    # Date: 11/4/19
    #
    # -----start point-----
    #
    x=seq(1,20,length.out=20)
    y=x^2
    both=c(x,y)
    
    sink("rout.txt")
       both
    sink()
    
    pdf("rout.pdf")
    plot(x,y)
    dev.off()
    end of capture
    .
    list r_test.r
    .
    . Step 2:   Determine if running on Windows or Linux and set R path
    .
    let computer = 1
    probe iopsy1
    if probeval = 1
       let computer = 2
    end of if
    .
    .           May need to tweak path for R based on version and
    .           optionally set desired Postscript viewer
    .
    if computer = 1
       set r path "c:\program files\r\r-3.6.1\bin\"
    end of if
    .
    . Step 3:   Run the R script
    .
    rscript  r_test.r
    .
    . Step 4:   Display the outputs in Dataplot
    .
    list rout.txt
    .
    psview rout.pdf

-----RUKHIN 1 TEST (LET)--------------------------
 
RUKHIN 1 TEST
 
Name:
    RUKHIN 1 TEST (LET)
 
Type:
    Let Subcommand
 
Purpose:
    For three binomial proportions, compute the p-value and lower and
    upper confidence limits for

        H0: p1 = p2*p3

    where p1, p2, and p3 are the four binomial proportions.

Description:
    For each of the binomial proportions, we actually use the
    correction terms

        p(i) = (x(i) + 0.5)/(n(i) + 1)

    with p(i), x(i), and n(i) denoting the binomial proportion,
    the number of successes and the number of trials for the i-th
    binomial proportion.

    The computed test statistic is 

        p1 - p2*p3

    and the associated standard error is

        SE = SQRT(term1 + term2 + term3)

    where

        term1 = p1*(1 - p1)/n1
        term2 = (p3**2)*p2*(1 - p2)/n2
        term3 = (p2**2)*p3*(1 - p3)/n3

    The p-value for a lower tailed test is

        1 - NORCDF((p2*p3 - p1)/SE)

    The p-value for an upper tailed test is

        1 - NORCDF((p1 - p2*p3)/SE)

    The p-value for a two tailed test is

        2*(1 - NORCDF((p1 - p2*p3)/SE)

    The confidence interval is

        (p1 - p2*p3) +/- NORPPF(ALPHA/2)*SE

    Although this is a fairly specialized test, it does have
    applicability in the following test scenario.  Suppose we are
    testing scanning devices to see if they can detect certain
    radionuclides.  Further suppose that in one case we have a "primary"
    screening device and then a "secondary" screening device.  For
    example, the "primary" device may be an alarm which then sends the
    object to a more accurate (but more costly or more time consuming)
    device to perform an id.  In this case, the binomial success for the
    primary device is that it alarms when the radionuclide is present and
    the binomial success for the secondary device is that it returns the
    correct id.  The RUKHIN 1 test could then be used to compare the
    performance of the primary/secondary device relative to using the
    secondary device only.  In this testing scenario, it is common for
    the primary device to be "moving" while the secondary device is
    typically "stationary".  So the more accurate device may not
    perform as well when it is used as a primary device relative to
    its use as a secondary device.

Syntax 1:
    LET <pval> <lowlim> <upplim> = RUKHIN 1 TEST
               <p1> <n1> <p2> <n2> <p3> <n3> <alpha>
               <SUBSET/EXCEPT/FOR qualification>
    where <p1> is constant, parameter, or variable that contains the
              proportion of successes for the first sample;
          <n1> is constant, parameter, or variable that contains the
              number of trials for the first sample;
          <p2> is constant, parameter, or variable that contains the
              proportion of successes for the second sample;
          <n2> is constant, parameter, or variable that contains the
              number of trials for the second sample;
          <p3> is constant, parameter, or variable that contains the
              proportion of successes for the third sample;
          <n3> is constant, parameter, or variable that contains the
              number of trials for the third sample;
          <alpha> is constant or parameter that contains the significance
              level;
          <pval> contains the returned p-value;
          <lowlim> contains the computed lower confidence limit;
          <upplim> contains the computed upper confidence limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs a two-tailed hypothesis test.

    The <p1>, <n1>, <p2>, <n2>, <p3>, and <n3> arguments can be either
    parameters or variables.  If they are variables, then the variables
    must have the same number of elements.  The <alpha> argument is
    always assumed to be either a constant or a parameter.

    If the arguments are all parameters, then <pval>, <lowlim> and
    <upplim> will be parameters.  Otherwise, they will be variables.

Syntax 2:
    LET <pval> <lowlim> <upplim> = RUKHIN 1 LOWER TAIL TEST
               <p1> <n1> <p2> <n2> <p3> <n3> <alpha>
               <SUBSET/EXCEPT/FOR qualification>
    where <p1> is constant, parameter, or variable that contains the
              proportion of successes for the first sample;
          <n1> is constant, parameter, or variable that contains the
              number of trials for the first sample;
          <p2> is constant, parameter, or variable that contains the
              proportion of successes for the second sample;
          <n2> is constant, parameter, or variable that contains the
              number of trials for the second sample;
          <p3> is constant, parameter, or variable that contains the
              proportion of successes for the third sample;
          <n3> is constant, parameter, or variable that contains the
              number of trials for the third sample;
          <alpha> is constant or parameter that contains the significance
              level;
          <pval> contains the returned p-value;
          <lowlim> contains the computed lower confidence limit;
          <upplim> contains the computed upper confidence limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs a lower-tailed hypothesis test.  However,
    the confidence limits correspond to the two-tailed test.

    The <p1>, <n1>, <p2>, <n2>, <p3>, and <n3> arguments can be either
    parameters or variables.  If they are variables, then the variables
    must have the same number of elements.  The <alpha> argument is
    always assumed to be either a constant or a parameter.

    If the arguments are all parameters, then <pval>, <lowlim> and
    <upplim> will be parameters.  Otherwise, they will be variables.

Syntax 3:
    LET <pval> <lowlim> <upplim> = RUKHIN 1 UPPER TAIL TEST
               <p1> <n1> <p2> <n2> <p3> <n3> <alpha>
               <SUBSET/EXCEPT/FOR qualification>
    where <p1> is constant, parameter, or variable that contains the
              proportion of successes for the first sample;
          <n1> is constant, parameter, or variable that contains the
              number of trials for the first sample;
          <p2> is constant, parameter, or variable that contains the
              proportion of successes for the second sample;
          <n2> is constant, parameter, or variable that contains the
              number of trials for the second sample;
          <p3> is constant, parameter, or variable that contains the
              proportion of successes for the third sample;
          <n3> is constant, parameter, or variable that contains the
              number of trials for the third sample;
          <alpha> is constant or parameter that contains the significance
              level;
          <pval> contains the returned p-value;
          <lowlim> contains the computed lower confidence limit;
          <upplim> contains the computed upper confidence limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs an upper-tailed hypothesis test.  However,
    the confidence limits correspond to the two-tailed test.

    The <p1>, <n1>, <p2>, <n2>, <p3>, and <n3> arguments can be either
    parameters or variables.  If they are variables, then the variables
    must have the same number of elements.  The <alpha> argument is
    always assumed to be either a constant or a parameter.

    If the arguments are all parameters, then <pval>, <lowlim> and
    <upplim> will be parameters.  Otherwise, they will be variables.

Examples:
    LET PVAL AL AU = RUKHIN 1 TEST P1 N1 P2 N2 P3 N3 ALPHA
    LET PVAL AL AU = RUKHIN 1 LOWER TAILED TEST P1 N1 P2 N2 P3 N3 ALPHA
    LET PVAL AL AU = RUKHIN 1 UPPER TAILED TEST P1 N1 P2 N2 P3 N3 ALPHA

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RUKHIN 3 TEST                   = Test binomial proportions
                                      p1*p2 = p3*p4.
    RUKHIN 2 TEST                   = Test binomial proportions
                                      p1 = 0.5*p2.
    BINOMIAL RATIO CONF LIMITS      = Compute confidence limits for
                                      the ratio of two binomial
                                      proportions.
    BINOMIAL PRODUCT CONF LIMITS    = Compute confidence limits for
                                      the product of two binomial
                                      proportions.
    AGRESTI-COULL CONF LIMITS       = Compute the Agresti-Coull confidence
                                      limits for binomial proportions.
    EXACT BINOMIAL CONF LIMITS      = Compute the exact binomial confidence
                                      limits for binomial proportions.
    DIFFERENCE OF PROP CONF LIMITS  = Compute the confidence limtis for
                                      the difference of two binomial
                                      proportions.
    BINOMIAL PROPORTION             = Compute the binomial proportion
                                      statistic.
    AGRESTI-COULL                   = Compute Agresti-Coull confidence
                                      limits statistic for binomial
                                      proportions.
    BINOMIAL PROPORTION TEST        = Perform a binomial proportions test.
    CROSS TABULATE (LET)            = Perform a cross tabulation for a
                                      specified statistic.
 
Reference:
    Private communication with Andrew Rukhin and Bill Strawderman.

Applications:
    Statistics
 
Implementation Date:
    2008/09
 
Program:
    LET P1 = 0.8
    LET N2 = 40
    LET P2 = 0.95
    LET N2 = 40
    LET P3 = 0.6
    LET N3 = 40
    LET ALPHA = 0.90
    .
    LET PVAL AL AU = RUKHIN 1 TEST P1 N1 P2 N2 P3 N3 ALPHA

-----RUKHIN 2 TEST (LET)--------------------------
 
RUKHIN 2 TEST
 
Name:
    RUKHIN 2 TEST (LET)
 
Type:
    Let Subcommand
 
Purpose:
    For two binomial proportions, compute the p-value and lower and
    upper confidence limits for

        H0: p1 = 0.5*p2

    where p1 and p2 are the two binomial proportions.

Description:
    For each of the binomial proportions, we actually use the
    correction terms

        p(i) = (x(i) + 0.5)/(n(i) + 1)

    with p(i), x(i), and n(i) denoting the binomial proportion,
    the number of successes and the number of trials for the i-th
    binomial proportion.

    The computed test statistic is 

        p1 - 0.5*p2

    and the associated standard error is

        SE = SQRT(term1 + term2)

    where

        term1 = p1*(1 - p1)/n1
        term2 = p2*(1 - p2)/(4*n2)

    The p-value for a lower tailed test is

        1 - NORCDF((0.5*p2 - p1)/SE)

    The p-value for an upper tailed test is

        1 - NORCDF((p1 - 0.5*p2)/SE)

    The p-value for a two tailed test is

        2*(1 - NORCDF((p1 - 0.5*p2)/SE)

    The confidence interval is

        (p1 - 0.5*p2) +/- NORPPF(ALPHA/2)*SE

Syntax 1:
    LET <pval> <lowlim> <upplim> = RUKHIN 2 TEST
               <p1> <n1> <p2> <n2> <alpha>
               <SUBSET/EXCEPT/FOR qualification>
    where <p1> is constant, parameter, or variable that contains the
              proportion of successes for the first sample;
          <n1> is constant, parameter, or variable that contains the
              number of trials for the first sample;
          <p2> is constant, parameter, or variable that contains the
              proportion of successes for the second sample;
          <n2> is constant, parameter, or variable that contains the
              number of trials for the second sample;
          <alpha> is constant or parameter that contains the significance
              level;
          <pval> contains the returned p-value;
          <lowlim> contains the computed lower confidence limit;
          <upplim> contains the computed upper confidence limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs a two-tailed hypothesis test.

    The <p1>, <n1>, <p2>, and <n2> arguments can be either parameters
    or variables.  If they are variables, then the variables must have
    the same number of elements.  The <alpha> argument is always assumed
    to be either a constant or a parameter.

    If the arguments are all parameters, then <pval>, <lowlim> and
    <upplim> will be parameters.  Otherwise, they will be variables.

Syntax 2:
    LET <pval> <lowlim> <upplim> = RUKHIN 2 LOWER TAIL TEST
               <p1> <n1> <p2> <n2> <alpha>
               <SUBSET/EXCEPT/FOR qualification>
    where <p1> is constant, parameter, or variable that contains the
              proportion of successes for the first sample;
          <n1> is constant, parameter, or variable that contains the
              number of trials for the first sample;
          <p2> is constant, parameter, or variable that contains the
              proportion of successes for the second sample;
          <n2> is constant, parameter, or variable that contains the
              number of trials for the second sample;
          <alpha> is constant or parameter that contains the significance
              level;
          <pval> contains the returned p-value;
          <lowlim> contains the computed lower confidence limit;
          <upplim> contains the computed upper confidence limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs a lower-tailed hypothesis test.  However,
    the confidence limits correspond to the two-tailed test.

    The <p1>, <n1>, <p2>, and <n2> arguments can be either parameters
    or variables.  If they are variables, then the variables must have
    the same number of elements.  The <alpha> argument is always assumed
    to be either a constant or a parameter.

    If the arguments are all parameters, then <pval>, <lowlim> and
    <upplim> will be parameters.  Otherwise, they will be variables.

Syntax 3:
    LET <pval> <lowlim> <upplim> = RUKHIN 2 UPPER TAIL TEST
               <p1> <n1> <p2> <n2> <alpha>
               <SUBSET/EXCEPT/FOR qualification>
    where <p1> is constant, parameter, or variable that contains the
              proportion of successes for the first sample;
          <n1> is constant, parameter, or variable that contains the
              number of trials for the first sample;
          <p2> is constant, parameter, or variable that contains the
              proportion of successes for the second sample;
          <n2> is constant, parameter, or variable that contains the
              number of trials for the second sample;
          <alpha> is constant or parameter that contains the significance
              level;
          <pval> contains the returned p-value;
          <lowlim> contains the computed lower confidence limit;
          <upplim> contains the computed upper confidence limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs an upper-tailed hypothesis test.  However,
    the confidence limits correspond to the two-tailed test.

    The <p1>, <n1>, <p2>, and <n2> arguments can be either parameters
    or variables.  If they are variables, then the variables must have
    the same number of elements.  The <alpha> argument is always assumed
    to be either a constant or a parameter.

    If the arguments are all parameters, then <pval>, <lowlim> and
    <upplim> will be parameters.  Otherwise, they will be variables.

Examples:
    LET PVAL AL AU = RUKHIN 2 TEST P1 N1 P2 N2 ALPHA
    LET PVAL AL AU = RUKHIN 2 LOWER TAILED TEST P1 N1 P2 N2 ALPHA
    LET PVAL AL AU = RUKHIN 2 UPPER TAILED TEST P1 N1 P2 N2 ALPHA

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RUKHIN 1 TEST                   = Test binomial proportions
                                      p1 = p2*p3.
    RUKHIN 3 TEST                   = Test binomial proportions
                                      p1*p2 = p3*p4.
    BINOMIAL RATIO CONF LIMITS      = Compute confidence limits for
                                      the ratio of two binomial
                                      proportions.
    BINOMIAL PRODUCT CONF LIMITS    = Compute confidence limits for
                                      the product of two binomial
                                      proportions.
    AGRESTI-COULL CONF LIMITS       = Compute the Agresti-Coull confidence
                                      limits for binomial proportions.
    EXACT BINOMIAL CONF LIMITS      = Compute the exact binomial confidence
                                      limits for binomial proportions.
    DIFFERENCE OF PROP CONF LIMITS  = Compute the confidence limtis for
                                      the difference of two binomial
                                      proportions.
    BINOMIAL PROPORTION             = Compute the binomial proportion
                                      statistic.
    AGRESTI-COULL                   = Compute Agresti-Coull confidence
                                      limits statistic for binomial
                                      proportions.
    BINOMIAL PROPORTION TEST        = Perform a binomial proportions test.
    CROSS TABULATE (LET)            = Perform a cross tabulation for a
                                      specified statistic.
 
Reference:
    Private communication with Andrew Rukhin and Bill Strawderman.

Applications:
    Statistics
 
Implementation Date:
    2008/09
 
Program:
    LET P1 = 0.9
    LET N2 = 40
    LET P2 = 0.6
    LET N2 = 40
    LET ALPHA = 0.90
    .
    LET PVAL AL AU = RUKHIN 2 TEST P1 N1 P2 N2 ALPHA

-----RUKHIN 3 TEST (LET)--------------------------
 
RUKHIN 3 TEST
 
Name:
    RUKHIN 3 TEST (LET)
 
Type:
    Let Subcommand
 
Purpose:
    For four binomial proportions, compute the p-value and lower and
    upper confidence limits for

        H0: p1*p2 = p3*p4

    where p1, p2, p3, and p4 are the four binomial proportions.

Description:
    For each of the binomial proportions, we actually use the
    correction terms

        p(i) = (x(i) + 0.5)/(n(i) + 1)

    with p(i), x(i), and n(i) denoting the binomial proportion,
    the number of successes and the number of trials for the i-th
    binomial proportion.

    The computed test statistic is 

        p1*p2 - p3*p4

    and the associated standard error is

        SE = SQRT(term1 + term2 + term3 + term4)

    where

        term1 = (p2**2)*p1*(1 - p1)/n1
        term2 = (p1**2)*p2*(1 - p2)/n2
        term3 = (p4**2)*p3*(1 - p3)/n3
        term4 = (p3**2)*p4*(1 - p4)/n4

    The p-value for a lower tailed test is

        1 - NORCDF((p3*p4 - p1*p2)/SE)

    The p-value for an upper tailed test is

        1 - NORCDF((p1*p2 - p3*p4)/SE)

    The p-value for a two tailed test is

        2*(1 - NORCDF((p3*p4 - p1*p2)/SE)

    The confidence interval is

        (p1*p2 - p3*p4) +/- NORPPF(ALPHA/2)*SE

    Although this is a fairly specialized test, it does have
    applicability in the following test scenario.  Suppose we are
    testing scanning devices to see if they can detect certain
    radionuclides.  Further suppose we have a "primary" screening
    device and then a "secondary" screening device.  For example, the
    "primary" device may be an alarm which then sends the object to a
    more accurate (but more costly or more time consuming) device to
    perform an id.  In this case, the binomial success for the primary
    device is that it alarms when the radionuclide is present and the
    binomial success for the secondary device is that it returns the
    correct id.  The RUKHIN 3 test could then be used to compare the
    performance of two different sets of primary/secondary devices.

Syntax 1:
    LET <pval> <lowlim> <upplim> = RUKHIN 3 TEST
               <p1> <n1> <p2> <n2> <p3> <n3> <p4> <n4> <alpha>
               <SUBSET/EXCEPT/FOR qualification>
    where <p1> is constant, parameter, or variable that contains the
              proportion of successes for the first sample;
          <n1> is constant, parameter, or variable that contains the
              number of trials for the first sample;
          <p2> is constant, parameter, or variable that contains the
              proportion of successes for the second sample;
          <n2> is constant, parameter, or variable that contains the
              number of trials for the second sample;
          <p3> is constant, parameter, or variable that contains the
              proportion of successes for the third sample;
          <n3> is constant, parameter, or variable that contains the
              number of trials for the third sample;
          <p4> is constant, parameter, or variable that contains the
              proportion of successes for the fourth sample;
          <n4> is constant, parameter, or variable that contains the
              number of trials for the fourth sample;
          <alpha> is constant or parameter that contains the significance
              level;
          <pval> contains the returned p-value;
          <lowlim> contains the computed lower confidence limit;
          <upplim> contains the computed upper confidence limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs a two-tailed hypothesis test.

    The <p1>, <n1>, <p2>, <n2>, <p3>, <n3>, <p4> and <n4> arguments
    can be either parameters or variables.  If they are variables, then
    the variables must have the same number of elements.  The <alpha>
    argument is always assumed to be either a constant or a parameter.

    If the arguments are all parameters, then <pval>, <lowlim> and
    <upplim> will be parameters.  Otherwise, they will be variables.

Syntax 2:
    LET <pval> <lowlim> <upplim> = RUKHIN 3 LOWER TAIL TEST
               <p1> <n1> <p2> <n2> <p3> <n3> <p4> <n4> <alpha>
               <SUBSET/EXCEPT/FOR qualification>
    where <p1> is constant, parameter, or variable that contains the
              proportion of successes for the first sample;
          <n1> is constant, parameter, or variable that contains the
              number of trials for the first sample;
          <p2> is constant, parameter, or variable that contains the
              proportion of successes for the second sample;
          <n2> is constant, parameter, or variable that contains the
              number of trials for the second sample;
          <p3> is constant, parameter, or variable that contains the
              proportion of successes for the third sample;
          <n3> is constant, parameter, or variable that contains the
              number of trials for the third sample;
          <p4> is constant, parameter, or variable that contains the
              proportion of successes for the fourth sample;
          <n4> is constant, parameter, or variable that contains the
              number of trials for the fourth sample;
          <alpha> is constant or parameter that contains the significance
              level;
          <pval> contains the returned p-value;
          <lowlim> contains the computed lower confidence limit;
          <upplim> contains the computed upper confidence limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs a lower-tailed hypothesis test.  However,
    the confidence limits correspond to the two-tailed test.

    The <p1>, <n1>, <p2>, <n2>, <p3>, <n3>, <p4> and <n4> arguments
    can be either parameters or variables.  If they are variables, then
    the variables must have the same number of elements.  The <alpha>
    argument is always assumed to be either a constant or a parameter.

    If the arguments are all parameters, then <pval>, <lowlim> and
    <upplim> will be parameters.  Otherwise, they will be variables.

Syntax 3:
    LET <pval> <lowlim> <upplim> = RUKHIN 3 UPPER TAIL TEST
               <p1> <n1> <p2> <n2> <p3> <n3> <p4> <n4> <alpha>
               <SUBSET/EXCEPT/FOR qualification>
    where <p1> is constant, parameter, or variable that contains the
              proportion of successes for the first sample;
          <n1> is constant, parameter, or variable that contains the
              number of trials for the first sample;
          <p2> is constant, parameter, or variable that contains the
              proportion of successes for the second sample;
          <n2> is constant, parameter, or variable that contains the
              number of trials for the second sample;
          <p3> is constant, parameter, or variable that contains the
              proportion of successes for the third sample;
          <n3> is constant, parameter, or variable that contains the
              number of trials for the third sample;
          <p4> is constant, parameter, or variable that contains the
              proportion of successes for the fourth sample;
          <n4> is constant, parameter, or variable that contains the
              number of trials for the fourth sample;
          <alpha> is constant or parameter that contains the significance
              level;
          <pval> contains the returned p-value;
          <lowlim> contains the computed lower confidence limit;
          <upplim> contains the computed upper confidence limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs an upper-tailed hypothesis test.  However,
    the confidence limits correspond to the two-tailed test.

    The <p1>, <n1>, <p2>, <n2>, <p3>, <n3>, <p4> and <n4> arguments
    can be either parameters or variables.  If they are variables, then
    the variables must have the same number of elements.  The <alpha>
    argument is always assumed to be either a constant or a parameter.

    If the arguments are all parameters, then <pval>, <lowlim> and
    <upplim> will be parameters.  Otherwise, they will be variables.

Examples:
    LET PVAL AL AU = RUKHIN 3 TEST P1 N1 P2 N2 P3 N3 P4 N4 ALPHA
    LET PVAL AL AU = RUKHIN 3 LOWER TAILED TEST ...
                     P1 N1 P2 N2 P3 N3 P4 N4 ALPHA
    LET PVAL AL AU = RUKHIN 3 UPPER TAILED TEST ...
                     P1 N1 P2 N2 P3 N3 P4 N4 ALPHA

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RUKHIN 1 TEST                   = Test binomial proportions
                                      p1 = p2*p3.
    RUKHIN 2 TEST                   = Test binomial proportions
                                      p1 = 0.5*p2.
    BINOMIAL RATIO CONF LIMITS      = Compute confidence limits for
                                      the ratio of two binomial
                                      proportions.
    BINOMIAL PRODUCT CONF LIMITS    = Compute confidence limits for
                                      the product of two binomial
                                      proportions.
    AGRESTI-COULL CONF LIMITS       = Compute the Agresti-Coull confidence
                                      limits for binomial proportions.
    EXACT BINOMIAL CONF LIMITS      = Compute the exact binomial confidence
                                      limits for binomial proportions.
    DIFFERENCE OF PROP CONF LIMITS  = Compute the confidence limtis for
                                      the difference of two binomial
                                      proportions.
    BINOMIAL PROPORTION             = Compute the binomial proportion
                                      statistic.
    AGRESTI-COULL                   = Compute Agresti-Coull confidence
                                      limits statistic for binomial
                                      proportions.
    BINOMIAL PROPORTION TEST        = Perform a binomial proportions test.
    CROSS TABULATE (LET)            = Perform a cross tabulation for a
                                      specified statistic.
 
Reference:
    Private communication with Andrew Rukhin and Bill Strawderman.

Applications:
    Statistics
 
Implementation Date:
    2010/06
 
Program:
    LET P1 = 0.95
    LET N1 = 40
    LET P2 = 0.8
    LET N2 = 40
    LET P3 = 0.95
    LET N3 = 40
    LET P4 = 0.6
    LET N4 = 40
    LET ALPHA = 0.90
    .
    LET PVAL AL AU = RUKHIN 3 TEST P1 N1 P2 N2 P3 N3 P4 N4 ALPHA

-----RUNGE KUTTA (LET)-------------------------------------------------
 
RUNGE KUTTA
 
Name:
    RUNGE KUTTA (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Solve first and second order initial value ordinary differential
    equations via Runge Kutta methods.
 
Description:
    Differential equations are those which involve a relation between
    derivatives.  For example, the equation
       y = x**2
    can be expressed as the differential equation
       dy/dx = 2x
    In this case, instead of giving a value of y for each value of x,
    the differential equation gives the slope at each value of x.
 
    The following should be noted:
    1) The term ordinary refers to the fact that only ordinary
       derivatives are involved (that is, no partial derivatives).
       DATAPLOT does not currently support any methods for solving
       partial differential equations.
    2) The dependent variable is the variable being differentiated and
       the independent variable is the variable with respect to which
       the differentiations are taken.  In the example dy/dx = 2x, x is
       the independent variable and y is the dependent variable.
    3) The order is the order of the highest derivative.  Currently,
       the RUNGE KUTTA command is limited to first and second order
       differential equations.  First order differential equations are
       often expressed as:
           dy/dx = F(x,y)
       while second order differential equations are often expressed as:
           d**2y/dx = G(x, y, dy/dx)
       Higher order differential equations can be expressed in a similar
       manner.
    4) The degree is the power to which the highest order derivative is
       raised.  The RUNGE KUTTA command only deals with first degree
       differential equations.
    5) An analytic solution is an equation of the form
           y = F(x)
       which results in the original differential equation when it is
       differentiated.  Although the RUNGE KUTTA command does not
       provide an analytic solution (that is, the function F), it can
       generate the y value for any corresponding x value.  The RUNGE
       KUTTA command returns y values (and dy/dx values for the second
       order case) for a given set of X values.
    6) Differential equations are complicated by the fact that there is
       an infinite number of solutions (this is due to the fact that the
       derivative of any constant is zero).  However, if the solution is
       required to pass through a specific point (x0,y0), then the
       solution is unique.  This point is referred to as an initial
       value.  Boundary value problems are those in which more than
       one initial point is specified.  The RUNGE KUTTA command can
       solve initial value problems, but it does not solve boundary
       value problems.  DATAPLOT does not currently provide any methods
       for solving boundary value problems.
 
Syntax 1: (for first order differential equations)
    LET <y> = RUNGE KUTTA <f> <x1> <SUBSET/EXCEPT/FOR qualification>
    where <f> is a function or functional expression that defines the
              differential equation (this function often contains <y>);
          <x1> is a variable that defines the desired grid of X values;
          <y> is a variable where the computed solution to the
              differential equation is saved (the first element of this
              variable must be previously defined);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
              rarely used in this context.
 
    The initial value (x0, y0) is specified by the first elements of
    <x1> and <y> respectively.  These points must be specified before
    entering the RUNGE KUTTA command.  The solution is the set of
    points <y> and <x1>.
 
Syntax 2: (for second order differential equations)
    LET <y> <yd> = RUNGE KUTTA  <f> <x1>
                   <SUBSET/EXCEPT/FOR qualification>
    where <f> is a function or functional expression that defines the
              differential equation (this function often contains <y>
              and <yd>);
          <x1> is a variable that defines the desired grid of X values;
          <y> is the variable where the computed values for the
              dependent variable are saved (the first element of this
              variable must be previously defined);
          <yd> is the variable where the computed values for the dy/dx
              term are saved (the first element of this variable must
              be previously defined);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
              rarely used in this context.
 
    The initial value (x0, y0, yd0) is specified by the first elements
    of <x1>, <y>, and <yd> respectively.  These points must be
    specified before entering the RUNGE KUTTA command.  The solution is
    the set of points <y>, <yd>, and <x1>.
 
Examples:
    LET Y = RUNGE KUTTA 2*X  X1
    LET Y = RUNGE KUTTA F  X1
    LET Y YD = RUNGE KUTTA F  X1
 
Note:
    DATAPLOT uses a fourth order Runge-Kutta algorithm.  This algorithm
    is documented in the Numerical Recipes book.  It is also covered in
    most numerical analysis textbooks.  Runge-Kutta methods have the
    advantage of almost always succeeding, but they do not always
    have as high an accuracy or the computational efficiency as more
    sophisticated methods such as Bulirsch-Stoer or predictor-corrector
    methods.
 
    Runge-Kutta methods are not appropriate for stiff differential
    equations.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    DERIVATIVE     = Compute the derivative of a function.
    INTEGRAL       = Compute the integral of a function.
    ROOTS          = Compute the roots of a function.
    INTERPOLATE    = Interpolate a function.
 
Reference:
    "Numerical Recipes: The Art of Scientific Computing (FORTRAN
    Version)", Press, Flannery, Teukolsky, and Vetterling.  Cambridge
    University Press, 1989 (chapter 14).
 
Applications:
    Differential Equations
 
Implementation Date:
    87/10
 
Program 1: (first order example)
    . THIS IS THE DATAPLOT PROGRAM FILE     RAIN.DP
    . PURPOSE--DETERMINE THE EQUATION OF MOTION OF A RAINDROP
    .          WITH SEVERAL DIFFERENT AIR RESISTANCE VALUES.
    . ANALYSIS TECHNIQUE--RUNGE-KUTTA SOLUTION TO DIFFERENTIAL EQUATION.
    . NOTE--Y = SPEED AFTER TIME X
    .       X = TIME (IN SECONDS)
    .       M = MASS
    .       C = AIR RESISTANCE
    . START POINT-----------------------------------
    .      STEP 1--DEFINE THE RIGHT-HAND SIDE FUNCTION OF Y' = F
    .              DEFINE THE DESIRED GRID OF X VALUES
    .              DEFINE INITIAL CONDITION
    .              DEFINE A TABLE OF VALUES FOR C
    LET FUNCTION F = 32-(C/M)*Y**2
    LET X = 0 .1 5
    LET Y(1)=0
    LET M = 1
    LET CTAB = DATA 2 1 .5 .1 .01 0
    .      STEP 2--SOLVE THE DIFFERENTIAL EQUATION FOR EACH VALUE OF C
    LOOP FOR K = 1 1 6
        LET C = CTAB(K)
        LET Y = RUNGE-KUTTA F X
        LET Y^K = Y
    END OF LOOP
    .      STEP 3--PLOT OUT THE 6 TRACES
    Y1LABEL SPEED
    XLABEL TIME (IN SECONDS)
    X2LABEL STARTING SPEED = 0
    X3LABEL AIR RESISTANCE = 2, 1, .5, .1, .01, 0
    PLOT Y1 Y2 Y3 Y4 Y5 Y6 VS X
 
Program 2: (second order example)
    . THIS IS THE DATAPLOT PROGRAM FILE     BEAM.DP
    . PURPOSE--DETERMINE DEFLECTION VS DISTANCE TRACE OF ELASTIC BEAM
    .          ANCHORED AT ONE END AND WITH A LOAD AT THE OTHER END
    .          (CANTILEVER).
    . TECHNIQUE--RUNGE-KUTTA SOLUTION OF 2ND ORDER DIFFERENTIAL EQUATION
    . APPLICATION--STRUCTURAL ENGINEERING
    . SOURCE--DORN, WILLIAM S. AND MCCRACKEN, DANIEL D., NUMERICAL
    .         METHODS WITH FORTRAN IV CASE STUDIES, JOHN WILEY AND SONS
    .         NEW YORK, 1972, PAGES 391-401.
    . TO FIND--DEFLECTION VALUE FOR VARIOUS DISTANCES OUT ONTO THE BEAM
    . NOTE--THE ELASTIC DEFLECTION SATISFIES THE DIFFERENTIAL EQUATION--
    .       Y'' / (1 + (Y')**2 )**(3/2)   =   P*(L-X) / (E*I)
    .       Y'' = P*(L-X) / (E*I)     *    (1 + (Y')**2 )**(3/2)
    .       WITH Y(0) = 0 AND Y'(0) = 0
    .       WHERE
    .          Y = DEFLECTION FROM HORIZONTAL (IN INCHES)
    .          X = DISTANCE OUT ONTO BEAM (X = 0, 2, 4, 6, ..., 100
    .              INCHES)
    .          P = LOAD (IN POUNDS) AT FREE END (HERE = 64)
    .          L = LENGTH (IN INCHES) OF BEAM (HERE = 100)
    .          E = YOUNG'S MODULUS (= 6 * 10**6)
    .          I = MOMENT OF INERTIA OF CROSS SECTION (HERE = 0.128
    .              INCHES**4)
    .
    .      STEP 1--DEFINE THE PHYSICAL PARAMETERS OF THE BEAM
    LET P = 64
    LET L = 100
    LET E = 6*10**6
    LET I = 0.128
    .      STEP 2--DEFINE THE RIGHT-SIDE FUNCTION OF Y''(X) = F
    LET FUNCTION F1 = P*(L-X)/(E*I)
    LET FUNCTION F2 = (1+YP**2)**(3/2)
    LET FUNCTION F = F1*F2
    .      STEP 3--DEFINE INITIAL CONDITIONS AND THE DESIRED SEQUENCE
    .              OF POINTS AT WHICH TO COMPUTE THE SOLUTION CURVE.
    LET Y(1) = 0
    LET YP(1) = 0
    LET X = SEQUENCE 0 2 100
    .      STEP 4--SOLVE THE DIFFERENTIAL EQUATION
    LET Y YP = RUNGE-KUTTA F X
    MULTIPLOT 2 1; MULTIPLOT CORNER COORDINATES 0 0 100 100
    PLOT Y X
    PRINT X Y YP
    .      STEP 5--PLOT OUT THE SOLUTION CURVE
    LET YBE = (P/(6*E*I))*(X**2)*(3*L-X)
    TITLE PLOT THE SOLUTION CURVE
    LINES SOLID DOTTED
    PLOT Y YBE VS X
    END OF MULTIPLOT
 
-----RUNS---------------------------------------------------
 
RUNS
 
Name:
    RUNS
 
Type:
    Analysis Command
 
Purpose:
    Perform a runs test.
 
Description:
    This test is designed to test the hypothesis that a sample has been
    drawn at random.  The data is split into 2 mutually exclusive
    groups.  A run is a series of values that fall into the same group.
    The number of runs of a given length are computed and compared to
    the expected number from a random sample.
 
Syntax:
    RUNS <x1>            <SUBSET/EXCEPT/FOR qualification>
    where <x1> is the variable for which the runs test is to be
              performed;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    RUNS Y1
    RUNS Y1  SUBSET TAG > 0
 
Note:
    A runs test divides the data into 2 mutually exclusive sets.  For
    quantitative data, this usually means data are split into groups
    above the mean and below the mean.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PROBABILITY PLOT   = Generates a probability plot.
    LET                = Computes data transformations.
    RUN SEQUENCE PLOT  = Generates a run sequence plot.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET = Y1 NORMAL RANDOM NUMBERS FOR I = 1 1 100
    RUNS Y1
 
-----RUN SEQUENCE PLOT-----------------------------------------------
 
RUN SEQUENCE PLOT
 
Name:
    RUN SEQUENCE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a run sequence plot.
 
Description:
    A run sequence plot is a graphical data analysis technique for
    preliminary scanning of the data.  It consists of:
       Vertical   axis = i-th observation;
       Horizontal axis = dummy index i.
    The runs sequence plot is thus a plot of the raw data plotted in
    the same order that it resides in the variable.  This is a useful
    first step in the analysis of any data (not just time series data)
    in that it provides information about trends, patterns in
    variation, and outliers.  It also gives the analyst an excellent
    "feel" for the data.
 
Syntax:
    RUN SEQUENCE PLOT   <x>   <SUBSET/EXCEPT/FOR qualification>
    where <x> is the variable of raw data values under analysis;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    RUN SEQUENCE PLOT Y
    RUN SEQUENCE PLOT Y2
 
Note:
    Plot points can be plotted as characters, connected lines, spikes,
    or bars.  These are set independently of each other.  The default
    is to plot each trace as a connected line with no symbol, no bar,
    and no spike.  The LINE, CHARACTER, SPIKE, and BAR commands are
    used to set the switches for plotting a given trace as a connected
    line, a character, a spike, or a bar respectively.
 
    There are attribute setting commands for lines, characters, spikes,
    and bars.  See the documentation for LINE, CHARACTER, SPIKE, and
    BAR for a complete list of these commands.  Attributes are set
    giving a list of values.  The first trace uses the first setting,
    the second trace uses the second setting, and so on.  For example,
    CHARACTER SIZE 2.0 3.0 1.5 sets the character size for trace 1 to
    2.0, the character size for trace 2 to 3.0, and the character size
    for trace 3 to 1.5.  Attributes can be set for up to 100 traces.
 
Default:
    None
 
Synonyms:
    PLOT Y is equivalent to RUN SEQUENCE PLOT Y.
 
Related Commands:
    CHARACTERS          = Sets the types for plot characters.
    LINES               = Sets the types for plot lines.
    SPIKES              = Sets the on/off switches for plot spikes.
    BARS                = Sets the on/off switches for plot bars.
    TITLE               = Sets the plot title.
    LABEL               = Sets the plot axis labels.
    LEGEND              = Sets the plot legends.
    MULTIPLOT           = Generate multiple plots per page.
    PLOT                = Generates a data or function plot.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    SKIP 25
    READ BOXJE142.DAT YIELD
    .
    TITLE AUTOMATIC
    Y1LABEL YIELD
    X1LABEL SEQUENCE NUMBER
    XLIMITS 0 70
    XTIC OFFSET 2 2
    PLOT YIELD
 
-------------------------------------------------------------








































































-------------------------  *S*  ZZZZZ--------------------
 
-----S CHART-----------------------------------------------------
 
S CHART
 
Name:
    S CHART
 
Type:
    Graphics Command
 
Purpose:
    Generates a standard deviation control chart.
 
Description:
    A standard deviation control chart is a data analysis analysis
    technique for determining if a measurement process has gone out of
    statistical control.  The S chart is sensitive to changes in
    variation in the measurement process.  It consists of:
       Vertical   axis = the standard deviation for each sub-group.
       Horizontal axis = sub-group designation.
    In addition, horizontal lines are drawn at the mean standard
    deviation value and at the upper and lower control limits.
 
Syntax:
    S CHART   <y>   <x>     <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the response (= dependent) variable (containing the
              raw data values);
          <x> is an independent variable (containing the
              sub-group identifications);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    S CHART Y X
 
Note:
    The distribution of the response variable is assumed to be normal.
    This assumption is the basis for calculating the upper and lower
    control limits.
 
Note:
    The attributes of the 4 traces can be controlled by the standard
    LINES, CHARACTERS, BARS, and SPIKES commands.  Trace 1 is the
    response variable, trace2 is the mean line, and traces 3 and 4 are
    the control limits.  Some analysts prefer to draw the response
    variable as a spike or character rather than a connected line.
 
Note:
    Versions prior to December 1993 have a bug in that the S CHART
    command conflicts with the SAVE command.  Use the SD CHART or the
    SD CONTROL CHART syntax (see SYNONYMS section below) for these
    versions.
 
Default:
    None
 
Synonyms:
    SD CHART for S CHART
    S CONTROL CHART for S CHART
    SD CONTROL CHART for S CHART
 
Related Commands:
    R CHART             = Generates a range control chart.
    X CHART             = Generates a mean control chart.
    P CHART             = Generates a p control chart.
    NP CHART            = Generates a Np control chart.
    U CHART             = Generates a U control chart.
    C CHART             = Generates a C control chart.
    CHARACTERS          = Sets the types for plot characters.
    LINES               = Sets the types for plot lines.
    SPIKES              = Sets the on/off switches for plot spikes.
    BARS                = Sets the on/off switches for plot bars.
    PLOT                = Generates a data or function plot.
    LAG PLOT            = Generates a lag plot.
    4-PLOT              = Generates 4-plot univariate analysis.
    STANDARD DEVI PLOT  = Generates a standard deviation (vs subset)
                          plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    SKIP 25
    READ GEAR.DAT DIAMETER BATCH
    .
    LINE SOLID SOLID DOT DOT
    TITLE AUTOMATIC
    X1LABEL GROUP-ID
    Y1LABEL STANDARD DEVIATION
    SD CHART DIAMETER BATCH
 
-----SAMPLE RANDOM PERMUTATION (LET)-----------------------------------
 
SAMPLE RANDOM PERMUTATION
 
Name:
    SAMPLE RANDOM PERMUTATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate a series of random permutations where possibly
    only a subset of the random permutations will be retained
    and where a specified proportion of the permutation values
    are allowed.
 
Description:
    For a given size N, to generate a random permutation the integers
    from 1 to N are randomly sampled (without replacement) until all
    elements have been selected.  This is implemented with the command

        LET Y = RANDOM PERMUTATION FOR I = 1 1 N

    This SAMPLE RANDOM PERMUTATION command was motivated by the desire to
    simulate the following problem.

    Given a worm that has infected a single computer, simulate
    the following:

        1. The infected machine will propogate to NKEEP IP addresses
           from a master list of NPOP IP addresses.

        2. Of the NPOP addresses, only a proportion, p, denote
           addresses corresponding to an actual machine.  That is,
           there will be p*NPOP valid addresses.

        3. Each newly infected machine will likewise attempt
           to propogate to NKEEP addresses.

    This process will be repated until all IP addresses corresponding
    to valid machines are infected.

    The Program 1 example demonstrates how this simulation can be
    implemented using the SAMPLE RANDOM PERMUTATION command.

Syntax:
    LET <y> <tag> = SAMPLE RANDOM PERMUTATION <npop> <nkeep> <p> <niter>
    where <npop> is a number or parameter that specifies the size of
              the random permutation;
          <nkeep> is a number of parameter that specifies how many
              permutated values are kept at each step;
          <p> is a parameter or number (greater than 0 and less than
              or equal to 1) that specifies the proportion of
              valid permutation values;
          <niter> is a number of parameter (less than or equal to
              <npop>) that specifies how many sets of randon
              permutations are generated;
          <y> is a variable where the permutated values are saved;
          <tag> is a variable that identifies which iteration generated
              the permuted values.
 
Examples:
    LET Y TAG = SAMPLE RANDOM PERMUTATION NPOP NKEEP P NITER
 
Note:
    The SEED command can be used to specify a seed for the random
    number generation.  The SET RANDOM NUMBER GENERATOR command can be
    used to specify which random number generator to use.
 
Note:
    By default, only the unique permutation values in the output variable
    are saved.  If you want all permutation values to be saved, then
    enter the command

       SET SAMPLE RANDOM PERMUTATION DISTINCT OFF

    This is demonstrated in the Program 2 and Program 3 examples below.

Note:
    Although this command was implemented with a specific simulation
    scenario in mind, it does have wider applicability.

    Specifically, it can be used to efficiently implement two sample
    permutation tests.  The Program 2 and Program 3 examples below
    demonstrate a two sample permutation test for the difference between
    the means of two samples.  These examples can be easily adapted to
    test for the difference between other location statistics such as
    the median or the trimmed mean.

    Based on extensive simulation studies, Higgins recommends that
    1,600 random permutations should be sufficient for most purposes.

Note:
    This routine uses a random permutation algorithm suggested by Knuth.
    Specifically, it adapts the RANDPERM routine of Knoble.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET                      = Generate data transformations.
    RANDOM PERMUTATION       = Generate a random permutation.
    SEED                     = Specify the seed for random number
                               generation.
    RANDOM NUMBER GENERATOR  = Specify the random number generator to
                               use.
    RANDOM NUMBER            = Generate random numbers from a specified
                               distribution.
    BOOTSTRAP SAMPLE         = Generate a bootstrap sample.
 
References:
    Knuth (1998), "The Art of Computer Programming: Volume 2 Seminumerical
    Algorithms, Third Edition", Section 3.4.2, Addison-Wesley.

    Knoble RANDPERM algorithm downloaded from:
    "http://coding.derkeiler.com/Archive/Fortran/comp.lang.fortran/
    2006-03/msg00748.html"

    Higgins (2004), "Introduction to Modern Nonparametric Statistics",
    Duxbury Press, Chapter 2.

Applications:
    Simulation, Permutation Tests
 
Implementation Date:
    2017/08
 
Program 1:
    set random number generator fibbonacci congruential
    seed 56791
    .
    let npop  = 64000
    let nkeep = 10
    let p     = 0.25
    let maxiter = 20
    let maxit2  = 19
    let nmax = p*npop
    .
    let y(1) = 1
    let nyv(1) = 1
    let y = 0 for i = 2 1 maxiter
    let iterv = sequence 0 1 maxit2
    .
    loop for k = 1 1 maxiter
        let niter = size y
        let ynew tag = sample random permutation npop nkeep p niter
        let ny = size y
        let nyv(k) = ny
        let y = combine y ynew
        let y = distinct y
        if ny >= nmax
           break loop
        end of if
    end of loop
    .
    set write decimals 0
    print iterv nyv

Program 2:
    set random number generator fibbonacci congruential
    seed 32119
    .
    .           Read the data
    .
    dimension 15 columns
    .
    skip 25
    read auto83b.dat y1 y2
    retain y2 subset y2 >= 0
    let y = comb y1 y2
    let n1 = size y1
    let n2 = size y2
    skip 0
    .
    .           Compute the statistic for the original sample
    .
    let mean1 = mean y1
    let mean2 = mean y2
    let statval = mean1 - mean2
    .
    .           Generate the random permutations
    .
    let npop  = n1 + n2
    let nkeep = npop
    let p     = 1
    let niter = 1600
    let ntot = npop*niter
    let repeat = data n1 n2
    let val = data 1 2
    let tag2 = sequence val repeat for i = 1 1 ntot
    set sample random permutation distinct off
    .
    let yindx tag1 = sample random permutation npop nkeep p niter
    let ynew = gather y yindx
    .
    .           Now compute the statistic for the permutations
    .
    set let cross tabulate collapse
    let ynew2 = ynew
    let tag12 = tag1
    retain ynew2 tag12 subset tag2 = 1
    let ym1 = cross tabulate mean ynew2 tag12
    let ynew2 = ynew
    let tag12 = tag1
    retain ynew2 tag12 subset tag2 = 2
    let ym2 = cross tabulate mean ynew2 tag12
    let ydiff = ym1 - ym2
    .
    .           Now plot the results of the permutation test
    .
    let xq = 0.025
    let low025 = quantile ydiff
    let low025 = round(low025,2)
    let xq = 0.975
    let upp975 = quantile ydiff
    let upp975 = round(upp975,2)
    .
    let xq = 0.025
    let low025 = quantile ydiff
    let low025 = round(low025,2)
    let xq = 0.975
    let upp975 = quantile ydiff
    let upp975 = round(upp975,2)
    .
    title offset 2
    title case asis
    label case asis
    y1label Count
    x1label Difference of Means for Permutations
    let statval = round(statval,2)
    x2label color red
    x2label Difference of Means for Original Sample: ^statval
    x3label color blue
    x3label 2.5 Percentile: ^low025, 97.5 Percentile: ^upp975
    xlimits -15 15
    title Histogram of Difference of Means for ^niter Permutations (AUTO83B.DAT)
    .
    histogram ydiff
    .
    line color red
    line dash
    drawdsds statval 20 statval 90
    line color blue
    line dash
    drawdsds low025 20 low025 90
    drawdsds upp975 20 upp975 90
 
Program 3:
    set random number generator fibbonacci congruential
    seed 32119
    .
    .           Read the data
    .
    dimension 15 columns
    .
    let y1 = norm rand numb for i = 1 1 200
    let y2 = norm rand numb for i = 1 1 80
    let y2 = y2 + 0.1
    let y = comb y1 y2
    let n1 = size y1
    let n2 = size y2
    skip 0
    .
    .           Generate the random permutations
    .
    let mean1 = mean y1
    let mean2 = mean y2
    let statval = mean1 - mean2
    .
    let npop  = n1 + n2
    let nkeep = npop
    let p     = 1
    let niter = 1600
    let ntot = npop*niter
    let repeat = data n1 n2
    let val = data 1 2
    let tag2 = sequence val repeat for i = 1 1 ntot
    set sample random permutation distinct off
    .
    let yindx tag1 = sample random permutation npop nkeep p niter
    let ynew = gather y yindx
    .
    .           Now compute the statistic for the permutations
    .
    set let cross tabulate collapse
    let ynew2 = ynew
    let tag12 = tag1
    retain ynew2 tag12 subset tag2 = 1
    let ym1 = cross tabulate mean ynew2 tag12
    let ynew2 = ynew
    let tag12 = tag1
    retain ynew2 tag12 subset tag2 = 2
    let ym2 = cross tabulate mean ynew2 tag12
    let ydiff = ym1 - ym2
    .
    .           Now plot the results of the permutation test
    .
    let xq = 0.025
    let low025 = quantile ydiff
    let low025 = round(low025,2)
    let xq = 0.975
    let upp975 = quantile ydiff
    let upp975 = round(upp975,2)
    .
    title offset 2
    title case asis
    label case asis
    y1label Count
    x1label Difference of Means for Permutations
    let statval = round(statval,2)
    x2label color red
    x2label Difference of Means for Original Sample: ^statval
    x3label color blue
    x3label 2.5 Percentile: ^low025, 97.5 Percentile: ^upp975
    xlimits -0.5 0.5
    title Histogram of Difference of Means for ^niter Permutations
    .
    histogram ydiff
    .
    line color red
    line dash
    drawdsds statval 20 statval 90
    line color blue
    line dash
    drawdsds low025 20 low025 90
    drawdsds upp975 20 upp975 90
 
-----SAVE-------------------------------------------------------
 
SAVE
 
Name:
    SAVE
 
Type:
    Support Command
 
Purpose:
    Selectively save one of, or a set of, the last 20 DATAPLOT
    commands that had been entered.
 
Description:
    The saved commands can be re-executed by entering the command /
    (i.e., the slash character) at any later time in the current
    DATAPLOT session.
 
Syntax 1:
    SAVE  <id1>   <id2>
    where <id1> is the line number of the first command to re-execute;
    and   <id2> is the line number of the last command to re-execute.
 
    The line numbers are obtained by preceding the SAVE command by a
    list command with no arguments.  All the commands between the
    first and last line are re-executed as well.
 
Syntax 2:
    SAVE  <list>
    where <list> is a list of 3 or more commands to save.
 
    The line numbers are obtained by preceding the SAVE command by a
    list command with no arguments.  Only the commands listed are
    saved.
 
Syntax 3:
    SAVE  <file>  <id1>   <id2>
    where <file> is the name of a file where the saved commands are
              written;
          <id1> is the line number of the first command to re-execute;
    and   <id2> is the line number of the last command to re-execute.
 
    The line numbers are obtained by preceding the SAVE command by a
    list command with no arguments.  All the commands between the
    first and last line are re-executed as well.  This syntax is useful
    for saving more than one command sequence.  The / command
    re-executes the most recently entered SAVE sequence.  However,
    the CALL <file> command can be used to execute any SAVE sequence
    that was written to a file.
 
Syntax 4:
    SAVE  <file>  <list>
    where <file> is the name of a file where the saved commands are
              written;
    and   <list> is a list of 3 or more commands to save.
 
    The line numbers are obtained by preceding the SAVE command by a
    list command with no arguments.  Only the commands listed are
    saved.  This syntax is useful for saving more than one command
    sequence.  The / command re-executes the most recently entered SAVE
    sequence.  However, the CALL <file> command can be used to execute
    any SAVE sequence that was written to a file.
 
Examples:
    SAVE 6 3            --to save commands 6, 5, 4, and 3 ago
    SAVE 3 6            --to save commands 6, 5, 4, and 3 ago
    SAVE 6 6            --to save command 6 ago
    SAVE 6              --to save command 6 ago
    SAVE 1              --to save the last command ago
    SAVE                --to save the last command ago
    SAVE 2 5 8          --to save commands 2, 5, and 8 ago
    SAVE COMM.DP 2 5 8  --to save commands 2, 5, and 8 ago to a file
    SAVE COMM.DP  6 3   --to save commands 2, 5, and 8 ago to a file
 
Default:
    If only one argument is entered, then only that command is
    saved.
    If no arguments are entered, then the last command is saved.
 
Synonyms:
    S
 
Note:
    The SAVE command is almost always preceded by the LIST command
    (with no arguments).  LIST will print the last 20 commands that
    were entered.  Based on that list, the analyst can then enter the
    SAVE command to selectively save one or more of those commands.
    For example,
 
       LIST
       SAVE 6 3
 
    would list the last 20 commands and then save the sixth, fifth,
    fourth, and third commands ago.  See the LIST command for details.
 
Note:
    DATAPLOT actually saves the last 200 (50 in earlier versions)
    commands.  Enter the command SET LIST LINES <n> where <n> is
    between 1 and 200 to control the number of commands that LIST
    prints.
 
Note:
    The SAVE command is commonly used for the re-execution of long
    complicated commands (e.g., PLOT with a complicated mathematical
    expression).  The saved commands can be re-executed at any time by
    entering the command /.
 
Note:
    The S synonym for the SAVE command is heavily used.
 
Note:
    DATAPLOT has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    DATAPLOT strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), DATAPLOT opens the file with the
    trailing period.
 
    Some users prefer to give all macro files a ".DP" or ".dp"
    extension.  Although this is a useful method for keeping track of
    macro files, it is strictly a user convention and is not enforced
    by DATAPLOT in any way.
 
Note:
    File names are case sensitive on Unix file systems.  For Unix,
    DATAPLOT opens the file as given.  All other currently supported
    systems are not case sensitive regarding file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    If only one argument is entered, then only that command is
    saved.
    If no arguments are entered, then the last command is saved.
 
Synonyms:
    S
 
Related Commands:
    /       = Re-execute previously saved commands.
    LIST    = List the previously entered commands.
    REPEAT  = Selectively re-execute previously entered commands.
    CALL    = Execute commands stored in a file.
    CREATE  = Echo entered commands to a file.
 
Applications:
    Interactive Usage
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----SAVE MEMORY--------------------------------------------------
 
SAVE MEMORY
 
Name:
    SAVE MEMORY
 
Type:
    Support Command
 
Purpose:
    Writes out all internal DATAPLOT parameters, variables, functions,
    and switches to a file.
 
Description:
    The SAVE MEMORY command allows the analyst to interrupt a DATAPLOT
    run (due to a meeting, lunch, etc.) without loss.  The RESTORE
    MEMORY command allows the analyst to reload the settings and resume
    at the point of interruption.
 
Syntax:
    SAVE MEMORY   <file name>
    where <file name> is the name of a file where the internal settings
               are saved.
 
    If the file name does not contain a period, place a period (no
    spaces) at the end of the file name.
 
    If no file name is given, "dpsavf.tex" will be used.
Examples:
    SAVE MEMORY OUT.
    SAVE MEMORY SCRATCH.
    SAVE MEMORY TEMP.
 
Note:
    This command was significantly updated 2020/12 to incorporate
    many new settings.

Note:
    DATAPLOT has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    DATAPLOT strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), DATAPLOT opens the file with the
    trailing period.
 
Note:
    File names are case sensitive on Unix file systems.  For Unix,
    DATAPLOT opens the file as given.  All other currently supported
    systems are not case sensitive regarding file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RESTORE MEMORY = Restore all internal DATAPLOT settings from a
                     previously saved file.
    RESTORE DATA   = Restore a user specified list of variables and
                     parameters.
    SAVE DATA      = Save a user specified list of variables and
                     parameters.
    RESET          = Reset internal DATAPLOT settings to their default
                     values.
 
Applications:
    Interactive Usage
 
Implementation Date:
    Pre-1987
    2020/12: Updated to include many new settings
    2020/12: Use "dpsavf.tex" if no file name is given
    2020/12: Added better error trapping
 
Program:
    XX
 
-----SAVE PLOT--------------------------------------------------
 
SAVE PLOT
 
Name:
    SAVE PLOT
 
Type:
    Support Command
 
Purpose:
    Save the current plot for later recall via the REPEAT PLOT
    command.
 
Description:
    The SAVE PLOT and REPEAT PLOT commands allow you to save and
    recall graphs.  The primary use of this is to compare the current
    graph to previously created graphs.
 
    This command is host dependent.  It is currently supported for
    the following platforms:
   
       1) Unix platforms via the X11 device driver;
       2) Windows 95/98/NT command line version built with the
          Microsoft Fortran compiler (saved in Windows bitmap format);
       3) Dataplot GUI (both Unix and Windows 95/98/NT).

Syntax 1:
    SAVE  PLOT <file>
    where <file> is the name of a file in which the current graph
          will be saved.
 
    This syntax saves the current plot in the specified file.
    If the file name is omitted, the plot is saved in the
    file "pixmap.<n>" where <n> is a counter.  The counter
    starts at 1 for each new Dataplot session.
 
Syntax 2:
    SAVE  PLOT <file> AUTOMATIC
    where <file> is the name of a file in which the current graph
          will be saved.
 
    This syntax saves all subsequent plots in the specified file.
    The current plot is not saved, only plots subsequent to
    when the SAVE PLOT command is entered.

    A counter is added to the file name, that is, if the file
    name specified was SCATPLOT, then the saved graphs are in
    SCATPLOT.1, SCATPLOT.2, etc.  If the file name is omitted,
    the plot is saved in the file "pixmap.<n>" where <n> is
    the counter.

    The counter starts at 1 for each new Dataplot session.
 
Examples:
    READ FILE.DAT Y1 Y2 Y3
    HISTOGRAM Y1
    SAVE PLOT HIST.1
    HISTOGRAM Y2
    SAVE PLOT HIST.2
    HISTOGRAM Y3
    SAVE PLOT HIST.3
 
Default:
    The default file name is "pixmap.<n>" where <n> is a
    counter (reset to 1 for each new Dataplot session).
 
Synonyms:
    SAVE GRAPH, SP, and SG are all synonyms for SAVE PLOT.
 
Note:
    The saved plots are essentially screen dumps.  There is
    currently no "linking" in the sense that if a given variable
    is changed the saved plots are automatically updated.
 
Note:
    As a technical note for the X11 implementation, the plots
    are saved in X11 "bitmap" format.  This is distinct from
    the X11 image format that is used by xwd to save a screen
    image.  This choice was made for performance reasons (xlib
    provides direct routines for reading and writing bitmaps,
    but not for reading and writing images).  The primary
    limitations are:

      i) Color is not supported for X11 bitmaps.  Elements drawn
         in color will not be saved in the bitmap.

     ii) You cannot use the X11 tools xwd and xwud to view the
         saved plots independently of Dataplot.  However, they
         can be viewed by any software the reads X11 bitmaps.
 
Note:
    Be aware that for SAVE GRAPH AUTOMATIC the saving for a given
    plot is not executed until the next screen erase (typically the
    next plot) is encountered to allow for multi-plotting and the
    addition of diagrammatic graphics to a plot.
 
Note:
    The REPEAT PLOT command is used to display a plot saved
    with SAVE PLOT.  The LIST PLOT command lists the currently
    saved plots (by sequence number, file name, and title).
    The CYCLE PLOT command allows you to cycle through the
    pixmaps in the current list by clicking mouse buttons.
    The PIXMAP TITLE command allows you to specify the title
    for a saved plot.  This title is simply for ease of
    identification in listing the saved plots and is not
    saved as part of the plot.
 
Related Commands:
    LIST PLOT    = List saved plots.
    REPEAT PLOT  = Draw a previously saved graph.
    CYCLE PLOT   = Cycle through previously saved graphs using 
                   mouse buttons.
    PIXMAP TITLE = Provide a temporary name for a saved graph.
 
Applications:
    Interactive Usage
 
Implementation Date:
    7/1997
 
Program:
    READ BERGER1.DAT Y X
    FIT Y X
    4-PLOT RES
    SAVE PLOT RES.1
    QUADRATIC FIT Y X
    4-PLOT RES
    SAVE PLOT RES.2
    REPEAT PLOT RES.1
    REPEAT PLOT RES.2
 
-----SAVE VARIABLE--------------------------------------------------
 
SAVE VARIABLE
 
Name:
    SAVE VARIABLE
 
Type:
    Support Command
 
Purpose:
    Save a user specified list of variables and parameters to an
    external file.

Description:
    The primary purpose of this command is for use with general
    purpose macros.  Specifically, macros can save the current
    values for certain variables, re-use those variables in the
    macro and then restore the original values to the variables.
 
    You can save variables and parameters.  However, matrices and
    strings/functions are not currently supported.

    The RESTORE VARIABLE command is used to restore the variables
    saved by this command.

Syntax:
    SAVE VARIABLE <file-name>  <list-variables>
    where <file-name> is the name of a file where the variables and
               parameters are saved;
    and   <list-variables> is a list of parameters and variables.

    If no <file-name> is given, the file "dpsavf.tex" is used.

    If no variables are specifed, then all currently defined variables
    and parameters will be saved.
 
Examples:
    SAVE VARIABLES
    SAVE VARIABLES VARLIST.DAT
    SAVE VARIABLES VARLIST.DAT Y X1 X2 X3 X4
 
Note:
    The format of the save file is something like

        Y        VARIABLE
                 3
          0.1800000E+02
          0.3800000E+02
          0.1500000E+02
        AVAL     PARAMETER
          0.1000000E+01

    For each name, the first line prints the variable/parameter name
    and also prints the type (VARIABLE or PARAMETER).  If the name is
    a variable, the next line specifies the number of elements in
    the variable.  The contents of the variable are then printed one
    element per line.  If the name is a parameter, then the value of
    the parameter is printed on the next line.

    Variables and parameters are printed one at a time.

Note:
    Dataplot has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    Dataplot strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), Dataplot opens the file with the
    trailing period.
 
Note:
    File names are case sensitive on Unix/Linux and MacOSX file
    systems.  For these systems, Dataplot opens the file as given.  All
    other currently supported systems are not case sensitive regarding
    file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RESTORE VARIABLE = Restore variables and parameters saved with a
                       SAVE VARIABLE command.
    SAVE MEMORY      = Save all internal Dataplot settings to a file.
    RESTORE MEMORY   = Restore all internal Dataplot settings from a
                       previously saved file.
    RESET            = Reset internal DATAPLOT settings to their default
                       values.
 
Applications:
    Utility for Macros
 
Implementation Date:
    2020/12
 
Program:
    SKIP 25
    READ BERGER1.DAT Y X BATCH
    SAVE VARIABLES Y X BATCH
    .
    LET Y = NORMAL RANDOM NUMBERS FOR I =  1 1 100
    LET X = SEQUENCE 1 1 10
    LET BATCH = 1 FOR I = 1 1 10
    .
    RESTORE VARIABLES
    PRINT Y X BATCH
 
-----SCATTER PLOT MATRIX--------------------------------------
 
SCATTER PLOT MATRIX
 
Name:
    SCATTER PLOT MATRIX
 
Type:
    Graphics Command
 
Purpose:
    Generates a scatter plot matrix.
 
Description:
    A scatter plot matrix of Y1, Y2, ... , Yk is a matrix of
    all the pairwise scatter plots between Y1, Y2, ...., Yk.
    This is a simple, but powerful, technique for viewing all the
    pairwise relationships between the variables.

    The pairwise plots need not be limited to scatter plots.
    Dataplot allows you to generate the pairwise plots for
    approximately 10 different plot types (and additional plot
    types will be added in future implementations).

    There are a number of alternatives for the appearance of this
    plot.  Dataplot tries to balance simplicity with flexibility
    by using default settings, but providing numerous SET commands
    to control the appearance of the plot.  These are described in
    detail in the NOTES section below.

Syntax 1:
    SCATTER PLOT MATRIX  <y1> <y2> ... <yk>  <SUBSET/EXCEPT/FOR qualification>
    where <y1> through <yk> are the response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    Up to 25 response variables can be specified.

Syntax 2:
    YOUDEN MATRIX PLOT <y1> <y2> ... <yk> <tag> <SUBSET/EXCEPT/FOR qualification>
    where <y1> through <yk> are the response variables;
          <tag> is a group id variable (and is always given last);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This is a special form of the command that plots 
     
         PLOT Yi Yj TAG

    for the individual plots.

Syntax 3:
    DEX <stat> INTERACTION PLOT <y1> <y2> ... <yk> <SUBSET/EXCEPT/FOR qualification>
    where <y1> through <yk> are the response variables;
          <stat> defines a statistic, such as MEAN or MEDIAN, for
               the plot;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This is a special form of the command that plots 
     
         DEX <stat> INTERACTION PLOT Yi Yj TAG

    for the individual plots.  <stat> is optional.

Examples:
    SCATTER PLOT MATRIX Y1 Y2 Y3 Y4 Y5
    SCATTER PLOT MATRIX Y1 Y2 Y3 Y4 Y5 SUBSET TAG > 2
 
Note:
    The concept of the scatter plot matrix generalizes quite 
    nicely to any plot type for two variables.  Dataplot
    supports the scatter plot matrix for a number of different plot
    types.  The type of plot generated is controlled by the following
    command:

        SET SCATTER PLOT MATRIX TYPE <value>

    where <value> is one of the following.

    The folllowing plot two variables (e.g., BIHISTOGRAM Y1 Y2).

        PLOT    - generate scatter plots (this is the default).
                  The x and y axis labels are automatically set
                  to the appropriate variable name.
 
        QUANTILE-QUANTILE - generate quantile-quantile plots.  This
                  degenerates to percent point plots on the diagonal.
                  The x and y axis labels are automatically set
                  to the appropriate variable name.
                  
        BIHISTOGRAM - generate relative bihistograms.  This
                  degenerates to relative histograms on the diagonal.
                  We recommend that you enter
                  SET RELATIVE HISTOGRAM PERCENT to generate more
                  consistent y-axis scales.  The X1LABEL is set
                  to the first variable name and the X2LABEL is set to
                  the second variable name.  If no YLABEL is
                  already defined, the YLABEL is set to "Frequency".

        CORRELATION  - generate a cross-correlation plot.  This
                  degenerates to an autocorrelation plot on the
                  diagonal.  If X1LABEL and Y1LABEL are not
                  previously defined, they are automatically set
                  to "Lag" and "Correlation" respectively.  The
                  X2LABEL is set to "X1*X2" where X1 and X2
                  represent the variable names.

        LAG     - generate a cross-lag plot.  This degenerates to a
                  lag plot on the diagonal.  If X1LABEL and Y1LABEL
                  are not previously defined, they are automatically
                  set to "I+1" and "I" respectively.  The
                  X2LABEL is set to "X1*X2" where X1 and X2
                  represent the variable names.

        SPECTRAL - generate a cross-spectral plot.  This degenerates
                  to a spectral plot on the diagonal.  If X1LABEL and
                  Y1LABEL are not previously defined, they are
                  automatically set to "Power" and "Frequency"
                  respectively.  The X2LABEL is set to "X1*X2" where
                  X1 and X2 represent the variable names.

        YOUDEN - this generates a Youden plot.  That is, 
                 PLOT Y1 Y2 TAG where TAG is a group id variable.
                 The TAG variable is the last variable listed on the
                 SCATTER PLOT MATRIX command and is the same for all
                 the plots.
 
    The folllowing plot Y X1 X2 (e.g., DEX CONTOUR PLOT Y X1 X2).
    That is, the response variable is the first variable in the
    list, and it remains constant for all the pairwise plots.

        DEX CONTOUR   - this generates a dex contour plot.  The
                 diagonal plot is empty.  The X2LABEL is set to
                 "X1*X2" where X1 and X2 represent the variable names.
                 No automatic labels are generated for X1LABEL and
                 Y1LABEL.

        DEX INTERACTION - generate a DEX INTERACTION PLOT.
                 The X1LABEL is set to "X1*X2" where X1 and X2
                 represent the variable names.  No automatic labels
                 are generated for X2LABEL and Y1LABEL.

        DEX <statistic> INTERACTION  - generate a DEX <statistic>
                 INTERACTION PLOT.  The X1LABEL is set to
                 "X1*X2" where X1 and X2 represent the variable names.
                 No automatic labels are generated for X2LABEL and
                 Y1LABEL.

        CROSS TABULATE <statistic> - generate a CROSS TABULATE
                 <statistic> plot.  This generates to a
                 <statistic> STATISTIC plot on the diagonal.
                 The X1LABEL is set to "X1*X2" where X1 and X2
                 represent the variable names.  No automatic labels
                 are generated for X2LABEL and Y1LABEL.

                 If no <statistic> is given, then a special form
                 of the CROSS TABULATE PLOT is generated.  For this
                 case, there is no response variable
                 (i.e., CROSS TABULATE PLOT X1 X2 as oppossed to
                 CROSS TABULATE MEAN PLOT Y X1 X2).  The X1LABEL
                 and Y1LABEL are set to the appropriate variable
                 name.

    A few of the above plots support a <statistic> option.  This
    can be one of 30+ supported statistics (the supported statistics
    are identical to those for the STATISTIC PLOT and the BOOTSTRAP
    PLOT).  It is typically a location statistic (e.g., MEAN, 
    MEDIAN) or a scale statistic (e.g., STANDARD DEVIATION, VARIANCE,
    MAD).
 
    Dataplot automatically defines X1LABEL, X2LABEL, and YLABEL
    commands for these plots.  You can control the attributes
    of these labels with the standard label setting commands.
    If you have defined variable labels (with the VARIABLE LABEL
    command), these will automatically be substituted for variable
    names in the labels.

    If you have defined variable labels with the VARIABLE LABEL
    command and you want to suppress the automatic expansion
    of the variable name to the variable label, enter

        SET VARIABLE LABEL EXPAND OFF

    To restore the default that variable names will be expanded to
    the corresponding variable label, enter

        SET VARIABLE LABEL EXPAND ON

Note:
    The following option controls which axis tic marks, tic mark
    labels, and axis labels are plotted.
 
        SET SCATTER PLOT MATRIX LABELS <ON/OFF/XON/YON/BOX>

    OFF means that all axis labels are suppressed (this can be
    useful if a large number of variables are being plotted).  ON
    means that both X and Y axis labels are printed.  XON only
    plots the x axis labels and YON only plots the y axis labels.

    BOX is a special option that creates an extra column on the
    left and an extra row on the bottom.  The axis label is
    printed in this box.

    The default is ON (both x and y axis labels are printed).

Note:
    The following option controls where the x axis tic marks,
    tic mark labels, and axis label are printed.
 
        SET SCATTER PLOT MATRIX X AXIS <BOTTOM/TOP/ALTERNATE>

    BOTTOM specifies that the x axis labels are printed on the
    bottom axis (on the last row only).  TOP specifies that
    the x axis labels are printed on the top axis (first row
    only).  ALTERNATE specifies that the x axis labels alternate
    between the top (first row) and bottom axis (last row).
    We recommend using the TIC OFFSET command to avoid overlap
    of axis labels and tic marks.

    The default is ALTERNATE.

Note:
    The following option controls where the y axis tic marks,
    tic mark labels, and axis label are printed.
 
        SET SCATTER PLOT MATRIX Y AXIS <LEFT/RIGHT/ALTERNATE>

    LEFT specifies that the y axis labels are printed on the
    left axis (on the first column only).  RIGHT specifies that
    the y axis labels are printed on the right axis (last column
    only).  ALTERNATE specifies that the y axis labels alternate
    between the left (first column) and right axis (last column).
    We recommend using the TIC OFFSET command to avoid overlap
    of axis labels and tic marks.

    The default is ALTERNATE.

Note:
    Users have different preferences in terms of whether the
    plot frames for neighboring plots are connected or not.
    This is controlled with the following option.
 
        SET SCATTER PLOT MATRIX FRAME <DEFAULT/CONNECTED/USER>

    DEFAULT connects neighboring frames (i.e., the FRAME CORNER
    COORDINATES are set to 0 0 100 100).  USER uses whatever
    frame coordinates are currently set (15 20 85 90 by default)
    and makes no special provisions for axis labels and tic marks
    (i.e., you set them as you normally would, each plot uses 
    whatever you have set).  CONNECTED uses whatever frame
    coordinates have been set by the user, but it draws the axis
    labels and tic marks as if DEFAULT were being used (that is, as
    determined by the SET SCATTER PLOT MATRIX <LABELS/X AXIS/Y AXIS>
    commands described above).  Typically, CONNECTED is used to
    put a small bit of space between plots.  For example, you
    might use FRAME CORNER COORDINATES  3 3 97 97 before the
    SCATTER PLOT MATRIX command.
 
    The default is DEFAULT.

Note:
    When the tic marks and tic mark labels are all plotted on the
    same side (i.e., SET SCATTER PLOT MATRIX Y AXIS is
    set to LEFT or RIGHT or SET SCATTER PLOT MATRIX X AXIS is
    set to BOTTOM or TOP), then overlap between plots is possible.
    The TIC OFFSET command can be used to avoid this.  In addition,
    you can stagger the tic labels with the following command:
 
        SET SCATTER PLOT MATRIX LABEL DISPLACEMENT
                <NORMAL/STAGGERED/VALUE>
 
    NORMAL means that all tic labels are plotted at a distance
    determined by the TIC LABEL DISPLACEMENT command.  STAGGERED
    means that alternating plots will be staggered.  That is, one
    will use the standard displacement while the next uses a
    staggered value.  Entering this command with a numeric value
    specifies the amount of the displacement for the staggered
    tic labels.  For example,

        TIC MARK LABEL DISPLACEMENT 10
        SET SCATTER PLOT MATRIX LABEL DISPLACEMENT STAGGERED
        SET SCATTER PLOT MATRIX LABEL DISPLACEMENT 25

    These commands specify that the default tic label displacement
    is 10 and the staggered tic mark label displacement is 25.

Note:
    It is often helpful on scatter plot matrices to overlay a
    fitted line on the plots.  The following command is used
    to specify the type of fit.

        SET SCATTER PLOT MATRIX FIT <NONE/LOWESS/LINE/QUAD/SMOOTH>

    NONE means that no fitted line is plotted.  LOWESS means
    that a locally weighted least squares line will be overlaid.
    LINE means that a linear fit (Y = A0 + A1*X) will be overlaid.
    QUAD means that a quadratic fit (Y = A0 + A1*X + A2*X**2) will
    be overlaid.  SMOOTH means that a least squares smoothing will
    be overlaid.

    For LOWESS, it is recommended that the lowess fraction be set
    fairly high (e.g., LOWESS FRACTION 0.6).

    The fitted line is currently only generated if the scatter plot
    matrix plot type is PLOT.

    The default is for no fitted line to be overlaid on the plot.
    If a overlaid fit is desired, the most common choice is to use
    LOWESS.

Note:
    Dataplot supports a special plot type

        PLOT Y X TAG

    In this form of the plot command, TAG is a group identifier
    variable.  Points belonging to the same group are plotted with
    the same attributes (controlled by the CHARACTER and LINE commands
    and their various attribute setting commands).

    Using a tag variable has two common purposes:

    1) If your data has natural groups (e.g., batch 1 and batch 2).
    2) To identify certain points.  The most common application
       would be to flag outliers.
 
    You can specify that the scatter plot matrix use the form
    of the PLOT command by using the command

        SET SCATTER PLOT MATRIX TAG <ON/OFF>

    OFF specifies that the standard plot command (PLOT Y1 Y2) will
    be used.  ON specifies that the last variable on the
    SCATTER PLOT MATRIX command is a tag variable.  That is, it is
    not plotted directly, but is instead the third variable on
    all the plot commands generated by the scatter plot matrix.

    Currently, this command only applies if the scatter plot matrix
    plot type is set to PLOT.

    This form is common enough that the command

        YOUDEN MATRIX PLOT Y1 Y2 ... YK TAG

    implements this automatically.  That is, YOUDEN MATRIX PLOT
    is equivalent to

        SET SCATTER PLOT MATRIX TAG ON
        SCATTER PLOT MATRIX Y1 Y2 ... YK TAG

    In some cases, you may want to use a tag variable for both
    purposes.  That is, you may have natural groups in your data,
    but you also want to flag certain outlying points.  You can
    do this by using a SUBSET clauuse.  For example,

        LIMITS 0 120
        SET SCATTER PLOT MATRIX TAG ON
        CHARACTER CIRCLE SQUARE TRIANGLE
        CHARACTER FILL OFF OFF OFF
        SCATTER PLOT MATRIX Y1 Y2 Y3 Y4 TAG  SUBSET Y2 <= 100
        PRE-ERASE OFF
        CHARACTER FILL ON ON ON
        SCATTER PLOT MATRIX Y1 Y2 Y3 Y4 TAG  SUBSET Y2 > 100

    The SET SCATTER PLOT MATRIX LIMITS command, discussed below,
    can be used to control the axis limits for the individual plots.

    The default is OFF.

Note:
    Dataplot allows you to set axis limits with the LIMITS command.
    For the scatter plot matrix, it is often desirable to set
    the axis limits for each plot.  This can be done with the
    command
 
        SET SCATTER PLOT MATRIX LIMITS <LOW1> <UPP1> <LOW2> <UPP2> ...

    Note that the pairs of limits correspond to the variable list
    in the SCATTER PLOT MATRIX command.  That is, if Y3 is the 
    third variable in the command, Dataplot will set the YLIMITS
    when Y3 is plotted on the y axis and the XLIMITS when Y3 is
    plotted on the x axis.
 
    This command is particularly useful if you want to overlay
    scatter plot matrices (the example discussed for the 
    SET SCATTER PLOT MATRIX TAG command gives an example of where
    you might want to do this).

    The default is to allow the axis limits to float with the data.

Note:
    Dataplot supports a subregion capability.  This is used to
    draw "engineering limits" on a plot.  For a scatter plot matrix,
    if you specify engineering limits, you typically want these
    limits to vary with each plot.  They can be specified with the
    command
 
        SET SCATTER PLOT MATRIX SUBREGION LIMITS <LOW1> <UPP1>
            <LOW2> <UPP2> ...

    This command is similar to the SET SCATTER PLOT MATRIX LIMITS
    command in that the list corresponds to the variables entered
    on the SCATTER PLOT MATRIX command.

    Only one set of subregion limits can be set for each variable.

    The default is that no subregion limits are set.

Note:
    For a scatter plot matrix, there are numerous choices for what
    to plot on the diagonal.  This is controlled with the command
 
        SET SCATTER PLOT MATRIX DIAGONAL <BLANK/LINE/HISTOGRAM/BOXPLOT>

    If BLANK, an empty plot is generated and the variable label
    is plotted in the center of the empty plot.  If LINE, a
    PLOT Y1 Y1 is generated (this will simply be a 45 degree line,
    but it does give some indication of the univariate distribution
    of the variable).  If HISTOGRAM, a relative histogram of the
    variable is generated.  For the HISTOGRAM, the axis labels do
    not apply to the histogram plot.  A relative histogram is drawn
    to make comparisons more meaningful.  If BOXPLOT, a box plot of
    the variable is generated.  The BOXPLOT only applies if the
    SET SCATTER PLOT MATRIX TAG ON command is entered. That is, the
    box plot is only used if there are groups in the data.  For the
    box plot, the y axis limtis are valid, but the x axis limits
    are not.

    This command only applies if the scatter plot matrix plot
    type is PLOT, CROSS TABULATE, or DEX CONTOUR.

    The default is BLANK.

Note:
    The scatter plot matrix is redundant in the sense that
    PLOT Y1 Y2 is equivalent to PLOT Y2 Y1 (with the axes reversed).
    For this reason, some analysts prefer to omit plots below the
    diagonal.  This can be controlled with the command
 
        SET SCATTER PLOT MATRIX LOWER DIAGONAL <ON/OFF>

    If OFF, the plots below the diagonal are omitted.  If ON, the
    plots below the diagonal are drawn.

    The default is ON.

Note:
    You can specify a special X2LABEL for the plots with the
    following command 
 
        SET SCATTER PLOT MATRIX X2LABEL <OFF/
              CORRELATION/PERCENT CORRELATION/EFFECT/
              PERCENT ACCEPT/NUMBER ACCEPT/ACCEPT TOTAL>

    where
        OFF      - no special X2LABEL is drawn.
        CORRELATION - the correlation of the points on the plot
                   is printed with the X2LABEL.  This option
                   is typically used with the plot type PLOT.
        PERCENT CORRELATION - this is the same as CORRELATION, except
                   that the correlation is printed as a percent.
        EFFECT   - the difference between the low and high value
                   is printed.  This option is typically used with
                   the plot type DEX <stat> INTERACTION (and doesn't
                   really make any sense with the other plot types).
        PERCENT ACCEPT - this option prints the percentage of points
                   inside the first subregion.  If no subregions are
                   defined, this option makes no sense.  It is
                   typically used to specify the percentage of points
                   within engineering limits.
        NUMBER ACCEPT - this option is similar to PERCENT ACCEPT.
                   However, the number of points rather than the
                   percentage is printed.
        ACCEPT TOTAL - this option is similar to NUMBER ACCEPT.
                   However, it prints the number accepted first,
                   then the total number of points.
        ACCEPT TOTAL PERCENT - this option is similar to ACCEPT TOTAL.
                   However, after printing the number accepted and
                   the total number, it prints the percentage
                   accepted.


    The following commands can be used to add a prefix and suffix
    to the X2LABEL.  For example, you might want the PERCENT
    CORRELATION to append a "%" after the percent correlation
    and to start with "CORR = ".

        SET X2LABEL PREFIX <prefix>
        SET X2LABEL SUFFIX <suffix>
 
    The appearance and location of the X2LABEL are controlled
    with the standard X2LABEL attribute setting commands.

    There are occassions where you may want to use the values
    computed in the X2LABEL for additional numeric computations.
    These values are automatically written to the file
    "dpst5f.dat".  The values are printed in the order the plots
    are generated.

Note:
    You can use standard plot control commands to control the
    appearance of the scatter plot matrix.

    For example,

       MULTIPLOT CORNER COORDINATES 5 5 95 95
       MULTIPLOT SCALE FACTOR 3
       TIC OFFSET UNITS SCREEN
       TIC OFFSET 5 5

    is a fairly typical set of commands commonly used with
    scatter plot matrices.

Default:
    None
 
Synonyms:
    MATRIX PLOT is a synonym for SCATTER PLOT MATRIX.
    SET MATRIX PLOT is a synonym for SET SCATTER PLOT MATRIX.
 
Related Commands:
    PLOT               = Generates a data or function plot.
    FACTOR PLOT        = Generate a factor plot.
    CONDITIONAL PLOT   = Generate a conditional (subset) plot.
 
Reference:
    "Visualizing Data", Cleveland, William S., Hobart Press, 1993.
 
    "Graphical Exploratory Data Analysis", du Toit, Steyn, and Stumpf,
    Springer-Verlang, 1986.
 
Applications:
    Exploratory Data Analysis, Multivariate Data Analysis
 
Implementation Date:
    2000/1
 
Program:
    read iris.dat y1 y2 y3 y4 tag
    multiplot corner coordinates 10 10 90 90
    multiplot scale factor 4
    tic offset units screen
    tic offset 5 5
    line blank blank blank
    character 1 2 3
    set matrix plot tag on
    matrix plot y1 y2 y3 y4 tag

-----SCATTER (LET)-------------------------------------
 
SCATTER
 
Name:
    SCATTER (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Save rows of a variable based on index values
    contained in another variable.
 
Description:
    The GATHER command (HELP GATHER for details) can be used
    to extract specific rows of a variable based on an index
    variable.

    The SCATTER command is most often used after a GATHER
    command.  That is, we use GATHER to extract specific rows
    of a variable, perform operations that modify these extracted
    values, and then use SCATTER to save these modfied values
    back in the original variable.

Syntax:
    LET <y> = SCATTER <x>  <index>
    where <x> is a response variable;
          <index> is a variable containing row numbers;
    and   <y> is a variable where the values of <x> will be saved.
 
Examples:
    LET Y = SCATTER X INDEX
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    GATHER             = Extract specified rows of data from a variable
                         based on an index variable.
    SEQUENCE           = Generate a patterned sequence of values.
    SORT               = Sort a column of numbers.
    RANK               = Rank a column of numbers.
    CODE               = Code a column of numbers.
    SUBSET             = Specifies a subset to be included in a plot,
                         analysis, or LET command.
    RETAIN             = Retain specified rows or a subset of a
                         variable.
 
Applications:
    Data Transformation
 
Implementation Date:
    2008/11
 
Program:
    let n = 30
    let xseq = sequence 1 1 n
    let x = normal rand numb for i = 1 1 n
    let iindex = data 10  14  8  23  19
    .
    let y = -10 for i = 1 1 n
    let y = scatter x iindex
    set write decimals 3
    print xseq  x  y iindex

-----SEARCH-------------------------------------------------------
 
SEARCH
 
Name:
    SEARCH
 
Type:
    Support Command
 
Purpose:
    Search a file for a string.
 
Syntax 1:
    SEARCH  <file name>  <string>
    where <file name> is the file to be searched;
    and   <string> is the string to search for.
 
    This syntax prints all lines where a match is found.
 
Syntax 2:
    SEARCH1   <file name>    <string>
    where <file name> is the file to be searched;
    and where <string> is the string to search for.
 
    This syntax prints the first line where a match is found.
 
Syntax 3:
    SEARCHB   <file name>    <string>
    where <file name> is the file to be searched;
    and   <string> is the string to search for.
 
    This syntax prints from the first line where a match is found to
    the next blank line.
 
Syntax 4:
    SEARCHDA  <file name>    <string>
    where <file name> is the file to be searched;
    and   <string> is the string to search for.
 
    This syntax prints from the first line where a match is found to
    the next dashed line.
 
Syntax 5:
    SEARCH  REFERENCE    <string>
    where <string> is the string to search for.
 
    This syntax searches the file refman.tex located in the Dataplot
    HELP directory.  This file is used by the WEB HELP command to access
    the Dataplot reference manual on the Dataplot web pages.
 
Syntax 6:
    SEARCH  HANDBOOK    <string>
    where <string> is the string to search for.
 
    This syntax searches the file handbk.tex located in the Dataplot
    HELP directory.  This file is used by the WEB HANDBOOK command to
    access the NIST/SEMATECH e-Handbook of Statistics web pages.
 
Syntax 7:
    SEARCH  DIRECTORY    <string>
    where <string> is the string to search for.
 
    This syntax searches the file dpdirf.tex located in the Dataplot
    HELP directory.  This file contains a one line description of
    Dataplot commands sorted by category.
 
Syntax 8:
    SEARCH  DICTIONARY    <string>
    where <string> is the string to search for.
 
    This syntax searches the file dpdicf.tex located in the Dataplot
    HELP directory.  This file contains a one line description of
    Dataplot commands sorted alphabetically.
 
Examples:
    SEARCH PLOTCALIB.  PLOT
    SEARCH PROG.PLOTLAB  READ
    SEARCH REFERENCE MEAN PLOT
    SEARCH HANDBOOK RELIABILITY

Note:
    In versions prior to 2018/04, only the first word of
    <string> was matched.  For example,
    SEARCH REFERENCE MEAN PLOT would find all lines in
    refman.tex that contain the word MEAN.

    Starting with the 2018/04 version,
    SEARCH REFERENCE MEAN PLOT will now only match the lines
    containing the phrase MEAN PLOT.  Note that words MEAN PLOT must
    appear contiguously (i.e., as a single phrase) on the line.
    It does not do a separate search for MEAN and then for
    PLOT and it does not match lines where MEAN and PLOT do not
    appear together.  For example, "MEAN OF THE PLOT" would not be
    a match for "MEAN PLOT".
Note:
    Dataplot will save the line number of the first match in the
    parameter LINENUMB.

Note:
    Only the first 80 characters of the line will be printed.

Note:
    The search is not case sensitive.

Note:
    The FOR clause can be used to search a restricted part of the
    file.  For example,

         SEARCH PROG.PLOTLAB  PLOT  FOR I = 1 1 200

    searches only the first 200 lines of the file.
 
Note:
    DATAPLOT has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    DATAPLOT strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), DATAPLOT tries to open the file with
    the trailing period.  If this fails, it then tries to open the file
    with the trailing period stripped off.
 
Note:
    File names are case sensitive on Unix file systems.  For Unix,
    DATAPLOT attempts to open the file as given.  If this fails, it
    attempts to open the file as all upper case characters.  If this
    fails, it attempts to open the file as all lower case characters.
    All other currently supported systems are not case sensitive
    regarding file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    None
 
Synonyms:
    SEARCHALL is a synonym for SEARCH.

    ? is a synonym for SEARCH REFERENCE
    SEARCH is a synonym for SEARCH REFERENCE
    SEARCH RM is a synonym for SEARCH REFERENCE

    ??? is a synonym for SEARCH HANDBOOK
    SEARCH HB is a synonym for SEARCH HANDBOOK
    SEARCH HANDBK is a synonym for SEARCH HANDBOOK

    SEARCH DIR is a synonym for SEARCH DIRECTORY
    SEARCH DIRE is a synonym for SEARCH DIRECTORY
    SEARCH DIC is a synonym for SEARCH DICTIONARY
    SEARCH DICT is a synonym for SEARCH DICTIONARY
 
Related Commands:
    LIST          = Print the contents of the file.
    WEB HELP      = Access Dataplot's web-based documentation.
    WEB HANDBOOK  = Access the NIST/SEMATECH Handbook of Statistical
                    Methods web pages.
 
Applications:
    Documentation
 
Implementation Date:
    1988/01
    1988/08: Support for DICTIONARY and DIRECTORY searches
    1994/01: Support for SEARCH1 option
    2003/02: Support for saving LINENUMB
    2018/04: Support for REFERENCE and HANDBOOK searches
    2018/04: Support for multi-word searches
    2018/04: Add various synonyms
 
Program:
    SEARCH REFERENCE MEAN PLOT
    WEB HELP MEAN PLOT
 
-----SEARCH DIRECTORY (SET)--------------------------------------------
 
SEARCH DIRECTORY
 
Name:
    SEARCH DIRECTORY (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify the name of the directory where Dataplot will look for files.
 
Description:
    When Dataplot encounters a file name (on the LIST, READ, WRITE, or CALL
    commands), it will do the following:

       1. It will first look for the file in the current directory (you
          can enter the PWD command if you are not sure what that is).

       2. If the command

             SET HOME PATH ON

          has been given, then your home directory will be searched next.

       3. If it does not find the file, it will look for the file in
          the Dataplot auxillary directory.  By default, this will be
          "C:\Program Files (x86)\NIST\DATAPLOT" under Windows systems
          and "/usr/local/lib/dataplot" under Unix/Linux/Mac OS X
          systems.  However, this may be different on your platform.

          Dataplot first searches this directory and then the following
          sub-directories "help", "data", "dex", "10step", "macros",
          "programs", "text", "menu", "ps", and "scripts" are searched
          (in the order given).

    Note that under Unix/Linux/Mac OS X systems, which are case sensitive,
    Datatplot will first try to open the file name as given.  If the file
    is not found, then Dataplot will convert the file name to all upper
    case and try to open the file.  If the file is not found, then Dataplot
    will convert the file name to all lower case and try to open the
    file.  Note that this file name conversion is performed in each
    directory before moving to the next directory.

    Some users may find it convenient to keep macros and datasets that will
    be used in subsequent Dataplot sessions in a common directory.  The
    SEARCH DIRECTORY command allows you to specify a directory to be
    searched for file names.  This directory will be searched after the
    current directory but before the Dataplot auxillary directories.

    Currently, this command is limited to a single directory.

    Note: The 2020/05 version of Dataplot added the SET SEARCH2 DIRECTORY,
          SET SEARCH3 DIRECTORY, SET SEARCH4 DIRECTORY,
          SET SEARCH5 DIRECTORY and SET SEARCH6 DIRECTORY commands to
          allow up to six user specified directories to be searched.

          The 2 to 6 suffix specifies the order in which the directories
          are searched.  However, you do not have to define them in any
          particular order.  For example, you can enter a SET SEARCH4
          DIRECTORY command without entering a SET SEARCH3 DIRECTORY or
          a SET SEARCH2 DIRECTORY command.

Syntax 1:
    SET SEARCH DIRECTORY <string>
    where <string> specifies the desired directory name.
 
Syntax 2:
    SET SEARCH2 DIRECTORY <string>
    where <string> specifies the desired directory name.
 
    This specifies a second user specified directory.

Syntax 3:
    SET SEARCH3 DIRECTORY <string>
    where <string> specifies the desired directory name.
 
    This specifies a third user specified directory.

Syntax 4:
    SET SEARCH4 DIRECTORY <string>
    where <string> specifies the desired directory name.
 
    This specifies a fourth user specified directory.

Syntax 5:
    SET SEARCH5 DIRECTORY <string>
    where <string> specifies the desired directory name.
 
    This specifies a fifth user specified directory.

Syntax 6:
    SET SEARCH6 DIRECTORY <string>
    where <string> specifies the desired directory name.
 
    This specifies a sixth user specified directory.

Examples:
    SET SEARCH DIRECTORY C:\DATAPLOT_MACROS
    SET SEARCH DIRECTORY C:\DATAPLOT_DATASETS
    SET SEARCH DIRECTORY /home/heckert/dataplot_macros
    SET SEARCH2 DIRECTORY C:\MY_DATAPLOT_FILES
 
Default:
    None
 
Synonyms:
    SET SEARCH PATH
 
Related Commands:
    SET PATH   = Define the location for Dataplot's auxillary files.
    LIST       = List the contents of a file.
    READ       = Read data from a file.
    WRITE      = Write data to a file.
    CALL       = Execute commands stored in a file.
 
Applications:
    File Usage
 
Implementation Date:
    2014/10
    2020/05: Added SEARCH2, SEARCH3, SEARCH4, SEARCH5 and SEARCH6 options
 
Program:
    . Assume "sample.dp" is in the /home/heckert/dataplot/macros directory
    .
    SET SEARCH DIRECTORY /home/heckert/dataplot/macros
    CALL sample.dp
 
-----SEASONAL LOWESS-----------------------------------------------
 
SEASONAL LOWESS
 
Name:
    SEASONAL LOWESS
 
Type:
    Analysis Command
 
Purpose:
    The SEASONAL LOWESS command decomposes a time series into
    trend, seasonal, and residual components using techniques
    based on locally weighted least squares.  That is,
   
       X(t) = TREND(t) + SEAS(t) + RES(t)

Description:
    There are a number of time series techniques that are
    based on decomposing time series into a trend, seasonal,
    and residual component.  The most popular of these is
    based on exponential smoothing.  Seasonal lowess is a
    decomposition method based on locally weighted least
    squares.

    In general, these methods are an alternative to
    autoregressive/moving average (ARMA) models.  Decomposition
    methods are a preferrable approach when the trend and seasonal
    components dominate the series.
    
    The seasonal and trend components are written to the file
    DPST1F.DAT (dpst1f.dat on Unix systems) and can be read
    back into Dataplot for further plotting and analysis.  The
    internal variable RES contains the residual component and
    the internal variable PRED contains the trend plus the
    seasonality component.  The sample program below demonstrates
    a common plot for displaying these components.

    The SEASONAL LOWESS command accepts a number of options
    which can be defined by LET commands.  The most important is
    the PERIOD parameter which identifies the number of seasons
    (e.g., 12 for monthly data).  PERIOD defaults to 12.  The
    STLWIDTH parameter identifies the number of data points to use
    in the LOWESS steps and defaults to N/10.  It is similar to
    specifying the LOWESS FRACTION for standard LOWESS smoothing.
    The more points used, the more smoothing that occurs.  The
    STLSDEG and STLTDEG parameters identify the polynomial degree
    used in the lowess for the seasonal and trend components
    respectively.  By default, the
    seasonal lowess performs some robustness iterations.  Enter

       LET STLROBST = 1 to suppress this.

    The mathematical details of this technique is described in

       Cleveland, Cleveland, McRae, and Terpenning, "STL: A
       Seasonal-Trend Decomposition Procedure Based on Loess",
       Statistics Research Report, AT&T Bell Laboratories.

    Dataplot uses the source code provided by these authors to
    implement the SEASONAL LOWESS command.
 
Syntax:
    LET PERIOD = <value>
    LET STLWIDTH = <value>
    LET STLSDEG = <0/1/2>
    LET STLTDEG = <0/1/2>
    LET STLROBST = <0/1>
    SEASONAL LOWESS   <y>   <SUBSET/EXCEPT/FOR qualification>
    READ DPST1F.DAT SEAS TREND
    where <y> is the variable containing the raw data for which
              a seasonal lowess is to be performed;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The LET commands are described in the Description section
    above.  The READ DPST1F.DAT command is used to read the 
    seasonal and trend components back into Dataplot.

Examples:
    LET PERIOD = 12
    LET STLWIDTH = 24
    LET STLSDEG = 1
    LET STLTDEG = 1
    LET STLROBST = 0
    SEASONAL LOWESS Y
 
Default:
    There is no default for the SEASONAL LOWESS command itself.
    The defaults for the various LET commands are given in the
    Description section.
 
Synonyms:
    SEASONAL LOESS is a synonym for SEASONAL LOWESS.
 
Related Commands:
    LOWESS SMOOTH      = Perform a lowess smooth.
    ARMA               = Perform an ARMA fit.
    FIT                = Carries out a least squares fit.
 
Reference:
    "STL: A Seasonal-Trend Decomposition Procedure Based on Loess",
    Cleveland, Cleveland, McRae, and Terpenning, Statistics
    Research Report, AT&T Bell Laboratories.

    "Visualizing Data", Cleveland, William S., Hobart Press, 1993.
 
Applications:
    Robust Time Series Analysis
 
Implementation Date:
    2000/1
 
Program:
    skip 25
    read mlco2mon.dat co2 date year month
    .
    .  Perform Seasonal Lowess
    .
    let period = 12
    let stlsdeg = 1
    let stltdeg = 1
    seasonal lowess co2
    skip 0
    read dpst1f.dat seas trend
    .
    .  Generate plot
    .
    multiplot 4 1
    multiplot scale factor 3
    multiplot corner coordinates 0 10 100 95
    frame corner coordinates 15 0 85 100
    xlimits 0 150
    tic offset units data
    xtic offset 0 15
    major xtic mark number 4
    xtic marks off
    xtic mark labels off
    .
    ylimits 320 360
    major ytic mark number 5
    ytic offser 10 10
    y1label raw data
    plot co2
    y1label trend
    plot trend
    major ytic mark number 5
    ylimits -4 4
    ytic offser 0.5 0.5
    y1label seasonal
    plot seas
    y1label residuals
    x1tic marks on
    x1tic mark labels on
    plot res
    end of multiplot
    .
    justification center
    move 50 97
    text SEASONAL LOWESS DECOMPOSITION FOR CO2 CONCENTRATIONS
 
-----SEASONAL SUBSERIES PLOT--------------------------------------
 
SEASONAL SUBSERIES PLOT
 
Name:
    SEASONAL SUBSERIES PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a seasonal subseries plot.
 
Description:
    A seasonal subseries plot is used to determine if there is
    significant seasonality in a time series.  Instead of a straight
    time order plot, it splits the plot into the corresponding
    seasons (or periods).  For example, for monthly data, all the
    January values are plotted, then all the February values, and
    so on.  Reference lines are drawn at the seasonal means.
 
Syntax:
    LET PERIOD = <value>
    LET START = <value>
    SEASONAL SUBSERIES PLOT  <y>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the variable of raw data values for which the
              the seasonal subseries will be plotted;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The LET command is uses to define the period (e.g., the period
    for monthly data is typically 12) and the start value.   The
    start value is used when the data do not start in the first
    unit of the period (e.g., if you have monthly data that starts
    in March instead of January, you would use LET START = 3).
 
 
Examples:
    LET PERIOD = 12
    LET START = 3
    SEASONAL SUBSERIES PLOT Y
 
    LET PERIOD = 4
    LET START = 1
    SEASONAL SUBSERIES PLOT Y
 
Note:
    The sample program below shows how to use various plot control
    commands to label the plot.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RUN SEQUENCE PLOT     = Generates a run sequence plot.
    SPECTRAL PLOT         = Generate a spectral plot.
    AUTOCORRELATION PLOT  = Generate an autocorrelation plot.
    ARMA                  = Fit an ARMA model.
    SEASONAL LOWESS       = Generate a lowess based trend/seasonality/
                            residual decomposition of a time series.
 
Reference:
    "Visualizing Data", Cleveland, William S., Hobart Press, 1993.
 
Applications:
    Time Series Analysis
 
Implementation Date:
    2000/1
 
Program:
    skip 25
    read mlco2mon.dat co2 date year month
    .
    .  Linear Fit to Detrend Data
    .
    fit co2 date
    let co2res = res
    .
    .  Seasonal Subseries Plot
    .
    xlimits 7 167
    xtic offset 7 7
    major xtic mark number 12
    minor xtic mark number 0
    x1tic mark label format alpha
    x1tic mark label content Jan Feb Mar Apr May June July Aug Sep ...
    Oct Nov Dec
    x1label Month
    y1label CO2 Concentrations
    let period = 12
    let start = 5
    title Seasonal Subseries Plot of CO2 Concentrations
    seasonal subseries plot co2res
 
-----SEC (LET)---------------------------------------------------
 
SEC
 
Name:
    SEC (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the secant (the reciprocal of the cosine) for a variable or
    parameter.
 
Description:
    The secant is defined for all real numbers except PI/2 +/- K*PI
    where K is an integer.  The range is 1 to plus infinity and -1 to
    negative infinity.  By default, the angle is specified in radian
    units.  To use degree values, enter the command ANGLE UNITS DEGREES
    (ANGLE UNITS RADIANS resets it).
 
Syntax:
    LET <y2> = SEC(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed secant value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SEC(-2)
    LET A = SEC(A1)
    LET X2 = SEC(X1)
    LET X2 = SEC(PI/2)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SIN      = Compute the sine.
    COS      = Compute the cosine.
    TAN      = Compute the tangent.
    COT      = Compute the cotangent.
    CSC      = Compute the cosecant.
    ARCCOS   = Compute the arccosine.
    ARCSIN   = Compute the arcsine.
    ARCTAN   = Compute the arctangent.
    ARCCOT   = Compute the arccotangent.
    ARCSEC   = Compute the arcsecant.
    ARCCSC   = Compute the arcsecant.
 
Reference:
    Consult any standard trigonometry or pre-calculus textbook.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    TITLE PLOT SECANT FROM -3.1 TO 3.1
    X1LABEL ANGLE (IN RADIANS)
    Y1LABEL SECANT VALUE
    READ X Y TAG
    -3.1   1   1
     3.1   1   1
    -3.1  -1   2
     3.1  -1   2
     1.57  20  3
     1.57 -20  3
    -1.57  20  4
    -1.57 -20  4
    END OF DATA
    YLIMITS -20 20
    XLIMITS -3 3
    XTIC OFFSET .4 .4
    LINES SOLID SOLID SOLID SOLID DOT DOT DOT DOT DOT
    PLOT SEC(X) FOR X = .01 .01 1.56 AND
    PLOT SEC(X) FOR X = 1.58 .01 3.10 AND
    PLOT SEC(X) FOR X =- .01 -.01 -1.56 AND
    PLOT SEC(X) FOR X = -1.58 -.01 -3.10 AND
    PLOT Y X TAG
 
-----SECH (LET)---------------------------------------------------
 
SECH
 
Name:
    SECH (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the hyperbolic secant for a variable or parameter.
 
Description:
    The equation for the hyperbolic secant is:
        sech(x) = 1/(e**x + e**-x)
    The hyperbolic secant is defined for all real numbers.  The range is
    zero to one.
 
Syntax:
    LET <y2> = SECH(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed hyperbolic secant value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SECH(-2)
    LET A = SECH(A1)
    LET X2 = SECH(X1)
    LET X2 = SECH(PI/2)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SIN      = Compute the sine.
    COS      = Compute the cosine.
    TAN      = Compute the tangent.
    COT      = Compute the cotangent.
    SEC      = Compute the secant.
    CSC      = Compute the cosecant.
    ARCCOS   = Compute the arccosine.
    ARCSIN   = Compute the arcsine.
    ARCTAN   = Compute the arctangent.
    ARCCOT   = Compute the arccotangent.
    ARCSEC   = Compute the arcsecant.
    ARCCSC   = Compute the arcsecant.
    SINH     = Compute the hyperbolic sine.
    COSH     = Compute the hyperbolic cosine.
    TANH     = Compute the hyperbolic tangent.
    COTH     = Compute the hyperbolic cotangent.
    SECH     = Compute the hyperbolic secant.
    CSCH     = Compute the hyperbolic cosecant.
    ARCCOSH  = Compute hyperbolic arccosine.
    ARCCOTH  = Compute hyperbolic arccotangent.
    ARCCSCH  = Compute hyperbolic arccosecant.
    ARCSECH  = Compute hyperbolic arcsecant.
    ARCSINH  = Compute hyperbolic arcsine.
    ARCTANH  = Compute hyperbolic arctangent.
 
Applications:
    Trigonometry
 
Implementation Date:
    Pre-1987
 
Program:
    TITLE AUTOMATIC
    PLOT SECH(X) FOR X = -3.1 .05 3.1
 
-----SDECDF (LET)--------------------------------
 
SDECDF
 
Name:
    SDECDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the skew double exponential cumulative distribution
    function.
 
Description:
    The skew double exponential distribution has the following
    cumulative distribution function:

       F(x,lambda)=0.5*EXP((1+lambda)*x)/(1+LAMBDA)
                                                  - infinity < x <= 0
                  =1 + EXP(-x) - 0.5/(EXP((1+lambda)*x)*(-1-lambda))
                                                  0 < x < infinity
                                                  lambda >= 0
 
    For lambda = 0, the skew double exponential reduces to the
    double exponential distribution.  As lambda goes to infinity,
    the skew double exponential tends to the exponential
    distribution.
 
    The standard skew double exponential distribution can be
    generalized with location and scale parameters.

    The skew double exponential distribution is also known as
    the skew Laplace distribution.

Syntax:
    LET <y> = SDECDF(<x>,<lambda>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <lambda> is a number of parameter that specifies the
              value of the shape parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <scale> is an optional positive number or parameter that
              specifies the value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed skew double exponential cdf value
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y = SDECDF(3,1)
    LET Y = SDECDF(X1,LAMBDA)
    PLOT SDECDF(X,LAMBDA) FOR X = -5 0.1 5
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SDEPDF = Compute the skew double exponential probability density
             function.
    SDEPPF = Compute the skew double exponential percent point
             function.
    ADEPDF = Compute the asymmetric double exponential probability density
             function.
    DEXCDF = Compute the double exponential probability density
             function.
    EXPCDF = Compute the exponential probability density function.
    SNCDF  = Compute the skew normal probability density function.
    STCDF  = Compute the skew t probability density function.
 
Reference:
    "The Laplace Distribution and Generalizations: A Revisit with
    Applications to Communications, Economics, Engineering, and
    Finance", Birkhauser, 2001, p. 136.
 
    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

Applications:
    Distributional Modeling
 
Implementation Date:
    6/2004
 
Program:
    Y1LABEL Probability
    X1LABEL X
    LABEL CASE ASIS
    TITLE CASE ASIS
    CASE ASIS
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    TITLE Lambda = 0
    PLOT SDECDF(X,0) FOR X = -5 0.1 5
    TITLE Lambda = 1
    PLOT SDECDF(X,1) FOR X = -5 0.1 5
    TITLE Lambda = 5
    PLOT SDECDF(X,5) FOR X = -5 0.1 5
    TITLE Lambda = 10
    PLOT SDECDF(X,10) FOR X = -5 0.1 5
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATIONC CENTER
    TEXT Skew Double Exponential Distribution
 
-----SDEPDF (LET)--------------------------------
 
SDEPDF
 
Name:
    SDEPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the skew double exponential probability density
    function.
 
Description:
    The skew double exponential distribution has the following
    probability density function:

       f(x,lambda)=0.5*EXP((1+lambda)*x)     - infinity < x <= 0
                  =EXP(-x) - 0.5*EXP(-(1+lambda)*x)  0 < x < infinity
                                             lambda >= 0
 
    For lambda = 0, the skew double exponential reduces to the
    double exponential distribution.  As lambda goes to infinity,
    the skew double exponential tends to the exponential
    distribution.
 
    The standard skew double exponential distribution can be
    generalized with location and scale parameters.

    The skew double exponential distribution is also known as
    the skew Laplace distribution.

Syntax:
    LET <y> = SDEPDF(<x>,<lambda>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <lambda> is a number of parameter that specifies the
              value of the shape parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <scale> is an optional positive number or parameter that
              specifies the value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed skew double exponential pdf value
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y = SDEPDF(3,1)
    LET Y = SDEPDF(X1,LAMBDA)
    PLOT SDEPDF(X,LAMBDA) FOR X = -5 0.01 5
 
Note:
    To generate skew double exponential random numbers, enter
    the commands

        LET LAMBDA = <value>
        LET Y = SKEW DOUBLE EXPONENTIAL RANDOM NUMBERS FOR I = 1 1 N

    To generate a skew double exponential probability plot or a
    skew double exponential Kolmogorov-Smirnov or chi-square
    goodness of fit test, enter the following commands

        LET LAMBDA = <value>
        SKEW DOUBLE EXPONENTIAL PROBABILITY PLOT Y
        SKEW DOUBLE EXPONENTIAL KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
        SKEW DOUBLE EXPONENTIAL CHI-SQUARE GOODNESS OF FIT Y
       
    To generate a PPCC or Kolmogorov-Smirnov plot, enter the
    following commands

        LET LAMBDA1 = <value>
        LET LAMBDA2 = <value>
        SKEW DOUBLE EXPONENTIAL PPCC PLOT Y
        SKEW DOUBLE EXPONENTIAL KS PLOT Y

    The default values for LAMBDA1 and LAMBDA2 are 0 and 10.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    SKEW LAPLACE is a synonym for SKEW DOUBLE EXPONENTIAL
 
Related Commands:
    SDECDF = Compute the skew double exponential cumulative
             distribution function.
    SDEPPF = Compute the skew double exponential percent point
             function.
    ADEPDF = Compute the asymmetric double exponential probability density
             function.
    DEXPDF = Compute the double exponential probability density
             function.
    EXPPDF = Compute the exponential probability density function.
    SNPDF  = Compute the skew normal probability density function.
    STPDF  = Compute the skew t probability density function.
 
Reference:
    "The Laplace Distribution and Generalizations: A Revisit with
    Applications to Communications, Economics, Engineering, and
    Finance", Birkhauser, 2001, p. 136.
 
    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

Applications:
    Distributional Modeling
 
Implementation Date:
    6/2004
 
Program:
    Y1LABEL Probability
    X1LABEL X
    LABEL CASE ASIS
    TITLE CASE ASIS
    CASE ASIS
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    TITLE Lambda = 0
    PLOT SDEPDF(X,0) FOR X = -5 0.1 5
    TITLE Lambda = 1
    PLOT SDEPDF(X,1) FOR X = -5 0.1 5
    TITLE Lambda = 5
    PLOT SDEPDF(X,5) FOR X = -5 0.1 5
    TITLE Lambda = 10
    PLOT SDEPDF(X,10) FOR X = -5 0.1 5
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATIONC CENTER
    TEXT Skew Double Exponential Distribution
 
-----SDEPPF (LET)--------------------------------
 
SDEPPF
 
Name:
    SDEPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the skew double exponential percent point function.
 
Description:
    The skew double exponential distribution has the following
    probability density function:

       f(x,lambda)=0.5*EXP((1+lambda)*x)     - infinity < x <= 0
                  =EXP(-x) - 0.5*EXP(-(1+lambda)*x)  0 < x < infinity
                                             lambda >= 0
 

    To compute the percent point function, Dataplot computes
    the cumulative distribution function for X = 0.  If this
    value is PCUT and P is the input probability value, then

        G(p,lambda) = LOG[2*p*(1-lambda)]/(1+lambda)]  p <= PCUT

    If P is greater than PCUT, then Dataplot computes the percent
    point function by numerically inverting the cumulative
    distribution function.
       
    For lambda = 0, the skew double exponential reduces to the
    double exponential distribution.  As lambda goes to infinity,
    the skew double exponential tends to the exponential
    distribution.
 
    The standard skew double exponential distribution can be
    generalized with location and scale parameters.

    The skew double exponential distribution is also known as
    the skew Laplace distribution.

Syntax:
    LET <y> = SDEPPF(<p>,<lambda>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, a number or a parameter in the
              interval (0,1);
          <lambda> is a number of parameter that specifies the
              value of the shape parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <scale> is an optional positive number or parameter that
              specifies the value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed skew double exponential ppf value
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SDEPPF(0.95,1)
    LET X = SDEPPF(P1,LAMBDA)
    PLOT SDEPPF(P,LAMBDA) FOR P = 0.01 0.01 0.99
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SDECDF = Compute the skew double exponential cumulative
             distribution function.
    SDEPDF = Compute the skew double exponential probability density
             function.
    ADEPDF = Compute the asymmetric double exponential probability density
             function.
    DEXPDF = Compute the double exponential probability density
             function.
    EXPPDF = Compute the exponential probability density function.
    SNPDF  = Compute the skew normal probability density function.
    STPDF  = Compute the skew t probability density function.
 
Reference:
    "The Laplace Distribution and Generalizations: A Revisit with
    Applications to Communications, Economics, Engineering, and
    Finance", Birkhauser, 2001, p. 136.
 
    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

Applications:
    Distributional Modeling
 
Implementation Date:
    6/2004
 
Program:
    X1LABEL Probability
    Y1LABEL X
    LABEL CASE ASIS
    TITLE CASE ASIS
    X1LABEL DISPLACEMENT 12
    CASE ASIS
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    TITLE Lambda = 0
    PLOT SDEPPF(P,0) FOR P = 0.01 0.01 0.99
    TITLE Lambda = 1
    PLOT SDEPPF(P,1) FOR P = 0.01 0.01 0.99
    TITLE Lambda = 5
    PLOT SDEPPF(P,5) FOR P = 0.01 0.01 0.99
    TITLE Lambda = 10
    PLOT SDEPPF(P,10) FOR P = 0.01 0.01 0.99
    END OF MULTIPLOT
    MOVE 50 97
    JUSTIFICATIONC CENTER
    TEXT Skew Double Exponential Distribution
 
-----SEED-------------------------------------------------------
 
SEED
 
Name:
    SEED
 
Type:
    Support Command
 
Purpose:
    Specify the seed for random number generation.
 
Description:
    Each distinct seed generates a different sequence of random numbers
    (the seed allows the random number generator to duplicate the same
    sequence of random numbers).
 
    Dataplot supports several different random number generators.
    The desired generator can be set with the command

        SET RANDOM NUMBER GENERATOR <generator>

    where <generator> is one of the following:
 
        FIBONACCI
        LINEAR CONGRUENTIAL
        MULTIPLICATIVE CONGRUENTIAL
        GFSR
        FUSHIMI
        AS183
        GENZ
        LUXURY
        FIBONACCI CONGRUENTIAL

    The deault generator is the FIBONACCI CONGRUENTIAL generator
    (the default prior to 2018/05 was the FIBONACCI generator).

    The seed value applies to the following generators

        FIBONACCI
        FIBONACCI CONGRUENTIAL
        MULTIPLICATIVE CONGRUENTIAL
        AS183

    For the FIBONACCI and FIBONACCI CONGRUENTIAL generators, the
    minimum seed value should be 305 and the seed should be an
    odd number.  Values of the seed less than 305 are equivalent
    to 305 and even values of the seed are equivalent to the
    nearest odd number.

    For the other generators, if you want to obtain a different
    sequence of random numbers you can do something like the
    following

        LET ISKIP = 50000
        LET NRAND = 10000
        LET YJUNK = UNIFORM RANDOM NUMBERS FOR I = 1 1 ISKIP
        LET Y = UNIFORM RANDOM NUMBERS FOR I = 1 1 NRAND

    This example will first generate 50,000 random numbers that
    will not be used.  It then generates 10,000 random numbers
    that will be used.  To obtain a different sequence of random
    numbers, modify the value of ISKIP.

Syntax:
    SEED    <iseed>
    where <iseed> is an integer number or parameter that defines the
               seed.
 
Examples:
    SEED 55671
    SEED DEFAULT
 
Note:
    To return the current value of the seed, enter

        PROBE SEED

Default:
    305 (Pre-2019/03)
    3005 (2019/03)
 
Synonyms:
    None
 
Related Commands:
    RANDOM NUMBERS (LET)  = Generate random numbers for various
                            distributions..
 
Applications:
    Random Number Generation
 
Implementation Date:
    Pre-1987
 
Program:
    SEED 4021
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    SEED 34201
    LET Y2 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    SEED 19793
    LET Y3 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    SEED 46987
    LET Y4 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LINE COLOR BLACK BLUE RED GREEN
    MULTIPLE KERNEL DENSITY PLOT Y1 Y2 Y3 Y4
 
-----SEGMENT COLOR----------------------------------------------------
 
SEGMENT COLOR
 
Name:
    SEGMENT ... COLOR
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the color for the line segments to appear on subsequent
    plots.
 
Description:
    Segments are straight lines that the analyst can position anywhere
    on the plot.  The segments appear on all subsequent plots until
    blanked out or overridden with new segment coordinates.  The
    segment colors hold for all subsequent plots until defaulted or
    overridden with new colors.  Up to 100 such line segments can be
    specified.
 
    Segments are most typically used in legend boxes to identify
    curves.
 
    Dataplot provides two methods for specifying colors.

        1. Colors can be defined by name (or by the corresponding index).
           Dataplot adopted it's named colors from the X11 project.
           Currently, 162 named colors and 100 levels of grayscale are
           supported.  Grayscale can be specified with either G0, G1, ...,
           G100 (or -1, -2, ..., -100).  Many older devices support only a
           limited number of colors.  For these devices, unsupported colors
           will be mapped to one of the available colors.  To specify a
           named color, see Syntax 1.

        2. Most modern graphics devices support full RGB (RedBlueGreen)
           color.  You can alternatively specify RGB colors by entering
           three integer values to represent the Red, Green and Blue
           components, respectively.  These values should be in the range
           0 to 255.

    When setting the segment RGB color, Dataplot first checks if the
    device supports RGB colors. If not, the named color will be used.
    If the device does support RGB color, Dataplot will check if an RGB
    color has been specified.  If yes, then that RGB color is used.  If
    not, the named color will be used.

    To see the list of supported named colors (with the associated index
    number), see

    https://www.itl.nist.gov/div898/software/dataplot/refman1/ch11/homepage.htm

Syntax 1:
    SEGMENT  <id>  COLOR  <color>
    where <id> is an integer number or parameter in the range 1 to 100
            that specifies the segment identifier;
    and   <color> is a character string or index number that specifies
            the desired color.
 
Syntax 2:
    SEGMENT  <id>  RGB COLORS <red> <green> <blue>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the segment identifier;
          <red> is a number or parameter that specifies the red
              component;
          <green> is a number or parameter that specifies the green
              component;
          <blue> is a number or parameter that specifies the blue
              component.

    To turn off the RGB color, set the values to -1 (any negative value
    will work).  Values greater than 255 will be set to 255.
 
Examples:
    SEGMENT 2 COLOR GREEN
    SEGMENT 2 COLOR BLUE
 
Note:
    A SEGMENT ... COLOR command with no arguments reverts the line
    segment color to default; thus SEGMENT 1 COLOR with no arguments
    reverts the color for line segment 1 to default.  A SEGMENT ...
    COLOR command with no <id> refers to all 100 line segments; thus
    SEGMENT COLOR GREEN assigns the color green to all 100 line
    segments.  SEGMENT COLOR with no <id> and no arguments reverts the
    color to default for all 100 line segments.
 
Default:
    All line segments are drawn in black.
 
Synonyms:
    None
 
Related Commands:
    SEGMENT COORDINATES    = Specify a segment location.
    SEGMENT PATTERN        = Specify the line type for a segment.
    SEGMENT THICKNESS      = Specify the line thickness for a segment.
    LEGEND                 = Specify a legend for a subsequent plot.
    ARROW COORDINATES      = Specify the location of an arrow.
    BOX COORDINATES        = Specify the location of a box.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
    2020/11: Support for RGB colors
 
Program 1:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    LET N = SIZE LEAD; LET X = SEQUENCE 1 1 N
    .
    LINE COLOR RED BLUE
    LINE THICKNESS 0.3 ALL
    SEGMENT 1 COORDINATES 17 87 22 87
    SEGMENT 2 COORDINATES 17 83 22 83
    SEGMENT 1 COLOR RED
    SEGMENT 2 COLOR BLUE
    SEGMENT THICKNESS 0.3
    LEGEND 1 COORDINATES 23 86
    LEGEND 1 POTASSIUM
    LEGEND 2 COORDINATES 23 82
    LEGEND 2 LEAD
    TITLE DEMONSTRATE SEGMENT COLOR
    PLOT POT LEAD VS X
 
Program 2:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    LET N = SIZE LEAD; LET X = SEQUENCE 1 1 N
    .
    LINE COLOR RED BLUE
    LINE RGB COLOR 220 109 88 175 238 238
    LINE THICKNESS 0.3 ALL
    SEGMENT 1 COORDINATES 17 87 22 87
    SEGMENT 2 COORDINATES 17 83 22 83
    SEGMENT 1 COLOR RED
    SEGMENT 2 COLOR BLUE
    SEGMENT 1 RGB COLOR 220 109 88
    SEGMENT 2 RGB COLOR 175 238 238
    SEGMENT THICKNESS 0.3
    LEGEND 1 COORDINATES 23 86
    LEGEND 1 POTASSIUM
    LEGEND 2 COORDINATES 23 82
    LEGEND 2 LEAD
    TITLE DEMONSTRATE SEGMENT RGB COLOR
    PLOT POT LEAD VS X
 
-----SEGMENT COORDINATES----------------------------------------------
 
SEGMENT COORDINATES
 
Name:
    SEGMENT ... COORDINATES
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the location of a line segment to appear on subsequent
    plots.
 
Description:
    Segments are straight lines that the analyst can position anywhere
    on the plot.  The segments appear on all subsequent plots until
    blanked out or overridden with new segment coordinates.  The
    segment colors hold for all subsequent plots until defaulted or
    overridden with new colors.  Up to 100 such line segments can be
    specified.
 
    The SEGMENT COORDINATES command defines the (x,y) values for the
    start and the end points respectively of the line segment.
 
    Segments are most typically used in legend boxes to identify
    curves.
 
Syntax:
    SEGMENT  <id>  COORDINATES  <x1>  <y1>  <x2>  <y2>
    where <id> is an integer number or parameter in the range 1 to 100
              that specifies the segment identifier;
          <x1> is a number or parameter in the decimal range 0 to 100
              that specifies the x coordinate of the start point;
          <y1> is a number or parameter in the decimal range 0 to 100
              that specifies the y coordinate of the start point;
          <x2> is a number or parameter in the decimal range 0 to 100
              that specifies the x coordinate of the stop point;
    and   <y2> is a number or parameter in the decimal range 0 to 100
              that specifies the y coordinate of the stop point.
 
Examples:
    SEGMENT 2 COORDINATES 20 80 60 60
    SEGMENT 2 COORDINATES 20 60 40 80
 
Note:
    A SEGMENT ... COORDINATES command with no arguments omits the line
    segment from subsequent plots; thus SEGMENT 1 COORDINATES with no
    arguments omits line segment 1 from subsequent plots.  A SEGMENT
    ... COORDINATES command with no <id> refers to all 100 line
    segments; thus SEGMENT COORDINATES 30 80 40 60 assigns the
    coordinates (30,80) and (40,60) to all 100  line segments (but
    this has no practical use).  SEGMENT COORDINATES with no <id> and
    no arguments omits all 100 line segments from subsequent plots.
 
Default:
    No line segments are drawn.
 
Synonyms:
    None
 
Related Commands:
    SEGMENT COLOR          = Specify the color for a segment.
    SEGMENT PATTERN        = Specify the line type for a segment.
    SEGMENT THICKNESS      = Specify the line thickness for a segment.
    LEGEND                 = Specify a legend for a subsequent plot.
    LEGEND COORDINATES     = Specify the location of a legend for a
                             subsequent plot.
    ARROW COORDINATES      = Specify the location of an arrow.
    BOX COORDINATES        = Specify the location of a box.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    LET N = SIZE LEAD; LET X = SEQUENCE 1 1 N
    .
    LINE SOLID DASH
    SEGMENT 1 COORDINATES 17 87 22 87
    SEGMENT 2 COORDINATES 17 83 22 83
    SEGMENT 2 PATTERN DASH
    LEGEND 1 COORDINATES 23 86; LEGEND 1 POTASSIUM
    LEGEND 2 COORDINATES 23 82; LEGEND 2 LEAD
    TITLE SEGMENT COORDINATES COMMAND
    PLOT POT LEAD VS X
 
-----SEGMENT PATTERN-------------------------------------------------
 
SEGMENT PATTERN
 
Name:
    SEGMENT ... PATTERN
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the line pattern for the line segments to appear on
    subsequent plots.
 
Description:
    Segments are straight lines that the analyst can position anywhere
    on the plot.  The segments appear on all subsequent plots until
    blanked out or overridden with new segment coordinates.  The
    segment colors hold for all subsequent plots until defaulted or
    overridden with new colors.  Up to 100 such line segments can be
    specified.
 
    Segments are most typically used in legend boxes to identify
    curves.
 
Syntax:
    SEGMENT   <id>   PATTERN  <pattern>
    where <id> is an integer number or parameter in the range 1 to 100
             that specifies the segment identifier;
    and   <pattern> is a character string that specifies the desired
             line pattern.
 
Examples:
    SEGMENT 2 PATTERN SOLID
    SEGMENT 2 PATTERN DASH
 
Note:
    A SEGMENT ... PATTERN command with no arguments reverts the line
    segment pattern to default; thus SEGMENT 1 PATTERN with no
    arguments reverts the pattern for line segment 1 to default.  A
    SEGMENT ... PATTERN command with no <id> refers to all 100 line
    segments; thus SEGMENT PATTERN SOLID assigns the pattern solid to
    all 100 line segments.  SEGMENT PATTERN with no <id> and no
    arguments reverts the pattern to default for all 100 line segments.
 
Default:
    All segments are drawn with solid lines.
 
Synonyms:
    None
 
Related Commands:
    SEGMENT COLOR          = Specify the color for a segment.
    SEGMENT COORDINATES    = Specify a segment location.
    SEGMENT THICKNESS      = Specify the line thickness for a segment.
    LEGEND                 = Specify a legend for a subsequent plot.
    ARROW COORDINATES      = Specify the location of an arrow.
    BOX COORDINATES        = Specify the location of a box.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    LET N = SIZE LEAD; LET X = SEQUENCE 1 1 N
    .
    LINE DASH DOT
    SEGMENT 1 COORDINATES 17 87 22 87
    SEGMENT 2 COORDINATES 17 83 22 83
    SEGMENT 1 PATTERN DASH
    SEGMENT 2 PATTERN DOT
    LEGEND 1 COORDINATES 23 86; LEGEND 1 POTASSIUM
    LEGEND 2 COORDINATES 23 82; LEGEND 2 LEAD
    TITLE SEGMENT COORDINATES COMMAND
    PLOT POT LEAD VS X
 
-----SEGMENT THICKNESS-------------------------------------------------
 
SEGMENT THICKNESS
 
Name:
    SEGMENT ... THICKNESS
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the thickness for the line segments to appear on
    subsequent plots.
 
Description:
    Segments are straight lines that the analyst can position anywhere
    on the plot.  The segments appear on all subsequent plots until
    blanked out or overridden with new segment coordinates.  The
    segment colors hold for all subsequent plots until defaulted or
    overridden with new colors.  Up to 100 such line segments can be
    specified.
 
    The thickness is specified in DATAPLOT 0 to 100 coordinates (i.e.,
    as a percentage of the vertical device size).  A value of 0.1
    yields a single line width on most devices.  Typical values are
    between 0.05 and 0.3.
 
    Segments are most typically used in legend boxes to identify
    curves.
 
Syntax:
    SEGMENT   <id>   THICKNESS   <thickness>
    where <id> is an integer number or parameter in the range 1 to 100
            that specifies the segment identifier;
    and   <thickness> is a decimal number or parameter in the range 0
              to 100 that specifies the desired line thickness.
 
Examples:
    SEGMENT 2 THICKNESS 0.2
    SEGMENT 2 THICKNESS 0.3
 
Note:
    A SEGMENT ... THICKNESS command with no arguments reverts the line
    segment thickness to default; thus SEGMENT 1 THICKNESS with no
    arguments reverts the thickness for line segment 1 to default.  A
    SEGMENT ... THICKNESS command with no <id> refers to all 100 line
    segments; thus SEGMENT THICKNESS 0.2 assigns the thickness 0.2 to
    all 100 line segments.  SEGMENT THICKNESS with no <id> and no
    arguments reverts the thickness to default for all 100 line
    segments.
 
Default:
    All segment line thicknesses are 0.1.
 
Synonyms:
    None
 
Related Commands:
    SEGMENT COLOR          = Specify the color for a segment.
    SEGMENT COORDINATES    = Specify a segment location.
    SEGMENT PATTERN        = Specify the line type for a segment.
    LEGEND                 = Specify a legend for a subsequent plot.
    ARROW COORDINATES      = Specify the location of an arrow.
    BOX COORDINATES        = Specify the location of a box.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    XX
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    SERIAL READ LEAD
    164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    END OF DATA
    SERIAL READ POT
    106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    END OF DATA
    LET N = SIZE LEAD; LET X = SEQUENCE 1 1 N
    .
    LINE THICKNESS 0.1 0.3
    SEGMENT 1 COORDINATES 17 87 22 87
    SEGMENT 2 COORDINATES 17 83 22 83
    SEGMENT 1 THICKNESS 0.1
    SEGMENT 2 THICKNESS 0.3
    LEGEND 1 COORDINATES 23 86; LEGEND 1 POTASSIUM
    LEGEND 2 COORDINATES 23 82; LEGEND 2 LEAD
    TITLE DEMONSTRATE SEGMENT THICKNESS
    PLOT POT LEAD VS X
 
-----SEMCDF (LET)--------------------------------
 
SEMCDF
 
Name:
    SEMCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the semi-circular cumulative distribution function.
 
Description:
    The semi-circular distribution is the distribution onto one axis
    of the points uniformly distributed within the unit circle.  As
    such, it is useful for testing 2-dimensional uniformity.

    The formula for the cumulative distribution function is:

       F(x;mu,r) = 0.5 + x*SQRT(r**2 - (x-mu)**2)/(PI*r**2) +
                   ARCSIN((x-mu)/r)/PI
                   -r <= x <= r
 
    with mu and r denoting the location and scale parameters,
    respectively.

    The case where mu = 0 and r = 1 is referred to as the
    standard semi-circular distribution.

Syntax:
    LET <y> = SEMCDF(<x>,<mu>,<r>)    <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, number, or parameter;
          <mu> is a variable, number, or parameter that specifies
               the location parameter;
          <r> is a variable, number, or parameter that specifies
               the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed semi-circular cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <mu> and <r> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = SEMCDF(0.5)
    LET A = SEMCDF(0.5,0,5)
    LET X2 = SEMCDF(X1)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SEMPDF = Compute the semi-circular probability density function.
    SEMPPF = Compute the semi-circular percent point function.
    UNIPDF = Compute the uniform probability density function.
    UNICDF = Compute the uniform cumulative distribution function.
    UNIPPF = Compute the uniform percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
 
Reference:
    "Continuous Univariate Distributions - 2", Johnson and Kotz,
    Houghton Mifflin, 1970 (chapter 25).
 
    "Simple and Robust Linear Estimation of the Location Parameter of
    a Symmetric Distribution", Filliben, unpublished Ph.d dissertation,
    Princeton University, 1969 (pp. 21-44, 229-231).
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/4: Implemented for the standard case
    2006/10: Implemented for the general case
 
Program:
    YLIMITS 0 1
    MAJOR YTIC NUMBER 6
    MINOR YTIC NUMBER 1
    YTIC DECIMAL 1
    XLIMITS -1 1
    XTIC OFFSET 0.1 0.1
    TITLE AUTOMATIC
    PLOT SEMCDF(X) FOR X = -1 0.01 1
 
-----SEMI CIRCLE-------------------------------------------------------
 
SEMI CIRCLE
 
Name:
    SEMI-CIRCLE
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Draws a semi-circle.
 
Description:
    The 2 pairs of coordinates define the (x,y) values for one end and
    the other end (respectively) of the diameter of the semi-circle.
 
Syntax:
    SEMI-CIRCLE   <x1>   <y1>   <x2>   <y2>
    where <x1> is a decimal number or parameter in the range 0 to 100
              that specifies the horizontal coordinate of one end;
          <y1> is a decimal number or parameter in the range 0 to 100
              that specifies the vertical coordinate of one end;
          <x2> is a decimal number or parameter in the range 0 to 100
              that specifies the horizontal coordinate of the other
              end;
    and   <y2> is a decimal number or parameter in the range 0 to 100
              that specifies the vertical coordinate of the other end.
 
Examples:
    SEMI-CIRCLE 50 50 60 60
    SEMI-CIRCLE 50 50 60 50
    SEMI-CIRCLE 20 20 30 30
    SEMI-CIRCLE 50 20 60 20
 
Note:
    The line style (i.e., solid, dash), color, and thickness are
    controlled by the LINE, LINE COLOR, and LINE THICKNESS commands.
    The REGION FILL command can be used to generate solid filled
    circles while the REGION PATTERN command can be used to generate
    hatch filled patterns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CIRCLE           = Draws a circle.
    POINT            = Draws a point.
    ARROW            = Draws an arrow.
    TRIANGLE         = Draws a triangle.
    BOX              = Draws a box.
    HEXAGON          = Draws a hexagon.
    SEMI-CIRCLE      = Draws a semi-circle.
    ARC              = Draws an arc.
    ELLIPSE          = Draws an ellipse.
    OVAL             = Draws an oval.
    DIAMOND          = Draws a diamond.
    DRAW             = Draws a line.
    MOVE             = Moves to a point.
    LINES            = Sets the line type for figures and plot lines.
    LINE THICKNESSES = Sets the line thickness for figures and  plot
                       lines.
    LINE COLOR       = Sets the line colors for figures and plot lines.
    CROSS-HAIR       = Activates and reads the cross-hair.
    TEXT             = Writes a text string.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    SEMI-CIRCLE 10 10 20 20
    SEMI-CIRCLE 60 10 80 30
    .
    THICKNESS 0.7
    SEMI-CIRCLE 10 30 20 40
    THICKNESS 0.2
    .
    LINE DASH
    SEMI-CIRCLE 10 50 20 60
    LINE SOLID
    .
    LINE COLOR G50
    SEMI-CIRCLE 10 80 20 90
    LINE COLOR BLACK
    .
    REGION FILL ON
    SEMI-CIRCLE 30 30 35 35
    REGION FILL COLOR G50
    SEMI-CIRCLE 40 40 60 60
    .
    REGION FILL COLOR BLACK
    REGION PATTERN D1D2
    REGION PATTERN SPACING 3
    SEMI-CIRCLE 75 60 90 72
 
-----SEMI INTERQUARTILE RANGE (LET)-------------------------------
 
SEMI INTERQUARTILE RANGE
LOWER SEMI INTERQUARTILE RANGE
UPPER SEMI INTERQUARTILE RANGE
 
Name:
    SEMI INTERQUARTILE RANGE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute either the lower semi-interquartile range or the upper
    semi-interquartile range for a variable.
 
Description:
    The interquartile range is:

        IQ = UPPER QUARTILE - LOWER QUARTILE

    That is, it is the difference betweeen the 75th and 25th
    percentiles of a variable.
 
    The lower semi-interquartile range is:

        SIQR(L) = q2 - q1

    and the upper semi-interquartile range is:

        SIQR(U) = q3 - q2

    with q1, q2, and q3 denoting the lower quartile, median, and
    upper quartile respectively.

    The semi-interquartile range is sometimes used in place of the
    interquartile range when there is significant skewness in the
    data.  For example, it can be used to provide an alternate
    definition of the fences in a box plot.

Syntax 1:
    LET <par> = LOWER SEMI INTERQUARTILE RANGE <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed lower semi-interquartile
               range is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <par> = UPPER SEMI INTERQUARTILE RANGE <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed upper semi-interquartile
               range is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = LOWER SEMI INTERQUARTILE RANGE Y1
    LET A = UPPER SEMI INTERQUARTILE RANGE Y1
    LET A = UPPER SEMI INTERQUARTILE RANGE Y1 SUBSER TAG > 2
    LET A = INTERQUARTILE RANGE Y1 SUBSET TAG > 2
 
Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

        HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    INTERQUARTILE RANGE    = Compute the interquartile range of a variable.
    BOX PLOT               = Generate a box plot.
 
References:
    Walker, Dovedo, Chakraborti and Hilton (2019), "An Improved Boxplot
    for Univariate Data". American Statistician, Vol. 72, No. 4,
    pp. 348-353.

Applications:
    Robust Data Analysis
 
Implementation Date:
    2019/08
 
Program:
    LET NU = 1
    LET Y = CHISQUARE RANDOM NUMBERS FOR I = 1 1 100
    LET SIQRL = LOWER SEMI INTERQUARTILE RANGE Y
    LET SIQRU = UPPER SEMI INTERQUARTILE RANGE Y
    PRINT SIQRL SIQRU

-----SEMPDF (LET)--------------------------------
 
SEMPDF
 
Name:
    SEMPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the semi-circular probability density function.
 
Description:
    The semi-circular distribution is the distribution onto one axis
    of the points uniformly distributed within the unit circle.  As
    such, it is useful for testing 2-dimensional uniformity.

    The probability density function for the semi-circular
    distribution is:

       f(x;mu,r) = 2*sqrt(r**2 - (x-mu)**2)/(PI*r**2)  -r <= x <= r

    with mu and r denoting the location and scale parameters,
    respectively.  The scale parameter, r, is the radius of
    the semi-circle (or ellipse if r not equal to 1).

    The case where mu = 0 and r = 1 is referred to as the
    standard semi-circular distribution and has the following
    probability density function:

       f(x) = 2*sqrt(1-x**2)/PI      -1 <= x <= 1

    This distribution has mean 0 and standard deviation r/2.
 
Syntax:
    LET <y> = SEMPDF(<x>,<mu>,<r>)    <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, number, or parameter;
          <mu> is a variable, number, or parameter that specifies
               the location parameter;
          <r> is a variable, number, or parameter that specifies
               the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed semi-circular pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <mu> and <r> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = SEMPDF(0.5)
    LET A = SEMPDF(1.2,0,5)
    LET X2 = SEMPDF(X1)

Note:
    Semi-circular random numbers, probability plots, and
    goodness of fit tests can be generated with the commands:

       LET Y = SEMI-CIRCULAR RANDOM NUMBERS FOR I = 1 1 N
       SEMI-CIRCULAR PROBABILITY PLOT Y
       SEMI-CIRCULAR PROBABILITY PLOT Y2 X2
       SEMI-CIRCULAR PROBABILITY PLOT Y3 XLOW XHIGH
       SEMI-CIRCULAR KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       SEMI-CIRCULAR CHI-SQUARE GOODNESS OF FIT Y2 X2
       SEMI-CIRCULAR CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    The location and scale estimates can be obtained from the
    probability plot (location = PPA0 and scale = PPA1).

    The BOOTSTRAP DISTRIBUTION command can be used to find
    uncertainty intervals for the location and scale parameters
    based on the probability plot.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SEMCDF = Compute the semi-circular cumulative distribution
             function.
    SEMPPF = Compute the semi-circular percent point function.
    UNIPDF = Compute the uniform probability density function.
    UNICDF = Compute the uniform cumulative distribution function.
    UNIPPF = Compute the uniform percent point function.
    NORCDF = Compute the normal cumulative distributoin function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
 
Reference:
    "Continuous Univariate Distributions - 2", Johnson and Kotz,
    Houghton Mifflin, 1970 (chapter 25).
 
    "Simple and Robust Linear Estimation of the Location Parameter of
    a Symmetric Distribution", Filliben, unpublished Ph.d dissertation,
    Princeton University, 1969 (pp. 21-44, 229-231).
 
Applications:
    Distributional Modeling
 
Implementation Date:
    94/4: Implemented for the standard case
    2006/10: Updated to support the general case
 
Program:
    XLIMITS -1 1
    XTIC OFFSET 0.1 0.1
    TITLE AUTOMATIC
    PLOT SEMPDF(X) FOR X = -1 0.01 1
 
-----SEMPPF (LET)--------------------------------
 
SEMPPF
 
Name:
    SEMPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the semi-circular percent point function.
 
Description:
    The semi-circular distribution has the following cumulative
    distribution function:

       F(x;mu,r) = 0.5 + x*SQRT(r**2 - (x-mu)**2)/(PI*r**2) +
                   ARCSIN((x-mu)/r)/PI
                   -r <= x <= r
 
    with mu and r denoting the location and scale parameters,
    respectively.

    The percent point function is computed by numerically
    inverting the cumulative distribution function.

Syntax:
    LET <y> = SEMPPF(<p>,<mu>,<r>)    <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, number, or parameter in the interval
              (0,1);
          <mu> is a variable, number, or parameter that specifies
               the location parameter;
          <r> is a variable, number, or parameter that specifies
               the scale parameter;
          <y> is a variable or a parameter (depending on what <p> is)
              where the computed semi-circular ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <mu> and <r> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = SEMPPF(0.99)
    LET A = SEMPPF(0.99,0,5)
    LET X2 = SEMPPF(X1)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SEMCDF = Compute the semi-circular cumulative distribution
             function.
    SEMPDF = Compute the semi-circular probability density function.
    UNIPDF = Compute the uniform probability density function.
    UNICDF = Compute the uniform cumulative distribution function.
    UNIPPF = Compute the uniform percent point function.
    NORCDF = Compute the normal cumulative distributoin function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
 
Reference:
    "Continuous Univariate Distributions - 2", Johnson and Kotz,
    Houghton Mifflin, 1970 (chapter 25).
 
    "Simple and Robust Linear Estimation of the Location Parameter of
    a Symmetric Distribution", Filliben, unpublished Ph.d dissertation,
    Princeton University, 1969 (pp. 21-44, 229-231).
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1994/4: Implemented for the standard case
    2006/10: Implemented for the general case
 
Program:
    XLIMITS 0 1
    MAJOR XTIC NUMBER 6
    MINOR XTIC NUMBER 1
    XTIC DECIMAL 1
    YLIMITS -1 1
    YTIC OFFSET 0.1 0.1
    TITLE AUTOMATIC
    PLOT SEMPPF(P) FOR P = 0  0.01  1
 
-----SEQUENCE-------------------------------------------------------
 
SEQUENCE
 
Name:
    SEQUENCE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Generate a sequence of values.
 
Description:
    This command is useful for generating variables that have constant
    increments.  Increments can be either positive or negative.
    Increments can also be real numbers (i.e., they are not restricted
    to integers).
 
    Specifically, you specify a start value, an increment, and
    a stop value.  You can also optionally specify a repeat factor
    (this defaults to 1 if not specified).

    The 2010/11 version of Dataplot updated this command to support
    variable arguments for the start, increment, stop, and repeat
    factors.  If more than one of these is a variable (as oppossed
    to a constant/parameter), then these variable must have the
    same length.  If a variable is used for one or more of the
    arguments, then we essentially create k separate sequences
    (where k is the number of elements in the variable) and
    append the results together.  Arguments that are entered as
    constants or parameters will use the same value for each sequence.

    In addition, a new syntax was added where the first argument
    is a list of values and the second argument is the number of
    times that each value is repeated.  This syntax is useful when
    you want to generate a simple sequence with repeat values
    where the number of repeats is variable.

    See the Note section below for some examples of using this new
    syntax.

Syntax 1:
    LET <resp> = SEQUENCE <start>  <inc>  <stop>
    where <start> is a constant, parameter, or variable that specifies
             the beginning value for the sequence;
          <inc> is a constant, parameter, or variable that specifies
             the increment value of the sequence;
          <stop> is a constant, parameter, or variable that specifies
             the ending value of the sequence;
    and   <resp> is a variable where the generated sequence is saved.
 
    This is the most common syntax for this command.
 
Syntax 2:
    LET <resp> = SEQUENCE <start>  <inc>  <stop>
                 FOR I = <start2>   <inc2>  <stop2>
    where <start> is a constant, parameter, or variable that specifies
             the beginning value for the sequence;
          <inc> is a constant, parameter, or variable that specifies
             the increment value of the sequence;
          <stop> is a constant, parameter, or variable that specifies
             the ending value of the sequence;
          <start2> is a number or parameter that identifies the
              first row of <resp> in which the sequence is saved
              (typically it has a value of 1);
          <inc2> is a number or parameter that identifies the row
              increment of <resp> in which the sequence is saved
              (typically it has a value of 1);
          <stop2> is a number or parameter that identifies the last row
              of <resp> in which the sequence is saved;
    and   <resp> is a variable where the generated sequence is saved.
 
    This syntax is similar to syntax 1 except that the generated
    sequence is repeated until the rows of <resp> are filled as
    specified by the FOR clause.
 
Syntax 3:
    LET <resp> = SEQUENCE <start>  <repeat>  <inc>  <stop>
    where <start> is a constant, parameter, or variable that specifies
             the beginning value for the sequence;
          <repeat> is a constant, parameter, or variable that specifies
                the number of times each value in the sequence is
                repeated;
          <inc> is a constant, parameter, or variable that specifies
             the increment value of the sequence;
          <stop> is a constant, parameter, or variable that specifies
             the ending value of the sequence;
    and   <resp> is a variable where the generated sequence is saved.
 
    This syntax is useful for generating sequence like 1 1 1 2 2 2
    3 3 3 4 4 4.
 
Syntax 4:
    LET <resp> = SEQUENCE <start>  <repeat>  <inc>  <stop>
                 FOR I = <start2> <inc2> <stop2>
    where <start> is a constant, parameter, or variable that specifies
             the beginning value for the sequence;
          <repeat> is a constant, parameter, or variable that specifies
                the number of times each value in the sequence is
                repeated;
          <inc> is a constant, parameter, or variable that specifies
             the increment value of the sequence;
          <stop> is a constant, parameter, or variable that specifies
             the ending value of the sequence;
          <start2> is a number or parameter that identifies the first
              row of <resp> in which the sequence is saved (typically it
              has a value of 1);
          <inc2> is a number or parameter that identifies the row
              increment of <resp> in which the sequence is saved
              (typically it has a value of 1);
          <stop2> is a number or parameter that identifies the last row
              of <resp> in which the sequence is saved;
    and   <resp> is a variable where the generated sequence is saved.
 
    This syntax is similar to syntax 3 except that the generated
    sequence is repeated until the rows of <resp> are filled as
    specified by the FOR clause.
 
Syntax 5:
    LET <resp> = SEQUENCE <values>  <repeat>
    where <values> is a constant, parameter, or variable that specifies
             the values for the sequence;
          <repeat> is a constant, parameter, or variable that specifies
                the number of times each value in <values> is
                repeated;
    and   <resp> is a variable where the generated sequence is saved.
 
    This syntax is useful when the number of repeated values varies.
    For example, you can do something like

        LET VAL = SEQUENCE 1 1 5
        LET REP = DATA 3 3 2 4 4

    to generate the sequence

        1 1 1 2 2 2 3 3 4 4 4 4 5 5 5 5
 
Examples:
    LET X = SEQUENCE 1 1 100
    LET X = SEQUENCE 1 1 10 FOR I = 1 1 100
    LET X = SEQUENCE -4 9 1 4
    LET X = SEQUENCE 1 50 1 2 FOR I = 1 1 100
 
Note:
    To generate the sequence

       1, 2, 3, 4, 5, 31, 32, 33, 61, 62, 63, 64, 65, 66, 67

    you can enter the commands

       LET START = DATA 1 31 61
       LET STOP = DATA 5 33 67
       LET Y = SEQUENCE START 1 STOP

    To generate the sequence

       1 1 1 2 2 3 3 3 3 4 4 4 4 4

    you can enter the command

       LET VAL = SEQUENCE 1 1 4
       LET REP = DATA 3 2 4 5
       LET Y = SEQUENCE VAL REP

    Additional examples of using the variables with the SEQUENCE
    command are given in the Program section below.

Default:
    None
 
Synonyms:
    The word SEQUENCE can be omitted from the command.
 
Related Commands:
    PATTERN             = Generate numbers with a specific pattern.
    DATA                = Place numbers in a variable.
    COMBINE             = Combine constants, parameters, and variables
                          into a single variable.
    FIBONNACCI NUMBERS  = Generate Fibonnacci numbers.
    LOGISTIC NUMBERS    = Generate numbers from a logistic sequence.
 
Applications:
    Data Management
 
Implementation Date:
    Pre-1987
    2010/11: Added support for variables as arguments
    2010/11: Added support for Syntax 5
 
Program 1:
    LET X = SEQUENCE -4 1 4 FOR I = 1 1 81
    LET Y = SEQUENCE -4 9 1 4
    LET Z = X**2+Y**2-X*Y
    LET Z0 = SEQUENCE 5 5 40
    CONTOUR PLOT Z X Y Z0
 
Program 2:
    set write decimals 1
    .
    .  Step 1: First test basic current usage
    .
    let y = sequence 1 1 10
    print y
    pause
    delete y
    .
    let y = sequence 1 3 1 10
    print y
    pause
    delete y
    .
    .  Step 2: Now test "variable" syntax
    .
    let rep = data 1 2 3 1 2 3 1 2 3 1
    let y = sequence 1 rep 1 10
    print y
    pause
    delete y rep
    .
    let stop = sequence 10 1 1
    let y = sequence 1 2 1 stop
    print y
    pause
    delete y stop
    .
    let start = data 1 100 1000
    let inc   = data 1  10  100
    let stop  = data 10 1000 10000
    let rep   = data 3 2 1
    let y = sequence start rep inc stop
    print y
    pause
    delete y start rep inc stop
    .
    let start = data 1 2 3 4 5
    let rep   = data 5 3 1 4 2
    let y = sequence start rep
    print y
    pause
    delete y start rep


SEQUENCE
 
Name:
    SEQUENCE
 
Type:
    Plot Control Command
 
Purpose:
    Specifies that a sequence number be automatically inscribed in the
    upper right corner of subsequent plots.
 
Description:
    This is useful for the ordering of the plot hardcopies after a
    session where many plots have been generated.
 
Syntax:
    SEQUENCE   <ON or OFF>   <start>
    where ON specifies that sequence numbers are generated on
             subsequent plots and OFF specifies that they are not;
    and   <start> specifies a starting number for the sequence (only
             used if ON specified).
 
Examples:
    SEQUENCE ON
    SEQUENCE OFF
    SEQUENCE
    SEQUENCE ON 11
 
Note:
    SEQUENCE ON with no <start> specified is equivalent to SEQUENCE ON
    1 .  SEQUENCE with no arguments is equivalent to SEQUENCE ON 1 .
 
Default:
    Sequence numbers are not generated.
 
Synonyms:
    None
 
Related Commands:
    PLOT      = Generates a data or function plot.
    BELL      = Sets the automatic bell switch for plots.
    PRE-ERASE = Sets the automatic pre-erase switch for plots.
    HARDCOPY  = Sets the automatic copy switch for plots.
    RING      = Rings the bell (immediately).
    ERASE     = Erases the screen (immediately).
    COPY      = Copies the screen (immediately).
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    . POLLUTION SOURCE ANALYSIS, LLOYD CURRIE, DATE--1990
    . SUBSET OF CURRIE.DAT REFERENCE FILE
    .
    LET ID2 = DATA 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2
    LET LEAD = DATA ...
       164 426 59 98 312 263 607 497 213 54 160 262 547 325 419 94 70
    LET POT = DATA ...
       106 175 61 79 94 121 424 328 107 218 140 179 246 231 245 339 99
    .
    SEQUENCE ON
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE SCATTER PLOT; X1LABEL LEAD; Y1LABEL POTASSIUM
    LINE BLANK ALL; CHARACTER CIRCLE; CHARACTER FILL ON
    PLOT POT LEAD
    .
    CHARACTER CIRCLE SQUARE; CHARACTER FILL OFF ALL
    TITLE SCATTER PLOT WITH GROUPS
    LEGEND 1 CIRC() - GROUP 1; LEGEND 2 SQUA() - GROUP 2
    LEGEND FILL ON; LEGEND FONT DUPLEX
    PLOT POT LEAD ID2
    .
    CHARACTER CIRCLE CIRCLE SQUARE SQUARE; CHARACTER FILL OFF ON OFF ON
    LET X = SEQUENCE 1 1 17
    LEGEND 1 CIRC() - POTASSIUM; LEGEND 2 SQUA() - LEAD
    X1LABEL SEQUENCE; Y1LABEL; TITLE CHARACTER FILL REPRESENTS GROUP ID
    PLOT POT X ID2 AND
    PLOT LEAD X ID2
    .
    CHARACTER BLANK ALL; LINE SOLID DASH
    SEGMENT 1 COORDINATES 16 85 19 85
    SEGMENT 2 COORDINATES 16 81 19 81
    SEGMENT 2 PATTERN DASH
    TITLE MULTIPLE TRACES AS LINES
    PLOT POT LEAD VS X
    END OF MULTIPLOT
 
-----SEQUENTIAL DIFFERENCE (LET)-------------------------------------
 
SEQUENTIAL DIFFERENCE
 
Name:
    SEQUENTIAL DIFFERENCE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the sequential differences (i.e., X(I) - X(I-1)) between
    the elements of a variable.
 
Description:
    Given a data series with N points, the sequential difference
    will contain the points

         Y(1) = X(2) - X(1)
         Y(2) = X(3) - X(2)
              ...
         Y(N-1) = X(N) - X(N-1)

    If there are less than two points in the series, nothing will be
    done.

    One use of sequential differencing is to remove trend from
    time series data.

    The 2016/02 version of Dataplot generalized this command in
    the following two ways.

       1. In additon to the difference, the following additional
          sequential values can also be computed:

             SEQUENTIAL SUM      - X(I) + X(I-1)
             SEQUENTIAL PRODUCT  - X(I) * X(I-1)
             SEQUENTIAL MEAN     - (X(I) + X(I-1))/2
             SEQUENTIAL MINIMUM  - MIN(X(I), X(I-1))
             SEQUENTIAL MAXIMUM  - MAX(X(I), X(I-1))
             SEQUENTIAL LOWER    - X(I-1)
             SEQUENTIAL UPPER    - X(I)

       2. A group-id variable can be included.  That is, the data
          values in each group will differenced.  If there are K
          groups, then the differenced series will have N - K
          points.

          The original data series does not have to be sorted
          by group.  However, the output series will be sorted
          as follows:

             a. The data will be sorted by group in the order that
                the groups are detected in the original series.

             b. Within a group, the order in the output series
                will be based on the order of the input series.

          For example, if X is the group-id variable and Y is the
          response variable

              X(1) = 1
              X(2) = 2
              X(3) = 3
              X(4) = 1
              X(5) = 2
              X(6) = 3
              X(7) = 1
              X(8) = 2
              X(9) = 3

        then the output group-id variable (X2) and differenced
        variable will be in the order

             X2(1) = 1,   Y2(1) = Y(4) - Y(1)
             X2(2) = 1,   Y2(2) = Y(7) - Y(4)
             X2(3) = 2,   Y2(3) = Y(5) - Y(2)
             X2(4) = 2,   Y2(4) = Y(8) - Y(5)
             X2(5) = 3,   Y2(5) = Y(6) - Y(3)
             X2(6) = 3,   Y2(6) = Y(9) - Y(6)

Syntax 1:
    LET <y> = SEQUENTIAL <stat> <x>    <SUBSET/EXCEPT/FOR qualification>
    where <x> is the response variable;
          <stat> is one of DIFFERENCE, SUM, PRODUCT, MEAN, MINIMUM,
                 MAXIMUM, LOWER, or UPPER;
          <y> is a variable containing the differenced series;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <y2> <x2> = SEQUENTIAL <stat> <y> <x>
                    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x> is a the group-id variable;
          <stat> is one of DIFFERENCE, SUM, PRODUCT, MEAN, MINIMUM,
                 MAXIMUM, LOWER, or UPPER;
          <y2> is a variable containing the differenced series;
          <x2> is a variable containing the group-id of the
                 differenced series;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET XD = SEQUENTIAL DIFFERENCE PRESSURE
    LET XD = SEQUENTIAL MEAN PRESSURE
    LET XD = SEQUENTIAL SUM PRESSURE
    LET XD = SEQUENTIAL DIFFERENCE PRESSURE  SUBSET X > 4
    LET YDIFF X2 = SEQUENTIAL DIFFERENCE Y X
 
Default:
    None
 
Synonyms:
    DIFFERENCE is a synonym for SEQUENTIAL DIFFERENCE
    SEQUENTIAL AVERAGE is a synonym for SEQUENTIAL MEAN
    SEQUENTIAL MIN is a synonym for SEQUENTIAL MINIMUM
    SEQUENTIAL MAX is a synonym for SEQUENTIAL MAXIMUM
 
Related Commands:
    CUMULATIVE SUM = Compute the cumulative sum of the elements of a
                     variable.
    SORT           = Sort the elements of a variable.
    COCODE         = Generate a cocoded variable.
    CODE           = Generate a coded variable.
    SEQUENCE       = Generate a sequence of numbers.
    PATTERN        = Generate numbers with a specific pattern.
 
Applications:
    Data Transformations
 
Implementation Date:
    Pre-1987
    2016/02: Support for SUM, PRODUCT, MEAN, MINIMUM, MAXIMUM,
             LOWER, and UPPER
    2016/02: Support for group-id variable
 
Program 1:
    LET X1 = DATA 12 4 2 3 9 7
    LET XD = SEQUENTIAL DIFFERENCE X1

    The variable XD will contain the following values:

       8, 2, 1, 6, 2

Program 2:
    . Step 1:   Define the data
    .
    let y = sequence 1 1 10
    .
    . Step 2:   Compute the sequential statistics
    .
    let ydiff = sequential difference y
    let ysum  = sequential sum        y
    let yprod = sequential product    y
    let ymean = sequential mean       y
    let ymin  = sequential min        y
    let ymax  = sequential max        y
    .
    . Step 3:   Print the results
    .
    set write decimals 1
    print y ydiff ysum yprod ymean ymin ymax

Program 3:
    . Step 1:   Define the data
    .
    dimension 40 columns
    let y = sequence 1 1 10
    let x = sequence 1 5 1 2
    .
    . Step 2:   Compute the sequential statistics
    .
    let ydiff ygroup = sequential difference y x
    let ysum  ygroup = sequential sum        y x
    let yprod ygroup = sequential product    y x
    let ymean ygroup = sequential mean       y x
    let ymin  ygroup = sequential min        y x
    let ymax  ygroup = sequential max        y x
    let ylow  ygroup = sequential lower      y x
    let yupp  ygroup = sequential upper      y x
    .
    . Step 3:   Print the results
    .
    set write decimals 1
    print ygroup ydiff ysum yprod ymean ymin ymax ylow yupp

----------SERIAL READ--------------------------------------
 
SERIAL READ
 
Name:
    SERIAL READ
 
Type:
    Support Command
 
Purpose:
    Reads data into variables:
       1) from a mass storage file;
       2) from within a CALLed DATAPLOT sub-program;
       3) from the terminal
 
Description:
    The rules regarding SERIAL READ are as follows:
       1) If there are k variables listed on the SERIAL READ
          statement, then all the data on each line image is read and
          sequentially fed into the next available elements of the k
          variables.  There is no restriction on the number of data
          values on any given line image.  A major difference between
          the SERIAL READ command and the READ command is that the
          SERIAL READ command reads in all data on a line, whereas the
          READ command only reads in the first k data values on a line.
          In practice, the READ command is more heavily used than the
          SERIAL READ command.  An example of the use of the SERIAL
          READ command is
             SERIAL READ X Y
             1 1 2 4 3 9 4 16 5
             25 6 36 7 49
             8 64
             9
             81 10 100
             END OF DATA
          which results in X containing the 10 elements 1, 2, ... 10;
          and Y containing the 10 elements 1, 4, 9, ...  100.
       2) The number of variables being read at one time must be
           between 1 and 10, inclusive.
       3) The full line image is scanned (for reading from a mass
          storage file, the full line image is 132 columns; for reading
          from within a sub-program and for reading from the terminal,
          the full line image is 80 columns).  For variations on this,
          see the COLUMN LIMITS command.
       4) Data values on a line image must be separated by at least one
          blank.
       5) Data values can be free-format.  They need not be aligned in
          specific columns.
       6) The format of individual data values is general.  It can be
          integer, floating point, or exponential.  It is stored
          internally as a single precision real number.
       7) All reads start from the beginning of the file (for
          variations of this, see the SKIP and ROW LIMITS commands).
       8) The analyst need not be concerned about the number of
          observations for each variable.  DATAPLOT automatically
          determines and reports this value at the end of the read.
       9) The read terminates when a line image is encountered which
          consists of
             END OF DATA
          or
             END DATA
          or when the end of the file is reached.
 
Syntax 1:
    SERIAL READ   <x1>   <x2>   ...   <xk>
    where <x1>, <x2>, ..., <xk> are the desired variable names.
 
    This syntax is used to read the data from the terminal or from a
    DATAPLOT sub-program.
 
Syntax 2:
    SERIAL READ   <file>   <x1>   <x2>   ...   <xk>
    where <file> is the name of the mass storage file where the data
              resides;
    and   <x1>, <x2>, ..., <xk> are the desired variable names.
 
    This syntax is used to read the data from a file.
 
Examples:
    SERIAL READ CALIB. PRES TEMP TIME
    SERIAL READ ASTM. Y1 Y2 Y3 X DAY LAB
    SERIAL READ Y1 Y2 Y3 X DAY LAB
    SERIAL READ Y
 
Note:
    The most common use of SERIAL READ is to read a large number of
    values into a single variable.
 
Note:
    By default, DATAPLOT does free format reads.  However, it has the
    capability for supporting FORTRAN style formats.  Formatted reads
    can be about 10 times faster on many systems which can be helpful
    for large data files.  Enter HELP READ FORMAT for more details.
 
Note:
    Blank lines in data files are ignored.
 
Note:
    DATAPLOT supports the ability to embed comment lines within the
    data file.  Enter HELP COMMENT CHECK for details.
 
Note:
    In order to determine whether the first argument is a file name or
    a variable name, it looks for a period in the name.  If it finds
    one, it assumes a file name.  If it does not, it assumes a variable
    name.  If your file name does not contain a period, attach a
    trailing period (no spaces) to the file name on the READ command.
 
Note:
    DATAPLOT has no restrictions on the file name other than it be a
    valid file name on the local operating system and that it contain
    a period "." in the file name itself or as a trailing character.
    DATAPLOT strips off trailing periods on those systems where it is
    appropriate to do so.  On systems where trailing periods can be a
    valid file name (e.g., Unix), DATAPLOT tries to open the file with
    the trailing period.  If this fails, it then tries to open the file
    with the trailing period stripped off.
 
    Some users prefer to give all data files a ".DAT" or ".dat"
    extension.  Although this is a useful method for keeping track of
    data files, it is strictly a user convention and is not enforced
    by DATAPLOT in any way.
 
Note:
    File names are case sensitive on Unix file systems.  For Unix,
    DATAPLOT attempts to open the file as given.  If this fails, it
    attempts to open the file as all upper case characters.  If this
    fails, it attempts to open the file as all lower case characters.
    All other currently supported systems are not case sensitive
    regarding file names.
 
    As a further caution for Unix hosts, certain expansion characters
    (specifically ~ to refer to your home directory) are interpreted
    by the shell and are not recognized by the Fortran compiler.  These
    expansion characters are interpreted as literal characters and do
    not yield the intended file name.
 
Default:
    1) If no file name is specified, and if a CALL is being
       executed, then the data values should be listed directly
       in the DATAPLOT sub-program immediately after the SERIAL
       READ command (do not forget the END OF DATA statement).
    2) If no file name is specified, and if commands are being
       manually entered/executed one at a time from the terminal,
       then the data should be entered directly from the terminal
       immediately after the SERIAL READ command (also terminated
       by an END OF DATA statement).
 
Synonyms:
    None
 
Related Commands:
    READ FUNCTION      = Read a function.
    READ MATRIX        = Read a matrix.
    READ PARAMETER     = Read a parameter.
    READ STRING        = Read a string.
    READ               = Perform a read.
    SET READ FORMAT    = Define a FORTRAN style format for reads.
    DATA (LET)         = Enter data values into a variable.
 
Applications:
    Data I/O
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----SET-------------------------------------------------------
 
SET
 
Name:
    SET
 
Type:
    Support Command
 
Purpose:
    Defines the values of certain internal underlying Fortran
    variables.
 
Description:
    This command allows access to information which can assist in
    implementation, tracing and debugging.  Most options are used by
    the service group which implements DATAPLOT on your computer.
    However some SET options are used by the general DATAPLOT user.
    These are documented separately in the HELP file.  The PROBE
    command returns the current value of the variables available with
    the SET command.
 
Syntax:
    SET  <Fortran variable name>  <setting>
    where <Fortran variable name> is the name of the underlying Fortran
              variable;
    and   <settings> is a number, parameter, or character string that
              specifies the value to assign to the variable.
 
Examples:
    SET IBUGAN ON
    SET IBUGA2 ON
    SET IBUGSU ON
    SET IBUGMA ON
    SET IPR 7
 
Note:
    The following SET commands are currently available.
 
    SET commands for general users (these are documented
    separately, for more details enter HELP <command>):
 
    SET READ FORMAT <string> - specify a FORTRAN format statement
        for the READ command.
 
    SET WRITE FORMAT <string> - specify a FORTRAN format
        statement for the WRITE command.
 
    SET WRITE DECIMAL <numb> - specify the number of decimal
        places for the WRITE and PRINT commands.
 
    SET IPR <file unit number> - specify the unit for DATAPLOT
        alphanumeric output.
 
    SET FOURIER WRITE -
 
    SET FOURIER EXPONENT <- or +> -
 
    SET HELP LINES - specify the number of lines printed for a
        help screen (a carriage return prints the next screen).
 
    SET LIST LINES - specify the number of lines printed by the
        LIST command (a carriage return prints the next screen).
 
    SET READ REWIND <ON/OFF> - specifies whether files are
        rewound before being read.
 
    SET WRITE REWIND <ON/OFF> - specifies whether files are
        rewound before being written to.
 
    SET PREPLOT <device> - specifies the device that preplot and
        postplot definitions apply to.  Equivalent to the PREPOST
        command.
 
    SET POSTPLOT <device> - same as SET PREPLOT.
 
    SET IO TERMINAL - used in writing menu macros.  Allows I/O to
        take place from the terminal while executing a macro.
 
    SET IO - turns off the SET IO TERMINAL command.
 
    Device specific SET commands.  These are documented in more
    detail in the HELP for that device (HELP POSTSCRIPT, HELP
    QUIC, HELP CALCOMP, HELP ZETA and HELP GENERAL).
 
    SET GENERAL JUSTIFICATION <ON/OFF>
    SET GENERAL REGION FILL <ON/OFF>
    SET GENERAL FONT <ON/OFF>
    SET GENERAL PEN WIDTH <ON/OFF>
    SET GENERAL PEN THICKNESS <number>
 
    SET QUIC FONT <number>
    SET QUIC PPI  <number>
    SET QUIC [LANDSCAPE/PORTRAIT] MARGIN LEFT     <number>
    SET QUIC [LANDSCAPE/PORTRAIT] MARGIN RIGHT    <number>
    SET QUIC [LANDSCAPE/PORTRAIT] MARGIN TOP      <number>
    SET QUIC [LANDSCAPE/PORTRAIT] MARGIN BOTTOM   <number>
 
    SET QMS FONT <number>
    SET QMS PPI  <number>
    SET QMS [LANDSCAPE/PORTRAIT] MARGIN LEFT     <number>
    SET QMS [LANDSCAPE/PORTRAIT] MARGIN RIGHT    <number>
    SET QMS [LANDSCAPE/PORTRAIT] MARGIN TOP      <number>
    SET QMS [LANDSCAPE/PORTRAIT] MARGIN BOTTOM   <number>
 
    SET POSTSCRIPT FONT <number>
    SET POSTSCRIPT PPI  <number>
    SET POSTSCRIPT [LANDSCAPE/PORTRAIT] MARGIN LEFT     <number>
    SET POSTSCRIPT [LANDSCAPE/PORTRAIT] MARGIN RIGHT    <number>
    SET POSTSCRIPT [LANDSCAPE/PORTRAIT] MARGIN TOP      <number>
    SET POSTSCRIPT [LANDSCAPE/PORTRAIT] MARGIN BOTTOM   <number>
 
    SET ZETA COLORS <number>
    SET ZETA WIDTH <number>
 
    SET CALCOMP COLORS <number>
    SET CALCOMP WIDTH <number>
 
    SET commands for DATAPLOT implementation and debugging.
    These are not needed by the general user.  The most common
    usage is to turn on the "debugging" variables.  These
    print the values of DATAPLOT variables while DATAPLOT is
    executing and can be a valuable debugging tool.  Looking at
    the bug variables in a given routine can guide which specific
    ones to turn on.
 
    SET ISUBRO <string> - turns on debugging for a specific
       subroutine.  Enter the last 4 characters of the subroutine
       name.
    SET IBUGMA <ON/OFF> - machine constants
    SET IBUGIN <ON/OFF> - initialization
    SET IBUGLS <ON/OFF> -
    SET IBUGMS <ON/OFF> -
    SET IBUGGC <ON/OFF> -
    SET IBUGTY <ON/OFF> -
    SET IBUGTE <ON/OFF> -
    SET IBUGPC <ON/OFF> - plot control commands
    SET IBUGP2 <ON/OFF> - plot control commands
    SET IBUGOD <ON/OFF> - output devices
    SET IBUGO2 <ON/OFF> - output devices
    SET IBUGSU <ON/OFF> - support commands
    SET IBUGS2 <ON/OFF> - support commands
    SET IBUGGR <ON/OFF> - graphics commands
    SET IBUGG2 <ON/OFF> - graphics commands
    SET IBUGG3 <ON/OFF> - graphics commands
    SET IBUGAN <ON/OFF> - analysis commands
    SET IBUGA2 <ON/OFF> - analysis commands
    SET IBUGA3 <ON/OFF> - analysis commands
    SET IBUGPL <ON/OFF> -
    SET IBUGGP <ON/OFF> -
    SET IBUGP1 <ON/OFF> -
    SET IBUGP3 <ON/OFF> -
    SET IBUGDG <ON/OFF> - diagrammatic graphics commands
    SET IBUGD2 <ON/OFF> - diagrammatic graphics commands
    SET IBUGCO <ON/OFF> -
    SET IBUGEV <ON/OFF> -
    SET IBUGQ  <ON/OFF> -
    SET IBUGRE <ON/OFF> -
    SET IBUGWR <ON/OFF> -
    SET IBUGSO <ON/OFF> -
    SET IBUGTO <ON/OFF> -
    SET IBUGUG <ON/OFF> - underlying graphics
    SET IBUGU2 <ON/OFF> - underlying graphics
    SET IBUGU3 <ON/OFF> - underlying graphics
    SET IBUGU4 <ON/OFF> - underlying graphics
    SET IBUGEX <ON/OFF> - expert subsystem
    SET IBUGE2 <ON/OFF> - expert subsystem
    SET IBUGHE <ON/OFF> - help
    SET IBUGH2 <ON/OFF> - help
 
    Data variables:
 
    SET MAXNK
    SET NK
    SET MAXCOL
    SET NUMCOL
    SET MAXN
    SET N
    SET MAXCHF
    SET NUMCHF
    SET MAXFUN
    SET NUMFUN
    SET MAXCHM
    SET NPLOTP
    SET ITRANS
    SET ICHAPA
 
   Machine constants (use PROBE to retrieve their current value):
 
    SET IRD    - unit for alphanumeric input
    SET IPR    - unit for alphanumeric output
    SET CPUMIN - smallest real number
    SET CPUMAX - largest real number
    SET NUMBPC - number of bits per character
    SET NUMCPW - number of characters per word
    SET NUMBPW - number bits per word
    SET IFEEDB - feedback switch
    SET IPRINT - print switch
    SET IECHO  - echo switch
 
    Housekeeping variables (use PROBE to retrieve their current value):
 
    SET MAXWID
    SET IWIDTH
    SET MAXWSV
    SET IWIDSV
    SET ICOM   - the current command (characters 1-4)
    SET ICOM2  - the current command (characters 5-8)
    SET MAXARG - maximum number of arguments
    SET NUMARG - number of arguments in current command
    SET IARG   - command arguments in integer format
    SET ARG    - command arguments in real format
    SET IHARG  - command arguments in character format
    SET MAXNAM - maximum number of names
    SET NUMNAM - current number of names
    SET IHNAME - names (characters 1-4)
    SET IHNAM2 - names (characters 5-8)
    SET IUSE   -
    SET IVALUE -
    SET VALUE  -
    SET IN     -
    SET IVSTAR -
    SET IVSTOP -
    SET IMESNU - unit for message file
    SET INEWNU - unit for news file
    SET IMAINU - unit for mail file
    SET IHELNU - unit for help file
    SET IBUGNU - unit for bugs file
    SET IQUENU - unit for query file
    SET ILOGNU - unit for log file
    SET IREANU - unit for user file to be read
    SET IWRINU - unit for user file to be written to
    SET ICRENU - unit for create macro file
    SET ISAVNU - unit for save memory file
    SET ISCRNU - unit for scratch file
    SET IDATNU - unit for         file
    SET IPL1NU - unit for DEVICE 2 graphics output file
    SET IPL2NU - unit for DEVICE 3 graphics output file
    SET IMESNA - name for message file
    SET INEWNA - name for news file
    SET IMAINA - name for mail file
    SET IHELNA - name for help file
    SET IBUGNA - name for bugs file
    SET IQUENA - name for query file
    SET ILOGNA - name for log file
    SET IREANA - name for user file to be read
    SET IWRINA - name for user file to be written to
    SET ICRENA - name for create macro file
    SET ISAVNA - name for save memory file
    SET ISCRNA - name for scratch file
    SET IDATNA - name for         file
    SET IPL1NA - name for DEVICE 2 graphics output file
    SET IPL2NA - name for DEVICE 3 graphics output file
    SET IMESST - status of message file
    SET INEWST - status of news file
    SET IMAIST - status of mail file
    SET IHELST - status of help file
    SET IBUGST - status of bugs file
    SET IQUEST - status of query file
    SET ILOGST - status of log file
    SET IREAST - status of user file to be read
    SET IWRIST - status of user file to be written to
    SET ICREST - status of create macro file
    SET ISAVST - status of save memory file
    SET ISCRST - status of scratch file
    SET IDATST - status of         file
    SET IPL1ST - status of DEVICE 2 graphics output file
    SET IPL2ST - status of DEVICE 3 graphics output file
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PROBE    = Print the value of an underlying Fortran variable.
 
Applications:
    Utility Commands
 
Implementation Date:
    Pre-1987
    New SET commands have been continuously added
 
Program:
    XX
 
-----SET COMMANDS (LET)-----------------------------------------------------
 
SET COMMANDS
The following are DATAPLOT set commands:
    SET CARDINALITY    = Computes a set cardinality.
    SET UNION          = Carries out a set union.
    SET INTERSECTION   = Carries out a set intersection.
    SET COMPLEMENT     = Carries out a set complement.
    SET CART PRODUCT   = Carries out a set Cartesian product.
    SET ELEMENTS       = Extracts the distinct elements of set.
 
-----SET CARDINALITY (LET)---------------------------------------
 
SET CARDINALITY (LET)
 
Name:
    SET CARDINALITY (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Compute the total number of elements in a set (with numeric
    elements).
 
Description:
    This cardinality counts repeats if repeats exist.  The cardinality
    of the following set:
          1 3 5 7 9 1 4 9 16 1 8 27
    is 12.
 
Syntax:
    LET <p> = SET CARDINALITY <v>   <SUBSET/EXCEPT/FOR qualification>
    where <v> is the variable whose elements are the elements of the
              input set;
          <p> is a parameter where the computed cardinality is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
              rarely used in this context.
 
Examples:
    LET N  = SET CARDINALITY Y
    LET N  = SET CARDINALITY Y SUBSET Y1 > 10
    LET N  = SET CARDINALITY Y FOR I = 1 1 3
 
Note:
    If the elements of a mathematical "set" are numbers (or can be
    translated into numbers-- always possible), then a DATAPLOT variable
    can be used to store the items of the mathematical "set".  Thus if
    the analyst wanted to "store the set" with the 12 elements--
          1 3 5 7 11 1 4 9 16 1 8 27
    he/she can do so by forming the variable Y via:
          SERIAL READ Y
          1 3 5 7 11 1 4 9 16 1 8 27
          END OF DATA
    or
          LET Y = DATA 1 3 5 7 11 1 4 9 16 1 8 27
 
Default:
    None
 
Synonyms:
    SIZE (LET) for SET CARDINALITY (LET)
 
Related Commands:
    SET UNION          = Carries out a set union.
    SET INTERSECTION   = Carries out a set intersection.
    SET COMPLEMENT     = Carries out a set complement.
    SET CART PRODUCT   = Carries out a set Cartesian product.
    SET ELEMENTS       = Extracts the distinct elements of set.
    PLOT               = Plots data or functions.
 
Applications:
    Mathematics
 
Implementation Date:
    88/7
 
Program:
    LET Y = DATA 1 3 5 7 11 1 4 9 16 1 8 27
    LET N = SET CARDINALITY Y
    SET WRITE DECIMALS 0
    WRITE Y N
 
-----SET CARTESIAN PRODUCT (LET)-----------------------------------
 
SET CARTESIAN PRODUCT (LET)
 
Name:
    SET CARTESIAN PRODUCT (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the cartesian product of 2 sets (with numeric elements).
 
Description:
    The Cartesian product of two sets is the set containing all the
    possible element pairs of the 2 original sets.  For example, the
    Cartesian product of the 3-element set:
          1 3 5
    and the 4-element set:
          1 4 9 16
    is the 12-element pair of sets:
          1 1
          1 4
          1 9
          1 16
          3 1
          3 4
          3 9
          3 16
          5 1
          5 4
          5 9
          5 16
 
Syntax:
    LET <v3> <v4> = SET CARTESIAN PRODUCT <v1> <v2>
                   <SUBSET/EXCEPT/FOR qualification>
    where <v1> is the variable whose elements are the elements of the
               first set;
          <v2> is the variable whose elements are the elements of the
               second set;
          <v3> is the variable whose elements are the elements of the
               resultant set corresponding to <v1>;
          <v4> is the variable whose elements are the elements of the
               resultant set corresponding to <v2>;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
              rarely used in this context.
 
Examples:
    LET Y3 Y4  = SET CARTESIAN PRODUCT Y1 Y2
    LET Y3 Y4  = SET CARTESIAN PRODUCT Y1 Y2 SUBSET Y1 > 10
    LET Y3 Y4  = SET CARTESIAN PRODUCT Y1 Y2 FOR I = 1 1 3
 
Note:
    If the elements of a mathematical "set" are numbers (or can be
    translated into numbers-- always possible), then a DATAPLOT variable
    can be used to store the items of the mathematical "set".  Thus if
    the analyst wanted to "store the set" with the 12 elements--
          1 3 5 7 11 1 4 9 16 1 8 27
    he/she can do so by forming the variable Y via:
          SERIAL READ Y
          1 3 5 7 11 1 4 9 16 1 8 27
          END OF DATA
    or
          LET Y = DATA 1 3 5 7 11 1 4 9 16 1 8 27
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SET CARDINALITY    = Computes the number of elements in a set.
    SET UNION          = Carries out a set union.
    SET INTERSECTION   = Carries out a set intersection.
    SET COMPLEMENT     = Carries out a set complement.
    SET DISTINCT       = Extracts the distinct elements of set.
    PLOT               = Plots data or functions.
    VECTOR DOT PRODUCT = Carries out a vector cross product.
    MATRIX MULT        = Carries out a matrix multiplication.
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 1 3 5 7 9
    LET Y2 = DATA 1 4 9 16
    LET Y3 Y4 = SET CARTESIAN PRODUCT Y1 Y2
    SET WRITE DECIMALS 0
    WRITE Y3 Y4
 
-----SET COMPLEMENT (LET)----------------------------------------
 
SET COMPLEMENT (LET)
 
Name:
    SET COMPLEMENT (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the complement of 2 sets (with numeric elements).
 
Description:
    The complement is of set 1 with respect to set 2 (the assumed
    superset).  The resultant set is those elements in set 2 which are
    not in set 1.  For example, the complement of the 3-element set:
          1 5 7
    with respect to the 5-element set:
          1 3 5 7 9
    is the 2-element set:
          3 9
 
Syntax:
    LET <v3> = SET COMPLEMENT <v1> <v2>
              <SUBSET/EXCEPT/FOR qualification>
    where <v1> is the variable whose elements are the elements of the
               first set;
          <v2> is the variable whose elements are the elements of the
               second set;
          <v3> is the variable whose elements are the elements of the
               resultant set;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
              rarely used in this context.
 
Examples:
    LET Y3  = SET COMPLEMENT Y1 Y2
    LET Y3  = SET COMPLEMENT Y1 Y2 SUBSET Y1 > 10
    LET Y3  = SET COMPLEMENT Y1 Y2 FOR I = 1 1 3
 
Note:
    If the elements of a mathematical "set" are numbers (or can be
    translated into numbers-- always possible), then a DATAPLOT variable
    can be used to store the items of the mathematical "set".  Thus if
    the analyst wanted to "store the set" with the 12 elements--
          1 3 5 7 11 1 4 9 16 1 8 27
    he/she can do so by forming the variable Y via:
          SERIAL READ Y
          1 3 5 7 11 1 4 9 16 1 8 27
          END OF DATA
    or
          LET Y = DATA 1 3 5 7 11 1 4 9 16 1 8 27
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SET CARDINALITY     = Computes the number of elements in a set.
    SET UNION           = Carries out a set union.
    SET INTERSECTION    = Carries out a set intersection.
    SET CART PRODUCT    = Carries out a set Cartesian product.
    SET ELEMENTS        = Extracts the distinct elements of set.
    PLOT                = Plots data or functions.
    COMPLEX SUBTRACTION = Carries out complex subtraction.
    POLY  SUBTRACTION   = Carries out polynomial subtraction.
    VECTOR SUBTRACTION  = Carries out vector subtraction.
    LOGICAL OR          = Carries out logical or.
    MATRIX SUBTRACTION  = Carries out matrix subtraction.
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 1 5 7
    LET Y2 = DATA 1 3 5 7 9
    LET Y3 = SET COMPLEMENT Y1 Y2
    SET WRITE DECIMALS 0
    WRITE Y1 Y2 Y3
 
-----SET DISTINCT (LET)------------------------------------------
 
SET DISTINCT (LET)
 
Name:
    SET DISTINCT (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Extract the distinct elements of a set (with numeric elements).
 
Description:
    The distinct elements of a set are those elements of the original
    set but with multiple occurrences ignored.  The set of distinct
    elements of the 12-element set:
          1 3 5 7 9 1 4 9 16 1 8 27
    is the 9-element resultant set:
          1 3 5 7 9 4 16 8 27
 
Syntax:
    LET <v2> = SET DISTINCT <v1>  <SUBSET/EXCEPT/FOR qualification>
    where <v1> is the variable whose elements are the elements of the
               input set;
          <v2> is the variable where the resultant set is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
              rarely used in this context.
 
Examples:
    LET Y3  = SET DISTINCT Y1
    LET Y3  = SET DISTINCT Y1 SUBSET Y1 > 10
    LET Y3  = SET DISTINCT Y1 FOR I = 1 1 20
 
Note:
    If the elements of a mathematical "set" are numbers (or can be
    translated into numbers-- always possible), then a DATAPLOT variable
    can be used to store the items of the mathematical "set".  Thus if
    the analyst wanted to "store the set" with the 12 elements--
          1 3 5 7 11 1 4 9 16 1 8 27
    he/she can do so by forming the variable Y via:
          SERIAL READ Y
          1 3 5 7 11 1 4 9 16 1 8 27
          END OF DATA
    or
          LET Y = DATA 1 3 5 7 11 1 4 9 16 1 8 27
 
Default:
    None
 
Synonyms:
    DISTINCT for SET DISTINCT (LET)
    SET ELEMENTS (LET) for SET DISTINCT (LET)
 
Related Commands:
    SET CARDINALITY    = Computes the number of elements in a set.
    SET UNION          = Carries out a set union.
    SET INTERSECTION   = Carries out a set intersection.
    SET COMPLEMENT     = Carries out a set complement.
    SET CART PRODUCT   = Carries out a set Cartesian product.
    PLOT               = Plots data or functions.
 
Applications:
    Mathematics
 
Implementation Date:
    88/7
 
Program:
    LET Y1 = DATA 1 3 5 7 11 1 4 9 16 1 8 27
    LET Y2 = SET DISTINCT Y1
    SET WRITE DECIMALS 0
    WRITE Y1 Y2
 
-----SET INTERSECTION (LET)--------------------------------------
 
SET INTERSECTION (LET)
 
Name:
    SET INTERSECTION (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the intersection of 2 sets (with numeric elements).
 
Description:
    The intersection of 2 sets is the set containing the elements
    common to both sets.  For example, the intersection of the
    5-element set:
          1 3 5 7 9
    and the 4-element set:
          1 4 9 16
    is the 2-element set:
          1 9
 
Syntax:
    LET <v3> = SET INTERSECTION <v1> <v2>
              <SUBSET/EXCEPT/FOR qualification>
    where <v1> is the variable whose elements are the elements of the
               first set;
          <v2> is the variable whose elements are the elements of the
               second set;
          <v3> is the variable whose elements are the elements of the
               resultant set;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
              rarely used in this context.
 
Examples:
    LET Y3  = SET INTERSECTION Y1 Y2
    LET Y3  = SET INTERSECTION Y1 Y2 SUBSET Y1 > 10
    LET Y3  = SET INTERSECTION Y1 Y2 FOR I = 1 1 3
 
Note:
    If the elements of a mathematical "set" are numbers (or can be
    translated into numbers-- always possible), then a DATAPLOT variable
    can be used to store the items of the mathematical "set".  Thus if
    the analyst wanted to "store the set" with the 12 elements--
          1 3 5 7 11 1 4 9 16 1 8 27
    he/she can do so by forming the variable Y via:
          SERIAL READ Y
          1 3 5 7 11 1 4 9 16 1 8 27
          END OF DATA
    or
          LET Y = DATA 1 3 5 7 11 1 4 9 16 1 8 27
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SET CARDINALITY     = Computes the number of elements in a set.
    SET UNION           = Carries out a set union.
    SET COMPLEMENT      = Carries out a set complement.
    SET CART PRODUCT    = Carries out a set Cartesian product.
    SET DISTINCT        = Extracts the distinct elements of set.
    PLOT                = Plots data or functions.
    COMPLEX SUBTRACTION = Carries out a complex subtraction.
    POLY  SUBTRACTION   = Carries out a polynomial subtraction.
    VECTOR SUBTRACTION  = Carries out a vector subtraction.
    LOGICAL OR          = Carries out a logical or.
    MATRIX SUBTRACTION  = Carries out a matrix subtraction.
 
Applications:
    Mathematics
 
Implementation Date:
    93/9
 
Program:
    . PURPOSE--DETERMINE THE SOLUTIONS OF A DIOPHANTINE EQUATION--
    .          FIND THE INTEGER SOLUTIONS (X AND Y) OF X**2 + 1 = 2*Y**4
    .
    .      STEP 1--DEFINE THE FUNCTION OF INTEREST IN Y = F(X) FORM.
    .      DEFINE A SEQUENCE OF X VALUES AND COMPUTE CORRESPONDING Y.
    LET FUNCTION F = ((X**2+1)/2)**0.25
    LET X = SEQUENCE 0 1 500
    LET Y = F
    .      STEP 2--DETERMINE THE INTERSECTION OF THE Y VALUES
    .              WITH THE (INTEGER) X VALUES.
    LET Y2 = SET INTERSECTION X Y
    PRINT Y2
    .      STEP 3--IN ANOTHER FASHION, DETERMINE THE Y VALUES WHICH ARE
    .              INTEGER AND THE (NECESSARILY INTEGER) X VALUES
    LET Y3 = FRACT(Y)
    LINE SOLID BLANK
    CHARACTER BLANK X
    PLOT Y X AND
    PLOT Y X SUBSET Y3 0
 
-----SET UNION (LET)---------------------------------------------
 
SET UNION (LET)
 
Name:
    SET UNION (LET)
 
Type:
    Subcommand under LET
 
Purpose:
    Carry out the union of 2 sets (with numeric elements).
 
Description:
    The union of two sets is the set containing elements that are in
    either of the 2 original sets (but not necessarily both sets).
    Repeats are only counted once.  For example, the union of the
    5-element set:
          1 3 5 7 9
    and the 4-element set:
          1 4 9 16
    is the 9-element set:
          1 3 5 7 9 1 4 9 16
 
Syntax:
    LET <v3> = SET UNION <v1> <v2>   <SUBSET/EXCEPT/FOR qualification>
    where <v1> is the variable whose elements are the elements of the
               first set;
          <v2> is the variable whose elements are the elements of the
               second set;
          <v3> is the variable whose elements are the elements of the
               resultant set;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional and
              rarely used in this context.
 
Examples:
    LET Y3  = SET UNION Y1 Y2
    LET Y3  = SET UNION Y1 Y2 SUBSET Y1 > 10
    LET Y3  = SET UNION Y1 Y2 FOR I = 1 1 3
 
Note:
    If the elements of a mathematical "set" are numbers (or can be
    translated into numbers-- always possible), then a DATAPLOT variable
    can be used to store the items of the mathematical "set".  Thus if
    the analyst wanted to "store the set" with the 12 elements--
          1 3 5 7 11 1 4 9 16 1 8 27
    he/she can do so by forming the variable Y via:
          SERIAL READ Y
          1 3 5 7 11 1 4 9 16 1 8 27
          END OF DATA
    or
          LET Y = DATA 1 3 5 7 11 1 4 9 16 1 8 27
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SET CARDINALITY    = Computes the number of elements in a set.
    SET INTERSECTION   = Carries out a set intersection.
    SET COMPLEMENT     = Carries out a set complement.
    SET CART PRODUCT   = Carries out a set Cartesian product.
    SET DISTINCT       = Extracts the distinct elements of set.
    PLOT               = Plots data or functions.
    COMPLEX ADDITION   = Carries out a complex addition.
    POLY  ADDITION     = Carries out a polynomial addition.
    VECTOR ADDITION    = Carries out a vector addition.
    LOGICAL AND        = Carries out a logical and.
    MATRIX ADDITION    = Carries out a matrix addition.
 
Applications:
    Mathematics
 
Implementation Date:
    87/10
 
Program:
    LET Y1 = DATA 1 3 5 7 9
    LET Y2 = DATA 1 4 9 16
    LET Y3 = SET UNION Y1 Y2
    SET WRITE DECIMALS 0
    WRITE Y1 Y2 Y3
 
-----SHANNON DIVERSITY INDEX (LET)-------------------------------------
 
SHANNON DIVERSITY INDEX
 
Name:
    SHANNON DIVERSITY INDEX (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the Shannon diversity index.
 
Description:
    Diversity indices are statistics used to summarize the diversity of a
    population in which each member belongs to a unique group.  For
    example, in ecology the groups are typically species.  In ecology,
    species richness refers to number of species and species eveness
    refers to homogeneity of the species.  That is, the more equal the
    proportions for each of the groups, the more homogeneous, or even,
    they are.  Different fields of application may use different
    terminology for these concepts.
   
    Given a vector of frequencies (counts), f(i), the Shannon diversity
    index is computed as

        H = {n*LOG(n) - SUM[i=1 to k][f(i)*LOG(f(i))]}/n

    with k and n denoting the number of groups and the total count,
    respectively.  If f(i) = 0, then the f(i)*LOG(f(i)) term is set
    to 0.

    The maximum value of the index is LOG(k).  This value occurs when
    each group has the same frequency (i.e., maximum eveness).

    The Shannon equitability index is simply the Shannon diversity
    index divided by the maximum diversity

         E(H) = H/LOG(k)

    This normalizes the Shannon diversity index to a value between 0 and
    1.   Note that lower values indicate more diversity while higher
    values indicate less diversity.  Specifically, an index value of 1
    means that all groups have the same frequency.  Some analysts
    use 1 - E(H) so that higher values indicate higher diversity.
    Some analysts also use 1/E(H).

    In some cases, you may have proportions rather than counts.  In
    this case, the formula for the Shannon diversity index is

         H = -SUM[i=1 to k][p(i)*LOG(p(i))]

    with p(i) denoting the proportion in group k.  As above, the Shannon
    equitability index is computed as

         E(H) = H/LOG(k)

    You may also have raw data.  That is, each row of the response
    variable identifies which group that row belongs to.  In this case,
    Dataplot will generate the frequency table and use the formulas
    above to compute the index.
 
Syntax 1:
    LET <par> = SHANNON <DIVERSITY/EQUITABILITY> INDEX <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <DIVERSITY/EQUITABILITY> specifies whether the diversity or
                equitability index is computed;
          <par> is a parameter where the Shannon diversity index is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used when the response variable is either a set
    of proportions or a set of counts.  Dataplot sums the values in
    the response variable.  If the sum equals 1, then it assumes the
    response variable contains proportions.  Otherwise, it assumes
    the response variable contains frequencies.  In either case,
    if negative values are encountered an error is reported.

Syntax 2:
    LET <par> = RAW SHANNON <DIVERSITY/EQUITABILITY> INDEX <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <DIVERSITY/EQUITABILITY> specifies whether the diversity or
                equitability index is computed;
          <par> is a parameter where the Shannon diversity index is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used when the response variable is a group-id
    variable.  The group frequencies will be computed automatically.

Examples:
    LET SDI = SHANNON DIVERSITY P
    LET SEI = SHANNON EQUITABILITY P

Note:
    The Shannon diversity/equitability is used in a wide variety of
    fields.  It may be referred to by a different name or have a
    slightly different formulation in various fields.
    
Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

    The SHANNON DIVERSITY INDEX command is not typically used in the context
    of these other commands.

Default:
    None
 
Synonyms:
    SHANNON EVENESS INDEX is a synonym for SHANNON EQUIABILIY INDEX
 
Related Commands:
    SIMPSON DIVERSITY INDEX   = Compute the Simpson diversity index.
 
References:
    Weaver, W.; C.E. Shannon (1949), "The Mathematical Theory of
    Communication," Urbana, Illinois: University of Illinois.

    Shannon, C.E. (July and October 1948), "A mathematical theory of
    communication," Bell System Technical Journal 27: 379–423 and 623–656.

    Brani Vidakovic (2011), "Statistics for Bioengineering
    Sciences: With MATLAB and WinBUGS Support," Springer, p. 23.

Applications:
    Data Management
 
Implementation Date:
    2011/12
 
Program:
    let p = data 0.25 0.15 0.40 0.20
    let nk = size p
    .
    let a = shannon diversity index p
    let b = shannon equitability index p
    .
    .  Following example from page 23 of:
    .
    .     Brani Vidakovic (2011), "Statistics for Bioengineering
    .     Sciences: With MATLAB and WinBUGS Support", Springer.
    .
    read y x
    115  1
    108  1
     25  1
      6  1
     28  1
     25  1
      6  1
      1  1
    220  2
    134  2
    183  2
     39  2
     12  2
      6  2
      6  2
     12  2
     83  3
    104  3
     16  3
      8  3
     14  3
     18  3
      2  3
      1  3
     99  4
     94  4
     21  4
      8  4
     18  4
     18  4
      5  4
      2  4
    end of data
    .
    set write decimals 4
    tabulate shannon diversity index y x
    tabulate shannon equitability index y x
    .
    let yn = cross tabulate sum y x
    let pn = y/yn
    tabulate shannon diversity index pn x
    tabulate shannon equitability index pn x
 
-----SHUFFLE GROUPS (LET)---------------------------------------
 
SHUFFLE GROUPS
 
Name:
    SHUFFLE GROUPS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Given a response variable and a group-id variable, re-arrange the
    groups based on an index variable (the response variable is not
    randomized within the group).
 
Description:
    The motivation for this command is to allow the rows (or columns)
    of a matrix or image to be randomly re-arranged.  The randomization
    can be either with replacement or without replacement (this is
    determined by the index variable).

    The size of the index variable should be equal to the number of groups
    in the group-id variable.  Although this command was motivated by
    cases where the group sizes are equal, this is not required.  If the
    group sizes are note equal, the output variable may not be the same
    length as the input variable.
 
Syntax:
    LET <y2> = SHUFFLE GROUPS <y> <x> <index>
               <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <x> is a group-id variable;
          <index> is a variable defining the order for the groups in the
               output variable;
          <y2> is a response variable containing the re-arranged groups;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    The response variable and group-id variable should have the same
    number of elements.  The index variable must be the same size as the
    number of groups in the group-id variable.

    If there are k groups in the group-id variable, then the values in
    the index variable should be between 1 and k.  An error will be
    reported if they are not.

Examples:
    LET Y2 = SHUFFLE GROUPS Y X XINDEX
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    RANDOM PERMUTATION     = Generate a set of random permutations.
    MATRIX RENUMBER        = Permute the rows and columns of a matrix.
 
Applications:
    Data Manipulation
 
Implementation Date:
    2014/07
 
Program:
    . Step 1:   Read the data
    .
    read x y
    1   1
    1   2
    1   3
    1   4
    1   5
    2  11
    2  12
    2  13
    2  14
    2  15
    3  21
    3  22
    3  23
    3  24
    3  25
    4  31
    4  32
    4  33
    4  34
    4  35
    end of data
    .
    . Step 2:   Now reshuffle the groups
    .
    let iindex = data 3  1 4  2
    let yout = shuffle groups y x iindex
    .
    . Step 3:   Print the results
    .
    set write decimals 0
    print x y yout
 
-----SIMPSON DIVERSITY INDEX (LET)--------------------------------------
 
SIMPSON DIVERSITY INDEX
 
Name:
    SIMPSON DIVERSITY INDEX (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the Simpson diversity index.
 
Description:
    Diversity indices are statistics used to summarize the diversity of a
    population in which each member belongs to a unique group.  For
    example, in ecology the groups are typically species.  In ecology,
    species richness refers to number of species and species eveness
    refers to homogeneity of the species.  That is, the more equal the
    proportions for each of the groups, the more homogeneous, or even,
    they are.  Different fields of application may use different
    terminology for these concepts.
   
    Given a vector of frequencies (counts), f(i), the Simpson diversity
    index is computed as

        D = SUM[i=1 to k][(f(i)/n)**2]

    with k and n denoting the number of groups and the total count,
    respectively.

    This index has a value between 0 and 1.  Lower values indicate more
    diversity while higher values indicate less diversity.

    In some cases, you may have proportions rather than counts.  In
    this case, the formula for the Simpson diversity index is

        D = SUM[i=1 to k][p(i)**2]

    You may also have raw data.  That is, each row of the response
    variable identifies which group that row belongs to.  In this case,
    Dataplot will generate the frequency table and use the formulas
    above to compute the index.
 
Syntax 1:
    LET <par> = SIMPSON DIVERSITY INDEX <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the Simpson diversity index is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used when the response variable is either a set
    of proportions or a set of counts.  Dataplot sums the values in
    the response variable.  If the sum equals 1, then it assumes the
    response variable contains proportions.  Otherwise, it assumes
    the response variable contains frequencies.  In either case,
    if negative values are encountered an error is reported.

Syntax 2:
    LET <par> = RAW SIMPSON DIVERSITY INDEX <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the Simpson diversity index is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used when the response variable is a group-id
    variable.  The group frequencies will be computed automatically.

Examples:
    LET SDI = SIMPSON DIVERSITY P

Note:
    The Simpson diversity is used in a wide variety of fields.  It may be
    referred to by a different name or have a slightly different
    formulation in various fields.
    
Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

    The SIMPSON DIVERSITY INDEX command is not typically used in the context of these
    other commands.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SHANNON DIVERSITY INDEX   = Compute the Shannon diversity index.
 
References:
    Edward H. Simpson (1949), "Measurement of diversity," Nature 163:688.

Applications:
    Data Management
 
Implementation Date:
    2011/12
 
Program:
    let p = data 0.25 0.15 0.40 0.20
    let nk = size p
    .
    let a = simpson diversity index p
    .
    .  Following example from page 23 of:
    .
    .     Brani Vidakovic (2011), "Statistics for Bioengineering
    .     Sciences: With MATLAB and WinBUGS Support", Springer.
    .
    read y x
    115  1
    108  1
     25  1
      6  1
     28  1
     25  1
      6  1
      1  1
    220  2
    134  2
    183  2
     39  2
     12  2
      6  2
      6  2
     12  2
     83  3
    104  3
     16  3
      8  3
     14  3
     18  3
      2  3
      1  3
     99  4
     94  4
     21  4
      8  4
     18  4
     18  4
      5  4
      2  4
    end of data
    .
    set write decimals 4
    tabulate simpson diversity index y x
    .
    let yn = cross tabulate sum y x
    let pn = y/yn
    tabulate simpson diversity index pn x
 
-----SHORTEST HALF MIDMEAN (LET)-----------------------------------------
 
SHORTEST HALF MIDMEAN
 
Name:
    SHORTEST HALF MIDMEAN (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the shortest half midmean for a variable.
 
Description:
    The midmean of a variable is the mean of the observations between
    the 25th and 75th percentiles.  The shortest half midmean uses the
    most compact half of the data rather than the middle half.  This is
    essentially an asymetric version of the midmean.  Although it has
    rather low efficiency (lower than the median), it is less sensitive
    to asymmetrically distributed outliers.  The formula for the shortest
    half midmean is

        M = SUM[i=k to k+m][X(i)]/m   for the minimum
                                      (X(k+m) - X(k))

        m = n/2                       n odd
        m = INT(n/2) + 1              n even

 
Syntax 1:
    LET <par> = SHORTEST HALF MIDMEAN <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed shortest half midmean
              is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Syntax 2:
    LET <par> = DIFFERENCE OF SHORTEST HALF MIDMEAN <y1> <y2>
                                      <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed difference of shortest
               half midmeans is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET A = SHORTEST HALF MIDMEAN Y1
    LET A = SHORTEST HALF MIDMEAN Y1 SUBSET TAG > 2

    LET A = DIFFERENCE OF SHORTEST HALFMIDMEAN Y1 Y2

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    SHORTEST HALF MID MEAN is a synonym for SHORTEST HALF MIDMEAN
 
Related Commands:
    MIDMEAN                 = Compute the midmean.
    SHORTEST HALF MIDRANGE  = Compute the shortest half midrange.
    MEAN                    = Compute the mean.
    MEDIAN                  = Compute the median.
    STANDARD DEVIATION      = Compute the standard deviation.
 
References:
    David Duewer (2008), "A Comparison of Location Estimators for
    Interlaboratory Data Contaminated with Value and Uncertainty
    Outliers", Accredited Quality Assurance, Vol. 13, pp. 193-216.

    Andrews, Bickel, Hampel, Huber, Rogers, and Tukey (1972), "Robust
    Estimates of Location", Princeton University Press, Princeton.

    Rousseeuw (1985), "Multivariate Estimation with High Breakdown
    Point", in Grossman, Pflug, Nincze, Wetrz (eds), "Mathematical
    Statistics and Applications", Reidel, Dordrecht, The Netherlands,
    pp. 283-297.

Applications:
    Robust Data Analysis
 
Implementation Date:
    2017/02
    2017/06: Added DIFFERENCE OF SHORTEST HALF MIDMEAN
 
Program 1:
    SKIP 25
    READ LGN.DAT Y
    LET SHMM = SHORTEST HALF MIDMEAN Y
 
Program 2:
    . Step 1:   Create the data
    .
    skip 25
    read gear.dat y x
    skip 0
    .
    char X
    line blank
    y1label Shortest Half Midmean
    x1label Group
    x1tic mark offset 0.5 0.5
    label case asis
    title case asis
    title Shortest Half Midmean of GEAR.DAT
    title offset 2
    .
    set statistic plot reference line average
    shortest half midmean plot y x
    .
    set write decimals 5
    tabulate shortest half midmean y x

Program 3:
    SKIP 25
    READ IRIS.DAT Y1 TO Y4 X
    .
    LET A = DIFFERENCE OF SHORTEST HALF MIDMEAN Y1 Y2
    SET WRITE DECIMALS 4
    TABULATE DIFFERENCE OF SHORTEST HALF MIDMEAN Y1 Y2 X
    .
    XTIC OFFSET 0.2 0.2
    X1LABEL GROUP ID
    Y1LABEL DIFFERENCE OF SHORTEST HALF MIDMEAN
    CHAR X
    LINE BLANK
    DIFFERENCE OF SHORTEST HALF MIDMEAN PLOT Y1 Y2 X
    CHAR X ALL
    LINE BLANK ALL
    BOOTSTRAP DIFFERENCE OF SHORTEST HALF MIDMEAN PLOT Y1 Y2 X 
 
-----SHORTEST HALF MIDRANGE (LET)-----------------------------------------
 
SHORTEST HALF MIDRANGE
 
Name:
    SHORTEST HALF MIDRANGE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the shortest half midrange for a variable.
 
Description:
    The midrange of a variable is the mean of the minimum and
    maximum values.  The shortest half midrange is based on the
    most compact half of the data.  This is essentially an asymetric
    version of the mean of the lower quartile and the upper quartile.
    Although it has rather low efficiency (lower than the median), it
    is less sensitive to asymmetrically distributed outliers.  The
    formula for the shortest half midrange is

        M = (X(k) + X(k+m))/2         for the minimum  (X(k+m) - X(k))

        m = n/2                       n odd
        m = INT(n/2) + 1              n even

Syntax 1:
    LET <par> = SHORTEST HALF MIDRANGE <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed shortest half midrange
              is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Syntax 2:
    LET <par> = DIFFERENCE OF SHORTEST HALF MIDRANGE <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed difference of shortest
               half midranges is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET A = SHORTEST HALF MIDRANGE Y1
    LET A = SHORTEST HALF MIDRANGE Y1 SUBSET TAG > 2

    LET A = DIFFERENCE OF SHORTEST HALF MIDRANGE Y1 Y2

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    SHORTEST HALF MID RANGE is a synonym for SHORTEST HALF MIDRANGE
 
Related Commands:
    MIDRANGE                = Compute the midrange.
    SHORTEST HALF MIDMEAN   = Compute the shortest half midmean.
    MEAN                    = Compute the mean.
    MEDIAN                  = Compute the median.
    STANDARD DEVIATION      = Compute the standard deviation.
 
References:
    David Duewer (2008), "A Comparison of Location Estimators for
    Interlaboratory Data Contaminated with Value and Uncertainty
    Outliers", Accredited Quality Assurance, Vol. 13, pp. 193-216.

    Andrews, Bickel, Hampel, Huber, Rogers, and Tukey (1972), "Robust
    Estimates of Location", Princeton University Press, Princeton.

    Rousseeuw (1985), "Multivariate Estimation with High Breakdown
    Point", in Grossman, Pflug, Nincze, Wetrz (eds), "Mathematical
    Statistics and Applications", Reidel, Dordrecht, The Netherlands,
    pp. 283-297.
Applications:
    Robust Data Analysis
 
Implementation Date:
    2017/02
    2017/06: Added DIFFERENCE OF SHORTEST HALF MIDRANGE
 
Program 1:
    SKIP 25
    READ LGN.DAT Y
    LET SHMM = SHORTEST HALF MIDRANGE Y
 
Program 2:
    . Step 1:   Create the data
    .
    skip 25
    read gear.dat y x
    skip 0
    .
    char X
    line blank
    y1label Shortest Half Midrange
    x1label Group
    x1tic mark offset 0.5 0.5
    label case asis
    title case asis
    title Shortest Half Midrange of GEAR.DAT
    title offset 2
    .
    set statistic plot reference line average
    shortest half midrange plot y x
    .
    set write decimals 5
    tabulate shortest half midrange y x

Program 3:
    SKIP 25
    READ IRIS.DAT Y1 TO Y4 X
    .
    LET A = DIFFERENCE OF SHORTEST HALF MIDRANGE Y1 Y2
    SET WRITE DECIMALS 4
    TABULATE DIFFERENCE OF SHORTEST HALF MIDRANGE Y1 Y2 X
    .
    XTIC OFFSET 0.2 0.2
    X1LABEL GROUP ID
    Y1LABEL DIFFERENCE OF SHORTEST HALF MIDRANGE
    CHAR X
    LINE BLANK
    DIFFERENCE OF SHORTEST HALF MIDRANGE PLOT Y1 Y2 X
    CHAR X ALL
    LINE BLANK ALL
    BOOTSTRAP DIFFERENCE OF SHORTEST HALF MIDRANGE PLOT Y1 Y2 X 
 
-----SHOW COLORS-------------------------------------------------------
 
SHOW COLORS
 
Name:
    SHOW COLORS
 
Type:
    Output Devices Command
 
Purpose:
    List the colors (and corresponding index numbers) available in
    DATAPLOT.
 
Description:
    DATAPLOT allows colors to be specified by name or by an index
    number.  All devices recognize the same color names and index
    numbers  and there is a consistent mapping from an index number to
    a color (e.g., index 1 always goes to black, index 2 always goes to
    red).  Devices that do not support a given color map it to the
    closest available color (closest is an arbitrary choice).
    Specifying a device on this command shows the mapping from the
    DATAPLOT color to the color that is actually used on the device.
 
Syntax 1:
    SHOW COLORS
 
    This syntax lists the color names and their associated index
    numbers recognized by DATAPLOT.
 
Syntax 2:
    SHOW COLORS <device>
    where <device> is one of the following:
              CALCOMP
              CGM
              HP 2622
              HPGL
              PC
              POSTSCRIPT
              REGIS
              SUN
              TEKTRONIX 4115
              TEKTRONIX 4662
              TEKTRONIX 4027
              X11
              ZETA.
 
    This syntax shows the mapping from the DATAPLOT color to the
    actual color used on the given device.
 
Examples:
    SHOW COLORS
    SHOW COLORS POSTSCRIPT
    SHOW COLORS TEKTRONIX 4115
 
Note:
    In previous versions, specifying a color by index would select
    the slot number on penplotter devices.  This is no longer the case.
    The index number now goes to a specific color, which then goes
    to the slot assigned to that color.  While this is less intuitive
    for plotters, it allows color names and indices to be treated
    consistently across devices (e.g., index 1 means BLACK on all
    devices).  The PEN MAP command can still be used to assign a color
    to a specific slot number for plotter devices (HPGL, CALCOMP, and
    ZETA).
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    ZETA                  = Direct graphical output to a Zeta device.
    POSTSCRIPT            = Direct graphical output to a Postscript
                            device.
    TEKTRONIX             = Direct graphical output to a Tektronix
                            device.
    DEVICE                = Specify certain actions for the graphics
                            output.
    PEN MAP               = Specify the pen slot to color mapping for
                            certain plotter devices.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----SHOW READ FORMAT-------------------------------------------
 
SHOW READ FORMAT
 
Name:
    READ FORMAT (SET)
 
Type:
    Support Command
 
Purpose:
    Show the current setting for the read format.
 
Description:
    Formatted reads provide faster performance at the expense of
    requiring a structured data file.
 
Syntax:
    SHOW READ FORMAT
 
Examples:
    SHOW READ FORMAT
 
Default:
    Free-format (i.e., no format).
 
Synonyms:
    None
 
Related Commands:
    READ             = Carries out a column-wise input of data.
    SERIAL READ      = Carries out a line-wise input of data.
    SET READ FORMAT  = Specifies a Fortran-like format for subsequent
                       reads.
 
Applications:
    Input/Output
 
Implementation Date:
    88/3
 
Program:
    XX
 
-----SHIFT PLOT--------------------------------------
 
SHIFT PLOT
 
Name:
    SHIFT PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a shift plot.
 
Description:
    The shift plot is a plot of

        y(q) - x(q) versus x(q)

    with y(q) and x(q) denoting the qth quantiles of y and x,
    respectively.  Although this plot can be generated for any
    pair of variables, the primary usage of this plot is for the
    case where x is a control group and y is an experimental
    method.  Alternatively, x could represent an "old" method
    while y represents a "new" method.  The plot measures how much
    the control group must be shifted so that it is comparable to
    the expermimental method (relative to the quantiles).

    The quantiles of a distribution are the distribution's "percent
    points" (e.g., the 0.5 quantile = 50% point = median).

    The plot consists of the following:
       Vertical axis   = difference in the estimated quantiles
                         between data set 1 and data set 2;
       Horizontal axis = estimated quantiles from data set 2.

    The shift plot is a variation of the quantile-quantile plot
    and the Tukey mean-difference plot.

Syntax 1:
    SHIFT PLOT <y> <x>      <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable for the experimental group;
          <x> is the response variable for the control group;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    With this syntax, the quantiles correspond to the data points
    of the <x> variable.

Syntax 2:
    SHIFT PLOT <y> <x> <q>     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable for the experimental group;
          <x> is the response variable for the control group;
          <q> is a variable containing values between 0 and 1 that
              specifies the desired quantiles to plot;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    With this syntax, you explicitly give the desired quantiles.

Examples:
    SHIFT PLOT Y X
    SHIFT PLOT Y X  SUBSET X > 1
    SHIFT PLOT Y X XQ
    SHIFT PLOT Y X  XQ SUBSET X > 1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS                 = Sets the type for plot characters.
    LINES                      = Sets the type for plot lines.
    QUANTILE-QUANTILE PLOT     = Generates a q-q plot.
    TUKEY MEAN-DIFFERENCE PLOT = Generates a Tukey mean-difference
                                 plot.
    BIHISTOGRAM                = Generates a bihistogram.
    T-TEST                     = Carries out a 2-sample t test.
    F-TEST                     = Carries out a 2-sample F test.
 
Reference:
    "Introduction to Robust Estimation and Hypothesis Testing",
    Rand R. Wilcox, Academic Press, 1997.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    2003/2
 
Program:
    SKIP 25
    READ AUTO83B.DAT Y1 Y2
    .
    DELETE Y2 SUBSET Y2 < 0
    LABEL CASE ASIS
    Y1LABEL Difference between Y1 and Y2 Quantiles
    X1LABEL Quantiles for Y1
    CHARACTER X
    LINE BLANK
    TIC OFFSET 0.3 0.3
    TIC OFFSET UNITS DATA
    SHIFT PLOT Y2 Y1
 
-----SHIFT (LET)-------------------------------------
 
SHIFT
 
Name:
    SHIFT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Shift the contents of a variable either up or down.
 
Description:
    It is sometimes convenient to move the elements of a
    variable either up or down.  

    For example, to shift the contents of the variable Y that
    contains 5 elements up (or right) by one element into the
    output vector Y2, we mean

       Y(1)    =>     Y2(2)
       Y(2)    =>     Y2(3)
       Y(3)    =>     Y2(4)
       Y(4)    =>     Y2(5)
       Y(5)    =>     Y2(6)

    To shift the contents of Y down (or left) by one element, we mean

       Y(2)    =>     Y2(1)
       Y(3)    =>     Y2(2)
       Y(4)    =>     Y2(3)
       Y(5)    =>     Y2(4)

    One question is how do we define the end-point values for Y2
    (i.e., Y2(1) for the up shift and Y2(5) for the down shift)?

    Dataplot handles this by first doing

       Y2 = Y

    for all elements.  So for the up shift, Y2(1) = Y1(1) and
    for the down shift Y2(5) = Y(5).

Syntax:
    LET <y> = SHIFT <x>  <nshift>
    where <x> is a response variable;
          <nshift> is a number or parameter that specifies how
              how many elements to shift;
    and   <y> is a variable that contains the shifted values.
 
    The sign of NSHIFT specifies the direction.  If NSHIFT is
    negative, the shift is down (or left) and if NSHIFT is positive
    the shift is up (or right).  If NSHIFT is zero, then Y = X.

Examples:
    LET Y = SHIFT X NSHIFT
 
Note:
    If you want to handle the end points differently, then
    this can usually be accomplished with FOR clause.  For
    example, the set the end points to zero, do something like

       LET NSHIFT =5
       LET AVAL = 0
       LET Y2 = SHIFT Y NSHIFT
       LET Y2 = AVAL FOR I = 1 1 NSHIFT

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CIRCULAR SHIFT     = Perform a circular shift of a variable.
    SCATTER            = Save data from a variable to specified
                         rows of another variable based on an
                         index variable.
    SEQUENCE           = Generate a patterned sequence of values.
    SORT               = Sort a column of numbers.
    RANK               = Rank a column of numbers.
    CODE               = Code a column of numbers.
    SUBSET             = Specifies a subset to be included in a plot,
                         analysis, or LET command.
    RETAIN             = Retain specified rows or a subset of a
                         variable.
 
Applications:
    Data Transformation
 
Implementation Date:
    2009/2
 
Program:
    let y = normal random numbers for i = 1 1 10
    let nshift = 3
    let y2 = shift y nshift
    let nshift = -3
    let y3 = shift y nshift
    set write decimals 3
    print y y2 y3

-----SIEGEL TUKEY TEST------------------------------------------------
 
SIEGEL TUKEY TEST
 
Name:
    SIEGEL TUKEY TEST
 
Type:
    Analysis Command
 
Purpose:
    Perform a two sample Siegel-Tukey test that the standard deviations
    of two samples are equal.
 
Description:
    The Siegel-Tukey test is computed as follows:

        1. Combine the data from the two response variables and
           sort from smallest to largst.

        2. Assign rank 1 to the smallest observation, rank 2 to the
           largest observation, rank 3 to next largest observation,
           rank 4 to the second smallest observation.  Continue this
           pattern until all values are ranked.

           If there are an odd number of total observations, then
           omit the observation that is the median of the combined
           observations.

        3. Perform a Mann-Whitney (rank sum) test on the ranked
           values.

Syntax 1:
    <LOWER TAILED/UPPER TAILED> SIEGEL TUKEY TEST  <y1>  <y2>
                                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If LOWER TAILED is specified, a lower tailed test is performed
    (i.e., sigma1 < sigma2).  If UPPER TAILED is specified, an upper
    tailed test is performed (i.e., sigma1 > sigma2).  If neither
    LOWER TAILED or UPPER TAILED is specified, a two-tailed test is
    performed (i.e., sigma1 not equal sigma2).

Syntax 2:
    <LOWER TAILED/UPPER TAILED> SIEGEL TUKEY TEST  <y1>  ... <yk>
                                <SUBSET/EXCEPT/FOR qualification>
    where <y1> ... <yk> is a list of two or more response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs all the two-way Siegel-Tukey tests for the
    listed variables.  This syntax supports the TO syntax.

    If LOWER TAILED is specified, a lower tailed test is performed
    (i.e., sigma1 < sigma2).  If UPPER TAILED is specified, an upper
    tailed test is performed (i.e., sigma1 > sigma2).  If neither
    LOWER TAILED or UPPER TAILED is specified, a two-tailed test is
    performed (i.e., sigma1 not equal sigma2).

Examples:
    SIEGEL TUKEY TEST Y1  Y2
    SIEGEL TUKEY TEST Y1  Y2 Y3
    SIEGEL TUKEY TEST Y1  TO Y6
    SIEGEL TUKEY TEST Y1  Y2  SUBSET Y2 > 0
    LOWER TAILED SIEGEL TUKEY TEST Y1  Y2
    UPPER TAILED SIEGEL TUKEY TEST Y1  Y2

Note:
    The following parameters are saved after the F test is
    performed.

         STATVAL   - value of the test statistic
         STATCDF   - CDF of the test statistic
         PVALUE    - p-value of the two tailed test statistic
         PVALUELT  - p-value of the lower tailed test statistic
         PVALUEUT  - p-value of the upper tailed test statistic

    For an upper tailed test, the following parameters are saved

         CUTUPP90  - 90%   upper critical value
         CUTUPP95  - 95%   upper critical value
         CUTUP975  - 97.5% upper critical value
         CUTUPP99  - 99%   upper critical value
         CUTUP995  - 99.5% upper critical value
         CUTUP999  - 99.9% upper critical value

    For a lower tailed test, the following parameters are saved

         CUTLOW10  - 10%   lower critical value
         CUTLOW05  - 5%    lower critical value
         CUTLO025  - 2.5%  lower critical value
         CUTLOW01  - 1%    lower critical value
         CUTLO005  - 0.5%  lower critical value
         CUTLO001  - 0.1%  lower critical value

Note:
    In addition to the SIEGEL TUKEY TEST command, the
    following commands can also be used:

        LET STATVAL = SIEGEL TUKEY TEST        Y1 Y2
        LET STATCDF = SIEGEL TUKEY TEST CDF    Y1 Y2
        LET PVALUE  = SIEGEL TUKEY TEST PVALUE Y1 Y2
        LET PVALUE  = SIEGEL TUKEY LOWER TAIL TEST PVALUE Y1 Y2
        LET PVALUE  = SIEGEL TUKEY UPPER TAIL TEST PVALUE Y1 Y2

    In addition to the above LET commands, built-in statistics are
    supported for 30+ different commands (enter HELP STATISTICS for
    details).

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    BARTLETTS TEST                 = Perform a k-sample Bartlett test for
                                     homogeneous variances.
    LEVENE TEST                    = Perform a k-sample Levene test for
                                     homogeneous variances.
    SQUARED RANKS TEST             = Perform a k-sample squared ranks test
                                     for homogeneous variances.
    KLOTZ TEST                     = Perform a k-sample Klotz test
                                     for homogeneous variances.
    RATIO OF SD CONFIDENCE LIMITS  = Compute the confidence limtis for the
                                     ratio of two standard deviations.
    SD CONFIDENCE LIMITS           = Compute the confidence limits for the
                                     standard deviation.
    CHI-SQUARE TEST                = Performs a one sample chi-square test
                                     that the standard deviation is equal
                                     to a given value.
    T TEST                         = Performs a two-sample t test for
                                     equal means.
    CONFIDENCE LIMITS              = Compute the confidence limits for the
                                     mean of a sample.
    STANDARD DEVIATION             = Computes the standard deviation of a
                                     variable.
 
Reference:
    Higgins (2004), "Introduction to Modern Nonparametric Statistics,"
    Duxbury Press, pp. 52-53.


Applications:
    Confirmatory Data Analysis
 
Implementation Date:
    2023/06:
 
Program:
    . Step 1:   Define the data (example from Higgin's book)
    .
    let y1 = data 16.55 15.36 15.94 16.43 16.01
    let y2 = data 16.05 15.98 16.10 15.88 15.91
    .
    . Step 2:   Compute Siegel Tukey test statistic
    .
    let statva  = siegel tukey test        y1 y2
    let statcdf = siegel tukey test cdf    y1 y2
    let pvalue  = siegel tukey test pvalue y1 y2
    .
    siegel tukey test y1 y2

-----SIEVE PLOT (LET)--------------------------------
 
SIEVE PLOT
 
Name:
    SIEVE PLOT (LET)
 
Type:
    Graphics Command
 
Purpose:
    Generate a sieve plot for a two-way contingency table.

Description:
    Given two discrete variables where variable one has r
    possible values and variable two has c possible values,
    we can generate a cross-tabulation of these two variables.
    This results in a two-way, or RxC contingency table.

    We can define the following values for the contingency
    table:
   
       r     = the number of rows in the contingency table
       c     = the number of columns in the contingency table
       n(ij) = the observed frequency of the ith row and jth column
       m(ij) = the expected frequency of the ith row and jth column
       n(i+) = the observed frequency for the ith row
       n(+j) = the observed frequency for the jth row
       n(++) = the total sample size

    When the two variables are independent, then the expected
    frequency is:

       m(ij) = n(i+)*n(+j)/n(++)
 
    In a sieve plot, each m(ij) is represented by a rectangle.
    The width of the rectangle is proportional to the total
    frequency in each column, n(+j), and the height is
    proportional to the total frequency in each row, n(i+).
    The area of the rectangle is then proportional to m(ij).

    Each rectangle is then cross-ruled based on the observed
    frequency.  The deviations from independence are reflected
    in the density of the shading.  Denser shading indicates
    the observed frequency is greater than expected and
    sparse shading indicates the observed frequency is less
    than expected.  As an additional cue, positive and negative
    departures from independence can be coded with different
    colors.

Syntax 1:
    SIEVE PLOT <y1> <y2>     <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where you have raw data (i.e.,
    the data has not yet been cross tabulated into a two-way table).

Syntax 2:
    SIEVE PLOT <m>    <SUBSET/EXCEPT/FOR qualification>
    where <m> is a matrix containing the two-way table;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where we the data have already
    been cross-tabulated into a two-way contingency table.

Syntax 3:
    SIEVE PLOT <n11> <n12> <n21> <n22>
    where <n11> is a parameter containing the value for row 1,
                column 1 of a 2x2 table;
          <n12> is a parameter containing the value for row 1,
                column 2 of a 2x2 table;
          <n21> is a parameter containing the value for row 2,
                column 1 of a 2x2 table;
          <n22> is a parameter containing the value for row 2,
                column 2 of a 2x2 table.

    This syntax is used for the special case where you have a
    2x2 table.  In this case, you can enter the 4 values directly,
    although you do need to be careful that the parameters are
    entered in the order expected above.

Examples:
    SIEVE PLOT Y1 Y2
    SIEVE PLOT M
    SIEVE PLOT N11 N12 N21 N22

Note:
    The LINE and LINE COLOR commands can be used to set
    the attributes for the sieve plot.

       Setting 1  = the line style and color for the frame
                    of the rectangles
       Setting 2  = the line style and color for the cross-ruled
                    lines when the observed frequency is greater
                    than the expected frequency

       Setting 3  = the line style and color for the cross-ruled
                    lines when the observed frequency is less
                    than the expected frequency

    Although the program example below uses the TIC MARK LABEL
    commands to generate row and column labels, you may need
    to use the LEGEND or TEXT command to obtain more accurately
    centered labels.

Default:
    None
 
Synonyms:
    None

Related Commands:
    ASSOCIATION PLOT              = Generate an association plot.
    ROSE PLOT                     = Generate a Rose plot.
    BINARY TABULATION PLOT        = Generate a binary tabulation plot.
    ROC CURVE                     = Generate a ROC curve.
    CHI-SQUARE INDEPENDENCE TEST  = Perform a chi-square test for
                                    independence.
    ODDS RATIO INDEPENDENCE TEST  = Perform a log(odds ratio) test for
    FISHER EXACT TEST             = Perform Fisher's exact test.

References:
    Friendly (2000), "Visualizing Categorical Data", SAS Institute
    Inc., pp. 85-89.

    Riedwyl and Schupbach (1994), "Parquet Diagram to Plot
    Contingency Tables".  In Faulbaum, editor, "Softstat '93:
    Advances In Statistical Software", pp. 293-299,
    Gustav Fischer, New York.

Applications:
    Graphical Analysis of Categorical Data
 
Implementation Date:
    2007/6
 
Program:
    . Hair and Eye Color Data from page 61 of Friendly
    read matrix m
     5  29 14 16
    15  54 14 10
    20  84 17 94
    68 119 26 7
    end of data
    .
    label case asis
    tic mark label case asis
    title case asis
    title offset 2
    .
    x3label
    title Sieve Plot
    y1label displacement 12
    y1label Eye Color
    x1label Hair Color
    tic offset units data
    xlimits 1 4
    major xtic mark number 4
    minor xtic mark number 0
    xtic mark offset 0.5 0.5
    x1tic mark label format alpha
    x1tic mark label content Black Brown Red Blond
    ylimits 1 4
    major ytic mark number 4
    minor ytic mark number 0
    ytic mark offset 0.5 0.5
    y1tic mark label format alpha
    y1tic mark label content Green Hazel Blue Brown
    y1tic mark label justification right
    .
    line solid dash dash
    line color black blue green
    .
    sieve plot m

-----SIGN (LET)--------------------------------
 
SIGN
 
Name:
    SIGN (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the sign of a number and assign a -1 to negative numbers
    and a +1 to positive numbers (zero is treated as a positive
    number).
 
Syntax:
    LET <y2> = SIGN(<y1>,<n>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter containing decimal
               number(s);
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed sign values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SIGN(14.2835)
    LET A = SIGN(A1)
    LET X2 = SIGN(X1)
    LET X2 = SIGN(X1-4)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    INT    = Compute the integer portion of number.
    FRACT  = Compute the fractional portion of number.
    ROUND  = Round a number to a specified number of decimal places.
    MSD    = Compute the most significant digit of a number.
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y2 = SIGN(Y1)
    PRINT Y1 Y2
 
-----SIGNAL TO NOISE RATIO (LET)------------------------------
 
SIGNAL TO NOISE RATIO
 
Name:
    SIGNAL TO NOISE RATIO (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the signal to noise ratio of a variable.
 
Description:
    The sample signal to noise ratio (SNR) is defined as the ratio of
    the mean to the standard deviation:

         SNR = xbar/s

    where s is the sample standard deviation and xbar is the sample
    mean.

    This is the reciprocal of the coefficient of variation:

         cv = s/xbar

    That is, it shows the variability, as defined by the standard
    deviation, relative to the mean.

    This definition of signal to noise ratio should typically only be used
    for data measured on a ratio scale.  That is, the data should be
    continuous and have a meaningful zero.  Measurement data in the
    physical sciences and engineering are often on a ratio scale.
    As an example, temperatures measured on a Kelvin scale are on a
    ratio scale while temperaturs measured on a Celcius or Farenheit
    scale are interval scales rather than ratio scales.  Given a set
    of temperature measurements, the signal to noise ratio on the
    Celcius scale will be different than the signal to noise ratio
    on the Farenheit scale.

    Note that this is only one specific definition of the signal to noise
    ratio.  There are numerous other definitions in common usage that are
    not described here.

Syntax 1:
    LET <par> = SIGNAL TO NOISE RATIO <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <par> is a parameter where the signal to noise ratio value is
              saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Syntax 2:
    LET <par> = DIFFERENCE OF SIGNAL TO NOISE RATIO <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the difference of the
              signal to noise ratios is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET SNR = SIGNAL TO NOISE RATIO Y1
    LET SNR = SIGNAL TO NOISE RATIO Y1  SUBSET TAG > 2

    LET SNRDIFF = DIFFERENCE OF SIGNAL TO NOISE RATIO Y1 Y2

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    SNR is a synonym for SIGNAL TO NOISE
 
Related Commands:
    COEFFICIENT OF VARIATION   = Compute the coefficient of variation of
                                 a variable.
    RELATIVE VARIANCE          = Compute the relative variance of a
                                 variable.
    COEF OF VARI CONF LIMI     = Compute confidence limits for the
                                 coefficient of variation.
    COEFFICIENT OF DISPERSION  = Compute the coefficient of
                                 dispersion of a variable.
    MEAN                       = Compute the mean of a variable.
    STANDARD DEVIATION         = Compute the standard deviation of a
                                 variable.
 
Applications:
    Data Analysis
 
Implementation Date:
    2017/01
    2017/03: Added DIFFERENCE OF SIGNAL TO NOISE
 
Program 1:
    . Step 1:   Create the data
    .
    skip 25
    read zarr13.dat y
    skip 0
    set write decimals 6
    .
    let snr = signal to noise ratio y
    let snr = round(snr,3)
    .
    . Step 2:   Define plot control
    .
    title case asis
    title offset 2
    label case asis
    .
    y1label Signal to Noise Ratio
    x1label Bootstrap Sample
    title Bootstrap of Signal to Noise Ratio for ZARR13.DAT
    .
    bootstrap samples 2000
    bootstrap snr plot y
    .
    let bmean = round(bmean,3)
    let bsd   = round(bsd,3)
    let b025  = round(b025,3)
    let b975  = round(b975,3)
    justification center
    move 50 6
    text Sample SNR: ^snr, Mean of Bootstrap Samples: ^bmean, SD of Bootstrap Samples: ^bsd
    move 50 3.5
    text 2.5 Percentile: ^B025, 97.5 Percentile: ^B975
 
Program 2:
    . Step 1:   Create the data
    .
    skip 25
    read gear.dat y x
    skip 0
    set write decimals 6
    .
    . Step 2:   Define plot control
    .
    title case asis
    title offset 2
    label case asis
    .
    y1label Signal to Noise Ratio
    x1label Group
    title Signal to Noise Ratio for GEAR.DAT
    let ngroup = unique x
    xlimits 1 ngroup
    major x1tic mark number ngroup
    minor x1tic mark number 0
    tic mark offset units data
    x1tic mark offset 0.5 0.5
    y1tic mark offset 5 0
    .
    character X
    line blank
    .
    set statistic plot reference line average
    snr plot y x
    .
    tabulate snr y x

Program 3:
    SKIP 25
    READ IRIS.DAT Y1 TO Y4 X
    .
    LET A = DIFFERENCE OF SNR Y1 Y2
    SET WRITE DECIMALS 4
    TABULATE DIFFERENCE OF SNR Y1 Y2 X
    .
    XTIC OFFSET 0.2 0.2
    X1LABEL GROUP ID
    Y1LABEL DIFFERENCE OF SNR
    CHAR X
    LINE BLANK
    DIFFERENCE OF SNR PLOT Y1 Y2 X
    CHAR X ALL
    LINE BLANK ALL
    BOOTSTRAP DIFFERENCE OF SNR PLOT Y1 Y2 X 
 
-----SIGN TEST--------------------------------------
 
SIGN TEST
 
Name:
    SIGN TEST
 
Type:
    Analysis Command
 
Purpose:
    Perform a one sample or a paired two sample sign test.
 
Description:
    The t-test is the standard test for testing that the
    difference between population means for two paired
    samples are equal.  If the populations are non-normal,
    particularly for small samples, then the t-test may not
    be valid.  The sign test is an alternative that can be
    applied when distributional assumptions are suspect.
    However, it is not as powerful as the t-test when the
    distributional assumptions are in fact valid.  It can
    also be applied in the case where there is no quantitative
    scale, but it is possible to order the data (i.e., an

    To form the sign test, compute d(i) = X(i) - Y(i) where
    X and Y are the two samples.  Count the number of times
    d(i) is positive, R+, and the number of times it is
    negative, R-.  If the samples have equal means and the
    populations are symmetric, then R+ and R- should be
    similar.  If there are too many positives (R+) or
    negatives (R-), then we reject the hypothesis of
    equality.  Ties are excluded from the analysis.  Since
    there are only two choices (+ or -) for d(i), the test
    statistic for the sign test follows a binomial distribution
    with p=0.5.

    Note that the binonial distribution is discrete, so the
    significane level will typically not be exact.

    More formally, the hypothesis test is defined as follows.
    
       H0: u1 = u2
       Ha: u1 <> u2
       Test Statistic: S- = BINCDF(R-,0.5,N)
                       S+ = BINCDF(R+,0.5,N)
                       where BINCDF is the cumulative distribution
                       for the binomial distribution, R- is the 
                       number of minus signs (i.e., d(i) < 0), R+
                       is the number of plus signs (i.e., d(i) > 0),
                       and N is the sample size excluding ties
                       between the samples.
       Alpha: Typically set to .05.  Due to the discreteness of the
              binomial distribution, the actual significance level
              will not in most cases be exact.
       Critical Region:
              S+ < alpha:                  one sided test: MU1 < MU2
              S- < alpha:                  one sided test: MU1 > MU2
              alpha/2 < S+ < 1 - alpha/2:  two sided test: MU1 = MU2
       Conclusion: Reject null hypothesis if test statistic is
                   in critical region
 
    Although the above discussion was in terms of a paired two
    sample test, it can easily be adapted to the following
    additional cases:

       1) For the one sample case that the population mean is
          equal to a value d0, simply compute d(i) = x(i) - d0
          and calculate R+ and R- based on d(i).

       2) For the paired two sample case where we want to test
          that the difference between the two population means
          is equal to d0, compute d(i) = x(i) - y(i) - d0 and
          calculate R+ and R- based on d(i).
          
Syntax 1:
    <LOWER TAILED/UPPER TAILED> SIGN TEST  <y1>  <mu>
                                <SUBSET/EXCEPT/FOR qualification>
    where <LOWER TAILED/UPPER TAILED> is an optional keyword that
               specifies either a lower tailed or an upper tailed
               test;
          <y1> is a response variable;
          <mu> is an optional number or parameter that is the
               hypothesized mean value;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax implements the one sample sign test.  If <mu> is
    omitted, it will be assumed to be zero.

    If neither LOWER TAILED or UPPER TAILED is specified, the
    sign test will return the results for the two-tailed case,
    the lower tailed case, and the upper tailed case.  If LOWER
    TAILED is specified, then only the results for the lower tailed
    case will be printed.  If UPPER TAILED is specified, then only
    the results for the upper tailed case will be printed.

Syntax 2:
    <LOWER TAILED/UPPER TAILED> SIGN TEST  <y1>  <y2>
                                <SUBSET/EXCEPT/FOR qualification>
    where <LOWER TAILED/UPPER TAILED> is an optional keyword that
               specifies either a lower tailed or an upper tailed
               test;
          <y1> is the first response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax implements the two sample paired sign test where
    the hypothesized difference between the population means for
    the two samples is zero.

Syntax 3:
    SIGN TEST  <y1>  <y2>  <mu>  <SUBSET/EXCEPT/FOR qualification>
    where <LOWER TAILED/UPPER TAILED> is an optional keyword that
               specifies either a lower tailed or an upper tailed
               test;
          <y1> is the first response variable;
          <y2> is the second response variable;
          <mu> is a number or parameter that is the hypothesized
               difference between the means of the two samples;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax implements the two sample paired sign test where
    the hypothesized difference between the population means for
    the two samples is not equal to zero.

Syntax 4:
    <LOWER TAILED/UPPER TAILED> SIGN TEST  <y1>  ... <yk>
                                <SUBSET/EXCEPT/FOR qualification>
    where <LOWER TAILED/UPPER TAILED> is an optional keyword that
               specifies either a lower tailed or an upper tailed
               test;
          <y1> ... <yk> is a list of 1 to 30 response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax will implement all the pairwise sign tests for
    the listed response variables.  For example,

         SIGN TEST Y1 TO Y4

    is equivalent to

         SIGN TEST Y1 Y2
         SIGN TEST Y1 Y3
         SIGN TEST Y1 Y4
         SIGN TEST Y2 Y3
         SIGN TEST Y2 Y4
         SIGN TEST Y3 Y4

    If either the first argument or the last argument is a parameter,
    this will be interpreted as the hypothesized mean value.

Examples:
    SIGN TEST Y1  0
    SIGN TEST Y1  Y2
    SIGN TEST Y1  Y2 MU
    SIGN TEST Y1  Y2  SUBSET TAG > 2
 
Note:
    The SIGN TEST will accept matrix arguments.  Since this is a
    paired test, the total number of elements for each variable
    or matrix argument must be the same.  Matrices are parsed in
    column order when generating the test.
 
Note:
    Dataplot saves the following internal parameters after a
    sign test:

        STATVAL   = the value of the test statistic
        STATCDF   = the CDF of the test statistic
        PVALUE    = the p-value for the two-sided test
        PVALUELT  = the p-value for the lower tailed test
        PVALUEUT  = the p-value for the upper tailed test
        CUTLOW50  = the 50% lower tailed critical value
        CUTUPP50  = the 50% upper tailed critical value
        CUTLOW80  = the 80% lower tailed critical value
        CUTUPP80  = the 80% upper tailed critical value
        CUTLOW90  = the 90% lower tailed critical value
        CUTUPP90  = the 90% upper tailed critical value
        CUTLOW95  = the 95% lower tailed critical value
        CUTUPP95  = the 95% upper tailed critical value
        CUTLOW99  = the 99% lower tailed critical value
        CUTUPP99  = the 99% upper tailed critical value
        CUTLO999  = the 99.9% lower tailed critical value
        CUTUP999  = the 99,9% upper tailed critical value
 
Note:
    The following statistics are also supported:

        LET A = ONE SAMPLE SIGN TEST                   Y
        LET A = ONE SAMPLE SIGN TEST CDF               Y
        LET A = ONE SAMPLE SIGN TEST PVALUE            Y
        LET A = ONE SAMPLE SIGN TEST LOWER TAIL PVALUE Y
        LET A = ONE SAMPLE SIGN TEST UPPER TAIL PVALUE Y

        LET A = TWO SAMPLE SIGN TEST                   Y1 Y2
        LET A = TWO SAMPLE SIGN TEST CDF               Y1 Y2
        LET A = TWO SAMPLE SIGN TEST PVALUE            Y1 Y2
        LET A = TWO SAMPLE SIGN TEST LOWER TAIL PVALUE Y1 Y2
        LET A = TWO SAMPLE SIGN TEST UPPER TAIL PVALUE Y1 Y2

    In addition to the above LET command, built-in statistics are
    supported for about 20+ different commands (enter HELP STATISTICS
    for details).

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    T-TEST                     = Compute a t-test.
    SIGNED RANK TEST           = Compute a signed rank test.
    CHI-SQUARED 2 SAMPLE TEST  = Compute a two sample chi-square
                                 test.
    BIHISTOGRAM                = Generates a bihistogram.
    QUANTILE-QUANTILE PLOT     = Generate a quantile-quantile plot.
    BOX PLOT                   = Generates a box plot.
 
Reference:
    Conover (1999), "Practical Non-Parametric Statistics", Third Edition,
    Wiley, pp. 157-165.

    Snedecor and Cochran (1989), "Statistical Methods", Eigth Edition,
    Iowa State University Press, pp. 138-140.
 
Applications:
    Confirmatory Data Analysis
 
Implementation Date:
    1999/5
    2000/8: bug fix for 2-sided interval.  Was actually calculating a
            90% interval rather than a 95% interval.
    2011/4: support for <LOWER TAILED/UPPER TAILED> option
    2011/4: support for Syntax 4 case, support for matrix arguments,
            support for TO syntax
 
Program:
    SKIP 25
    READ NATR332.DAT Y1 Y2
    SIGN TEST Y1 Y2
 
-----SIGNED RANK TEST--------------------------------------
 
SIGNED RANK TEST
 
Name:
    SIGNED RANK TEST
 
Type:
    Analysis Command
 
Purpose:
    Perform a one sample or a paired two sample signed rank
    test.
 
Description:
    The t-test is the standard test for testing that the
    difference between population means for two paired
    samples are equal.  If the populations are non-normal,
    particularly for small samples, then the t-test may not
    be valid.  The signed rank test is an alternative that can
    be applied when distributional assumptions are suspect.
    However, it is not as powerful as the t-test when the
    distributional assumptions are in fact valid.

    The signed rank test is also commonly called the Wilcoxon
    signed rank test or simply the Wilcoxon test.

    To form the signed rank test, compute d(i) = X(i) - Y(i)
    where X and Y are the two samples.  Rank the d(i) without
    regard to sign.  Tied values are not included in the Wilcoxon
    test.  After ranking, restore the sign (plus or
    minus) to the ranks.  Then compute W+ and W- as the
    sums of the positive and negative ranks respectively.
    If the two population means are in fact equal, then 
    the sums of the ranks should also be nearly equal.  If the
    difference between the sum of the ranks is too great, we
    reject the null hypothesis that the population means are
    equal.

    Significance levels are based on the fact that if there
    is no difference in the population means, then there
    are 2**N equally likely ways for the N ranks to recieve
    signs.

    More formally, the hypothesis test is defined as follows.
    
       H0: u1 = u2
       Ha: u1 <> u2
       Test Statistic: W=MIN(W-,W+) where the computation of
                       W- and W+ is discussed above.
       Alpha: Typically set to .05.  Due to the discreteness of the
              ranks, the actual significance level will not in most
              cases be exact.
       Critical Region: For small samples (N <= 30), the critical
              regions have been tabulated.  For N > 30,
              the test statistic W approaches a normal
              distribution with mean N(N+1)/4 and a
              standard deviation of SQRT[N(N+1)(2*N+1)/24].
              The critical regions are thus based on the normal
              percent point function.  That is, for a 2-sided
              test, 

              Uw - Sw*NORPPF(ALPHA/2) < W < Uw + Sw*NORPPF(1-ALPHA/2)
    
              where Uw and Sw are the mean and standard deviation
              of W as described above and NORPPF is the normal
              percent point function.
       Conclusion: Reject null hypothesis if test statistic is
                   in critical region
 
    Although the above discussion was in terms of a paired two
    sample test, it can easily be adapted to the following
    additional cases:

       1) For the one sample case that the population mean is
          equal to a value d0, simply compute d(i) = x(i) - d0
          and calculate W+ and W- based on d(i).

       2) For the paired two sample case where we want to test
          that the difference between the two population means
          is equal to d0, compute d(i) = x(i) - y(i) - d0 and
          calculate W+ and W- based on d(i).
          
Syntax 1:
    SIGNED RANK TEST  <y1>  <mu>    <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a response variable;
          <mu> is a number or parameter that is the hypothesized
               mean value;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax implements the one sample signed rank test.

Syntax 2:
    SIGNED RANK TEST  <y1>  <y2>    <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax implements the two sample paired signed rank test
    where the hypothesized difference between the population means
    for the two samples is zero.

Syntax 3:
    SIGNED RANK TEST  <y1>  <y2>  <mu>
                            <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <mu> is a number or parameter that is the hypothesized
               difference between the means of the two samples;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax implements the two sample paired signed rank test
    where the hypothesized difference between the population means
    for the two samples is equal to a non-zero value.

Examples:
    SIGNED RANK TEST Y1  0
    SIGNED RANK TEST Y1  Y2
    SIGNED RANK TEST Y1  Y2 MU
    SIGNED RANK TEST Y1  Y2  SUBSET TAG > 2
 
Note:
    DATAPLOT automatically prints the test statistic for both
    one sided and two sided tests.
 
Note:
    Dataplot saves the following internal parameters after a
    sign test:

        STATVAL   = W, i.e., the minimum of the signed ranks
        STATCD2   = the normal cdf value of W
        CUTLOW90  = 0.05 critical value
        CUTUPP90  = 0.95 critical value
        CUTLOW95  = 0.025 critical value
        CUTUPP95  = 0.975 critical value
        CUTLOW99  = 0.005 critical value
        CUTUPP99  = 0.995 critical value
 
    Note that the above critical values are the lower and upper
    tails for two sided tests (i.e., each tail is alpha/2.  For
    example, CUTLOW90 is the lower 5% of the normal percent point
    function (adjusted for the mean and standard deviation).  This
    is the critical regions for alpha = 0.10, so there is 0.05 in
    each tail.

Note:
    The sign test is also an alternative to the t test for 
    paired samples when the normality assumption is in doubt.
    The signed rank test is generally preferred over the sign
    test because it takes into account both the sign of the
    difference and the magnitude of the difference for paired
    samples while the sign test only takes the difference of 
    the sign into account.

Note:
    From Conover, the signed rank test is based on the following
    assumptions:

        1. The distribution of each d(i) is symmetric.

        2. The d(i) are mutually independent.

        3. The d(i) all have the same mean.

        4. The measurement scale of the d(i)'s is at least interval.

    So the signed rank test weakens the assumption of normality of the
    paired t-test to an assumption of symmetry.  The signed rank test is
    more powerful than a sign test (it takes the magnitude of the
    differences into account as well as the sign), but it has stronger
    assumptions than the sign test.  So if your data is at approximately
    symmetric, then the signed rank test is preferred to the sign test.
    However, if the symmetry assumption is not reasonable, the sign test
    is preferred.

    Also according to Conover, the null hypothesis can be stated either
    in terms of the mean or the median.  This is due to the assumption
    of symmetry.

Note:
    The following statistics are also supported:

        LET A = ONE SAMPLE WILCOXON SIGNED RANK TEST         Y
        LET A = ONE SAMPLE WILCOXON SIGNED RANK TEST CDF     Y
        LET A = ONE SAMPLE WILCOXON SIGNED RANK TEST PVALUE  Y
        LET A = ONE SAMPLE WILCOXON SIGNED RANK TEST LOWER ...
                TAIL PVALUE Y
        LET A = ONE SAMPLE WILCOXON SIGNED RANK TEST UPPER ...
                TAIL PVALUE Y

        LET A = TWO SAMPLE WILCOXON SIGNED RANK TEST        Y1 Y2
        LET A = TWO SAMPLE WILCOXON SIGNED RANK TEST CDF    Y1 Y2
        LET A = TWO SAMPLE WILCOXON SIGNED RANK TEST PVALUE Y1 Y2
        LET A = TWO SAMPLE WILCOXON SIGNED RANK TEST LOWER  ...
                TAIL PVALUE Y1 Y2<BR>
        LET A = TWO SAMPLE WILCOXON SIGNED RANK TEST UPPER ...
                TAIL PVALUE Y1 Y2

    In addition to the above LET command, built-in statistics are
    supported for about 20+ different commands (enter HELP STATISTICS
    for details).

Default:
    None
 
Synonyms:
    The following are synonyms for SIGNED RANK TEST:

        WILCOXON SIGNED RANK TEST
        WILCOXON SIGNED RANK
        WILCOXON SIGN TEST
        WILCOXON TEST
        SIGNED RANK
 
Related Commands:
    T-TEST                     = Compute a t-test.
    SIGN TEST                  = Compute a sign test.
    CHI-SQUARED 2 SAMPLE TEST  = Compute a two sample chi-square
                                 test.
    BIHISTOGRAM                = Generates a bihistogram.
    QUANTILE-QUANTILE PLOT     = Generate a quantile-quantile plot.
    BOX PLOT                   = Generates a box plot.
 
Reference:
    Conover (1999), "Practical Non-Parametric Statistics," Third Edition,
    Wiley, pp. 352-364.

    Snedecor and Cochran (1989), "Statistical Methods," Eigth Edition,
    Iowa State University Press, pp. 140-142.
 
Applications:
    Confirmatory Data Analysis
 
Implementation Date:
    1999/5
    2011/05: Switch algorithm to that given in Conover.
 
Program:
    SKIP 25
    READ NATR332.DAT Y1 Y2
    SIGNED RANK TEST Y1 Y2
 
-----SIN (LET)---------------------------------------------------
 
SIN
 
Name:
    SIN (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the sine for a variable or parameter.
 
Description:
    The sine is defined for all real numbers and the returned value
    will be between -1 and 1.  By default, the angle is specified in
    radian units.  To use degree values, enter the command ANGLE UNITS
    DEGREES (ANGLE UNITS RADIANS resets it).
 
Syntax:
    LET <y2> = SIN(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed sine value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SIN(-2)
    LET A = SIN(A1)
    LET X2 = SIN(X1)
    LET X2 = SIN(PI/2)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    COS      = Compute the cosine.
    TAN      = Compute the tangent.
    COT      = Compute the cotangent.
    SEC      = Compute the secant.
    CSC      = Compute the cosecant.
    ARCCOS   = Compute the arccosine.
    ARCSIN   = Compute the arcsine.
    ARCTAN   = Compute the arctangent.
    ARCCOT   = Compute the arccotangent.
    ARCSEC   = Compute the arcsecant.
    ARCCSC   = Compute the arcsecant.
 
Reference:
    Consult any standard trigonometry or pre-calculus textbook.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    X1LABEL ANGLE VALUES (RADIANS)
    Y1LABEL SINE VALUE
    TITLE AUTOMATIC
    YLIMITS -1 1
    YTIC OFFSET 0.2 0.2
    PLOT SIN(X) FOR X = -3.1 .05 3.1
 
-----SINE AMPLITUDE PLOT-----------------------------------------
 
SINE AMPLITUDE PLOT
 
Name:
    SINE AMPLITUDE PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a sine amplitude plot.
 
Description:
    A sine amplitude plot is a plot consisting of subsample sine
    amplitude versus subsample index.  The subsample sine amplitude is
    the approximate least squares estimate of the amplitude in a
    single-frequency sinusoidal model based on data from that subsample
    only.  The sine amplitude plot is used to answer the question--
    "Does the subsample amplitude change over different subsamples?".
    It consists of:
       Vertical   axis = subsample sine amplitude;
       Horizontal axis = subsample index.
    The sine amplitude plot yields 2 traces:
       1. a subsample sine amplitude trace; and
       2. a full-sample sine amplitude reference line.
    Like usual, the appearance of these 2 traces is
    controlled by the first 2 settings of the LINES,
    CHARACTERS, SPIKES, BARS, and similar attributes.
 
Syntax:
    SINE AMPLITUDE PLOT  <y>  <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    SINE AMPLITUDE PLOT Y X
    SINE AMPLITUDE PLOT Y X1
 
Default:
    None
 
Synonyms:
    SA PLOT
 
Related Commands:
    CHARACTERS              = Sets the type for plot char.
    LINES                   = Sets the type for plot lines.
    SINE FREQUENCY PLOT     = Generates a sine frequency plot.
    COMPLEX DEMOD AMPL PLOT = Generate a complex demodulation
                              amplitude plot.
    COMPLEX DEMOD FREQ PLOT = Generate a complex demodulation
                              frequency plot.
    RANGE PLOT              = Generates a range plot.
    MEAN PLOT               = Generates a mean plot.
    AUTOCORRELATION PLOT    = Generates a autocorrelation plot.
    SPECTRAL PLOT           = Generates a spectral plot.
    BOX PLOT                = Generates a box plot.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Time Series Analysis
 
Implementation Date:
    88/2
 
Program:
    TITLE AUTOMATIC
    LET  X = SEQUENCE .1 .1 10.01
    LET AMP = SEQUENCE 0.1 25 0.1 0.405
    LET Y = AMP*SIN(X)
    LET TAG = SEQUENCE 1 25 1 4
    MULTIPLOT 2 1; MULTIPLOT CORNER COORDINATES 0 0 100 100
    PLOT Y X
    SINE AMPLITUDE PLOT Y TAG
    END OF MULTIPLOT
 
-----SINE FREQUENCY PLOT-----------------------------------------
 
SINE FREQUENCY PLOT
 
Name:
    SINE FREQUENCY PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a sine frequency plot.
 
Description:
    A sine frequency plot is a plot consisting of subsample sine
    frequency versus subsample index.  The subsample sine frequency is
    the approximate least squares estimate of the frequency in a
    single-frequency sinusoidal model based on data from that subsample
    only.  The sine frequency plot is used to answer the question--
    "Does the subsample frequency change over different subsamples?".
    It consists of:
       Vertical   axis = subsample sine frequency;
       Horizontal axis = subsample index.
    The sine frequency plot yields 2 traces:
       1. a subsample sine frequency trace; and
       2. a full-sample sine frequency reference line.
    Like usual, the appearance of these 2 traces is
    controlled by the first 2 settings of the LINES,
    CHARACTERS, SPIKES, BARS, and similar attributes.
 
Syntax:
    SINE FREQUENCY PLOT  <y>  <x>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    SINE FREQUENCY PLOT Y X
    SINE FREQUENCY PLOT Y X1
 
Default:
    None
 
Synonyms:
    SF PLOT
 
Related Commands:
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    SINE AMPLITUDE PLOT     = Generates a sine amplitude plot.
    COMPLEX DEMOD AMPL PLOT = Generates a complex demodulation
                              amplitude plot.
    COMPLEX DEMOD FREQ PLOT = Generates a complex demodulation
                              frequency plot.
    RANGE PLOT              = Generates a range plot.
    MEAN PLOT               = Generates a mean plot.
    AUTOCORRELATION PLOT    = Generates an autocorrelation plot.
    BOX PLOT                = Generates a box plot.
    RANGE PLOT              = Generates a range plot.
    MEAN PLOT               = Generates a mean plot.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Time Series Analysis
 
Implementation Date:
    88/2
 
Program:
    TITLE AUTOMATIC
    LET  X = SEQUENCE .1 .1 10.01
    LET FREQ = SEQUENCE 1.0 25 .5 2.5
    LET Y = SIN(FREQ*X)
    LET TAG = SEQUENCE 1 25 1 4
    MULTIPLOT 2 1; MULTIPLOT CORNER COORDINATES 0 0 100 100
    PLOT Y X
    SINE FREQUENCY PLOT Y TAG
    END OF MULTIPLOT
 
-----SINE TRANSFORM (LET)------------------------------------------
 
SINE TRANSFORM
 
Name:
    SINE TRANSFORM (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the sine transform of a variable.
 
Description:
    The sine transform converts a time domain function into a frequency
    domain function.  In practice, functions are sampled at equally
    spaced discrete points.  The discrete sine transform is:
        F(k) = SUM(j=0 to N-1) [f(j)sin(PI*j*k/N)]
    where f(j) is the data array for j = 0, 1, ... , N-1.
 
    DATAPLOT calculates the discrete sine transform.  If you wish to
    calculate these transforms for a function, then evaluate this
    function at a series of points.
 
    See the REFERENCE section below for references which give a more
    detailed explanation of sine transforms.
 
Syntax:
    LET <r1> = SINE TRANSFORM <y1> <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a response variable for which the sine transform is to
               be computed;
          <r1> is a variable containing the computed sine transform;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET RPART = SINE TRANSFORM Y1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    FOURIER TRANSFORM  = Compute the Fourier transform.
    INVERSE FOUR TRANS = Compute the inverse cosine transform.
    FFT                = Compute the fast cosine transform.
    INVERSE FFT        = Compute the inverse FFT.
    COSINE TRANSFORM   = Compute the cosine transformation.
    SPECTRAL PLOT      = Generate a spectral plot.
 
Reference:
    "Numerical Recipes: The Art of Scientific Computing (FORTRAN
    Version)", Press, Flannery, Teukolsky, and Vetterling.  Cambridge
    University Press, 1989 (chapter 12).
 
    "Fourier Analysis of Time Series: An Introduction", Peter
    Bloomfield, John Wiley and Sons, 1976.
 
Applications:
    Frequency analysis of time series, signal processing
 
Implementation Date:
    87/5
 
Program:
    TITLE SINE TRANSFORM
    LEGEND 1 TIME SERIES SMOOTHING
    .
    LET X = SEQUENCE 0 .1 25.55
    LET YS = SIN(X)
    LET YN = NORMAL RANDOM NUMBERS FOR I = 1 1 256
    LET YN = YN/10
    LET Y = YS+YN
    .
    LET U  = SINE TRANSFORM Y
    LET NU = NUMBER U
    LET XU = SEQUENCE 1 1 NU
    LET XU = XU+50
    .
    LET U = 2.5*U
    PLOT U VS XU
 
-----SINGLE SAMPLE ACCEPTANCE PLAN---------------------------------
 
SINGLE SAMPLE ACCEPTANCE PLAN
 
Name:
    SINGLE SAMPLE ACCEPTANCE PLAN
 
Type:
    Analysis Command
 
Purpose:
    Generates a single sample acceptance plan.
 
Description:
    A lot acceptance sampling plan is a sampling scheme and a
    set of rules for making decisions.  The decision, based on
    counting the number of defectives in a sample, can be to
    accept the lot, reject the lot, or to take another sample.

    For a single sampling plan, one sample of items is selected
    at random from a lot and the disposition of the lot is
    determined from the resulting information.  These plans are
    also denoted as (n,c) plans since there are n observations
    and the lot is rejected if there are more than c defectives.
 
    Single sample acceptance plans are the most common and
    easiest plans to use.  However, they are not the most
    efficient in terms of the average number of samples needed.

    The input to this command is the following four parameters:
       1) P1 = the acceptable quality level (AQL).  The AQL is the
          a proportion defective that is the base line requirement
          for the quality of the producer's product.  The producer
          would like to design a sampling plan such that there
          is a high probability of accepting a lot that has a
          defect level less than or equal to the AQL.  In Dataplot,
          this value should be entered as a proportion (i.e., 
          a value between 0 and 1.0).
       2) P2 = the lot tolerance percent defective (LTPD).  The
          LTPD is a designated high defect level that would be
          unacceptable to the consumer.  The consumer would like
          the sampling plan to have a low probability of accepting
          a lot with a defect level as high as the LTPD.  In
          Dataplot, this value should be entered as a proportion
          (i.e., a value between 0 and 1.0).

          Note that P2 should be greater than P1.

       3) ALPHA = the Type I Error (Producers Risk).  This is the
          probability, for a given (n,c) sampling plan, of 
          rejecting a lot that has a defect level equal to the
          AQL.  The producer suffers when this occurs because a
          lot with acceptable was rejected.  Typical values for
          ALPHA range from 0.2 to 0.01.
       4) BETA = the Type II Error (Consumers Risk).  This is the
          probability, for a given (n,c) sampling plan, of 
          accepting a lot with a defect level equal to the
          LTPD.  The consumer suffers when this occurs because
          a lot with unacceptable quality was accepted.  Typical
          values for BETA range from 0.2 to 0.01.

    The output is the following two numbers:
       1) N = the size sample to collect
       2) C = reject the lot if this number of defectives
              exceeded

Syntax:
    SINGLE SAMPLE ACCEPTANCE PLAN <p1> <p2> <alpha> <beta>
    where <p1> is a number or parameter that specifies the AQL;
          <p2> is a number of parameter that specifies the LTPD;
          <alpha> is a number or parameter that is the producers
               risk;
    and where <beta> is a number or parameter that is the 
              consumers risk.
 
Examples:
    SINGLE SAMPLE ACCEPTANCE PLAN 0.05 0.10 0.01 0.10

    LET P1 = 0.01
    LET P2 = 0.05
    LET ALPHA = 0.01
    LET BETA = 0.10
    SINGLE SAMPLE ACCEPTANCE PLAN P1 P2 ALPHA BETA
 
Note:
    In addition to printing the values of N and C, Dataplot
    stores these values in the internal parameters SSN and 
    SSNC.  These parameters can be used in subsequent Dataplot
    analysis if needed.
 
Note:
    Dataplot provides the following related macros:

       OC_SSB.DP  - generate an Operating Characteristic (OC) curve
                    assuming binomial probabilities.  The OC
                    curve is a plot of probability of acceptance
                    versus percent defective.
       OC_SSA.DP  - generate an Operating Characteristic (OC) curve
                    assuming hypergeometric probabilities.  The OC
                    curve is a plot of probability of acceptance
                    versus percent defective.
       AOQSS.DP   - generate an Average Outgoing Quality (AOQ) curve.
                    For non-destructive samples, rejected lots are
                    often 100% inspected and defective units are
                    replaced with good units.  This means that the
                    only defective units are those in lots that
                    were accepted.  The AOQ is the long term defect
                    level for these combined lots.  The AOQ curve
                    is a plot of this AOQ versus percent defective.
       ATISS.DP   - generate an Average Total Inspection (ATI) curve.
                    The ATI curve is a plot of probability of
                    acceptance versus lot fraction defective. 
           
    You can enter LIST <macro> where <macro> is the name of one
    of the macros above for details on how to use them.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CONTROL CHART  = Generate a control chart.
    CP             = Compute a Cp capability index.
    CUSUM ARL      = Generate a cusum average run length chart.
 
Reference:
    Douglas Montgomery, "Introduction to Statistical Quality
    Control", John wiley, 1991.
 
Applications:
    Quality Control
 
Implementation Date:
    1999/3

    2001/8: Updated code to print an error message if P2 <= P1
 
Program:
    LET P1 = 0.01
    LET P2 = 0.05
    LET ALPHA = 0.05
    LET BETA = 0.10
    SINGLE SAMPLE ACCEPTANCE PLAN P1 P2 ALPHA BETA
    LET N = SSN 
    LET C = SSC
    . Purpose--Generate an Operating Characteristic curve for a
    .          single sample plan.
    .          The OC is defined as:
    .            BINCDF(c,p,n) versus p
    .          where 
    .            n      = sample size
    .            c      = acceptance number for defectives
    .            p      = desired binomial probabilities
    .
    LABEL CASE ASIS
    TITLE CASE ASIS
    Y1LABEL Probability of Acceptance, Pa
    X1LABEL Lot Fraction Defective, p
    TITLE OC Single Sample (^SSN, ^SSC) Curve
    .
    PLOT BINCDF(SSC,P,SSN) FOR P = 0.001 0.001 0.20

-----SINH (LET)---------------------------------------------------
 
SINH
 
Name:
    SINH (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the hyperbolic sine for a variable or parameter.
 
Description:
    The formula for the hyperbolic sine is:
        sinh(x) = (e**x - e**-x)/2
    This function is defined for all real x.  The range is negative
    infinity to positive infinity.
 
Syntax:
    LET <y2> = SINH(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed hyperbolic sine value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SINH(-2)
    LET A = SINH(A1)
    LET X2 = SINH(X1)
    LET X2 = SINH(PI/2)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SIN      = Compute the sine.
    COS      = Compute the cosine.
    TAN      = Compute the tangent.
    COT      = Compute the cotangent.
    SEC      = Compute the secant.
    CSC      = Compute the cosecant.
    ARCCOS   = Compute the arccosine.
    ARCSIN   = Compute the arcsine.
    ARCTAN   = Compute the arctangent.
    ARCCOT   = Compute the arccotangent.
    ARCSEC   = Compute the arcsecant.
    ARCCSC   = Compute the arcsecant.
    COSH     = Compute the hyperbolic cosine.
    TANH     = Compute the hyperbolic tangent.
    COTH     = Compute the hyperbolic cotangent.
    SECH     = Compute the hyperbolic secant.
    CSCH     = Compute the hyperbolic cosecant.
    ARCCOSH  = Compute hyperbolic arccosine.
    ARCCOTH  = Compute hyperbolic arccotangent.
    ARCCSCH  = Compute hyperbolic arccosecant.
    ARCSECH  = Compute hyperbolic arcsecant.
    ARCSINH  = Compute hyperbolic arcsine.
    ARCTANH  = Compute hyperbolic arctangent.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    TITLE AUTOMATIC
    Y1LABEL HYPERBOLIC SINE VALUE
    PLOT SINH(X) FOR X = -5 .1 5
 
-----SINHINT (LET)--------------------------------
 
SINHINT
 
Name:
    SINHINT (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the hyperbolic sine integral.
 
Description:
    The hyperbolic sine integral is defined as:
        Shi(X) = INTEGRAL(SINH(t)/t)dt
    where the integral is taken from 0 to x and SINH is the hyperbolic
    sine function.

Syntax:
    LET <y2> = SINHINT(<x>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-zero number, variable, or parameter;
          <y2> is a variable or a parameter (depending on what <x> is
               where the computed hyperbolic sine integral values
               are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SINHINT(0.1)
    LET A = SINHINT(-0.1)
    LET X2 = SINHINT(X)
 
Note:
    DATAPLOT uses the routine SICIEI written by Irene Stegum and
    Ruth Zucker of NIST (see the REFERENCE section below).

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SININT     = Compute the hyperbolic sine integral.
    COSINT     = Compute the hyperbolic cosine integral.
    COSHINT    = Compute the hyperbolic cosine integral.
    EXPINTN    = Compute the exponential integral of order N.
    LOGINT     = Compute the logarithmic integral.
    DAWSON     = Compute Dawson's integral.
 
Reference:
    "SICIEI: Automatic Computing Methods for Special FUnctions.  Part
    III. The Sine, Cosine, Exponential Integrals and Related
    Functions", Stegum and Zucker, Journal of Research of the National
    Bureau of Standards, 80B(2), 1976.

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 5).
 
Applications:
    Special Functions
 
Implementation Date:
    94/9
 
Program:
    TITLE AUTOMATIC
    PLOT SINHINT(X) FOR X = -10 0.1 10
 
-----SINGULAR VALUES (LET)---------------------------------
 
SINGULAR VALUES
 
Name:
    SINGULAR VALUES (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the singular values of a matrix.
 
Description:
    DATAPLOT uses the singular value decomposition (SVD) to compute
    the singular values.
 
    If X is a matrix with row and column dimensions n and p
    respectively, then an n by n orthogonal matrix U and a p by p
    orthogonal matrix V can be found such that:
           U'XV = [ SIGMA]    - if n >= p
                  [  0   ]
           U'XV = [SIGMA 0]   - if n < p
    where SIGMA is a m by m diagonal matrix (m is the minimum of
    n and p).  The diagonal elements of SIGMA are the singular values
    of X and they are stored from largest to smallest.  Singular values
    of zero (or near zero) indicate that the matrix is singular (i.e.,
    not of full rank) or ill-conditioned.  Chapters 2 and 14 of the
    Numerical Recipes book describe some applications of the SVD.
 
    For large matrices, it can be impractical to compute U (which is
    n by n).  However, U can be partitioned into
            U = (U1, U2)
    where U1 is n by p.  Then
            X = U1xSIGMAxV'
    is called the singular value factorization of X.  Several
    multivariate statistical techniques are based on this
    factorization.
 
Syntax:
    LET <resp> = SINGULAR VALUES <mat1>
              <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the singular values are to be
                 computed;
          <resp> is a variable where the resulting singular values are
                 saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET C = SINGULAR VALUES A
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPAL COMPONENTS = Compute the principal components of a
                           matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    "LINPACK User's Guide", Dongarra, Bunch, Moler, Stewart.  Siam,
    1979.
 
    "Numerical Recipes: The Art of Scientific Programming (FORTRAN
    Version)", Press, Flannery, Teukolsky, and Vetterling.  Cambridge
    University Press, 1989 (chapter 2).
 
Applications:
    Linear Algebra, Multivariate Analysis
 
Implementation Date:
    93/8
 
Program:
    . SOURCE: "GRAPHICAL EXPLORATORY DATA ANALYSIS", DU TOIT, ET AL
    . 28 STUDENTS FROM ABILITY TEST DATA SET (PAGE 6)
    .
    DIMENSION 100 COLUMNS
    READ MATRIX X
    11 19 21 21 18 20 21 15 14 15 13 15 16 19 19 19 20 17 17 39 21  9
    11 21 20 15 24 22 18 11 18 16 19 14 17 21 15 17 18 18 19 42 22  4
     0 18 19 16 18 18 23 11 13 13 15 11 11 15 18 13 15 18 13 38 18  6
     0 18 23 10 18 16 16 11  9  8 15  6  9 12 16  8 13  9 15 34 15  9
     0 24 24 19 20 23 24 22 18 16 19 16 19 19 21 21 20 18 20 46 21  2
     1 19 19 23 21 23 23  9  8 13 15 20 15 17 12 20 16 16 21 35 18  9
     0 21 20 19 21 21 23 11 16 11 18 18 14 21 17 14 19 18 16 42 19  4
     0 21 20 21 20 16 22  7 11 17 16  8 10 13 17 16 17 15 11 28 20  9
     1 19 20 19 22 18 21 11 12  7 15  9 11 13 12 13 17 12 12 38 19  8
     1 19 23 22 22 16 25 12 15 16 19 15 10 15 20 18 18 17 13 33 18  9
     0 17 13  8 18 13 18 12  8  9 12 12 11  9 14 15 12 13  9 23 16  9
    10 21 22 22 15 23 23 16 12 16 15 13 14 19 17 16 18 19 18 42 24  9
    11 18 18 17 16 15 22  8 11 10 16  8 14 10 13 10 14  9 14 27 14  8
    10 13 18 21 16 17 15 11 12 11  9 11 11 16 18 14 13 15 18 24 15  9
    11 17 13 17 20 22 19 15 11 11 12 11 13 15 15 15 13 16 12 33 10  9
    10 18 12  9  9 15 17  9  5  3 12  7  7 12 10 10 13 10 12 27 12  9
    10 22 15 24 17 15 20 10 12 12 11  9 12 19 16 16  8 11 17 30 22  6
    10 18 17 18 18 13 18 14 12 15 11 10  9 21 14 12 15 11 13 31 16  9
    10 17 15 14 14 12 13  9 10 11  9  7 11 13 15 11 13 10 13 31 11  9
    10 16 20 17 13 15 16 10 16 12 10  7 13 12 18 13 18 10 15 34 16  9
     1 24 21 22 21 21 25 11 17 17 21 11 15 15 18 16 16 17 17 37 21  3
     0 23 23 21 22 16 21 10 18 16 14 14 13 17 21 19 16 17 19 34 12  9
     1 22 22 21 24 18 24  6 16 14 20 16 18 12 12 13 18 18 21 31 19  4
     0 22 17 19 19 21 20 17 15  9 13 16 17 18 11 13 16 19 14 40 18  1
     0 20 23 23 22 22 24 11 18 16 16 16 20 13 16 18 18 20 20 41 21  3
     1 22 17 21 17 17 22 10 14 16 16 13  8 13 18 21 12 13 15 33 14  9
     1 21 18 20 23 21 22  8 15  9 17 11 13 13 20 20 21 15 20 38 21  6
     1 21 22 19 20 18 17 11 15 12 14 11 10 11 13 14 14 15 14 39 12  9
    END OF DATA
    LET S = SINGULAR VALUES X
    SET WRITE FORMAT F10.5
    PRINT S
    The computed singular values are:
      419.53979 32.21864 26.63654 22.93816 19.67355 18.49977 16.47950
       14.76893 14.27686 13.22598 12.82934 11.64946 10.87689 9.98086
        9.34820 7.87245 6.51996 6.08804 3.80118 3.12485 2.97399 0.78713
 
-----SINGULAR VALUE DECOMPOSITION (LET)--------------------------
 
SINGULAR VALUE DECOMPOSITION
 
Name:
    SINGULAR VALUE DECOMPOSITION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the singular value decomposition of a matrix.
 
Description:
    If X is a matrix with row and column dimensions n and p
    respectively, then an n by n orthogonal matrix U and a p by p
    orthogonal matrix V can be found such that:
           U'XV = [ SIGMA]    - if n >= p
                  [  0   ]
           U'XV = [SIGMA 0]   - if n < p
    where SIGMA is a m by m diagonal matrix (m is the minimum of
    n and p).  The diagonal elements of SIGMA are the singular values
    of X and they are stored from largest to smallest.  Singular values
    of zero (or near zero) indicate that the matrix is singular (i.e.,
    not of full rank) or ill-conditioned.  Chapters 2 and 14 of the
    Numerical Recipes book describe some applications of the SVD.
 
    Since U and V are orthogonal (and so their inverses are equal to
    their transpose), the above equation can also be written as:
             X = U[SIGMA]V'
                  [  0  ]
 
    For large matrices, it can be impractical to compute U (which is
    n by n).  However, U can be partitioned into
            U = (U1, U2)
    where U1 is n by p.  Then
            X = U1xSIGMAxV'
    is called the singular value factorization of X.  Several
    multivariate statistical techniques are based on this
    factorization.
 
Syntax:
    LET <u> <s> <v> = SINGULAR VALUE DECOMPOSITION <mat1>
               <SUBSET/EXCEPT/FOR qualification>
    where <mat1> is a matrix for which the singular values are to be
                 computed;
          <u> is an n by n matrix where U is saved;
          <s> is a variable where the singular values are saved
              (length is minimum of n and p);
          <v> is an p by p matrix where V is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional (and
                 rarely used in this context).
 
Examples:
    LET U S V = SINGULAR VALUE DECOMPOSITION A
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPAL COMPONENTS = Compute the principal components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE FACT  = Compute the singular value factorization of
                           a matrix.
 
Reference:
    "LINPACK User's Guide", Dongarra, Bunch, Moler, Stewart.  Siam,
    1979.
 
    "Numerical Recipes: The Art of Scientific Programming (FORTRAN
    Version)", Press, Flannery, Teukolsky, and Vetterling.  Cambridge
    University Press, 1989 (chapter 2).
 
Applications:
    Linear Algebra, Multivariate Analysis
 
Implementation Date:
    93/8
 
Program:
    . SOURCE: "GRAPHICAL EXPLORATORY DATA ANALYSIS", DU TOIT, ET AL
    . 28 STUDENTS FROM ABILITY TEST DATA SET (PAGE 6)
    .
    DIMENSION 100 COLUMNS
    READ MATRIX X
    11 19 21 21 18 20 21 15 14 15 13 15 16 19 19 19 20 17 17 39 21  9
    11 21 20 15 24 22 18 11 18 16 19 14 17 21 15 17 18 18 19 42 22  4
     0 18 19 16 18 18 23 11 13 13 15 11 11 15 18 13 15 18 13 38 18  6
     0 18 23 10 18 16 16 11  9  8 15  6  9 12 16  8 13  9 15 34 15  9
     0 24 24 19 20 23 24 22 18 16 19 16 19 19 21 21 20 18 20 46 21  2
     1 19 19 23 21 23 23  9  8 13 15 20 15 17 12 20 16 16 21 35 18  9
     0 21 20 19 21 21 23 11 16 11 18 18 14 21 17 14 19 18 16 42 19  4
     0 21 20 21 20 16 22  7 11 17 16  8 10 13 17 16 17 15 11 28 20  9
     1 19 20 19 22 18 21 11 12  7 15  9 11 13 12 13 17 12 12 38 19  8
     1 19 23 22 22 16 25 12 15 16 19 15 10 15 20 18 18 17 13 33 18  9
     0 17 13  8 18 13 18 12  8  9 12 12 11  9 14 15 12 13  9 23 16  9
    10 21 22 22 15 23 23 16 12 16 15 13 14 19 17 16 18 19 18 42 24  9
    11 18 18 17 16 15 22  8 11 10 16  8 14 10 13 10 14  9 14 27 14  8
    10 13 18 21 16 17 15 11 12 11  9 11 11 16 18 14 13 15 18 24 15  9
    11 17 13 17 20 22 19 15 11 11 12 11 13 15 15 15 13 16 12 33 10  9
    10 18 12  9  9 15 17  9  5  3 12  7  7 12 10 10 13 10 12 27 12  9
    10 22 15 24 17 15 20 10 12 12 11  9 12 19 16 16  8 11 17 30 22  6
    10 18 17 18 18 13 18 14 12 15 11 10  9 21 14 12 15 11 13 31 16  9
    10 17 15 14 14 12 13  9 10 11  9  7 11 13 15 11 13 10 13 31 11  9
    10 16 20 17 13 15 16 10 16 12 10  7 13 12 18 13 18 10 15 34 16  9
     1 24 21 22 21 21 25 11 17 17 21 11 15 15 18 16 16 17 17 37 21  3
     0 23 23 21 22 16 21 10 18 16 14 14 13 17 21 19 16 17 19 34 12  9
     1 22 22 21 24 18 24  6 16 14 20 16 18 12 12 13 18 18 21 31 19  4
     0 22 17 19 19 21 20 17 15  9 13 16 17 18 11 13 16 19 14 40 18  1
     0 20 23 23 22 22 24 11 18 16 16 16 20 13 16 18 18 20 20 41 21  3
     1 22 17 21 17 17 22 10 14 16 16 13  8 13 18 21 12 13 15 33 14  9
     1 21 18 20 23 21 22  8 15  9 17 11 13 13 20 20 21 15 20 38 21  6
     1 21 22 19 20 18 17 11 15 12 14 11 10 11 13 14 14 15 14 39 12  9
    END OF DATA
    LET U S V = SINGULAR VALUE DECOMPOSITION X
 
-----SINGULAR VALUE FACTORIZATION (LET)--------------------------
 
SINGULAR VALUE FACTORIZATION
 
Name:
    SINGULAR VALUE FACTORIZATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the singular value factorization of a matrix.
 
Description:
    If X is a matrix with row and column dimensions n and p
    respectively, then an n by n orthogonal matrix U and a p by p
    orthogonal matrix V can be found such that:
           U'XV = [ SIGMA]    - if n >= p
                  [  0   ]
           U'XV = [SIGMA 0]   - if n < p
    where SIGMA is a m by m diagonal matrix (m is the minimum of
    n and p).  The diagonal elements of SIGMA are the singular values
    of X and they are stored from largest to smallest.  Singular values
    of zero (or near zero) indicate that the matrix is singular (i.e.,
    not of full rank) or ill-conditioned.  Chapters 2 and 14 of the
    Numerical Recipes book describe some applications of the SVD.
 
    Since U and V are orthogonal (and so their inverses are equal to
    their transpose), the above equation can also be written as:
             X = U[SIGMA]V'
                  [  0  ]
 
    For large matrices, it can be impractical to compute U (which is
    n by n).  However, U can be partitioned into
            U = (U1, U2)
    where U1 is n by p.  Then
            X = U1xSIGMAxV'
    is called the singular value factorization of X.  Several
    multivariate statistical techniques are based on this factorization.
    The program example demonstrates the biplot proposed by Ruben
    Gabriel.
 
Syntax:
    LET <u> <s> <v> = SINGULAR VALUE FACTORIZATION <mat1>
    where <mat1> is a matrix for which the singular values are to be
                 computed;
          <u> is an n by p matrix where U is saved;
          <s> is a variable where the singular values are saved
              (length is minimum of n and p);
          <v> is an p by p matrix where V is saved.
 
Examples:
    LET U S V = SINGULAR VALUE DECOMPOSITION A
 
Note:
    DATAPLOT uses a LINPACK routine to compute the singular value
    factorization.
 
Note:
    Matrices are created with either the READ MATRIX command or the
    MATRIX DEFINITION command.  Enter HELP MATRIX DEFINITION and HELP
    READ MATRIX for details.
 
Note:
    The columns of a matrix are accessible as variables by appending an
    index to the matrix name.  For example, the 4x4 matrix C has
    columns C1, C2, C3, and C4.  These columns can be operated on like
    any other DATAPLOT variable.
 
Note:
    The maximum size matrix that DATAPLOT can handle is set when
    DATAPLOT is built on a particular site.  The default maximums are
    100 columns and 500 rows.  Earlier versions may be 20 rows and 20
    columns or 100 rows and 100 columns.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MATRIX ADDITION      = Perform a matrix addition.
    MATRIX ADJOINT       = Compute the adjoint matrix of a matrix.
    MATRIX COFACTOR      = Compute a matrix cofactor.
    MATRIX DEFINITION    = Set a matrix definition.
    MATRIX DETERMINANT   = Compute a matrix determinant.
    MATRIX EIGENVALUES   = Compute the matrix eigenvalues.
    MATRIX EIGENVECTORS  = Compute the matrix eigenvectors.
    MATRIX EUCLID NORM   = Compute the matrix Euclidean norm.
    MATRIX INVERSE       = Compute a matrix inverse.
    MATRIX MINOR         = Compute a matrix minor.
    MATRIX MULTIPLICAT   = Perform a matrix multiplication.
    MATRIX NUMB OF COLU  = Compute the number of columns in a matrix.
    MATRIX NUMB OF ROWS  = Compute the number of rows in a matrix.
    MATRIX RANK          = Compute the rank of a matrix.
    MATRIX SIMPLEX SOLU  = Compute a matrix simplex solution.
    MATRIX SOLUTION      = Solve a system of linear equations.
    MATRIX SPECTRAL NORM = Compute the matrix spectral norm.
    MATRIX SPECTRAL RADI = Compute the matrix spectral radius.
    MATRIX SUBMATRIX     = Define a matrix submatrix.
    MATRIX SUBTRACTION   = Perform a matrix subtraction.
    MATRIX TRACE         = Compute a matrix trace.
    MATRIX TRANSPOSE     = Compute a matrix transpose.
    CORRELATION MATRIX   = Compute the correlation matrix of a matrix.
    VARIANCE-COVA MATRIX = Compute the variance-covariance matrix of a
                           matrix.
    PRINCIPAL COMPONENTS = Compute the principal components of a
                           matrix.
    SINGULAR VALUES      = Compute the singular values of a matrix.
    SINGULAR VALUE DECOM = Compute the singular value decomposition of
                           a matrix.
 
Reference:
    "LINPACK User's Guide", Dongarra, Bunch, Moler, Stewart.  Siam,
    1979.
 
    "Numerical Recipes: The Art of Scientific Programming (FORTRAN
    Version)", Press, Flannery, Teukolsky, and Vetterling.  Cambridge
    University Press, 1989 (chapter 2).
 
Applications:
    Linear Algebra, Multivariate Analysis
 
Implementation Date:
    93/8
 
Program:
    . Generate a biplot (derived from the singular value factorization)
    . SOURCE: "THE BIPLOT AS A DIAGNOSTIC TOOL FOR MODELS OF TWO-WAY
    .         TABLES", BRANDU, GABRIEL, TECHNOMETRICS, FEB. 1978.
    . DATA IS YIELDS OF COTTON, ROWS ARE VARIETY, COLUMNS ARE CENTER
    DIMENSION 100 COLUMNS
    READ MATRIX X
     1.55 1.26 1.41  1.78
     3.39 3.47 2.82  3.89
     1.95 1.91 1.74  2.29
    10.47 9.12 9.55 17.78
     1.45 1.51 1.41  1.70
     3.72 3.55 3.09  4.27
     4.47 4.07 3.98  4.47
    END OF DATA
    LET N = SIZE X1
    .
    FEEDBACK OFF
    LET P = MATRIX NUMBER OF COLUMNS X
    LOOP FOR K = 1 1 P
        LET X^K = LOG10(X^K)
    END OF LOOP
    LET SUM1 = 0
    LOOP FOR K = 1 1 P
        LET TEMP = SUM X^K
        LET SUM1 = SUM1 + TEMP
    END OF LOOP
    LET GMEAN = SUM1/(N*P)
    LET X = MATRIX SUBTRACTION X GMEAN
    LET U S V = SINGULAR VALUE FACTORIZATION X
    LET DENOM = MATRIX EUCLIDEAN NORM X
    LET S1 = S(1)
    LET S2 = S(2)
    LET GF = (S1**2 + S2**2)/DENOM**2
    .
    LET B = MATRIX TRANSPOSE V
    LET U1 = U1*SQRT(S1)
    LET U2 = U2*SQRT(S2)
    LET B1 = B1*SQRT(S1)
    LET B2 = B2*SQRT(S2)
    .
    LET TAG = SEQUENCE 1 1 N
    LET TAG2 = SEQUENCE 1 1 P
    CHARACTER CIRCLE SQUARE
    CHARACTER FILL SOLID ALL
    LINE BLANK ALL
    TITLE BIPLOT
    X1LABEL GOODNESS OF FIT = ^GF
    LEGEND FILL SOLID
    LEGEND FONT SIMPLEX
    LEGEND 1 SQUA() - COLUMN MARKERS
    LEGEND 2 CIRC() - ROW MARKERS
    .
    PLOT U2 U1 AND
    PLOT B2 B1
    LEGEND 1
    LEGEND 2
    LIMITS FREEZE
    PRE-ERASE OFF
    CHARACTER 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
    CHARACTER OFFSET 1.2 0 ALL
    PLOT U2 U1 TAG
    PLOT B2 B1 TAG2
 
-----SININT (LET)--------------------------------
 
SININT
 
Name:
    SININT (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the sine integral.
 
Description:
    The sine integral is defined as:
        Si(X) = INTEGRAL(SIN(t)/t)dt
    where the integral is taken from 0 to x.

Syntax:
    LET <y2> = SININT(<x>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, variable, or parameter;
          <y2> is a variable or a parameter (depending on what <x> is
               where the computed cosine integral values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SININT(0.1)
    LET A = SININT(-0.1)
    LET X2 = SININT(X)
 
Note:
    DATAPLOT uses the routine SICIEI written by Irene Stegum and
    Ruth Zucker of NIST (see the REFERENCE section below).

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    COSHINT    = Compute the hyperbolic cosine integral.
    COSINT     = Compute the cosine integral.
    SINHINT    = Compute the hyperbolic sine integral.
    EXPINTN    = Compute the exponential integral of order N.
    LOGINT     = Compute the logarithmic integral.
    DAWSON     = Compute Dawson's integral.
 
Reference:
    "SICIEI: Automatic Computing Methods for Special FUnctions.  Part
    III. The Sine, Cosine, Exponential Integrals and Related
    Functions", Stegum and Zucker, Journal of Research of the National
    Bureau of Standards, 80B(2), 1976.

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 5).
 
Applications:
    Special Functions
 
Implementation Date:
    94/9
 
Program:
    TITLE AUTOMATIC
    PLOT SININT(X) FOR X = -10 0.1 10
 
-----SIZE (LET)---------------------------------------------------
 
SIZE
 
Name:
    SIZE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the number of elements in a variable.
 
Syntax:
    LET <par> = SIZE <x1>  <SUBSET/EXCEPT/FOR qualification>
    where <x1> is the variable for which the size is to be computed;
          <par> is a parameter where the size is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET N = SIZE Y1
 
Default:
    None
 
Synonyms:
    NUMBER
    COUNT
 
Related Commands:
    SEQUENCE       = Generate a sequence of numbers.
    PATTERN        = Generate numbers with a specific pattern.
 
Applications:
    Data Management
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----SKEWNESS OUTLIER TEST------------------------------------
 
SKEWNESS OUTLIER TEST
 
Name:
    SKEWNESS OUTLIER TEST
 
Type:
    Analysis Command
 
Purpose:
    Perform the skewness test for univariate outliers from a normal
    distribution.
 
Description:
    The ASTM E178-16a standard for detecting outliers from a univariate
    normal distribution includes the skewness outlier test.

    The test statistic is the adjusted Fisher-Pearson skewness
    coefficient

       g1 = n*SUM[i=1 to n][(x(i)-xbar)**2]/((n-1)*(n-2)*s**2)

    with n, xbar and s denoting the sample size, the sample mean
    and the sample standard deviation, respectively.

    The critical values are obtained via simulation.  The ASTM standard
    provides table values for n = 3 to 50 and alpha levels of 0.10, 0.05
    and 0.01.  Linear interpolation is used for values of n not given in
    the table.  Alternatively, you can perform a dynamic simulation
    to obtain the critical values.

    To specify the method used to compute the critical value, enter
    one of the following commands (the default is ASTM)

        SET SKEW OUTLIER TEST CRITICAL VALUES ASTM
        SET SKEW OUTLIER TEST CRITICAL VALUES SIMULATION

    If n > 50, the simulation method will be used.

Syntax 1:
    SKEWNESS OUTLIER TEST  <y>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable being tested;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Syntax 2:
    MULTIPLE SKEWNESS OUTLIER TEST <y1> ... <yk>   
                                   <SUBSET/EXCEPT/FOR qualification>
    where <y1> ... <yk> is a list of up to k response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs the skewness outlier test on <y1>, then on
    <y2>, and so on.  Up to 30 response variables can be specified.

    Note that the syntax

         MULTIPLE SKEWNESS OUTLIER TEST Y1 TO Y4

    is supported.  This is equivalent to

         MULTIPLE SKEWNESS OUTLIER TEST Y1 Y2 Y3 Y4

Syntax 3:
    REPLICATED SKEWNESS OUTLIER TEST <y> <x1> ... <xk>   
                                     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> ... <xk> is a list of up to k group-id variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax performs a cross-tabulation of <x1> ... <xk> and performs
    a skewness outlier test for each unique combination of cross-tabulated
    values.  For example, if X1 has 3 levels and X2 has 2 levels, there
    will be a total of 6 skewness outlier tests performed.

    Up to six group-id variables can be specified.

    Note that the syntax

         REPLICATED SKEWNESS OUTLIER TEST Y X1 TO X4

    is supported.  This is equivalent to

         REPLICATED SKEWNESS OUTLIER TEST Y X1 X2 X3 X4

Examples:
    SKEWNESS OUTLIER TEST Y1
    MULTIPLE SKEWNESS OUTLIER TEST Y1 Y2 Y3
    REPLICATED SKEWNESS OUTLIER TEST Y X1 X2
    SKEWNESS OUTLIER TEST Y1   SUBSET TAG > 2

Note:
    Tests for outliers are dependent on knowing the distribution of the
    data.  The skewness outlier test assumes that the data come from an
    approximately normal distribution.  For this reason, it is strongly
    recommended that the skewness outlier test be complemented with a
    normal probability test.  If the data are not approximately normally
    distributed, then the skewness outlier test may be detecting the
    non-normality of the data rather than the presence of an outlier.

Note:
    You can specify the number of digits in the skewness outlier test
    output with the command

        SET WRITE DECIMALS <value>

Note:
    The SKEWNESS OUTLIER TEST command automatically saves the following
    parameters:

       STATVAL    = the value of the test statistic
       STATDCF    = the CDF value of the test statistic
       PVALUE     = the p-value of the test statistic
       CUTOFF80   = the 80 percent point of the reference distribution
       CUTOFF90   = the 90 percent point of the reference distribution
       CUTOFF95   = the 95 percent point of the reference distribution
       CUTOF975   = the 97.5 percent point of the reference distribution
       CUTOFF99   = the 99 percent point of the reference distribution

    The STATCDF and PVALUE are only saved when the simulation method
    is used to obtain critical values.  If the ASTM method is used to
    obtain critical values, the CUTOFF80 and CUTOF975 values are not
    saved.

    If the MULTIPLE or REPLICATED option is used, these values will
    be written to the file "dpst1f.dat" instead.

Note:
    In addition to the SKEWNESS OUTLIER TEST command, the following
    commands can also be used:

        LET A = SKEWNESS OUTLIER TEST Y
        LET A = SKEWNESS OUTLIER TEST CDF Y
        LET A = SKEWNESS OUTLIER TEST PVALUE Y
        LET A = SKEWNESS OUTLIER TEST INDEX Y

        LET ALPHA = <value>
        LET A = SKEWNESS OUTLIER TEST CRITICAL VALUE Y

    The SKEWNESS OUTLIER TEST, SKEWNESS OUTLIER TEST CDF, and
    SKEWNESS OUTLIER TEST PVALUE return the values of the test statistic,
    the cdf of the test statistic and the pvalue of the test statistic,
    respectively.  For the SKEWNESS OUTLIER TEST CDF and
    SKEWNESS OUTLIER TEST PVALUE commands, the simulation method will be
    used.  Otherwise, the method specified by the
    SET SKEWNESS OUTLIER TEST CRITICAL VALUE command will be used.

    The SKEWNESS OUTLIER TEST INDEX returns the row index of the most
    extreme value in the response variable.  The most extreme value is
    defined as the value furtherest from the mean.

    The SKEWNESS OUTLIER TEST CRITICAL VALUE returns the critical value
    for the specified value of ALPHA.  If ALPHA is not specified, it will
    be set to 0.05.  Note that if the ASTM method is specified for the
    critical values, only a few select values for alpha are supported
    (0.01, 0.05 and 0.10).

    In addition to the above LET command, built-in statistics are
    supported for 30+ different commands (enter HELP STATISTICS
    for details).

Default:
    The ASTM method is used to obtain critical values
 
Synonyms:
    None
 
Related Commands:
    KURTOSIS OUTLIER TEST       = Perform the kurtosis outlier test.
    GRUBBS TEST                 = Perform the Grubbs outlier test.
    DAVID TEST                  = Perform the David outlier test.
    TIETJEN-MOORE TEST          = Perform the Tietjen-Moore outlier
                                  test.
    EXTREME STUDENTIZED DEVIATE = Perform the generalized extreme
                                  studentized deviate outlier test.
    DIXON TEST                  = Perform the Dixon outlier test.
    SKEWNESS OUTLIER TEST       = Perform the skewness outlier test.
    KURTOSIS OUTLIER TEST       = Perform the kurtosis outlier test.
    ANDERSON DARLING TEST       = Perform the Anderson-Darling test for
                                  normality.
    WILK SHAPIRO TEST           = Perform the Wilk-Shapiro test for
                                  normality.
    PROBABILITY PLOT            = Generates a probability plot.
    HISTOGRAM                   = Generate a histogram.
    BOX PLOT                    = Generate a box plot.
 
Reference:
    E178 - 16A (2016), "Standard Practice for Dealing with Outlying
    Observations", ASTM International, 100 Barr Harbor Drive,
    PO Box C700, West Conshohocken, PA 19428-2959, USA.

    Ferguson, T.S. (1961), "On the Rejection of Outliers," Fourth
    Berkeley Symposium on Mathematical Statistics and Probability,
    edited by Jerzy Neyman, University of California Press, Berkeley
    and Los Angeles, CA.

    Ferguson, T.S. (1961), "Rules for Rejection of Outliers," Revue
    Inst. Int. de Stat., RINSA, Vol. 29, No. 3, pp. 29-43.

Applications:
    Outlier Detection
 
Implementation Date:
    2019/10
 
Program:
    . Step 1:   Read the data (from ASTM E-178 document)
    .
    read y
    3.73
    3.59
    3.94
    4.13
    3.04
    2.22
    3.23
    4.05
    4.11
    2.02
    end of data
    set write decimals 3
    .
    . Step 2:   Compute the statistics
    .
    let stat = skew outlier test y
    set skew outlier test critical values astm
    let cv1 = skew outlier test critical value y
    set skew outlier test critical values simulation
    let cv2 = skew outlier test critical value y
    .
    let pval = skew outlier test pvalue y
    let statcdf = skew outlier test cdf y
    let iindx = skew outlier test index y
    .
    print stat cv1 cv2 pval statcdf iindx
    .
    set skew outlier test critical values astm
    skewness outlier test y
    set skew outlier test critical values simulation
    skewness outlier test y

-----SKEWNESS (LET)---------------------------------------------------
 
SKEWNESS
 
Name:
    SKEWNESS (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the skewness (or standardized third central moment) of a
    variable.
 
Description:
    Skewness measures the lack of symmetry in a variable.  The
    formula for the Fisher-Pearson skewness coefficient is:

       g1 = (SUM[i=1 to n][(X(i)-Xbar)**3/N))/s**3]

    where xbar, s, and N are the sample mean, the sample standard
    deviation, and the sample size, respectively.  Note that in
    computing the skewness, the standard deviation is computed using
    n in the denominator rather than n - 1.
 
    The adjusted Fisher-Pearson skewness coefficient is: 

       G1 = (SQRT(N*(N-1))/(N-1))*(SUM[i=1 to n][(X(i)-Xbar)**3/N))/s**3]

    This provides a correction factor to adjust for the sample size.
    This adjustment factor approaches 1 as the sample size gets
    large.

    In Dataplot, you can specify that the adjusted form of the
    statistic be computed by entering the command

        SET SKEWNESS DEFINITION ADJUSTED FISHER-PEARSON

    To reset the unadjusted skewness statistic, enter

        SET SKEWNESS DEFINITION FISHER-PEARSON

    There are many alternative definitions of skewness in the
    literature.  Dataplot supports the following two additional
    definitions of skewness.

    The Galton skewness (also known as Bowley's skewness) is defined as

        Galton skewness = (Q1 + Q3 - 2*Q2)/(Q3 - Q1)

    where Q1 is the lower quartile, Q3 is the upper quartile, and
    Q2 is the median.

    The Pearson 2 skewness coefficient is defined as

        Sk2 = 3*(Ybar - Ymed)/s

   where Ymed is the sample median.

Syntax 1:
    LET <par> = SKEWNESS <y>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the skewness is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the Fisher-Pearson skewness.

Syntax 2:
    LET <par> = GALTON SKEWNESS <y>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the skewness is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the Galton skewness.

Syntax 3:
    LET <par> = PEARSON TWO SKEWNESS <y>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the skewness is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the Pearson two skewness.

Examples:
    LET A = SKEWNESS Y1
    LET A = GALTON SKEWNESS Y1
    LET A = PEARSON TWO SKEWNESS Y1
 
Note:
    The skewness for a normal distribution is zero.  Symmetric data
    should have a skewness near zero.  Negative values for the skewness
    indicate data that are skewed left and positive values for the
    skewness indicate data that are skewed right.  By skewed left, we
    mean that the left tail is long relative to the right tail.
    Similarly, skewed right means that the right tail is long relative
    to the left tail.  Note that if the data are multi-modal, then this
    may affect the sign of the skewness.

    Measurement data is often bounded below (e.g., the measurement
    must be positive) but not above.  This type of data will
    frequently exhibit right skewness.
 
Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    STANDARDIZED THIRD CENTRAL MOMENT
    STANDARDIZED 3RD CENTRAL MOMENT
    PEARSON 2 SKEWNESS
    PEARSON TYPE TWO SKEWNESS
    PEARSON TYPE 2 SKEWNESS
 
Related Commands:
    MEAN                = Compute mean of a variable.
    STANDARD DEVIATION  = Compute the standard deviation of a variable.
    KURTOSIS            = Compute the Kurtosis of a variable.
 
Applications:
    Data Analysis
 
Implementation Date:
    Pre-1987
    2013/04: Added adjusted Fisher-Pearson skewness
    2014/12: Added Galton skewness
    2014/12: Added Pearson two skewness
 
Program:
    skip 25
    read weibbury.dat y
    .
    let s1 = skewness y
    set skewness definition adjusted fisher pearson
    let s2 = skewness y
    let s3 = galton skewness y
    let s4 = pearson two skewness y
    .
    set write decimals 4
    print s1 s2 s3 s4
 
-----SKEWNESS PLOT-----------------------------------------------
 
SKEWNESS PLOT
 
Name:
    SKEWNESS PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a skewness plot.
 
Description:
    A skewness plot is a plot consisting of subsample skewnesss versus
    subsample index.  The subsample skewness is the cube root of the
    standardized third central moment of the data in the subsample.
    The skewness plot is used to answer the question-- "Does the
    subsample skewness change over different subsamples?".  It consists
    of:
       Vertical   axis = subsample skewness;
       Horizontal axis = subsample index.
    The skewness plot yields 2 traces:
       1. a subsample skewness trace; and
       2. a full-sample skewness reference line.
    Like usual, the appearance of these 2 traces is
    controlled by the first 2 settings of the LINES,
    CHARACTERS, SPIKES, BARS, and similar attributes.
 
Syntax:
    SKEWNESS PLOT   <y>   <x>    <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    SKEWNESS PLOT Y X
    SKEWNESS PLOT Y X1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS              = Sets the type for plot char.
    LINES                   = Sets the type for plot lines.
    KURTOSIS PLOT           = Generates a kurtosis plot.
    VARIANCE PLOT           = Generates a variance plot.
    STANDARD DEVIATION PLOT = Generates a standard deviation plot.
    RANGE PLOT              = Generates a range plot
    MEAN PLOT               = Generates a mean plot.
    MEDIAN PLOT             = Generates a median plot.
    BOX PLOT                = Generates a box plot.
    S CHART                 = Generates a standard deviation
                              control chart.
    PLOT                    = Generates a data or function plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    SKIP 25
    READ GEAR.DAT Y X
    LINE BLANK DASH
    CHARACTER X BLANK
    XTIC OFFSET 0.2 0.2
    Y1LABEL SKEWNESS
    X1LABEL SAMPLE ID
    TITLE AUTOMATIC
    SKEWNESS PLOT Y X
 
-----SKIP-------------------------------------------------------
 
SKIP
 
Name:
    SKIP
 
Type:
    Support Command
 
Purpose:
    Specifies the number of lines at the beginning of a file that
    should be skipped over during subsequent READ and SERIAL READ
    commands.
 
Description:
    This gives the analyst a convenient method of skipping over
    non-data lines (consisting, for example, of descriptive text)
    which may exist at the beginning of a data file.
 
Syntax 1:
    SKIP   <num>
    where <num> is an integer number or parameter that specifies the
              desired number of lines to be skipped during subsequent
              READs and SERIAL READs.
 
Syntax 2:
    SKIP   AUTOMATIC

    This syntax skips until a line beginning with "---" is
    found.  Note that most of the built-in Dataplot data files
    follow this convention.

Examples:
    SKIP 10
    SKIP 3
    SKIP 0
    SKIP
 
Note:
    SKIP with no arguments reverts the number of lines to be skipped
    to 0.
 
Default:
    The default number of lines to be skipped is 0.
 
Synonyms:
    SKIP <N> is identical in function to ROW LIMITS <N> INFINITY.
 
Related Commands:
    READ         = Carries out a column-wise input of data.
    SERIAL READ  = Carries out a row-wise input of data.
    ROW LIMITS   = Specifies the start and stop row for subsequent
                   READ commands.
 
Applications:
    Data Input
 
Implementation Date:
    Pre-1987.  The SKIP AUTOMATIC option was added 1997/12.
 
Program:
    SKIP 25
    READ BERGER1.DAT Y X
    FIT Y X
 
-----SLACDF (LET)--------------------------------
 
SLACDF
 
Name:
    SLACDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the slash cumulative distribution function.
 
Description:
    The standard slash distribution has the following
    probability density function:

       f(x) = (NORPDF(0) - NORPDF(X))/(X**2)      X <> 0
            = 0.5*NORPDF(0)                       X = 0

    The slash cumulative distribution function is computed
    by numerically integrating the slash probability density
    function.

    The most common use of the slash distribution is in
    simulation studies.  It is a useful distribution in this
    context because it has heavier tails than a normal distribution,
    but it is not as pathological as the Cauchy distribution.
 
Syntax:
    LET <y> = SLACDF(<x>)      <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed slash cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SLACDF(3)
    LET X2 = SLACDF(X1)
 
Note:
    Dataplot uses the DQAGI routine from the Quadpack library
    to perform the numerical integration.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SLAPDF          = Compute the slash probability density function.
    SLAPPF          = Compute the slash percent point function.
    NORPDF          = Compute the normal probability density function.
    LOGPDF          = Compute the logistic probability density function.
    CAUPDF          = Compute the Cauchy probability density function.
    RANDOM NUMBERS  = Generate random numbers from 60+ univariate
                      distributions.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", 2nd. Ed.,
    Johnson, Kotz, and Balakrishnan, John Wiley, 1994,
    (page 63).
 
Applications:
    Simulation
 
Implementation Date:
    2004/1
 
Program:
    TITLE SLASH CUMULATIVE DISTRIBUTION FUNCTION
    PLOT SLACDF(X)  FOR X = -10 0.01 10

-----SLAPDF (LET)--------------------------------
 
SLAPDF
 
Name:
    SLAPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the slash probability density function.
 
Description:
    The slash distribution has the following probability density
    function:

       f(x) = (NORPDF(0) - NORPDF(X))/(X**2)      X <> 0
            = 0.5*NORPDF(0)                       X = 0

    The most common use of the slash distribution is in
    simulation studies.  It is a useful distribution in this
    context because it has heavier tails than a normal distribution,
    but it is not as pathological as the Cauchy distribution.
 
Syntax:
    LET <y> = SLAPDF(<x>)      <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable, a number, or a parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed slash pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SLAPDF(3)
    LET X2 = SLAPDF(X1)
 
Note:
    You can generate random numbers from a slash distribution
    with the following command:

        LET Y = SLASH RANDOM NUMBERS FOR I = 1 1 N
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SLACDF          = Compute the slash cumulative distribution
                      function.
    SLAPPF          = Compute the slash percent point function.
    NORPDF          = Compute the normal probability density function.
    LOGPDF          = Compute the logistic probability density function.
    CAUPDF          = Compute the Cauchy probability density function.
    RANDOM NUMBERS  = Generate random numbers from 60+ univariate
                      distributions.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", 2nd. Ed.,
    Johnson, Kotz, and Balakrishnan, John Wiley, 1994,
    (page 63).
 
Applications:
    Simulation
 
Implementation Date:
    2003/3
 
Program:
    TITLE SLASH PDF
    PLOT SLAPDF(X)  FOR X = -10 0.01 10

-----SLAPPF (LET)--------------------------------
 
SLAPPF
 
Name:
    SLAPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the slash percent point function.
 
Description:
    The standard slash distribution has the following
    probability density function:

       f(x) = (NORPDF(0) - NORPDF(X))/(X**2)      X <> 0
            = 0.5*NORPDF(0)                       X = 0

    The slash cumulative distribution function is computed
    by numerically integrating the slash probability density
    function.  The slash percent point function is computed
    by numerically inverting the slash cumulative distribution
    function.

    The most common use of the slash distribution is in
    simulation studies.  It is a useful distribution in this
    context because it has heavier tails than a normal distribution,
    but it is not as pathological as the Cauchy distribution.
 
Syntax:
    LET <y> = SLAPPF(<p>)      <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable, a number, or a parameter in the range
               [0,1];
          <y> is a variable or a parameter (depending on what <p> is)
               where the computed slash ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SLAPPF(0.95)
    LET X2 = SLAPPF(P1)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SLACDF          = Compute the slash cumulative distribution
                      function.
    SLAPDF          = Compute the slash probability density function.
    NORPDF          = Compute the normal probability density function.
    LOGPDF          = Compute the logistic probability density function.
    CAUPDF          = Compute the Cauchy probability density function.
    RANDOM NUMBERS  = Generate random numbers from 60+ univariate
                      distributions.
 
Reference:
    "Continuous Univariate Distributions: Volume 1", 2nd. Ed.,
    Johnson, Kotz, and Balakrishnan, John Wiley, 1994,
    (page 63).
 
Applications:
    Simulation
 
Implementation Date:
    2004/1
 
Program:
    TITLE SLASH PERCENT POINT FUNCTION
    PLOT SLAPPF(P)  FOR P = 0.01 0.01 0.99

-----SLEEP-------------------------------------------------------
 
SLEEP
 
Name:
    SLEEP
 
Type:
    Support Command
 
Purpose:
    This command pauses for a specified number of seconds.
 
Description:
    The primary application of this command is to put a
    pause in a macro after a plot.  This allows you to view
    individual plots in a multi-plot macro without having to
    enter carriage returns as you would with the PAUSE command.
 
    This is a system dependent command.  It is currently
    supported for Unix and Windows 95/98/NT.

Syntax:
    SLEEP <n>
    where <n> specifies the number of seconds the pause will
              last.
 
Examples:
    PLOT X**2 FOR X = 1 1 9
    SLEEP 5
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SYSTEM        = Enter an operating system command within a
                    Dataplot session.
    CD            = Change the current directory
    PAUSE         = Wait for a carriage return before continuing.
 
Applications:
    Interactive Usage
 
Implementation Date:
    1997/9
 
Program:
    PLOT X**2 FOR X = 1 1 9
    SLEEP 5
 
-----SLOCDF (LET)--------------------------------
 
SLOCDF
 
Name:
    SLOCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the slope cumulative distribution function
    with shape parameter alpha.
 
Description:
    The standard slope distribution has the following
    cumulative distribution function:

       F(x;alpha) = alpha*x + (1-alpha)*x**2
                    0 <= x <= 1, 0 <= alpha <= 2
 
    with alpha denoting the shape parameter.

    This distribution can be extended with lower and upper
    bound parameters.  If a and b denote the lower and upper
    bounds, respectively, then the location and scale 
    parameters are:

        location = a
        scale    = b - a

    The general form of the distribution can then be found
    by using the relation

        F(x;alpha,a,b) = F((x-a)/(b-a);alpha,0,1)

Syntax:
    LET <y> = SLOCDF(<x>,<alpha>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing
              values in the interval (a,b);
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed slope cdf value
              is stored;
          <alpha> is a positive number, parameter, or variable that
              specifies the shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = SLOCDF(0.3,0.2)
    LET Y = SLOCDF(X,0.5,0,5)
    PLOT SLOCDF(X,2,0,3) FOR X = 0  0.01  3
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SLOPDF = Compute the slope probability density function.
    SLOPPF = Compute the slope percent point function.
    TSSPDF = Compute the two-sided slope probability density function.
    OGIPDF = Compute the ogive probability density function.
    TOPPDF = Compute the Topp and Leone probability density function.
    RGTPDF = Compute the generalized reflected slope
             probability density function.
    GTLPDF = Compute the generalized slope probability
             density function.
    TSPPDF = Compute the two-sided power probability density
             function.
    BETPDF = Compute the alpha probability density function.
    TRIPDF = Compute the triangular probability density function.
    TRAPDF = Compute the trapezoid probability density function.
    UNIPDF = Compute the uniform probability density function.
    POWPDF = Compute the power probability density function.
    JSBPDF = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond Alpha:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, chapter 8.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/10
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET ALPHA  = 0.5
    TITLE Alpha = ^alpha
    PLOT SLOCDF(X,ALPHA) FOR X = 0  0.01  1
    .
    LET ALPHA  = 1
    TITLE Alpha = ^alpha
    PLOT SLOCDF(X,ALPHA) FOR X = 0  0.01  1
    .
    LET ALPHA  = 1.5
    TITLE Alpha = ^alpha
    PLOT SLOCDF(X,ALPHA) FOR X = 0  0.01  1
    .
    LET ALPHA  = 2
    TITLE Alpha = ^alpha
    PLOT SLOCDF(X,ALPHA) FOR X = 0  0.01  1
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Slope Cumulative Distribution Functions
 
-----SLOPDF (LET)--------------------------------
 
SLOPDF
 
Name:
    SLOPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the slope probability density function
    with shape parameter alpha.
 
Description:
    The standard slope distribution has the following
    probability density function:

       f(x;alpha) = alpha + 2*(1-alpha)*x
                    0 <= x <= 1, 0 <= alpha <= 2
 
    with alpha denoting the shape parameter.

    This distribution can be extended with lower and upper
    bound parameters.  If a and b denote the lower and upper
    bounds, respectively, then the location and scale 
    parameters are:

        location = a
        scale    = b - a

    The general form of the distribution can then be found
    by using the relation

        f(x;alpha,a,b) = f((x-a)/(b-a);alpha,0,1)/(b-a)

Syntax:
    LET <y> = SLOPDF(<x>,<alpha>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, parameter, or variable containing
              values in the interval (a,b);
          <y> is a variable or a parameter (depending on what
              <x> is) where the computed slope pdf value
              is stored;
          <alpha> is a positive number, parameter, or variable that
              specifies the shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = SLOPDF(0.3,0.2)
    LET Y = SLOPDF(X,0.5,0,5)
    PLOT SLOPDF(X,2,0,3) FOR X = 0  0.01  3
 
Note:
    Slope random numbers, probability plots, and goodness of
    fit tests can be generated with the commands:

       LET ALPHA = <value>
       LET A = <value>
       LET B = <value>
       LET Y = SLOPE RANDOM NUMBERS FOR I = 1 1 N
       SLOPE PROBABILITY PLOT Y
       SLOPE PROBABILITY PLOT Y2 X2
       SLOPE PROBABILITY PLOT Y3 XLOW XHIGH
       SLOPE KOLMOGOROV SMIRNOV GOODNESS OF FIT Y
       SLOPE CHI-SQUARE GOODNESS OF FIT Y2 X2
       SLOPE CHI-SQUARE GOODNESS OF FIT Y3 XLOW XHIGH

    The following commands can be used to estimate the alpha
    shape parameter for the slope distribution:

       LET ALPHA1 = <value>
       LET ALPHA2 = <value>
       SLOPE PPCC PLOT Y
       SLOPE PPCC PLOT Y2 X2
       SLOPE PPCC PLOT Y3 XLOW XHIGH
       SLOPE KS PLOT Y
       SLOPE KS PLOT Y2 X2
       SLOPE KS PLOT Y3 XLOW XHIGH

    The default values for ALPHA1 and ALPHA2 are 0.05 and 2.

    The probability plot can then be used to estimate the
    lower and upper limits (lower limit = PPA0,
    upper limit = PPA0 + PPA1).

    For the ks plot, we can fix the location and scale.
    This is equivalent to assuming that the lower and
    upper limits are known (e.g., we could use the
    data minimum and maximum as the lower and upper
    limit values).  Given that the lower and upper
    limits are LOWLIM and UPPLIM, enter the commands

         LET KSLOC   = LOWLIM
         LET KSSCALE = UPPLIM - LOWLIM

    The ppcc plot is invariant to location and scale,
    so we cannot fix the lower and upper limits.

    The BOOTSTRAP DISTRIBUTION command can be used to find
    uncertainty intervals for the ppcc plot and ks plot.
       
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SLOCDF = Compute the slope cumulative distribution
             function.
    SLOPPF = Compute the slope percent point function.
    TSSPDF = Compute the two-sided slope probability density function.
    OGIPDF = Compute the ogive probability density function.
    TOPPDF = Compute the Topp and Leone probability density function.
    RGTPDF = Compute the generalized reflected slope
             probability density function.
    GTLPDF = Compute the generalized slope probability
             density function.
    TSPPDF = Compute the two-sided power probability density
             function.
    BETPDF = Compute the alpha probability density function.
    TRIPDF = Compute the triangular probability density function.
    TRAPDF = Compute the trapezoid probability density function.
    UNIPDF = Compute the uniform probability density function.
    POWPDF = Compute the power probability density function.
    JSBPDF = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond Alpha:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, chapter 8.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/10
 
Program 1:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET ALPHA  = 0.5
    TITLE Alpha = ^alpha
    PLOT SLOPDF(X,ALPHA) FOR X = 0  0.01  1
    .
    LET ALPHA  = 1
    TITLE Alpha = ^alpha
    PLOT SLOPDF(X,ALPHA) FOR X = 0  0.01  1
    .
    LET ALPHA  = 1.5
    TITLE Alpha = ^alpha
    PLOT SLOPDF(X,ALPHA) FOR X = 0  0.01  1
    .
    LET ALPHA  = 2
    TITLE Alpha = ^alpha
    PLOT SLOPDF(X,ALPHA) FOR X = 0  0.01  1
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Slope Probability Density Functions
 
Program 2:
    let alpha = 1.2
    let y = slope rand numb for i = 1 1 200
    .
    let alphasav = alpha
    slope ppcc plot y
    just center
    move 50 5
    let alpha = shape
    text maxppcc = ^maxppcc, Alpha = ^alpha
    move 50 2
    text Alphasav = ^alphasav
    .
    char x
    line blank
    slope prob plot y
    move 50 5
    text PPA0 = ^ppa0, PPA1 = ^ppa1
    move 50 2
    let upplim = ppa0 + ppa1
    text Lower Limit = ^ppa0, Upper Limit = ^upplim
    char blank
    line solid
    .
    let ksloc = ppa0
    let ksscale = upplim
    slope kolm smir goodness of fit y

-----SLOPE (LET)--------------------------------
 
SLOPE
 
Name:
    SLOPE (LET)
 
Type:
    Library Function
 
Purpose:
    Return the slope between two points.
 
Description:
    Given two points, (X1,Y1) and (X2,Y2), the slope is defined as

       m = (Y2-Y1)/(X2-X1)

Syntax:
    LET <y> = SLOPE(<x1>,<y1>,<x2>,<y2>)
              <SUBSET/EXCEPT/FOR qualification>
    where <x1> is a variable or a parameter containing the x coordinates
               of the first point;
          <y1> is a variable or a parameter containing the y coordinates
               of the first point;
          <x2> is a variable or a parameter containing the x coordinates
               of the second point;
          <y2> is a variable or a parameter containing the y coordinates
               of the second point;
          <y> is a variable or a parameter (depending on what the input
               arguments are) where the computed slope values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SLOPE(0,0,10,15)
    LET A = SLOPE(X1,Y1,X2,Y2)

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None

Related Commands:
    DPNTLINE           = Compute the perpindicular distance between a point
                         and a line defined by a point and a slope.
    POINTS IN POLYGON  = Determine whether points are in the interior
                         of a convex polygon.
    CONVEX HULL        = Determine the convex hull of a set of points.
    TRANSFORM POINTS   = Perform location, scale, and rotation
                         transformation for a set of points.
    EXTREME POINTS     = Determine the extreme points of a set of points.
    LINE INTERSECTIONS = Determine the intersection points for a set of
                         lines.
    PARALLEL LINE      = Determine the coordinates for a point that defines
                         a parallel line determined by a point and a line
                         defined by two points.
    PERPINDICULAR LINE = Determine the coordinates for a point that defines
                         a perpindicular line determined by a point and a
                         line defined by two points.
 
Applications:
    Computational Geometry
 
Implementation Date:
    2013/01
 
Program:
    skip 25
    read convhull.dat x y
    .
    let y2 x2 = 2d convex hull y x
    let xtemp = x2(1)
    let ytemp = y2(1)
    let y2 = combine y2 ytemp
    let x2 = combine x2 xtemp
    let x3 = x2
    let y3 = y2
    let n = size y2
    let nm1 = n - 1
    retain x2 y2 for i = 1 1 nm1
    retain x3 y3 for i = 2 1 n
    let slope = slope(x2,y2,x3,y3)
    .
    set write decimals 4
    print x2 y2 x3 y3 slope

-----SLOPPF (LET)--------------------------------
 
SLOPPF
 
Name:
    SLOPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the slope percent point function with shape
    parameter alpha.
 
Description:
    The standard slope distribution has the following
    percent point function:

       G(p;alpha) = p                                 alpha = 1
                  = {-alpha +
                    SQRT(alpha**2 + 4*p*(1-alpha))}/
                    (2*(1-alpha))                     alpha <> 1

                    0 <= p <= 1, 0 <= alpha <= 2
 
    with alpha denoting the shape parameter.

    This distribution can be extended with lower and upper
    bound parameters.  If a and b denote the lower and upper
    bounds, respectively, then the location and scale 
    parameters are:

        location = a
        scale    = b - a

    The general form of the distribution can then be found
    by using the relation

        G(p;alpha,a,b) = a + (b-a)*G(p;alpha,0,1)

Syntax:
    LET <y> = SLOPPF(<p>,<alpha>,<a>,<b>) 
              <SUBSET/EXCEPT/FOR qualification>
    where <p> is a number, parameter, or variable containing
              values in the interval (0,1);
          <y> is a variable or a parameter (depending on what
              <p> is) where the computed slope ppf value
              is stored;
          <alpha> is a positive number, parameter, or variable that
              specifies the shape parameter;
          <a> is a number, parameter, or variable that
              specifies the lower limit;
          <b> is a number, parameter, or variable that
              specifies the upper limit;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    If <a> and <b> are omitted, they default to 0 and 1,
    respectively.

Examples:
    LET A = SLOPPF(0.95,0.2)
    LET Y = SLOPPF(X,0.5,0,5)
    PLOT SLOPPF(P,2,0,3) FOR P = 0  0.01  1
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SLOCDF = Compute the slope cumulative distribution function.
    SLOPDF = Compute the slope probability density function.
    TSSPDF = Compute the two-sided slope probability density function.
    OGIPDF = Compute the ogive probability density function.
    TOPPDF = Compute the Topp and Leone probability density function.
    RGTPDF = Compute the generalized reflected slope
             probability density function.
    GTLPDF = Compute the generalized slope probability
             density function.
    TSPPDF = Compute the two-sided power probability density
             function.
    BETPDF = Compute the alpha probability density function.
    TRIPDF = Compute the triangular probability density function.
    TRAPDF = Compute the trapezoid probability density function.
    UNIPDF = Compute the uniform probability density function.
    POWPDF = Compute the power probability density function.
    JSBPDF = Compute the Johnson SB probability density function.
 
Reference:
    Samuel Kotz and J. Rene Van Dorp 2004, "Beyond Alpha:
    Other Continuous Families of Distributions with Bounded
    Support and Applications", World Scientific, chapter 8.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    2007/10
 
Program:
    LABEL CASE ASIS
    TITLE CASE ASIS
    TITLE OFFSET 2
    .
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 95
    MULTIPLOT SCALE FACTOR 2
    .
    LET ALPHA  = 0.5
    TITLE Alpha = ^alpha
    PLOT SLOPPF(P,ALPHA) FOR P = 0  0.01  1
    .
    LET ALPHA  = 1
    TITLE Alpha = ^alpha
    PLOT SLOPPF(P,ALPHA) FOR P = 0  0.01  1
    .
    LET ALPHA  = 1.5
    TITLE Alpha = ^alpha
    PLOT SLOPPF(P,ALPHA) FOR P = 0  0.01  1
    .
    LET ALPHA  = 2
    TITLE Alpha = ^alpha
    PLOT SLOPPF(P,ALPHA) FOR P = 0  0.01  1
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 97
    TEXT Slope Percent Point Functions
 
-----SMALLEST (LET)-------------------------------------
 
SMALLEST
 
Name:
    SMALLEST (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Extract the smallest elements of a variable.

Description:
    This is a generalization of the MINIMUM command.  However, instead of
    returning the single smallest value, it returns the user specified
    number of smallest values.

    The values will be returned in sorted order.  If the requested number
    of smallest values is less than 1, then an error will be returned.  If
    the requested number of smallest values is greater than the number of
    observations in the response variable, then the full response variable
    will be returned in sorted order.

Syntax:
    LET <y> = SMALLEST <x>  <nval>    <SUBSET/EXCEPT/FOR>
    where <x> is a response variable;
          <nval> is a number or parameter that specifies how
              many values to extract;
          <y> is a variable that contains the smallest values.
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET NVAL = 3
    LET Y = SMALLEST X NVAL
 
    LET Y = SMALLEST X 3
    LET Y = SMALLEST X 5
    LET Y = SMALLEST X 5  FOR I = 1 1 500

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LARGEST            = Return the largest values in a variable.
    MAXIMUM            = Return the maximum value of a variable.
    MINIMUM            = Return the minimum value of a variable.
 
Applications:
    Data Transformation
 
Implementation Date:
    2018/10
 
Program:
    let y = normal random numbers for i = 1 1 100
    let nval = 5
    let yout = smallest y nval
    set write decimals 3
    print yout

-----SMOOTH-------------------------------------------------------
 
SMOOTH
 
Name:
    ... SMOOTH
 
Type:
    Analysis Command
 
Purpose:
    Carries out
       1) least squares smoothing;
       2) moving average type smoothing;
       2) robust smoothing.
 
Description:
    These are data analysis techniques for producing a "smooth" set of
    values from a time series which has been contaminated with noise.
    For least squares smoothing, the analyst can specify the
       1) degree (default = 1); and
       2) width  (default = 3)
    of the smoothing function.  Any smoothing function from degree 0 to
    degree 5 may be used (moving average smoothing is mathematically
    equivalent to both degree 0 and degree 1 smoothing).  To specify
    the desired degree, the POLYNOMIAL DEGREE command should be used
    prior to the SMOOTH command.  Alternatively (and more commonly) the
    desired degree can be specified as the first word of the SMOOTH
    command.  Thus
       POLYNOMIAL DEGREE 3
       SMOOTH Y
    can be shortened to
       CUBIC SMOOTH Y
    To specify the width of the least squares smoothing function, the
    FILTER WIDTH command should be used prior to the SMOOTH command.
    The filter width must be odd.  For robust smoothing, the 3RSR
    smoother (developed by John Tukey) is used.  For the 3RSR smoother,
    the filter width is always 3 (and so the FILTER WIDTH command is
    not needed).  The 3RSR smoother involves 4 steps:
       1) computes 3-term moving medians;
       2) computes 3-term medians of the 3-term medians repeatedly
          until no change;
       3) applies a "splitting" process;
       4) repeats the splitting process until no change.
    See the Tukey book for complete details of the robust smoothing.
 
Syntax 1:
    <d>   SMOOTH   <y>     <SUBSET/EXCEPT/FOR qualification>
    where <d> is the specification of the desired degree:
              CONSTANT  or ZERO-DEGREE
              LINEAR    or FIRST-DEGREE
              QUADRATIC or SECOND-DEGREE
              CUBIC     or THIRD-DEGREE
              QUARTIC   or FOURTH-DEGREE
              QUINTIC   or FIFTH-DEGREE
          <y> is the variable under analysis;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    ROBUST SMOOTH   <y>     <SUBSET/EXCEPT/FOR qualification>
          <y> is the variable under analysis;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 3:
    <stat>   SMOOTH   <y>     <SUBSET/EXCEPT/FOR qualification>
    where <stat> is the specification of the type of smoothing:
              MOVING AVERAGE
              MOVING MEDIAN
              MOVING MIDMEAN
              MOVING MIDRANGE
              MOVING UPPER QUARTILE
              MOVING LOWER QUARTILE
              MOVING MAXIMUM
              MOVING MINIMUM
              MOVING TRIANGLE
              MOVING HAMMING;
          <y> is the variable under analysis;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LINEAR SMOOTH Y
    QUADRATIC SMOOTH TEMP
    CUBIC SMOOTH V
    ROBUST SMOOTH CONC
    MOVING MEDIAN SMOOTH Y
 
Note:
    The smoothed values are stored in the internal variable PRED.  The
    internal variable RES contains the difference between the observed
    values (i.e., the raw data) and the smoothed values.
 
Note:
    See the sources under the REFERENCE section for the mathematical
    details of the various type of smoothing operations.
 
Note:
    The least squares SMOOTH command assumes equispaced data.  The
    LOWESS SMOOTH command performs locally weighted least squares
    smoothing and can be used for non-equispaced data.
 
Default:
    For least squares smoothing, the default is degree 1 and filter
    width 3 (that is, moving average smoothing of width 3).
 
Synonyms:
    MOVING AVERAGE SMOOTH is identical to LINEAR SMOOTH.
 
Related Commands:
    POLYNOMIAL DEGREE  = Sets the degree for least squares smoothing.
    FILTER WIDTH       = Sets the filter width for least squares
                         smoothing.
    LOWESS SMOOTH      = Carries out a locally weighted least squares
                         smoothing.
    FIT                = Carries out a least squares fit.
 
References:
    "Introduction to Numerical Analysis", F. B. Hildebrand, Dover
    Press, (pp. 295-302, especially 301).
 
    "A First Course in Numerical Analysis", Anthony Ralston,
    (pp. 250-254).
 
    "Smoothing and Differentiation of Data by Simplified Least Squares
    Procedures", A. Savitsky M. J. E. Golay, Analytical Chemistry,
    July, 1964, (pp. 1627-1639).
 
    "Exploratory Data Analysis", John Tukey, Addison-Wesley, 1977.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    SKIP 25
    READ MAVRO.DAT Y
    LET N = SIZE Y
    LET X = SEQUENCE 1 1 N
    .
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE AUTOMATIC
    CHARACTER SIZE 1.2
    CHAR X BLANK
    LINES BLANK SOLID
    PLOT Y
    TITLE LEAST SQUARES CUBIC SMOOTH
    CAPTURE SMOOTH_OUT.DAT
    CUBIC SMOOTH Y
    PLOT Y PRED VS X
    ROBUST SMOOTH Y
    TITLE ROBUST SMOOTH
    PLOT Y PRED VS X
    MOVING MEDIAN SMOOTH Y
    END OF CAPTURE
    TITLE MOVING MEDIAN SMOOTH
    PLOT Y PRED VS X
    END OF MULTIPLOT
 
-----SN (LET)----------------------------------------------
 
SN
 
Name:
    SN (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Jacobi elliptic function sn.
 
Description:
    The Jacobi elliptic function sn is defined as:
        sn(u,k)=SIN(phi)
    where phi is the amplitude and is defined as:
        u = INTEGRAL(1./SQRT(1-k*sin(theta)*sin(theta)))dtheta
    where INTEGRAL is the integral from 0 to phi.

    The algorithm DATAPLOT uses takes MC=1-k**2 as its second
    argument rather than k.  Be aware that other routines take k**2
    as the second argument (e.g., IMSL, NAG, and mathematica).  If
    you want to use k**2, enter something like the following:
        LET K2 = <value>
        LET MC = 1 - K2

Syntax:
    LET <a> = SN(<u>,<mc>)  <SUBSET/EXCEPT/FOR qualification>
    where <u> is a number, parameter, or variable;
          <mc> is a number, parameter, or variable;
          <a> is a variable or a parameter (depending on what <u>
               and <mc> are) where the computed values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SN(2,1)
    LET A = SN(X,0.5)
    LET X2 = SN(9,0)
 
Note:
    The Jacobi elliptic functions are computed using a Fortran
    translation of the Algol-60 procedure given by Bulirsch (see the
    REFERENCE section below).

Note:
    DATAPLOT computes the Jacobi elliptic functions sn, cn, and dn.
    An additional 9 functions can be computed from these:
        cd(u,k) = cn(u,k)/dn(u,k)
        sd(u,k) = sn(u,k)/dn(u,k)
        nd(u,k) = 1/dn(u,k)
        dc(u,k) = dn(u,k)/cn(u,k)
        nc(u,k) = 1/cn(u,k)
        sc(u,k) = sn(u,k)/cn(u,k)
        ns(u,k) = 1/sn(u,k)
        ds(u,k) = dn(u,k)/sn(u,k)
        cs(u,k) = cn(u,k)/sn(u,k)

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CN      = Compute the Jacobi elliptic function cn.
    DN      = Compute the Jacobi elliptic function dn.
    PEQ     = Compute the real component of the Weirstrass elliptic
              function (equianharmonic case).
    PEQI    = Compute the complex component of the Weirstrass elliptic
              function (equianharmonic case).
    PLEM    = Compute the real component of the Weirstrass elliptic
              function (lemniscatic case).
    PLEMI   = Compute the complex component of the Weirstrass elliptic
              function (lemniscatic case).
    RC      = Compute the Carlson degenerate elliptic integral.
    RF      = Compute the Carlson elliptic integral of the first kind.
    RD      = Compute the Carlson elliptic integral of the second kind.
    RJ      = Compute the Carlson elliptic integral of the third kind.
    ELLIPC1 = Compute the Legendre complete elliptic integral of the
              first kind.
    ELLIPC2 = Compute the Legendre complete elliptic integral of the
              second kind.
    ELLIP1  = Compute the Legendre elliptic integral of the first
              kind.
    ELLIP2  = Compute the Legendre elliptic integral of the second
              kind.
    ELLIP3  = Compute the Legendre's elliptic integral of the third
              kind.
 
Reference:
    "Numerical Calculation of Elliptic Integrals and Elliptic
    Functions", Bulirsch, Numerische Mathematik, vol. 7, 1965 
    (pp. 78-90).

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 16).

Applications:
    Special Functions
 
Implementation Date:
    94/11
 
Program:
    TITLE JACOBI ELLIPTIC FUNCTIONS
    LET MC = 0.5
    LINE SOLID DASH DOT
    PLOT SN(X,MC) FOR X = -10 0.1 10 AND
    PLOT CN(X,MC) FOR X = -10 0.1 10 AND
    PLOT DN(X,MC) FOR X = -10 0.1 10
 
-----SNCDF (LET)--------------------------------
 
SNCDF
 
Name:
    SNCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the skew-normal cumulative distribution function.
 
Description:
    The skew-normal distribution has the following probability density
    function:

       f(x,lambda)=2*NORCDF(lambda*x)*NORPDF(x)
                                     -infinity < x, lambda < infinity
 
    For lambda = 0, the skew-normal reduces to a normal distribution.
    As lambda goes to infinity, the skew-normal tends to the
    half-normal distribution.
 
    The cumulative distribution function is computed by numerically
    integrating the skew-normal density function.

    The standard skew-normal distribution can be generalized with
    location and scale parameters.

Syntax:
    LET <y> = SNCDF(<x>,<lambda>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <lambda> is a number of parameter that specifies the
              value of the shape parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <scale> is an optional positive number or parameter that
              specifies the value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed skew-normal cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SNCDF(3,1)
    LET A = SNCDF(A1,LAMBDA)
    LET X2 = SNCDF(X1,0.5)
 
Note:
    Dataplot uses the DQAGI subroutine of Piessens and De Doncker
    from the Quadpack library of integration routines.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SNPDF  = Compute the skew-normal probability density function.
    SNPPF  = Compute the skew-normal percent point function.
    NORPDF = Compute the normal density function.
    CHIPDF = Compute the chi probability density function.
    CHSPDF = Compute the chi-square probability density function.
    WEIPDF = Compute the Weibull probability density function.
 
Reference:
    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

    "Continuous Univariate Distributions: Volume I", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, p. 454.
 
Applications:
    Distributional Analysis, Bayesian Analysis
 
Implementation Date:
    1/2004
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE SKEW-NORMAL: LAMBDA = 0
    PLOT SNCDF(X,0) FOR X = -5 0.1 5
    TITLE SKEW-NORMAL: LAMBDA = 1
    PLOT SNCDF(X,1) FOR X = -5 0.1 5
    TITLE SKEW-NORMAL: LAMBDA = 5
    PLOT SNCDF(X,5) FOR X = -5 0.1 5
    TITLE SKEW-NORMAL: LAMBDA = 10
    PLOT SNCDF(X,10) FOR X = -5 0.1 5
    END OF MULTIPLOT
 
-----SNPDF (LET)--------------------------------
 
SNPDF
 
Name:
    SNPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the skew-normal probability density function.
 
Description:
    The skew-normal distribution has the following probability density
    function:

       f(x,lambda)=2*NORCDF(lambda*x)*NORPDF(x)
                                     -infinity < x, lambda < infinity
 
    For lambda = 0, the skew-normal reduces to a normal distribution.
    As lambda goes to infinity, the skew-normal tends to the
    half-normal distribution.
 
    The standard skew-normal distribution can be generalized with
    location and scale parameters.

Syntax:
    LET <y> = SNPDF(<x>,<lambda>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <lambda> is a number of parameter that specifies the
              value of the shape parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <scale> is an optional positive number or parameter that
              specifies the value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed skew-normal pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SNPDF(3,1)
    LET A = SNPDF(A1,LAMBDA)
    LET X2 = SNPDF(X1,0.5)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SNCDF  = Compute the skew-normal cumulative distribution function.
    SNPPF  = Compute the skew-normal percent point function.
    NORPDF = Compute the normal density function.
    CHIPDF = Compute the chi probability density function.
    CHSPDF = Compute the chi-square probability density function.
    WEIPDF = Compute the Weibull probability density function.
 
Reference:
    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

    "Continuous Univariate Distributions: Volume I", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, p. 454.
 
Applications:
    Distributional Analysis, Bayesian Analysis
 
Implementation Date:
    1/2004
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE SKEW-NORMAL: LAMBDA = 0
    PLOT SNPDF(X,0) FOR X = -5 0.1 5
    TITLE SKEW-NORMAL: LAMBDA = 1
    PLOT SNPDF(X,1) FOR X = -5 0.1 5
    TITLE SKEW-NORMAL: LAMBDA = 5
    PLOT SNPDF(X,5) FOR X = -5 0.1 5
    TITLE SKEW-NORMAL: LAMBDA = 10
    PLOT SNPDF(X,10) FOR X = -5 0.1 5
    END OF MULTIPLOT
 
-----SNPPF (LET)--------------------------------
 
SNPPF
 
Name:
    SNPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the skew-normal percent point function.
 
Description:
    The skew-normal distribution has the following probability density
    function:

       f(x,lambda)=2*NORCDF(lambda*x)*NORPDF(x)
                                     -infinity < x, lambda < infinity
 
    For lambda = 0, the skew-normal reduces to a normal distribution.
    As lambda goes to infinity, the skew-normal tends to the
    half-normal distribution.
 
    The skew-normal percent point function is computed by numerically
    inverting the skew-normal cumulative distribution function (which
    in turn is computed by numerically integrating the skew-normal
    density function).

    The standard skew-normal distribution can be generalized with
    location and scale parameters.

Syntax:
    LET <y> = SNPPF(<p>,<lambda>,<loc>,<scale>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable or a parameter in the range (0,1);
          <lambda> is a number of parameter that specifies the
              value of the shape parameter;
          <loc> is an optional number or parameter that specifies the
              value of the location parameter;
          <scale> is an optional positive number or parameter that
              specifies the value of the scale parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed skew-normal ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SNPPF(0.95,1)
    LET A = SNPPF(A1,LAMBDA)
    LET X = SNPPF(P1,0.5)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SNCDF  = Compute the skew-normal cumulative distribution function.
    SNPDF  = Compute the skew-normal probability density function.
    NORPDF = Compute the normal density function.
    CHIPDF = Compute the chi probability density function.
    CHSPDF = Compute the chi-square probability density function.
    WEIPDF = Compute the Weibull probability density function.
 
Reference:
    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

    "Continuous Univariate Distributions: Volume I", Second Edition,
    Johnson, Kotz, and Balakrishnan, Wiley, 1994, p. 454.
 
Applications:
    Distributional Analysis, Bayesian Analysis
 
Implementation Date:
    1/2004
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE SKEW-NORMAL: LAMBDA = 0
    PLOT SNPPF(P,0) FOR P = 0.01 0.01 0.99
    TITLE SKEW-NORMAL: LAMBDA = 1
    PLOT SNPPF(P,1) FOR P = 0.01 0.01 0.99
    TITLE SKEW-NORMAL: LAMBDA = 5
    PLOT SNPPF(P,5) FOR P = 0.01 0.01 0.99
    TITLE SKEW-NORMAL: LAMBDA = 10
    PLOT SNPPF(P,10) FOR P = 0.01 0.01 0.99
    END OF MULTIPLOT
 
-----SN SCALE (LET)-------------------------------
 
SN SCALE
 
Name:
    SN SCALE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the Sn scale estimate for a variable.
 
Description:
    Mosteller and Tukey (see Reference section below) define
    two types of robustness:

      1) resistance means that changing a small part, even by a
         large amount, of the data does not cause a large change
         in the estimate

      2) robustness of efficiency means that the statistic has
         high efficiency in a variety of situations rather than
         in any one situation.  Efficiency means that the estimate
         is close to optimal estimate given that we know what
         distribution that the data comes from.  A useful measure
         of efficiency is:

              Efficiency = (lowest variance feasible)/
                           (actual variance)
   
    Many statistics have one of these properties.  However,
    it can be difficult to find statistics that are both
    resistant and have robustness of efficiency.

    The most common estimate of scale, the standard deviation,
    is the most efficient estimate of scale if the data come from
    a normal distribution.  However, the standard deviation is
    not robust in the sense that changing even one value can
    dramatically change the computed value of the standard deviation
    (i.e., poor resistance).  In addition, it does not have
    robustness of efficiency for non-normal data.

    The median absolute deviation (MAD) and interquartile range are
    the two most commonly used robust alternatives to the standard
    deviation.  The MAD in particular is a very robust scale
    estimator.  However, the MAD has the following limitations:

       1) It does not have particularly high efficiency for
          data that is in fact normal (37%).  In comparison, the
          median has 64% efficiency for normal data.

       2) The MAD statistic also has an implicit assumption of
          symmetry.  That is, it measures the distance from a
          measure of central location (the median).

    Rousseeuw and Croux proposed the Sn estimate of scale as an
    alternative to the MAD.  It shares desirable robustness
    properties with MAD (50% breakdown point, bounded influence
    function).  In addition, it has significantly better normal
    efficiency (58%) and it does not depend on symmetry.
      
    The Sn scale estimate is defined as:

        Sn = c*MEDIAN(i){MEDIAN(j)|x(i) - x(j)|}

    That is, for each i we compute the median of
    {|x(i) - x(j)|; j = 1, ..., n}.  The median of these n
    numbers is then the estimate of Sn.  The constant c is
    determined to make Sn a consistent estimator.  The value
    used is 1.1926 (this is the value needed to make Sn a
    consistent estimator for normal data).

    The Sn statistic measures typical distances between values
    in contrast to the MAD and the standard deviation which
    measure the distance from a central location.  This is why
    the Sn is appropriate for asymmetic distributions as well
    symmetric distributions.

    The Rousseeuw and Croux article (see the Reference section
    below) discusses the properties of the Sn estimate in
    detail.
 
Syntax:
    LET <par> = SN SCALE <y>      <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed Sn scale
               statistic is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SN SCALE Y1
    LET A = SN SCALE Y1 SUBSET TAG > 2
 
Note:
    Dataplot uses code provided by Rousseeuw and Croux to compute
    the Sn estimate.  This algorithm uses an efficient computational
    method for computing Sn.

Note:
    The Rousseeuw and Croux article also proposes the Qn scale
    estimate.  The article discusses the properties of both
    estimators in detail.

Note:
    In addition, the Sn statistic is supported for the following
    plots and commands

       SN SCALE PLOT Y X
       CROSS TABULATE SN SCALE PLOT Y X1 X2
       BOOTSTRAP SN SCALE PLOT Y
       JACKNIFE SN SCALE PLOT Y
       DEX SN SCALE PLOT Y X1 ... XK
       SN SCALE BLOCK PLOT Y X1 ... XK
       SN SCALE INFLUENCE CURVE Y
       SN SCALE INTERACTION PLOT Y X1 X2

       TABULATE SN SCALE Y X
       CROSS TABULATE SN Y X1 X2
       LET Z = CROSS TABULATE SN SCALE Y X1 X2
       LET Y = MATRIX COLUMN SN SCALE M 
       LET Y = MATRIX ROW SN SCALE M 


Default:
    None
 
Synonyms:
    None
 
Related Commands:
    QN SCALE                   = Compute the Qn scale estimate of a
                                 variable.
    MEDIAN ABSOLUTE DEVIATION  = Compute the median absolute
                                 deviation of a variable.
    INTERQUARTILE RANGE        = Compute the interquartile range of
                                 a variable.
    STANDARD DEVIATION         = Compute the standard deviation of a
                                 variable.
    DIFFERENCE OF SN           = Compute the difference of the Sn
                                 scale estimates between two variables.
    STATISTIC PLOT             = Generate a statistic versus subset
                                 plot.
    CROSS TABULATE PLOT        = Generate a statistic versus subset
                                 plot (two subset variables).
    BOOTSTRAP PLOT             = Generate a bootstrap plot for a
                                 statistic.
 
Reference:
    "Alternatives to the Median Absolute Deviation",
    Peter J. Rousseuw and Christophe Croux, Journal of the American
    Statistical Association, December, 1993, Vol. 88, No. 424,
    pp. 1273-1283.

    "Data Analysis and Regression: A Second Course in Statistics",
    Mosteller and Tukey, Addison-Wesley, 1977, pp. 203-209.

Applications:
    Data Analysis
 
Implementation Date:
    2003/4
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    MULTIPLOT SCALE FACTOR 2
    X1LABEL DISPLACEMENT 12
    .
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 200
    LET SIGMA = 1
    LET Y2 = LOGNORMAL RANDOM NUMBERS FOR I = 1 1 200
    .
    BOOTSTRAP SAMPLES 500
    BOOTSTRAP SN SCALE PLOT Y1
    X1LABEL B025 = ^B025, B975=^B975
    HISTOGRAM YPLOT
    X1LABEL
    .
    BOOTSTRAP SN SCALE PLOT Y2
    X1LABEL B025 = ^B025, B975=^B975
    HISTOGRAM YPLOT
    .
    END OF MULTIPLOT
    JUSTIFICATION CENTER
    MOVE 50 96
    TEXT SN SCALE BOOTSTRAP: NORMAL
    MOVE 50 46
    TEXT SN SCALE BOOTSTRAP: LOGNORMAL
 
-----SORT2 (LET)---------------------------------------------------
 
SORT2
 
Name:
    SORT2 (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Sort the elements of two, three, or four variables in ascending
    order.
 
Description:
    The SORT command is used to sort a single variable.  In some
    cases, it is desirable to sort based on more than one
    variable.  Note that this only makes sense if some of the
    variables contain replication.  For example, if you have
    one or more group variables, you might want to sort a
    response variable within common values of the group-id
    variables.

    In the variable list, the sorts are performed from left
    to right.  For example, if we are sorting the variables
    X and Y, we first sort the X variable (and carry the
    corresponding rows in Y).  We then determine the distinct
    values in the X array.  For each distinct value of X,
    we sort the corresponding rows in the Y variable.

Syntax 1:
    LET <y1> <y2> = SORT2 <x1> <x2>
                    <SUBSET/EXCEPT/FOR qualification>
    where <x1> is the first variable to be sorted;
          <x2> is the second variable to be sorted;
          <y1> is a variable where the sorted <x1> values are saved;
          <y2> is a variable where the sorted <x2> values are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where we are sorting based
    on two variables.

Syntax 2:
    LET <y1> <y2> <y3> = SORT3 <x1> <x2> <x3>
                    <SUBSET/EXCEPT/FOR qualification>
    where <x1> is the first variable to be sorted;
          <x2> is the second variable to be sorted;
          <x3> is the third variable to be sorted;
          <y1> is a variable where the sorted <x1> values are saved;
          <y2> is a variable where the sorted <x2> values are saved;
          <y3> is a variable where the sorted <x3> values are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where we are sorting based
    on three variables.

Syntax 3:
    LET <y1> <y2> <y3> <y4> = SORT4 <x1> <x2> <x3> <x4>
                    <SUBSET/EXCEPT/FOR qualification>
    where <x1> is the first variable to be sorted;
          <x2> is the second variable to be sorted;
          <x3> is the third variable to be sorted;
          <x4> is the fourth variable to be sorted;
          <y1> is a variable where the sorted <x1> values are saved;
          <y2> is a variable where the sorted <x2> values are saved;
          <y3> is a variable where the sorted <x3> values are saved;
          <y4> is a variable where the sorted <x4> values are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case where we are sorting based
    on four variables.

Examples:
    LET X2 Y2 = SORT2 X Y
    LET Y1 Y2 Y3 = SORT3 X1 X2 X3
    LET Y1 Y2 Y3 Y4 = SORT3 X1 X2 X3 X4
 
Note:
    Once data for specific replication has been extracted,
    DATAPLOT uses the QUICKSORT algorithm developed by Richard
    Singelton to perform the sort of a single variable.
 
Note:
    By default, the values are sorted in ascending order.  If
    you want to sort values in descending order, enter the
    command

       SET SORT DIRECTION DESCENDING

    Currently, all variables must be sorted in the same
    direction (i.e., either ascending or descending).

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SORT         = Sort the elements of a variable.
    SORTC        = Sort the elements of a variable and carry one or
                   more variables along.
    COCODE       = Generate a cocoded variable.
    CODE         = Generate a coded variable.
    SEQUENCE     = Generate a sequence of numbers.
    PATTERN      = Generate numbers with a specific pattern.
    RANK         = Rank the elements of a variable.
 
Reference:
    "Quicksort Algorithm", Richard Singelton, CACM, March, 1969.
 
Applications:
    Data Management
 
Implementation Date:
    2008/10
 
Program 1:
    SKIP 25
    READ GEAR.DAT Y X
    LET X2 Y2 = SORT2 X Y
    SET WRITE DECIMALS 3
    PRINT X Y X2 Y2
 
Program 2:
    SKIP 25
    READ RIPKEN.DAT Y X1 X2 X3 X4
    LET Z2 Z3 Y2 = SORT3 X2 X3 Y
    SET WRITE DECIMALS 3
    PRINT X2 X3 Y Z2 Z3 Y2
    LET Z2 Z3 Z4 Y2 = SORT4 X2 X3 X4 Y
    SET WRITE DECIMALS 3
    PRINT X2 X3 X4 Y Z2 Z3 Z4 Y2
 
-----SORT (LET)---------------------------------------------------
 
SORT
 
Name:
    SORT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Sort the elements of a variable in ascending order.
 
Syntax:
    LET <resp> = SORT <y1>  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the variable to be sorted (it is not changed);
          <resp> is a variable where the sorted values are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET YSORT = SORT Y1
 
Note:
    DATAPLOT uses the QUICKSORT algorithm developed by Richard
    Singelton.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    COCODE       = Generate a cocoded variable.
    CODE         = Generate a coded variable.
    SEQUENCE     = Generate a sequence of numbers.
    PATTERN      = Generate numbers with a specific pattern.
    RANK         = Rank the elements of a variable.
    SORTC        = Sort the elements of a variable and carry one or
                   more variables along.
 
Reference:
    "Quicksort Algorithm", Richard Singelton, CACM, March, 1969.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y2 = SORT Y1
 
-----SORT BY STATISTIC (LET)-----------------------------------------
 
SORT BY STATISTIC (LET)
 
Name:
    SORT BY STATISTIC (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Sort the values of a group variable based on the values
    of a user-specified statistic for each group.
 
Description:
    For plots based on a response variable and a corresponding
    group-id variable, it is often desirable to generate the
    plot sorted by the value of some statistic for each group.
    For example, you may want to generate a box plot ordered
    from the smallest median to the largest median.

    In most cases, the sorting statistic will be a location
    statistic such as the mean, median, minimum, or maximum.
    However, Dataplot supports 40+ statistics for the sorting
    statistic.

    The SORT BY command is a utility command that simplifies
    the generation of these sorted plots.  Specifically, it can
    be used in conjunction with the following types of plots:

       1) BOX PLOT
       2) <STATISTIC> PLOT
       3) PLOT Y X TAG  (i.e., scatter plot with replication)

    Given a response variable, Y, and a group-id variable, X,
    the SORT BY command computes the value of a specified
    statistic for each group and returns the following two
    variables:

       1) An index variable which is the ranking of the
          computed statistic for each group (if there are five
          groups in the data, the index variable will have
          five elements).

       2) A sorted group-id variable, X2, that is used in
          place of the original X variable in subsequent
          plots.

Syntax:
    LET <x2> <index> = SORT BY <stat> <y> <x>
                        <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x> is the group-id variable;
          <stat> is one of the following statistics:
              MEAN, MIDMEAN, MEDIAN, TRIMMED MEAN, WINSORIZED MEAN,
              GEOMETRIC MEAN, HARMONIC MEAN, HODGES LEHMAN,
              BIWEIGHT LOCATION,
              SUM, PRODUCT, SIZE (or NUMBER or SIZE),
              STANDARD DEVIATION, STANDARD DEVIATION OF MEAN,
              VARIANCE, VARIANCE OF THE MEAN,
              TRIMMED MEAN STANDARD ERROR,
              AVERAGE ABSOLUTE DEVIATION (or AAD),
              MEDIAN ABSOLUTE DEVIATION (or MAD),
              IQ RANGE, BIWEIGHT MIDVARIANCE, BIWEIGHT SCALE,
              PERCENTAGE BEND MIDVARIANCE,
              WINSORIZED VARIANCE, WINSORIZED STANDARD DEVIATION,
              RELATIVE STANDARD DEVIATION, RELATIVE VARIANCE,
              COEFFICIENT OF VARIATION,
              RANGE, MIDRANGE, MAXIMUM, MINIMUM, EXTREME,
              LOWER HINGE, UPPER HINGE, LOWER QUARTILE, UPPER QUARTILE,
              <FIRST/SECOND/THIRD/FOURTH/FIFTH/SIXTH/SEVENTH/EIGHTH/
                  NINTH/TENTH> DECILE,
              PERCENTILE, QUANTILE, QUANTILE STANDARD ERROR,
              SKEWNESS, KURTOSIS, NORMAL PPCC,
              AUTOCORRELATION, AUTOCOVARIANCE,
              SIN FREQUENCY, SIN AMPLITUDE,
              CP, CPK, CNPK, CPM, CC,
              EXPECTED LOSS, PERCENT DEFECTIVE,
              TAGUCHI SN0 (or SN), TAGUCHI SN+ (or SNL),
              TAGUCHI SN- (or SNS), TAGUCHI SN00 (or SN2);
          <x2> is a variable where the sorted group-id values are
             stored;
          <index> is a variable where the ranking of the statistic
             for each group are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET X2 INDX = SORT BY MEAN Y X
    LET X2 INDX = SORT BY MEIDAN Y X
    LET X2 INDX = SORT BY SD Y X
    LET X2 INDX = SORT BY MINIMUM Y X
    LET X2 INDX = SORT BY IQ RANGE Y X

Note:
    These plots often have alphabetic tick mark labels.  The
    following enhancements were made to simplify the use
    of alphabetic tick mark labels with sorted plots.

    a) The TIC MARK LABEL FORMAT and TIC MARK LABEL CONTENT
       commands were previously augmented to allow numeric
       variables, group label variables, or the row label
       variable as the contents for the tick mark labels.
       Specifically,

          LET LAB = DATA 50 40 30 20 10 0
          X1TIC MARK LABEL FORMAT VARIABLE
          X1TIC MARK LABEL CONTENT LAB

          LET IG = GROUP LABELS A B C D E
          X1TIC MARK LABEL FORMAT GROUP LABEL
          X1TIC MARK LABEL CONTENT IG

          X1TIC MARK LABEL FROMAT ROW LABELS

       This has been enhanced to allow an index variable to
       be specified on the above TIC MARK LABEL CONTENT
       commands (the index variable is typically generated by
       a SORT BY <stat> command).  The index variable specifies
       the order in which the tic mark labels will be generated.
    
       So the above examples can be augmented by

          LET X2 INDX = SORT BY MEAN Y X
          LET LAB = DATA 50 40 30 20 10 0
          X1TIC MARK LABEL FORMAT VARIABLE
          X1TIC MARK LABEL CONTENT LAB INDX

          LET X2 INDX = SORT BY MEAN Y X
          LET IG = GROUP LABELS A B C D E
          X1TIC MARK LABEL FORMAT GROUP LABEL
          X1TIC MARK LABEL CONTENT IG INDX

          LET X2 INDX = SORT BY MEAN Y X
          X1TIC MARK LABEL FROMAT ROW LABELS
          X1TIC MARK LABEL CONTENT INDX

       Note that it is the values of INDX when the plot is
       generated, not when the TIC MARK LABEL CONTENT is
       entered, that will be used to sort the tick mark labels.

    b) The LET ... = GROUP LABEL .... command was augmented in
       the following two ways.

        i) You can specify literal strings for group labels.
           For example,

              LET IG = GROUP LABEL  BATCHSP()1 BATCHSP()2 ...
                       BATCHSP()3 BATCHSP()4

           The strings are separated by spaces.  If you need to
           include a space in a particular string, use the
           SP() as in the above example.

       ii) Pre-defined strings can be used to define a group
           label variable.  For example,

              LET IG = GROUP LABEL ST1 TO ST10

           where ST1, ST2, ...., ST10 are previously defined
           strings.  The TO syntax is useful in this context
           when the number of strings is large.
        
       Dataplot's algorithm for parsing the GROUP LABEL command
       is:

         i) Dataplot first checks the character variables file
            (HELP SET CONVERT CHARACTER for details).  If the
            first name listed is found, Dataplot uses this
            character variable to define the group labels.
 
        ii) If a character variable is not found, Dataplot
            checks all the listed names to see if they are
            previously defined strings.  If they are, then
            Dataplot substitutes the values of these strings.
 
       iii) If one or more of the names is not a previously
            defined string, then Dataplot treats all of the
            names as literal text strings.

    
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PLOT                   = Generate a plot.
    BOX PLOT               = Generate a box plot.
    STATISTIC PLOT         = Generate a statistic versus subset plot.
    TIC MARK LABEL FORMAT  = Specify the format for tic mark labels.
    TIC MARK LABEL CONTENT = Specify the content for alphabetic
                             tic mark labels.
 
Applications:
    Data Analysis
 
Implementation Date:
    2006/1: Original Implementation
 
Program 1:
    skip 25
    read splett2.dat y x
    .
    let x2 indx = sort by median y x
    let ig = group label Tinius1 Tinius2 Satec Tokyo
    x1tic mark label case asis
    x1tic mark label format group labels
    x1tic mark label content ig indx
    .
    char box plot
    line box plot
    fences on
    .
    xlimits 1 4
    major xtic mark number 4
    minor xtic mark number 0
    xtic offset 0.5 0.5
    .
    title case asis
    title offset 2
    title Charpy V-NIST Notch Testing
    label case asis
    x1label Machine Manufacturer
    y1label Absorbed Energy
    .
    box plot y x2

Program 2:
    set convert character on
    skip 25
    read draft69c.dat rank day month
    .
    let ig = group label month
    x1tic mark label format group label
    let xcode = character code month
    .
    major xtic mark number 12
    minor xtic mark number 0
    xlimits 1 12
    xtic offset 0.5 0.5
    .
    let xcode2 indx = sort by mean rank xcode
    x1tic mark label content ig  indx
    .
    x1tic mark label size 1.5
    tic mark label case asis
    label case asis
    title case asis
    title displacement 2
    x1label Month
    y1label Draft Ranking
    title Mean Plot Ordered by Mean
    .
    mean plot rank xcode2

Program 3:
    skip 25
    read splett2.dat y x
    .
    let ig = group label Tinius1 Tinius2 Satec Tokyo
    .
    char x blank
    line blank dash
    .
    xlimits 1 4
    major xtic mark number 4
    minor xtic mark number 0
    tic offset units screen
    tic offset 5 5
    .
    title offset 2
    multiplot corner coordinates 0 0 100 100
    multiplot 2 2
    multiplot scale factor 2
    .
    x1tic mark label format group label
    x1tic mark label content ig
    title Mean Plot (Unsorted)
    mean plot y x
    .
    title SD Plot (Unsorted)
    sd plot y x
    .
    title Mean Plot (Sorted by Mean)
    let x2 indx = sort by mean y x
    x1tic mark label content ig indx
    mean plot y x2
    .
    title SD Plot (Sorted by SD)
    let x2 indx = sort by sd y x
    x1tic mark label content ig indx
    sd plot y x2
    .
    end of multiplot

Program 4:
    skip 25
    read gear.dat y x
    .
    char x all
    line solid all
    .
    xlimits 1 10
    major xtic mark number 10
    minor xtic mark number 0
    xtic offset 0.5 0.5
    .
    title offset 2
    multiplot corner coordinates 0 0 100 100
    multiplot 2 2
    multiplot scale factor 2
    .
    title Original Data
    plot y x x
    .
    title Sort by Mean
    let x2 indx = sort by mean y x
    x1tic mark label format variable
    x1tic mark label content indx
    plot y x2 x2
    .
    title Sort by Minimum
    let x2 indx = sort by minimum y x
    x1tic mark label content indx
    plot y x2 x2
    .
    title Sort by SD
    let x2 indx = sort by sd y x
    x1tic mark label content indx
    plot y x2 x2
    .
    end of multiplot

-----SORTC (LET)---------------------------------------------------
 
SORTC
 
Name:
    SORTC (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Sort the elements of a variable in ascending order.  In addition,
    carry one or more additional variables along when doing the sort
    (that is, the additional variables are sorted in the order of the
    first variable).
 
Syntax:
    LET <resp> = SORTC <y1>  <y2> ... <yn>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the variable to be sorted (it is not changed);
          <y2> ... <yn> is a list of variables to be carried along;
          <resp> is a variable where the sorted values are saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET YSORT = SORT Y1  Y2
    LET YSORT = SORT Y1  Y2 Y3 Y4
 
Note:
    DATAPLOT uses the QUICKSORT algorithm developed by Richard
    Singelton.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    COCODE       = Generate a cocoded variable.
    CODE         = Generate a coded variable.
    SEQUENCE     = Generate a sequence of numbers.
    PATTERN      = Generate numbers with a specific pattern.
    RANK         = Rank the elements of a variable.
    SORT         = Sort the elements of a variable.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    XX
 
-----SORT DIRECTION (SET)---------------------------------------
 
SORT DIRECTION
 
Name:
    SORT DIRECTION (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify whether sorts performed by SORT and SORTC generate
    ascending or descending sorts.
 
Syntax:
    SET SORT DIRECTION <value>
    where <value> is ASCENDING or DESCENDING.
 
Examples:
    SET SORT DIRECTION ASCENDING
    SET SORT DIRECTION DESCENDING
 
Default:
    The default is ASCENDING.
 
Synonyms:
    None
 
Related Commands:
    SORT     = Sort an array of numbers.
    SORTC    = Sort an array of numbers and carry other arrays.
 
Applications:
    Sorting
 
Implementation Date:
    2000/1
 
Program:
    LET Y = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y2 = SORT Y
    SET SORT DIRECTION DESCENDING
    LET Y3 = SORT Y
    SET WRITE DECIMALS 3
    PRINT Y Y2 Y3
 
-----SPACING-------------------------------------------------------
 
SPACING
 
Name:
    SPACING
 
Type:
    Diagrammatic Graphics Command
 
Purpose:
    Specifies whether text is drawn with fixed or proportional spacing.
 
Description:
    Proportional spacing often has a neater appearance.  However, fixed
    spacing is desirable when it is important to line up different
    portions of text.
 
Syntax:
    SPACING  <FIXED/PROPORTIONAL>
    where FIXED specifies fixed spacing and PROPORTIONAL specifies
             proportional spacing.
 
Examples:
    SPACING FIXED
    SPACING PROPORTIONAL
 
Note:
    This command only applies to software fonts.  The spacing for
    hardware fonts is determined by the definition of the font and
    cannot be changed.  Most hardware fonts are fixed space fonts.
    The exception is that most Postscript and QMS fonts are
    proportional space fonts.  If fixed spacing is needed for
    Postscript, use the SET POSTSCRIPT FONT command to set one of the
    Courier fonts (all the rest are proportional).  The SET QMS FONT
    command can be used to set the hardware font for QMS devices.
    See the documentation for the QMS device for a list of which fonts
    are fixed and which are proportional.
 
Default:
    Proportional spacing is used by default.
 
Synonyms:
    None
 
Related Commands:
    TEXT             = Writes a text string.
    FONT             = Specify the font to use for text.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    VERTICAL SPACING 6
    CRLF ON
    MARGIN 10
    FONT DUPLEX
    SPACING PROPORTIONAL
    .
    HW 4 2
    MOVE 5 95
    TEXT JAPAN's 6-POINT PROGRAM FOR
    MOVE 5 89
    TEXT QUALITY MANUFACTURING
    MOVE 10 80
    HW 2.6 1.3
    TEXT CIRC() QUALITY AUDITS
    TEXT CIRC() COMPANY-WIDE QUALITY CONTROL (CWQC)
    TEXT CIRC() QUALITY TRAINING AND EDUCATION
    TEXT CIRC() APPLICATION OF STATISTICAL METHODS
    .
    SPACING FIXED
    .
    TEXT CIRC() QUALITY CIRCLE ACTIVITIES
    TEXT CIRC() NATION-WIDE QUALITY CONTROL PROMOTIONAL ACTIVITIES
    HW 2 1
    MOVE 5 10
    TEXT SOURCE: Q.C. TRENDS WINTER 1985, PAGES 22-23.
 
-----SPEARMAN DISSIMILARITY (LET)--------------------------------
 
SPEARMAN DISSIMILARITY
 
Name:
    SPEARMAN DISSIMILARITY (LET)
    SPEARMAN SIMILARITY (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the Spearman rank correlation coefficient transformed to a
    dissimilarity measure between two variables.
 
Description:
    If the measurements in the two samples are replaced with their ranks
    (and average ranks in the case of ties) and the Pearson correlation
    coefficient (HELP CORRELATION for details) is computed, the result is
    the Spearman rho correlation coefficient.

    The rank correlation is recommended in the following cases:

      1) When the underlying data does not have a meaningful numerical
         measure, but it can be ranked;
      2) When the relationship between the two variables is not
         linear;
      3) When the normality assumption for two variables is not
         valid.

    A perfect linear relationship yields a correlation coefficient of
    +1 (or -1 for a negative relationship) and no linear relationship
    yields a correlation coefficient of 0.
 
    In some applications, such as clustering, it can be useful to
    transform the correlation coefficient to a dissimilarity measure.
    The transformation used here is

        d = (1 - R)/2

    This converts the correlation coefficient with values between -1 and
    1 to a score between 0 and 1.  High positive correlation (i.e., very
    similar) results in a dissimilarity near 0 and high negative
    correlation (i.e., very dissimilar) results in a dissimilarity near 1.

    If a similarity score is preferred, you can use

        s = 1 - d

    where d is defined as above.

Syntax 1:
    LET <par> = SPEARMAN DISSIMILARITY <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed Spearman dissimilarity
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Syntax 2:
    LET <par> = SPEARMAN SIMILARITY <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed Spearman similarity
               is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

Examples:
    LET A = SPEARMAN DISSIMILARITY Y1 Y2
    LET A = SPEARMAN DISSIMILARITY Y1 Y2 SUBSET TAG > 2
    LET A = SPEARMAN SIMILARITY Y1 Y2
 
Note:
    The two variables must have the same number of elements.
 
Default:
    None
 
Synonyms:
    SPEARMAN DISTANCE is a synonym for SPEARMAN DISSIMILARITY
 
Related Commands:
    RANK CORRELATION          = Compute Spearman's rank correlation
                                coefficient.
    CORRELATION               = Compute the Pearson correlation of two
                                variables.
    PEARSON DISSIMILARITY     = Compute the dissimilarity of two variables
                                based on Pearson correlation.
    KENDALL TAU DISSIMILARITY = Compute the dissimilarity of two variables
                                based on Kendall's tau correlation.
    COSINE DISTANCE           = Compute the cosine distance.
    MANHATTAN DISTANCE        = Compute the Euclidean distance.
    EUCLIDEAN DISTANCE        = Compute the Euclidean distance.
    MATRIX DISTANCE           = Compute various distance metrics for a
                                matrix.
    GENERATE MATRIX <stat>    = Compute a matrix of pairwise statistic
                                values.
    CLUSTER                   = Perform a cluster analysis.
 
Reference:
    Kaufman and Rousseeuw (1990), "Finding Groups in Data: An
    Introduction To Cluster Analysis", Wiley.

Applications:
    Clustering
 
Implementation Date:
    2017/08:
    2018/10: SPEARMAN DISTANCE is a synonym for SPEARMAN DISSIMILARITY
 
Program 1:
    SKIP 25
    READ BERGER1.DAT Y X
    LET CORR = RANK CORRELATION Y X
    LET D    = SPEARMAN DISSIMILARITY Y X
    SET WRITE DECIMALS 4
    PRINT CORR D
 
Program 2:
    SKIP 25
    READ IRIS.DAT Y1 Y2 Y3 Y4
    SET WRITE DECIMALS 3
    .
    LET M = GENERATE MATRIX SPEARMAN DISSIMILARITY Y1 Y2 Y3 Y4
    PRINT M
 
Program 3:
    SKIP 25
    READ IRIS.DAT Y1 Y2 Y3 Y4 TAG
    .
    TITLE CASE ASIS
    TITLE OFFSET 2
    CASE ASIS
    TIC MARK OFFSET UNITS DATA
    YLIMITS 0 1
    MAJOR YTIC MARK NUMBER 6
    MINOR YTIC MARK NUMBER 1
    Y1TIC MARK LABEL DECIMAL 1
    XLIMITS 1 3
    MAJOR XTIC MARK NUMBER 3
    MINOR XTIC MARK NUMBER 0
    XTIC MARK OFFSET 0.3 0.3
    CHARACTER X BLANK
    LINES BLANK SOLID
    .
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    MULTIPLOT SCALE FACTOR 2
    MULTIPLOT 2 3
    .
    TITLE Sepal Length vs Sepal Width
    SPEARMAN DISSIMILARITY PLOT Y1 Y2 TAG
    .
    TITLE Sepal Length vs Petal Length
    SPEARMAN DISSIMILARITY PLOT Y1 Y3 TAG
    .
    TITLE Sepal Length vs Petal Width
    SPEARMAN DISSIMILARITY PLOT Y1 Y4 TAG
    .
    TITLE Sepal Width vs Petal Length
    SPEARMAN DISSIMILARITY PLOT Y2 Y3 TAG
    .
    TITLE Sepal Width vs Petal Width
    SPEARMAN DISSIMILARITY PLOT Y2 Y4 TAG
    .
    TITLE Petal Length vs Petal Width
    SPEARMAN DISSIMILARITY PLOT Y3 Y4 TAG
    .
    END OF MULTIPLOT
    .
    JUSTIFICATION CENTER
    MOVE 50 5
    TEXT Species
    DIRECTION VERTICAL
    MOVE 5 50
    TEXT Spearman Rank Dissimilarity Coefficient
    DIRECTION HORIZONTAL
 
-----SPECTRAL PLOT---------------------------------------------------
 
SPECTRAL PLOT
 
Name:
    ... SPECTRAL PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a spectral plot.
 
Description:
    A spectral plot is a graphical data analysis technique for
    examining frequency-domain models for a single time series or for
    two time series.  The spectral power function is a smoothed Fourier
    transform of the autocorrelation function.  The spectral plot is a
    graphical technique for assessing autocorrelation and cyclic
    structure in time series.  The frequency is plotted (on the
    horizontal axis) from 0 to 0.5 cycles per unit time where unit time
    is assumed to be 1 (i.e., unit time is the elapsed time between
    adjacent data values).  The variance component at each frequency is
    plotted on the vertical axis.
 
    From a data analysis point of view, the type of structure in the
    autocorrelation plot indicates the location of peaks in the
    spectral plot.  The peaks in the spectral plot also indicate the
    dominant frequency for underlying cyclic models.  Once the dominant
    peaks have been identified, the next step is typically to use other
    time series analysis techniques (such as the complex demodulation
    phase plots) to determine if this frequency is constant over the
    entire domain of the data, or to carry out a non-linear fit with an
    underlying cyclic model (see the documentation for COMPLEX
    DEMODULATION PLOT).
 
    The axes depend on the type of spectral plot.  The autospectral
    plot has the following:
       Vertical   axis = power (= variable contribution);
       Horizontal axis = frequency (cycles per observation).
    Spectral plots are available in the following 9 types:
          1) spectral plot (= autospectral plot)
          2) cross-spectral plot
          3) co-spectral plot
          4) quadrature spectral plot
          5) coherency spectral plot
          6) amplitude spectral plot
          7) phase spectral plot
          8) gain spectral plot
          9) argand spectral plot
 
Syntax 1:
    SPECTRAL PLOT <y1>       <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for a single time series.
 
Syntax 2:
    <keyword> PLOT <y1> <y2>  <SUBSET/EXCEPT/FOR qualification>
    where <keyword> is one of the following:
               CROSS-SPECTRAL
               CO-SPECTRAL
               QUADRATURE SPECTRAL
               COHERENCY SPECTRAL
               AMPLITUDE SPECTRAL
               PHASE PSECTRAL
               ARGAND SPECTRAL;
          <y1> is the first response variable;
          <y2> is the second response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for two time series.
 
Examples:
    SPECTRAL PLOT Y
    SPECTRAL PLOT Y2  SUBSET Y2 > 2
    CROSS-SPECTRAL PLOT Y1 Y2
    CO-SPECTRAL PLOT Y1 Y2
    QUADRATURE SPECTRAL PLOT Y1 Y2
    COHERENCY SPECTRAL PLOT Y1 Y2
    AMPLITUDE SPECTRAL PLOT Y1 Y2
    PHASE SPECTRAL PLOT Y1 Y2
    ARGAND SPECTRAL PLOT Y1 Y2
 
Note:
    The SPECTRAL PLOT command assumes the data are equi-spaced and
    that there is no missing data.  Any equi-spaced time series is
    intrinsically limited to detecting frequencies no larger than 0.5
    cycles per data point (this corresponds to the fact that the
    smallest detectable cycle in the data is 2 data points per cycle).
 
Note:
    The spectral plot is essentially a "smoothed" periodogram.  The
    smoothing is done in the frequency domain.  There are several
    alternative methods for computing the spectrum estimates.  DATAPLOT
    uses the algorithm from the Jenkins and Watts reference (pp. 382-
    383).
 
Note:
    Spectral plots are often drawn with log scales to provide better
    resolution (enter LOG ON).  Some analysts prefer to draw the plot
    as a solid connected lines while others prefer to draw it with
    spikes.  Either way is straightforward to generate with the proper
    settings for the LINES and SPIKES commands.
 
Default:
    None
 
Synonyms:
    SPECTRUM is a synonym for SPECTRAL.
    The word PLOT is optional in the various SPECTRAL PLOT commands
    (e.g., SPECTRUM Y, CROSS-SPECTRUM Y1 Y2).
    AUTO SPECTRAL PLOT is a synonym for SPECTRAL PLOT.
 
Related Commands:
    PERIODOGRAM         = Generates a periodogram plot.
    CORRELATION PLOT    = Generates a correlation plot.
    COMPLEX DEMOD  PLOT = Generates a complex demodulation plot.
    LAG PLOT            = Generates a lag plot.
    PLOT                = Generates a data or function plot.
    4-PLOT              = Generates 4-plot univariate analysis.
    CHARACTERS          = Sets the types for plot characters.
    LINES               = Sets the types for plot lines.
    LOG                 = Sets the log switches on/off.
    SPIKES              = Sets the on/off switches for plot spikes.
    SUMMARY             = Generates a table of summary statistics.
    LET                 = Generates  sin/cos transformations (plus
                          much more).
    FIT                 = Carries out a least squares fit.
 
Reference:
    "Spectral Analysis and Its Applications", Jenkins and Watts.
    Holden-Day, 1968 (pp. 16-23).
 
    "Fourier Analysis of Time Series", Peter Bloomfield, Wiley, 1976.
 
Applications:
    Frequency Time Series Analysis
 
Implementation Date:
    XX
 
Program 1:
    SKIP 25
    READ LEW.DAT Y
    .
    MULTIPLOT 2 1; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE SPECTRAL PLOT; Y1LABEL POWER; X1LABEL FREQUENCY
    SPIKE ON; LINE BLANK
    SPECTRAL PLOT Y
    LOG ON
    SPIKE OFF; LINE SOLID
    SPECTRAL PLOT Y
    END OF MULTIPLOT
 
Program 1:
    SKIP 25
    READ HAYES1.DAT JUNK Y1 Y2
    .
    MULTIPLOT 3 3; MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE AUTOMATIC; Y1LABEL POWER; X1LABEL FREQUENCY
    LINE SOLID DOTTED
    CROSS-SPECTRAL PLOT Y1 Y2
    COSPECTRAL PLOT Y1 Y2
    QUADRATURE SPECTRAL PLOT Y1 Y2
    COHERENCY SPECTRAL PLOT Y1 Y2
    AMPLITUDE SPECTRAL PLOT Y1 Y2
    PHASE SPECTRAL PLOT Y1 Y2
    GAIN SPECTRAL PLOT Y1 Y2
    ARGAND SPECTRAL PLOT Y1 Y2
    END OF MULTIPLOT
 
-----SPENCE (LET)--------------------------------
 
SPENCE
 
Name:
    SPENCE (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Spence integral.
 
Description:
    The Spence integral is defined as:
        F(x) = INTEGRAL(-LOG(1-Y)/Y) DY
    where INTEGRAL is the integral from 0 to x.

    This is a form of Spence's integral due to K. Mitchell.  It
    differs from the definition in the NBS Handbook of Mathematical
    Functions (see the REFERENCE section below).

Syntax:
    LET <y> = SPENCE(<x>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a number, variable, or parameter;
          <y> is a variable or a parameter (depending on what <x> is
               where the computed SPENCE integral values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SPENCE(0.1)
    LET A = SPENCE(10)
    LET X2 = SPENCE(X)
 
Note:
    DATAPLOT uses the routine DSPENC from the SLATEC Common
    Mathematical Library to compute this function.  SLATEC is a large
    set of high quality, portable, public domain Fortran routines for
    various mathematical capabilities maintained by seven federal
    laboratories.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOGINT     = Compute the logarithmic integral.
    EXPINT1    = Compute the exponential integral of order 1.
    EXPINTN    = Compute the exponential integral of order N.
    EXPINTE    = Compute the principla value of the exponential
                 integral.
    ERF        = Compute the error function.
    SININT     = Compute the sine integral.
    COSINT     = Compute the cosine integral.
 
Reference:
    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (page 1004).
 
    Article by K. Mitchell in the Philosophical Magazine, 40, p. 351,
    (1949).

Applications:
    Special Functions
 
Implementation Date:
    94/9
 
Program:
    TITLE AUTOMATIC
    PLOT SPENCE(X) FOR X = -10 0.1 10
 
-----SPIKE-------------------------------------------------------
 
SPIKE
 
Name:
    SPIKE
 
Type:
    Plot Control Command
 
Purpose:
    Specifies if a spike will be drawn at the plot points of each
    trace on subsequent plots.
 
Description:
    A spike is a vertical line from the plot point to the spike base
    (most typically the x axis).
 
    DATAPLOT can draw a trace as a character or plot symbol at each
    point, as a connected line, as a spike from the point to a base,
    as a bar from the plot point to a base, or as any combination of
    the above.  The choice is determined by the BAR, SPIKE, CHARACTER,
    and LINE commands.  The switches for these commands work
    independently of each other.
 
    Spikes are commonly used in time series plots.  They are also
    useful in showing deviation from a common value such as the mean
    or median.  They are also used to generate dot charts.  Dot charts
    are an alternative bar charts recommended by Bill Cleveland in the
    books listed in the REFERENCE section below.
 
Syntax:
    SPIKE  <ON/OFF>  <ON/OFF>  <ON/OFF>  etc.
    where ON specifies that the trace is to be drawn with spikes and
             OFF specifies that it is not.  Up to 100 spike types can
             be specified.
 
Examples:
    SPIKE ON OFF ON OFF
    SPIKE ON ALL
    SPIKE ALL ON
    SPIKE
 
Note:
    Dot charts are typically drawn vertically rather than horizontally.
    This can done with either the SPIKE DIRECTION or the HORIZONTAL
    SWITCH command.
 
Note:
    It is common with dot charts to want alphabetic labels.  The TIC
    MARK LABEL FORMAT, TIC MARK LABEL CONTENT, and TIC OFFSET commands
    can be used for this purpose.
 
Note:
    The SPIKE command with no arguments sets the spike type to blank
    for all traces.  The SPIKE command with the word ALL before or
    after the specified type assigns that spike type to all traces;
    thus SPIKE ON ALL or SPIKE ALL ON plots spikes for all traces.
 
Default:
    No spikes are drawn (i.e., all OFF).
 
Synonyms:
    None
 
Related Commands:
    PLOT              = Generates a data or function plot.
    SPIKE BASE        = Sets the base locations for plot spikes.
    SPIKE COLOR       = Sets the colors for plot spikes.
    SPIKE DIRECTION   = Sets the directions for plot spikes.
    SPIKE LINE        = Sets the line types for plot spikes.
    SPIKE THICKNESS   = Sets the line thicknesses for plot spikes.
 
Reference:
    "Elements of Graphing Data" by William S. Cleveland, Wadsworth
    Advanced Books and Software, 1985.
 
    "Visualizing Data", William S. Cleveland, Hobart Press, 1993.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    XX
 
Program 1:
    SKIP 25
    READ BOXJE142.DAT YIELD
    .
    TITLE TIME SERIES PLOT
    Y1LABEL YIELD
    X1LABEL SEQUENCE NUMBER
    XLIMITS 0 70
    XTIC OFFSET 2 2
    LET N = SIZE YIELD
    LET X = DATA 1 N
    LET A = MEAN YIELD
    LET Y = DATA A A
    CHARACTER OFF
    SPIKE ON
    SPIKE BASE A
    LINE BLANK
    PLOT YIELD AND
    PLOT Y X
 
Program 2:
    READ STRING S1 S2 S3 S4 S5 S6 S7
    ALABAMA ALASKA ARIZONA ARKANSAS CALIFORNIA SP()COLORADO CONNETICUIT
    READ STRING S8 S9 S10 S11 S12 S13 S14
    DELAWARE WASHINGTONSP()DC FLORIDA GEORGIA HAWAII IDAHO ILLINOIS
    READ STRING S15 S16 S17 S18 S19 S20 S21 S22
    INDIANA IOWA KANSAS KENTUCKY LOUSIANA MAINE MARYLAND MASSACHUSETS
    READ STRING S23 S24 S25 S26 S27 S28 S29
    MICHIGAN MINNESOTA MISSISSIPPI MISSOURI MONTANA NEBRASKA NEVADA
    READ STRING S30 S31 S32 S33
    NEWSP()HAMPSHIRE NEWSP()JERSEY NEWSP()MEXICO NEWSP()YORK
    READ STRING S34 S35 S36 S37 S38
    NORTHSP()CAROLINA NORTHSP()DAKOTA OHIO OKLAHOMA OREGON
    READ STRING S39 S40 S41 S42
    PENNSYLVANIA RHODESP()ISLAND SOUTHSP()CAROLINA SOUTHSP()DAKOTA
    READ STRING S43 S44 S45 S46 S47 S48 S49 S50 S51
    TENNESSEE TEXAS UTAH VERMONT VIRGINIA WASHINGTON WESTSP()VIRGINIA
    READ STRING S50 S51
    WISCONSIN WYOMING
    .
    SKIP 25
    COLUMN LIMITS 5 30
    READ MURDER86.DAT RATE
    .
    TITLE DOT CHART WITH ONE VARIABLE
    Y1TIC MARK LABEL OFF; YTIC SIZE 0.5
    YLIMITS 1 51; YTIC OFFSET 1 1
    MAJOR YTIC MARK NUMBER 51; MINOR YTIC MARK NUMBER 0
    X1LABEL MURDER RATE (PER 100,000); XLIMITS 0 30; XTIC OFFSET 0 2
    HORIZONTAL SWITCH ON
    CHARACTER CIRCLE; CHARACTER FILL ON; CHARACTER HW 0.8 0.7
    LINE BLANK
    SPIKE ON
    SPIKE LINE DOT
    LET INDX = SEQUENCE 1 1 51
    LET RATE2 = SORTC RATE INDX
    PLOT RATE2
    HEIGHT 0.7; JUSTIFICATION RIGHT
    LET INC = (90-20)/52; LET YPOS = 19.7; LET XPOS = 14
    LOOP FOR K = 1 1 51
        LET YPOS = YPOS + INC
        LET J = INDX(K)
        MOVE XPOS YPOS; TEXT ^S^J
    END OF LOOP
 
-----SPIKE BASE-------------------------------------------------------
 
SPIKE BASE
 
Name:
    SPIKE BASE
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the base location for spikes on plots.
 
Description:
    A spike is a vertical line from the base number to the plot point.
    Spike bases are specified by trace.
 
Syntax:
    SPIKE BASES  <number>  <number>  <number>  etc.
    where <number> is a number or parameter that specifies the desired
               spike base.  Up to 100 spike bases can be specified.
 
Examples:
    SPIKE BASES 0. 0. 10.
    SPIKE BASES 20. 20. 20.
    SPIKE BASES 0. ALL
    SPIKE BASES ALL 0.
    SPIKE BASES
 
Note:
    The SPIKE BASE command with no arguments sets the spike base to 0.0
    for all traces.  The SPIKE BASE command with the word ALL before or
    after the specified base assigns that spike base to all traces;
    thus SPIKE BASE 0.0 ALL or SPIKE BASE ALL 0.0 uses a base of 0.0
    for all traces.
 
Note:
    The BAR BASE, SPIKE, CHARACTER, and LINE switch all work
    independently of each other.  That is, a plot point can be a line,
    a character, a spike or a bar or any combination of the above.
 
Default:
    All spike bases are 0.0.
 
Synonyms:
    None
 
Related Commands:
    PLOT              = Generates a data or function plot.
    SPIKE             = Sets the on/off switches for plot spikes.
    SPIKE COLOR       = Sets the colors for plot spikes.
    SPIKE DIRECTION   = Sets the directions for plot spikes.
    SPIKE LINE        = Sets the line types for plot spikes.
    SPIKE THICKNESS   = Sets the line thicknesses for plot spikes.
 
References:
    "Elements of Graphing Data" by William S. Cleveland, Wadsworth
    Advanced Books and Software, 1985.
 
    "Visualizing Data", William S. Cleveland, Hobart Press, 1993.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    XX
 
Program:
    SKIP 25
    READ ELNINO.DAT Y YEAR MONTH
    .
    SPIKE ON
    LINE BLANK
    LET A = MEAN Y
    SPIKE BASE A
    X1LABEL MEAN PLOT
    Y1LABEL SOUTHERN OSCILLATION INDEX
    XLIMITS 1 12
    XTIC OFFSET 1 1
    MAJOR XTIC MARK NUMBER 12
    MINOR XTIC MARK NUMBER 0
    X1TIC MARK LABEL FORMAT ALPHA
    X1TIC MARK LABEL CONTENTS JAN FEB MARCH APRIL MAY JUNE JULY AUG ...
         SEP OCT NOV DEC
    MEAN PLOT Y MONTH
 
-----SPIKE COLOR-------------------------------------------------------
 
SPIKE COLOR
 
Name:
    SPIKE COLOR
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the colors used to draw spikes on subsequent plots.
 
Description:
    A spike is a vertical line from the plot point to the spike base
    (most typically the x axis).
 
    Dataplot defines the points on a plot by "traces".  A trace is a set
    of points that are drawn with the same attributes.  For example,

        PLOT Y1 X1 AND
        PLOT Y2 X2

    has two traces.  The first is the points defined by Y1 and X1 and the
    second is the points defined by Y2 and X2.  Attributes can be set for
    up to 100 traces.

    Dataplot provides two methods for specifying colors.

        1. Colors can be defined by name (or by the corresponding index).
           Dataplot adopted it's named colors from the X11 project.
           Currently, 162 named colors and 100 levels of grayscale are
           supported.  Grayscale can be specified with either G0, G1, ...,
           G100 (or -1, -2, ..., -100).  Many older devices support only a
           limited number of colors.  For these devices, unsupported colors
           will be mapped to one of the available colors.  To specify a
           named color, see Syntax 1.

        2. Most modern graphics devices support full RGB (RedBlueGreen)
           color.  You can alternatively specify RGB colors by entering
           three integer values to represent the Red, Green and Blue
           components, respectively.  These values should be in the range
           0 to 255.

    When setting the spike color, Dataplot first checks if the device
    supports RGB colors. If not, the named color will be used.  If the
    device does support RGB color, Dataplot will check if an RGB color
    has been specified.  If yes, then that RGB color is used.  If not,
    the named color will be used.

    To see the list of supported named colors (with the associated index
    number), see

    https://www.itl.nist.gov/div898/software/dataplot/refman1/ch11/homepage.htm

Syntax 1:
    SPIKE COLOR  <color>  <color>  <color>  etc.
    where <color> is a character string that specifies the desired
                color.

    Up to 100 spike colors can be specified.
 
Syntax 2:
    SPIKE RGB COLORS <red-1> <green-1> <blue-1> ...
                     <red-n> <green-n> <red-n>
    where <red-1>, <green-1>, <blue-1>, ..., <red-n>, <green-n>, <blue-n>
    is a list of integer values that specify the desired RGB spike colors.

    Up to 100 such triplets of color values can be specified.

    To turn off the RGB color, set the values to -1 (any negative value
    will work).  Values greater than 255 will be set to 255.
 
Examples:
    SPIKE COLOR RED BLUE GREEN
    SPIKE COLORS BLACK ALL
    SPIKE COLORS ALL RED
    SPIKE COLORS
    SPIKE RGB COLORS 220 109 88 240 220 160
    SPIKE RGB COLORS 220 109 88 ALL
 
Note:
    The SPIKE COLOR command with no arguments sets the spike color to
    default for all traces.  The SPIKE COLOR command with the word ALL
    before or after the specified type assigns that color to all
    traces; thus SPIKE COLOR RED ALL or SPIKE LINE ALL RED plots spikes
    with red lines for all traces.
 
Default:
    All spikes are drawn with black lines and RGB colors are off.
 
Synonyms:
    SPIKE PATTERN
 
Related Commands:
    PLOT              = Generates a data or function plot.
    SPIKE             = Sets the on/off switches for plot spikes.
    SPIKE BASE        = Sets the base locations for plot spikes.
    SPIKE DIRECTION   = Sets the directions for plot spikes.
    SPIKE LINE        = Sets the line types for plot spikes.
    SPIKE THICKNESS   = Sets the line thicknesses for plot spikes.
    LINE COLOR        = Sets the color for plot lines.
    CHARACTER COLOR   = Sets the color for plot characters.
    BAR COLOR         = Sets the color for plot bars.
 
References:
    William S. Cleveland (1985), "Elements of Graphing Data,"
    Wadsworth Advanced Books and Software.
 
    William S. Cleveland (1993), "Visualizing Data," Hobart Press.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    Pre-1987
    2020/11: Support for RGB colors
 
Program:
    LET CARTER = DATA 66 30 11 43 44 41 35 82 54 36
    LET REAGAN = DATA 26 54 84 47 51 51 52 14 36 55
    LET X = DATA 1 2 3 5 6 7 8 10 11 12
    .
    LET CART2 = -CARTER
    LET XJUNK = DATA 0.5 12.5; LET YJUNK = DATA 0 0
    .
    TIC MARK LABEL FORMAT ALPHA
    YLIMITS 1 12
    YTIC OFFSET 1 1
    Y1TIC LABEL CONTENT DEMOCRATS INDEPENDENTS REPUBLICANS SP() ...
          EAST SOUTH MIDWEST WEST SP() BLACKS HISPANICS WHITES SP()
    MINOR Y1TIC MARK NUMBER 0
    X1LABEL PERCENT
    XLIMITS -100 100
    MAJOR XTIC MARK NUMBER 11
    MINOR XTIC MARK NUMBER 1
    XTIC MARK LABEL CONTENT 100 80 60 40 20 0 20 40 60 80 100
    .
    LINE BLANK BLANK SOLID
    SPIKE ON ON OFF
    SPIKE THICKNESS 0.5 ALL
    SPIKE DIRECTION H ALL
    .
    SPIKE COLOR G25 G75
    TITLE DEMONSTRATE GRAYSCALE SPIKE COLOR COMMAND
    PLOT X VS REAGAN AND
    PLOT X VS CART2 AND
    PLOT XJUNK YJUNK
    .
    SPIKE COLOR RED BLUE
    TITLE DEMONSTRATE SPIKE COLOR COMMAND
    PLOT X VS REAGAN AND
    PLOT X VS CART2 AND
    PLOT XJUNK YJUNK
    .
    SPIKE RGB COLORS 220 109 88 240 220 160
    TITLE DEMONSTRATE SPIKE RGB COLOR COMMAND
    PLOT X VS REAGAN AND
    PLOT X VS CART2 AND
    PLOT XJUNK YJUNK
 
-----SPIKE DIRECTION-------------------------------------------------
 
SPIKE DIRECTION
 
Name:
    SPIKE DIRECTION
 
Type:
    Plot Control Command
 
Purpose:
    Specifies if a spike will be drawn horizontally or vertically
    on subsequent plots.
 
    TIC MARK LABEL FORMAT ALPHA
    YLIMITS 1 12
    YTIC OFFSET 1 1
    Y1TIC LABEL CONTENT DEMOCRATS INDEPENDENTS REPUBLICANS SP() ...
       EAST SOUTH MIDWEST WEST SP() BLACKS HISPANICS WHITES SP()
    MINOR Y1TIC MARK NUMBER 0
    X1LABEL PERCENT
    XLIMITS -100 100
    MAJOR XTIC MARK NUMBER 11
    MINOR XTIC MARK NUMBER 1
    XTIC MARK LABEL CONTENT 100 80 60 40 20 0 20 40 60 80 100
    .
    LINE BLANK BLANK SOLID
    SPIKE ON ON OFF
    SPIKE THICKNESS 0.5 ALL
    SPIKE DIRECTION H ALL
    LEGEND 1 CARTER; LEGEND 1 COORDINATES 17 85
    LEGEND 2 REAGAN; LEGEND 2 COORDINATES 83 85; LEGEND 2 JUST RIGHT
    .
Description:
    A spike is a vertical line from the plot point to the spike base.
    Vertical spikes are drawn from the x-axis to the plot point while
    horizontal spikes are drawn from the y-axis to the plot point.
 
Syntax:
    SPIKE DIRECTIONS  <H/V>  <H/V>  <H/V>  etc.
    where H specifies the spike is drawn horizontally while V specifies
               that the spike is drawn vertically.  Up to 100 spike
               directions can be specified.
 
Examples:
    SPIKE DIRECTIONS H H
    SPIKE DIRECTIONS V V
    SPIKE DIRECTIONS V ALL
    SPIKE DIRECTIONS ALL V
    SPIKE DIRECTIONS
 
Note:
    The HORIZONTAL SWITCH command can also be used to generate
    horizontal bars.  This command is more general in that all plot
    elements are drawn horizontally (SPIKE DIRECTION only does the
    spikes).  It also exchanges the x and y data values before
    plotting (the BAR DIRECTION command does not do this).
 
Note:
    Horizontal spikes are typically combined with a portrait page
    orientation to generate publication quality bar dot graphs.
 
Note:
    The SPIKE DIRECTION command with no arguments sets the spike
    direction to vertical for all spikes.  The SPIKE DIRECTION command
    with the word ALL before or after the specified direction assigns
    that spike direction to all traces; thus SPIKE DIRECTION H ALL or
    SPIKE DIRECTION ALL H plots all spikes horizontally.
 
Note:
    The BAR, SPIKE, CHARACTER, and LINE switch all work independently
    of each other.  That is, a plot point can be a line, a character,
    a spike or a bar or any combination of the above.
 
Default:
    All spikes are drawn vertically.
 
Synonyms:
    None
 
Related Commands:
    PLOT              = Generates a data or function plot.
    HORIZONTAL SWITCH = Specifies whether a plot is drawn horizontally
                        or vertically.
    SPIKE             = Sets the on/off switches for plot spikes.
    SPIKE BASE        = Sets the base locations for plot spikes.
    SPIKE COLOR       = Sets the colors for plot spikes.
    SPIKE LINE        = Sets the line types for plot spikes.
    SPIKE THICKNESS   = Sets the line thicknesses for plot spikes.
 
References:
    "Elements of Graphing Data" by William S. Cleveland, Wadsworth
    Advanced Books and Software, 1985.
 
    "Visualizing Data", William S. Cleveland, Hobart Press, 1993.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    XX
 
Program:
    LET CARTER = DATA 66 30 11 43 44 41 35 82 54 36
    LET REAGAN = DATA 26 54 84 47 51 51 52 14 36 55
    LET X = DATA 1 2 3 5 6 7 8 10 11 12
    .
    TIC MARK LABEL FORMAT ALPHA; YLIMITS 1 12; YTIC OFFSET 1 1
    Y1TIC LABEL CONTENT DEMOCRATS INDEPENDENTS REPUBLICANS SP() ...
       EAST SOUTH MIDWEST WEST SP() BLACKS HISPANICS WHITES SP()
    MINOR Y1TIC MARK NUMBER 0
    X1LABEL PERCENT
    XLIMITS -100 100
    MAJOR XTIC MARK NUMBER 11; MINOR XTIC MARK NUMBER 1
    XTIC MARK LABEL CONTENT 100 80 60 40 20 0 20 40 60 80 100
    .
    LINE BLANK BLANK SOLID
    SPIKE ON ON OFF
    SPIKE DIRECTION H ALL
    CHARACTER CIRCLE CIRCLE; CHARACTER FILL ON ON
    CHARACTER HW 1 0.75 ALL
    TITLE DOT CHART WITH HORIZONTAL DIRECTION
    LEGEND 1 CARTER; LEGEND 1 COORDINATES 17 85
    LEGEND 2 REAGAN; LEGEND 2 COORDINATES 83 85; LEGEND 2 JUST RIGHT
    .
    LET CART2 = -CARTER
    LET XJUNK = DATA 0.5 12.5; LET YJUNK = DATA 0 0
    PLOT X VS REAGAN AND
    PLOT X VS CART2 AND
    PLOT XJUNK YJUNK
 
-----SPIKE LINE-------------------------------------------------------
 
SPIKE LINE
 
Name:
    SPIKE LINE
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the line patterns used to draw spikes on subsequent
    plots.
 
Description:
    A spike is a vertical line from the plot point to the spike base
    (most typically the x axis).  Spikes are specified by trace.  That
    is, all points belonging to the same trace are drawn with the same
    spike attributes.
 
Syntax:
    SPIKE LINE  <type>  <type>  <type>  etc.
    where <type> is a character string that specifies the desired line
                type.  Up to 100 spike line types can be specified.
 
Examples:
    SPIKE LINE SOLID DASH DOT
    SPIKE LINES SOLID ALL
    SPIKE LINES ALL SOLID
    SPIKE LINES
 
Note:
    The SPIKE LINE command with no arguments sets the spike type to
    solid for all traces.  The SPIKE LINE command with the word ALL
    before or after the specified type assigns that pattern line type
    to all traces; thus SPIKE LINE SOLID ALL or SPIKE LINE ALL SOLID
    plots spike patterns with solid lines for all traces.
 
Note:
    The BAR, SPIKE, CHARACTER, and LINE switch all work independently
    of each other.  That is, a plot point can be a line, a character,
    a spike or a bar or any combination of the above.
 
Default:
    All spikes are drawn with solid lines.
 
Synonyms:
    SPIKE PATTERN
 
Related Commands:
    PLOT              = Generates a data or function plot.
    SPIKE             = Sets the on/off switches for plot spikes.
    SPIKE BASE        = Sets the base locations for plot spikes.
    SPIKE COLOR       = Sets the colors for plot spikes.
    SPIKE DIRECTION   = Sets the directions for plot spikes.
    SPIKE THICKNESS   = Sets the line thicknesses for plot spikes.
 
References:
    "Elements of Graphing Data" by William S. Cleveland, Wadsworth
    Advanced Books and Software, 1985.
 
    "Visualizing Data", William S. Cleveland, Hobart Press, 1993.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    XX
 
Program:
    LET CARTER = DATA 66 30 11 43 44 41 35 82 54 36
    LET REAGAN = DATA 26 54 84 47 51 51 52 14 36 55
    LET X = DATA 1 2 3 5 6 7 8 10 11 12
    .
    TIC MARK LABEL FORMAT ALPHA; YLIMITS 1 12; YTIC OFFSET 1 1
    Y1TIC LABEL CONTENT DEMOCRATS INDEPENDENTS REPUBLICANS SP() ...
       EAST SOUTH MIDWEST WEST SP() BLACKS HISPANICS WHITES SP()
    MINOR Y1TIC MARK NUMBER 0
    X1LABEL PERCENT; XLIMITS -100 100
    MAJOR XTIC MARK NUMBER 11; MINOR XTIC MARK NUMBER 1
    XTIC MARK LABEL CONTENT 100 80 60 40 20 0 20 40 60 80 100
    .
    LINE BLANK BLANK SOLID
    CHARACTER CIRCLE CIRCLE; CHARACTER FILL ON ON
    CHARACTER HW 1 0.75 ALL
    SPIKE ON ON OFF; SPIKE DIRECTION H ALL
    SPIKE LINE DASH DASH
    TITLE DEMONSTRATE SPIKE LINE COMMAND
    LEGEND 1 CARTER; LEGEND 1 COORDINATES 17 85
    LEGEND 2 REAGAN; LEGEND 2 COORDINATES 83 85; LEGEND 2 JUST RIGHT
    .
    LET CART2 = -CARTER
    LET XJUNK = DATA 0.5 12.5; LET YJUNK = DATA 0 0
    PLOT X VS REAGAN AND
    PLOT X VS CART2 AND
    PLOT XJUNK YJUNK
 
-----SPIKE THICKNESS--------------------------------------------------
 
SPIKE THICKNESS
 
Name:
    SPIKE THICKNESS
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the thickness of lines used to draw spikes on subsequent
    plots.
Description:
    A spike is a vertical line from the plot point to the spike base
    (most typically the x axis).  Spikes are specified by trace.  That
    is, all points belonging to the same trace are drawn with the same
    spike attributes.
 
    Line thickness is specified as a percentage of the vertical
    height of the device.  Line widths are typically between 0.1 and
    0.3.
 
Syntax:
    SPIKE THICKNESSS  <thickness>  <thickness>  <thickness>  etc.
    where <thickness> is a number or parameter that specifies the
              desired line thickness.  Up to 100 spike thicknesses can
              be specified.
 
Examples:
    SPIKE THICKNESSS 0.1 0.2 0.1 0.2
    SPIKE THICKNESSS 0.2 0.2 0.1
    SPIKE THICKNESSS 0.1 ALL
    SPIKE THICKNESSS ALL 0.1
    SPIKE THICKNESSS
 
Note:
    The SPIKE THICKNESS command with no arguments sets the spike line
    thickness to default for all traces.  The SPIKE THICKNESS command
    with the word ALL before or after the specified thickness assigns
    that spike line thickness to all spikes; thus SPIKE THICKNESS 0.1
    ALL or SPIKE THICKNESS ALL 0.1 draws spikes with a line thickness
    of 0.1 for all traces on the plot.
 
Note:
    The SPIKE, BAR, CHARACTER, and LINE switch all work independently
    of each other.  That is, a plot point can be a line, a character,
    a spike, a bar, or any combination of the above.
 
Default:
    All spikes are drawn with a line width of 0.1.
 
Synonyms:
    None
 
Related Commands:
    PLOT              = Generates a data or function plot.
    SPIKE             = Sets the on/off switches for plot spikes.
    SPIKE BASE        = Sets the base locations for plot spikes.
    SPIKE COLOR       = Sets the colors for plot spikes.
    SPIKE DIRECTION   = Sets the directions for plot spikes.
    SPIKE LINE        = Sets the line types for plot spikes.
 
References:
    "Elements of Graphing Data" by William S. Cleveland, Wadsworth
    Advanced Books and Software, 1985.
 
    "Visualizing Data", William S. Cleveland, Hobart Press, 1993.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    XX
 
Program:
    LET CARTER = DATA 66 30 11 43 44 41 35 82 54 36
    LET REAGAN = DATA 26 54 84 47 51 51 52 14 36 55
    LET X = DATA 1 2 3 5 6 7 8 10 11 12
    .
    TIC MARK LABEL FORMAT ALPHA; YLIMITS 1 12; YTIC OFFSET 1 1
    Y1TIC LABEL CONTENT DEMOCRATS INDEPENDENTS REPUBLICANS SP() ...
       EAST SOUTH MIDWEST WEST SP() BLACKS HISPANICS WHITES SP()
    MINOR Y1TIC MARK NUMBER 0
    X1LABEL PERCENT
    XLIMITS -100 100
    MAJOR XTIC MARK NUMBER 11; MINOR XTIC MARK NUMBER 1
    XTIC MARK LABEL CONTENT 100 80 60 40 20 0 20 40 60 80 100
    .
    LINE BLANK BLANK SOLID
    SPIKE ON ON OFF; SPIKE DIRECTION H ALL
    SPIKE THICKNESS 0.5 ALL
    TITLE DEMONSTRATE SPIKE THICKNESS COMMAND
    LEGEND 1 CARTER; LEGEND 1 COORDINATES 17 85
    LEGEND 2 REAGAN; LEGEND 2 COORDINATES 83 85; LEGEND 2 JUST RIGHT
    .
    LET CART2 = -CARTER
    LET XJUNK = DATA 0.5 12.5; LET YJUNK = DATA 0 0
    PLOT X VS REAGAN AND
    PLOT X VS CART2 AND
    PLOT XJUNK YJUNK
 
-----SPHRHRMR (LET)--------------------------------
 
SPHRHRMR
 
Name:
    SPHRHRMR (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the spherical harmonic function of order N and degree M.
 
Description:
    The spherical harmonic function is related to the associated
    Legendre function as follows:
       Yn,m(theta,phi) = SQRT((2n+1)*(n-m)!/(4*PI*(n+m)!))*
                          Pn,m(cos(theta))*EXP(i*m*phi)
    where Pn,m is the associated Legendre polynomial.  See the
    documentation for the LEGENDRE command for a description of
    Legendre polynomials and associated Legendre polynomials.
 
    DATAPLOT use the NORMP set of routines from the Slatec library to
    compute the normalized associated Legendre polynomials.  These are
    then transformed in an appropriate manner to obtain the spherical
    harmonic value.  These routines use a technique called extended
    range arithmetic to avoid underflow and overflow problems.
    However, DATAPLOT stores the result as a single precision real
    number.  If it is unable to do so, it prints an error message.

Syntax 1:
    LET <y> = SPHRHRMR(<theta>,<phi>,<n>,<m>) 
                                   <SUBSET/EXCEPT/FOR qualification>
    where <theta> is a number, parameter, or variable in the range
              (-PI,PI);
          <phi> is a number, parameter, or variable in the range
              (-PI,PI);
          <n> is a non-negative integer number, parameter, or variable
              that specifies the order of the Legendre polynomial;
          <m> is a non-negative integer number, parameter, or variable
              that specifies the degree of the Legendre polynomial;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed spherical harmonic value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the real component of the spherical harmonic
    function.

Syntax 2:
    LET <y> = SPHRHRMC(<theta>,<phi>,<n>,<m>) 
                                   <SUBSET/EXCEPT/FOR qualification>
    where <theta> is a number, parameter, or variable in the range
              (-PI,PI);
          <phi> is a number, parameter, or variable in the range
              (-PI,PI);
          <n> is a non-negative integer number, parameter, or variable
              that specifies the order of the Legendre polynomial;
          <m> is a non-negative integer number, parameter, or variable
              that specifies the degree of the Legendre polynomial;
          <y> is a variable or a parameter (depending on what <x> is)
              where the computed spherical harmonic value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the complex component of the spherical
    harmonic function.

Examples:
    DEGREES; LET AR = SPHRHRMR(45,60,5,2); LET AC = SPHRMRC(45,60,5,2)
    DEGREES; LET AR = SPHRHRMR(T,P,5,2); LET AC = SPHRMRC(T,P,5,2)
    DEGREES; LET AR = SPHRHRMR(T,P,N,M); LET AC = SPHRMRC(T,P,N,M)
 
Note:
    Spherical harmonics are often specified with an angular input
    value.  If your input value is in terms of the (-1,1) interval,
    use the command
        LET TNEW = ARCCOS(T)
        LET PNEW = ARCCOS(P)
    and then use TNEW and PNEW as the input arguments to the spherical
    harmonic functions.

    By default, the angle is specified in radians.  Enter the command
    DEGREES to specify degree units.

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LEGENDRE = Compute the Legendre polynomial of order N.
    CHEBT    = Compute the Chebychev polynomial first kind, order N.
    CHEBU    = Compute the Chebychev polynomial second kind, order N.
    HERMITE  = Compute the Hermite polynomial of order N.
    JACOBIPE = Compute the Jacobi polynomial of order N.
    ULTRASPH = Compute the ultrasperical polynomial of order N.
    LAGUERRE = Compute the Laguerre polynomial of order N.
 
Reference:
    "Extended-Range Arithmetic and Normalized Legendre Polynomials",
    Smith, Olver, and Lozier, ACM Transactions On Mathematical
    Software, Vol. 7, No. 1, March, 1981 (pp. 93-105).

    "Associated Legendre Functions on the Cut", Smith, and Olver, 
    Journal of Computational Physics, Vol. 51, No. 3, September, 1983,
    (pp. 502-518).

    "Handbook of Mathematical Functions, Applied Mathematics Series,
    Vol. 55", Abramowitz and Stegun, National Bureau of Standards,
    1964 (chapter 22).

Applications:
    Mathematics
 
Implementation Date:
    95/7
 
Program:
    TITLE CASE ASIS; LABEL CASE ASIS; LINE SOLID DASH
    DEGREES
    Y1LABEL Y(theta,phi,n,m)
    X1LABEL THETA   (phi = 60, n = 5)
    X2LABEL SOLID = Real Component
    X3LABEL DASH = Complex Component
    TITLE Spherical Harmonics (m = 2)
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    PLOT SPHRHRMR(X,60,5,2) FOR X = 1 1 89 AND
    PLOT SPHRHRMC(X,60,5,2) FOR X = 1 1 89
    TITLE Spherical Harmonics (m = 3)
    PLOT SPHRHRMR(X,60,5,3) FOR X = 1 1 89 AND
    PLOT SPHRHRMC(X,60,5,3) FOR X = 1 1 89
    TITLE Spherical Harmonics (m = 4)
    PLOT SPHRHRMR(X,60,5,4) FOR X = 1 1 89 AND
    PLOT SPHRHRMC(X,60,5,4) FOR X = 1 1 89
    TITLE Spherical Harmonics (m = 5)
    PLOT SPHRHRMR(X,60,5,5) FOR X = 1 1 89 AND
    PLOT SPHRHRMC(X,60,5,5) FOR X = 1 1 89
    END OF MULTIPLOT
 
-----SPLINE FIT-------------------------------------------------------
 
SPLINE FIT
 
Name:
    ... SPLINE FIT
 
Type:
    Analysis Command
 
Purpose:
    Carries out a B-spline fit.
 
Description:
    A spline fit is a data analysis technique for estimating (via the
    least squares criterion) the parameters in a spline polynomial
    model.  It is commonly used to fit curves that have different
    shapes in different areas of the horizontal axis variable.  Knot
    points are defined to delineate these different regions.  Separate
    spline polynomials are fit in these different areas.  The
    distinction of spline fits is that the fitted curve will be smooth
    at the knot points.
 
Syntax 1:
    <degree> SPLINE FIT <y> <x> <x2>  <SUBSET/EXCEPT/FOR qualification>
    where <degree> is the degree of the spline fit:
                 LINEAR      (or 1ST or FIRST)
                 QUADRATIC   (or 2ND or SECOND)
                 CUBIC       (or 3RD or THIRD ) (the default)
                 QUARTIC     (or 4TH or FOURTH)
                 QUINTIC     (or 5TH or FIFTH)
                 SEXTIC      (or 6TH or SIXTH)
                 SEPTIC      (or 7TH or SEVENTH)
                 OCTIC       (or 8TH or EIGHTH)
                 NONIC       (or 9TH or NINTH)
                 DEXIC       (or 10TH or TENTH);
          <y> is the response (vertical axis) variable;
          <x> is the independent (horizontal axis) variable;
          <x2> is the knots variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    <degree> SPLINE FIT <y> <x>   <SUBSET/EXCEPT/FOR qualification>
    where <degree> is the degree of the spline fit (same choices as for
              syntax 1);
          <y> is the response (vertical axis) variable;
          <x> is the independent (horizontal axis) variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    With this syntax, the knots variable is specified with the KNOTS
    command before doing the SPLINE FIT command.
 
Examples:
    SPLINE FIT Y X X2
    CUBIC SPLINE FIT Y X K
 
Note:
    The knots variable contains the values along the X axis which
    define the end points of sub-domains (a separate spline is fit in
    each sub-domain).  The individual points are "splined" together at
    these knot points.
 
Note:
    The values for the spline fit are placed in the internal variable
    PRED. The residuals (the difference between the fitted values and
    the raw data) are placed in the internal variable RES.
 
Note:
    A maximum of 50 knot points can be defined.
 
Note:
    Cubic splines are the most commonly used.  Degrees above 3 are
    rarely used.
 
Default:
    Cubic splines (i.e., degree 3).
 
Synonyms:
    None
 
Related Commands:
    KNOTS         = Specify the knots variable for a spline fit.
    FIT           = Compute a least squares fit.
    LOWESS        = Compute a locally weighted least squares.
    SMOOTH        = Perform a smoothing of a variable.
 
Reference:
    "...", Wold, Technometrics, 1974, page 2.
 
    "Numerical Recipes", Press, Flannery, Teukolsky, Vetterling,
    Cambridge Press, 1989 (chapter 3).
 
Applications:
    Fitting
 
Implementation Date:
    Pre-1987
 
Program:
    LET X = DATA 1 2 3 4 5 6 7 8 9 10
    LET Y = DATA 1 2 3 4 5 5.1 5.2 5.3 5.4 5.5
    .
    LET KNOT(1) = 5
    CAPTURE SPLINE_OUT.DAT
    LINEAR SPLINE FIT Y X KNOT
    END OF CAPTURE
    CHARACTER CIRCLE BLANK
    LINE BLANK SOLID
    CHARACTER FILL ON
    CHARACTER SIZE 1.2
    TITLE LINEAR SPLINE FIT
    PLOT Y PRED VS X
 
-----SPREAD LOCATION PLOT--------------------------------------
 
SPREAD LOCATION PLOT
 
Name:
    SPREAD LOCATION PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a spread location plot.
 
Description:
    The spread-location (s-l) plot is a robust alternative to
    the homoscedasticity plot.

    Given a response variable Y and a group-id variable X, 
    the homoscedasticity plot is the group standard deviations
    versus the group means.  This is a graphical measure of
    how the spread (variability) changes as the location changes
    across groups.  This is basically a graphical test for 
    the assumption of homogeneous variances across samples.

    The s-l plot has the square roots of the absolute value of
    the Y(i) minus their group medians on the vertical axis and
    the group medians on the horizontal axis.  A reference line
    connects the group medians.  This provides a more robust
    measure of how the spread changes as the location changes.

    The basic idea can be applied to other measure of location
    and spread.  That is, some measure of spread (or variability)
    is plotted on the vertical axis and some measure of location
    is plotted on the horizontal axis.  Although Dataplot only
    supports the HOMOSCEDASTICITY PLOT and the SPREAD LOCATION
    PLOT directly, it should be straight forward to implement
    other alternatives as macros.

    When setting the LINE and CHARACTER commands, the reference
    line is the first trace and the data starts with trace 2
    (each group is identified as a unique trace).  That is, to
    draw the data points as circles and the reference line as a
    solid line, do something like the following

        CHARACTER CIRCLE ALL
        CHARACTER BLANK
        LINE BLANK ALL
        LINE SOLID
        SPREAD LOCATION PLOT Y X
 
Syntax:
    SPREAD LOCATION PLOT <y> <tag>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is a  response variable;
          <tag> is a group identifier variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    SPREAD LOCATION PLOT Y1 TAG
    SPREAD LOCATION PLOT Y1 TAG  SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
References:
    "Visualizing Data", Cleveland, William S., Hobart Press, 1993.

Related Commands:
    LINES                  = Sets the type for plot lines.
    CHARACTER              = Sets the type for plot characters.
    HOMOSCEDATICITY PLOT   = Generates a homoscedasticity plot.
    BOX PLOT               = Generates a box plot.
    PLOT                   = Generates a data or function plot.
    LEVENES TEST           = Perform Levenes test for homogeneity
                             of variances.
 
    BARTLET TEST           = Perform Bartlet;s test for homogeneity
                             of variances.
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    2000/1
 
Program:
    SKIP 25
    READ SPLETT2.DAT Y MACHINE
    TIC OFFSET UNITS DATA
    XTIC OFFSET 0.5 0.5
    YTIC OFFSET 0.2 0.2
    YTIC MARK DECIMAL 1
    CHARACTER BLANK 1 2 3 4
    LINE SOLID BLANK BLANK BLANK BLANK
    TITLE AUTOMATIC
    Y1LABEL SPREAD
    X1LABEL LOCATION
    SPREAD LOCATION PLOT Y MACHINE 

-----SQRT (LET)------------------------------------------------
 
SQRT
 
Name:
    SQRT (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the square root of a non-negative number.
 
Syntax:
    LET <y2> = SQRT(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter containing non-negative
               decimal number(s);
          <y2> is a variable or a parameter (depending on what <y1> is)
               where the computed square roots are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SQRT(14.2835,1)
    LET A = SQRT(A1,2)
    LET X2 = SQRT(X1,1)
    LET X2 = SQRT(X1-4,2)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    ABS    = Compute the absolute value of a number.
    EXP    = Compute the exponential of a number.
    MOD    = Compute the modulo function.
    MIN    = Compute the minimum of two numbers.
    MAX    = Compute the maximum of two numbers.
    DIM    = Compute the positive difference of two numbers.
    IND    = Compute the mathematical indicator function.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    TITLE PLOT SQUARE ROOT FUNCTION
    PLOT SQRT(X) FOR X = 0 .1 9.9
 
-----SQUARED RANKS TEST-----------------------------------------
 
SQUARED RANKS
 
Name:
    SQUARED RANKS
 
Type:
    Analysis Command
 
Purpose:
    Perform a squared ranks test that k samples have equal variances.
 
Description:
    The F test is the standard parameteric test for testing the
    equality of variances for the two sample case.  The squared
    ranks test is a nonparametric test for either the two sample
    case or the case of k groups.

    The assumptions for using this test are

        1. The k samples are random samples from their respective
           populations.

        2. The k samples are mutually independent.

        3. The measurement is scale is at least interval (i.e.,
           the data can be ranked).
           
    More formally,

        H0: The samples are identically distributed except for
            possibly different means
        HA: At least two of the variances are not equal
        Test Statistic: 

                T = (1/D**2)*{SUM[i=1 to k][S(i)**2/n(i)] - N*SBAR**2}
       
            where
       
                S(i) = sum of squared ranks in subsample i
                n(i) = number of observations in subsample i
                D**2 = (1/(N-1))*{SUM[i=1 to N][R(i)**4] - N*SBAR**2}
                SBAR = (1/N)*SUM[j=1 to k][S(k)]
                     = (1/N)*SUM[i=1 to N][S(k)]
                R(i) = rank of observation i
       
            For the 2-sample case, the test statistic is
       
               T1 = {T - N1*SBAR**2}/
                    SQRT{(N1*N2)/(N*(N-1))}*SUM[i=1 to N][R(i)**4] -
                    (N1*N2/(N-1))*(SBAR)**2}

        Significance Level: alpha
        Critical Region: For the k sample case

                             T1 > CHIPPF(ALPHA,K-1)
 
                         where CHIPPF is the chi-square percent point
                         function.

                         For the 2 sample case,

                             T1 > NORPPF(1 - ALPHA/2)
                             T1 < NORPPF(ALPHA/2)
 
                         where CHIPPF is the chi-square percent point
                         function.

        Conclusion: Reject the null hypothesis if the test
                    statistic is in the critical region.

Syntax 1:
    <LOWER TAILED/UPPER TAILED> SQUARED RANKS  <y>  <x>
                                <SUBSET/EXCEPT/FOR qualification>
    where <LOWER TAILED/UPPER TAILED> is an optional keyword for the
              two sample case;
          <y> is the response (= dependent) variable;
          <x> is the factor (= independent) variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    The LOWER TAILED and UPPER TAILED options are only available
    for the two sample case.  Only one can be specified and if
    neither is entered a two-tailed test will be performed.

Syntax 2:
    MULTIPLE SQUARED RANKS  <y1> ... <yk>
                             <SUBSET/EXCEPT/FOR qualification>
    where <LOWER TAILED/UPPER TAILED> is an optional keyword for the
              two sample case;
          <y1> ... <yk> is a list of 1 to 30 response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for the case when the data for each group is
    stored in a separate variable.  This syntax accepts matrix arguments.

    The LOWER TAILED and UPPER TAILED options are only available
    for the two sample case.  Only one can be specified and if
    neither is entered a two-tailed test will be performed.

Examples:
    SQUARED RANKS TEST Y X
    SQUARED RANKS TEST Y X  SUBSET X = 1 TO 4
    MULTIPLE SQUARED RANKS TEST Y1 Y2 Y3 Y4
    MULTIPLE SQUARED RANKS TEST Y1 TO Y4
    LOWER TAILED SQUARED RANKS TEST Y1 Y2
    UPPER TAILED SQUARED RANKS TEST Y1 Y2
 
Note:
    For the k sample case and if the hypothesis of identical distributions
    is rejected, you can perform a multiple comparisons procedure to
    determine which pairs of populations tend to differ.

    The populations i and j seem to have different variances if the
    following inequality is satisfied:

       |S(i)/N(i) - S(j)/n(j)| > TPPF(1-(alpha/2))*
                                 SQRT(D**2**(N-1-T1)/(N-k))*
                                 SQRT((1/N(i)) + (1/N(j)))

    with TPPF and T1 denoting the t percent point function with N - k
    degrees of freedom and the Kruskal-Wallis test statistic,
    respectively.

Note:
    The following statistics are also supported:

        LET A = SQUARED RANKS TEST                     Y
        LET A = SQUARED RANKS TEST CDF                 Y
        LET A = SQUARED RANKS TEST PVALUE              Y
        LET A = SQUARED RANKS TEST LOWER TAILED PVALUE Y
        LET A = SQUARED RANKS TEST UPPER TAILED PVALUE Y

    Enter HELP STATISTICS to see what commands can use these
    statistics.

Default:
    None
 
Synonyms:
    SQUARED RANKS is a synonym for SQUARED RANKS TEST

Related Commands:
    KLOTZ TEST            = Perform two sample test for equal variances.
    KRUSKAL WALLIS TEST   = Perform Kruskal Wallis test for equal
                            locations.
    ANOVA                 = Perform an analysis of variance.
    MEDIAN TEST           = Perform a median test for equal variances.
    BLOCK PLOT            = Generate a block plot.
    DEX ... PLOT          = Generates a dex plot for a statistic.
    T TEST                = Performs a t test.
 
Reference:
    W. J. Conover, (1999).  "Practical Nonparameteric Statistics",
    Third Edition, Wiley, pp. 300-310.

Applications:
    Nonparametric Analysis
 
Implementation Date:
    2011/6
 
Program:
    . Step 1: Read Data (example 1 from pp. 304-305 of Conover)
    .
    let y1 = data 10.8 11.1 10.4 10.1 11.3
    let y2 = data 10.8 10.5 11.0 10.9 10.8 10.7 10.8
    .
    . Step 2: Data with more than 2 groups
    .
    let z1 = data 0.7  1  2  1.4  0.5  0.8  1  1.1  1.9  1.2  1.5
    let z2 = data 1.7  2.1  -0.4  0  1  1.1  0.9  2.3  1.3  0.4  0.5
    let z3 = data 0.9  0.9  1  0  0.1  -0.6  2.2  -0.3  0.6  2.4  2.5
    .
    . Step 3: Convert to form needed for "statistic" command
    .
    let y x = stacked y1 y2
    let zy zx = stacked z1 z2 z3
    set write decimals 4
    .
    .  Step 2: Check the statistic
    .
    .  stat = 5.192, pvalue = 0.0754
    .
    let stat = squared rank test         zy zx
    let pval = squared rank test pvalue  zy zx
    let cdf  = squared rank test cdf     zy zx
    print stat cdf pval
    pause
    .
    let stat2 = squared rank test         y x
    let cdf2  = squared rank test cdf     y x
    let pval2 = squared rank test pvalue  y x
    let pvallt = squared rank test lower tailed pvalue  y x
    let pvalut = squared rank test upper tailed pvalue  y x
    print stat2 cdf2 pval2 pvallt pvalut
    .
    squared rank test y1 y2

-----SRACDF (LET)--------------------------------
 
SRACDF
 
Name:
    SRACDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the studentized range cumulative distribution
    function with degrees of freedom parameter V and number of
    samples parameter R. 
 
Description:
    The studentized range is defined as:

       Q = Range/Standard Deviation

    The studentized range is used in constructing confidence
    intervals for tests of multiple comparisons in analysis
    of variance problems.

    The parameter V must be >= 1 and R must be >= 2.  Note 
    that for the most common uses of this distribution
    R is usually set to V + 1.

Syntax:
    LET <y> = SRACDF(<x>,<v>,<r>)  <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter where the studentized
               range will be computed (<x> > 0);
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed studentized range cdf values are
               stored;
          <v> is a number or parameter that specifies the degrees
               of freedom parameter (<v> >= 1);
          <r> is a number or parameter that specifies the sample
               size parameter (<r> >= 2);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SRACDF(3,10,11)
    LET A = SRACDF(A1,22,23)
    LET X2 = SRACDF(X1,V,R)
 
Note:
    This command is implemented using the Algorithm AS 190,
    prtrng, from Applied Statistics (1983), Vol. 32, No. 2.
    It incorporates modifications from Applied Statistics,
    (1985) Vol. 34, (1).

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SRAPPF = Compute the studentized range percent point function.
    ANOVA  = Perform an analysis of variance.
    CHSPDF = Compute the chi-square probability density function.
    CHSPPF = Compute the chi-square percent point function.
    CHSCDF = Compute the chi-square cumulative distribution function.
    FCDF   = Compute the F cumulative distribution function.
    FPDF   = Compute the F probability density function.
    FPPF   = Compute the F percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
    TCDF   = Compute the T cumulative distribution function.
    TPDF   = Compute the T probability density function.
    TPPF   = Compute the T percent point function.
 
Applications:
    Analysis of Variance
 
Implementation Date:
    1999/3
 
Program:
    TITLE AUTOMATIC
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    MULTIPLOT 2 2
    PLOT SRACDF(X,4,5) FOR X = 0.01 0.01 10
    PLOT SRACDF(X,9,10) FOR X = 0.01 0.01 10
    PLOT SRACDF(X,19,20) FOR X = 0.01 0.01 10
    PLOT SRACDF(X,29,30) FOR X = 0.01 0.01 10
    END OF MULTIPLOT
 
-----SRAPPF (LET)--------------------------------
 
SRAPPF
 
Name:
    SRAPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the studentized range percent point function with
    degrees of freedom parameter V and number of samples
    parameter R. 
 
Description:
    The studentized range is defined as:

       Q = Range/Standard Deviation

    The studentized range is used in constructing confidence
    intervals for tests of multiple comparisons in analysis
    of variance problems.

    The parameter V must be >= 1 and R must be >= 2.  Note 
    that for the most common uses of this distribution
    R is usually set to V + 1.

    This function is only supported for values in the range
    0.90 to 0.99.

Syntax:
    LET <y> = SRAPPF(<p>,<v>,<r>)  <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable or a parameter where the studentized
               range percent point will be computed
               (0.90 <= <p> <= 0.99);
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed studentized range cdf values are
               stored;
          <v> is a number or parameter that specifies the degrees
               of freedom parameter (<v> >= 1);
          <r> is a number or parameter that specifies the sample
               size parameter (<r> >= 2);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SRAPPF(0.90,10,11)
    LET A = SRAPPF(0.95,22,23)
    LET X2 = SRAPPF(0.99,V,R)
 
Note:
    This command is implemented using the Algorithm AS 190,
    qrtrng, from Applied Statistics (1983), Vol. 32, No. 2.
    It incorporates modifications from Applied Statistics,
    (1985) Vol. 34, (1).

Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SRACDF = Compute the studentized range cumulative distribution
             function.
    ANOVA  = Perform an analysis of variance.
    CHSPDF = Compute the chi-square probability density function.
    CHSPPF = Compute the chi-square percent point function.
    CHSCDF = Compute the chi-square cumulative distribution function.
    FCDF   = Compute the F cumulative distribution function.
    FPDF   = Compute the F probability density function.
    FPPF   = Compute the F percent point function.
    NORCDF = Compute the normal cumulative distribution function.
    NORPDF = Compute the normal probability density function.
    NORPPF = Compute the normal percent point function.
    TCDF   = Compute the T cumulative distribution function.
    TPDF   = Compute the T probability density function.
    TPPF   = Compute the T percent point function.
 
Applications:
    Analysis of Variance
 
Implementation Date:
    1999/3
 
Program:
    TITLE AUTOMATIC
    MULTIPLOT CORNER COORDINATES 5 5 95 95
    MULTIPLOT 2 2
    PLOT SRAPPF(P,4,5) FOR P = 0.90 0.01 0.99
    PLOT SRAPPF(P,9,10) FOR P = 0.90 0.01 0.99
    PLOT SRAPPF(P,19,20) FOR P = 0.90 0.01 0.99
    PLOT SRAPPF(P,29,30) FOR P = 0.90 0.01 0.99
    END OF MULTIPLOT
 
-----STACK-------------------------------------------------------
 
STACK
 
Name:
    STACK
 
Type:
    LET Subcommand
 
Purpose:
    Convert a set of response variables to a single response
    variable and a group-id variable.
 
Description:
    Many commands in Dataplot expect the data to be in the
    form of a single response variable and a group-id variable
    (e.g., BOX PLOT, MEAN PLOT, SD PLOT, TABULATE).  However, many
    data files will contain grouped data in a form where each group
    is stored as a separate response variable.

    The STACK command provides a convenient method for converting
    from the multi-column form to the single response variable
    with group-id variable form.

Syntax:
    LET <y2> <x2> = STACK <x1> ... <xk>
                          <SUBSET/EXPCEPT/FOR qualification>
    where <x1> ... <xk> is a set of one or more response variables
               (they do not have to be of equal size);
          <y2> is the variable to contain <x1> ... <xk> in a
               single response variable; 
          <x2> is the variable to contain the group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET Y2 X2 = STACK Z1 Z2 Z3 Z4 Z5
 
Default:
    None.
 
Synonyms:
    None
 
Related Commands:
    EXTEND        = Extends a variable by another variable.
    LET           = Creates, transforms, etc. a variable.
    MEAN PLOT     = Generate a mean plot.
    BOX PLOT      = Generate a box plot.
    TABULATE      = Peform a tabulation.
    UNSTACK       = Create multiple response variables from a response
                    variable and an associated group-id variable.
 
Applications:
    Data Management
 
Implementation Date:
    2003/5
 
Program:
    SKIP 25
    READ MONTGOME.DAT Y1 Y2 Y3
    .
    LET Z2 X2 = STACK Y1 Y2 Y3
    .
    XTIC OFFSET 0.5 0.5
    LET NVAR = 3
    XLIMITS 1 NVAR
    MAJOR XTIC MARK NUMBER NVAR
    MINOR XTIC MARK NUMBER 0
    MAJOR XTIC MARK NUMBER NVAR
    X1TIC MARK LABEL FORMAT ALPHA
    X1TIC MARK LABEL CONTENT LARGE MEDIUM SMALL
    .
    MULTIPLOT SCALE FACTOR 1.5
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    MULTIPLOT 2 2
    CHARACTER X BLANK
    LINE BLANK SOLID
    Y1LABEL MEAN (PERCENTAGE CLASSIFICATION)
    MEAN PLOT Z2 X2
    Y1LABEL SD (PERCENTAGE CLASSIFICATION)
    SD PLOT Z2 X2
    LINES BOX PLOT
    CHARACTER BOX PLOT
    FENCES ON
    Y1LABEL (PERCENTAGE CLASSIFICATION)
    BOX PLOT Z2 X2
    END OF MULTIPLOT 
  
-----STANDARD DEVIATION (LET)-----------------------------------------
 
STANDARD DEVIATION
 
Name:
    STANDARD DEVIATION (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the standard deviation of a variable.
 
Description:
    The standard deviation is a common measure of the spread of a
    distribution or variable.  The formula is:
          SD = SQRT(SUM(Xi - Xmean)**2/(N-1))
 
Syntax:
    LET <par> = STANDARD DEVIATION <y>
               <SUBSET/EXCEPT/FOR qualification>
    where <y> is the variable for which the standard deviation is to
              be computed;
          <par> is a parameter where the computed standard deviation
              is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET SD = STANDARD DEVIATION Y1
    LET SD = STANDARD DEVIATION Y1  SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MEAN                 = Compute the mean of a variable.
    RANGE                = Compute the range of a variable.
    VARIANCE             = Compute the variance of a variable.
    WEIGHTED STAND DEVI  = Compute the weighted standard deviation of
                           a variable.
 
Applications:
    Data Analysis
 
Implementation Date:
    Pre-1987
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET SD = STANDARD DEVIATION Y1
 
-----SD CONFIDENCE LIMITS--------------------------------------
 
SD CONFIDENCE LIMITS
 
Name:
    SD CONFIDENCE LIMITS
 
Type:
    Analysis Command
 
Purpose:
    Generates a confidence interval for the standard deviation.
 
Description:
    Given a sample of n observations with standard deviation s, the
    two-sided confidence interval for the standard deviation is

       lower confidence limit = s*SQRT((n-1)/CHSPPF(1-alpha/2;n-1))
       upper confidence limit = s*SQRT((n-1)/CHSPPF(alpha/2;n-1))

    with CHSPPF denoting the percent point function of the chi-square
    distribution.  In these formulas, alpha is less than 0.5 (i.e.,
    for a 95% confidence interval, we are using alpha = 0.05).

    The one-sided lower confidence limit is

       lower confidence limit = s*SQRT((n-1)/CHSPPF(1-alpha;n-1))

    The one-sided upper confidence limit is

       upper confidence limit = s*SQRT((n-1)/CHSPPF(alpha;n-1))

    This confidence interval is based on the assumption that
    the underlying data is approximately normally distributed.
    The confidence interval for the standard deviation is highly
    sensitive to non-normality in the data.  It is recommended
    that the original data be tested for normality before using
    these normal based intervals.  If the data is not approximately
    normal, an alternative is to use the command

       BOOTSTRAP STANDARD DEVIATION PLOT Y

Syntax 1:
    <LOWER/UPPER> SD CONFIDENCE LIMITS  <y>
                                        <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    If LOWER is specified, a one-sided lower confidence limit is
    returned.  If UPPER is specified, a one-sided upper confidence
    limit is returned.  If neither is specified, a two-sided limit
    is returned.

    This syntax supports matrix arguments for the response variable.

Syntax 2:
    MULTIPLE <LOWER/UPPER> SD CONFIDENCE LIMITS  <y1> ... <yk>
                           <SUBSET/EXCEPT/FOR qualification>
    where <y1>  .... <yk> is a list of 1 to 30 response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax will generate a confidence interval for each of
    the response variables.  The word MULTIPLOT is optional.  That is,

         MULTIPLE SD CONFIDENCE LIMITS Y1 Y2 Y3

    is equivalent to

         SD CONFIDENCE LIMITS Y1 Y2 Y3

    If LOWER is specified, a one-sided lower confidence limit is
    returned.  If UPPER is specified, a one-sided upper confidence
    limit is returned.  If neither is specified, a two-sided limit
    is returned.

    This syntax supports matrix arguments for the response variables.

Syntax 3:
    REPLICATED <LOWER/UPPER> SD CONFIDENCE LIMITS  <y> <x1> ... <xk>
                             <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1>  .... <xk> is a list of 1 to 6 group-id variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax performs a cross-tabulation of the <x1> ... <xk>
    and generates a confidence interval for each unique combination
    of the cross-tabulated values.  For example, if X1 has 3 levels
    and X2 has 2 levels, six confidence intervals will be generated.

    If LOWER is specified, a one-sided lower confidence limit is
    returned.  If UPPER is specified, a one-sided upper confidence
    limit is returned.  If neither is specified, a two-sided limit
    is returned.

    This syntax does not support matrix arguments.

Examples:
    SD CONFIDENCE LIMITS Y1
    SD CONFIDENCE LIMITS Y1  SUBSET TAG > 2
    MULTIPLE SD CONFIDENCE LIMITS Y1 TO Y5
    REPLICATED SD CONFIDENCE LIMITS Y X
 
Note:
    As noted above, the confidence interval for the standard
    deviation is very sensitive to non-normality in the data.
    Bonett (2006) has proposed an interval that is nearly exact when
    the data is normally distributed and provides good performance
    for moderately non-normal data.  The interval for the variance (for
    the standard deviation, take the square root of these values) is

          EXP{LOG(c*s**2) - z(alpha/2)*se} < sigma**2 <
              EXP{LOG(c*s**2) + z(alpha/2)*se}

    where

        s         = sample standard deviation
        c         = n/(n - z(alpha/2))
        z         = the normal percent point function
        se        = the standard error
                  = c*SQRT[(gamma4hat - (n-3)/n))/(n-1)]
        gam4hat   = an adjusted estimate of kurtosis
                  = N*SUM[i=1 to n][(x(i) - m)**4/
                    (SUM[i=1 to n][(x(i) - xbar)**2])**2
        m         = trimmed mean with trim proportion equal
                    to 1/(2*SQRT(n-4))

    The use of the trimmed mean reduces the bias of the
    kurtosis estimate for heavy tailed and skewed data.

    The justification and derivation of this interval is given
    in Bonett's paper.

    To request that the Bonett interval be generated, enter

        SET BONETT STANDARD DEVIATION CONFIDENCE LIMITS ON

    Based on simulation studies by Bonett, this interval results
    in greatly improved coverage properties for moderately
    non-normal data.  For more extreme non-normality, large
    sample sizes may be required to obtain good coverage
    properties.  Often a transformation to reduce skewness
    (which may reduce the heavy tailedness as well), such as
    the LOG or square root, can significantly reduce the sample
    size required to obtain good coverage properties.

    Bonett also suggests that improved estimates for the kurtosis can
    significantly improve the coverage properties.  Bonett's example is
    quality control applications where much historical data is frequently
    available.  If a prior estimate of kurtosis is available, then the
    above formula pools this prior estimate with the kurtosis estimate
    from the data using

       gamma4hat = (n0*gam4(0) + n*gam4hat)/(n0 + n)

    with gam4(0) and n0 denoting the prior estimate of kurtosis
    and the associated sample size, respectively.  Bonett gives
    guidance on pooling multiple estimates of kurtosis based on
    several small samples (it is often the case in quality control
    applications that a large number of small samples are available).

    In Dataplot, you can specify a prior estimate of kurtosis by
    entering the commands

       LET KURTOSIS = <value>
       LET N0 = <value>

    Niwitpong and Kirdwichai (2008) suggested two modifications to
    Bonett's interval to improve the coverage for data that are
    skewed and heavy tailed.  Specifically, the following modifications
    are made to Bonett's interval

        1. Use the median instead of the trimmed mean to compute
           the sample kurtosis.

        2. Use the t percent point function rather than the normal
           percent point function.

    This interval will be more conservative than the original
    Bonett data.  Based on simulation studies in their paper, these
    adjustments can improve the nominal coverage for data that are
    skewed.  However, it may be overly conservative for data that
    are only moderately non-normal.

    To use the Niwitpong and Kirdwichai adjusted interval, enter

        SET BONETT STANDARD DEVIATION CONFIDENCE LIMITS ADJUSTED ON

Note:
    A table of confidence limits is printed for alpha levels of
    50.0, 80.0, 90.0, 95.0, 99.0, and 99.9.
 
Note:
    In addition to the STANDARD DEVIATION CONFIDENCE LIMIT command, the
    following commands can also be used:

        LET ALPHA = 0.05

        LET A = LOWER STANDARD DEVIATION CONFIDENCE LIMIT Y
        LET A = UPPPER STANDARD DEVIATION CONFIDENCE LIMIT Y
        LET A = LOWER BONETT STANDARD DEVIATION CONFIDENCE LIMIT Y
        LET A = UPPPER BONETT STANDARD DEVIATION CONFIDENCE LIMIT Y
        LET A = ONE SIDED LOWER STANDARD DEVIATION CONFIDENCE LIMIT Y
        LET A = ONE SIDED UPPER STANDARD DEVIATION CONFIDENCE LIMIT Y

        LET A = SUMMARY LOWER STANDARD DEVIATION CONFIDENCE LIMIT YSD N
        LET A = SUMMARY UPPPER STANDARD DEVIATION CONFIDENCE LIMIT YSD N
        LET A = SUMMARY ONE SIDED LOWER STANDARD DEVIATION CONFIDENCE LIMIT
                YSD N
        LET A = SUMMARY ONE SIDED UPPER STANDARD DEVIATION CONFIDENCE LIMIT
                YSD N

    The first command specifies the significance level.  The next six
    commands are used when you have raw data.  The last four commands are
    used when only summary data (standard deviation, sample size) is
    available.

    In addition to the above LET command, built-in statistics are
    supported for about 20 different commands (enter HELP STATISTICS
    for details).

Default:
    None
 
Synonyms:
    STANDARD DEVIATION CONFIDENCE INTERVAL is a synonym for
    STANDARD DEVIATION CONFIDENCE LIMITS
 
    SD CONFIDENCE LIMIT is a synonym for STANDARD DEVIATION CONFIDENCE
    LIMIT

Related Commands:
    SD PREDICTION LIMITS    = Generate a prediction limit for the
                              standard deviation.
    CONFIDENCE LIMITS       = Generate a confidence limit for the mean.
    PREDICTION LIMITS       = Generate prediction limits for the mean.
    PREDICTION BOUNDS       = Generate prediction limits to cover all
                              new observations.
    TOLERANCE LIMITS        = Generate a tolerance limit.
 
Reference:
    Hahn and Meeker (1991), "Statistical Intervals: A Guide for
    Practitioners," Wiley, pp. 55-56.
 
    Bonett (2006), "Approximate Confidence Interval for Standard
    Deviation of Nonnormal Distributions", Computational Statistics
    and Data Analysis, Vol. 50, pp. 775 - 782.

    Niwitpong and Kirdwichai (2008), "Adjusted Bonett Confidence
    Interval for Standard Deviation of Non-Normal Distributions",
    Thailand Statistician, Vol. 6, No. 1, pp. 1-6.

Applications:
    Confirmatory Data Analysis
 
Implementation Date:
    2013/04
    2017/12: Support for Bonett intervals
 
Program 1:
    SKIP 25
    READ ZARR13.DAT Y
    SET WRITE DECIMALS 5
    .
    SD CONFIDENCE LIMITS Y
    LOWER SD CONFIDENCE LIMITS Y
    UPPER SD CONFIDENCE LIMITS Y
 
Program 2:
    SKIP 25
    READ GEAR.DAT Y X
    LET NNEW = 3
    .
    REPLICATED SD CONFIDENCE LIMITS Y X
 
Program 3:
    .  Following example from Hahn and Meeker's book.
    .
    let ymean = 50.10
    let ysd   = 1.31
    let n1    = 5
    let alpha = 0.05
    .
    set write decimals 5
    let slow1 = summary lower sd confidence limits ysd n1
    let supp1 = summary upper sd confidence limits ysd n1
    let slow2 = summary one sided lower sd confidence limits ysd n1
    let supp2 = summary one sided upper sd confidence limits ysd n1
    print slow1 supp1 slow2 supp2

Program 4:
    . Step 1:   Read the data (example from Bonett paper)
    .
    let y = data 15.83 16.01 16.24 16.42 15.33 15.44 16.88 16.31
    .
    . Step 2:   Compute the statistics
    .
    set write decimals 4
    let ysd = standard deviation y
    let lcl = lower bonett standard deviation confidence limit y
    let ucl = upper bonett standard deviation confidence limit y
    print ysd lcl ucl
    .
    set bonett standard deviation confidence limit on
    standard deviation confidence limits y

-----STANDARD DEVIATION OF THE MEAN (LET)----------------------------
 
STANDARD DEVIATION OF THE MEAN
 
Name:
    STANDARD DEVIATION OF THE MEAN (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the standard deviation of the mean of a variable.
 
Description:
    The standard deviation of the mean is:
        sd of mean = s/SQRT(N)
    where s is the standard deviation of the variable.
 
Syntax:
    LET <par> = STANDARD DEVIATION OF THE MEAN <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the variable for which the standard deviation of the
              mean is to be computed;
          <par> is a parameter where the computed standard deviation
              of the mean is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET SD = STANDARD DEVIATION OF THE MEAN Y1
    LET SD = STANDARD DEVIATION OF THE MEAN Y1 SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    MEAN         = Compute the mean of a variable.
    STAND DEVI   = Compute the standard deviation of a variable.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET SD = STANDARD DEVIATION OF THE MEAN Y1
 
-----STANDARD DEVIATION PLOT-------------------------------------
 
STANDARD DEVIATION PLOT
 
Name:
    STANDARD DEVIATION PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a standard deviation plot.
 
Description:
    A standard deviation plot is a plot consisting of subsample
    standard deviations versus subsample index.  The subsample standard
    deviation is the standard deviation (with divisor ni-1) of the data
    in the subsample.  The standard deviation plot is used to answer
    the question--"Does the subsample variation change over different
    subsamples?".  It consists of:
       Vertical   axis = subsample standard deviation;
       Horizontal axis = subsample index.
    The standard deviation plot yields 2 traces;
       1. a subsample standard deviation trace; and
       2. a full-sample standard deviation reference line.
    Like usual, the appearance of these 2 traces is
    controlled by the first 2 settings of the LINES,
    CHARACTERS, SPIKES, BARS, and similar attributes.
 
Syntax:
    STANDARD DEVIATION PLOT <y> <x>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    STANDARD DEVIATION PLOT Y X
    STANDARD DEVIATION PLOT Y X1
 
Default:
    None
 
Synonyms:
    SD PLOT
    S PLOT
 
Related Commands:
    CHARACTERS               = Sets the type for plot char.
    LINES                    = Sets the type for plot lines.
    VARIANCE  PLOT           = Generates a variance plot.
    STAN DEVI OF MEAN PLOT   = Generates standard deviation of the mean
                               plot.
    RANGE PLOT               = Generates a range plot.
    MEAN PLOT                = Generates a mean plot.
    MEDIAN PLOT              = Generates a median plot.
    BOX PLOT                 = Generates a box plot.
    S CHART                  = Generates a standard deviation
                               control chart.
    PLOT                     = Generates a data or function plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    SKIP 25
    READ GEAR.DAT DIAMETER BATCH
    LINE BLANK DASH
    CHARACTER X BLANK
    XTIC OFFSET 0.2 0.2
    Y1LABEL STANDARD DEVIATION
    X1LABEL BATCH
    TITLE STANDARD DEVIATION PLOT
    STANDARD DEVIATION PLOT DIAMETER BATCH
 
-----STANDARD DEVIATION OF THE MEAN PLOT-------------------------
 
STANDARD DEVIATION OF THE MEAN PLOT
 
Name:
    STANDARD DEVIATION OF THE MEAN PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a standard deviation of the mean plot.
 
Description:
    A standard deviation of the mean plot consists of subsample
    standard deviations of the mean versus subsample index.  The
    subsample standard deviation of the mean is the subsample standard
    deviation divided by the square root of the subsample size.  The
    standard deviation of the mean plot is used to answer the
    question--"Does the subsample variation of the mean change over
    different subsamples?".  It consists of:
       Vertical   axis = subsample standard deviation;
       Horizontal axis = subsample index.
    The standard deviation of the mean plot yields 2 traces:
       1. a subsample standard deviation of the mean trace;
       2. a full-sample standard deviation of the mean reference line.
    Like usual, the appearance of these 2 traces is
    controlled by the first 2 settings of the LINES,
    CHARACTERS, SPIKES, BARS, and similar attributes.
 
Syntax:
    STANDARD DEVIATION OF THE MEAN PLOT <y> <x>
                      <SUBSET/EXCEPT/FOR/qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    STANDARD DEVIATION OF THE MEAN PLOT Y X
    STANDARD DEVIATION OF THE MEAN PLOT Y X1
 
Default:
    None
 
Synonyms:
    STANDARD DEVIATION OF MEAN PLOT
    SDM PLOT
 
Related Commands:
    CHARACTERS                = Sets the type for plot char.
    LINES                     = Sets the type for plot lines.
    STANDARD DEVIATION PLOT   = Generates a standard deviation plot.
    VARIANCE  PLOT            = Generates a variance plot.
    VARIANCE OF MEAN PLOT     = Generates variance of the mean plot.
    RANGE PLOT                = Generates a range plot.
    MEAN PLOT                 = Generates a mean plot.
    MEDIAN PLOT               = Generates a median plot.
    BOX PLOT                  = Generates a box plot.
    S CHART                   = Generates a standard deviation control
                                chart.
    PLOT                      = Generates a data or function plot.
 
Applications:
    Quality Control
 
Implementation Date:
    88/2
 
Program:
    SKIP 25
    READ GEAR.DAT DIAMETER BATCH
    LINE BLANK DASH
    CHARACTER X BLANK
    XTIC OFFSET 0.2 0.2
    Y1LABEL STANDARD DEVIATION OF THE MEAN
    X1LABEL BATCH
    TITLE STANDARD DEVIATION OF THE MEAN PLOT
    STANDARD DEVIATION OF THE MEAN PLOT DIAMETER BATCH
 
-----SD PREDICTION LIMITS--------------------------------------
 
SD PREDICTION LIMITS
 
Name:
    SD PREDICTION LIMITS
 
Type:
    Analysis Command
 
Purpose:
    Generates a prediction interval for the standard deviation of one
    or more new observations given a previous sample.
 
Description:
    Given a sample of n observations with standard deviation s, the
    two-sided prediction interval to contain the standard deviation
    of m new indpendent, identically distributed observations is

       lower prediction limit = s*SQRT(1/F(1-alpha/2;n-1,m-1))
       upper prediction limit = s*SQRT(F(1-alpha/2;n-1,m-1))

    with F denoting the percent point function of the F distribution.

    The one-sided lower prediction limit is

       lower prediction limit = s*SQRT(1/F(1-alpha;n-1,m-1))

    The one-sided upper prediction limit is

       upper prediction limit = s*SQRT(F(1-alpha;n-1,m-1))

    In this formula, the only value from the new observations is the
    sample size.  That is, it can be applied before the new data is
    actually collected.  The number of observations for the new sample
    is entered with the command

        LET NNEW = <value>

    If NNEW is not defined, then a value of 1 is used.

    This prediction interval is based on the assumption that
    the underlying data is approximately normally distributed.
    The prediction interval for the standard deviation is highly
    sensitive to non-normality in the data.  It is recommended
    that the original data be tested for normality before using
    these normal based intervals.

Syntax 1:
    <LOWER/UPPER> <LOGNORMAL/BOXCOX> SD PREDICTION LIMITS  <y>
                                     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    If LOWER is specified, a one-sided lower prediction limit is
    returned.  If UPPER is specified, a one-sided upper prediction
    limit is returned.  If neither is specified, a two-sided limit
    is returned.

    If the keyword LOGNORMAL is present, the log of the data will be
    taken, then the normal prediction limits will be computed, and then
    the computed normal lower and upper limits will be exponentiated to
    obtain the lognormal prediction limtis.

    Similarly, if the keyword BOXCOX is present, a Box-Cox transformation
    to normality will be applied to the data before computing the normal
    prediction limits.  The computed lower and upper limits will then
    be transformed back to the original scale.

    This syntax supports matrix arguments for the response variable.

Syntax 2:
    MULTIPLE <LOWER/UPPER> <LOGNORMAL/BOXCOX> SD PREDICTION LIMITS
                           <y1> ... <yk>
                           <SUBSET/EXCEPT/FOR qualification>
    where <y1>  .... <yk> is a list of 1 to 30 response variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax will generate a prediction interval for each of
    the response variables.  The word MULTIPLOT is optional.  That is,

         MULTIPLE SD PREDICTION LIMITS Y1 Y2 Y3

    is equivalent to

         SD PREDICTION LIMITS Y1 Y2 Y3

    If LOWER is specified, a one-sided lower prediction limit is
    returned.  If UPPER is specified, a one-sided upper prediction
    limit is returned.  If neither is specified, a two-sided limit
    is returned.

    If the keyword LOGNORMAL is present, the log of the data will be
    taken, then the normal prediction limits will be computed, and then
    the computed normal lower and upper limits will be exponentiated to
    obtain the lognormal prediction limtis.

    Similarly, if the keyword BOXCOX is present, a Box-Cox transformation
    to normality will be applied to the data before computing the normal
    prediction limits.  The computed lower and upper limits will then
    be transformed back to the original scale.

    This syntax supports matrix arguments for the response variables.

Syntax 3:
    REPLICATED <LOWER/UPPER> <LOGNORMAL/BOXCOX>
                             SD PREDICTION LIMITS  <y> <x1> ... <xk>
                             <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1>  .... <xk> is a list of 1 to 6 group-id variables;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax performs a cross-tabulation of the <x1> ... <xk>
    and generates a prediction interval for each unique combination
    of the cross-tabulated values.  For example, if X1 has 3 levels
    and X2 has 2 levels, six prediction intervals will be generated.

    If LOWER is specified, a one-sided lower prediction limit is
    returned.  If UPPER is specified, a one-sided upper prediction
    limit is returned.  If neither is specified, a two-sided limit
    is returned.

    If the keyword LOGNORMAL is present, the log of the data will be
    taken, then the normal prediction limits will be computed, and then
    the computed normal lower and upper limits will be exponentiated to
    obtain the lognormal prediction limtis.

    Similarly, if the keyword BOXCOX is present, a Box-Cox transformation
    to normality will be applied to the data before computing the normal
    prediction limits.  The computed lower and upper limits will then
    be transformed back to the original scale.

    This syntax does not support matrix arguments.

Examples:
    SD PREDICTION LIMITS Y1
    SD PREDICTION LIMITS Y1  SUBSET TAG > 2
    MULTIPLE SD PREDICTION LIMITS Y1 TO Y5
    REPLICATED SD PREDICTION LIMITS Y X
 
Note:
    A table of prediction limits is printed for alpha levels of
    50.0, 80.0, 90.0, 95.0, 99.0, and 99.9.
 
Note:
    In addition to the STANDARD DEVIATION PREDICTION LIMIT command, the
    following commands can also be used:

        LET ALPHA = 0.05
        LET NNEW = <value>

        LET A = LOWER STANDARD DEVIATION PREDICTION LIMIT Y
        LET A = UPPPER STANDARD DEVIATION PREDICTION LIMIT Y
        LET A = ONE SIDED LOWER STANDARD DEVIATION PREDICTION LIMIT Y
        LET A = ONE SIDED UPPER STANDARD DEVIATION PREDICTION LIMIT Y

        LET A = SUMMARY LOWER STANDARD DEVIATION PREDICTION LIMIT YSD N
        LET A = SUMMARY UPPPER STANDARD DEVIATION PREDICTION LIMIT YSD N
        LET A = SUMMARY ONE SIDED LOWER STANDARD DEVIATION PREDICTION LIMIT
                YSD N
        LET A = SUMMARY ONE SIDED UPPER STANDARD DEVIATION PREDICTION LIMIT
                YSD N

    The first 2 commands specify the significance level and the number
    of new observations.  The next 4 commands are used when you have raw
    data.  The last 4 commands are used when only summary data (standard
    deviation, sample size) is available.

    In addition to the above LET command, built-in statistics are
    supported for about 20 different commands (enter HELP STATISTICS
    for details).

Default:
    None
 
Synonyms:
    STANDARD DEVIATION PREDICTION INTERVAL is a synonym for
    STANDARD DEVIATION PREDICTION LIMITS
 
    SD PREDICTION LIMIT is a synonym for STANDARD DEVIATION PREDICTION
    LIMIT

Related Commands:
    SD CONFIDENCE LIMITS    = Generate a confidence limit for the
                              standard deviation.
    PREDICTION LIMITS       = Generate prediction limits for the mean.
    PREDICTION BOUNDS       = Generate prediction limits to cover all
                              new observations.
    CONFIDENCE LIMITS       = Generate a confidence limit for the mean.
    TOLERANCE LIMITS        = Generate a tolerance limit.
 
Reference:
    Hahn and Meeker (1991), "Statistical Intervals: A Guide for
    Practitioners", Wiley, pp. 61-62.
 
Applications:
    Confirmatory Data Analysis
 
Implementation Date:
    2013/04
    2014/06: Support for LOGNORMAL and BOXCOX options
 
Program 1:
    SKIP 25
    READ ZARR13.DAT Y
    SET WRITE DECIMALS 5
    LET NNEW = 5
    .
    SD PREDICTION LIMITS Y
    LOWER SD PREDICTION LIMITS Y
    UPPER SD PREDICTION LIMITS Y
 
Program 2:
    SKIP 25
    READ GEAR.DAT Y X
    SET WRITE DECIMALS 5
    LET NNEW = 3
    .
    REPLICATED SD PREDICTION LIMITS Y X
 
Program 3:
    .  Following example from Hahn and Meeker's book.
    .
    let ymean = 50.10
    let ysd   = 1.31
    let n1    = 5
    let nnew  = 3
    let alpha = 0.05
    .
    set write decimals 5
    let slow1 = summary lower sd prediction limits ysd n1
    let supp1 = summary upper sd prediction limits ysd n1
    let slow2 = summary one sided lower sd prediction limits ysd n1
    let supp2 = summary one sided upper sd prediction limits ysd n1
    print slow1 supp1 slow2 supp2

-----STANDARDIZE (LET)-----------------------------------------
 
STANDARDIZE
 
Name:
    STANDARDIZE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Standardize, i.e., subtract the mean and divide by the
    standard deviation, a variable.
 
Description:
    In many applications, it is desirable to standardize the
    data values.

    This command provides additional flexibility in that either
    one or two group id variables can also be specified.  That is,
    if one group id variable is given, the mean and standard
    deviation is computed for each group and the data values
    are standardized by the corresponding group mean and standard
    deviation.  Likewise, if two group variables are specified,
    then a mean and standard deviaiton are computed for each cell
    of the cross tabulation and the data values are standardized
    by the corresponding cell mean and standard deviaition.
 
    You can specify several alternative measures to the mean for
    the location statistic and several alternative measures to
    the standard deviaition for the scale statistic.  See the
    Note below for details.  In addition, you can choose to
    standardize only by location (i.e., subtract the mean but
    do not divide by the standard deviation) or only by scale.

    You can also specifically specify a z-score or  u-score.
    A z-score subtracts the mean and divides by the standard
    deviation (i.e,, it scales to a standard normal distribution).
    Similarly, the u-score subtracts the minimum and divides by
    the range.  That is, it creates a standard uniform random
    variable (i.e., the data is scaled to a range between 0 and 1).
    If a z-score or u-score is explicitly requested, the
    settings for the SET LOCATION STATISTIC and SET SCALE STATISTIC
    (see Note below) are ignored.

Syntax 1:
    LET <var> = STANDARDIZE <y>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax standardizes (with respect to both location and
    scale) the variable with no groups.

Syntax 2:
    LET <var> = LOCATION STANDARDIZE <y>
                                     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax standardizes the variable (with respect to location
    only) with no groups.

Syntax 3:
    LET <var> = SCALE STANDARDIZE <y>
                                     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax standardizes the variable (with respect to scale
    only) with no groups.

Syntax 4:
    LET <var> = ZSCORE <y>      <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax specifically computes a z-score.

Syntax 5:
    LET <var> = USCORE <y>      <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax specifically computes a u-score.

Syntax 6:
    LET <var> = STANDARDIZE <y> <x1>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> is a group id variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax standardizes (with respect to both location and
    scale) the variable with one group variable.

Syntax 7:
    LET <var> = LOCATION STANDARDIZE <y> <x1>
                                     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> is a group id variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax standardizes the variable (with respect to location
    only) with one group variable.

Syntax 8:
    LET <var> = SCALE STANDARDIZE <y> <x1>
                                     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> is a group id variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax standardizes the variable (with respect to scale
    only) with one group variable.

Syntax 9:
    LET <var> = ZSCORE <y> <x1> <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> is a group id variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes a z-score with one group variable.

Syntax 10:
    LET <var> = USCORE <y> <x1> <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> is a group id variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes a u-score with one group variable.

Syntax 11:
    LET <var> = STANDARDIZE <y> <x1> <x2>
                            <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> is the first group id variable;
          <x2> is the second group id variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax standardizes (with respect to both location and
    scale) the variable with two group variable.

Syntax 12:
    LET <var> = LOCATION STANDARDIZE <y> <x1> <x2>
                                     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> is a group id variable;
          <x2> is the second group id variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax standardizes the variable (with respect to location
    only) with two group variable.

Syntax 13:
    LET <var> = SCALE STANDARDIZE <y> <x1> <x2>
                                     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> is a group id variable;
          <x2> is the second group id variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax standardizes the variable (with respect to scale
    only) with two group variable.

Syntax 14:
    LET <var> = ZSCORE <y> <x1> <x2> <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> is a group id variable;
          <x2> is the second group id variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes a z-score with two group variables.

Syntax 15:
    LET <var> = USCORE <y> <x1> <x2> <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <x1> is a group id variable;
          <x2> is the second group id variable;
          <var> is a variable where the standardized values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes a u-score with two group variables.

Examples:
    LET Y2 = STANDARDIZE  Y1
    LET Y2 = LOCATION STANDARDIZE  Y1
    LET Y2 = LOCATION STANDARDIZE  Y1 X1
    LET Y2 = LOCATION STANDARDIZE  Y1 X1 X2

    SET LOCATION STATISTIC MEDIAN
    SET SCALE STATISTIC MAD
    LET Y2 = STANDARDIZE  Y1 X1 X2
 
Note:
    The most common application of this command is to standardize
    using the mean as the location measure and the standard
    deviation as the scale measure.  Several alternative measures
    are allowed.

    To set the location measure, enter the command

        SET LOCATION STATISTIC  <MEAN/MEDIAN/MIDMEAN/TRIMMED MEAN/
                                WINSORIZED MEAN/MIDRANGE/
                                HARMONIC MEAN/GEOMETRIC MEAN>

    To set the scale measure, enter the command

        SET SCALE STATISTIC  <SD/MAD/AAD/INTERQUARTILE RANGE/
                             GEOMETRIC STANDARD DEVIATION/
                             SN SCALE/QN SCALE>

    Here, SD is the standard deviation, MAD is the median absolute
    deviation, and AAD is the average absolute deviation.

    Note the using the ZSCORE or USCORE syntax overrides the settings
    specified by these SET commands.  That is, ZSCORE always uses the
    mean and standard deviation and USCORE always uses the minimum and
    the range.

Default:
    The default location statistic is the mean and the default
    scale statistic is the standard deviation.
 
Synonyms:
    IQ RANGE is a synonym for INTERQUARTILE RANGE.
 
Related Commands:
    MEAN PLOT       = Generate a mean vs. subset plot.
    SD PLOT         = Generate a standard deviation vs. subset plot.
    TABULATE        = Compute group statistics (one group variable).
    CROSS TABULATE  = Compute group statistics (two group variables).
    MEDIAN          = Compute the median.
    MIDDMEAN        = Compute the midmean.
    TRIMMED MEAN    = Compute the trimmed mean.
    SD              = Compute the standard deviation.
    AAD             = Compute the average absolute deviation.
    MAD             = Compute the median absolute deviation.
 
Applications:
    Data Analysis
 
Implementation Date:
    2001/3: Initial Implementation
 
    2001/9: Add support for following:
            1) Additional location statistics: MINIMUM, HARMONIC MEAN,
               GEOMETRIC MEAN, WINSORIZED MEAN, MIDRANGE
            2) Additional scale statistics: IQ RANGE, GEOMETRIC SD
            3) Support for USCORE
            4) Support for SCALE STANDARDIZE 
    2003/5: Added support for SN SCALE, QN SCALE
 
Program 1:
    SKIP 25
    READ GEAR.DAT Y X
    LET Y2 = STANDARDIZE Y X
 
Program 2:
    SKIP 25
    READ GEAR.DAT Y X
    LET Y2 = LOCATION STANDARDIZE Y X
 
Program 3:
    SKIP 25
    READ GEAR.DAT Y X
    SET LOCATION STATISTIC MEDIAN
    SET SCALE STATISTIC MAD
    LET Y2 = STANDARDIZE Y X
 
Program 4:
    SKIP 25
    READ RIPKEN.DAT Y X1 X2
    LET Y2 = STANDARDIZE Y X1 X2
 
-----STANDARD INPUT (SET)---------------------------------------
 
STANDARD INPUT
 
Name:
    STANDARD INPUT (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify the name of a file that will be equivalenced to
    standard input.
 
Description:
    By default, Dataplot reads commands from standard input (in Fortran,
    this is typically unit 5).  The SET STANDARD INPUT is used to specify
    the name of a file to read from when input is expected from standard
    input.

    In it's simplest usage, this is essentially equivalent to using a
    CALL command (this is demonstrated in the Program 1 and Program 2
    sections below).

    However, the SET STANDARD INPUT is typically used in a different
    context than the CALL command.  Specifcally, it is motivated by
    the idea of having an external program control the input to
    Dataplot in a dynamic fashion.

    For example, suppose you have a Python script and you would like that
    script to use Dataplot to perform a certain analysis.  Suppose
    further that the user of the Python script has interactive control
    over what analysis he would like Dataplot to perform and when
    he would like that analysis performed.  A typical sequence would
    then be

       1. The Python script initiates Dataplot and has Dataplot
          execute the commands

             SET MAXIMUM COUNTER STANDARD INPUT 0
             SET DELAY STANDARD INPUT 2
             SET STANDARD INPUT POLL file.dp

          When the POLL CLOSE option is used, Dataplot does the
          following

             a. Check for the existence of the file.  If the file
                exists, then execute the commands in "file.dp" (the
                file name does not have to be "file.dp").

             b. If the file does not exist, wait for a specified
                time and then check for the existence of the file
                again.  Repeat until the file is found.

                The wait time is specified by the SET DELAY STANDARD
                INPUT command.  The value is specified in seconds.
                If this command is not given, the default value is 2.
                The SET MAXIMUM COUNTER STANDARD INPUT command can
                be used to specify a maximum number of iterations.
                If this command is omitted or a value of 0 is given,
                then Dataplot will keep repeating until the file is
                found.

          If the POLL option is omitted, then Dataplot will check
          for the existence of the file only once.  If the file
          is not found, nothing is done and standard input is restored
          to unit 5.

       2. The last line of the "file.dp" file will typically contain one
          of the following lines

              SET STANDARD INPUT
              SET STANDARD INPUT CLOSE
              SET STANDARD INPUT CLOSE POLL

          where

          a. The SET STANDARD INPUT command closes "file.dp" and reverts
             standard input back to the terminal.  The "file.dp" file is
             not deleted.

          b. The SET STANDARD INPUT CLOSE command close and deletes the
             "file.dp" file.  Standard input reverts back to the
             terminal.

             This option is useful when the external program will not
             subsequently send additional commands to Dataplot.

          c. The SET STANDARD INPUT CLOSE POLL command close and deletes
             the "file.dp" file.  However, it resumes polling mode.  That
             is, it effectively enters the command

                SET STANDARD INPUT POLL file.dp

             This option is used when the external program expects to
             subsequently send additonal commands to Dataplot.

    The external program is not limited to Python.  A similar sequence
    can be used within Perl, Tcl/TK, or any number of other programs.

Syntax 1:
    SET STANDARD INPUT <fname>
    where <fname> is a file name.

    This syntax equates standard input to <fname>.  It will only
    search for the existence of <fname> one time.
 
Syntax 2:
    SET STANDARD INPUT

    This syntax closes the file equated to standard input and reverts
    standard input back to the terminal.

Syntax 3:
    SET STANDARD INPUT POLL <fname>
    where <fname> is a file name.

    This syntax equates standard input to <fname>.  It will continually
    search for the existence of <fname> (based on the SET MAXIMUM
    COUNTER STANDARD INPUT and SET DELAY STANDARD INPUT commands).

Syntax 4:
    SET STANDARD INPUT CLOSE <fname>
    where <fname> is a file name.

    This syntax closes and deletes the <fname> file and reverts standard
    input back to the terminal.
 
Syntax 5:
    SET STANDARD INPUT POLL CLOSE <fname>
    where <fname> is a file name.

    This syntax closes and deletes the <fname> file and reverts POLL
    mode for <fname>.
 
Examples:
    SET STANDARD INPUT commands.dp
    SET STANDARD INPUT POLL commands.dp

Note:
    SET RESUME POLL is a synonym for SET STANDARD INPUT POLL.  However,
    no file name is entered.  The previously defined file name (from
    the most recent SET STANDARD INPUT POLL command) will be used.

Default:
    None
 
Synonyms:
    SET SUSPEND POLL is a synonym for SET STANDARD INPUT.
    SET POLL SUSPEND is a synonym for SET STANDARD INPUT.
    SET POLL RESUME is a synonym for SET RESUME POLL.
 
Related Commands:
    CALL      = Execute the commands from an external file.
 
Applications:
    Program Control
 
Implementation Date:
    2016/01
 
Program 1:
    .  Put these lines in the external file
    .
    .     stdin.dp
    .
    .  These commands will be executed by the Program 2 example.
    .
    print "in file stdin.dp"
    let a = 3
    let b = 4
    set standard input
 
Program 2:
    . Execute the commands in file stdin.dp
    .
    set standard input stdin.dp
 
-----STANDARDIZED THIRD CENTRAL MOMENT (LET)------------------------
 
STANDARDIZED THIRD CENTRAL MOMENT
 
Name:
    STANDARDIZED THIRD CENTRAL MOMENT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the standardized third central moment (or skewness) of a
    variable.
 
Description:
    The skewness measures the lack of symmetry in a variable.  The
    formula is:
       skew = (SUM(Xi-Xmean)**3/(N-1))/s**3
    where s is the standard deviation and N is the number of
    observations.
 
Syntax:
    LET <par> = STANDARDIZED THIRD CENTRAL MOMENT <x1>
               <SUBSET/EXCEPT/FOR qualification>
    where <x1> is the variable for which the skewnes is to be computed;
          <par> is a parameter where the skewness is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET N = STANDARDIZED THIRD CENTRAL MOMENT Y1
 
Default:
    None
 
Synonyms:
    SKEWNESS
    STANDARDIZED 3RD CENTRAL MOMENT
 
Related Commands:
    MEAN         = Compute mean of a variable.
    STAND DEVI   = Compute the standard deviation of a variable.
    KURTOSIS     = Compute the Kurtosis of a variable.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET SKEW = STANDARDIZED THIRD CENTRAL MOMENT Y1
 
-----STANDARDIZED FOURTH CENTRAL MOMENT (LET)-----------------------
 
STANDARDIZED FOURTH CENTRAL MOMENT
 
Name:
    STANDARDIZED FOURTH CENTRAL MOMENT (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the standardized fourth central moment of a variable.
 
Description:
    The formula is:
       F = (SUM(X-XMEAN)**4/(N-1))/XSD**4
    where X is the sample variable, XMEAN is the mean of X, XSD is the
    standard deviation of X, and N is the sample size.  This statistic
    (also called the kurtosis) is the measure of the "fatness" of the
    distribution.  The higher the kurtosis, the more spread out the
    distribution is.
 
Syntax:
    LET <par> = STANDARDIZED FOURTH CENTRAL MOMENT <resp>
                 <SUBSET/EXCEPT/FOR qualification>
    where <resp> is the variable for which the fourth central moment is
                 to be computed;
          <par> is a parameter where the calculated fourth central
                 moment is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A1 = STANDARDIZED FOURTH CENTRAL MOMENT Y1
 
Default:
    None
 
Synonyms:
    KURTOSIS
 
Related Commands:
    SEQUENCE        = Generate a sequence of numbers.
    PATTERN         = Generate numbers with a specific pattern.
    MEAN            = Compute the mean of a variable.
    STAND DEVIATION = Compute the standard deviation of a variable.
    SKEWNESS        = Compute the skewness of a variable.
    VARIANCE        = Compute the variance of a variable.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET A1 = STANDARDIZED FOURTH CENTRAL MOMENT Y1
 
-----STAR PLOT---------------------------------------------------
 
STAR PLOT
 
Name:
    STAR PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a star plot.
 
Description:
    A star plot is a graphical data analysis technique for examining
    the relative behavior of all variables in a multivariate data set.
    The star plot consists of a sequence of equi-angular spokes
    (radii).  Each spoke represents a different variable in the
    multivariate data set.  An individual star plot examines the
    behavior of all such variables but only for a specified subset of
    the data (e.g., looking at all the attributes of car performance,
    but only for a particular car, such as Chevrolet).  The total
    length of a given spoke is uniformly set to unity for sake of
    reference.  The "data length" of a given spoke is proportional to
    the magnitude of the variable for the subset relative to the
    maximum magnitude of the variable across all subsets.  Thus we are
    looking at the ratio of the "local" value of the variable to the
    "global" maximum of the variable. An interconnecting line cutting
    across each spoke at the "data length" gives the star plot its
    unique appearance and name.
 
Syntax:
    STAR PLOT <y1> <y2> ... <yk>   <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first  response variable;
          <y2> is the second response variable;
          <yk> is the last   response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> must be given.
    It is not optional for this command as it is for most other
    DATAPLOT commands.
 
Examples:
    STAR PLOT Y1 Y2 Y3 Y4 Y5 SUBSET AUTO 4
    STAR PLOT Y1 Y2 Y3 Y4 Y5 Y6 Y7 Y8 Y9 SUBSET STATE 25
 
Note:
    A few variations of the star plot exist, all of which DATAPLOT
    can easily handle by judicious use of the components in the LINES
    command.  For example, suppose there are k variables in the star
    plot (and so k spokes), then
       1) element 1 of LINES controls the appearance of the
          interconnecting line (this is usually SOLID);
       2) the next k elements of LINES controls the appearance of the
          spokes from the origin out to the interconnecting line
          (some analysts prefer this to be SOLID, others prefer this
          to be DOTTED);
       3) the following k elements of LINES controls the appearance
          of the spokes from the interconnecting line out to the
          uniform end of the spoke (some analysts prefer this to be
          SOLID, others prefer this to be DOTTED, others prefer this
          to be BLANKed out).
    When using the LINES command in this context, note the convenient
    abbreviations SO for SOLID, DO for DOTTED, DA for DASHED, BL for
    BLANK, etc., as in LINES SO DO DO DO DO DO BL BL BL BL BL which
    for a 5-variable star plot, would set the interconnecting line to
    SOLID, the inner part of the spokes to DOTTED, and BLANK out the
    outer part of the spokes.
 
Note:
    The generation of multiple star plots per page is typical (one
    star plot for each subset of interest).  This is easily done in
    DATAPLOT by using the STAR PLOT command in conjunction with the
    MULTIPLOT and LOOP commands.  The following generates 50 star
    plots on the same page with each star plot consisting of 6
    variables (spokes):
       MULTIPLOT 5 10
       LOOP FOR K = 1 1 50
       STAR PLOT Y1 Y2 Y3 Y4 Y5 Y6 SUBSET STATE K
       END OF LOOP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PROFILE PLOT  = Generates a (multivariate) profile plot.
    ANDREWS PLOT  = Generates an Andrews plot.
    SYMBOL PLOT   = Generates a symbol plot.
    LINES         = Sets the type for plot lines.
    MULTIPLOT     = Allows multiple plots per page.
    LOOP          = Starts a loop (iteration).
    END OF LOOP   = Terminates a loop.
    ^             = Allows string and value substitution.
 
Reference:
    "Graphical Methods for Data Analysis", Chambers, Cleveland,
    Kleiner, and Tukey.  Wadsworth, 1983 (pp. 160-161).
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    88/3
 
Program:
    TITLE
    FEEDBACK OFF
    DIMENSION 100 COLUMNS
    SKIP 25
    COLUMN LIMITS 20 132
    READ AUTO79.DAT Y1 TO Y9
    LET N = SIZE Y1; LET CAR = SEQUENCE 1 1 N
    .
    COLUMN LIMITS 1 19; SKIP 0
    LOOP FOR K = 1 1 25
        LET K1 = 25+K; ROW LIMITS K1 K1; READ STRING AUTO79.DAT S^K
    END OF LOOP
    .
    MULTIPLOT 5 5; MULTIPLOT CORNER COORDINATES 0 0 100 100
    FRAME CORNER COORDINATES 15 10 95 95
    .
    LEGEND 1 COORDINATES 55 5
    LEGEND JUSTIFICATION CENTER
    LEGEND SIZE 4
    LOOP FOR K = 1 1 25
        LEGEND 1 ^S^K
        STAR PLOT Y1 Y2 Y3 Y4 Y5 Y6 Y7 Y8 Y9  SUBSET CAR K
    END OF LOOP
    END OF MULTIPLOT
 
-----<dist> ANDERSON DARLING----------------------------------------
 
STATISTIC ANDERSON DARLING
 
Name:
    <dist> ANDERSON DARLING
 
Type:
    LET Subcommand
 
Purpose:
    Compute the Anderson-Darling (A-D) goodness of fit statistic for a
    specified distribution for a response variable.
 
Description:
    The Anderson-Darling test is a goodness of fit statistic (see the
    documentation for the GOODNESS OF FIT command for details).

    Although this value is normally determined using the GOODNESS OF FIT
    command, for a limited number of distributions you can also generate
    this as a statistic LET subcommand.  The advantage in this case is
    that you can use it with any of the commands that support built-in
    statistics (e.g., the STATISTIC PLOT or the TABULATION command).  For
    example, if you have groups of data, you can use the TABULATE or
    STATISTIC PLOT commands to easily compare the goodness of fit across
    the groups.

    In order to compute the Anderson-Darling statistic, the distribution
    parameters are first computed using maximum likelihood.  This command
    can also return the maximum likelihood estimates.

    This command is only supported for a subset of the distributions for
    which the Anderson-Darling statistic is supported with the GOODNESS
    OF FIT command.  See the Note section below for a list of
    distributions supported by this command.

Syntax 1:
    LET <par> = <dist> ANDERSON DARLING  <y>
                       <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <dist> is one of the supported distributions listed below;
          <par> is the parameter where the AD value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for the case where there are no shape parameters.
 
Syntax 2:
    LET <par> = <dist> ANDERSON DARLING  STATISTIC  <y>
                       <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <dist> is one of the supported distributions listed below;
          <par> is the parameter where the AD value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax is used for those distributions that have a shape
    parameter.  When the distribution has a shape parameter, then the word
    STATISTIC is required to distinguish this command from the
    ANDERSON DARLING PLOT command.  Specifically it is used to distinguish
    the following two cases

       WEIBULL ANDERSON DARLING PLOT Y
       WEIBULL ANDERSON DARLING STATISTIC PLOT Y X
 
    The first command is the Weibull Anderson Darling plot (i.e., a plot
    of the Anderson-Darling goodness of fit across values of the shape
    parameter) while the second command plots the Anderson Darling statistic
    for Y for each group in X.

Syntax 3:
    LET <par> = <dist> ANDERSON DARLING LOCATION  <y>
                       <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <dist> is one of the supported distributions listed below;
          <par> is the parameter where the location value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax returns the estimate of the location parameter rather
    than the AD value.  Not all supported distributions have a location
    parameter.

Syntax 4:
    LET <par> = <dist> ANDERSON DARLING SCALE  <y>
                       <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <dist> is one of the supported distributions listed below;
          <par> is the parameter where the scale value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax returns the estimate of the scale parameter rather
    than the AD value.

Syntax 5:
    LET <par> = <dist> ANDESON DARLING SHAPE  <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <dist> is one of the supported distributions listed below;
          <par> is the parameter where the shape value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax returns the estimate of the shape parameter rather
    than the Anderson-Darling statistic.  Not all supported distributions
    have a shape parameter.

Examples:
    LET A = NORMAL ANDERSON DARLING Y
    LET A = NORMAL ANDERSON DARLING LOCATION Y
    LET A = NORMAL ANDERSON DARLING SCALE Y

    LET A = LOGISTIC ANDERSON DARLING Y

    LET A = WEIBULL ANDERSON DARLING STATISTIC Y
    LET A = WEIBULL ANDERSON DARLING SCALE Y
    LET A = WEIBULL ANDERSON DARLING SHAPE Y
 
Note:
    The following location/scale distributions are supported.

       LET A = DOUBLE EXPONENTIAL ANDERSON DARLING  Y
       LET A = EXPONENTIAL ANDERSON DARLING         Y
       LET A = GUMBEL ANDERSON DARLING              Y
       LET A = LOGISTIC ANDERSON DARLING            Y
       LET A = MAXWELL ANDERSON DARLING             Y
       LET A = NORMAL ANDERSON DARLING              Y
       LET A = RAYLEIGH ANDERSON DARLING            Y
       LET A = UNIFORM ANDERSON DARLING             Y

    The Maxwell and Rayleigh support the 2-parameter case rather than
    the 1-parameter case (i.e., the location parameter will be
    estimated).

    For the uniform distribution, the scale parameter will actually
    return the upper limit parameter.

    In addition, the following distributions with a single shape
    parameter are supported.

       LET A = BURR TYPE 10 ANDERSON DARLING STATISTIC Y
       LET A = FATIGUE LIFE ANDERSON DARLING STATISTIC Y
       LET A = FRECHET ANDERSON DARLING STATISTIC Y
       LET A = GAMMA ANDERSON DARLING STATISTIC Y
       LET A = GEOMETRIC EXTREME EXPONENTIAL ANDERSON DARLING STATISTIC Y
       LET A = INVERTED GAMMA ANDERSON DARLING STATISTIC Y
       LET A = LOGISTIC EXPONENTIAL ANDERSON DARLING STATISTIC Y
       LET A = LOGNORMAL ANDERSON DARLING STATISTIC Y
       LET A = WEIBULL ANDERSON DARLING STATISTIC Y

    Note that the above support the 2-parameter form of the distribution
    (i.e., the scale and shape parameters are estimated from the data
    and the location parameter is set to zero).

Note:
    The distribution parameters are estimated using maximum likelihood.
    For several distributions, you can choose an alternative estimation
    method using the command

        SET DISTRIBUTIONAL FIT TYPE <value>

    where <value> can be one of the following

        ML                       - use the default maximum likelihood
                                   (available for all supported
                                   distributions)
        MOMENT                   - use the moment estimates, available for
                                   uniform, Gumbel, 2-par Maxwell,
                                   2-par gamma, 2-par inverted gamma,
                                   2-par fatigue life
        MODIFIED MOMENT          - use the modified moment estimates,
                                   available for 2-par Rayleigh

Note:
    Dataplot statistics can be used in 20+ commands.  For details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    AD is a synonym for ANDERSON DARLING
 
Related Commands:
    GOODNESS OF FIT     = Perform a distributional goodness of fit test.
    MAXIMUM LIKELIHOOD  = Perform maximum likelihood to estimate
                          distributional parameters.
    STATISTIC PPCC      = Compute the ppcc value for a specified
                          distribution.
    STATISTIC PLOT      = Generates a statistic versus subset plot.
    TABULATE            = Compute a statistic based on a cross-tabulation.
    PPCC PLOT           = Generates a probability plot correlation
                          coefficient plot.
    PROBABILITY PLOT    = Generates a probability plot.
 
Reference:
    Stephens, M. A. (1974), "EDF Statistics for Goodness of Fit and
    Some Comparisons," Journal of the American Statistical Association,
    Vol. 69, pp. 730-737.

    Stephens, M. A. (1976), "Asymptotic Results for Goodness-of-Fit
    Statistics with Unknown Parameters," Annals of Statistics,
    Vol. 4, pp. 357-369.

    Stephens, M. A.  (1977), "Goodness of Fit for the Extreme Value
    Distribution," Biometrika, Vol. 64, pp. 583-588.

    Stephens, M. A. (1977), "Goodness of Fit with Special Reference to
    Tests for Exponentiality," Technical Report No. 262, Department of
    Statistics, Stanford University, Stanford, CA.

    Stephens, M. A. (1979), "Tests of Fit for the Logistic Distribution
    Based on the Empirical Distribution Function," Biometrika, Vol. 66,
    pp. 591-595.

Applications:
    Distributional Modeling
 
Implementation Date:
    2015/2
 
Program 1:
    . Step 1:   Read the data
    .
    skip 25
    read nor.dat      y1
    read exp.dat      y2
    read weibbury.dat y3
    read lgn.dat      y4
    read gamma.dat    y5
    read frechet.dat  y6
    let y x = stack y1 y2 y3 y4 y5 y6
    skip 0
    .
    case asis
    label case asis
    title case asis
    title offset 2
    multiplot corner coordinates 2 2 98 98
    multiplot scale factor 2
    .
    . Step 2:   Plot normal a-d statistic
    .
    multiplot 2 2
    y1label Anderson-Darling Statistic
    x3label Datasets
    xlimits 1 6
    major xtic mark number 6
    minor xtic mark number 0
    x1tic mark offset 0.5 0.5
    x1tic mark label format alpha
    x1tic mark label content NOR.DAT sp()cr()sp()cr()EXP.DAT WEIBBURY.DAT ...
          sp()cr()sp()cr()LGN.DAT GAMMA.DAT sp()cr()sp()cr()FRECHET.DAT
    x1tic mark label size 1.2
    y1label displacement 12
    ylimits 0 1
    character X
    line blank
    .
    title Normal AD
    normal anderson darling plot y x
    .
    ylimits
    y1label Location
    title Normal AD Location
    normal anderson darling location plot y x
    .
    y1label Scale
    title Normal AD Scale
    normal anderson darling scale plot y x
    .
    . Step 3:   Location/Scale distributions
    .
    multiplot 2 2
    label
    .
    ylimits 0 1
    title Normal AD
    normal anderson darling plot y x
    .
    ylimits 0 6
    title Exponential AD
    exponential anderson darling plot y x
    ylimits 0 1000
    title Double Exponential AD
    double exponential anderson darling plot y x
    ylimits 0  1.5
    title Gumbel (Maximum)
    gumbel anderson darling plot y x
    .
    end of multiplot
    .
    justification center
    move 50 3
    text Datasets
    direction vertical
    move 2 50
    text Anderson-Darling Statistic
    direction horizontal
    .
    multiplot 2 2
    x1tic mark label format numeric
    label
    .
    ylimits 0 20
    title Uniform AD
    uniform anderson darling plot y x
    .
    ylimits 0 1
    title Maxwell AD
    maxwell anderson darling plot y x
    .
    ylimits 0 10
    title Rayleigh AD
    rayleigh anderson darling plot y x
    .
    ylimits 0 1
    title Logistic
    logistic anderson darling plot y x
    .
    end of multiplot
    .
    justification center
    move 50 3
    text Datasets
    direction vertical
    move 2 50
    text Anderson-Darling Statistic
    direction horizontal

Program 2:
    . Step 1:   Read the data
    .
    skip 25
    read nor.dat      y1
    read exp.dat      y2
    read weibbury.dat y3
    read lgn.dat      y4
    read gamma.dat    y5
    read frechet.dat  y6
    let y x = stack y1 y2 y3 y4 y5 y6
    skip 0
    .
    case asis
    title case asis
    title offset 2
    .
    xlimits 1 6
    major xtic mark number 6
    minor xtic mark number 0
    x1tic mark offset 0.5 0.5
    x1tic mark label size 1.5
    character X
    line blank
    .
    . Step 3:   Weibull, Lognormal, Gamma, Fatigue Life
    .
    multiplot corner coordinates 2 2 98 98
    multiplot scale factor 2
    multiplot 2 2
    x1tic mark label format numeric
    label
    .
    ylimits 0 1
    title Weibull AD
    weibull anderson darling statistic plot y x
    . weibull ad statistic plot y x
    .
    ylimits 0 1
    title Lognormal AD
    lognormal anderson darling statistic plot y x
    ylimits
    .
    .           Note that gamma has problem with datasets 1 and 4
    .
    ylimits 0 1
    title Gamma AD
    gamma anderson darling statistic plot y x  subset x 2 3 5 6
    .
    ylimits 0 2
    title Fatigue Life AD
    fatigue life anderson darling statistic plot y x
    .
    end of multiplot
    .
    justification center
    move 50 3
    text Datasets
    direction vertical
    move 2 50
    text Anderson-Darling Statistic
    direction horizontal

-----SET STATISTIC MISSING VALUE (SET)----------------------------------
 
STATISTIC MISSING VALUE
 
Name:
    SET STATISTIC MISSING VALUE (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify a numeric value that will interpreted as a missing
    value when computing one of the built-in statistics.
 
Description:
    Data will often contain missing values.  In computing built-in
    statistics with the LET sub-commands, you can define a value that will
    be interpreted as a missing value.  Data that are equal to this
    missing value will be omitted from the computation of the statistic.

    In computing a simple statistic LET sub-command such as

         LET A = MEAN Y

    it is relatively easy to omit missing values with a SUBSET clause.
    For example

         LET A = MEAN Y  SUBSET Y <> -99999

    You can also do this with the commands

         SET STATISTIC MISSING VALUE -99999
         LET A = MEAN Y  SUBSET Y

    Although in this simple case there is no need to use the
    SET STATISTIC MISSING VALUE, there are 20+ commands (such as
    CROSS TABULATE, STATISTIC PLOT) that utilize the built-in statistics.
    In these cases, using the SET STATISTIC MISSING VALUE can be more
    convenient than using the SUBSET clause.

    Enter HELP STATISTICS for a list of built-in statistics and the
    commands that can utilize them.

Syntax:
    SET STATISTIC MISSING VALUE <value>
    where <value> is a number or parameter that specifies a value that
               will be interpreted as a missing value code.
 
Examples:
    SET STATISTIC MISSING VALUE -9999
    SET STATISTIC MISSING VALUE -1

Note:
    In addition to built-in statistic LET sub-commands, the following
    commands also recognize the SET STATISTIC MISSING VALUE command

        MANTEL HAENSZEL TEST
        ODDS RATIO CHI-SQUARE TEST
        ODDS RATIO INDEPENDENCE TEST
        LET ... = WEIBULL MOMENT ESTIMATE
        LET ... = LOGNORMAL MOMENT ESTIMATE
        LET ... = GAMMA MOMENT ESTIMATE
        LET ... = INVERSE GAUSSIAN MOMENT ESTIMATE
        LET ... = VARIABLE TO MATRIX
        LET ... = STANDARDIZE

Default:
    The missing value is set to minimum real value on the machine (this
    can be determined with a PROBE CPUMIN command).
 
Synonyms:
    None
 
Related Commands:
    STATISTICS               = List built-in statistics and commands
                               that can utilize them.
    MANTEL HAENSZEL          = Perform a Mantel-Haenszel test.
    WEIBULL MOMENT ESTIMATE  = Compute Weibull parameter estimates based
                               on moments.
 
Applications:
    Terminal usage
 
Implementation Date:
    2007/04
 
Program 1:
    read matrix m
    2 4 7 -9999
    2 -9999 2 3
    1 2 -9999 3
    end of data
    .
    set statistic missing value -9999
    .
    let meanv = matrix row mean m
    .
    set write decimals 3
    print meanv
 
Program 2:
    let n1 = 105
    let n2 = 192
    let n3 = 145
    let n = n1 + n2 + n3
    let x = 3 for i = 1 1 n
    let x = 1 for i = 1 1 n1
    let istrt = n1 + 1
    let istop = n1 + n2
    let x = 2 for i = istrt 1 istop
    .
    set statistic missing value -99
    .
    .  Group 1 values
    .
    let y1 = 0 for i = 1 1 n
    let y2 = 0 for i = 1 1 n
    let y1 = 1 for i = 1 1  81
    let y2 = 1 for i = 1 1  34
    .
    .  Group 2 values (have unequal samples here, so fill
    .          with missing values
    .
    let istrt = n1 + 1
    let istop1 = istrt + 118 - 1
    let istop2 = istrt + 69 - 1
    let y1 = 1 for i = istrt 1 istop1
    let y2 = 1 for i = istrt 1 istop2
    let istrt2 = n1 + 174 + 1
    let istop2 = n1 + n2
    let y2 = -99 for i = istrt2 1 istop2
    .
    .  Group 3 values
    .
    let istrt = n1 + n2 + 1
    let istop1 = istrt + 82 - 1
    let istop2 = istrt + 52 - 1
    let y1 = 1 for i = istrt 1 istop1
    let y2 = 1 for i = istrt 1 istop2
    .
    set statistic missing value -99
    .
    odds ratio chi-square test y1 y2 x

-----STATISTIC BLOCK-----------------------------------------------------
 
STATISTIC BLOCK
 
Name:
    statISTIC BLOCK
 
Type:
    Analysis Command
 
Purpose:
    Defines a statistic via a group of Dataplot commands.
 
Description:
    Dataplot supports a large number of built-in statistics (enter
    HELP statISTICS for a complete list).  For example,

        LET A = MEAN Y
        LET A = STANDARD DEVIATION Y
        LET A = CORRELATION Y1 Y2

    Built-in statistics can be used in the following commands

         1. LET A = <stat>
         2. <stat> STATISTIC PLOT
         3. CROSS TABULATE <stat> STATISTIC PLOT
         4. FLUCTUATION PLOT <stat>
         5. <stat> BLOCK PLOT
         6. BOOTSTRAP <stat> PLOT
         7. JACKNIFE <stat> PLOT
         8. DEX <stat> PLOT
         9. <stat> INFLUENCE CURVE
        10. CROSS TABULATE <stat>
        11. POSITIONAL TABULATION <stat>
        12. LET V = MATRIX COLUMN <stat>
        13. LET V = MATRIX ROW <stat>
        14. LET A = MATRIX GRAND <stat>
        15. LET M = MATRIX PARTITION <stat>
        16. LET V = CROSS TABULATE <stat>
        17. LET V = CROSS TABULATE CUMULATIVE <stat>
        18. LET V = SORT BY <stat>
        19. LET YOUT = MOVING <stat>
        20. LET YOUT = CUMULATIVE <stat>
        21. <STAT> INTERACTION PLOT

    Although Dataplot provides a large number of built-in statistics,
    there may be situations where you would like to define a statistic
    not already supported by Dataplot.  Statistic blocks were introduced
    to address this limitation.  Statistic blocks allow you to define
    statistics using various Dataplot LET subcommands.

    Statistic blocks are created using the CAPTURE syntax.  For
    example,

        CAPTURE STATISTIC BLOCK ONE ZZZZMEAN A Y
        LET N = SIZE Y
        LET YSUM = SUM Y
        LET A  = YSUM/N
        END OF CAPTURE

    The statistic block contains the following components

        1. CAPTURE STATISTIC BLOCK - this initiates the creation
           of the statistic block.  The CAPTURE command is typically
           used to direct Dataplot output to a file.  However,  in this
           case it saves the specified commands in an internal
           structure that can be accessed later.

        2. ONE - up to three statistic blocks can be defined.  In this
           example, "ONE" specifies that this is statistic block one.
           You can redefine these three statistic blocks as often as
           you need in a Dataplot session.

        3. ZZZZMEAN - this is the name of the statistic block.  This is
           the name that will be used to execute the statistic block in
           subsequent commands.  This follows the rules for other
           Dataplot names (i.e., up to eight alphanumeric characters).

           Note that this name should not be the same as one of Dataplot's
           built-in statistics.

        4. A - this is name of the parameter that will contain the
           response for the statistic block.  This is the value that
           is typically defined in the last line of the statistic block.
           For statistic blocks, the response must be a parameter.  If
           the response is a variable, an error will be returned.

        5. Y - this is the response variable for which the statistic is
           being computed.  You can specify from one to three response
           variables.

    The following Dataplot commands can be included in a statistic block:

         1. LET ... = PATTERN ...
         2. LET ... = DATA ...
         3. LET ... = ... RANDOM NUMBERS ...
         4. ARITHMETIC OPERATIONS
         5. STATISTIC LET SUB-COMMANDS
         6. MATH LET SUB-COMMANDS
            The following MATH LET sub-commands are not allowed:

            a. MATRIX sub-commands
            b. DERIVATIVE
            c. NUMERICAL DERIVATIVE
            d. INTEGRAL
            e. RUNGE-KUTTA
            f. OPTIMIZE
            g. ROOTS

    The arithmetic operations and statistics LET sub-commands are of
    particular interest.  Commands that are not supported are not added
    to the statistic block during the CAPTURE operation.  Up to 30
    commands can be saved to a given statistic block.

Syntax 1:
    CAPTURE STATISTIC BLOCK <one/two/three> <name>  <resp> <variable list>
    where <one/two/three> specifies which statistic block is being created;
          <name> is the name of the statistic block;
          <resp> is the name of parameter that is the result of the
                statistic block;
    and where <variable list> is a list of 1 to 3 variable names that are
                used to compute the statistic.

    This syntax is used to create the contents of a statistic block.
 
Syntax 2:
    LIST STATISTIC BLOCK <one/two/three>
    where <one/two/three> specifies which statistic block is being listed.

    This syntax is used to list the contents of a statistic block.

Examples:
    capture statistic block one zzzzsd a y
    let n = size y
    let ysum = sum y
    let ymean = ysum/n
    let y2 = (y - ymean)**2
    let y2sum = sum y2
    let a = sqrt(y2sum/(n-1))
    end of capture

Note:
    Error checking (e.g., matching parenthesis, valid number of
    arguments for a built-in function) is performed when the statistic
    block is evaluated, not when it is created.

Note:
    There may be cases where you cannot create the needed statistic even
    with the STATISTIC BLOCK command.  The LET ... = EXECUTE ... command
    can be used to run an external prorgram.  That is, your statistic
    block can use the EXECUTE command to compute the desired statistic.
    You can create the external program in whatever language is most
    convenient for your application.  The basic requirement is that the
    resulting external file can be run from the command line and that it
    can read from standard input and write to standard output.

    This is demonstrated in the Program 2 example below.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET              = Carries out a variety of operations on variables,
                       parameters, and functions.
    LET FUNCTION     = Define a function.
    FUNCTION BLOCK   = Define a function block.
    EXECUTE          = Run an external program.
    CAPTURE          = Re-direct Dataplot output to an external file.
 
Applications:
    Statistics
 
Implementation Date:
    2016/08
 
Program 1:
    skip 25
    read gear.dat y x
    skip 0
    .
    . Step 2:   Define the statistic block
    .
    capture statistic block one zzzzsd a y
    let n = size y
    let ysum = sum y
    let ymean = ysum/n
    let y2 = (y - ymean)**2
    let y2sum = sum y2
    let a = sqrt(y2sum/(n-1))
    end of capture
    .
    xlimits 1 10
    major xtic mark number 10
    x1tic mark offset 0.5 0.5
    x1label Batch
    y1label SD of Batch
    line blank
    char X
    .
    multiplot corner coordinates 2 2 98 98
    multiplot scale factor 2
    multiplot 2 1
    title automatic
    .
    zzzzsd plot y x
    sd     plot y x
    .
    end of multiplot

Program 2:
    . Step 1:   Read the data
    .  
    skip 25
    read gear.dat y x
    skip 0
    .
    . Step 2:   Create and compile the Fortran code
    .
    capture script exec.for
          program test
    c
    c     For this simple example, read in a data set and
    c     compute the mean and standard deviation.
    c
          real x(10000)
    c
          xmean=0.0
          xsd=0.0
          nval=0
          read(*,*,end=19,err=9020)nval
    c
          sum1=0.0
          do 10 i=1,min(nval,10000)
             read(*,*,end=19,err=9020)x(i)
             sum1=sum1 + x(i)
       10 continue
       19 continue
          if(nval.ge.1)then
            xmean=sum1/real(nval)
          endif
    c
          if(nval.gt.1)then
            sum1=0.0
            do 20 i=1,nval
               sum1=sum1 + (x(i)-xmean)**2
      20    continue
            xsd=sqrt(sum1/real(nval-1))
          endif
    c
    c     Now write sd to standard output
    c
     9020 continue
          write(*,*)xsd
    c
          stop
          end
    end of capture
    .
    system gfortran -o exec.exe  exec.for
    .
    . Step 3:   Define the statistic block
    .
    capture statistic block one zzzzsd a y
    let ztemp = execute ./exec.exe y
    let a = ztemp(1)
    end of capture
    .
    xlimits 1 10
    major xtic mark number 10
    x1tic mark offset 0.5 0.5
    x1label Batch
    y1label SD of Batch
    line blank
    char X
    .
    multiplot corner coordinates 2 2 98 98
    multiplot scale factor 2
    multiplot 2 1
    title automatic
    .
    zzzzsd plot y x
    sd     plot y x
    .
    end of multiplot

-----STATISTIC PLOT---------------------------------------------------
 
STATISTIC PLOT
 
Name:
    ... STATISTIC PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a statistic versus index plot for a given statistic.
 
Description:
    A statistic plot consists of subsample statistic versus subsample
    index.  The subsample statistic is the value of some statistic for
    the data in the subsample.  The statistic plot is used to answer the
    question--"Does the subsample statistic change over different
    subsamples?".  The plot consists of:

       Vertical   axis = subsample statistic;
       Horizontal axis = subsample index.

    The statistic plot yields 2 traces:

       1. a subsample statistic trace; and
       2. a full-sample statistic reference line.

    The appearance of these two traces is controlled by the first two
    settings of the LINES, CHARACTERS, SPIKES, BARS, and similar
    attributes.
 
Syntax 1:
    <stat> STATISTIC PLOT  <y1> ... <yk>  <x>
                           <SUBSET/EXCEPT/FOR qualification>
    where <stat> is one of Dataplot's supported statistics;
          <y1> ... <yk> is a list of 1 to 3 response variables
              (<stat> determines how many response variables);
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    For a list of supported statistics, enter

          HELP STATISTICS

Syntax 2:
    <stat> STATISTIC PLOT  <y1> ... <yk>  <x>
                           <SUBSET/EXCEPT/FOR qualification>
    where <stat> is one of Dataplot's supported statistics;
          <y1> ... <yk> is a list of 1 to 30 response variables;
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used for multiple response variables.  See the
    Note section below for details on this syntax.

Syntax 3:
    <stat> STATISTIC TAG PLOT <y>  <x> <tag>
                              <SUBSET/EXCEPT/FOR qualification>
    where <stat> is one of Dataplot's supported statistics;
          <y1> ... <yk> is a list of 1 to 3 response variables
              (<stat> determines how many response variables);
          <x> is the subsample identifier variable (this variable
              appears on the horizontal axis);
          <tag> is group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    For this syntax, there are two group variables.  The <x>
    variable is used as in syntax 1.  That is, this variable
    is used to define the sub-groups for computing the statistic.
    In syntax 1, there are two plot traces created.  The first
    contains the statistic value for each group and the second
    contains the statistic for the full data set.  With this
    syntax, the <tag> variable is used to define groups with the
    same plot attributes.  For example, if <tag> contains three
    distinct values (1, 2, and 3), there will be four plot traces
    created.  The first trace is for groups (<x>) where the
    corresponding <tag> value is 1, the second trace is where the
    corresponding <tag> value is 2, the third trace is where the
    corresponding <tag> value is 3, and the fourth trace is
    the statistic for the full data set.

    The <tag> value should be the same for all rows in a
    group defined by <x>.  However, if this is not the case,
    the <tag> value corresponding to the first row in <x> for
    that group will be used.

    This syntax is used to highlight certain groups.  For
    example, groups that denote potential outliers might be
    highlighted in a different color.

    This syntax is demonstrated in the Program 3 example.

Examples:
    MEAN PLOT Y X
    STANDARD DEVIATION PLOT Y X1
    MEAN PLOT Y1 TO Y5 X
    MEAN TAG PLOT Y X TAG
 
Note:
    A number of the subcommands (e.g., MEAN PLOT) are documented
    individually.
 
Note:
    Although DATAPLOT supports this command for a large number of
    statistics, there may be cases where you want it for another one.
    The following example shows how to compute the rank correlation
    (assume Y1 and Y2 are the response variables and TAG is the group
    identifier).

        LET TAGDIST = DISTINCT TAG
        LET NGROUP = SIZE TAGDIST
        LOOP FOR K = 1 1 NGROUP
            LET IGROUP TAGDIST(K)
            LET A = RANK CORRELATION Y1 Y2 SUBSET TAG = IGROUP
            LET YNEW(K) = A
            LET XNEW(K) = K
        END OF LOOP
        LET A = RANK CORRELATION Y1 Y2
        LET YNEW2 = DATA A A
        LET XNEW2 = DATA 1 NGROUP
        PLOT YNEW XNEW AND
        PLOT YNEW2 XNEW2

    This basic idea can be easily adapted to other statistics (even ones
    that are not built-in to DATAPLOT).  It can also be adapted to
    statistics requiring any arbitrary number of variables to compute.
 
    The 2016/08 version of Dataplot added the STATISTIC BLOCK
    command that can be used to define a statistic.

Note:
    The 2009/05 version of Dataplot updated the <stat> PLOT command to
    support multiple response variables (Syntax 2).  For example,

        MEAN PLOT Y1 TO Y4 X

    That is, for each distinct value of X, there are now 4 means
    plotted instead of just one.

    The following commands can be used to control the appearance of
    the plot:

        SET STATISTIC PLOT FORMAT   <DEX/OVERLAY>
        SET STATISTIC PLOT SUMMARY  <VARIABLE/GROUP>

    If the FORMAT option is set to OVERLAY and the SUMMARY option
    is set to VARIABLE, this is equivalent to the following:

        YLIMITS ...
        PRE-ERASE OFF
        ERASE
        MEAN PLOT Y1 X
        MEAN PLOT Y2 X
        MEAN PLOT Y3 X
        MEAN PLOT Y4 X
        PRE-ERASE ON

    That is, there will be a curve corresponding to each response
    variable and there will be a reference line corresponding to
    each variable.

    If the FORMAT option is set to DEX, then this plot uses a
    format similar to the DEX <stat> PLOT command.  That is, for
    each distinct value of X, there will be curve connecting the
    mean values for the 4 response variables.

    If the SUMMARY option is set to GROUP, there will be a single
    reference curve.  At each distinct value of X, a single overall
    mean is computed for all 4 of the response variables.

    In addition, the following option is added to this command:

        <stat> <zscore/uscore> PLOT

    If ZSCORE is given, then a z-score transformation (subtract the
    mean and then divide by the standard deviation) is computed
    on each response variable first.  If USCORE is given, then a
    u-score transformation (subtract the minimum and divide by the
    range) is computed on each column.  Note these z-score and
    u-score transformations apply to the entire response variable, not
    to each distinct group within the response variable.

Note:
    By default, Dataplot draws a reference line where the vertical
    axis coordinate is the value of the statistic for all of the
    data.

    For some statistics (e.g., STANDARD DEVIATION and other scale
    statistics), this may not be particularly meaningful.  Alternatively
    you can specify either the mean or the median value of the
    statistic over the groups.  For example, if you are generating
    a standard deviation plot and you have 10 groups, you can
    specify that the reference line be drawn at the mean (or the
    median) of the 10 computed standard deviations.

    To specify what reference line is drawn, enter

         SET STATISTIC PLOT REFERENCE LINE <OVERALL/AVERAGE/MEDIAN>

    where OVERALL is the value of the statistic for all of the data,
    AVERAGE is the mean of the statistic over the groups, and
    MEDIAN is the median of the statistic over the groups.

    The default is OVERALL.

Default:
    None
 
Synonyms:
    On most of the commands, the word STATISTIC is optional and is
    usually omitted (e.g., the mean plot is documented under MEAN PLOT
    rather than MEAN STATISTIC PLOT).
 
Related Commands:
    CHARACTERS              = Sets the type for plot characters.
    LINES                   = Sets the type for plot lines.
    BOX PLOT                = Generates a box plot.
    CONTROL CHART           = Generates a control chart.
    PLOT                    = Generates a data or function plot.
    SUMMARY                 = Computes various statistics for a
                              variable.
    STATISTIC BLOCK         = Define a new statistic.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    1988/02
    2009/04: support for multiple response variables
    2015/04: added SET STATISTIC PLOT REFERENCE LINE
    2018/02: support for a tag variable (Syntax 3)

    The list of supported statistics has been regulary updated
    since the original 1988/2 implementation.
 
Program 1:
    SKIP 25
    READ GEAR.DAT DIAMETER BATCH
    .
    TITLE AUTOMATIC
    TITLE OFFSET 2
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 3 0 100 100
    MULTIPLOT SCALE FACTOR 2
    X1LABEL DISPLACEMENT 14
    Y1LABEL DISPLACEMENT 12
    TIC MARK LABEL SIZE 1.8
    .
    XTIC OFFSET 1 1
    X1LABEL BATCH
    LINE BLANK SOLID
    CHARACTER X BLANK
    Y1LABEL MEAN
    TITLE MEAN PLOT
    MEAN PLOT DIAMETER BATCH
    Y1LABEL STANDARD DEVIATION
    TITLE SD PLOT
    STANDARD DEVIATION PLOT DIAMETER BATCH
    Y1LABEL RELATIVE STANDARD DEVIATION
    TITLE RELSD PLOT
    RELSD PLOT DIAMETER BATCH
    Y1LABEL RANGE
    TITLE RANGE PLOT
    RANGE PLOT DIAMETER BATCH
    .
    END OF MULTIPLOT
 
Program 2:
    skip 25
    read iris.dat y1 to y4 x
    .
    title case asis
    title offset 2
    label case asis
    y1label Mean
    x1label Group-ID
    xlimits 1 3
    major xtic mark number 3
    minor xtic mark number 0
    xtic offset 0.6 0.6
    ytic offset 1 1
    .
    set stat plot format  dex
    set stat plot summary vari
    title sp()Case 1: Format = DEX, Summary = Variable
    line color black black black blue red green cyan
    mean plot y1 to y4 x
    title sp()Case 1b: Z-Score - Format = DEX, Summary = Variable
    mean zscore plot y1 to y4 x
    .
    set stat plot format  dex
    set stat plot summary group
    title sp()Case 2: Format = DEX, Summary = Group
    mean plot y1 to y4 x
    title sp()Case 2: Z-Score - Format = DEX, Summary = Group
    mean zscore plot y1 to y4 x
    .
    set stat plot format overlay
    set stat plot summary group
    line color blue red green cyan
    line so so so so bl
    char bl bl bl bl x
    title sp()Case 3: Format = Overlay, Summary = Group
    mean plot y1 to y4 x
    title sp()Case 3: Z-Score Format = Overlay, Summary = Group
    mean zscore plot y1 to y4 x
    .
    set stat plot format overlay
    set stat plot summary variable
    line so all
    char bl all
    line color blue red green cyan blue red green cyan
    title sp()Case 4: Format = Overlay, Summary = Variable
    mean plot y1 to y4 x
    title sp()Case 4: Z-Score - Format = Overlay, Summary = Variable
    mean zscore plot y1 to y4 x

Program 3:
    . Name:     meantag.dp
    . Purpose:  Test "tag" option on statistic plot case
    .
    . Step 0:   Define output devices
    .
    let string fplot = meantag.ps
    set ipl1na ^fplot
    call checksys.dp
    .
    . Step 1:   Read the data
    .
    skip 25
    read gear.dat y x
    skip 0
    let tag = sequence 1 10 1 2 for i = 1 1 100
    .
    . Step 2:   Define plot control settings
    .
    case asis
    label case asis
    title case asis
    title offset 2
    .
    xlimits 1 10
    major x1tic mark number 10
    minor x1tic mark number  0
    tic offset units data
    x1tic mark offset 0.5 0.5
    .
    title Mean Plot of GEAR.DAT
    y1label Mean Diameter
    x1label Batch
    .
    . Step 3:   Generate the plot without tags
    .
    character circle blank
    character fill on
    character hw 1.0 0.75 all
    line blank solid
    mean plot y x
    .
    . Step 4:   Generate the plot with tags
    .
    character circle circle blank
    character fill on on
    character hw 1.0 0.75 all
    character color blue red
    line blank blank solid
    .
    . mean tag plot y x tag
    mean character plot y x tag

-----<dist> PPCC------------------------------------------------
 
STATISTIC PPCC
 
Name:
    <dist> PPCC
 
Type:
    LET Subcommand
 
Purpose:
    Compute the probability plot correlation coefficient (also
    called the ppcc) value for a variable for a specified distribution.
 
Description:
    The ppcc value is the correlation coefficient of the straight line
    fitted to a probability plot (see the documentation for PPCC PLOT for
    details).

    Although this value is normally determined using either a probability
    plot or a ppcc plot, for a limited number of distributions you can
    also generate this as a statistic LET subcommand.  The advantage in
    this case is that you can use it with any of the commands that
    support built-in statistics (e.g., the STATISTIC PLOT or the
    TABULATION command).

    This command was updated 2013/02 in the following ways.

        1. In addition to the PPCC value, you can now extract the
           estimates of the location and scale parameters based on
           the probability plot.  See Syntax 2 and Syntax 3 below.

        2. For certain one and two shape parameter distritutions, you
           can extract the shape parameter based on the
           PPCC plot/probability plot method.

           In using these commands, the shape parameter can be
           be handled in one of two ways.

              a. You can assume a fixed shape parameter.  For example,

                     LET GAMMA = 2.6
                     WEIBULL PPCC STATISTIC PLOT Y X

                 This command will plot the ppcc value for a Weibull
                 distribution with a shape parameter of 2.6 for the
                 groups defined by the X variable.

              b. No shape parameter will be pre-defined.

                 In the example above, if GAMMA is not pre-defined then
                 the shape parameter will be estimated using the PPCC
                 plot method (this is done in the background) for each
                 distinct group.

           See the Note section below for a list of supported
           distributions.

Syntax 1:
    LET <par> =  <dist>  PPCC  <y>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <dist> is one of the distributions listed in the Note section
                 below;
          <par> is the parameter where the ppcc value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <par> =  <dist>  PPCC LOCATION  <y>
                 <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <dist> is one of the distributions described in the Note
              section below;
          <par> is the parameter where the location value is
              saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax returns the estimate of the location parameter rather
    than the PPCC value.

Syntax 3:
    LET <par> =  <dist>  PPCC SCALE  <y>
                 <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <dist> is one of the distributions described in the Note
              section below;
          <par> is the parameter where the normal location value is
              saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax returns the estimate of the location parameter rather
    than the PPCC value.

Syntax 4:
    LET <par> =  <dist>  PPCC  STATISTIC  <y>
                 <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <dist> is one of the distributions with shape parameters
              described in the Note section below;
          <par> is the parameter where the normal ppcc value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    When the distribution has a shape parameter, then the word
    STATISTIC is required to distinguish this command from the
    PPCC PLOT command.  Specifically the following can conflict

       WEIBULL PPCC PLOT Y
       WEIBULL PPCC STATISTIC PLOT Y X
 
    The first command is the Weibull PPCC plot while the second
    command plots the PPCC value for Y for each group in X.

Syntax 5:
    LET <par> =  <dist>  PPCC SHAPE  <y>
                 <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <dist> is one of the distributions with a single shape
              parameters described in the Note section below;
          <par> is the parameter where the normal ppcc value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax returns the estimate of the shape parameter rather
    than the PPCC value.

Syntax 6:
    LET <par> =  <dist>  PPCC SHAPE ONE  <y>
                 <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <dist> is one of the distributions with two shape
              parameters described in the Note section below;
          <par> is the parameter where the normal ppcc value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax returns the estimate of the first shape parameter
    rather than the PPCC value.

Syntax 7:
    LET <par> =  <dist>  PPCC SHAPE TWO  <y>
                 <SUBSET/EXCEPT/FOR qualification>
    where <y> is a response variable;
          <dist> is one of the distributions with two shape
              parameters described in the Note section below;
          <par> is the parameter where the normal ppcc value is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax returns the estimate of the second shape parameter
    rather than the PPCC value.

Examples:
    LET A = LOGISTIC PPCC Y
    LET A = DOUBLE EXPONENTIAL PPCC Y SUBSET Y > -3
 
Note:
    The following location/scale distributions are supported.

       LET A = ANGLIT PPCC              Y
       LET A = ARCSINE PPCC             Y
       LET A = CAUCHY PPCC              Y
       LET A = COSINE PPCC              Y
       LET A = DOUBLE EXPONENTIAL PPCC  Y
       LET A = EXPONENTIAL PPCC         Y
       LET A = HALF CAUCHY PPCC         Y
       LET A = HALF NORMAL PPCC         Y
       LET A = HYPERBOLIC SECANT PPCC   Y
       LET A = LOGISTIC PPCC            Y
       LET A = MAXWELL PPCC             Y
       LET A = MAXIMUM GUMBEL PPCC      Y
       LET A = MINIMUM GUMBEL PPCC      Y
       LET A = MAXWELL PPCC             Y
       LET A = NORMAL PPCC              Y
       LET A = RAYLEIGH PPCC            Y
       LET A = SEMICIRCULAR PPCC        Y
       LET A = SLASH PPCC               Y
       LET A = UNIFORM PPCC             Y

    In addition, the following distributions with a single shape
    parameter are supported.  If you want a fixed value of the
    shape parameter, you can specify it as shown here:

       LET GAMMA = <value>
       LET A = WEIBULL PPCC STATISTIC Y
       LET A = 2PARAMETER WEIBULL PPCC STATISTIC Y

       LET GAMMA = <value>
       LET A = INVERTED WEIBULL PPCC STATISTIC Y

       LET GAMMA = <value>
       LET A = GAMMA PPCC STATISTIC Y

       LET GAMMA = <value>
       LET A = WALD PPCC STATISTIC Y

       LET GAMMA = <value>
       LET A = FATIGUE LIFE PPCC STATISTIC Y

       LET GAMMA = <value>
       LET A = GENERALIZED PARETO PPCC STATISTIC Y

       LET SIGMA = <value>
       LET A = LOGNORMAL PPCC STATISTIC Y

       LET LAMBDA = <value>
       LET A = TUKEY LAMBDA PPCC STATISTIC Y

       LET G = <value>
       LET A = G PPCC STATISTIC Y

    In addition, the following distribution with two shape
    parameters is supported.  If you want fixed values of the
    shape parameters, you can specify it as shown here:

       LET G = <value>
       LET H = <value>
       LET A = G AND H PPCC STATISTIC Y

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STATISTIC PLOT      = Generates a statistic versus subset plot.
    CROSS TABULATE      = Compute a statistic based on a cross-tabulation.
    PPCC PLOT           = Generates a probability plot correlation
                          coefficient plot.
    PROBABILITY PLOT    = Generates a probability plot.
 
Reference:
    James J. Filliben (1975), "The Probability Plot Correlation Coefficient
    Test for Normality," Technometrics, Vol. 17, No. 1.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    2011/06
    2013/02: Support for location, scale and shape parameters
    2013/02: Support for additional distributions
    2015/02: Support for g distribution
    2016/06: Support for 2-parameter Weibull
 
Program 1:
    SKIP 25
    READ GEAR.DAT  Y X
    .
    LABEL CASE ASIS
    Y1LABEL Correlation
    X1LABEL Batch
    Y1LABEL DISPLACEMENT 15
    X1LABEL DISPLACEMENT 12
    TITLE CASE ASIS
    TITLE OFFSET 2
    XLIMITS 1 10
    X1TIC MARK OFFSET 0.5 0.5
    Y1LIMITS 0.92 0.99
    TIC MARK OFFSET UNITS DATA
    LINE BLANK SOLID
    CHARACTER X BLANK
    .
    MULTIPLOT CORNER COORDIANTES 2 2 98 98
    MULTIPLOT SCALE FACTOR 2
    MULTIPLOT 2 2
    .
    TITLE Normal PPCC Values
    NORMAL PPCC PLOT Y X
    TITLE Logistic PPCC Values
    LOGISTIC PPCC PLOT Y X
    TITLE Double Exponential PPCC Values
    DOUBLE EXPONENTIAL PPCC PLOT Y X
    TITLE Uniform PPCC Values
    UNIFORM PPCC PLOT Y X
    .
    END OF MULTIPLOT

Program 2:
    skip 25
    read gear.dat y x
    .
    tic mark offset units screen
    tic mark offset 5 5
    char X
    line blank
    .
    multiplot scale factor 2
    multiplot corner coordinates 5 5 95 95
    .
    y1label displacement 16
    x1label displacement 12
    title offset 2
    label case asis
    title automatic
    x1label Batch
    .
    multiplot 2 2
    y1label Correlation
    normal ppcc statistic plot y x
    y1label Location
    normal ppcc location plot y x
    y1label Scale
    normal ppcc scale plot y x
    char X all
    line blank all
    y1label Raw Data
    plot y x x
    end of multiplot

-----STCDF (LET)--------------------------------
 
STCDF
 
Name:
    STCDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the skew-t cumulative distribution function.
 
Description:
    The skew-t distribution has the following probability density
    function:

       f(x,nu,lambda)=2*TCDF(lambda*x*SQRT((1+nu)/(x**2+nu)),nu+1)*
                      TPDF(x,nu)    -infinity < x, lambda < infinity
 
    For lambda = 0, the skew-t reduces to a t distribution.
    As lambda goes to infinity, the skew-t tends to the
    folded-t distribution.
 
    The cumulative distribution is computed by numerically
    integrating the skew-t probability density function.

    The standard skew-t distribution can be generalized with
    location and scale parameters.

Syntax:
    LET <y> = STCDF(<x>,<nu>,<lambda>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <nu> is a number of parameter that specifies the
              value of the degrees of freedom shape parameter;
          <lambda> is a number of parameter that specifies the
              value of the skewness shape parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed skew-t cdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = STCDF(3,5,1)
    LET A = STCDF(A1,DF,LAMBDA)
    LET X2 = STCDF(X1,NU,0.5)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STPDF  = Compute the skew-t probability density function.
    STPPF  = Compute the skew-t percent point function.
    SNPDF  = Compute the skew-normal probability density function.
    TPDF   = Compute the t probability density function.
    FTPDF  = Compute the folded t probability density function.
    NORPDF = Compute the normal density function.
    CHSPDF = Compute the chi-square probability density function.
 
Reference:
    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

    "Log-Skew-Normal and Log-Skew-t Distributions as Models for
    Familiy Income Data", Azzalini and Dal Cappello,
    unpublished paper downloaded from Azzallini web site.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1/2004
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE SKEW-T (NU=3): LAMBDA = 0
    PLOT STCDF(X,3,0) FOR X = -5 0.1 5
    TITLE SKEW-T (NU=3): LAMBDA = 1
    PLOT STCDF(X,3,1) FOR X = -5 0.1 5
    TITLE SKEW-T (NU=3): LAMBDA = 5
    PLOT STCDF(X,3,5) FOR X = -5 0.1 5
    TITLE SKEW-T (NU=3): LAMBDA = 10
    PLOT STCDF(X,3,10) FOR X = -5 0.1 5
    END OF MULTIPLOT
 
-----STEM AND LEAF PLOT-----------------------------------------------
 
STEM AND LEAF PLOT
 
Name:
    STEM AND LEAF PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a stem and leaf plot.
 
Description:
    A stem and leaf plot is a graphical data analysis technique for
    summarizing the distributional information of a variable.  It is
    similar to a histogram, but it preserves the original numeric
    values in the data.  As such, it is an effective alternative to
    the histogram for small to moderate size data sets.  It is not
    recommended for large data sets.
 
Syntax:
    STEM AND LEAF PLOT   <x>   <SUBSET/EXCEPT/FOR qualification>
    where <x> is the variable of raw data values;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    STEM AND LEAF PLOT TEMP
 
Note:
    Although the stem and leaf plot is a graphics command, the
    plot is generated as alphanumeric output, not as graphics output.
    This means that if device 2 is on, the stem and leaf plot is not
    generated in the plot file DPPL1F.DAT.  The CAPTURE command can
    be used to direct the stem and leaf output to a text file.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    FREQUENCY PLOT     = Generates a frequency plot.
    HISTOGRAM          = Generates a histogram.
    PIE CHART          = Generates a pie chart.
    PERCENT POINT PLOT = Generates a percent point plot.
    PROBABILITY PLOT   = Generates a probability plot.
    PPCC PLOT          = Generates probability plot correlation
                         coefficient plot.
    CAPTURE            = Redirect alphanumeric output to a file.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    Pre-1987
 
Program:
    SKIP 25
    READ GEAR.DAT DIAMETER
    .
    CAPTURE STEM_LEAF_OUT.DAT
    STEM AND LEAF PLOT DIAMETER
    END OF CAPTURE
 
    The following output is generated:
 
      97 :
      98 : 01244
      98 : 788
      99 : 00111123344444
      99 : 5555566666666666666677777788888888888889999
      00 : 000000000122222222224444
      00 : 56666699
      01 : 03
      01 : 8
 
-----STATUS-------------------------------------------------------
 
STATUS
 
Name:
    STATUS
 
Type:
    Support Command
 
Purpose:
    Prints the current character types, line type variable names,
    parameter values, functions, etc.
 
Syntax 1:
    STATUS
 
    This lists all status information.
 
Syntax 2:
    STATUS <keyword>
    where <keyword> is one of the following:
             MACHINE      - print host name and machine constants
             FILE         - print DATAPLOT file names
             ARROWS       - print current ARROW settings
             SEGMENTS     - print current SEGMENT settings
             LEGENDS      - print current LEGEND settings
             BOXES        - print current BOX settings
             SPIKES       - print current SPIKE settings
             BARS         - print current BAR settings
             DIMENSION    - print current dimension settings
             CHARACTERS   - print current CHARACTER settings
             LINES        - print current LINE settings
             VARIABLES    - print information on currently defined
                            variables
             PARAMETERS   - print information on currently defined
                            parameters
             FUNCTIONS    - print the currently defined functions
             MATRICES     - print information on currently defined
                            matrices.
 
Syntax 3:
    STATUS VARIABLES <a>
    where <a> is a single alphabetic character.

    This syntax displays all variables beginning with the letter
    <a>.  For example, STATUS VARIABLES X displays all variables
    beginning with the letter X.  This can be useful when you have
    created a large number of variables.

Syntax 4:
    GUI STATUS VARIABLE

    This is a special form of the command that is sent by the Tcl/Tk
    scripts for the Dataplot Graphical User Interface (GUI).  If this
    command is entered directly by the Dataplot user, it is equivalent
    to entering a STATUS VARIABLES command.

    The command

        SET GUI FEEDBACK <ON/OFF>

    is used to set the FEEDBACK switch for this command.

Examples:
    STATUS
    STATUS VARIABLES
    STATUS VARIABLES  X
    STATUS V X
    STATUS PARAMETERS
 
Note:
    If the variable status is requested, the following information will
    be written to "dpst1f.dat".


       1) Line 1 will contain the number of currently defined variables.

       2) For each currently defined variable, the succeeding lines will
          contain

           a) The variable name
           b) The number of observations
           c) The number of distinct observations
           d) The first 10 distinct values

Default:
    None
 
Synonyms:
    LS is a synonym for STATUS
 
Related Commands:
    RESET        = Reset DATAPLOT internal parameters, variables,
                   functions, and switches to their default values.
 
Applications:
    Interactive Usage
 
Implementation Date:
    Pre-1987
    1991/12: Support for STATUS <keyword> syntax
    2010/07: Support for Syntax 3
    2010/09: Added LS as a synonym
    2014/11: Write variable list to dpst1f.dat
    2015/12: Additional info to dpst1f.dat
 
Program:
    SKIP 25
    READ BERGER1.DAT Y X BAT
    STATUS VARIABLES
 
-----STEP (LET)--------------------------------
 
STEP
 
Name:
    STEP (LET)
 
Type:
    Library Function
 
Purpose:
    Return the integer portion of a number or variable rounded to
    positive integer.
 
Syntax:
    LET <y2> = STEP(<y1>)  <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a variable or a parameter;
          <y2> is a variable or a parameter (depending on what <y1>
               is) where the computed integer values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = STEP(2.83)
    LET A = STEP(A1)
    LET X2 = STEP(X1)
    LET X2 = STEP(X1-4.2)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    FLOOR
 
Related Commands:
    CEIL   = Compute the integer value rounded to positive infinity.
    INT    = Compute the integer value rounded to zero.
    SIGN   = Compute the sign of a number.
    FRACT  = Compute the fractional portion of number.
    MSD    = Compute the most significant digit of a number.
    ROUND  = Round to the closest integer of a number.
 
Applications:
    Elementary function
 
Implementation Date:
    95/4
 
Program:
    LET Y1 = SEQUENCE -5 0.1 5
    LET Y2 = STEP(Y1)
    PRINT Y1 Y2
 
-----STOP-------------------------------------------------------
 
STOP
 
Name:
    STOP
 
Type:
    Support Command
 
Purpose:
    Terminates a DATAPLOT run.
 
Syntax:
    STOP
 
Examples:
    STOP
 
Default:
    None
 
Synonyms:
    EXIT, END, HALT, QUIT
 
Related Commands:
    XX
 
Applications:
    Interactive Usage
 
Implementation Date:
    Pre-1987
 
Program:
    XX
 
-----STPDF (LET)--------------------------------
 
STPDF
 
Name:
    STPDF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the skew-t probability density function.
 
Description:
    The skew-t distribution has the following probability density
    function:

       f(x,nu,lambda)=2*TCDF(lambda*x*SQRT((1+nu)/(x**2+nu)),nu+1)*
                      TPDF(x,nu)    -infinity < x, lambda < infinity
 
    For lambda = 0, the skew-t reduces to a t distribution.
    As lambda goes to infinity, the skew-t tends to the
    folded-t distribution.
 
    The standard skew-t distribution can be generalized with
    location and scale parameters.

Syntax:
    LET <y> = STPDF(<x>,<nu>,<lambda>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <x> is a variable or a parameter;
          <nu> is a number of parameter that specifies the
              value of the degrees of freedom shape parameter;
          <lambda> is a number of parameter that specifies the
              value of the skewness shape parameter;
          <y> is a variable or a parameter (depending on what <x> is)
               where the computed skew-t pdf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = STPDF(3,5,1)
    LET A = STPDF(A1,DF,LAMBDA)
    LET X2 = STPDF(X1,NU,0.5)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STCDF  = Compute the skew-t cumulative distribution function.
    STPPF  = Compute the skew-t percent point function.
    SNPDF  = Compute the skew-normal probability density function.
    TPDF   = Compute the t probability density function.
    FTPDF  = Compute the folded t probability density function.
    NORPDF = Compute the normal density function.
    CHSPDF = Compute the chi-square probability density function.
 
Reference:
    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

    "Log-Skew-Normal and Log-Skew-t Distributions as Models for
    Familiy Income Data", Azzalini and Dal Cappello,
    unpublished paper downloaded from Azzallini web site.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1/2004
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE SKEW-T (NU=3): LAMBDA = 0
    PLOT STPDF(X,3,0) FOR X = -5 0.1 5
    TITLE SKEW-T (NU=3): LAMBDA = 1
    PLOT STPDF(X,3,1) FOR X = -5 0.1 5
    TITLE SKEW-T (NU=3): LAMBDA = 5
    PLOT STPDF(X,3,5) FOR X = -5 0.1 5
    TITLE SKEW-T (NU=3): LAMBDA = 10
    PLOT STPDF(X,3,10) FOR X = -5 0.1 5
    END OF MULTIPLOT
 
-----STPPF (LET)--------------------------------
 
STPPF
 
Name:
    STPPF (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the skew-t percent point function.
 
Description:
    The skew-t distribution has the following probability density
    function:

       f(x,nu,lambda)=2*TCDF(lambda*x*SQRT((1+nu)/(x**2+nu)),nu+1)*
                      TPDF(x,nu)    -infinity < x, lambda < infinity
 
    For lambda = 0, the skew-t reduces to a t distribution.
    As lambda goes to infinity, the skew-t tends to the
    folded-t distribution.
 
    The skew-t percent point function is computed numerically
    (by inverting the skew-t cdf function with the bisection
    method).

    The standard skew-t distribution can be generalized with
    location and scale parameters.

Syntax:
    LET <y> = STPPF(<p>,<nu>,<lambda>)
                                <SUBSET/EXCEPT/FOR qualification>
    where <p> is a variable or a parameter in the range [0,1];
          <nu> is a number of parameter that specifies the
              value of the degrees of freedom shape parameter;
          <lambda> is a number of parameter that specifies the
              value of the skewness shape parameter;
          <y> is a variable or a parameter (depending on what <p> is)
               where the computed skew-t ppf value is stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = STPPF(0.95,5,1)
    LET A = STPPF(A1,DF,LAMBDA)
    LET X2 = STPPF(P1,NU,0.5)
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STCDF  = Compute the skew-t cumulative distribution function.
    STPDF  = Compute the skew-t probability density function.
    SNPDF  = Compute the skew-normal probability density function.
    TPDF   = Compute the t probability density function.
    FTPDF  = Compute the folded t probability density function.
    NORPDF = Compute the normal density function.
    CHSPDF = Compute the chi-square probability density function.
 
Reference:
    "A Class of Distributions Which Includes the Normal Ones",
    Azzalini, Scandinavian Journal of Statistics, 12, 171-178.

    "Log-Skew-Normal and Log-Skew-t Distributions as Models for
    Familiy Income Data", Azzalini and Dal Cappello,
    unpublished paper downloaded from Azzallini web site.
 
Applications:
    Distributional Modeling
 
Implementation Date:
    1/2004
 
Program:
    MULTIPLOT 2 2
    MULTIPLOT CORNER COORDINATES 0 0 100 100
    TITLE SKEW-T (NU=3): LAMBDA = 0
    PLOT STPPF(P,3,0) FOR P = 0.01  0.01  0.99
    TITLE SKEW-T (NU=3): LAMBDA = 1
    PLOT STPPF(P,3,1) FOR P = 0.01  0.01  0.99
    TITLE SKEW-T (NU=3): LAMBDA = 5
    PLOT STPPF(P,3,5) FOR P = 0.01  0.01  0.99
    TITLE SKEW-T (NU=3): LAMBDA = 10
    PLOT STPPF(P,3,10) FOR P = 0.01  0.01  0.99
    END OF MULTIPLOT
 
-----STREAM READ-------------------------------------------------------
 
STREAM READ
 
Name:
    STREAM READ
 
Type:
    Support Command
 
Purpose:
    Read data and perform certain computations for data sets that
    are too large to read into memory.
 
Description:
    Dataplot was designed primarily for interactive usage.  For this reason,
    it reads all data into memory.  The current default is to have a
    workspace that accomodates 10 columns with 1,500,000 rows (you can
    re-dimension to obtain more columns at the expense of fewer rows, however
    you cannot increase the maximum number of rows).

    With the advent of "big data", there are more data files that cannot be
    read into Dataplot's available memory.  For these data files, there are
    several things that can potentially be done

       1. For some platforms, if you have a large amount of memory you may
          be able to build a version of Dataplot that raises the maximum
          number of rows.  For example, on a Linux system with 64MB of RAM,
          we were able to build a version that supports a maximum of
          10,000,000 rows.  Contact Alan Heckert if you need assistance
          with this.
    
       2. The STREAM READ command was added.  This command uses one pass
          algorithms to do a number of things.
    
          a. You can create a new file that uses SET WRITE FORMAT.  This
             is typically done once so that you can use SET READ FORMAT on
             subsequent reading of the data file (this can substantially
             speed up processing of these large files).

          b. You can generate various summary statistics either for the
             full data set or for groups in the data.

          c. You can generate cross tabulation statistics (up to 4 cross
             tabulation variables can be specified).

          d. You can create various types of distance or similarity
             (e.g., Euclidean distances, correlation) matrices either for
             the full data set or for cross tabulations of the data.

             Distance and similarity matrices are often used for various
             types of multivariate analysis.

          e. You can generate approximate percentiles either for the full
             data set or for cross tabulations of the data.  Based on this,
             you can perform distributional modeling for a single variable
             or distributional comparisons between variables (e.g.,
             quantile quantile plots, bihistograms, two sample KS tests,
             and so on).

          Although Dataplot may not be able to read many of these large
          data sets into memory, the STREAM READ command does allow you to
          perform certain types of exploratory analyses on these large data
          sets.

Syntax 1:
    STREAM READ WRITE <file>  <x1>  <x2> ... <xk>
    where <file> is the name of the file to read;
    and where <x1>, <x2>, ... <xk> is a list of variables to read.

    This version of the command is used to read the input file and to
    write a new version of the data using a specified Fortran-like format.

    This command is useful in the following way.  Large data files can
    take a long time to read.  If you can use the SET READ FORMAT command
    to read the data, this can significantly speed up the reading of the
    data.  For example, reading the data set used by the example programs
    below used 24.7 cpu seconds on a Linux machine running CentOS.
    Performing the same read on the same platform with a SET READ FORMAT
    required 0.6 cpu seconds.  Cpu times will vary depending on the
    hardware and operating system, but this is indicative of the relative
    performance improvement that can be obtained by using the SET READ
    FORMAT command.  This example file is not particularly large
    (361,920 rows).  The speed improvement becomes even more important
    when we start dealing with multiple millions of rows.  

    Often large data sets will initially not be in a format where the
    SET READ FORMAT can be used.  So this command can be used once, with
    the SET WRITE FORMAT command, to create a new version of the file that
    is formatted in a way that the SET READ FORMAT can be used.  This new
    file is then used for subsequent Dataplot sessions that use this data.

Syntax 2:
    STREAM READ GROUP STATISTICS <stat> <file> <x1> <x2> ... <xk>
    where <stat> is one of Dataplot's supported univariate statistics;
          <file> is the name of the file to read;
    and where <x1>, <x2>, ... <xk> is a list of variables to read.

    This syntax will read the file a user-specified number of rows at a
    time.  It will then replace those rows with the specified statistic.
    That is, the original data will be replaced with the specified
    statistic  for fixed intervals of the data.

    For example, you can read 1,000 rows, compute (and save) the mean
    for those 1,000 rows for each variable, then repeat for the next
    1,000 rows.  That is, the original data will be replaced with the
    means of fixed intervals of the data.

    To specify the number of rows to read at a time, enter

         SET STREAM READ SIZE <value>

    Alternatively, you can specify one of the variabes to define
    the group (i.e., when the value of the specified variable
    changes, this denotes the start of a new group).  For this
    option, enter

         SET STREAM READ GROUP VARIBLE <var-name>

    This capability is motivated by the desire to handle large data
    sets that may exceed Dataplot's storage limits.  This command
    allows you to compute some basic statistics (mean, minimum,
    maximum, standard deviation, and so on) for slices of the data.
    Often, some useful exploratory analysis can be performed on this
    compressed data.

    To see a list of supported univariate statistics, enter

         HELP STATISTICS

Syntax 3:
    STREAM READ DEFAULT STATISTICS <file>  <x1> <x2> ... <xk>
    where <file> is the name of te file to read;
    and where <x1>, <x2>, ... <xk> is a list of variables to read.

    This is a variant of Syntax 2 that allows a default set of statistics
    to be computed on a single pass of the data.

    This computes the statistic for slices of the data as in Syntax 2
    (it uses the SET STREAM READ SIZE and SET STREAM READ GROUP VARIABLE
    commands as in Syntax 2).

    The following statistics are computed:

         1. VALUE OF LAST ROW OF GROUP
         2. GROUP-ID
         3. SIZE
         4. MINIMUM
         5. MAXIMUM
         6. MEAN
         7. STANDARD DEVIATION
         8. SKEWNESS
         9. KURTOSIS
        10. MEDIAN
        11. INTERQUARTILE RANGE
        12. RANGE
        13. AUTOCORRELATION
        14. LOWER QUARTILE
        15. UPPER QUARTILE
        16. 0.01 QUANTILE
        17. 0.05 QUANTILE
        18. 0.10 QUANTILE
        19. 0.90 QUANTILE
        20. 0.95 QUANTILE
        21. 0.99 QUANTILE

    For this syntax, a tag variable (TAGSTAT) will be created that
    defines the statistic (i.e., each row of TAGSTAT contains a
    value from 1 to 21).  TAGSTAT can be used to exract the desired
    statistic for each group.

    If a group variable was specified, that variable will contain the
    group-id.  For example, if X is the group id variable and it has
    3 groups with values of 1, 2, and 3, then the X will have a value of
    1 in rows 1 to 21, a value of 2 in rows 22 to 42, and a value of 3
    in rows 43 to 63.

Syntax 4:
    STREAM READ FULL STATISTICS <file>  <x1> <x2> ... <xk>
    where <file> is the name of the file to read;
    and where <x1>, <x2>, ... <xk> is a list of variables to read.

    This syntax will compute the following statistics using 1-pass
    algorithms for all of the data:

         1. COUNT
         2. MINIMUM
         3. MAXIMUM
         4. MEAN
         5. STANDARD DEVIATION
         6. SKEWNESS
         7. KURTOSIS
         8. RANGE

    Each of the <x1> ... <xk> will have 8 rows containing the above
    eight statistics for each column read.

Syntax 5:
    STREAM READ CROSS TABULATE <file>  <var-list>
    where <file> is the name of the file to read;
    and where <x1>, <x2>, ... <xk> is a list of variables to read.

    This is similar to syntax 4.  However, instead of computing
    the statistics for the full data set, it will compute them for
    cross tabulations of the data.

    You can specify from one to four cross-tabulation variables
    with the commands

        SET STREAM READ CROSS TABULATE VARIABLE ONE <name>
        SET STREAM READ CROSS TABULATE VARIABLE TWO <name>
        SET STREAM READ CROSS TABULATE VARIABLE THREE <name>
        SET STREAM READ CROSS TABULATE VARIABLE FOUR <name>

    With this syntax, the following nine statistics will be computed
    for each cross-tabulation cell

         1. COUNT
         2. MINIMUM
         3. MAXIMUM
         4. MEAN
         5. STANDARD DEVIATION
         6. SKEWNESS
         7. KURTOSIS
         8. RANGE
         9. NUMBER OF MISSING VALUES

    For this syntax, a tag variable (TAGSTAT) will be created that
    defines the statistic (i.e., each row of TAGSTAT contains a
    value from 1 to 9).  TAGSTAT can be used to exract the desired
    statistic for each group.

    For each cell, 9 rows will be generated.  The variables defined as
    cross tabulation variables will simply have their value for that
    cell for all 9 rows.  For the variables that are not defined as
    cross tabulation variables, the 9 rows will contain the values of
    the above 9 statistics.

Syntax 6:
    STREAM READ <metric> <file>  <x1> <x2> ... <xk>
    where <file> is the name of the file to read;
          <metric> is one of the measures defined below;
    and where <x1>, <x2>, ... <xk> is a list of variables to read.

    With this option, the STREAM READ will return a distance, similarity,
    covariance, or correlation matrix.  The raw data is not saved.  For
    example,

         STREAM READ CORRELATION FILE.DAT Y1 Y2 Y3

    will return the 3 variables Y1, Y2, and Y3 where each of these variables
    will contain 3 rows.  For example, Y2(3) contains the correlation between
    the second response column and the third response column.

    The <metric> option can be any of the following

        EUCLIDEAN DISTANCE 
        MANHATTAN DISTANCE
        CHEBYCHEV DISTANCE
        CANBERRA DISTANCE
        HAMMING DISTANCE
        COSINE DISTANCE
        COSINE SIMILARITY
        ANGULAR COSINE DISTANCE
        ANGULAR COSINE SIMILARITY
        COVARIANCE
        CORRELATION

    This syntax will ignore character fields.  If you do not want some fields
    in the file to be included, you can do something like the following

        LET ITYPE = DATA 1 1 1 0 1
        SET STREAM READ VARIABLE TYPE ITYPE

    These commands specify that fields 1, 2, 3, and 5 will be included while
    field 4 will be excluded.  This can be useful if some of the fields are
    categorical variables where distance and covariance/correlation do not
    make sense.

Syntax 7:
    STREAM READ CROSS TABULATE <metric> <file>  <x1> <x2> ... <xk>
    where <file> is the name of the file to read;
          <metric> is one of measures specified in Syntax 6;
    and where <x1>, <x2>, ... <xk> is a list of variables to read.

    This is similar to Syntax 6.  However, the metric will be
    computed separately for each cross tabulation cell.

    The cross tabulation variables are specified as in Syntax 5.  This
    syntax also creates a TAGSTAT variable.  However, in this case the
    TAGSTAT variable is the "cell id" value.

    For each cell, the number of rows generated will be equal to the
    number of columns used to compute the distance metric (i.e., the cross
    tabulation variables or variables omitted by the SET STREAM READ
    VARIABLE TYPE command).  The variables defined as cross tabulation
    variables will simply have their value for that cell for all the rows.

Syntax 8:
    STREAM READ PERCENTILES <file>  <x1> <x2> ... <xk>
    where <file> is the name of the file to read;
    and where <x1>, <x2>, ... <xk> is a list of variables to read.

    This syntax will replace the raw data with a user-specified number
    of approximate percentiles.  To specify the number of equally spaced
    percentiles to generate, enter the command

       SET STREAM READ NUMBER OF PERCENTILES <value>

    where <value> is one of 9, 99, 999, or 9999.  The default is 999.
    The minimum and maximum values are also saved.  So if the number of
    percentiles is 999, 1001 points will be returned.

    Dataplot uses the extended P2 algorithm (the P2 algorithm was
    originally proposed by Jain and Chlamtac and was extended for
    multiple percentiles by Raatikanien).  This algorithm requires
    2*m+3 points where m is the desired number of percentiles.
    So if the number of values read is less than or equal to 2*m+3,
    Dataplot returns the original data (in sorted order).  If the
    number of points is greater than this, then the approximate
    percentiles are returned.

Syntax 9:
    STREAM READ CROSS TABULATE PERCENTILES <file>  <x1> <x2> ... <xk>
    where <file> is the name of the file to read;
    and where <x1>, <x2>, ... <xk> is a list of variables to read.

    This is similar to Syntax 8.  However, the percentiles will be
    computed separately for each cross tabulation cell.

    The cross tabulation variables are specified as in Syntax 5.  This
    syntax also creates a TAGSTAT variable.  However, in this case the
    TAGSTAT variable is the "cell id" value.

    For each cell, the number of rows generated will be equal to the
    number of percentiles requested.  The variables defined as cross
    tabulation variables will simply have their value for that cell for
    all the rows.

Examples:
    SET WRITE FORMAT 10E15.7
    STREAM READ WRITE BIG.DAT X1 TO X10

    SET STREAM READ SIZE 100
    STREAM READ GROUP STATISTIC MEAN BIG.DAT X1 TO X10
    STREAM READ GROUP STATISTIC STANDARD DEVIATION BIG.DAT X1 TO X10
    STREAM READ DEFAULT STATISTICS BIG.DAT X1 TO X10
 
    STREAM READ FULL STATISTICS BIG.DAT X1 TO X10
    STREAM READ CROSS TABULATE BIG.DAT X1 TO X10

Note:
    For the WRITE and CROSS TABULATE cases, character variables
    will be automatically converted to categorical variables.  For
    the GROUP STATISITC, DEFAULT STATISTIC, FULL STATISTIC, and
    PERCENTILE cases, character variables will still be ignored.

    If you would like to save the character strings from the
    character variables as group labels, enter the command

        SET STREAM READ GROUP LABEL ON

    If you have specified a column to be the row label variable
    using the SET ROW LABEL COLUMN command, this variable will
    not be converted to a numeric variable and group labels will
    not be created.

Note:
    When computing statistics, missing values (as specified by the
    SET READ MISSING VALUE command) will be omitted.

Note:
    Note that the STREAM READ command has a number of limitations compared
    to the standard READ command.

        1. Functions/strings, parameters, matrices, and images are not
           supported.

        2. Reading from the clipboard is not supported.

        3. Automatic name detection is not supported.

        4. The STREAM READ command is restricted to files (i.e., reading
           from the terminal is not supported).

Default:
    None

Synonyms:
    None

Related Commands:
    READ                   = Read variables from a file or the terminal.
    SERIAL READ            = Perform a serial read.
    READ FUNCTION          = Read a function.
    READ MATRIX            = Read a matrix.
    READ PARAMETER         = Read a parameter.
    READ STRING            = Read a string.
    READ IMAGE             = Read an image format into numeric arrays.
    READ STACKED VARIABLE  = Read a list of variables into a single
                             response variable and a group-id variable.
    SET READ FORMAT        = Define a FORTRAN style format for reads.
    DATA (LET)             = Enter data values into a variable.
    CLIPBOARD              = Various commands for reading from the
                             system clipboard.

References:
    Jain and Chlamtac (1985), "The P^2 Algorithm for Dynamic Calculation
    of Quantiles and Histograms without Storing Observations,"
    Communications of the ACM, 28, No. 10, pp. 1076-1085.

    Raatikanien (1987), "Simultaneous Estimation of Several Percentiles,"
    Simulation, pp. 159-164.
 
Applications:
    Data Input
 
Implementation Date:
    2016/07: Original implementation
    2018/07: Interpret character variables as categorical numeric
             variables for the WRITE and CROSS TABULATE cases
    2018/07: Support for CROSS TABULATION
    2018/07: Omit missing values when computing statistics
    2018/07: Option to automatically create group labels from character
             data
    2018/07: Allow specification of a "row label" column
    2018/07: Support for DISTANCE metrics
    2018/08: Support for CROSS TABULATION for DISTANCE metrics
    2018/08: Support for PERCENTILE and CROSS TABULATE PERCENTILE
 
Program 1:
    . Step 1:   Demonstrate the group statistic option of stream read
    .
    skip 25
    set read format 3F7.0
    set stream read group variable rowid
    stream read group statistics mean elliottr.dat redcolme rowid colid
    .
    . Step 2:   Generate plot of column means
    .
    title offset 2
    title case asis
    label case asis
    .
    title Column Means for Red Pixels for ELLIOTTR.DAT
    y1label Column Mean
    x1label Row
    .
    plot redcolme vs rowid
    .
    . Step 3:   Reset read settings
    .
    skip 0
    set read format

Program 2:
    . Step 1:   Demonstrate the default statistic option of stream read
    .
    skip 25
    set read format 3F7.0
    set stream read group variable rowid
    stream read default statistics elliottr.dat red rowid colid
    .
    let redmean = red
    retain redmean subset tagstat = 6
    let redsd = red
    retain redsd subset tagstat = 7
    let redmin = red
    retain redmin subset tagstat = 4
    let redmax = red
    retain redmax subset tagstat = 5
    .
    . Step 2:   Plot some of the statistics
    .
    multiplot corner coordinates 5 5 95 95
    multiplot scale factor 2
    multiplot 2 2
    .
    label case asis
    title case asis
    case asis
    title offset 2
    .
    title Mean of Columns
    plot redmean
    .
    title SD of Columns
    plot redsd
    .
    title Minimum of Columns
    plot redmin
    .
    title Maximum of Columns
    plot redmax
    .
    end of multiplot
    .
    justification center
    move 50 97
    text Statistics for Columns of Red Pixels in ELLIOTTR.DAT
    .
    . Step 2:   Reset read settings
    .
    skip 0
    set read format
 
Program 3:
    . Step 1:   Demonstrate the default statistic option of stream read
    .
    skip 25
    set read format 3F7.0
    stream read full statistics elliottr.dat red rowid colid
    .
    . Step 2:   Print statistics for red variable
    .
    feedback off
    set write decimals 2
    print "Statistics for variable RED:"
    print " "
    print " "
    let aval = red(1)
    print "Size:      ^aval"
    let aval = red(2)
    print "Minimum:   ^aval"
    let aval = red(3)
    print "Maximum:   ^aval"
    let aval = red(4)
    let aval = round(aval,2)
    print "Mean:      ^aval"
    let aval = red(5)
    let aval = round(aval,2)
    print "SD:        ^aval"
    let aval = red(6)
    let aval = round(aval,2)
    print "Skewness:  ^aval"
    let aval = red(7)
    let aval = round(aval,2)
    print "Kurtosis:  ^aval"
    let aval = red(8)
    print "Range:     ^aval"
    feedback on
    .
    . Step 3:   Reset read settings
    .
    skip 0
    set read format

Program 4:
    set write decimals 4
    set read missing value -999
    let itype = data 1 1 1 1 0
    set stream read variable type itype
    set stream read cross tabulate variable one groupid
    .
    skip 25
    stream read cross tabulate iris.dat y1 y2 y3 y4 groupid
    print y1 y2 y3 y4 groupid tagstat

Program 5:
    set write decimals 4
    set read missing value -999
    let itype = data 1 1 1 1 0
    set stream read variable type itype
    skip 25
    .
    .  Options to pick which distance/similarity metric to compute
    . let iflag1 = 1
    let iflag1 = 2
    let iflag2 = 1
    . let iflag2 = 2
    . let iflag2 = 3
    . let iflag2 = 4
    . let iflag2 = 5
    . let iflag2 = 6
    . let iflag2 = 7
    . let iflag2 = 8
    . let iflag2 = 9
    . let iflag2 = 10
    . let iflag2 = 11
    .
    if iflag1 = 1
       if iflag2 = 1
          stream read covariance iris.dat y1 y2 y3 y4
       else if iflag2 = 2
          stream read correlation iris.dat y1 y2 y3 y4
       end of if
    else if iflag1 = 2
       if iflag2 = 1
          stream read euclidean distance iris.dat y1 y2 y3 y4
       else if iflag2 = 2
          stream read manhattan distance iris.dat y1 y2 y3 y4
       else if iflag2 = 3
          stream read chebychev distance iris.dat y1 y2 y3 y4
       else if iflag2 = 4
          stream read cosine distance iris.dat y1 y2 y3 y4
       else if iflag2 = 5
          stream read cosine similarity iris.dat y1 y2 y3 y4
       else if iflag2 = 6
          stream read angular cosine distance iris.dat y1 y2 y3 y4
       else if iflag2 = 7
          stream read angular cosine similarity iris.dat y1 y2 y3 y4
       else if iflag2 = 8
          let v = jaccard column similarity x
          stream read jaccard similarity iris.dat y1 y2 y3 y4
       else if iflag2 = 9
          stream read jaccard distance iris.dat y1 y2 y3 y4
       else if iflag2 = 10
          stream read hamming distance iris.dat y1 y2 y3 y4
       else if iflag2 = 11
          stream read canberra distance iris.dat y1 y2 y3 y4
       end of if
    end of if
    .
    print y1 y2 y3 y4

Program 6:
    set write decimals 4
    set read missing value -999
    set stream read cross tabulate variable one groupid
    let itype = data 1 1 1 1 0
    set stream read variable type itype
    skip 25
    .
    .  Options to select which distance metric to use
    .
    . let iflag1 = 1
    let iflag1 = 2
    let iflag2 = 1
    . let iflag2 = 2
    . let iflag2 = 3
    . let iflag2 = 4
    . let iflag2 = 5
    . let iflag2 = 6
    . let iflag2 = 7
    . let iflag2 = 8
    . let iflag2 = 9
    . let iflag2 = 10
    . let iflag2 = 11
    .
    if iflag1 = 1
       if iflag2 = 1
          stream read cross tabulate covariance iris.dat y1 y2 y3 y4 groupid
       else if iflag2 = 2
          stream read cross tabulate correlation iris.dat y1 y2 y3 y4 groupid
       end of if
    else if iflag1 = 2
       if iflag2 = 1
          stream read cross tabulate euclidean distance iris.dat y1 y2 y3 y4 groupid
       else if iflag2 = 2
          stream read cross tabulate manhattan distance iris.dat y1 y2 y3 y4 groupid
       else if iflag2 = 3
          stream read cross tabulate chebychev distance iris.dat y1 y2 y3 y4 groupid
       else if iflag2 = 4
          stream read cross tabulate cosine distance iris.dat y1 y2 y3 y4 groupid
       else if iflag2 = 5
          stream read cross tabulate cosine similarity iris.dat y1 y2 y3 y4 groupid
       else if iflag2 = 6
          stream read cross tabulate angular cosine distance iris.dat y1 y2 y3 y4 groupid
       else if iflag2 = 7
          stream read cross tabulate angular cosine similarity iris.dat y1 y2 y3 y4 groupid
       else if iflag2 = 8
          stream read cross tabulate jaccard similarity iris.dat y1 y2 y3 y4 groupid
       else if iflag2 = 9
          stream read cross tabulate jaccard distance iris.dat y1 y2 y3 y4 groupid
       else if iflag2 = 10
          stream read cross tabulate hamming distance iris.dat y1 y2 y3 y4 groupid
       else if iflag2 = 11
          stream read cross tabulate canberra distance iris.dat y1 y2 y3 y4 groupid
       end of if
    end of if
    .
    print y1 y2 y3 y4 groupid tagstat

-----STRING COMBINE-------------------------------------------
 
STRING COMBINE
 
Name:
    STRING COMBINE
 
Type:
    Let Subcommand
 
Purpose:
    Combine strings or create a string from a list of arguments.

Description:
    The STRING CONCATENATE command is used to concatenate strings.
    The STRING COMBINE command is a variant of STRING CONCATENATE
    that varies in the following ways:

       1. With STRING CONCATENATE, the arguments are previously
          defined strings.  With STRING COMBINE, Dataplot first
          checks to see if the argument is the name of a previously
          defined string.  If yes, the contents of the string
          are added to the contents of the output string (i.e.,
          the same as STRING CONCATENATE).  However if the argument
          is of any type other than string or it is not a previously
          defined name, the argument is added to the output string
          as literal text.

       2. The STRING COMBINE inserts a space between the input
          strings/arguments.  With STRING CONCATENATE, this has
          to be done manually (i.e., you need to define a string
          that contains a space and use this between the other
          arguments).

       3. The STRING COMBINE command supports the TO syntax.  That
          is, entering 

              LET SOUT = STRING COMBINE X1 TO X8

          is equivalent to entering

              LET SOUT = STRING COMBINE X1 X2 X3 X4 X5 X6 X7 X8

    This command has two primary uses:

       1. As an alternative to STRING CONCATENATE when you want to
          automatically include a space between the input strings.

       2. Most Dataplot analysis and graphics commands now support
          the TO syntax.  However, there are cases, such as the
          LET command, where the TO syntax can be useful.  The
          STRING COMBINE can be used to easily create a command
          string.  This is demonstrated in the program example
          below.

Syntax:
    LET <sout> = STRING COMBINE  <s1>  ... <sk>
    where <sout> is the name of the resulting string;
    and   <s1> ... <sk> is a list of one or more previously defined strings.
 
Examples:
    LET STALL = STRING COMBINE X1 X2 X3
    LET STALL = STRING COMBINE X1 TO X8
 
Note:
    The name of the output string can be the same as one of the
    input strings.  For example,

        LET STRING S1 = One
        LET STRING S2 = Two
        LET STRING S3 = Three
        LET SOUT = STRING COMBINE S1 S2 S3

Note:
    By default, a space character is used as the separator character.
    To specify a different separator command, enter

        SET STRING SEPARATOR <char>

    where <char> denotes the character to be used as the separator.

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to
    the combined number of characters for all functions and strings.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STRING CONCATENATE  = Concatenate two or more strings.
    &                   = Concatenate two strings.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBTRING            = Extract a substring from an existing string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING EDIT         = Edit a string.
    STRING LENGTH       = Return the length of a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2018/02
    2019/12: Added SET STRING SEPARATOR
 
Program 1:
    SKIP 25
    READ BOXREACT.DAT Y X1 TO X5
    LET STALL = STRING COMBINE X1 TO X5
    LET CONFTAG1 CONFTAG2 = DEX CONFOUND ^STALL

-----STRING COMPARE-----------------------------------------------------
 
STRING COMPARE
 
Name:
    STRING COMPARE
 
Type:
    Let Subcommand
 
Purpose:
    Compare two strings and return a 1 if they are identical and
    return a 0 if they are not.
 
Syntax 1:
    LET <ival> = STRING COMPARE  <s1>  <s2>
    where <ival> is a parameter containing a 1 if the strings are
              identical and 0 if they are not;
          <s1> is the name of the first string;
    and   <s2> is the name of the second string.

    With this syntax, the comparison is case sensitive and the full
    strings are compared (if the strings are of unequal length a 0 will
    be returned even if the strings match up to length of the shorter
    string).
 
Syntax 2:
    LET <ival> = STRING COMPARE NOCASE <s1>  <s2>
    where <ival> is a parameter containing a 1 if the strings are
              identical and 0 if they are not;
          <s1> is the name of the first string;
    and   <s2> is the name of the second string.
 
    With this syntax, the comparison is not case sensitive and the full
    strings are compared (if the strings are of unequal length a 0 will
    be returned even if the strings match up to length of the shorter
    string).
 
Syntax 3:
    LET <ival> = STRING COMPARE  <s1>  <s2>  <len>
    where <ival> is a parameter containing a 1 if the strings are
              identical and 0 if they are not;
          <s1> is the name of the first string;
          <s2> is the name of the second string.
    and   <len> is a number or a parameter that specifies the number of
               characters in the strings to compare.

    With this syntax, the comparison is case sensitive, but only the
    first <len> characters in <s1> and <s2> are compared.
 
Syntax 4:
    LET <ival> = STRING COMPARE NOCASE <s1>  <s2>  <len>
    where <ival> is a parameter containing a 1 if the strings are
              identical and 0 if they are not;
          <s1> is the name of the first string;
          <s2> is the name of the second string.
    and   <len> is a number or a parameter that specifies the number of
               characters in the string to compare.

    With this syntax, the comparison is not case sensitive and only the
    first <len> characters in <s1> and <s2> are compared.
 
Examples:
    LET IVAL = STRING COMPARE S1 S2
    LET IVAL = STRING COMPARE NOCASE S1 S2
    LET IVAL = STRING COMPARE S1 S2 NCHAR
    LET IVAL = STRING COMPARE NOCASE S1 S2 NCHAR
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    SUBTRING            = Extract a substring from an existing string.
    STRING LENGTH       = Return the length of the string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING EDIT         = Edit a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2011/01
    2021/08: Support for NOCASE option
    2021/08: Support for limiting the comparison to a specified
             number of characters at the start of the string
 
Program:
    LET STRING S1 = file23.dat
    LET STRING S2 = file13.dat
    LET STRING S3 = file23.dat
    LET IVAL1 = STRING COMPARE S1 S2
    LET IVAL2 = STRING COMPARE S1 S3

    The resulting values of IVAL1 and IVAL2 are 0 and 1, respectively.

-----STRING COMPARE AND REPLACE--------------------------------------------
 
STRING COMPARE AND REPLACE
 
Name:
    STRING COMPARE AND REPLACE
 
Type:
    Let Subcommand
 
Purpose:
    Compare a string to a list of strings and if a match is found
    define a replacement string.
 
Description:
    This is a specialized command that was developed to improve
    performance in the EST.DP macro used by the 10-step macros for
    the analysis of 2-level full or fractional factorial designs.

    The specific code that motivated this command was

       loop for j1 = 1 1 numeff
          let string stefc^j1 = -999
          let string stprobe = ^stmain^j1
          loop for j2 = 1 1 numconf
             let string starch = ^stt^j2
             if stprobe = starch
                let string stefc^j1 = ^stc^j2
             end if
          end loop
       end loop

    In this code, we are looping over the main factors.  For
    each main factor, a string is compared to a list of strings.
    The numconf parameter defines the number of strings being
    compared.  This value can grow fairly large.  For example,
    for a 2**(8-4) design, numconf is 96.  If a match is
    found, a new string (stefc^j1) is set to a string that
    is not in the list being compared (^stc^j2).

    The updated code using the STRING AND REPLACE command is

       loop for j1 = 1 1 numeff
           let string stefc^j1 = -999
           let stefc^j1 = string compare and replace stmain^j1 stc ...
                          stt1 to stt^numconf
       end loop

    This command eliminates the inner loop.  For our 2**(8-4)
    example, this reduces the number of loop iterations from
    8*96 = 768 to 8.  The string stmain^j1 is being compared
    to the strings stt1 to stt^numconf.  If stt9 matches stmain^j1,
    the stefc^j1 is set equal to stc9.  That is, the replacement
    string defines a base name to which the index of the matching
    string is appended to define the replacement string name.

    If in our example, the string "stc" is a previously defined
    string, then this would be used rather than "stc9".

Syntax:
    LET <sout> = STRING COMPARE AND REPLACE <sorg>  <sold>  <srepl>
                 <sc1> ...  <sck>
    where <sout> is the name of the resulting string;
          <sorg> is a pre-existing string that will be compared
                to each of <sc1> ... <sck>;
          <srepl> is pre-existing string that will be set to
                <sout> if a match is found;
    and where <sc1> ... <sck> is a list of pre-existing strings.

    If <srepl> does not exist but <srepl1> ... <sreplk> do exist,
    the replacement string will be <sreplj> where j denotes the
    index of the match.

    If no match is found, <sout> will not be created.

    The TO syntax can be used for <sc1> ... <sck>.

Examples:
    LET STRING STNEW = STRING COMPARE AND REPLACE SOLD SREPLACE ...
                       S1 S2 S3 S4 S5 S6
    LET STRING STNEW = STRING COMPARE AND REPLACE SOLD SREPLACE ...
                       S1 TO S6
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    SUBTRING            = Extract a substring from an existing string.
    STRING EDIT         = Edit the contents of a string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING LENGTH       = Return the length of a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2018/03
 
Program:
    LET STRING S1 = One
    LET STRING S2 = Two
    LET STRING S3 = Three
    LET STRING S4 = Four
    LET STRING S5 = Five
    .
    LET STRING SOLD = Four
    LET STRING SREPL = String Found
    LET STRING SNEW = String Not Found
    LET SNEW = STRING COMPARE AND REPLACE SOLD SREPL S1 TO S5
    PRINT "SNEW: ^SNEW"
 
-----STRING CONCATENATE-------------------------------------------
 
STRING CONCATENATE
 
Name:
    STRING CONCATENATE
 
Type:
    Let Subcommand
 
Purpose:
    Concatenate one or more strings.
 
Description:
    This command allows you to concatenate strings.  Although this
    can also be done using the "^" and "&" characters, using the
    STRING CONCATENATE command may result in Dataplot code that is 
    somewhat easier to use and read (particularly when many strings
    are being concatenated).

Syntax:
    LET <sout> = STRING CONCATENATE  <s1>  ... <sk>
    where <sout> is the name of the resulting string;
    and   <s1> ... <sk> is a list of one or more previously defined strings.
 
Examples:
    LET STRING S1 = file
    LET STRING S2 = 99
    LET STRING S3 = .dat
    LET SOUT = STRING CONCATENATE S1 S2 S3
 
Note:
    The name of the new string can be the same as one of the
    previously defined strings.  For example,

        LET FNAME = FILE
        LET SINDEX = ^K
        LET SEXT = .DAT
        LET FNAME = STRING CONCATENATE FNAME SINDEX SEXT

Note:
    All strings on the right hand side of the equal sign must be
    previously existing strings.  That is, expressions are not allowed.
    For example, instead of

        LET FNAME = STRING CONCATENATE FNAME  ".txt"

    you need to do

        LET STRING SEXT = .txt
        LET FNAME = STRING CONCATENATE FNAME  SEXT

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to
    the combined number of characters for all functions and strings.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    &                   = Concatenate two strings.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBTRING            = Extract a substring from an existing string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING EDIT         = Edit a string.
    STRING LENGTH       = Return the length of a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    11/2008
 
Program 1:
    LET STRING S1 = file
    LET STRING S2 = 23
    LET STRING S3 = .txt
    LET SOUT = STRING CONCATENATE S1 S2 S3

    The resulting string SOUT will contain

       file23.txt

Program 2:
    .  Assume we have variables X and Y in the files "file1.dat" to
    .  "file10.dat" and we want to plot each of these in turn.
    .
    LET STRING SBASE = file
    LET STRING SEXT = xx
    TITLE CASE ASIS
    LOOP FOR K = 1 1 10
        LET STRING SINDEX = ^K
        LET FNAME = STRING CONCATENATE SBASE SINDEX SEXT
        READ ^FNAME  Y X
        TITLE Data from File ^SOUT
        PLOT Y X
        DELETE Y X
    END OF LOOP
 
-----STRING CONTAIN----------------------------------------------
 
STRING CONTAIN
 
Name:
    STRING CONTAIN
 
Type:
    Let Subcommand
 
Purpose:
    Return a 1 if a string contains a specified substring and a 0 if it
    does not.
 
Syntax:
    LET <iflag> = STRING CONTAIN  <s1>  <s2>
    where <iflag> is a parameter containing a 1 if <s1> contains
              the string <s2> and 0 otherwise;
          <s1> is the name of a pre-existing string;
    and   <s2> is the name of a pre-existing string.
 
Examples:
    LET IFLAG = STRING CONTAINS SORG  SMATCH

Note:
    The strings on the right hand side of the equal sign must be
    previously existing strings.  That is, expressions are not allowed.
    For example, the following will result in an error message

        LET IFLAG = STRING CONTAINS "alan.heckert@nist.gov"  "alan"

    you need to do

        LET STRING SORG = alan.heckert@nist.gov
        LET STRING SMATCH = alan
        LET SOUT = STRING CONTAINS SORG SMATCH

    The name on the left hand side of the equal sign should either be a
    previously existing parameter or not previously defined.  If it is a
    previously existing string, variable, or matrix name, an error will
    be reported and the requested parameter will not be created.

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to
    the combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SUBTRING            = Extract a substring from an existing string.
    STRING ENDS WITH    = Check whether a string starts with a
                          specified substring.
    STRING ENDS WITH    = Check whether a string ends with a
                          specified substring.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    STRING LENGTH       = Return the length of the string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING EDIT         = Edit a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2019/01
 
Program:
    LET STRING S1 = alan.heckert@gmail.com
    LET STRING S2 = alan
    LET IFLAG = STRING CONTAINS S1 S2

-----STRING DELETE------------------------------------------
 
STRING DELETE

Name:
    STRING DELETE
 
Type:
    Let Subcommand
 
Purpose:
    Remove a user specified list of characters from a string.
 
Description:
    The STRING REMOVE SPACES, STRING REMOVE WHITESPACE, and STRING
    REMOVE PUNCTUATION commands can be used to remove certain pre-defined
    sets of characters from a string.  However, there may be times when
    you need to specifiy a specific list of characters to remove.  The
    STRING DELETE command can be used to do that.

Syntax:
    LET <sout> = STRING DELETE  <sorg>  <slist>
    where <sout> is the name of the resulting string;
          <sorg> is the name of the original string;
    and   <slist> is the name of the original string.

    You specifiy the characters you want to delete by defining the
    <slist> string.  That is, <sorg> will be checked against each
    character in <slist>.

Examples:
    LET SOUT = STRING DELETE STIN SLIST
 
Note:
    The name of the new string can be the same as the original
    string.  For example,

        LET STR = STRING DELETE STR  SDELETE

    In this case, STR will now contain the the string with the
    characters removed rather than the original string.

Note:
    The strings on the right hand side of the equal sign must be
    previously existing strings.  That is, expressions are not allowed.
    For example, the following will result in an error message

        LET STOUT = STRING DELETE "alan.heckert@nist.gov"  "@"

    you need to do

        LET STRING SORG = alan.heckert@nist.gov
        LET STRING SLIST = @
        LET SOUT = STRING DELETE SORG SLIST

    The name on the left hand side of the equal sign may be a
    previously existing string.  However, if it is a previously
    existing parameter, variable, or matrix name, an error will
    be reported and the requested string will not be created.

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to the
    combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STRING REMOVE PUNCTUATION = Remove punctuatuin characters from a string.
    STRING REMOVE SPACE       = Remove spaces from a string.
    STRING REMOVE WHITESPACE  = Remove white space characters from a string.
    NUMBER OF WORDS           = Return the number of words in a string.
    UPPER CASE                = Convert a string to upper case.
    LOWER CASE                = Convert a string to lower case.
    LET FUNCTION              = Defines a function.
    LET STRING                = Defines a string.
    READ STRING               = Reads a string from a file.
    SUBSTITUTE CHARACTER (^)  = Substitute the value of a string or
                                parameter.
    CONCATENATE CHARACTER (&) = Concatenate two strings.
    SUBTRING                  = Extract a substring from an existing
                                string.
    STRING INDEX              = Extract the start/stop positions of a
                                substring within a string.
    STRING CONCATENATE        = Concatenate one or more previously
                                defined strings.
    STRING EDIT               = Edit a string.
    STRING MERGE              = Insert a string into another string
                                without overwrite.
    STRING LENGTH             = Return the length of a string.
    STRING WORD               = Extract a specified word from a string.
    CHARACTER                 = Convert numeric values to strings based
                                on the ASCII collating sequence.
    ICHAR                     = Convert a string to numeric values based
                                on the ASCII collating sequence.
    GROUP LABEL               = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2018/10
 
Program:
    let string stin = abcdefgabcdefg
    let string slist = cde
    let stout = string delete stin slist
    print stin stout

-----STRING EDIT-----------------------------------------------------
 
STRING EDIT
 
Name:
    STRING EDIT
 
Type:
    Let Subcommand
 
Purpose:
    Edit the contents of a string.
 
Description:
    This command allows you to edit the contents of a previosuly defined
    string.

    The STRING EDIT command involves three string:

       1) The original string which we will call SORG.

       2) A substring, which we will call SOLD, that contains the text
          to be changed.

       3) A substring, which we will call SNEW, which contains the
          replacement text.

    The STRING EDIT command searches the string SORG for the
    substring SOLD.  If found, it replaces the SOLD text with
    the SNEW text.  If no match is found, an error message is
    printed and the new string is not created.
 
Syntax 1:
    LET <sout> = STRING EDIT  <sorg>  <sold>  <snew>
    where <sout> is the name of the resulting string;
          <sorg> is the name of the original string to be edited;
          <sold> is the name of the match string;
    and where <snew> is the name of the replacement string.

    This syntax edits the first occurence of <sold> only.
 
Syntax 2:
    LET <sout> = STRING GLOBAL EDIT  <sorg>  <sold>  <snew>
    where <sout> is the name of the resulting string;
          <sorg> is the name of the original string to be edited;
          <sold> is the name of the match string;
    and where <snew> is the name of the replacement string.
 
    This syntax edits all occurences of <sold>.

Examples:
    LET STRING S1 = filexx.dat
    LET STRING S2 = xx
    LET STRING S3 = 23
    LET SOUT = STRING EDIT S1 S2 S3

    LET SOUT = STRING GLOBAL EDIT SIN SOLD SNEW
 
Note:
    The name of the new string can be the same as the original string.
    For example,

        LET FNAME = STRING EDIT FNAME SOLD SNEW

Note:
    All three strings on the right hand side of the equal sign must be
    previously existing strings.  That is, expressions are not allowed.
    For example, instead of

        LET FNAME = STRING EDIT FNAME  ".dat"  ".txt"

    you need to do

        LET STRING SOLD = .dat
        LET STRING SNEW = .txt
        LET FNAME = STRING EDIT FNAME  SOLD SNEW

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to
    the combined number of characters for all functions and strings.
 
Note:
    Only the first occurrence that is matched is changed.  That is,
    there is currently no "global" option and no option to specify
    that the second or third or last occurence be changed.

    Also, there is currently no support for wild cards or regular
    expressions.

Note:
    If you want the replacement string to be null (i.e., you want
    to delete the match string), then you can do the following

       LET STRING SOUT = NULL()
       LET SOUT = STRING EDIT STIN SOLD SNEW

    or

       LET SOUT = STRING EDIT STIN NULL() SNEW

    The use of "NULL()" is currently specific to this command.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    SUBTRING            = Extract a substring from an existing string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING LENGTH       = Return the length of a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2008/11
    2015/02: Support for STRING GLOBAL EDIT<BR>
    2015/02: Support for "NULL()" for replacement string<BR>
 
Program 1:
    LET STRING S1 = file23.dat
    LET STRING S2 = dat
    LET STRING S3 = txt
    LET SOUT = STRING EDIT S1 S2 S3

    The resulting string SOUT will contain

       file23.txt

Program 2:
    .  Assume we have variables X and Y in the files "file1.dat" to
    .  "file10.dat" and we want to plot each of these in turn.
    .
    LET STRING SOLD = filexx.dat
    LET STRING S3 = xx
    TITLE CASE ASIS
    LOOP FOR K = 1 1 10
        LET STRING S2 = ^K
        LET FNAME = STRING EDIT SOLD S3 S2
        READ ^FNAME  Y X
        TITLE Data from File ^SOUT
        PLOT Y X
        DELETE Y X
    END OF LOOP
 
-----STRING ENDS WITH----------------------------------------------
 
STRING ENDS WITH
 
Name:
    STRING ENDS WITH
 
Type:
    Let Subcommand
 
Purpose:
    Return a 1 if a string ends with a specified substring
    and a 0 if it does not.
 
Syntax:
    LET <iflag> = STRING ENDS WITH  <s1>  <s2>
    where <iflag> is a parameter containing a 1 if <s1> ends
              with <s2> and 0 otherwise;
          <s1> is the name of a pre-existing string;
    and   <s2> is the name of a pre-existing string.
 
Examples:
    LET IFLAG = STRING ENDS WITH S1  S2
 
Note:
    The strings on the right hand side of the equal sign must be
    previously existing strings.  That is, expressions are not allowed.
    For example, the following will result in an error message

        LET IFLAG = STRING ENDS WITH "alan.heckert@nist.gov"  "nist.gov"

    you need to do

        LET STRING SORG = alan.heckert@nist.gov
        LET STRING SMATCH = nist.gov
        LET SOUT = STRING ENDS WITH SORG SMATCH

    The name on the left hand side of the equal sign should either be a
    previously existing parameter or not previously defined.  If it is a
    previously existing string, variable, or matrix name, an error will
    be reported and the requested parameter will not be created.

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to
    the combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STRING STARTS WITH  = Check whether a string starts with a
                          specified substring.
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    SUBTRING            = Extract a substring from an existing string.
    STRING LENGTH       = Return the length of the string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING EDIT         = Edit a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2018/10
 
Program:
    LET STRING S1 = alan.heckert@gmail.com
    LET STRING S2 = gmail.com
    LET IFLAG = STRING ENDS WITH S1 S2

-----STRING EXPAND WHITESPACE----------------------------------------
 
STRING EXPAND WHITESPACE

Name:
    STRING EXPAND WHITESPACE
 
Type:
    Let Subcommand
 
Purpose:
    Replace non-printing characters in a string with a single space
    character.
 
Description:
    When extracting strings from external sources, you may encounter
    non-printing characters.  The STRING REMOVE WHITESPACE can be used
    to simply remove these characters from the string.  Alternatively,
    the STRING EXPAND WHITESPACE can be used to convert non-printing
    characters to a single space character.

    The tab character is treated somewhat differently.  Specifically,
    you can use the command

       SET TAB EXPAND <value>

    to specify how tab characters are handled.  Specifically, if <value>
    is 0, then the tab character is retained in the string (no space
    is added).  If <value> is a positive integer, the tab character
    will be replaced with <value> spaces.

    The non-printing characters are the ones with codes 0 to 31 and 127
    in the ASCII collating sequence.  Currently, Dataplot only checks
    for characters in the 0 - 127 range of the ASCII collating sequence.

Syntax:
    LET <sout> = STRING EXPAND WHITESPACE  <sorg>
    where <sout> is the name of the resulting string;
    and   <sorg> is the name of the original string.

Examples:
    LET SOUT = STRING EXPAND WHITESPACE STIN
 
Note:
    The name of the new string can be the same as the original
    string.  For example,

        LET STR = STRING EXPAND WHITESPACE STR

    In this case, STR will now contain the the string with all white
    space characters removed rather than the original string.

Note:
    The string on the right hand side of the equal sign must be a
    previously existing string.  That is, expressions are not allowed.
    For example, the following will result in an error message

        LET STOUT = STRING EXPAND WHITESPACE "a b c d"

    you need to do

        LET STRING SORG = a b c d
        LET SOUT = STRING EXPAND WHITESPACE SORG

    The name on the left hand side of the equal sign may be a
    previously existing string.  However, if it is a previously
    existing parameter, variable, or matrix name, an error will
    be reported and the requested string will not be created.

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to the
    combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STRING REMOVE WHITE SPACE = Remove white space and non-printing
                                characters from a string.
    STRING REMOVE SPACE       = Remove spaces from a string.
    STRING REMOVE PUNCTUATION = Remove punctuation from a string.
    STRING DELETE             = Remove user specifed characters from a
                                string.
    NUMBER OF WORDS           = Return the number of words in a string.
    UPPER CASE                = Convert a string to upper case.
    LOWER CASE                = Convert a string to lower case.
    LET FUNCTION              = Defines a function.
    LET STRING                = Defines a string.
    READ STRING               = Reads a string from a file.
    SUBSTITUTE CHARACTER (^)  = Substitute the value of a string or
                                parameter.
    CONCATENATE CHARACTER (&) = Concatenate two strings.
    SUBTRING                  = Extract a substring from an existing
                                string.
    STRING INDEX              = Extract the start/stop positions of a
                                substring within a string.
    STRING CONCATENATE        = Concatenate one or more previously
                                defined strings.
    STRING EDIT               = Edit a string.
    STRING MERGE              = Insert a string into another string
                                without overwrite.
    STRING LENGTH             = Return the length of a string.
    STRING WORD               = Extract a specified word from a string.
    CHARACTER                 = Convert numeric values to strings based
                                on the ASCII collating sequence.
    ICHAR                     = Convert a string to numeric values based
                                on the ASCII collating sequence.
    GROUP LABEL               = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2019/02
 
Program:
    set tab expand 3
    read string tab.dat t
    let tout = string expand whitespace t
    print t tout

-----STRING HAMMING DISTANCE-----------------------------------------
 
STRING HAMMING DISTANCE
 
Name:
    STRING HAMMING DISTANCE
 
Type:
    Let Subcommand
 
Purpose:
    Given two equal length strings, returns the count of the number
    of character positions that match.
 
Syntax:
    LET <dist> = STRING HAMMING DISTANCE  <s1>  <s2>
    where <dist> is a parameter containing the Hamming distance;
          <s1> is the name of a pre-existing string;
    and   <s2> is the name of a pre-existing string.

    The <s1> and <s2> strings must be the same length.
 
Examples:
    LET IFLAG = STRING HAMMING DISTANCE S1  S2

Note:
    The strings on the right hand side of the equal sign must be
    previously existing strings.  That is, expressions are not allowed.
    For example, the following will result in an error message

        LET IFLAG = STRING HAMMING DISTANCE "gmail.com" "gmail.org"

    you need to do

        LET STRING S1 = gmail.com
        LET STRING S2 = gmail.org
        LET SOUT = STRING HAMMING DISTANCE S1 S2

    The name on the left hand side of the equal sign may be a
    previously existing parameter.  However, if it is a previously
    existing string, variable, or matrix name, an error will
    be reported and the requested parameter will not be created.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    HAMMING DISTANCE    = Compute the Hamming distance of two
                          vectors.
    EUCLIDEAN DISTANCE  = Compute the Euclidean distance.
    COSINE DISTANCE     = Compute the cosine distance.
    MANHATTAN DISTANCE  = Compute the Manhattan distance.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
 
Applications:
    Data Management
 
Implementation Date:
    2018/10
 
Program:
    LET STRING S1 = 1011100111
    LET STRING S2 = 1010010110
    LET DIST = STRING HAMMING DISTANCE S1 S2

-----STRING INDEX-----------------------------------------------------
 
STRING INDEX
 
Name:
    STRING INDEX
    STRING RIGHT INDEX
 
Type:
    Let Subcommand
 
Purpose:
    Return the start and stop position of a substring within a
    string.
 
Syntax 1:
    LET <nstart> <nstop> = STRING INDEX  <sorg> <smatch>
    where <nstart> is a parameter containing the returned start position;
          <nstop> is a parameter containing the returned stop position;
          <sorg> is the original string;
    and   <smatch> is the substring to be matched within <sorg>.

    This syntax searches <sorg> from left to right.
 
Syntax 2:
    LET <nstart> <nstop> = STRING RIGHT INDEX  <sorg> <smatch>
    where <nstart> is a parameter containing the returned start position;
          <nstop> is a parameter containing the returned stop position;
          <sorg> is the original string;
    and   <smatch> is the substring to be matched within <sorg>.

    This syntax searches <sorg> from right to left.
 
Examples:
    LET NSTART NSTOP = STRING INDEX S1 S2
    LET NSTART NSTOP = STRING RIGHT INDEX SORG SMATCH
 
Note:
    Both of the strings on the right hand side of the equal sign
    must be previously defined strings.  String expressions are
    not allowed.  So

        LET NSTART NSTOP = STRING INDEX SORG  ".dat"

    should be coded as

        LET STRING S2 = .dat
        LET NSTART NSTOP = STRING INDEX SORG  S2
    
Default:
    None
 
Synonyms:
    STRING FIND is a synonym for STRING INDEX
    STRING RIGHT FIND is a synonym for STRING RIGHT INDEX
 
Related Commands:
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    SUBTRING            = Extract a substring from an existing string.
    STRING LENGTH       = Return the length of a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING EDIT         = Edit a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2008/11
    2018/10: Added STRING RIGHT INDEX
    2018/10: Added STRING FIND as a synonym for STRING INDEX
 
Program:
    LET STRING S1 = file23.dat
    LET STRING S2 = 23
    LET NSTART NSTOP = STRING INDEX S1 S2

    The resulting values of NSTART and NSTOP are 5 and 6,
    respectively.

-----STRING INTERACTION-------------------------------------------------
 
STRING INTERACTION

Name:
    STRING INTERACTION
 
Type:
    Let Subcommand
 
Purpose:
    Given a list of parameters, create a string that represents
    an interaction term.
 
Description:
    This is a specialized command that is used in creating labels
    in the context of a 2-level full or fractional factorial design.

    As an example, suppose we have the parameters J1, J2, and J3
    where J1 = 3, J2 = 1, and J3 = 5, then this command will create a
    string containing

         X3 * X1 * X5

    The parameters identify factors of interest, so they will
    typically contain integers in the range 1 to k where k is the
    number of factors in the design.  If the parameter is negative,
    then that parameter will not be included in the output string.

Syntax:
    LET <sout> = STRING INTERACTION <j1> ... <jk>
    where <sout> is the name of the resulting string;
    and   <j1> ... <jk> is a list of parameters.

Examples:
    LET SOUT = STRING INTERACTION J1 J2 J3
    LET SOUT = STRING INTERACTION J1 J2 J3 J4 J5

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to the
    combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NUMBER OF WORDS           = Return the number of words in a string.
    UPPER CASE                = Convert a string to upper case.
    LOWER CASE                = Convert a string to lower case.
    LET FUNCTION              = Defines a function.
    LET STRING                = Defines a string.
    READ STRING               = Reads a string from a file.
    SUBSTITUTE CHARACTER (^)  = Substitute the value of a string or
                                parameter.
    CONCATENATE CHARACTER (&) = Concatenate two strings.
    BLANK STRING              = Create a blank string.
    SUBTRING                  = Extract a substring from an existing
                                string.
    STRING INDEX              = Extract the start/stop positions of a
                                substring within a string.
    STRING CONCATENATE        = Concatenate one or more previously
                                defined strings.
    STRING EDIT               = Edit a string.
    STRING MERGE              = Insert a string into another string
                                without overwrite.
    STRING LENGTH             = Return the length of a string.
    CHARACTER                 = Convert numeric values to strings based
                                on the ASCII collating sequence.
    ICHAR                     = Convert a string to numeric values based
                                on the ASCII collating sequence.
    GROUP LABEL               = Define the text for group labels.
 
Applications:
    2-Level Full and Fractional Factorial Designs
 
Implementation Date:
    2018/04
 
Program:
    . Step 1:   Define inputs
    .
    let j1 = 1
    let j2 = 2
    let j3 = 3
    let j4 = 4
    let j5 = 5
    .
    . Step 2:   Execute the command
    .
    let stnew  = string interaction j1 j2 j3 j4 j5
    .
    let j4 = -9999
    let j5 = -9999
    let stnew2  = string interaction j1 j2 j3 j4 j5
    .
    print "stnew:  ^stnew"
    print "stnew2: ^stnew2"

-----STRING JUSTIFY-------------------------------------------------
 
STRING JUSTIFY
 
Name:
    STRING <LEFT/CENTER/RIGHT> JUSTIFY
 
Type:
    Let Subcommand
 
Purpose:
    Left, center, or right justify a string.

Description:
    The STRING REMOVE SPACES command can be used to remove leading or
    trailing spaces from a string.  This command allows you to add
    leading or trailing spaces.

    That is, you specify the desired length of the string.  If LEFT
    justification is requested, trailing spaces will be added to the end
    of the string so that the string has the desired length.  Likewise, if
    RIGHT justification is requested, leading spaces will be added to the
    beginning of the string.  If CENTER justification is requested, both
    leading and trailing spaces will be added.

    If the requested string already has a length greater than the
    requested length, the output string will be set equal to the input
    string.

    By default, the added leading and trailing characters are spaces.
    You can specify a different character by entering the command

         SET STRING JUSTIFICATION CHARACTER <char>

    To reset the default of spaces, enter

         SET STRING JUSTIFICATION CHARACTER SPACE

Syntax 1:
    LET <sout> = STRING LEFT JUSTIFY <sorg>  <nlen>
    where <sout> is the name of the resulting string;
          <sorg> is the name of the original string;
    and   <nlen> is the desired length of the output string.

    If n1 is the length of the original string and <nlen> is n2, then
    n2 - n1 spaces will be added to the end of <sorg>.  If n1 >= n2,
    <sout> will be set equal to <sorg>.
 
Syntax 2:
    LET <sout> = STRING RIGHT JUSTIFY <sorg>  <nlen>
    where <sout> is the name of the resulting string;
          <sorg> is the name of the original string;
    and   <nlen> is the desired length of the output string.

    If n1 is the length of the original string and <nlen> is n2, then
    n2 - n1 spaces will be added to the beginning of <sorg>.  If n1 >= n2,
    <sout> will be set equal to <sorg>.
 
Syntax 3:
    LET <sout> = STRING CENTER JUSTIFY <sorg>  <nlen>
    where <sout> is the name of the resulting string;
          <sorg> is the name of the original string;
    and   <nlen> is the desired length of the output string.

    If n1 is the length of the original string and <nlen> is n2, then
    (n2 - n1)/2 spaces will be added to the beginning of <sorg> and
    (n2 - n1)/2 spaces will be added to the end of <sorg>.  If n2 - n1
    is odd, the extra space will be added to the beginning of <sorg>.  If
    n1 >= n2, <sout> will be set equal to <sorg>.
 
Examples:
    LET SOUT = STRING LEFT JUSTIFY S1 NLEN
    LET SOUT = STRING RIGHT JUSTIFY S1 20
    LET SOUT = STRING CENTER JUSTIFY S1 NLEN
 
Note:
    The name of the new string can be the same as the original
    string.  For example,

        LET SORG = STRING RIGHT JUSTIFY SORG NLEN

Note:
    The string on the right hand side of the equal sign must be a
    previously existing string.  That is, expressions are not allowed.
    For example, instead of

        LET SOUT = STRING RIGHT JUSTIFY  "XXXXX"  10

    you need to do

        LET STRING SORG = XXXXX
        LET SOUT = STRING RIGHT JUSTIFY SORG 10

    The length parameter can be either a parameter or a numeric
    value.  However, it cannot be a numeric expression.  So

        LET SOUT = STRING RIGHT JUSTIFY SORG 10
        LET SOUT = STRING RIGHT JUSTIFY SORG NLEN

    are both allowed but

        LET SOUT = STRING RIGHT JUSTIFY SORG NLEN/2

    is not allowed.  You would need to enter this as

        LET NLEN2 = NLEN/2
        LET SOUT = STRING RIGHT JUSTIFY SORG NLEN2

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to the
    combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING LENGTH       = Return the length of a string.
    STRING EDIT         = Edit a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2019/01
 
Program:
    SKIP 25
    READ BERGER1.DAT Y X
    FIT Y X
    LET CC = CORRELATION Y X
    .
    LET STRING S1 = A0:
    LET STRING S2 = A1:
    LET STRING S3 = CORR:
    LET NLEN = 8
    LET S1 = STRING LEFT JUSTIFY S1 NLEN
    LET S2 = STRING LEFT JUSTIFY S2 NLEN
    LET S3 = STRING LEFT JUSTIFY S3 NLEN
    LET A0 = ROUND(A0,2)
    LET A1 = ROUND(A1,2)
    LET CC = ROUND(CC,2)
    LEGEND 1 ^S1 ^A0
    LEGEND 2 ^S2 ^A1
    LEGEND 3 ^S3 ^CC
    .
    CHARACTER X BLANK
    LINE BLANK SOLID
    .
    PLOT Y PRED VS X

-----STRING LENGTH-----------------------------------------------------
 
STRING LENGTH
 
Name:
    STRING LENGTH
 
Type:
    Let Subcommand
 
Purpose:
    Return the number of characters in a previously defined string.
 
Syntax:
    LET <nlen> = STRING LENGTH  <sorg>
    where <nlen> is a parameter containing the returned length
              of the string;
    and   <sorg> is the name of the string.
 
Examples:
    LET NLEN = STRING LENGTH S1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    SUBTRING            = Extract a substring from an existing string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING EDIT         = Edit a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    11/2008
 
Program:
    LET STRING S1 = file23.dat
    LET NLEN = STRING LENGTH S1

    The resulting value of NLEN is 10.

-----STRING MERGE-----------------------------------------------------
 
STRING MERGE
 
Name:
    STRING MERGE
 
Type:
    Let Subcommand
 
Purpose:
    Insert the contents of one string into another string at a
    specified position.
 
Description:
    This command is used to insert the contents of one string
    into an arbitrary position of another string.  For example,
    if the original string is

         FILE.DAT

    and the insertion string is

         99

    and the merge position is given as 5, then the resulting
    merged string would be

         FILE99.DAT

    Note that if the the merge position is 5, then the
    insertion string starts at position 5 (i.e., the position
    parameter is the before position rather than the after
    position).

    The STRING REPLACE command performs a similar function.
    However, the original string is not shifted.  In the above
    example, the resulting string from the STRING REPLACE command
    would be

         FILE99AT

    The STRING EDIT command can be used to perform more
    general edits of a string.

Syntax:
    LET <sout> = STRING MERGE  <sorg>  <snew>  <nstart>
    where <sout> is the name of the resulting string;
          <sorg> is the name of the original string;
          <snew> is the name of the insertion string;
    and   <nstart> is the merge position.
 
Examples:
    LET SOUT = STRING MERGE S1 SNEW NSTART
 
Note:
    The name of the new string can be the same as the original
    string.  For example,

        LET FNAME = STRING MERGE FNAME SNEW NSTART

Note:
    Both strings on the right hand side of the equal sign must be
    previously existing strings.  That is, expressions are not allowed.
    For example, instead of

        LET FNAME = STRING MERGE FNAME  ".dat"  NSTART

    you need to do

        LET STRING SNEW = .dat
        LET FNAME = STRING MERGE FNAME  SNEW  NSTART

    The starting position can be either a parameter or a numeric
    value.  However, it cannot be a numeric expression.  So

        LET FNAME = STRING MERGE FNAME  SNEW  NSTART
        LET FNAME = STRING MERGE FNAME  SNEW  5

    are both allowed but

        LET FNAME = STRING MERGE FNAME  SNEW  NLEN/2

    is not allowed.  You would need to enter this as

        LET NSTART = NLEN/2
        LET FNAME = STRING MERGE FNAME  SNEW  NSTART

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to the
    combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    SUBTRING            = Extract a substring from an existing string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING LENGTH       = Return the length of a string.
    STRING EDIT         = Edit a string.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    11/2008
 
Program 1:
    LET STRING S1 = file.dat
    LET STRING S2 = 23
    LET NPOS = 5
    LET SOUT = STRING MERGE S1 S2 NPOS

    The resulting string SOUT will contain

       file23.txt

Program 2:
    .  Assume we have variables X and Y in the files "file1.dat" to
    .  "file10.dat" and we want to plot each of these in turn.
    .
    LET STRING SOLD = file.dat
    LET NPOS = 5
    TITLE CASE ASIS
    LOOP FOR K = 1 1 10
        LET STRING S2 = ^K
        LET FNAME = STRING MERGE SOLD S2 NPOS
        READ ^FNAME  Y X
        TITLE Data from File ^SOUT
        PLOT Y X
        DELETE Y X
    END OF LOOP
 
-----STRING REMOVE PUNCTUATION--------------------------------------
 
STRING REMOVE PUNCTUATION

Name:
    STRING REMOVE PUNCTUATION
 
Type:
    Let Subcommand
 
Purpose:
    Remove the punctuation characters from a string.
 
Description:
    The following punctuation characters will be removed from the string

        !"'#$%&\()*+,-./:;<=>?@[]^_`~{}|

    If you would like to define your own list of characters to delete,
    you can use the command STRING DELETE.

Syntax:
    LET <sout> = STRING REMOVE PUNCTUATION  <sorg>
    where <sout> is the name of the resulting string;
    and   <sorg> is the name of the original string.

Examples:
    LET SOUT = STRING REMOVE PUNCTUATION STIN
 
Note:
    The name of the new string can be the same as the original
    string.  For example,

        LET STR = STRING REMOVE PUNCTUATION STR

    In this case, STR will now contain the the string with punctuation
    characters removed rather than the original string.

Note:
    The string on the right hand side of the equal sign must be a
    previously existing string.  That is, expressions are not allowed.
    For example, the following will result in an error message

        LET STOUT = STRING REMOVE PUNCTUATION "alan.heckert@nist.gov"

    you need to do

        LET STRING SORG = alan.heckert@nist.gov
        LET SOUT = STRING REMOVE PUNCTUATION SORG

    The name on the left hand side of the equal sign may be a
    previously existing string.  However, if it is a previously
    existing parameter, variable, or matrix name, an error will
    be reported and the requested string will not be created.

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to the
    combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STRING REMOVE SPACE       = Remove spaces from a string.
    STRING REMOVE WHITESPACE  = Remove white space characters from a string.
    STRING DELETE             = Remove user specifed characters from a
                                string.
    NUMBER OF WORDS           = Return the number of words in a string.
    UPPER CASE                = Convert a string to upper case.
    LOWER CASE                = Convert a string to lower case.
    LET FUNCTION              = Defines a function.
    LET STRING                = Defines a string.
    READ STRING               = Reads a string from a file.
    SUBSTITUTE CHARACTER (^)  = Substitute the value of a string or
                                parameter.
    CONCATENATE CHARACTER (&) = Concatenate two strings.
    SUBTRING                  = Extract a substring from an existing
                                string.
    STRING INDEX              = Extract the start/stop positions of a
                                substring within a string.
    STRING CONCATENATE        = Concatenate one or more previously
                                defined strings.
    STRING EDIT               = Edit a string.
    STRING MERGE              = Insert a string into another string
                                without overwrite.
    STRING LENGTH             = Return the length of a string.
    STRING WORD               = Extract a specified word from a string.
    CHARACTER                 = Convert numeric values to strings based
                                on the ASCII collating sequence.
    ICHAR                     = Convert a string to numeric values based
                                on the ASCII collating sequence.
    GROUP LABEL               = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2018/10
 
Program:
    read string stin
    alan.heckert@nist.gov;james.filliben@nist.gov
    let stout = string remove punctuation stin
    print stin stout

-----STRING REMOVE SPACES------------------------------------------
 
STRING REMOVE SPACES

Name:
    STRING REMOVE SPACES
 
Type:
    Let Subcommand
 
Purpose:
    Remove the spaces from a string.
 
Description:
    You can optionally remove all spaces, just the leading spaces, or
    just the trailing spaces from a string.

Syntax 1:
    LET <sout> = STRING REMOVE SPACES  <sorg>
    where <sout> is the name of the resulting string;
    and   <sorg> is the name of the original string.

    This syntax removes all spaces from the string.

Syntax 2:
    LET <sout> = STRING REMOVE LEADING SPACES  <sorg>
    where <sout> is the name of the resulting string;
    and   <sorg> is the name of the original string.

    This syntax removes only leading spaces from the string.

Syntax 3:
    LET <sout> = STRING REMOVE TRAILING SPACES  <sorg>
    where <sout> is the name of the resulting string;
    and   <sorg> is the name of the original string.

    This syntax removes only trailing spaces from the string.

Examples:
    LET SOUT = STRING REMOVE SPACES STIN
    LET SOUT = STRING REMOVE LEADING SPACES STIN
    LET SOUT = STRING REMOVE TRAILING SPACES STIN
 
Note:
    The name of the new string can be the same as the original
    string.  For example,

        LET FNAME = STRING REMOVE SPACES FNAME

    In this case, FNAME will now contain the the string with all spaces
    removed rather than the original string.

Note:
    The string on the right hand side of the equal sign must be a
    previously existing string.  That is, expressions are not allowed.
    For example, the following will result in an error message

        LET STOUT = STRING REMOVE SPACES "a b c d"

    you need to do

        LET STRING SORG = a b c d
        LET SOUT = STRING REMOVE SPACES SORG

    The name on the left hand side of the equal sign may be a
    previously existing string.  However, if it is a previously
    existing parameter, variable, or matrix name, an error will
    be reported and the requested string will not be created.

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to the
    combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NUMBER OF WORDS           = Return the number of words in a string.
    UPPER CASE                = Convert a string to upper case.
    LOWER CASE                = Convert a string to lower case.
    LET FUNCTION              = Defines a function.
    LET STRING                = Defines a string.
    READ STRING               = Reads a string from a file.
    SUBSTITUTE CHARACTER (^)  = Substitute the value of a string or
                                parameter.
    CONCATENATE CHARACTER (&) = Concatenate two strings.
    SUBTRING                  = Extract a substring from an existing
                                string.
    STRING INDEX              = Extract the start/stop positions of a
                                substring within a string.
    STRING CONCATENATE        = Concatenate one or more previously
                                defined strings.
    STRING EDIT               = Edit a string.
    STRING MERGE              = Insert a string into another string
                                without overwrite.
    STRING LENGTH             = Return the length of a string.
    STRING WORD               = Extract a specified word from a string.
    CHARACTER                 = Convert numeric values to strings based
                                on the ASCII collating sequence.
    ICHAR                     = Convert a string to numeric values based
                                on the ASCII collating sequence.
    GROUP LABEL               = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2015/03
 
Program:
    let string stin = a b c d
    let stout = string remove spaces stin
    print stin stout

-----STRING REMOVE WHITESPACE------------------------------------------
 
STRING REMOVE WHITESPACE

Name:
    STRING REMOVE WHITESPACE
 
Type:
    Let Subcommand
 
Purpose:
    Remove the white space characters from a string.
 
Description:
    The STRING REMOVE SPACES command can be used to remove spaces from a
    string.  This command will remove, in addition to spaces, the
    non-printing characters (i.e., codes 0 to 32 and 127 in the ASCII
    collating sequence).  Currently, Dataplot only checks for characters
    in the 0 - 127 range of the ASCII collating sequence.

Syntax:
    LET <sout> = STRING REMOVE WHITESPACE  <sorg>
    where <sout> is the name of the resulting string;
    and   <sorg> is the name of the original string.

Examples:
    LET SOUT = STRING REMOVE WHITESPACE STIN
 
Note:
    The name of the new string can be the same as the original
    string.  For example,

        LET STR = STRING REMOVE WHITESPACE STR

    In this case, STR will now contain the the string with all white
    space characters removed rather than the original string.

Note:
    The string on the right hand side of the equal sign must be a
    previously existing string.  That is, expressions are not allowed.
    For example, the following will result in an error message

        LET STOUT = STRING REMOVE WHITESPACE "a b c d"

    you need to do

        LET STRING SORG = a b c d
        LET SOUT = STRING REMOVE SPACES SORG

    The name on the left hand side of the equal sign may be a
    previously existing string.  However, if it is a previously
    existing parameter, variable, or matrix name, an error will
    be reported and the requested string will not be created.

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to the
    combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STRING REMOVE SPACE       = Remove spaces from a string.
    STRING REMOVE PUNCTUATION = Remove punctuation from a string.
    STRING DELETE             = Remove user specifed characters from a
                                string.
    NUMBER OF WORDS           = Return the number of words in a string.
    UPPER CASE                = Convert a string to upper case.
    LOWER CASE                = Convert a string to lower case.
    LET FUNCTION              = Defines a function.
    LET STRING                = Defines a string.
    READ STRING               = Reads a string from a file.
    SUBSTITUTE CHARACTER (^)  = Substitute the value of a string or
                                parameter.
    CONCATENATE CHARACTER (&) = Concatenate two strings.
    SUBTRING                  = Extract a substring from an existing
                                string.
    STRING INDEX              = Extract the start/stop positions of a
                                substring within a string.
    STRING CONCATENATE        = Concatenate one or more previously
                                defined strings.
    STRING EDIT               = Edit a string.
    STRING MERGE              = Insert a string into another string
                                without overwrite.
    STRING LENGTH             = Return the length of a string.
    STRING WORD               = Extract a specified word from a string.
    CHARACTER                 = Convert numeric values to strings based
                                on the ASCII collating sequence.
    ICHAR                     = Convert a string to numeric values based
                                on the ASCII collating sequence.
    GROUP LABEL               = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2018/10
 
Program:
    let string stin = a b c d
    let stout = string remove whitespace stin
    print stin stout

-----STRING REPEAT-----------------------------------------------------
 
STRING REPEAT

Name:
    STRING REPEAT
 
Type:
    Let Subcommand
 
Purpose:
    Create a string that repeats an input string a user
    specified number of times.

Syntax:
    LET <sout> = STRING REPEAT  <sorg>  <count>
    where <sout> is the name of the resulting string;
          <sorg> is the name of the original string;
    and   <count> is a number or parameter that specifies the
          number of times <sorg> will be repeated.

Examples:
    LET SOUT = STRING REPEAT S1 NWORD
    LET SOUT = STRING REPEAT S1 5
 
Note:
    The name of the new string can be the same as the original
    string.  For example,

        LET S1 = STRING REPEAT S1 COUNT

Note:
    The string on the right hand side of the equal sign must be a
    previously existing string.  That is, expressions are not allowed.
    For example, instead of

        LET SOUT = STRING REPEAT "a b c d"  2

    you need to do

        LET STRING SORG = a b c d
        LET SOUT = STRING REPEAT SORG  2

    The repeat factor can be either a parameter or a numeric value.
    However, it cannot be a numeric expression.  So

        LET SOUT = STRING REPEAT SORG  5
        LET SOUT = STRING REPEAT SORG  COUNT

    are both allowed but

        LET SOUT = STRING REPEAT SORG  COUNT/2

    is not allowed.  You would need to enter this as

        LET COUNT2 = COUNT/2
        LET SOUT = STRING REPEAT SORG COUNT2

    The name on the left hand side of the equal sign may be a
    previously existing string.  However, if it is a previously
    existing parameter, variable, or matrix name, an error will
    be reported and the requested string will not be created.

Note:
    The repeat factor should be in the range 1 to 255.  If the repeat
    factor is outside this range, an error is reported and the
    requested string will not be created.

    The maximum length of the string to be repeated is 255 characters.
    If the the string is longer than this, an error is reported and the
    requested string will not be created.
 
Note:
    The total number of characters that Dataplot can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (08/2021) is 100,000 characters.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NUMBER OF WORDS           = Return the number of words in a string.
    UPPER CASE                = Convert a string to upper case.
    LOWER CASE                = Convert a string to lower case.
    LET FUNCTION              = Defines a function.
    LET STRING                = Defines a string.
    READ STRING               = Reads a string from a file.
    SUBSTITUTE CHARACTER (^)  = Substitute the value of a string or
                                parameter.
    CONCATENATE CHARACTER (&) = Concatenate two strings.
    SUBTRING                  = Extract a substring from an existing
                                string.
    STRING INDEX              = Extract the start/stop positions of a
                                substring within a string.
    STRING CONCATENATE        = Concatenate one or more previously
                                defined strings.
    STRING EDIT               = Edit a string.
    STRING MERGE              = Insert a string into another string
                                without overwrite.
    STRING LENGTH             = Return the length of a string.
    STRING WORD               = Extract a specified word from a string.
    CHARACTER                 = Convert numeric values to strings based
                                on the ASCII collating sequence.
    ICHAR                     = Convert a string to numeric values based
                                on the ASCII collating sequence.
    GROUP LABEL               = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2021/08
 
Program:
    let x = sequence 1 1 10
    let x2 = x**2
    let x3 = x**3
    let string s = -
    let sdash = string repeat s 30
    set write format 3F10.0
    write1 temp.out "         X      X**2      X**3"
    write1 temp.out "^sdash"
    write1 temp.out x x2 x3

-----STRING REPLACE-----------------------------------------------------
 
STRING REPLACE
 
Name:
    STRING REPLACE
 
Type:
    Let Subcommand
 
Purpose:
    Insert the contents of one string into another string at a
    specified position.
 
Description:
    This command is used to insert the contents of one string
    into an arbitrary position of another string.  For example,
    if the original string is

         FILExx.DAT

    and the insertion string is

         99

    and the replacement position is given as 5, then the
    resulting string would be

         FILE99.DAT

    Note that the replacement string overwrites the contents
    of the original string.  Also note that if the the replacement
    position is 5, then the replacement string starts at position 5
    (i.e., the position parameter is the before position rather than
    the after position).

    The STRING MERGE command performs a similar function.
    However, the original string is shifted to the right at the
    replacement position rather than overwritten.  In the above
    example, the resulting string from the STRING MERGE command
    would be

         FILE99xx.DAT

    The STRING EDIT command can be used to perform more
    general edits of a string.

Syntax:
    LET <sout> = STRING REPLACE  <sorg>  <snew>  <nstart>
    where <sout> is the name of the resulting string;
          <sorg> is the name of the original string;
          <snew> is the name of the replacement string;
    and   <nstart> is the replacement position.
 
Examples:
    LET SOUT = STRING REPLACE S1 SNEW NSTART
 
Note:
    The name of the new string can be the same as the original
    string.  For example,

        LET FNAME = STRING REPLACE FNAME SNEW NSTART

Note:
    Both strings on the right hand side of the equal sign must be
    previously existing strings.  That is, expressions are not
    allowed.  For example, instead of

        LET FNAME = STRING REPLACE FNAME  ".dat"  NSTART

    you need to do

        LET STRING SNEW = .dat
        LET FNAME = STRING REPLACE FNAME  SNEW  NSTART

    The starting position can be either a parameter or a numeric
    value.  However, it cannot be a numeric expression.  So

        LET FNAME = STRING REPLACE FNAME  SNEW  NSTART
        LET FNAME = STRING REPLACE FNAME  SNEW  5

    are both allowed but

        LET FNAME = STRING REPLACE FNAME  SNEW  NLEN/2

    is not allowed.  You would need to enter this as

        LET NSTART = NLEN/2
        LET FNAME = STRING REPLACE FNAME  SNEW  NSTART

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to the
    combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    SUBTRING            = Extract a substring from an existing string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING LENGTH       = Return the length of a string.
    STRING EDIT         = Edit a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    11/2008
 
Program 1:
    LET STRING S1 = filexx.dat
    LET STRING S2 = 23
    LET NPOS = 5
    LET SOUT = STRING REPLACE S1 S2 NPOS

    The resulting string SOUT will contain

       file23.txt

Program 2:
    .  Assume we have variables X and Y in the files "file1.dat" to
    .  "file10.dat" and we want to plot each of these in turn.
    .
    LET STRING SOLD = filex.dat
    LET NPOS = 5
    TITLE CASE ASIS
    LOOP FOR K = 1 1 9
        LET STRING S2 = ^K
        LET FNAME = STRING REPLACE SOLD S2 NPOS
        READ ^FNAME  Y X
        TITLE Data from File ^SOUT
        PLOT Y X
        DELETE Y X
    END OF LOOP
 
-----STRING SPACE (SET)--------------------------------------------
 
STRING SPACE
 
Name:
    STRING SPACE (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify how a "SP()" is interpreted in a string.
 
Description:
    By default, the command

        LET STRING S = SP()

    will create a string S with a single space character.

    However, if you do something like

       LET STRING S = SP()
       LET STRING T = ^S

    you will get an error message and the string T will not be
    created.  This is due to the fact that the substitution
    (i.e., the "^") is performed before the command is
    interpreted.  That is, the command that Dataplot tries to
    interpret is

        LET STRING T = 

    However, if you enter the commands

       SET STRING SPACE IGNORE
       LET STRING S = SP()
       SET STRING SPACE EXPAND
       LET STRING T = ^S

    then Dataplot sees the command

       LET STRING T = SP()

    and it creates the string T with a single space character.

    Since in most cases you want the SP() to be converted to a
    single space, EXPAND is the default.

Syntax:
    SET STRING SPACE <EXPAND/IGNORE>

    Specifying EXPAND means that if SP() is encountered in a
    LET STRING command, it will be converted to a single space.
    Specifying IGNORE means that if SP() is encountered in a
    LET STRING command, it will left as SP().

    Any argument other than PROMPT or TERMINATE will be treated as
    equivalent to IGNORE (for example, SET FATAL ERROR DEFAULT).
 
Examples:
    SET STRING SPACE IGNORE
    SET STRING SPACE EXPAND
 
Default:
    EXPAND is the default.
 
Synonyms:
    OFF and NO will be interpreted as IGNORE.  All other arguments
    will be interpreted as EXPAND.
 
Related Commands:
    LET STRING    = Define a string.
    ^             = Substitute the value of a string or parameter.
 
Applications:
    String Manipulation
 
Implementation Date:
    2009/02
 
Program:
    . The following sequence of commands results in an error
    . for the string st2.
    .
    let string st1 = sp()
    let string st2 = ^st1
    .
    . The following successfully creates st2 as a string with
    . single blank character.
    .
    set string space ignore
    let string st1 = sp()
    set string space expand
    let string st2 = ^st1

-----STRING SPLIT-------------------------------------------
 
STRING SPLIT
 
Name:
    STRING SPLIT
 
Type:
    Let Subcommand
 
Purpose:
    Extract the individual words from a currently existing string.

Description:
    This command is used to extract the individual words from a string.

    This command is an alternative to using STRING WORD.  STRING WORD is
    used to extract a specific word in the string while STRING SPLIT will
    extract all the words in a string to individual strings.  Note that
    only the base name will be specified.  For example, if you specify
    SOUT as the base name and there are three words in the original
    string, then string SOUT1 will contain the first word, SOUT2 will
    contain the second word, and SOUT3 will contain the third word.

    In Dataplot, spaces are used to separate words.

Syntax:
    LET <sout> = STRING SPLIT  <sorg>
    where <sorg> is the name of a pre-existing string.
    and   <sout> is the base name of the resulting strings;

    The <sout> defines the base name.  An integer index will be appended
    to the base name for each string (the index starts at 1).

Examples:
    LET STBASE = STRING SPLIT SORG
 
Note:
    The original string being processed must be a pre-existing string.
    If you want to split literal text, you need to do something like

        LET STRING SORG = xxxx yyyy zzzz
        LET SOUT = STRING SPLIT SORG

    Using

        LET SOUT = STRING SPLIT xxxx yyyy zzzz

    will not work.  It will try to see if "xxxx" is the name of currently
    defined string.  If it is not, no new strings will be created.
    Enclosing the literal text in quotes will not make this work.

    The name on the left hand side of the equal sign may be a
    previously existing string.  However, if it is a previously
    existing parameter, variable, or matrix name, an error will
    be reported and the requested string will not be created.

Note:
    By default, Dataplot uses a space as the word delimiter.  You can
    specify an alternative character to be the word delimiter with
    the command

        SET WORD DELIMITER  <char>

    with <char> denoting the character to use as the word delimiter.

Note:
    Starting with the 2020/08 version of Dataplot, the parameter
    NUMBWORD is automatically created.  This parameter contains the
    number of strings that are created by this command.

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to
    the combined number of characters for all functions and strings.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STRING CONCATENATE  = Concatenate two or more strings.
    &                   = Concatenate two strings.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBTRING            = Extract a substring from an existing string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING EDIT         = Edit a string.
    STRING LENGTH       = Return the length of a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2018/10
    2020/08: Automatically save NUMBWORD parameter
 
Program:
    LET STRING SORG = X1 X2 X3 X4 X5
    LET SNAME = STRING SPLIT SORG
    PRINT SNAME1 SNAME2 SNAME3 SNAME4 SNAME5

-----STRING STARTS WITH----------------------------------------------
 
STRING STARTS WITH
 
Name:
    STRING STARTS WITH
 
Type:
    Let Subcommand
 
Purpose:
    Return a 1 if a string starts with a specified substring
    and a 0 if it does not.
 
Syntax:
    LET <iflag> = STRING STARTS WITH  <s1>  <s2>
    where <iflag> is a parameter containing a 1 if <s1> starts
              with <s2> and 0 otherwise;
          <s1> is the name of a pre-existing string;
    and   <s2> is the name of a pre-existing string.
 
Examples:
    LET IFLAG = STRING STARTS WITH S1  S2

Note:
    The strings on the right hand side of the equal sign must be
    previously existing strings.  That is, expressions are not allowed.
    For example, the following will result in an error message

        LET IFLAG = STRING STARTS WITH "alan.heckert@nist.gov"  "alan"

    you need to do

        LET STRING SORG = alan.heckert@nist.gov
        LET STRING SMATCH = alan
        LET SOUT = STRING STARTS WITH SORG SMATCH

    The name on the left hand side of the equal sign should either be a
    previously existing parameter or not previously defined.  If it is a
    previously existing string, variable, or matrix name, an error will
    be reported and the requested parameter will not be created.

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to
    the combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STRING ENDS WITH    = Check whether a string ends with a
                          specified substring.
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    SUBTRING            = Extract a substring from an existing string.
    STRING LENGTH       = Return the length of the string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING EDIT         = Edit a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2018/10
 
Program:
    LET STRING S1 = alan.heckert@gmail.com
    LET STRING S2 = alan
    LET IFLAG = STRING STARTS WITH S1 S2

-----STRING SUBSET COUNT-----------------------------------------
 
STRING SUBSET COUNT
 
Name:
    STRING SUBSET COUNT
 
Type:
    Let Subcommand
 
Purpose:
    Return the number of times a substring occurs within another string.
 
Syntax:
    LET <count> = STRING SUBSET COUNT  <sorg>  <smatch>
    where <count> is a parameter containing the number of times <smatch>
              is found in <sorg>;
          <sorg> is the name of a pre-existing string;
    and   <smatch> is the name of a pre-existing string.
 
Examples:
    LET NC = STRING SUBSET COUNT SORG SMATCH

Note:
    The strings on the right hand side of the equal sign must be
    previously existing strings.  That is, expressions are not allowed.
    For example, the following will result in an error message

        LET NC = STRING SUBSET COUNT "alan.heckert@nist.gov"  "@"

    you need to do

        LET STRING SORG = alan.heckert@nist.gov
        LET STRING SMATCH = @
        LET NC = STRING SUBSET COUNT SORG SMATCH

    The name on the left hand side of the equal sign should either be a
    previously existing parameter or not previously defined.  If it is a
    previously existing string, variable, or matrix name, an error will
    be reported and the requested parameter will not be created.

Note:
    The total number of characters that Dataplot can use for storing
    functions and strings is set when Dataplot is built.  The current
    default (11/2008) is 50,000 characters.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SUBTRING            = Extract a substring from an existing string.
    STRING ENDS WITH    = Check whether a string starts with a
                          specified substring.
    STRING ENDS WITH    = Check whether a string ends with a
                          specified substring.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    STRING LENGTH       = Return the length of the string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING EDIT         = Edit a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2019/02
 
Program:
    LET STRING S1 = alan.heckert@nist.gov,james.filliben@nist.gov
    LET STRING S2 = @
    LET NNAMES = STRING SUBSET COUNT S1 S2

-----STRING VARIABLE (SET)---------------------------------------
 
SET STRING VARIABLE
 
Name:
    STRING VARIABLE (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify whether the READ and STRING VARIABLE commands will overwrite
    the contents of the dpzchf.dat file or append the new data to the
    current contents of the dpzchf.dat file.
 
Description:
    The READ command can optionally read character variables
    (HELP SET CONVERT CHARACTER).  Dataplot saves the character
    variables in the file "dpzchf.dat".  In addition, the
    LET ... = STRING VARIABLE command can be used to create a character
    variable from a list of strings.  This variable will be saved in
    the "dpzchf.dat" as well.

    By default, Dataplot overwrites the current contents of the
    "dpzchf.dat" file whenever a READ or STRING VARIABLE command
    creates new character variables.  To have these commands append
    the contents of the new character variables to the current contents
    of "dpzchf.dat", enter the command

         SET STRING VARIABLE APPEND

    To reset the default of overwriting the current contents of
    "dpzchf.dat", enter

         SET STRING VARIABLE OVERWRITE

Syntax:
    SET STRING VARIABLE <OVERWRITE/APPEND>
    where OVERWRITE replaces the current contents of "dpzchf.dat"
    and APPEND appends to the current contents of "dpzchf.dat".

Examples:
    SET STRING VARIABLE APPEND
    SET STRING VARIABLE OVERWRITE

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    STRING VARIABLE    = Create a character variable from a list of
                         strings.
    READ               = Read numeric/character variables from a file.
 
Applications:
    Character Data
 
Implementation Date:
    2019/09
 
Program:
    set string variable overwrite
    let string s1 = Group 1
    let string s2 = Group 2
    let string s3 = Group 3
    let ix = string variable s1 s2 s3
    list dpzchf.dat
    pause
    .
    set string variable append
    let string s4 = Group 4
    let string s5 = Group 5
    let string s6 = Group 6
    let iy = string variable s4 s5 s6
    list dpzchf.dat

-----STRING VARIABLE-------------------------------------------
 
STRING VARIABLE
 
Name:
    STRING VARIABLE
 
Type:
    Let Subcommand
 
Purpose:
    Create a string variable from a list of strings and save it to
    the file dpzchf.dat.

Description:
    The Dataplot READ command can optionally read character data.  The
    READ command saves these character variables to the file
    "dpzchf.dat".

    The STRING VARIABLE command allows you to add character variables
    to "dpzchf.dat" from a list of scalar strings.

    You can specify whether you want Dataplot to overwrite the current
    contents of "dpzchf.dat" or append the new variable to the current
    contents of "dpzchf.dat".

    To have the STRING VARIABLE command overwrite the current contents
    of "dpzchf.dat", enter

        SET CHARACTER VARIABLE OVERWRITE

    To have the STRING VARIABLE command append the new string variable to
    the current contents of "dpzchf.dat", enter

        SET CHARACTER VARIABLE APPEND

Syntax:
    LET <sout> = STRING VARIABLE  <s1>  ... <sk>
    where <sout> is the name of the resulting string variable;
    and   <s1> ... <sk> is a list of one or more previously defined
          strings or literal text strings.
 
    Literal text strings should be enclosed in quotes.  If an
    argument on the right hand side of the equal sign is not enclosed
    in quotes, it will be assumed to be a previously defined string.
    If an argument is not enclosed in quotes and is not the name of
    a previously defined string, an error message will be returned and
    <sout> will not be created.

    The TO syntax is supported for the argument list (see the Examples).

Examples:
    LET IX = STRING VARIABLE  S1 S2 S3
    LET IX = STRING VARIABLE  S1 TO S10
    LET IX = STRING VARIABLE  "Group 1"  "Group 2"  "Group 3"
    LET IX = STRING VARIABLE  "Group 1"  S2  "Group 3" S4

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    READ                = Read variables from the terminal or a file.
    READ STRING         = Reads a string from a file.
    LET STRING          = Defines a string.
    STRING CONCATENATE  = Concatenate two or more strings.
    &                   = Concatenate two strings.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    LET FUNCTION        = Defines a function.
    SUBTRING            = Extract a substring from an existing string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING EDIT         = Edit a string.
    STRING LENGTH       = Return the length of a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2019/10
 
Program 1:
    set string variable overwrite
    let ix = string variable "Group 1" "Group 2"  "Group 3"
    list dpzchf.dat

Program 2:
    set string variable overwrite
    let string s1 = Group 1
    let string s2 = Group 2
    let string s3 = Group 3
    let ix = string variable s1 s2 s3
    list dpzchf.dat
    pause
    .
    set string variable append
    let string s4 = Group 4
    let string s5 = Group 5
    let string s6 = Group 6
    let iy = string variable s4 s5 s6
    list dpzchf.dat

-----STRING WORD-----------------------------------------------------
 
STRING WORD

Name:
    STRING WORD
 
Type:
    Let Subcommand
 
Purpose:
    Extract a specified word from a string.
 
Description:
    There may be times when it is useful to extract the individual
    words in a string.

    Dataplot delineates words in a string by spaces.  It will treat
    non-printing characters in the string as spaces.  That is,
    any character in the string with an ASCII collating index less
    than or equal to 32 or greater than 127 will be treated as a space.
    In particular, tabs will be treated as spaces.  However, hyphens
    and other special characters such as "&" will not be treated as
    word boundaries.

Syntax:
    LET <sout> = STRING WORD  <sorg>  <nword>
    where <sout> is the name of the resulting string;
          <sorg> is the name of the original string;
    and   <nword> is the index of the word to extract.

Examples:
    LET SOUT = STRING WORD S1 NWORD
    LET SOUT = STRING WORD S1 5
 
Note:
    The name of the new string can be the same as the original
    string.  For example,

        LET FNAME = STRING WORD FNAME NWORD

    In this case, FNAME will now contain the extracted word rather than
    the original string.

Note:
    The string on the right hand side of the equal sign must be a
    previously existing string.  That is, expressions are not allowed.
    For example, instead of

        LET FNAME = STRING WORD "a b c d"  2

    you need to do

        LET STRING SORG = a b c d
        LET FNAME = STRING WORD SORG  2

    The word index position can be either a parameter or a numeric
    value.  However, it cannot be a numeric expression.  So

        LET FNAME = STRING WORD SORG  5
        LET FNAME = STRING WORD SORG  NWORD

    are both allowed but

        LET FNAME = STRING WORD SORG  NWORD/2

    is not allowed.  You would need to enter this as

        LET NWORD = NWORD/2
        LET FNAME = STRING WORD FNAME  NWORD

    The name on the left hand side of the equal sign may be a
    previously existing string.  However, if it is a previously
    existing parameter, variable, or matrix name, an error will
    be reported and the requested string will not be created.

Note:
    If the requested word is less than one or is greater than the
    number of words in the string, an error is reported and the
    requested string will not be created.
 
Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to the
    combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    NUMBER OF WORDS           = Return the number of words in a string.
    UPPER CASE                = Convert a string to upper case.
    LOWER CASE                = Convert a string to lower case.
    LET FUNCTION              = Defines a function.
    LET STRING                = Defines a string.
    READ STRING               = Reads a string from a file.
    SUBSTITUTE CHARACTER (^)  = Substitute the value of a string or
                                parameter.
    CONCATENATE CHARACTER (&) = Concatenate two strings.
    SUBTRING                  = Extract a substring from an existing
                                string.
    STRING INDEX              = Extract the start/stop positions of a
                                substring within a string.
    STRING CONCATENATE        = Concatenate one or more previously
                                defined strings.
    STRING EDIT               = Edit a string.
    STRING MERGE              = Insert a string into another string
                                without overwrite.
    STRING LENGTH             = Return the length of a string.
    CHARACTER                 = Convert numeric values to strings based
                                on the ASCII collating sequence.
    ICHAR                     = Convert a string to numeric values based
                                on the ASCII collating sequence.
    GROUP LABEL               = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    10/2010
 
Program:
    let string s = funnel ramp cone square
    .
    feedback off
    print "String s = ^s"
    let nword = number of words s
    loop for k = 1 1 nword
        let s^k = string word s k
        print "String ^k = ^s^k"
    end of loop
    feedback on

-----STRIP PLOT-------------------------------------------------------
 
STRIP PLOT
 
Name:
    ... STRIP PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a strip plot (also known as a dot plot).
 
Description:
    A strip plot is a graphical data anlysis technique for
    summarizing a univariate data set.  The strip plot consists of:
   
        Horizontal axis = the value of the response variable;
        Verticalal axis = all values are set to 1.

    That is, a strip plot is simply a plot of the sorted response
    values along one axis.  The strip plot is an alternative
    to a histogram or a density plot.  It is typically used for
    small data sets (histograms and density plots are typically
    preferred for larger data sets).

    There are a few variations supported for the strip plot.

       1) One problem with strip plots is how to display
          multiple points with the same value.  Dataplot provides
          two options to address this.

           i) With the jitter option, a small amount of random
              noise is added to the vertical coordinate.

          ii) With the stack option, repeated values add a
              fixed increment to the vertical coordinate.
              So if there are 3 points with the same value,
              the y coordinates might be 1, 1.1, and 1.2.
              This gives the strip plot a histogram-like
              appearance.

              The value of the fixed increment can be set
              with the command

                  SET STRIP PLOT INCREMENT <value>

              The default value is 1, although a value of
              on the order of 0.1 is often desirable.  This
              command can be used with the YLIMITS command and
              the CHARACTER SIZE command to generate the desired
              appearance for the plot.

          You can specify your preference with the command

              SET STRIP PLOT STYLE <STACK/JITTER>

          The default value is STACK.

       2) The strip plot can be generated with a group-id
          variable.  For this variant, the y coordinate is
          is set equal to the corresponding value of the
          group-id variable.  This results in a set of parallel
          strip plots.
      

       3) You can generate a strip plot with binned data.
          In this case, the STACK option is automatically
          used.  This option is essentially an alternative
          form for a histogram.  Binned data can also be
          grouped.

          You can bin your data with the command

              LET Y2 X2 = BINNED Y

          The binning algorithm can be controlled with the
          commands

              CLASS LOWER  <value>
              CLASS UPPER  <value>
              CLASS WIDTH  <value>
 
Syntax 1:
    STRIP PLOT <y>            <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
    and where the <SUBSET/EXCEPT/FOR qualification is optional.
 
    This syntax is used when you have raw data with a single group.
 
Syntax 2:
    STRIP PLOT <y> <x>        <SUBSET/EXCEPT/FOR qualification>
    where <y> is the variable of pre-computed frequencies;
          <x> is the variable containing the class mid-points;
    and where the <SUBSET/EXCEPT/FOR qualification is optional.
 
    This syntax is used when you have binned data with a single
    group.
 
Syntax 3:
    BATCH STRIP PLOT <y> <tag>     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <tag> is a group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification is optional.
 
    This syntax is used when you have raw data with multiple
    groups.

    The word BATCH is required here to distinguish the
    multiple groups case from the binned data case.

Syntax 4:
    BATCH STRIP PLOT <y> <x> <tag>
                     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the variable of pre-computed frequencies;
          <x> is the variable containing the class mid-points;
          <tag> is a group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification is optional.
 
    This syntax is used when you have binned data with multiple
    groups.
 
    In this case, the word BATCH is optional.

Syntax 5:
    BATCH MULTIPLE STRIP PLOT <y> <tag1> <tag2>
                              <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <tag1> is a group-id variable;
          <tag2> is a group-id variable;
    and where the <SUBSET/EXCEPT/FOR qualification is optional.
 
    This syntax is used when you have raw data with two group-id
    variables.

    The first group-id variable works as in Syntax 3.  That is, it
    defines the position on the y-axis.  The second group-id variable
    is used to identify multiple curves within the first group-id
    variable.  Appropriate settings for the the CHARACTER command
    and its various attribute setting commands can be used to highlight
    the different sub-groups within a group.  This option is
    demonstrated with the Program 4 example below.

Examples:
    STRIP PLOT Y
    STRIP PLOT Y  SUBSET Y > 2
    STRIP PLOT Y X

Note:
    The appearance of the strip plot can be controlled by
    appropriate settings for the CHARACTER command (and its
    attributes).

    This is demonstrated in the sample programs below.
 
Note:
    You may want to generate strip plots for the case where there
    are multiple group variables.  This can done using the
    CODE CROSS TABULATE command.  For example, if there are two
    group id variables, you can do something like

         LET ICODE = CODE CROSS TABULATE X1 X2

    Then use ICODE as the single group id variable.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    HISTOGRAM             = Generates a histogram.
    FREQUENCY PLOT        = Generates a frequency plot.
    CLASS LOWER           = Sets the lower class minimum for
                            histograms, frequency plots, and
                            pie charts.
    CLASS UPPER           = Sets the upper class maximum for
                            histograms, frequency plots, and
                            pie charts.
    CLASS WIDTH           = Sets the class width for histograms,
                            frequency plots, and pie charts.
    HISTOGRAM CLASS WIDTH = Specify alternative default class wdith
                            algorithms for histograms.
    LIMITS                = Sets the frame limits for all plots.
    CHARACTERS            = Sets the character symbol for plots.
 
Reference:
    "Standard Practice for Statistical Analysis of One-Sample and
    Two-Sample Interlaboratory Proficiency Testing Programs", 2006,
    ASTM International, 100 Barr Harbor Drive, PO BOX C700,
    West Conshohoceken, PA 19428-2959, USA.
 
    Unwin, Theus, and Hofmann (2006), "Graphics of Large
    Datasets: Visualizing a Million", Springer, p. 36.

Applications:
    Data Analysis
 
Implementation Date:
    11/2008
    10/2009: Added the "BATCH MULTIPLE" option
 
Program 1:
    .
    .  Step 1: Read the data
    .
    skip 25
    read E2489A.DAT labid y
    .
    title case asis
    title offset 2
    label
    x2frame off
    y2frame off
    char circle all
    char hw 1 0.75 all
    char fill on all
    line blank all
    tic offset units data
    tic offset 0 0
    xtic offset 0.2 0.2
    .
    set strip plot increment 0.1
    set strip plot style stack
    .
    multiplot corner coordiantes 5 5 95 95
    multiplot scale factor 2 1
    multiplot 2 1
    .
    .  Step 2a: Generate the strip plot for unbinned data
    .           (with one group) Stack Option
    .
    ylimits 0 2
    y1tic marks off
    y1tic mark labels off
    y1frame off
    title Strip Plot - Stacked, Single Group
    y1label Number of Occurrences
    x1label Data Values
    label case asis
    strip plot y
    .
    .  Step 2b: Generate the strip plot for unbinned data
    .           (with one group) Jitter Option
    .
    set strip plot style jitter
    .
    title Strip Plot - Jittered, Single Group
    x1label Data Values
    strip plot y
    .
    end of multiplot

Program 2:
    .
    .  Step 1: Read the data
    .
    skip 25
    read gear.dat y x
    .
    title case asis
    title offset 2
    label
    x2frame off
    y2frame off
    char circle all
    char hw 1 0.75 all
    char fill on all
    line blank all
    .
    set strip plot increment 0.15
    set strip plot style stack
    .
    ylimits 1 10
    major ytic mark number 10
    minor ytic mark number 0
    y1tic mark offset 1 1
    tic offset unit data
    ygrid on
    title Strip Plot - Stacked, Multiple Groups
    y1label Batch Number
    x1label Data Values
    label case asis
    xlimits 0.98 1.02
    major xtic mark number 5
    minor xtic mark number 1
    xtic mark offset 0.002 0.002
    .
    batch strip plot y x

Program 3:
    .
    .  Step 1: Read the data
    .
    skip 25
    read E2489A.DAT labid y
    .
    .  Step 2: Bin the data
    .
    class lower 0.0
    class upper 5.0
    class width 0.1
    let y2 x2 = binned y
    .
    .  Step 3: Define the appearance of the plot
    .
    title case asis
    title offset 2
    label
    x2frame off
    y2frame off
    char circle all
    char hw 1 0.75 all
    char fill on all
    line blank all
    tic offset units data
    tic offset 0 0
    xtic offset 0.2 0.2
    .
    ylimits 0.8 2
    y1tic marks off
    y1tic mark labels off
    y1frame off
    title Strip Plot - Single Group with Binned Data
    y1label Number of Occurrences
    x1label Data Values
    label case asis
    .
    .  Step 4: Generate the strip plot
    .
    frame corner coordinate 15 35 85 70
    set strip plot increment 0.1
    set strip plot style stack
    strip plot y2 x2

Program 4:
    .
    .  Step 1: Read the data
    .
    skip 25
    read ripken.dat y x1 x2
    .
    .  Step 2: Set Plot Options
    .
    title case asis
    title offset 2
    label
    x2frame off
    y2frame off
    char circle all
    char hw 1 0.75 all
    char fill on all
    char color red blue green red blue green red blue green
    line blank all
    .
    tic offset unit data
    ylimits 1 3
    major ytic mark number 3
    minor ytic mark number 0
    y1tic mark label format alpha
    y1tic mark label content Inside Middle Outside
    y1label Horizontal Location
    y1tic mark offset 0.2  0.2
    ygrid on
    grid pattern dotted
    x1label Batting Average
    label case asis
    tic mark label case asis
    xlimits 0 1
    major xtic mark number 6
    minor xtic mark number 1
    xtic mark offset 0.05 0.05
    x3label Vertical Location: Red = Low, Blue = Middle, Green = High
    .
    .  Step 3: Generate the Strip Plot
    .
    set strip plot increment 0.1
    . set strip plot style stack
    set strip plot style jitter
    title Strip Plot - Stacked, Multiple Batch Option
    batch multiple strip plot y x1 x2

-----STROM (LET)--------------------------------
 
STROM
 
Name:
    STROM (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the Stromgren integral.
 
Description:
    The Stromgren integral is defined as:

        f(x) = C*INTEGRAL[t**7*EXP(2*t)/((EXP(t)-1)**3)dt]   x >= 0

    where C = (15/(4*PI**4)) and the integral is defined from
    0 to x.

    Dataplot computes this function using ACM Algorithm 757 (see
    Reference: below).
 
Syntax:
    LET <y> = STROM(<x>)    <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, variable or parameter;
          <y> is a variable or a parameter (depending on what <x> 
               is) where the computed Stromgren integral values are
               stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = STROM(2)
    LET A = STROM(X) 
    LET X2 = STROM(X) FOR X1 = 0.1 0.1 3.0
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    ABRAM      = Compute the Abramowitz integral.
    CLAUSN     = Compute the Clausen integral.
    DEBYE      = Compute the Debye function.
    EXP3       = Compute the cubic exponential integral.
    GOODST     = Compute the Goodwin and Stanton integral.
    LOBACH     = Compute the Lobachevski integral.
    SYNCH1     = Compute the synchrotron radiation function.
    SYNCH2     = Compute the synchrotron radiation function.
    TRAN       = Compute the transport integral.
 
Reference:
    "ACM Transactions of Mathematical Software", Allan MacLead,
    Vol. 22, No. 3, September, 1996, pp. 288-301.
 
Applications:
    Special Functions
 
Implementation Date:
    1999/6
 
Program:
    TITLE AUTOMATIC
    PLOT STROM(X) FOR X = 0 0.01 10
 
-----SUBREGION --------------------------------------------------
 
SUBREGION
 
Name:
    SUBREGION
 
Type:
    Plot Control Command
 
Purpose:
    Specifies whether subregions on subsequent plots are on (active)
    or off (inactive).
 
Description:
    Dataplot now supports subregions on plots.  Subregions are
    motivated by the desire to denote "engineering limits" on a
    plot.  That is, a rectangle, denoting an acceptance region in
    both the X and Y directions, is drawn and then the plot is
    overlaid on top of this.

    Although the subregion capability was motivated for the purpose
    of denoting engineering limits, they can in fact be used for
    whatever purpose you want.  Subregions apply to all subsequent
    2-D plots (but not 3-D plots).

    Currently, subregions are limited to rectangular regions.  This
    will be upgraded to polygonal regions in a future implementation.

    The SUBREGION command is used to turn subregions on or off and
    up to 10 subregions can be specified.  In most cases where
    subregions are defined, only a single subregion is used.

Syntax:
    SUBREGION <ON/OFF> <ON/OFF> ... <ON/OFF>
    where <ON> specifies that the subregion is active and OFF
               specifies that it is inactive.  Up to 10 subregion
               switches can be set.

    In most cases, only a single subregion is specified.

Examples:
    SUBREGION ON
    SUBREGION OFF
    SUBREGION ON ON ON
 
Note:
    The coordinates for the subregion areas are set with the
    SUBREGION LIMITS command.

Note:
    The subregions are plotted before any of the plot
    curves.  The significance of this is that a solid filled
    subregion will be drawn and then the regular plot points
    are drawn on top.  The effect of this can be hardware
    dependent.  On X11 and Postscript devices, a solid character
    can be seen on top of a light gray scale box (if the gray
    scale gets too dark, the plot points are no longer
    distinguishable).  However, on some hardware devices, you may
    not be able to see points plotted on top of a solid fill
    region.  In this case, plot the border of the subregion and
    leave the interior blank.

    It is this order of plotting that distinguishes the
    subregion from simply using a BOX <id> command to plot
    rectangular regions on the screen.

Note:
    For the first subregion defined, Dataplot returns the following
    internal parameters on subsequent plots:

       NACCEPT = number of plot points inside the subregion.
       NREJECT = number of plot points outisde the subregion.
       NTOTAL  = number of plot points (NACCEPT + NREJECT).

Note:
    You do not need to adjust the settings for the CHARACTER, LINE,
    BAR, and SPIKE when using subregions.  DATAPLOT automatically
    shifts these in the background.  The attributes for the subregion
    are set with the following commands:

       REGION FILL <ON/OFF>
       REGION COLOR <COLOR>
       REGION BORDER LINE <LINETYPE>
       REGION BORDER COLOR <COLOR>

    The REGION FILL and REGION COLOR determine the attributes of the
    interior of the rectangle.  The two most common choices are
    to leave it blank or to fill it with some type of light
    gray scale color.  The attributes of the rectangle border are
    set with the REGION BORDER LINE and REGION BORDER COLOR commands.
    The standard line types (SOLID, BLANK, DASH, DOTTED) are supported.
    If you have more than one subregion defined, you should specify
    multiple settings on the above commands.  For example,
 
       REGION FILL ON ON ON
       REGION COLOR G25 G25 G25

Note:
    The SUBREGION command with no argument turns off all subregions.
 
Default:
    No subregions are drawn.
 
Synonyms:
    None
 
Related Commands:
    PLOT              = Generates a data or function plot.
    SUBREGION LIMITS  = Specifiy the limits for a subregion.
 
Applications:
    Denoting "Engineering Limits" on plots.
 
Implementation Date:
    2000/1
 
Program:
    dimension 50 varialbes
    skip 25
    read simon1.dat y1 y2 x1 x2 x3 x4 x5 block runseq
    .
    char x 
    line blank
    .
    subregion on
    subregion xlimits 0.35 0.42
    subregion ylimits 2000 3000
    region fill on
    region border line dash
    region color g90
    .
    plot y1 vs x1
    .
    move 20 80
    text n = ^ntotal
    move 20 75
    text accept = ^naccept
    move 20 70
    text reject = ^nreject
 
-----SUBREGION LIMITS--------------------------------------------------
 
SUBREGION LIMITS
 
Name:
    ...SUBREGION LIMITS
 
Type:
    Plot Control Command
 
Purpose:
    Specifies the limits (minimum and maximum) for subregions
    of subsequent plots.
 
Description:
    Dataplot now supports subregions on plots.  Subregions are
    motivated by the desire to denote "engineering limits" on a
    plot.  That is, a rectangle, denoting an acceptance region in
    both the X and Y directions, is drawn and then the plot is
    overlaid on top of this.

    Although the subregion capability was motivated for the purpose
    of denoting engineering limits, they can in fact be used for
    whatever purpose you want.  Subregions apply to all subsequent
    2-D plots (but not 3-D plots).

    Currently, subregions are limited to rectangular regions.  This
    will be upgraded to polygonal regions in a future implementation.

    The SUBREGION command is used to turn subregions on or off and
    up to 10 subregions can be specified.  In most cases where
    subregions are defined, only a single subregion is used.

Syntax 1:
    SUBREGION <prefix>LIMITS   <n1>   <n2>
    where <n1> is a number or parameter that specifies the desired
               lower limit;
          <n2> is a number or parameter that specifies the desired
               upper limit;
    and   <prefix> is one of the following:
               X             refers to vertical axis
               Y             refers to horizontal axis
               no prefix     refers to both axes.
 
    This syntax sets the subregion limits for the first subregion.

Syntax 2:
    SUBREGION <id> <prefix>LIMITS   <n1>   <n2>
    where <id> is a number or parameter between 1 and 10 that specifies
               which of the 10 subregions that these limits apply to;
          <n1> is a number or parameter that specifies the desired
               lower limit;
          <n2> is a number or parameter that specifies the desired
               upper limit;
    and   <prefix> is one of the following:
               X             refers to vertical axis
               Y             refers to horizontal axis
               no prefix     refers to both axes.
 
Examples:
    SUBREGION LIMITS 0.5 4.5
    SUBREGION XLIMITS 0 100
    SUBREGION YLIMITS 0 100
    SUBREGION XLIMITS A B
    SUBREGION 2 LIMITS 0.5 4.5
 
Note:
    You do not need to adjust the settings for the CHARACTER, LINE,
    BAR, and SPIKE when using subregions.  DATAPLOT automatically
    shifts these in the background.  The attributes for the subregion
    are set with the following commands:

       REGION FILL <ON/OFF>
       REGION COLOR <COLOR>
       REGION BORDER LINE <LINETYPE>
       REGION BORDER COLOR <COLOR>

    The REGION FILL and REGION COLOR determine the attributes of the
    interior of the rectangle.  The two most common choices are
    to leave it blank or to fill it with some type of light
    gray scale color.  The attributes of the rectangle border are
    set with the REGION BORDER LINE and REGION BORDER COLOR commands.
    The standard line types (SOLID, BLANK, DASH, DOTTED) are supported.
    If you have more than one subregion defined, you should specify
    multiple settings on the above commands.  For example,
 
       REGION FILL ON ON ON
       REGION COLOR G25 G25 G25

Note:
    The SUBREGION ...LIMITS command with no argument reverts the limits
    to the default.  A SUBREGION ...LIMITS command with no prefix refers
    to both axes.  Thus SUBREGION LIMITS 3 7 sets the limits for both
    axes to 3 and 7.
 
Default:
    No subregions are drawn.  If a subregion is turned on, but no
    limits are specified, then the subregion extends to the minimum and
    maximum points in both the X and Y axes.
 
Synonyms:
    None
 
Related Commands:
    PLOT        = Generates a data or function plot.
    SUBREGION   = Specifiy whether a subregion is on or off.
 
Applications:
    Denoting "Engineering Limits" on plots.
 
Implementation Date:
    2000/1
 
Program:
    dimension 50 varialbes
    skip 25
    read simon1.dat y1 y2 x1 x2 x3 x4 x5 block runseq
    .
    char x 
    line blank
    .
    subregion on
    subregion xlimits 0.35 0.42
    subregion ylimits 2000 3000
    region fill on
    region border line dash
    region color g90
    .
    plot y1 vs x1
    .
    move 20 80
    text n = ^ntotal
    move 20 75
    text accept = ^naccept
    move 20 70
    text reject = ^nreject
 
-----SUBSAMPLE (LET)--------------------------------
 
SUBSAMPLE
 
Name:
    SUBSAMPLE (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute a subsample for a variable based on another index variable.
 
Description:
    The SUBSAMPLE command is similar to the BOOTSTRAP SAMPLE command.
    In either case, an index variable is generated (often with the
    DISCRETE UNIFORM RANDOM NUMBERS, BOOTSTRAP INDEX or JACKNIFE INDEX
    commands).  This index variable contains integer entries into the
    original variable.  For example, an index variable containing the
    values 3, 5, 1, and 8 refers to Y(3), Y(5), Y(1), and Y(8) where Y
    is the original data variable.
 
    The distinction between SUBSAMPLE and BOOTSTRAP SAMPLE is that
    BOOTSTRAP SAMPLE expects the original variable and the index
    variable to be the same length while SUBSAMPLE allows the index
    variable to be smaller than the original variable.  With SUBSAMPLE,
    the returned variable is the same length as the index variable.
 
    Both commands allow repeated values (i.e., sampling with
    replacement).  This is determined by repeat values in the index
    variable.
 
Syntax:
    LET <resp> = SUBSAMPLE <var> <ind> <SUBSET/EXCEPT/FOR qualification>
    where <var> is the variable being sampled;
          <ind> is the index variable (size less than or equal to
                <var>);
          <resp> is a variable (with the same length as <ind>) where the
                sampled values are returned;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET RES3 = SUBSAMPLE RES2 IND
 
Note:
    Index values less than 1 or greater than the size of the variable
    being sampled are ignored.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    BOOTSTRAP SAMPLE    = Generate a bootstrap sample.
    BOOTSTRAP INDEX     = Generate a bootstrap index.
    LOOP                = Initiate a loop.
    BOOTSTRAP PLOT      = Generate a bootstrap plot.
    JACKNIFE PLOT       = Generate a jacknife plot.
    JACKNIFE INDEX      = Generate a jacknife index.
 
Applications:
    XX
 
Implementation Date:
    89/2
 
Program:
    . PERFORM A JACKNIFE ANALYSIS
    LET Y = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LOOP FOR K = 1 1 100
        LET IND = SEQUENCE 1 1 100
        LET IND(K) = 0
        LET JUNK = SUBSAMPLE Y IND
        LET YMEAN = MEAN JUNK
        LET Y0(K) = YMEAN
    END OF LOOP
    HISTOGRAM Y0
 
-----SUBSET-------------------------------------------------------
 
SUBSET
 
Name:
    SUBSET
 
Type:
    Keyword
 
Purpose:
    Specifies a subset to be included for any plot, analysis, and
    certain support commands.
 
Syntax 1:
    <command> SUBSET <var> <qual> <list of values>
    where <command> is a DATAPLOT command that allows subsets;
          <var> is a variable for which the subset is defined;
          <qual> is an optional qualifier (=, <, >, <>, <=, >=);
    and   <list of values> are the values of <var> to be excluded.
 
    If <qual> is omitted, equality (i.e, =) is assumed.
 
Syntax 2:
    <command> SUBSET <var> <min> TO <max>
    <command> SUBSET <var> = <min> TO <max>
    where <command> is a DATAPLOT command that allows subsets;
          <var> is a variable for which the subset is defined;
          <min> is the minimum value of <var> to exclude;
    and   <max> is the maximum value of <var> to exclude.
 
    The "=" qualifier is optional in this syntax.  This syntax excludes
    all values between (inclusive) <min> and <max>.
 
Examples:
    FIT Y=A*EXP(B*X) SUBSET X 101 TO 1000
    PLOT Y PRED VERSUS X SUBSET LAB 4
    PLOT Y X SUBSET LAB 2 TO 8 SUBSET LAB 4
    LET Y1 = Y2 SUBSET TAG = 4
 
Note:
    Expressions are not supported.  That is,

        PLOT Y X  SUBSET Y > 2*A

    is not valid.  You need to do something like

        LET B = 2*A
        PLOT Y X  SUBSET Y > B

Note:
    The SUBSET variable does not have to be one of the variables used
    in the command (e.g., PLOT X SUBSET TAG > 0).
 
Note:
    Using SUBSET TAG 101 1000 means to subset on the specific values
    101 and 1000 (you can list more than two values) while using
    SUBSET 101 TO 1000 means to subset on the values between 101 and
    1000 (inclusive).
 
Note:
    Although DATAPLOT does not explicitly support missing values, the
    SUBSET command can be used to exclude missing data (pick a value
    to mean missing and SUBSET on that value).
 
Note:
    More than one SUBSET clause can be used on a single command.
 
Note:
    Previously for SUBSET clauses the value to the right of the
    operator was restricted to being a number or a parameter.  That
    is, for

         PLOT Y X  SUBSET X > A

    the name A was restricted to a parameter name (i.e., a single
    value).

    The 2021/07 version of Dataplot extended this to support variables
    on he right hand side.  So you can now do something like

         LET N = 10
         LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 N
         LET Y1 = SORT Y1
         LET Y2 = LOGISTIC RANDOM NUMBERS FOR I = 1 1 N
         LET Y2 = SORT Y2
         LET TAG = 0 FOR I = 1 1 N
         LET TAG = 1 SUBSET Y1 < Y2

    This is only supported for Syntax 1.

Default:
    None
 
Synonyms:
    None
 
Related Commands:
    EXCEPT = Allows exclusion-specification of a subset.
    FOR    = Allows row-specification of a subset.
    <      = Allows "less than" subset.
    <=     = Allows "less than or equal to" subset.
    =      = Allows "equal to" subset.
    >=     = Allows "greater than or equal to" subset.
    >      = Allows "greater than" subset.
    <>     = Allows "not equal" subset.
 
Applications:
    Data Subsetting
 
Implementation Date:
    Pre-1987
 
Program:
    LET X = SEQUENCE 1 1 10
    LET Y = X**2
    PRINT X Y
    PRINT X Y SUBSET Y > 60
    RETAIN X Y SUBSET Y > 60
    PRINT X Y
 
-----SUBSTITUTE CHARACTER--------------------------------------------
 
SUBSTITUTE CHARACTER
 
Name:
    SUBSTITUTE CHARACTER
 
Type:
    Support Command
 
Purpose:
    Specify the character to use as the substitution character.
 
Description:
    The substitute character signifies that the parameter name
    following it should be replaced with the value of that parameter.

    The following name types can be substituted.

        1. If the name is a parameter, the value of the parameter
           will be substituted.

        2. If the name is a string, the value of the string will
           be substituted.

        3. If the name is a variable, Dataplot will check to see
           if an alias for the variable name has been defined
           (via the VARIABLE LABEL command).  If so, that alias
           will be substituted.  If an alias has not been defined,
           the substitution may be unpredictable.

           If Y is a variable, the following is not currently
           supported

               LET STRING S = ^Y(2)

           For this case, you need to do something like

               LET A = Y(2)
               LET STRING S = ^A

        4. If you have defined row labels (via READ ROW LABEL or
           LET ... = ROW LABEL ...), you can do something like

              ^ROWLABEL^K

           where K in an index to the desired row of the row
           labels.

        5. Any other name type will result in an error message
           with no substitution being performed.
 
Syntax:
    SUBSTITUTE CHARACTER  <char>
    where <char> is the character to use as the substitute character.
 
Examples:
    SUBSTITUTE CHARACTER @
    SUBSTITUTE CHARACTER ^
 
Note:
    Generally it is not necessary to change the substitute character.
    The one exception is if you want to define strings that contain
    the default substitute character.
 
Note:
    The substitute character can be used effectively with the LOOP
    command.  For example, assume that variables Y1 thru YN and
    strings S1 and SN have been previously defined:

        LOOP FOR K = 1 1 N
            TITLE Y^K VS X
            LEGEND 1 ^S^K
            PLOT Y^K VS X
        END OF LOOP

    Note the distinction between Y^K in the PLOT command and ^S^K in
    the LEGEND command.  For the plot command, we want PLOT Y1 VS X
    while for the LEGEND command we want to insert the value of the
    string S1.  This is the reason that the Y^K has no preceding ^
    while the ^S^K does.
 
Note:
    The following characters are used to determine the end of the
    parameter name:
               - a space
       (       - a left parenthesis
       )       - a right parenthesis
       "       - a quote character
       &       - an ampersand character
       .       - a period
       ^       - another substitute character
       ,       - a comma
       :       - a colon
       ;       - a semi-colon
       ]       - a right bracket
       +       - a plus
       -       - a minus
       *       - an asterisk
       /       - a forward slash
 
Note:
    The substitution is performed before the command is interpreted.
 
Note:
    If the parameter is undefined, it is replaced with a space
    character in the command line.
 
Note:
    The VALU() command also performs parameter substitution.  However,
    it only works for a few commands (specifically LEGEND, TITLE,
    LABEL, and TEXT) while the substitute character works on any
    command.
 
Note:
    The substitute character can also be changed with the command

        SET REPLACE <char>

Note:
    There may be occassions where you want to suppress the
    character substitution.  For examle, you may want to use
    the "^" character in a string.  You can suspend character
    substitution with the command

        SET COMMAND SUBSTITUTION OFF

    To resume character substitution, enter
 
        SET COMMAND SUBSTITUTION ON

Note:
    If you are substituting for a parameter, there are several
    ways you can control the appearance.

       1. You can use the ROUND command.  For example,

             LET CC = ROUND(CC,2)
             LET STRING S = CORR: ^CC

       2. By default, parameters are expanded into numeric
          format (e.g., 0.0017).  If you would like the parameter
          expanded in exponential format, enter the command

              SET PARAMETER EXPANSION EXPONENTIAL

          To restore the default, enter

              SET PARAMETER EXPANSION NUMERIC

       3. For the most control, you can specify a Fortran
          format by entering the command

              SET SUBSTITUTION FORMAT <string>

          For example,

              SET SUBSTITUTION FORMAT F4.2
              SET SUBSTITUTION FORMAT E15.7

          To turn this off, enter

              SET SUBSTITUTION FORMAT OFF

           Dataplot uses the specified format with an internal Fortran
           WRITE statement.  That is

              WRITE(ISTR,IFORMT,ERR=statement)VAL

           where IFORMT is the specified format and VAL is the
           value of the parameter.  Dataplot does no parsing or
           error checking on the specified format.  Typically, only
           F, E, or G formats should be used.  If there is an error
           using the Fortran format specification, Dataplot will
           revert to its default parameter expansion (no error
           message will be generated).  The format string is limited
           to a maximum of 8 characters and the maximum number of
           characters for the expanded parameter is 20.

Synonyms:
    REPLACEMENT CHARACTER
 
Related Commands:
    LOOP                  = Perform a loop.
    VALU()                = Perform parameter substitution within
                            certain
                            commands.
    TERMINATOR CHARACTER  = Define the character that terminates a
                            command.
    CONTINUE CHARACTER    = Define the character that specifies that
                            a command is continued onto the next line.
 
Applications:
    XX
 
Implementation Date:
    Pre-1987
    2000/01: Support for VARIABLE LABEL substitution
    2007/09: Support for ^ROWLABEL^K
    2019/01: Support for SET SUBSTITUTION FORMAT
    2019/01: Support for SET COMMAND SUBSTITUTION
 
Program:
    . Step 1:   Read the data
    .
    skip 25
    read weibbury.dat y
    skip 0
    .
    . Step 2:   Maximum likelihood estimates
    .
    set write decimals 5
    weibull mle y
    let gamma = gammaml
    let pploc   = 0
    let ppscale = alphaml
    .
    title case asis
    label case asis
    title Weibull Probability Plot
    y1label Sorted Data
    x1label Percentiles for Fitted Weibull Distribution
    character circle
    character hw 1 0.75
    character fill on
    line blank
    .
    . Step 3:   Generate probability plot
    .
    weibull probability plot y
    .
    let gamma = round(gamma,2)
    move 20 85
    text Gamma = ^gamma
    let ppscale = round(ppscale,2)
    move 20 82
    text Scale = ^ppscale
    let ppcc = round(ppcc,3)
    move 20 79
    text PPCC = ^ppcc

-----SUBSTRING-----------------------------------------------------
 
SUBSTRING
 
Name:
    SUBSTRING
 
Type:
    Let Subcommand
 
Purpose:
    Extract a substring of a previously defined string.
    specified position.

Syntax:
    LET <sout> = SUBSTRING  <sorg>  <nstart>  <nstop>
    where <sout> is the name of the resulting string;
          <sorg> is the name of the original string;
          <nstart> is the start position in <sorg>;
    and   <nstop> is the stop position in <sorg>.
 
Examples:
    LET SOUT = SUBSTRING S1 NSTART  NSTOP
    LET SOUT = SUBSTRING S1 3  8
 
Note:
    The name of the new string can be the same as the original
    string.  For example,

        LET FNAME = SUBSTRING FNAME NSTART NSTOP

    In this case, FNAME will now contain the substring rather than
    the original string.

Note:
    The string on the right hand side of the equal sign must be a
    previously existing string.  That is, expressions are not allowed.
    For example, instead of

        LET FNAME = SUBSTRING "file99.dat"  5  6

    you need to do

        LET STRING SORG = file99.dat
        LET FNAME = SUBSTRING SORG  5  6

    The start and stop position can be either a parameter or a numeric
    value.  However, it cannot be a numeric expression.  So

        LET FNAME = SUBSTRING SORG  5  6
        LET FNAME = SUBSTRING SORG  NSTART  NSTOP

    are both allowed but

        LET FNAME = SUBSTRING SORG  NSTART  NLEN/2

    is not allowed.  You would need to enter this as

        LET NSTOP = NLEN/2
        LET FNAME = SUBSTRING FNAME  NSTART  NSTOP

Note:
    The total number of characters that DATAPLOT can use for storing
    functions and strings is set when DATAPLOT is built.  The current
    default (11/2008) is 50,000 characters.  Previous versions may set
    this limit at 1,000 or 10,000 characters.  This limit applies to the
    combined number of characters for all functions and strings.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING LENGTH       = Return the length of a string.
    STRING EDIT         = Edit a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    11/2008
 
Program:
    LET STRING S1 = file23.dat
    LET NSTOP = STRING LENGTH S1
    LET NSTART = STRING INDEX S1 SPERIOD
    LET SEXT = SUBSTRING S1 NSTART NSTOP
    LET NSTOP = NSTART - 1
    LET NSTART = 1
    LET SBASE = SUBSTRING S1 NSTART NSTOP

    The resulting strings SEXT and SBASE will contain

       .dat
       file23

-----SUM (LET)---------------------------------------------------
 
SUM
 
Name:
    SUM (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Sum the elements of a variable.
 
Syntax:
    LET <par> = SUM <x1>  <SUBSET/EXCEPT/FOR qualification>
    where <x1> is the variable for which the sum is to be computed;
          <par> is a parameter where the computed sum is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    LET A = SUM Y
    LET A = SUM Y SUBSET TAG > 2
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    PRODUCT        = Compute the product of the elements of a variable.
    INTEGRAL       = Compute the integral of elements in a variable.
    SUM PLOT       = Generate a sums (vs subsets) plot.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET A = SUM Y1
 
-----SUM OF SQUARES (LET)-----------------------------------------
 
SUM OF SQUARES
 
Name:
    SUM OF SQUARES (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the sum of squares of a variable.
 
Description:
    The sum of squares has the formula:

         SSQ = SUM[i=1 to N][X(i)**2]
 
Syntax 1:
    LET <par> = SUM OF SQUARES <y>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed sum of squares is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <par> = DIFFERENCE OF SUM OF SQUARES <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed difference of
              the sum of squares is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax computes the sum of squares of <y1> and <y2> and then
    computes the difference of the two sum of squares values.
 
Examples:
    LET A = SUM OF SQUARES Y1
    LET A = SUM OF SQUARES Y1  SUBSET TAG > 2
    LET A = DIFFERENCE OF SUM OF SQUARES Y1 Y2
 
Note:
    In some applications it may be desired to cap the value
    of outliers.  This is most common when the response variable
    is a z-score or some other standardized score.

    To specify this value, enter the command

        LET CAPVALUE = <value>

    where <value> is typically 3 or 4 (if the reponse data are
    z-scores or z-score type data).  Note that the value represents
    an absolute value.  For example, if CAPVALUE is 4, values greater
    than 4 will be set to 4 and values less than -4 will be set to -4.

Note:
    Dataplot statistics can be used in a number of commands.  For
    details, enter

         HELP STATISTICS

Default:
    None
 
Synonyms:
    SSQ is a synonym for SUM OF SQUARES
 
Related Commands:
    MEAN                 = Compute the mean of a variable.
    STANDARD DEVIATION   = Compute the standard deviation of a variable.
    ROOT MEAN SQUARE     = Compute the root mean square error of a
                           variable.
 
Applications:
    Statistics
 
Implementation Date:
    2012/2
    2012/6: Added DIFFERENCE OF SUM OF SQUARES
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET SSQ = SUM OF SQUARES Y1
 
-----SUM OF SQUARES FROM MEAN (LET)----------------------------------
 
SUM OF SQUARES FROM MEAN
 
Name:
    SUM OF SQUARES FROM MEAN (LET)
 
Type:
    Let Subcommand
 
Purpose:
    Compute the sum of squares from the mean of a variable.
 
Description:
    The sum of squares from the mean has the formula:

         SSQ = SUM[i=1 to N][(X(i) - Xbar)**2]
 
    with Xbar denoting the mean of the X(i).

Syntax 1:
    LET <par> = SUM OF SQUARES FROM MEAN <y>
                <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response variable;
          <par> is a parameter where the computed sum of squares from the
               mean is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    LET <par> = DIFFERENCE OF SUM OF SQUARES FROM MEAN <y1> <y2>
                <SUBSET/EXCEPT/FOR qualification>
    where <y1> is the first response variable;
          <y2> is the second response variable;
          <par> is a parameter where the computed difference of
              the sum of squares from the mean is saved;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.

    This syntax computes the sum of squares from the mean of <y1> and
    <y2> and then computes the difference of the two sum of squares
    values.
 
Examples:
    LET A = SUM OF SQUARES FROM MEAN Y1
    LET A = SUM OF SQUARES FROM MEAN Y1  SUBSET TAG > 2
    LET A = DIFFERENCE OF SUM OF SQUARES FROM MEAN Y1 Y2

Default:
    None
 
Synonyms:
    SUMS OF SQUARES FROM MEAN is a synonym for SUM OF SQUARES FROM MEAN
 
Related Commands:
    SUM OF SQUARES       = Compute the sum of squares for a variable.
    MEAN                 = Compute the mean of a variable.
    STANDARD DEVIATION   = Compute the standard deviation of a variable.
    ROOT MEAN SQUARE     = Compute the root mean square error of a
                           variable.
 
Applications:
    Statistics
 
Implementation Date:
    2013/2
 
Program:
    LET Y1 = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    LET Y1 = 10 + 5*Y1
    LET SSQM = SUM OF SQUARES FROM MEAN Y1
    SET WRITE DECIMALS 4
    PRINT "Sum of Squares from Mean = ^SSQM"
 
-----SUM PLOT---------------------------------------------------
 
SUM PLOT
 
Name:
    SUM PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a sum plot.
 
Description:
    A sum plot is a plot consisting of subsample sums versus
    subsample index.  The subsample sum is the sum of the data in the
    subsample.  The sum plot is used to answer the question-- "Does
    the subsample sum-of-counts change over different subsamples?".
    It consists of:
       Vertical   axis = subsample sum;
       Horizontal axis = subsample index.
    The sum plot yields 2 traces:
       1. a subsample sum trace; and
       2. a full-sample sum reference line.
    Like usual, the appearance of these 2 traces is
    controlled by the first 2 settings of the LINES,
    CHARACTERS, SPIKES, BARS, and similar attributes.
 
Syntax:
    SUM PLOT   <y>   <x>     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the response (= dependent) variable;
          <x> is the subsample identifier variable (this variable
              will appear on the horizontal axis);
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    SUM PLOT Y X
    SUM PLOT Y X1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTERS         = Sets the type for plot characters.
    LINES              = Sets the type for plot lines.
    FREQUENCY (LET)    = Compute subsample frequencies.
    HISTOGRAM          = Generates a histogram.
    PRODUCT  PLOT      = Generates a product plot.
    MEAN  PLOT         = Generates a mean plot.
    BOX PLOT           = Generates a box plot.
    PLOT               = Generates a data or function plot.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    88/9
 
Program:
    LET Y = DATA 2 4 5 10 10 20 25 30 35
    LET X = DATA 1 1 1 2 2 3 3 3 3
    LINE BLANK DASH
    CHARACTER X BLANK
    XLIMITS 0.5 3.5
    Y1LABEL SUM
    X1LABEL GROUP ID
    SUM PLOT Y X
 
-----SUMMARY-------------------------------------------------------
 
SUMMARY
 
Name:
    SUMMARY
 
Type:
    Analysis Command
 
Purpose:
    Carries out a summary analysis.
 
Description:
    A summary analysis is a data analysis technique for computing and
    tabulating a variety of summary statistics for a data set.  This
    includes measures of location (e.g., the mean), of dispersion
    (e.g., the standard deviation), of randomness (the
    autocorrelation), and of the distribution (e.g., the skewness).
 
Syntax:
    SUMMARY  <y1>   <SUBSET/EXCEPT/FOR qualification>
    where <y1> is a response variable;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    SUMMARY Y
    SUMMARY Y2
 
Note:
    Most of the statistics computed by SUMMARY can also be computed
    individually as LET subcommands.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LET     = Compute various statistics and transformations.
 
Applications:
    XX
 
Implementation Date:
    XX
 
Program:
    LET Y = NORMAL RANDOM NUMBERS FOR I = 1 1 100
    SUMMARY Y
 
-----SUPERSCRIPT SCALE (SET)---------------------------------------
 
SUPERSCRIPT SCALE
 
Name:
    SUPERSCRIPT SCALE (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Specify the horizontal and vertical scale factors for the size
    of superscript and subscript characters.
 
Description:
    By default, Dataplot sets the height and width of characters
    drawn in superscripts and subscripts to 0.5 of the current
    character height and width.

    This command allows you to specify a different size factor.
    Note that the value is entered as a fraction of the current
    character size.  For example, a size of 1.0 leaves the
    character size unchanged and the default size is 0.5.

Syntax 1:
    SET SUPERSCRIPT HORIZONTAL SCALE <value>
    where <value> is positive number between 0 and 20.
 
    This syntax sets the width of the superscript/subscript
    characters relative to the current character width.

Syntax 2:
    SET SUPERSCRIPT VERTICAL SCALE <value>
    where <value> is positive number between 0 and 20.
 
    This syntax sets the height of the superscript/subscript
    characters relative to the current character height.

Examples:
    SET SUPERSCRIPT VERTICAL SCALE  1.0
    SET SUPERSCRIPT HORIZONTAL SCALE  1.0

    SET SUPERSCRIPT VERTICAL SCALE  0.75
    SET SUPERSCRIPT HORIZONTAL SCALE  0.5

    SET SUPERSCRIPT VERTICAL SCALE  0.25
    SET SUPERSCRIPT HORIZONTAL SCALE  0.5
 
Default:
    The default is to set both the character height and width to
    0.5 of their current value.
 
Synonyms:
    SET SUBSCRIPT VERTICAL SCALE is a synonym for SET SUPERSCRIPT
    VERTICAL SCALE and SET SUBSCRIPT HORIZONTAL SCALE is a synonym for
    SET SUPERSCRIPT HORIZONTAL SCALE.
 
Related Commands:
    SUP()    = Initiate a superscript in a text string.
    UNSP()   = Terminate a superscript in a text string.
    SUB()    = Initiate a subscript in a text string.
    UNSB()   = Terminate a subscript in a text string.
    TEXT     = Generate a text string on a graph.
 
Applications:
    Presentation Graphics
 
Implementation Date:
    2001/3
 
Program:
    erase
    font triplex italic
    crlf off
    hw 4 3
    .
    move 20 95
    text default size:
    move 20 90
    text sub()tunsb()nsup()()13unsp()
    hw .5 1
    arrow 36 91 44 91
    hw 4 3
    text sub()6unsb()csup()13unsp() + lc()beta()sup()+unsp() + nu()
    .
    move 20 75
    text size 1:
    move 20 70
    set superscript horizontal scale 1
    set superscript vertical scale 1
    text sub()tunsb()nsup()()13unsp()
    hw .5 1
    arrow 36 71 44 71
    hw 4 3
    text sub()6unsb()csup()13unsp() + lc()beta()sup()+unsp() + nu()
    .
    move 20 55
    text size 0.5, 0.75:
    move 20 50
    set superscript horizontal scale 0.5
    set superscript vertical scale 0.75
    text sub()tunsb()nsup()()13unsp()
    hw .5 1
    arrow 36 51 44 51
    hw 4 3
    text sub()6unsb()csup()13unsp() + lc()beta()sup()+unsp() + nu()
 
-----SYMBOL PLOT--------------------------------------
 
SYMBOL PLOT
 
Name:
    SYMBOL PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a symbol plot.
 
Description:
    A symbol plot is a scatter plot for which the attributes of the
    plot symbols are controlled by the values of other variables.
    This plot allows the size, type, color, and fill attribute to be
    controlled.
 
Syntax 1:
    SYMBOL PLOT <y> <x> <size>  <SUBSET/EXCEPT/FOR qualification>
    where <y> is the vertical axis variable;
          <x> is the horizontal axis variable;
          <size> is a variable that controls the size of the plot
              symbol;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 2:
    SYMBOL PLOT <y> <x> <size> <symbol>
              <SUBSET/EXCEPT/FOR qualification>
    where <y> is the vertical axis variable;
          <x> is the horizontal axis variable;
          <size> is a variable that controls the size of the plot
              symbol;
          <symbol> is a variable that controls the type of symbol
              plotted;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 3:
    SYMBOL PLOT <y> <x> <size> <symbol> <color>
              <SUBSET/EXCEPT/FOR qualification>
    where <y> is the vertical axis variable;
          <x> is the horizontal axis variable;
          <size> is a variable that controls the size of the plot
              symbol;
          <symbol> is a variable that controls the type of symbol
              plotted;
          <color> is a variable that controls the color of the symbol;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Syntax 4:
    SYMBOL PLOT <y> <x> <size> <symbol> <color> <fill>
              <SUBSET/EXCEPT/FOR qualification>
    where <y> is the vertical axis variable;
          <x> is the horizontal axis variable;
          <size> is a variable that controls the size of the plot
              symbol;
          <symbol> is a variable that controls the type of symbol
              plotted;
          <color> is a variable that controls the color of the symbol;
          <fill> is an optional variable that controls whether the
              symbol is filled or not;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
Examples:
    SYMBOL PLOT Y X PRESSURE
    SYMBOL PLOT Y X PRESSURE TYPE
    SYMBOL PLOT Y X PRESSURE TYPE ICOL
    SYMBOL PLOT Y X PRESSURE TYPE ICOL IFILL
 
Note:
    SYMBOL PLOT Y and SYMBOL PLOT Y X are equivalent to PLOT Y and
    PLOT Y X respectively.  The only difference is that the line
    pattern is automatically set to blank.
 
Note:
    The <size>, <symbol>, <color>, and <fill> variables are optional,
    but must be entered in that order.  To skip one, set all the
    elements of the skipped variable to 1.  For example,
       LET N = SIZE Y
       LET SYMBOL = 1 FOR I = 1 1 N
       SYMBOL PLOT Y X SIZE SYMBOL COLOR
 
Note:
    The size for Y(i) is scaled to: Y(i)/MAXIMUM(ABS(Y)).  The maximum
    value of Y is set to the size given in the CHARACTER SIZE (or
    CHARACTER HW) command while the others multiply this size by the
    scale factor.  The minimum scale factor is truncated at 5%.
 
Note:
    The <symbol> and <color> variables define indices to the CHARACTER
    and CHARACTER COLOR commands respectively.  That is, they contain
    values between 1 and 100 (e.g., a value of 3 would go to the third
    setting of these commands).
 
Note:
    Zero values for the <fill> variable indicate non-filled characters
    while non-zero values indicate filled characters.  In addition, to
    generate filled characters a fillable symbol must be used (e.g.,
    CIRCLE or SQUARE).
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    CHARACTER        = Sets the type for plot characters.
    CHARACTER COLOR  = Sets the color for plot characters.
    CHARACTER FILL   = Sets the fill for plot characters.
    ANDREWS PLOT     = Generates an Andrews plot.
    PROFILE PLOT     = Generates a profile plot.
    STAR PLOT        = Generates a star plot.
    PLOT             = Generates a data or function plot.
 
Reference:
    "Graphical Methods of Data Analysis", Chambers, Cleveland, Kleiner,
    and Tukey.  Wadsworth, 1983.
 
Applications:
    Multivariate Analysis
 
Implementation Date:
    92/12
 
Program:
    DIMENSION 20 COLUMNS
    MULTIPLOT 2 2; MULTIPLOT CORNER COORDINATES 0 0 100 100
    SKIP 25
    READ CURRIE.DAT ID1 ID2 FRWC CTOTAL POT LEAD IRON
    LET TYPE = ID1
    LET TYPE = 1 SUBSET ID1 < 10
    LET TYPE = 2 SUBSET ID1 = 11 TO 19
    LET TYPE = 3 SUBSET ID1 > 19
    LET N = SIZE ID1
    LET DUMMY = 1 FOR I = 1 1 N
    TITLE AUTOMATIC
    Y1LABEL POTASSIUM
    X1LABEL LEAD
    LEGEND SIZE 1.2
    CHARACTER SIZE 6.0 ALL
    .
    CHARACTER CIRCLE SQUARE DIAMOND TRIANGLE
    LEGEND 1 IRON DETERMINES SYMBOL SIZE
    SYMBOL PLOT POT LEAD IRON
    .
    CHARACTER SIZE 2.0 ALL
    LEGEND 1 ID1 DETERMINES SYMBOL TYPE
    SYMBOL PLOT POT LEAD DUMMY TYPE
    .
    CHARACTER SIZE 6.0 ALL
    LEGEND 1 IRON DETERMINES SYMBOL SIZE
    LEGEND 2 ID1 DETERMINES SYMBOL TYPE
    SYMBOL PLOT POT LEAD IRON TYPE
    .
    LET AFILL = 0 FOR I = 1 1 N
    LET AFILL = 1 SUBSET ID2 = 1
    LEGEND 3 ID2 DETERMINES FILL
    SYMBOL PLOT POT LEAD IRON TYPE DUMMY AFILL
    END OF MULTIPLOT
 
-----SYMMETRY PLOT--------------------------------------
 
SYMMETRY PLOT
 
Name:
    SYMMETRY PLOT
 
Type:
    Graphics Command
 
Purpose:
    Generates a symmetry plot.
 
Description:
    A symmetry plot is a graphical data analysis technique for
    assessing if a data set is symmetric about the mean.  It consists
    of:
       Vertical   axis = Y(n-i+1) - median;
       Horizontal axis = median - Y(i);
    where median is the sample median, Y is sample variable, and i goes
    from 1 to the index of the median point.  This plot graphs the
    distance from the median of points above the median against the
    corresponding points below the median.  The interpretation of this
    plot is that the closer these points lie to the 45% line, the
    more symmetric the data is.  The symmetry plot can be generated
    for either raw data of for pre-computed frequencies (i.e., grouped
    data).
 
Syntax 1:
    SYMMETRY PLOT   <y>     <SUBSET/EXCEPT/FOR qualification>
    where <y> is the variable of raw data values;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used when you have raw data.
 
Syntax 2:
    SYMMETRY PLOT  <y>  <X>   <SUBSET/EXCEPT/FOR qualification>
    where <y> is the variable of pre-computed frequencies;
          <x> is the variable of group identifiers;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax is used when you have raw data.
 
Examples:
    SYMMETRY PLOT Y1
    SYMMETRY PLOT Y1 GROUP
    SYMMETRY PLOT Y1  SUBSET Y1 > -3.0
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LINES              = Sets the type for plot lines.
    CHARACTERS         = Sets the type for plot characters.
    PLOT               = Generates a data or function plot.
    PROBABILITY PLOT   = Generate a probability plot.
    PERCENT POINT PLOT = Generates a percent point plot.
 
Reference:
    "Graphical Methods for Data Analysis", Chambers, Cleveland,
    Kleiner, and Tukey.  Wadsworth, 1983.
 
Applications:
    Exploratory Data Analysis
 
Implementation Date:
    88/9
 
Program:
    SKIP 25
    READ MARSHAK.DAT Y
    CHARACTER CIRCLE
    CHARACTER HW 2.0 1.5
    LINE BLANK
    Y1LABEL POINTS ABOVE MEDIAN
    X1LABEL POINTS BELOW MEDIAN
    TITLE AUTOMATIC
    SYMMETRY PLOT Y
 
-----SYNTAX-------------------------------------------------------
 
 
Syntax:
 
Name:
    SYNTAX
 
Type:
    Keyword
 
Purpose:
    Symbolic name for DATAPLOT's syntax file.  It is used with the
    SEARCH and LIST commands.
 
Description:
    DATAPLOT's syntax file contains an example of the syntax for each
    DATAPLOT command sorted alphabetically.
 
Syntax:
    None
 
Examples:
    SEARCH SYNTAX FIT
    LIST SYNTAX FOR I = 1 1 35
 
Note:
    The SYNTAX file is stored in the DATAPLOT directory.  It has the
    name SYNTAX (or syntax for Unix systems).  The exact file name and
    the directory where it is stored can vary depending on the
    installation (see your local DATAPLOT implementor to find the
    exact name on your system).
 
Note:
    If DATAPLOT is unable to open the syntax file, it is most likely
    because the directory name is not specified correctly in the local
    DATAPLOT code.  See your local DATAPLOT implementor to have this
    corrected.
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    SEARCH        = Search a file for a string.
    LIST          = Lists the contents of a file.
    DIRECTORY     = Symbolic name for DATAPLOT's directory file.
    DICTIONARY    = Symbolic name for DATAPLOT's dictionary file.
    DATASETS      = Symbolic name for DATAPLOT's data sets file.
    DESIGNS       = Symbolic name for DATAPLOT's design of experiments
                    file.
    COMMANDS      = Symbolic name for DATAPLOT's command file.
    MACROS        = Symbolic name for DATAPLOT's macros file.
    PROGRAMS      = Symbolic name for DATAPLOT's programs file.
    DISTRIBU      = Symbolic name for DATAPLOT's distributions file.
    FUNCTION      = Symbolic name for DATAPLOT's function file.
 
Applications:
    XX
 
Implementation Date:
    93/12
 
Program:
    XX
 
-----SYNCH (LET)--------------------------------
 
SYNCH
 
Name:
    SYNCH (LET)
 
Type:
    Library Function
 
Purpose:
    Compute the synchrotron radiation function.
 
Description:
    The synchrotron radiation function of order 1 is
    defined as:

        f(x,1) = x*INTEGRAL[K(5/3)(t)dt],   x >= 0

    where the integral is defined from x to positive
    infinity and K(n) is the modified Bessel function of
    order n.

    The synchrotron radiation function of order 2 is
    defined as:

        f(x,2) = x*K(2/3)(x)       x >= 0

    where K(n) is the modified Bessel function of order n.

    Dataplot computes this function using ACM Algorithm 757 (see
    Reference: below).
 
Syntax 1:
    LET <y> = SYNCH1(<x>)    <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, variable or parameter;
          <y> is a variable or a parameter (depending on what <x> 
              is) where the computed synchrotron radiation
              function values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the order 1 synchrotron radiation 
    function.

Syntax 2:
    LET <y> = SYNCH2(<x>)    <SUBSET/EXCEPT/FOR qualification>
    where <x> is a non-negative number, variable or parameter;
          <y> is a variable or a parameter (depending on what <x> 
              is) where the computed synchrotron radiation
              function values are stored;
    and where the <SUBSET/EXCEPT/FOR qualification> is optional.
 
    This syntax computes the order 2 synchrotron radiation 
    function.

Examples:
    LET A = SYNCH1(2)
    LET A = SYNCH2(X) 
    LET X2 = SYNCH1(X) FOR X1 = 0.1 0.1 3.0
 
Note:
    Library functions are distinguished from let subcommands
    in the following ways.
    1) Functions enclose the input value in parenthesis.  Let
       subcommands use spaces.
    2) Functions can accept (and return) either parameters
       (i.e., single values) or variables (i.e., an array of
       values) while let subcommands are specific in which they
       accept as input and what they return as output.
    3) Functions can accept expressions while let subcommands
       do not.  For example, the following is legal:
           LET Y2 = ABS(Y1-INT(Y1))
       For let subcommands, you typically have to do something
       like the following:
           LET YTEMP = Y**2 + 8
           LET A = SUM YTEMP
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    ABRAM      = Compute the Abramowitz integral.
    CLAUSN     = Compute the Clausen integral.
    DEBYE      = Compute the Debye function.
    EXP3       = Compute the cubic exponential integral.
    GOODST     = Compute the Goodwin and Stanton integral.
    LOBACH     = Compute the Lobachevski integral.
    STROM      = Compute the Stromgren integral.
    TRAN       = Compute the transport integral.
 
Reference:
    "ACM Transactions of Mathematical Software", Allan MacLead,
    Vol. 22, No. 3, September, 1996, pp. 288-301.
 
Applications:
    Special Functions
 
Implementation Date:
    1999/6
 
Program:
    LINE SOLID DOTTED
    PLOT SYNCH1(X) FOR X = 0 0.01 10 AND
    PLOT SYNCH2(X) FOR X = 0 0.01 10
 
-----SYSTEM-------------------------------------------------------
 
SYSTEM
 
Name:
    SYSTEM
 
Type:
    Support Command
 
Purpose:
    This command allows DATAPLOT to issue an operating system command
    on the host computer.
 
Description:
    The Fortran 77/90 standard do not explicitly support a SYSTEM
    library function, so this command is compiler dependent.  However,
    most Fortran compilers do provide a library function that supports
    this capability.

    This command should be available on most currently suppported
    platforms.  However, it is possible that the command is not
    available on your local platform.
 
Syntax:
    SYSTEM <string>
    where <string> contains a command to be executed on the local
              operating system.
 
Examples:
    SYSTEM  DIR       (on an IBM/PC system)
    SYSTEM  ls        (on a Unix system)
 
Note:
    This command is host dependent.  It is operational on the
    following systems:

        UNIX/Linux          (except Cray UNICOS)
        Microsoft Windows   (based on Intel compiler)
        CYBER NOS/VE

    It has been coded, but not tested, on the VAX/VMS system.
 
Note:
    DATAPLOT does no error checking on the requested command.  It is
    the users responsibility to enter the correct operating system
    command.
 
Note:
    Systems may vary somewhat in how sophisticated a command can be
    executed.  Also be aware that on most systems, a separate process
    is spawned and the environment is not passed back to the calling
    system.  Specifically, on a Unix system, the following does not
    work:

         SYSTEM cd ~/datasets

    since the current environment is restored after the command
    completes execution.
 
Note:
    The following updates were made to the SYSTEM command 03/2019.

    For the Windows 7/8/10 platforms, the SYSTEM command works
    as follows:

      1) A new terminal window is opened.
      2) The requested command is executed.
      3) When the requested command is completed, the new window is
         closed and control returns to the Dataplot session.

    Several SET commands have been added to control this behavior.
    Specifically,

      1) In some cases, it is desirable to leave the new Window up.
         For example, you may need to view the results from the
         SYSTEM command.  To specify that the new command window
         should remain, enter the command

              SET SYSTEM PERSIST ON

         To reset the default, enter

              SET SYSTEM PERSIST OFF

         Note that control does not return to the Dataplot session
         until the new terminal window is closed.

         This command has no effect on Unix/Linux and MacOS platforms.

      2) In some cases, you may want the SYSTEM command to operate in
         the background and not open a new terminal window.  To specify
         this, enter the command

              SET SYSTEM HIDDEN ON

         For Windows, Dataplot normally executes the SYSTEM command with
         the SYSTEMQQ system call in the Intel Fortran library.  If
         HIDDEN is set to ON, Dataplot will use the EXECUTE_COMMAND_LINE
         routine that was added in the Fortran 2008 standard.  If you
         compile Dataplot for Windows using an older version of the Intel
         compiler or a non-Intel compiler, the EXECUTE_COMMAND_LINE
         subroutine may or may not be available.  If not, Dataplot will
         revert to using SYSTEMQQ (and HIDDEN ON will have no effect).

         To reset the default, enter

              SET SYSTEM HIDDEN OFF

         This command has no effect on Unix/Linux and MacOS platforms.

      3) By default, Dataplot uses "CALL SYSTEM" for Linux/Unix and
         MacOS platforms and "CALL SYSTEMQQ" for Windows platforms.

         You can request that Dataplot use the EXECUTE_COMMAND_LINE
         subroutine instead by entering the command

              SET QWIN SYSTEM EXECUTE COMMAND LINE

         Be aware that this is relatively new addition to the Fortran
         standard and may not be available in all Fortran compilers (or
         in older versions of compilers).  Specifically, it is not
         supported in gfortran (Linux, MacOS) until version 5.x and
         version 16 of the Intel compiler.  So this option may not be
         available on all platforms.  The Windows executable for 2019/03
         that can be downloaded from the Dataplot web site uses version 17
         of the Intel compiler, so this feature is available.  If you are
         running Dataplot on a platform where EXECUTE_COMMAND_LINE is not
         available, Dataplot will revert to "CALL SYSTEM" or
         "CALL SYSTEMQQ".

         One advantage of using EXECUTE_COMMAND_LINE is that it supports
         either synchronous or asynchronous execution.  By synchronous, we
         mean that control does not return to the Dataplot session until
         the SYSTEM command completes execution.  By asynchronous, we
         mean that control returns to the Dataplot session after the
         SYSTEM command is initated (but not neccessarily completed).

         To specify asynchronous, enter

             SET COMMAND LINE EXECUTE WAIT ON

         To restore the default of synchronous, enter

             SET COMMAND LINE EXECUTE WAIT OFF

         Note that this command only applies if EXECUTE_COMMAND_LINE is
         used to implement the SYSTEM command.

Note:
    This command preserves the case as entered.  This is
    important for the Unix implementation since Unix commands are
    case sensitive.  DATAPLOT does not try to guess what case
    should be passed to the local host.

Default:
    None
 
Synonyms:
    DOS
    UNIX
 
Related Commands:
    SLEEP         = Pause for <n> seconds.
    CD            = Change the current directory
    PWD           = Retrieve the current working directory.
 
Applications:
    Interact with the local operating system
 
Implementation Date:
    1989/02: Original implementation
    2019/03: Support for SET SYSTEM PERSIST
    2019/03: Support for SET SYSTEM HIDDEN
    2019/03: Support for SET QWIN SYSTEM EXECUTE COMMAND LINE
    2019/03: Support for SET COMMAND LINE EXECUTE WAIT
 
Program:
    DEVICE 2 POSTSCRIPT
    PLOT X**2 FOR X = 1 1 9
    DEVICE 2 CLOSE
    SYSTEM lpr dppl1f.dat 
 
-----SYSTEM SWITCHES (SET)--------------------------------------------
 
SYSTEM SWITCHES
 
Name:
    SYSTEM SWITCHES (SET)
 
Type:
    Set Subcommand
 
Purpose:
    Probe for values pertaining to certain operating system values.
 
Description:
    Dataplot extracts the values of several operating system
    environment variables.  These values can be obtained by the user
    using the PROBE command.  Note that these settings cannot be
    modified with the SET command.

    The list of available environment variable switches is

        HOME              - Returns the user's home directory.

                            On Windows platforms, this is the value of
                            the USERPROFILE environment variable.

                            On Linux platforms, this is the value of the
                            HOME environment variable.

        USER              - Returns the user name.

                            On Windows platforms, this is the value of the
                            USERPNAME environment variable.

                            On Linux platforms, this is the value of the
                            USER environment variable.

        HOST              - Returns the computer name.

                            On Windows platforms, this is the value of the
                            COMPUTERNAME environment variable.

                            On Linux platforms, this is the value of the
                            HOST environment variable for the c-shell or
                            t-shell and the HOSTNAME variable for the
                            bash shell.

        DEFAULT PRINTER   - Returns the default printer.

                            On Linux platforms, this is the value of the
                            PRINTER environment variable.

                            This is not supported on Windows platforms.

        SHELL             - Returns the current shell.

                            On Linux platforms, this is the value of the
                            SHELL environment variable.

                            This is not supported on Windows platforms.

        WINDOWS BITS      - Returns "64" if the machine is a 64-bit
                            machine and "32" if the machine is a
                            32-bit machine.

                            On Windows platforms, this is determined
                            from the PROCESSOR_ARCHITECTURE environment
                            variable.

                            This is not supported on Linux platforms.

        PROGRAM FILES     - On Windows platforms, this is the value of
                            the PROGRAMFILES environment variable.

                            This is not supported on Linux platforms.

        PROGRAM FILES X86 - On Windows platforms, this is the value
                            of the PROGRAMFILES(X86) environment
                            variable.

                            This is not supported on Linux platforms.

Syntax:
    PROBE <SYSTEM SWITCH>
    where <SYSTEM SWITCH> is one of the names listed above.
 
Examples:
    PROBE HOME
    PROBE USER
    PROBE HOST
    PROBE DEFAULT PRINTER
    PROBE SHELL
    PROBE PROGRAM FILES X86
    PROBE PROGRAM FILES
    PROBE WINDOW BITS

Note:
    The value is saved in the string PROBESTR.  You can save the
    value to your own string as follows

        PROBE USER
        LET STRING USERNAME = ^PROBESTR

Default:
    Dataplot queries the values of these settings when Dataplot
    is first initialized.
 
Synonyms:
    USER PROFILE is a synonym for HOME
    USER NAME is a synonym for USER
    HOST NAME is a synonym for HOST
    COMPUTER NAME is a synonym for HOST
 
Related Commands:
    WORKSPACE SWITCHES     = Probe for values pertaining to the Dataplot
                             workspace.
    HOUSEKEEPING SWITCHES  = Probe for values pertaining to certain
                             Dataplot housekeeping settings.
    SYSTEM LIMITS          = Parameters defining certain Dataplot limits.
    MACHINE CONSTANTS      = Return the values for certain machine
                             constants.

Applications:
    Debugging
 
Implementation Date:
    2020/01
 
Program:
    PROBE USER
    LET STRING USERNAME = ^PROBESTR
    PROBE HOST
    LET STRING COMPNAME = ^PROBESTR
    PROBE HOME
    LET STRING USERHOME = ^PROBESTR
    .
    PRINT "Computer Name:   ^COMPNAME"
    PRINT "User Name:       ^USERNAME"
    PRINT "Home Directory:  ^USERHOME"
 
-----SUN-------------------------------------------------------
 
SUN
 
Name:
    SUN
 
Type:
    Output Device Command
 
Purpose:
    The SUN command is used to direct graphical output to a SUN
    workstation running in SunWindows (either in a gfxtool or a Sun
    View window).
 
Description:
    As gfxtool and Sun View are no longer supported, this is an obsolete
    device.

Syntax 1:
    SUN
 
    This form designates device 1 as a Sun device.
 
Syntax 2:
    DEVICE <1/2/3> SUN
 
    This form designates one of DATAPLOT's 3 devices (typically device
    1) as a Sun device.
 
Examples:
    SUN
    DEVICE 1 SUN
 
Note:
    The SUN driver only works if DATAPLOT is running on the SUN using
    the Sun View window system.  The SUN driver uses SUN specific
    libraries.  This means the local DATAPLOT installers must uncomment
    some source code before this driver is operational.  If the SUN is
    running DATAPLOT from another host machine, or if the SUN driver
    has not been activated at your site, then run DATAPLOT in a
    TEKTOOLS window (and specify a Tektronix 4014 device).
 
Note:
    The SUN driver can automatically determine whether you are running
    on a color or a black and white device.
 
Note:
    This driver is becoming obsolete since Sun is switching to OpenLook
    and Motif based window systems.  Use the X11 driver (HELP X11 for
    details) with OpenLook, Motif, or a plain vanilla X11 window
    system.
 
Default:
    Off
 
Synonyms:
    None
DEVICE NOTES
    1) HARDWARE TEXT - Hardware characters are scalable.  No special
       fonts are supported.  Vertical strings are not rotated.
    2) COLOR - The colors WHITE, BLACK, RED, GREEN, BLUE, MAGENTA, and
       YELLOW are supported.  All other colors are mapped to one of
       these colors (enter SHOW COLORS SUN for the list).
    3) HARDWARE FILL - Solid area fills are generated in hardware.
    4) DASH PATTERNS - Unique dash patterns are generated for DASH,
       DOT, DASH2, and DASH3.  DASH4 and DASH5 generate whatever the
       most recently set pattern was.
    5) LINE WIDTH - Thick lines are generated in hardware.
    6) GRAPHICS INPUT - The CROSS-HAIR command is supported for this
       device.
 
Related Commands:
    TEKTRONIX       = Direct graphical output to a Tektronix device.
    X11             = Direct graphical output to an X11 device.
    HP              = Direct graphical output to an HP device.
    POSTSCRIPT      = Direct graphical output to a Postscript device.
    DEVICE          = Specify certain actions for the graphics output.
 
Applications:
    Device Specification
 
Implementation Date:
    1989/02
 
Program:
    XX
 
-----SWAP CASE-----------------------------------------------------
 
SWAP CASE
 
Name:
    SWAP CASE
 
Type:
    Let Subcommand
 
Purpose:
    Given a string, convert all upper case characters to lower case and
    convert all lower case characters to upper case.
 
Syntax:
    LET <sout> = SWAP CASE  <sorg>
    where <sout> is the resulting string;
    and   <sorg> is the name of the original string.
 
Examples:
    LET SOUT = SWAP CASE S1
 
Default:
    None
 
Synonyms:
    None
 
Related Commands:
    LOWER CASE          = Convert a string to lower case.
    UPPER CASE          = Convert a string to upper case.
    LET FUNCTION        = Defines a function.
    LET STRING          = Defines a string.
    READ STRING         = Reads a string from a file.
    SUBSTITUTE CHARACTE = Substitute the value of a string or parameter.
    &                   = Concatenate two strings.
    SUBTRING            = Extract a substring from an existing string.
    STRING INDEX        = Extract the start/stop positions of a substring
                          within a string.
    STRING CONCATENATE  = Concatenate one or more previously defined
                          strings.
    STRING EDIT         = Edit a string.
    STRING MERGE        = Insert a string into another string without
                          overwrite.
    STRING REPLACE      = Insert a string into another string with
                          overwrite.
    STRING LENGTH       = Return the length of a string.
    CHARACTER           = Convert numeric values to strings based on
                          the ASCII collating sequence.
    ICHAR               = Convert a string to numeric values based on
                          the ASCII collating sequence.
    GROUP LABEL         = Define the text for group labels.
 
Applications:
    Data Management
 
Implementation Date:
    2019/02
 
Program:
    LET STRING S1 = XXXXyyyyZZZZwwww
    LET SOUT = UPPER CASE S1

    The resulting string is xxxxYYYYzzzzWWWW.

-----SVG---------------------------------------------------------
 
SVG
 
Name:
    SVG
 
Type:
    Output Device Command
 
Purpose:
    Create SVG (Scalable Vector Graphics) format graphics files.
 
Description:
    The ability to generate graphics for web based applications is
    increasingly important.  The three most common formats for
    web applications are:

        1) GIF
        2) JPEG
        3) PNG (Portable Network Graphics)

    Note that these are all bit mapped formats.

    SVG (Scalable Vector Graphics) is an XML based graphics format
    for web applications.  Note that XML is a meta markup language,
    that is it is a langauge for defining languages.  SVG is one
    specific implementation of an XML language.  This is analogous
    to HTML being a specific implementation of a SGML (Standard
    Generalized Markup Language) language.

    As of 9/2010, most major browsers provide native support for
    SVG files.  The one exception is Internet Explorer.  However,
    version 9 of Internet Explorer is expected to provide native
    support and various SVG plugins are available for earlier
    versions.

    In addition to web browsers, a number of image viewers and
    graphics editing programs now support SVG files.  For example,
    the open source GIMP program can view SVG files.  Having a
    non web-based viewer can be helpful when debugging web applications
    in addition to providing another alternative for graphics output.

    SVG is a vector based rather than a bitmap based protocol.
    Also, SVG is an ASCII file that contains a textual
    description of the graph.  One of the primary advantages
    of this approach is that web graphics can be easily edited
    much the way the HTML files can be edited.  This can make
    the maintenance of the graphics on a web site easier.

    This driver was substantially overhauled 10/2010.  If you
    are interested in using this driver, it is strongly recommended
    that you upgrade to a version of Dataplot that is at least as
    new as 10/2010.

Syntax 1:
    SVG

    This form designates device 1 as an SVG graphics device,
    which results in the SVG output being written to the
    screen.  This syntax is not partiucularly useful since the
    SVG needs to be saved in a file so that an external SVG viewer
    or web browser can read it.
 
Syntax 2:
    DEVICE <1/2/3> SVG

    This form designates one of DATAPLOT's 3 devices (typically
    device 2) as an SVG device.
 
Syntax 3:
    DEVICE <1/2/3> SVG  <hor>   <vert>
    where <hor> specifies the width (in pixels) of the graph;
    and where <vert> specifies the height (in pixels) of the graph.

    By default, Dataplot generates the SVG graph at 600x465
    pixels.  Since the dimensions of the SVG graph are defined when
    the device is intialized (i.e., when the DEVICE 2 SVG command is
    entered), the typical method for specifying the pixel dimensions

         DEVICE 2 PICTURE POINTS 800 600

    cannot be used.  This syntax provides a method for overriding
    the default dimensions.  Note that the minimum dimension is 200
    pixels and the maximum dimension is 1200 pixels.
 
Examples:
    SET IPL1NA plot1.svg
    DEVICE 2 SVG
 
    DEVICE 2 SVG 800 600

Note:
    For SVG, it is typically desirable to put each plot in a
    separate file with a unique name.  This can be accomplished
    with a sequence of commands like the following:

        SET IPL1NA  plot1.svg
        DEVICE 2 SVG
           generate first plot
        DEVICE 2 CLOSE
        SET IPL1NA  plot2.svg
        DEVICE 2 SVG
           generate second plot
        DEVICE 2 CLOSE

    The SET IPL1NA command must come before the DEVICE 2 SVG command
    in order for the name to be used.
 
Note:
    SVG was designed primarily as a graphics format for web pages.
    In Dataplot, you can generate an HTML page with embedded SVG
    graphics by using the CAPTURE HTML command.  This is
    demonstrated in the Program example below.  Note that
    when the CAPTURE HTML is in effect, a DEVICE 2 CLOSE will
    cause the following lines are inserted into the HTML output:

        <OBJECT data="plot.svg"
                width="  600" height="  465"
                type="image/svg+xml">
        </OBJECT>

    The "plot.svg" will actually be the name specified on the
    SET IPL1NA command.

    Note that in some cases, you may want to specify a URL for
    the file name.  This can be specified with the command

        SET SVG URL <url>

    In this case, the path will be removed from the file name
    and replaced with the specified URL.  To turn this off, enter

        SET SVG URL NULL

Note:
    Style sheets allow easier maintenance/editing by specifying
    default attributes in an external style sheet file.  The
    default Dataplot style sheet is "dataplot.css" and it is
    stored in the Dataplot "HELP" sub-directory.

    Currently, Dataplot supports the following class for
    the background (this only sets the color, not the size):

       rect.background

    Currently, Dataplot supports the following classes for
    lines:

       polyline.narrow-solid
       polyline.medium-solid
       polyline.wide-solid
       polyline.extrawide-solid
       polyline.narrow-dotted
       polyline.medium-dotted
       polyline.wide-dotted
       polyline.extrawide-dotted
       polyline.narrow-dash
       polyline.medium-dash
       polyline.wide-dash
       polyline.extrawide-dash
       polyline.narrow-dash2
       polyline.medium-dash2
       polyline.wide-dash2
       polyline.extrawide-dash2
       polyline.narrow-dash3
       polyline.medium-dash3
       polyline.wide-dash3
       polyline.extrawide-dash3
       polyline.narrow-dash4
       polyline.medium-dash4
       polyline.wide-dash4
       polyline.extrawide-dash4
       polyline.narrow-dash5
       polyline.medium-dash5
       polyline.wide-dash5
       polyline.extrawide-dash5

    Currently, Dataplot supports the following classes for
    text:

       text.left-horizontal
       text.center-horizontal
       text.right-horizontal

    Currently, no classes are supported for region fills.

    As we develop more experience with SVG graphics, we may
    expand the supported classes.

    When using external style sheets, you modify the attributes
    of the clases.  However, you do not edit which classes are
    available (Dataplot generates the SVG file based on the above
    classes.

    Dataplot will check the value of certain attributes
    (color for lines, color and size for text) when generating
    the SVG file.  If these are not the default values, then
    a local "style" option will be added for that element
    to override the value in the style sheet.

    To make your own style sheets, simply copy the default
    file "dataplot.css" to a new file name and then edit that
    file.  Use the SET SVG STYLE SHEET NAME command (see below)
    to specify the location of the style sheet you wish to use
    (this should be the location of the style sheet relative to
    the location of the SVG file on your web pages).

Note:
    The following SET commands apply to the SVG output.

        SET SVG COORDINATE SYSTEM  <PIXEL/PERCENT>
            - specify whether coordinates are specified in
              pixel units or percent untis.  Currently, only
              pixel units are supported.  The PERCENT option is
              reserved for possible future implementation.

        SET SVG FONT NAME <SERIF/SANS/MONOSPACE>
            - specify the font name for hardware characters.
              Generic names (i.e., supported on all SVG viewers)
              are: serif, sans-serif, and monospace.  Specific
              font names (e.g., Arial) depend on what fonts are
              installed on your local system.  Currently, only
              the generic fonts are supported.  For specific
              fonts, use style sheets and set the name in the
              style sheet.  The default is sans-serif.
        SET SVG FONT WEIGHT <NORMAL/BOLD>
            - specify whether text is drawn as bold or normal.
              The default is bold.
        SET SVG FONT STYLE <NORMAL/ITALIC>
            - specify whether text is drawn in an italic style
              or a normal style.  The default is normal.

        SET SVG CAP STYLE <BUTT/ROUND/SQUARE/NONE>
            - specify the cap style for line drawing.  The default
              is butt.
        SET SVG JOIN STYLE <MITER/ROUND/BEVEL/NONE>
            - specify the join style for line draweing.  The default
              is miter.

        SET SVG HARDWARE FILL SWITCH <NONZERO/EVENODD/SOFTWARE>
            - by default, region fills are performed in hardware
              using a "non-zero" rule.  You can also specify
              that an "evenodd" rule be used.  In general, using
              hardware region fill will have better performance.
              However, hardware fills can occassionally have
              unpredictable results.  In this case, you can
              have Dataplot perform region fills in software
              by specifing SOFTWARE.

        SET SVG STYLE SHEET <INTERNAL/EXTERNAL/NONE>
            - specify whether the SVG graphics are generated
              using style sheets (EXTERNAL) or not (NONE).  In
              general, style sheets are most beneficial when
              multiple graphics are being used on a web site.
              SVG supports both external style sheets (i.e.,
              stored in a separate file) or internal to the
              SVG file.  Currently, Dataplot only supports
              external style sheets.  The INTERNAL switch is
              reserved for possible future implementation.
              There is also an EXTERNAL USE and an EXTERNAL
              CREATE option.  This is reserved for future use,
              but it currently has no effect.
        SET SVG STYLE SHEET NAME <file name>
            - specify the name of the external file sheet
              (up to 80 characters).  The default name is
              "dataplot.css".
        SET SVG FOREGROUND COLOR <color>
            - specify the default foreground color when style
              sheets are being used.  If a line or text color
              does not match this foreground color, then Dataplot
              inserts a "style" option that overrides the style
              sheet value.  Note that the default color is
              set independently in the style sheet file.  So
              you may need to edit the style sheet as well.

Note:
    Each "page" is assigned an ID using the "<g>" element.
    You can add your own translate, scale, and rotate options
    to the SVG file to transform the full plot (this is an element
    of the "Scalable" part of Scalable Vector Graphics).
 
Note:
    Currently, Dataplot generates static plots in SVG format.
    SVG supports advanced capabilities such as animation,
    gradients, and Javascript scripting.  Support for at least
    some of these capabilities may be added in future
    implementations.  However, you can edit the SVG file
    (either via an ASCII text editor or a graphics editing
    program) to add such capabilities.
 
Note:
    Graphic elements are now assigned "layers".  This may be
    useful if you import the SVG graphic into a graphics editing
    program (i.e., it may allow individual elements of the graph
    to be edited).
 
Default:
    None
 
Synonyms:
    None
 
Device Notes:
    HARDWARE TEXT  - The SVG device currently supports
                     hardware characters.  Available fonts may
                     depend on what fonts you have supported on
                     your system.
    COLOR          - SVG supports the full range of 88 colors supported
                     by Dataplot.
    HARDWARE FILL  - Solid area fills are performed in hardware.  You
                     can override this to generate them in software.
    DASH PATTERNS  - The following dash patterns are available:

                        DASH  - 3 pixels on, 3 pixels off;
                        DOT   - 1 pixel on, 1 pixels off;
                        DASH2 - 9 pixels on, 5 pixels off
                        DASH3 - 5 pixels on, 3 pixels off,
                                9 pixel on, 2 pixel off;
                        DASH4 - 9 pixels on, 3 pixels off,
                                5 pixel on, 9 pixel off, 
                                3 pixel on, 5 pixel off;
                        DASH5 - 5 pixels on, 2 pixels off;
 
                     If you want to modify these patterns, it is
                     recommended that you use external style sheets.
    LINE WIDTH     - Thick lines are generated in hardware.
    GRAPHICS INPUT - The CROSS-HAIR command is not supported
                     for this device.
    The CHARACTER PIXEL option is supported on this device.
 
Related Commands:
    GD PNG/JPEG     = Direct graphical output to a file in PNG/JPEG
                      format.
    POSTSCRIPT      = Direct graphical output to a Postscript device.
    LATEX           = Direct graphical output to a file in Latex format.
    HPGL            = Direct graphical output to an HPGL device.
    DEVICE          = Specify certain actions for the graphics output.
 
Applications:
    Web Applications, Graphics Import Into Graphics Editing
    Programs
 
Reference:
    David Eisenberg (2002), "SVG Essentials", O'Reilly.

    Andrew Watt (2002), "Designing SVG Web Graphics", New Riders.
 
Implementation Date:
    2002/3
    2008/3 - Added support for layers
    2010/9 - Substantially overhauled this driver
 
Program 1:
    SET IPL1NA PLOT1.SVG
    DEVICE 2 SVG
    DEVICE 2 PICTURE POINTS 400 300
    TITLE SAMPLE SVG PLOT
    PLOT X**2 FOR X = 1 1 9
    DEVICE 2 CLOSE
    SET IPL1NA PLOT2.SVG
    DEVICE 2 SVG
    DEVICE 2 PICTURE POINTS 500 400
    TITLE SECOND SAMPLE SVG PLOT
    PLOT X**3 FOR X = 1 1 9
    DEVICE 2 CLOSE

Program 2:
    .  svg.dp  - Sample SVG program
    .
    .            Demonstrate how to generate SVG within an
    .            HTML page
    .
    background color yellow
    .
    set ipl1na plot.svg
    device 2 svg  800 600
    .
    title size 3
    title offset 2
    title case asis
    label case asis
    title Sample SVG Plot
    title offset 2
    y1label Y Axis
    x1label X Axis
    label size 1.5
    char size 1
    .
    char x circle box
    char hw 1 0.5  0.5 0.375 0.5 0.375
    char fill off on on
    line solid dash dotted
    .
    feedback off
    capture html svg.htm
    plot x      for x = 1 1 9 and
    plot x**1.5 for x = 1 1 9 and
    plot x**2   for x = 1 1 9
    device 2 close
    end of capture
    feedback on

---------------------------------------------------------









































-END -----*-----      ----------------ZZZZZ------
